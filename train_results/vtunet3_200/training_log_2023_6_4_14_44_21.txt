2023-06-04 14:44:23.592358: Created Ð° model 
2023-06-04 14:44:23.593384: total number of trainable parameters 20757084 
2023-06-04 14:44:26.098561: total number of flops 164961401216.0 
2023-06-04 14:44:26.100967: <bound method EDiceLoss.metric of EDiceLoss()> 
2023-06-04 14:44:26.107611: Train dataset number of batch: 129 
2023-06-04 14:44:26.107701: Val dataset number of batch: 72 
2023-06-04 14:44:26.107736: Bench Test dataset number of batch: 25 
2023-06-04 14:44:26.107830: start training now! 
2023-06-04 14:44:26.107875: Batches per epoch:  129 
2023-06-04 14:44:35.199706: train Epoch: [0][  0/129]	Time  9.092 ( 9.092)	Data  7.922 ( 7.922)	Loss 8.7899e-01 (8.7899e-01) 
2023-06-04 14:44:36.177078: train Epoch: [0][  1/129]	Time  0.977 ( 5.035)	Data  0.001 ( 3.961)	Loss 8.5139e-01 (8.6519e-01) 
2023-06-04 14:44:42.535945: train Epoch: [0][  2/129]	Time  6.359 ( 5.476)	Data  5.376 ( 4.433)	Loss 8.4643e-01 (8.5893e-01) 
2023-06-04 14:44:43.527017: train Epoch: [0][  3/129]	Time  0.991 ( 4.355)	Data  0.001 ( 3.325)	Loss 8.4646e-01 (8.5582e-01) 
2023-06-04 14:44:50.026343: train Epoch: [0][  4/129]	Time  6.499 ( 4.784)	Data  5.516 ( 3.763)	Loss 8.2416e-01 (8.4949e-01) 
2023-06-04 14:44:51.033952: train Epoch: [0][  5/129]	Time  1.008 ( 4.154)	Data  0.039 ( 3.142)	Loss 8.3157e-01 (8.4650e-01) 
2023-06-04 14:44:57.505038: train Epoch: [0][  6/129]	Time  6.471 ( 4.485)	Data  5.501 ( 3.479)	Loss 8.2674e-01 (8.4368e-01) 
2023-06-04 14:44:58.899186: train Epoch: [0][  7/129]	Time  1.394 ( 4.099)	Data  0.426 ( 3.098)	Loss 7.9699e-01 (8.3784e-01) 
2023-06-04 14:45:05.146958: train Epoch: [0][  8/129]	Time  6.248 ( 4.338)	Data  5.258 ( 3.338)	Loss 8.1301e-01 (8.3508e-01) 
2023-06-04 14:45:06.471405: train Epoch: [0][  9/129]	Time  1.324 ( 4.036)	Data  0.344 ( 3.038)	Loss 8.1989e-01 (8.3356e-01) 
2023-06-04 14:45:12.667329: train Epoch: [0][ 10/129]	Time  6.196 ( 4.233)	Data  5.213 ( 3.236)	Loss 7.7765e-01 (8.2848e-01) 
2023-06-04 14:45:13.946226: train Epoch: [0][ 11/129]	Time  1.279 ( 3.987)	Data  0.296 ( 2.991)	Loss 8.0885e-01 (8.2684e-01) 
2023-06-04 14:45:20.165074: train Epoch: [0][ 12/129]	Time  6.219 ( 4.158)	Data  5.249 ( 3.165)	Loss 7.9821e-01 (8.2464e-01) 
2023-06-04 14:45:21.569885: train Epoch: [0][ 13/129]	Time  1.405 ( 3.962)	Data  0.436 ( 2.970)	Loss 7.7364e-01 (8.2100e-01) 
2023-06-04 14:45:27.780348: train Epoch: [0][ 14/129]	Time  6.210 ( 4.111)	Data  5.231 ( 3.121)	Loss 7.4909e-01 (8.1620e-01) 
2023-06-04 14:45:29.264871: train Epoch: [0][ 15/129]	Time  1.485 ( 3.947)	Data  0.515 ( 2.958)	Loss 7.9837e-01 (8.1509e-01) 
2023-06-04 14:45:35.211678: train Epoch: [0][ 16/129]	Time  5.947 ( 4.065)	Data  4.957 ( 3.075)	Loss 7.2253e-01 (8.0964e-01) 
2023-06-04 14:45:36.760186: train Epoch: [0][ 17/129]	Time  1.548 ( 3.925)	Data  0.567 ( 2.936)	Loss 7.7340e-01 (8.0763e-01) 
2023-06-04 14:45:42.724012: train Epoch: [0][ 18/129]	Time  5.964 ( 4.032)	Data  4.983 ( 3.044)	Loss 7.5303e-01 (8.0476e-01) 
2023-06-04 14:45:44.226057: train Epoch: [0][ 19/129]	Time  1.502 ( 3.906)	Data  0.508 ( 2.917)	Loss 7.5873e-01 (8.0246e-01) 
2023-06-04 14:45:50.399056: train Epoch: [0][ 20/129]	Time  6.173 ( 4.014)	Data  5.193 ( 3.025)	Loss 7.5203e-01 (8.0005e-01) 
2023-06-04 14:45:51.809762: train Epoch: [0][ 21/129]	Time  1.411 ( 3.896)	Data  0.429 ( 2.907)	Loss 7.3133e-01 (7.9693e-01) 
2023-06-04 14:45:57.955025: train Epoch: [0][ 22/129]	Time  6.145 ( 3.993)	Data  5.164 ( 3.005)	Loss 6.9198e-01 (7.9237e-01) 
2023-06-04 14:45:59.339053: train Epoch: [0][ 23/129]	Time  1.384 ( 3.885)	Data  0.405 ( 2.897)	Loss 7.1660e-01 (7.8921e-01) 
2023-06-04 14:46:05.684984: train Epoch: [0][ 24/129]	Time  6.346 ( 3.983)	Data  5.357 ( 2.995)	Loss 7.2873e-01 (7.8679e-01) 
2023-06-04 14:46:06.952696: train Epoch: [0][ 25/129]	Time  1.268 ( 3.879)	Data  0.287 ( 2.891)	Loss 7.5220e-01 (7.8546e-01) 
2023-06-04 14:46:12.984384: train Epoch: [0][ 26/129]	Time  6.032 ( 3.958)	Data  5.044 ( 2.971)	Loss 6.8143e-01 (7.8161e-01) 
2023-06-04 14:46:14.477490: train Epoch: [0][ 27/129]	Time  1.493 ( 3.870)	Data  0.509 ( 2.883)	Loss 7.0623e-01 (7.7892e-01) 
2023-06-04 14:46:20.392457: train Epoch: [0][ 28/129]	Time  5.915 ( 3.941)	Data  4.945 ( 2.954)	Loss 7.2162e-01 (7.7694e-01) 
2023-06-04 14:46:22.036617: train Epoch: [0][ 29/129]	Time  1.644 ( 3.864)	Data  0.673 ( 2.878)	Loss 6.9924e-01 (7.7435e-01) 
2023-06-04 14:46:28.021549: train Epoch: [0][ 30/129]	Time  5.985 ( 3.933)	Data  5.015 ( 2.947)	Loss 6.9936e-01 (7.7193e-01) 
2023-06-04 14:46:29.569033: train Epoch: [0][ 31/129]	Time  1.547 ( 3.858)	Data  0.578 ( 2.873)	Loss 7.1341e-01 (7.7010e-01) 
2023-06-04 14:46:35.251547: train Epoch: [0][ 32/129]	Time  5.683 ( 3.913)	Data  4.703 ( 2.928)	Loss 6.9145e-01 (7.6772e-01) 
2023-06-04 14:46:37.322324: train Epoch: [0][ 33/129]	Time  2.071 ( 3.859)	Data  1.101 ( 2.875)	Loss 6.5975e-01 (7.6454e-01) 
2023-06-04 14:46:42.869876: train Epoch: [0][ 34/129]	Time  5.548 ( 3.907)	Data  4.577 ( 2.923)	Loss 6.9076e-01 (7.6243e-01) 
2023-06-04 14:46:44.966695: train Epoch: [0][ 35/129]	Time  2.097 ( 3.857)	Data  1.110 ( 2.873)	Loss 7.0113e-01 (7.6073e-01) 
2023-06-04 14:46:50.444078: train Epoch: [0][ 36/129]	Time  5.477 ( 3.901)	Data  4.508 ( 2.917)	Loss 6.6672e-01 (7.5819e-01) 
2023-06-04 14:46:52.669136: train Epoch: [0][ 37/129]	Time  2.225 ( 3.857)	Data  1.254 ( 2.873)	Loss 6.6791e-01 (7.5582e-01) 
2023-06-04 14:46:57.898251: train Epoch: [0][ 38/129]	Time  5.229 ( 3.892)	Data  4.252 ( 2.909)	Loss 7.2876e-01 (7.5512e-01) 
2023-06-04 14:47:00.341095: train Epoch: [0][ 39/129]	Time  2.443 ( 3.856)	Data  1.472 ( 2.873)	Loss 6.7967e-01 (7.5324e-01) 
2023-06-04 14:47:05.487289: train Epoch: [0][ 40/129]	Time  5.146 ( 3.887)	Data  4.174 ( 2.905)	Loss 6.4761e-01 (7.5066e-01) 
2023-06-04 14:47:08.052882: train Epoch: [0][ 41/129]	Time  2.566 ( 3.856)	Data  1.583 ( 2.873)	Loss 6.6753e-01 (7.4868e-01) 
2023-06-04 14:47:13.160514: train Epoch: [0][ 42/129]	Time  5.108 ( 3.885)	Data  4.125 ( 2.902)	Loss 6.6134e-01 (7.4665e-01) 
2023-06-04 14:47:15.838833: train Epoch: [0][ 43/129]	Time  2.678 ( 3.858)	Data  1.668 ( 2.874)	Loss 6.1954e-01 (7.4376e-01) 
2023-06-04 14:47:20.620019: train Epoch: [0][ 44/129]	Time  4.781 ( 3.878)	Data  3.810 ( 2.895)	Loss 6.1531e-01 (7.4091e-01) 
2023-06-04 14:47:23.376055: train Epoch: [0][ 45/129]	Time  2.756 ( 3.854)	Data  1.787 ( 2.871)	Loss 6.2162e-01 (7.3831e-01) 
2023-06-04 14:47:28.412875: train Epoch: [0][ 46/129]	Time  5.037 ( 3.879)	Data  4.068 ( 2.896)	Loss 6.3472e-01 (7.3611e-01) 
2023-06-04 14:47:30.891031: train Epoch: [0][ 47/129]	Time  2.478 ( 3.850)	Data  1.498 ( 2.867)	Loss 5.7318e-01 (7.3271e-01) 
2023-06-04 14:47:36.047220: train Epoch: [0][ 48/129]	Time  5.156 ( 3.876)	Data  4.147 ( 2.893)	Loss 5.7993e-01 (7.2960e-01) 
2023-06-04 14:47:38.549888: train Epoch: [0][ 49/129]	Time  2.503 ( 3.849)	Data  1.534 ( 2.866)	Loss 5.9185e-01 (7.2684e-01) 
2023-06-04 14:47:43.350723: train Epoch: [0][ 50/129]	Time  4.801 ( 3.868)	Data  3.816 ( 2.885)	Loss 5.1560e-01 (7.2270e-01) 
2023-06-04 14:47:46.352791: train Epoch: [0][ 51/129]	Time  3.002 ( 3.851)	Data  2.032 ( 2.868)	Loss 5.6517e-01 (7.1967e-01) 
2023-06-04 14:47:50.725288: train Epoch: [0][ 52/129]	Time  4.372 ( 3.861)	Data  3.402 ( 2.878)	Loss 5.2443e-01 (7.1599e-01) 
2023-06-04 14:47:53.812819: train Epoch: [0][ 53/129]	Time  3.088 ( 3.846)	Data  2.119 ( 2.864)	Loss 5.2041e-01 (7.1236e-01) 
2023-06-04 14:47:58.084444: train Epoch: [0][ 54/129]	Time  4.272 ( 3.854)	Data  3.289 ( 2.872)	Loss 5.7632e-01 (7.0989e-01) 
2023-06-04 14:48:01.361354: train Epoch: [0][ 55/129]	Time  3.277 ( 3.844)	Data  2.306 ( 2.862)	Loss 5.5336e-01 (7.0710e-01) 
2023-06-04 14:48:05.490440: train Epoch: [0][ 56/129]	Time  4.129 ( 3.849)	Data  3.140 ( 2.867)	Loss 4.8492e-01 (7.0320e-01) 
2023-06-04 14:48:09.029487: train Epoch: [0][ 57/129]	Time  3.539 ( 3.843)	Data  2.556 ( 2.862)	Loss 4.5875e-01 (6.9898e-01) 
2023-06-04 14:48:12.979420: train Epoch: [0][ 58/129]	Time  3.950 ( 3.845)	Data  2.966 ( 2.863)	Loss 4.8916e-01 (6.9543e-01) 
2023-06-04 14:48:16.483929: train Epoch: [0][ 59/129]	Time  3.505 ( 3.840)	Data  2.523 ( 2.858)	Loss 4.9640e-01 (6.9211e-01) 
2023-06-04 14:48:20.701026: train Epoch: [0][ 60/129]	Time  4.217 ( 3.846)	Data  3.235 ( 2.864)	Loss 4.6136e-01 (6.8833e-01) 
2023-06-04 14:48:24.407600: train Epoch: [0][ 61/129]	Time  3.707 ( 3.844)	Data  2.722 ( 2.862)	Loss 4.2053e-01 (6.8401e-01) 
2023-06-04 14:48:28.095023: train Epoch: [0][ 62/129]	Time  3.687 ( 3.841)	Data  2.697 ( 2.859)	Loss 3.6607e-01 (6.7896e-01) 
2023-06-04 14:48:32.037979: train Epoch: [0][ 63/129]	Time  3.943 ( 3.843)	Data  2.960 ( 2.860)	Loss 5.2584e-01 (6.7657e-01) 
2023-06-04 14:48:35.503444: train Epoch: [0][ 64/129]	Time  3.465 ( 3.837)	Data  2.469 ( 2.854)	Loss 4.8474e-01 (6.7362e-01) 
2023-06-04 14:48:39.617592: train Epoch: [0][ 65/129]	Time  4.114 ( 3.841)	Data  3.143 ( 2.859)	Loss 4.7855e-01 (6.7066e-01) 
2023-06-04 14:48:43.163770: train Epoch: [0][ 66/129]	Time  3.546 ( 3.837)	Data  2.577 ( 2.855)	Loss 4.7184e-01 (6.6769e-01) 
2023-06-04 14:48:47.081812: train Epoch: [0][ 67/129]	Time  3.918 ( 3.838)	Data  2.947 ( 2.856)	Loss 4.0746e-01 (6.6387e-01) 
2023-06-04 14:48:50.716321: train Epoch: [0][ 68/129]	Time  3.635 ( 3.835)	Data  2.665 ( 2.853)	Loss 4.3376e-01 (6.6053e-01) 
2023-06-04 14:48:54.613490: train Epoch: [0][ 69/129]	Time  3.897 ( 3.836)	Data  2.928 ( 2.854)	Loss 3.8245e-01 (6.5656e-01) 
2023-06-04 14:48:58.547434: train Epoch: [0][ 70/129]	Time  3.934 ( 3.837)	Data  2.965 ( 2.856)	Loss 4.8428e-01 (6.5413e-01) 
2023-06-04 14:49:01.926815: train Epoch: [0][ 71/129]	Time  3.379 ( 3.831)	Data  2.400 ( 2.850)	Loss 2.9083e-01 (6.4909e-01) 
2023-06-04 14:49:06.058217: train Epoch: [0][ 72/129]	Time  4.131 ( 3.835)	Data  3.161 ( 2.854)	Loss 5.7129e-01 (6.4802e-01) 
2023-06-04 14:49:09.312392: train Epoch: [0][ 73/129]	Time  3.254 ( 3.827)	Data  2.284 ( 2.846)	Loss 3.3485e-01 (6.4379e-01) 
2023-06-04 14:49:13.628617: train Epoch: [0][ 74/129]	Time  4.316 ( 3.834)	Data  3.341 ( 2.853)	Loss 3.8004e-01 (6.4027e-01) 
2023-06-04 14:49:16.700167: train Epoch: [0][ 75/129]	Time  3.072 ( 3.824)	Data  2.101 ( 2.843)	Loss 4.4277e-01 (6.3767e-01) 
2023-06-04 14:49:21.280994: train Epoch: [0][ 76/129]	Time  4.581 ( 3.833)	Data  3.606 ( 2.853)	Loss 3.2326e-01 (6.3359e-01) 
2023-06-04 14:49:24.172495: train Epoch: [0][ 77/129]	Time  2.892 ( 3.821)	Data  1.924 ( 2.841)	Loss 4.1415e-01 (6.3078e-01) 
2023-06-04 14:49:28.807684: train Epoch: [0][ 78/129]	Time  4.635 ( 3.832)	Data  3.667 ( 2.851)	Loss 2.8614e-01 (6.2642e-01) 
2023-06-04 14:49:31.629554: train Epoch: [0][ 79/129]	Time  2.822 ( 3.819)	Data  1.853 ( 2.839)	Loss 3.6524e-01 (6.2315e-01) 
2023-06-04 14:49:36.236017: train Epoch: [0][ 80/129]	Time  4.606 ( 3.829)	Data  3.626 ( 2.849)	Loss 3.6761e-01 (6.2000e-01) 
2023-06-04 14:49:39.098905: train Epoch: [0][ 81/129]	Time  2.863 ( 3.817)	Data  1.894 ( 2.837)	Loss 3.4910e-01 (6.1669e-01) 
2023-06-04 14:49:43.523771: train Epoch: [0][ 82/129]	Time  4.425 ( 3.824)	Data  3.454 ( 2.844)	Loss 3.1089e-01 (6.1301e-01) 
2023-06-04 14:49:46.274189: train Epoch: [0][ 83/129]	Time  2.750 ( 3.811)	Data  1.771 ( 2.832)	Loss 3.2915e-01 (6.0963e-01) 
2023-06-04 14:49:51.103828: train Epoch: [0][ 84/129]	Time  4.830 ( 3.823)	Data  3.861 ( 2.844)	Loss 3.0634e-01 (6.0606e-01) 
2023-06-04 14:49:53.942210: train Epoch: [0][ 85/129]	Time  2.838 ( 3.812)	Data  1.869 ( 2.832)	Loss 3.6900e-01 (6.0330e-01) 
2023-06-04 14:49:58.802052: train Epoch: [0][ 86/129]	Time  4.860 ( 3.824)	Data  3.892 ( 2.844)	Loss 3.7505e-01 (6.0068e-01) 
2023-06-04 14:50:01.445621: train Epoch: [0][ 87/129]	Time  2.644 ( 3.811)	Data  1.676 ( 2.831)	Loss 1.9007e-01 (5.9601e-01) 
2023-06-04 14:50:05.647320: train Epoch: [0][ 88/129]	Time  4.202 ( 3.815)	Data  3.225 ( 2.836)	Loss 4.0016e-01 (5.9381e-01) 
2023-06-04 14:50:06.773087: train Epoch: [0][ 89/129]	Time  1.126 ( 3.785)	Data  0.152 ( 2.806)	Loss 3.1890e-01 (5.9076e-01) 
2023-06-04 14:50:11.637563: train Epoch: [0][ 90/129]	Time  4.864 ( 3.797)	Data  3.894 ( 2.818)	Loss 3.7816e-01 (5.8842e-01) 
2023-06-04 14:50:13.328035: train Epoch: [0][ 91/129]	Time  1.690 ( 3.774)	Data  0.721 ( 2.795)	Loss 3.7001e-01 (5.8605e-01) 
2023-06-04 14:50:18.814545: train Epoch: [0][ 92/129]	Time  5.487 ( 3.793)	Data  4.517 ( 2.813)	Loss 2.6534e-01 (5.8260e-01) 
2023-06-04 14:50:20.838500: train Epoch: [0][ 93/129]	Time  2.024 ( 3.774)	Data  1.041 ( 2.795)	Loss 3.6243e-01 (5.8026e-01) 
2023-06-04 14:50:26.462597: train Epoch: [0][ 94/129]	Time  5.624 ( 3.793)	Data  4.644 ( 2.814)	Loss 3.0001e-01 (5.7731e-01) 
2023-06-04 14:50:28.575361: train Epoch: [0][ 95/129]	Time  2.113 ( 3.776)	Data  1.129 ( 2.797)	Loss 3.3190e-01 (5.7475e-01) 
2023-06-04 14:50:34.088126: train Epoch: [0][ 96/129]	Time  5.513 ( 3.794)	Data  4.519 ( 2.814)	Loss 4.1970e-01 (5.7315e-01) 
2023-06-04 14:50:36.156910: train Epoch: [0][ 97/129]	Time  2.069 ( 3.776)	Data  1.098 ( 2.797)	Loss 3.9530e-01 (5.7134e-01) 
2023-06-04 14:50:41.637001: train Epoch: [0][ 98/129]	Time  5.480 ( 3.793)	Data  4.494 ( 2.814)	Loss 2.6045e-01 (5.6820e-01) 
2023-06-04 14:50:43.954577: train Epoch: [0][ 99/129]	Time  2.318 ( 3.778)	Data  1.347 ( 2.799)	Loss 3.4792e-01 (5.6600e-01) 
2023-06-04 14:50:49.374398: train Epoch: [0][100/129]	Time  5.420 ( 3.795)	Data  4.431 ( 2.815)	Loss 4.4726e-01 (5.6482e-01) 
2023-06-04 14:50:51.326408: train Epoch: [0][101/129]	Time  1.952 ( 3.777)	Data  0.982 ( 2.797)	Loss 4.1075e-01 (5.6331e-01) 
2023-06-04 14:50:56.940843: train Epoch: [0][102/129]	Time  5.614 ( 3.794)	Data  4.613 ( 2.815)	Loss 3.3458e-01 (5.6109e-01) 
2023-06-04 14:50:58.883831: train Epoch: [0][103/129]	Time  1.943 ( 3.777)	Data  0.972 ( 2.797)	Loss 3.6364e-01 (5.5919e-01) 
2023-06-04 14:51:04.889600: train Epoch: [0][104/129]	Time  6.006 ( 3.798)	Data  5.018 ( 2.818)	Loss 3.7987e-01 (5.5748e-01) 
2023-06-04 14:51:06.689549: train Epoch: [0][105/129]	Time  1.800 ( 3.779)	Data  0.818 ( 2.800)	Loss 3.6379e-01 (5.5566e-01) 
2023-06-04 14:51:12.865779: train Epoch: [0][106/129]	Time  6.176 ( 3.801)	Data  5.199 ( 2.822)	Loss 2.5770e-01 (5.5287e-01) 
2023-06-04 14:51:14.241511: train Epoch: [0][107/129]	Time  1.376 ( 3.779)	Data  0.395 ( 2.800)	Loss 3.0588e-01 (5.5058e-01) 
2023-06-04 14:51:20.560249: train Epoch: [0][108/129]	Time  6.319 ( 3.802)	Data  5.344 ( 2.823)	Loss 2.2606e-01 (5.4761e-01) 
2023-06-04 14:51:21.992057: train Epoch: [0][109/129]	Time  1.432 ( 3.781)	Data  0.462 ( 2.801)	Loss 3.6339e-01 (5.4593e-01) 
2023-06-04 14:51:28.164765: train Epoch: [0][110/129]	Time  6.173 ( 3.802)	Data  5.203 ( 2.823)	Loss 3.3341e-01 (5.4402e-01) 
2023-06-04 14:51:29.468385: train Epoch: [0][111/129]	Time  1.304 ( 3.780)	Data  0.332 ( 2.801)	Loss 3.7818e-01 (5.4254e-01) 
2023-06-04 14:51:35.642593: train Epoch: [0][112/129]	Time  6.174 ( 3.801)	Data  5.204 ( 2.822)	Loss 4.3062e-01 (5.4155e-01) 
2023-06-04 14:51:37.178389: train Epoch: [0][113/129]	Time  1.536 ( 3.781)	Data  0.567 ( 2.802)	Loss 2.7250e-01 (5.3919e-01) 
2023-06-04 14:51:41.883731: train Epoch: [0][114/129]	Time  4.705 ( 3.789)	Data  3.727 ( 2.810)	Loss 2.7025e-01 (5.3685e-01) 
2023-06-04 14:51:43.032434: train Epoch: [0][115/129]	Time  1.149 ( 3.767)	Data  0.179 ( 2.788)	Loss 3.7862e-01 (5.3548e-01) 
2023-06-04 14:51:49.451148: train Epoch: [0][116/129]	Time  6.419 ( 3.789)	Data  5.450 ( 2.810)	Loss 2.9919e-01 (5.3346e-01) 
2023-06-04 14:51:50.742139: train Epoch: [0][117/129]	Time  1.291 ( 3.768)	Data  0.320 ( 2.789)	Loss 3.8621e-01 (5.3222e-01) 
2023-06-04 14:51:56.953999: train Epoch: [0][118/129]	Time  6.212 ( 3.789)	Data  5.241 ( 2.810)	Loss 3.7696e-01 (5.3091e-01) 
2023-06-04 14:51:58.325298: train Epoch: [0][119/129]	Time  1.371 ( 3.768)	Data  0.400 ( 2.790)	Loss 2.7971e-01 (5.2882e-01) 
2023-06-04 14:52:04.604139: train Epoch: [0][120/129]	Time  6.279 ( 3.789)	Data  5.311 ( 2.811)	Loss 3.1597e-01 (5.2706e-01) 
2023-06-04 14:52:06.067431: train Epoch: [0][121/129]	Time  1.463 ( 3.770)	Data  0.493 ( 2.792)	Loss 4.1545e-01 (5.2614e-01) 
2023-06-04 14:52:12.102905: train Epoch: [0][122/129]	Time  6.035 ( 3.789)	Data  5.065 ( 2.810)	Loss 3.5170e-01 (5.2473e-01) 
2023-06-04 14:52:13.612089: train Epoch: [0][123/129]	Time  1.509 ( 3.770)	Data  0.526 ( 2.792)	Loss 2.6639e-01 (5.2264e-01) 
2023-06-04 14:52:19.623186: train Epoch: [0][124/129]	Time  6.011 ( 3.788)	Data  5.031 ( 2.810)	Loss 2.5161e-01 (5.2047e-01) 
2023-06-04 14:52:21.071188: train Epoch: [0][125/129]	Time  1.448 ( 3.770)	Data  0.467 ( 2.791)	Loss 2.8694e-01 (5.1862e-01) 
2023-06-04 14:52:27.138601: train Epoch: [0][126/129]	Time  6.067 ( 3.788)	Data  5.100 ( 2.809)	Loss 3.1759e-01 (5.1704e-01) 
2023-06-04 14:52:28.581361: train Epoch: [0][127/129]	Time  1.443 ( 3.769)	Data  0.472 ( 2.791)	Loss 2.6784e-01 (5.1509e-01) 
2023-06-04 14:52:33.069336: train Epoch: [0][128/129]	Time  4.488 ( 3.775)	Data  3.495 ( 2.796)	Loss 2.3295e-01 (5.1290e-01) 
2023-06-04 14:52:33.257639: Train Epoch done in 487.14976493804716 s 
2023-06-04 14:52:37.054329: val Epoch: [0][ 0/72]	Time  3.316 ( 3.316)	Data  3.037 ( 3.037)	Loss 2.2998e-01 (2.2998e-01) 
2023-06-04 14:52:37.200608: val Epoch: [0][ 1/72]	Time  0.146 ( 1.731)	Data  0.001 ( 1.519)	Loss 4.0722e-01 (3.1860e-01) 
2023-06-04 14:52:39.660634: val Epoch: [0][ 2/72]	Time  2.460 ( 1.974)	Data  2.327 ( 1.788)	Loss 2.7389e-01 (3.0370e-01) 
2023-06-04 14:52:39.787400: val Epoch: [0][ 3/72]	Time  0.127 ( 1.512)	Data  0.001 ( 1.341)	Loss 2.4995e-01 (2.9026e-01) 
2023-06-04 14:52:42.261156: val Epoch: [0][ 4/72]	Time  2.474 ( 1.705)	Data  2.343 ( 1.542)	Loss 2.7990e-01 (2.8819e-01) 
2023-06-04 14:52:42.391902: val Epoch: [0][ 5/72]	Time  0.131 ( 1.442)	Data  0.001 ( 1.285)	Loss 1.4360e-01 (2.6409e-01) 
2023-06-04 14:52:45.015708: val Epoch: [0][ 6/72]	Time  2.624 ( 1.611)	Data  2.492 ( 1.457)	Loss 6.9124e-01 (3.2511e-01) 
2023-06-04 14:52:45.146485: val Epoch: [0][ 7/72]	Time  0.131 ( 1.426)	Data  0.001 ( 1.275)	Loss 3.5944e-01 (3.2940e-01) 
2023-06-04 14:52:47.644809: val Epoch: [0][ 8/72]	Time  2.498 ( 1.545)	Data  2.363 ( 1.396)	Loss 2.6508e-01 (3.2226e-01) 
2023-06-04 14:52:47.775210: val Epoch: [0][ 9/72]	Time  0.130 ( 1.404)	Data  0.001 ( 1.257)	Loss 2.8502e-01 (3.1853e-01) 
2023-06-04 14:52:50.267356: val Epoch: [0][10/72]	Time  2.492 ( 1.503)	Data  2.360 ( 1.357)	Loss 2.0594e-01 (3.0830e-01) 
2023-06-04 14:52:50.414092: val Epoch: [0][11/72]	Time  0.147 ( 1.390)	Data  0.017 ( 1.245)	Loss 5.9651e-01 (3.3231e-01) 
2023-06-04 14:52:52.952838: val Epoch: [0][12/72]	Time  2.539 ( 1.478)	Data  2.409 ( 1.335)	Loss 4.7843e-01 (3.4355e-01) 
2023-06-04 14:52:53.079361: val Epoch: [0][13/72]	Time  0.127 ( 1.382)	Data  0.001 ( 1.239)	Loss 4.9720e-01 (3.5453e-01) 
2023-06-04 14:52:55.661480: val Epoch: [0][14/72]	Time  2.582 ( 1.462)	Data  2.458 ( 1.321)	Loss 2.1909e-01 (3.4550e-01) 
2023-06-04 14:52:55.785274: val Epoch: [0][15/72]	Time  0.124 ( 1.378)	Data  0.000 ( 1.238)	Loss 1.9705e-01 (3.3622e-01) 
2023-06-04 14:52:58.241109: val Epoch: [0][16/72]	Time  2.456 ( 1.441)	Data  2.326 ( 1.302)	Loss 3.3527e-01 (3.3617e-01) 
2023-06-04 14:52:58.375207: val Epoch: [0][17/72]	Time  0.134 ( 1.369)	Data  0.001 ( 1.230)	Loss 2.6209e-01 (3.3205e-01) 
2023-06-04 14:53:00.891234: val Epoch: [0][18/72]	Time  2.516 ( 1.429)	Data  2.387 ( 1.291)	Loss 2.8148e-01 (3.2939e-01) 
2023-06-04 14:53:01.021230: val Epoch: [0][19/72]	Time  0.130 ( 1.364)	Data  0.001 ( 1.226)	Loss 1.5987e-01 (3.2091e-01) 
2023-06-04 14:53:03.528617: val Epoch: [0][20/72]	Time  2.507 ( 1.419)	Data  2.378 ( 1.281)	Loss 2.9897e-01 (3.1987e-01) 
2023-06-04 14:53:03.653497: val Epoch: [0][21/72]	Time  0.125 ( 1.360)	Data  0.001 ( 1.223)	Loss 2.0009e-01 (3.1442e-01) 
2023-06-04 14:53:06.145600: val Epoch: [0][22/72]	Time  2.492 ( 1.409)	Data  2.364 ( 1.272)	Loss 1.7982e-01 (3.0857e-01) 
2023-06-04 14:53:06.274457: val Epoch: [0][23/72]	Time  0.129 ( 1.356)	Data  0.001 ( 1.219)	Loss 5.4926e-01 (3.1860e-01) 
2023-06-04 14:53:08.722936: val Epoch: [0][24/72]	Time  2.448 ( 1.399)	Data  2.319 ( 1.263)	Loss 2.4147e-01 (3.1552e-01) 
2023-06-04 14:53:08.853357: val Epoch: [0][25/72]	Time  0.130 ( 1.351)	Data  0.001 ( 1.215)	Loss 2.5934e-01 (3.1335e-01) 
2023-06-04 14:53:11.275809: val Epoch: [0][26/72]	Time  2.422 ( 1.390)	Data  2.293 ( 1.255)	Loss 2.1432e-01 (3.0969e-01) 
2023-06-04 14:53:11.400699: val Epoch: [0][27/72]	Time  0.125 ( 1.345)	Data  0.001 ( 1.210)	Loss 3.6137e-01 (3.1153e-01) 
2023-06-04 14:53:13.816225: val Epoch: [0][28/72]	Time  2.416 ( 1.382)	Data  2.291 ( 1.247)	Loss 6.7865e-01 (3.2419e-01) 
2023-06-04 14:53:13.941090: val Epoch: [0][29/72]	Time  0.125 ( 1.340)	Data  0.001 ( 1.206)	Loss 2.6315e-01 (3.2216e-01) 
2023-06-04 14:53:16.433049: val Epoch: [0][30/72]	Time  2.492 ( 1.377)	Data  2.366 ( 1.243)	Loss 5.6116e-01 (3.2987e-01) 
2023-06-04 14:53:16.562476: val Epoch: [0][31/72]	Time  0.129 ( 1.338)	Data  0.001 ( 1.204)	Loss 1.9420e-01 (3.2563e-01) 
2023-06-04 14:53:19.069266: val Epoch: [0][32/72]	Time  2.507 ( 1.374)	Data  2.359 ( 1.239)	Loss 2.3400e-01 (3.2285e-01) 
2023-06-04 14:53:19.192569: val Epoch: [0][33/72]	Time  0.123 ( 1.337)	Data  0.000 ( 1.203)	Loss 5.4025e-01 (3.2924e-01) 
2023-06-04 14:53:21.577644: val Epoch: [0][34/72]	Time  2.385 ( 1.367)	Data  2.265 ( 1.233)	Loss 4.0504e-01 (3.3141e-01) 
2023-06-04 14:53:21.698208: val Epoch: [0][35/72]	Time  0.121 ( 1.332)	Data  0.001 ( 1.199)	Loss 6.2034e-01 (3.3944e-01) 
2023-06-04 14:53:24.203612: val Epoch: [0][36/72]	Time  2.505 ( 1.364)	Data  2.376 ( 1.231)	Loss 2.0699e-01 (3.3586e-01) 
2023-06-04 14:53:24.333453: val Epoch: [0][37/72]	Time  0.130 ( 1.331)	Data  0.001 ( 1.198)	Loss 3.9415e-01 (3.3739e-01) 
2023-06-04 14:53:26.710712: val Epoch: [0][38/72]	Time  2.377 ( 1.358)	Data  2.249 ( 1.225)	Loss 2.0340e-01 (3.3395e-01) 
2023-06-04 14:53:26.840502: val Epoch: [0][39/72]	Time  0.130 ( 1.328)	Data  0.001 ( 1.195)	Loss 2.8699e-01 (3.3278e-01) 
2023-06-04 14:53:29.340933: val Epoch: [0][40/72]	Time  2.500 ( 1.356)	Data  2.371 ( 1.223)	Loss 3.2040e-01 (3.3248e-01) 
2023-06-04 14:53:29.460110: val Epoch: [0][41/72]	Time  0.119 ( 1.327)	Data  0.000 ( 1.194)	Loss 2.8336e-01 (3.3131e-01) 
2023-06-04 14:53:31.818931: val Epoch: [0][42/72]	Time  2.359 ( 1.351)	Data  2.236 ( 1.219)	Loss 2.8499e-01 (3.3023e-01) 
2023-06-04 14:53:31.938814: val Epoch: [0][43/72]	Time  0.120 ( 1.323)	Data  0.001 ( 1.191)	Loss 3.2216e-01 (3.3005e-01) 
2023-06-04 14:53:34.481342: val Epoch: [0][44/72]	Time  2.543 ( 1.350)	Data  2.419 ( 1.218)	Loss 3.8174e-01 (3.3120e-01) 
2023-06-04 14:53:34.604601: val Epoch: [0][45/72]	Time  0.123 ( 1.323)	Data  0.001 ( 1.192)	Loss 2.7625e-01 (3.3000e-01) 
2023-06-04 14:53:37.034023: val Epoch: [0][46/72]	Time  2.429 ( 1.347)	Data  2.299 ( 1.215)	Loss 4.1734e-01 (3.3186e-01) 
2023-06-04 14:53:37.153370: val Epoch: [0][47/72]	Time  0.119 ( 1.321)	Data  0.000 ( 1.190)	Loss 6.0511e-01 (3.3755e-01) 
2023-06-04 14:53:39.521237: val Epoch: [0][48/72]	Time  2.368 ( 1.343)	Data  2.235 ( 1.211)	Loss 3.1725e-01 (3.3714e-01) 
2023-06-04 14:53:39.643181: val Epoch: [0][49/72]	Time  0.122 ( 1.318)	Data  0.001 ( 1.187)	Loss 1.9321e-01 (3.3426e-01) 
2023-06-04 14:53:42.048689: val Epoch: [0][50/72]	Time  2.406 ( 1.339)	Data  2.281 ( 1.208)	Loss 3.3856e-01 (3.3434e-01) 
2023-06-04 14:53:42.168585: val Epoch: [0][51/72]	Time  0.120 ( 1.316)	Data  0.001 ( 1.185)	Loss 5.3429e-01 (3.3819e-01) 
2023-06-04 14:53:44.511810: val Epoch: [0][52/72]	Time  2.343 ( 1.335)	Data  2.223 ( 1.205)	Loss 2.0520e-01 (3.3568e-01) 
2023-06-04 14:53:44.631694: val Epoch: [0][53/72]	Time  0.120 ( 1.313)	Data  0.000 ( 1.183)	Loss 3.4074e-01 (3.3577e-01) 
2023-06-04 14:53:47.030307: val Epoch: [0][54/72]	Time  2.399 ( 1.333)	Data  2.279 ( 1.202)	Loss 6.8024e-01 (3.4204e-01) 
2023-06-04 14:53:47.149418: val Epoch: [0][55/72]	Time  0.119 ( 1.311)	Data  0.000 ( 1.181)	Loss 4.2024e-01 (3.4343e-01) 
2023-06-04 14:53:49.586460: val Epoch: [0][56/72]	Time  2.437 ( 1.331)	Data  2.275 ( 1.200)	Loss 4.0782e-01 (3.4456e-01) 
2023-06-04 14:53:49.748682: val Epoch: [0][57/72]	Time  0.162 ( 1.311)	Data  0.001 ( 1.179)	Loss 5.0417e-01 (3.4732e-01) 
2023-06-04 14:53:52.096347: val Epoch: [0][58/72]	Time  2.348 ( 1.328)	Data  2.221 ( 1.197)	Loss 2.3040e-01 (3.4533e-01) 
2023-06-04 14:53:52.216308: val Epoch: [0][59/72]	Time  0.120 ( 1.308)	Data  0.001 ( 1.177)	Loss 3.6762e-01 (3.4570e-01) 
2023-06-04 14:53:54.645304: val Epoch: [0][60/72]	Time  2.429 ( 1.326)	Data  2.308 ( 1.196)	Loss 5.5809e-01 (3.4919e-01) 
2023-06-04 14:53:54.766605: val Epoch: [0][61/72]	Time  0.121 ( 1.307)	Data  0.002 ( 1.176)	Loss 1.8821e-01 (3.4659e-01) 
2023-06-04 14:53:57.215595: val Epoch: [0][62/72]	Time  2.449 ( 1.325)	Data  2.329 ( 1.195)	Loss 2.7025e-01 (3.4538e-01) 
2023-06-04 14:53:57.335111: val Epoch: [0][63/72]	Time  0.120 ( 1.306)	Data  0.001 ( 1.176)	Loss 5.0358e-01 (3.4785e-01) 
2023-06-04 14:53:59.738809: val Epoch: [0][64/72]	Time  2.404 ( 1.323)	Data  2.283 ( 1.193)	Loss 2.6281e-01 (3.4654e-01) 
2023-06-04 14:53:59.859138: val Epoch: [0][65/72]	Time  0.120 ( 1.305)	Data  0.001 ( 1.175)	Loss 4.1540e-01 (3.4759e-01) 
2023-06-04 14:54:02.258601: val Epoch: [0][66/72]	Time  2.399 ( 1.321)	Data  2.279 ( 1.192)	Loss 4.7925e-01 (3.4955e-01) 
2023-06-04 14:54:02.378238: val Epoch: [0][67/72]	Time  0.120 ( 1.304)	Data  0.001 ( 1.174)	Loss 3.5523e-01 (3.4963e-01) 
2023-06-04 14:54:04.851211: val Epoch: [0][68/72]	Time  2.473 ( 1.320)	Data  2.353 ( 1.191)	Loss 3.3895e-01 (3.4948e-01) 
2023-06-04 14:54:04.971941: val Epoch: [0][69/72]	Time  0.121 ( 1.303)	Data  0.001 ( 1.174)	Loss 3.7567e-01 (3.4985e-01) 
2023-06-04 14:54:07.306998: val Epoch: [0][70/72]	Time  2.335 ( 1.318)	Data  2.215 ( 1.189)	Loss 3.7875e-01 (3.5026e-01) 
2023-06-04 14:54:07.427269: val Epoch: [0][71/72]	Time  0.120 ( 1.301)	Data  0.000 ( 1.172)	Loss 2.3985e-01 (3.4873e-01) 
2023-06-04 14:54:07.726072: Epoch 0 :Val : ['ET : 0.4277191758155823', 'TC : 0.5449151992797852', 'WT : 0.5985906720161438'] 
2023-06-04 14:54:07.731606: Epoch 0 :Val : ['ET : 0.4277191758155823', 'TC : 0.5449151992797852', 'WT : 0.5985906720161438'] 
2023-06-04 14:54:07.735530: Saving the model with DSC 0.5180122256278992 
2023-06-04 14:54:08.170882: Val epoch done in 94.91321964701638 s 
2023-06-04 14:54:08.175957: Batches per epoch:  129 
2023-06-04 14:54:17.396759: train Epoch: [1][  0/129]	Time  9.220 ( 9.220)	Data  8.166 ( 8.166)	Loss 3.7475e-01 (3.7475e-01) 
2023-06-04 14:54:18.398839: train Epoch: [1][  1/129]	Time  1.002 ( 5.111)	Data  0.001 ( 4.084)	Loss 2.1315e-01 (2.9395e-01) 
2023-06-04 14:54:24.812014: train Epoch: [1][  2/129]	Time  6.413 ( 5.545)	Data  5.444 ( 4.537)	Loss 2.9104e-01 (2.9298e-01) 
2023-06-04 14:54:25.784246: train Epoch: [1][  3/129]	Time  0.972 ( 4.402)	Data  0.001 ( 3.403)	Loss 2.7215e-01 (2.8777e-01) 
2023-06-04 14:54:32.167001: train Epoch: [1][  4/129]	Time  6.383 ( 4.798)	Data  5.415 ( 3.805)	Loss 2.7825e-01 (2.8587e-01) 
2023-06-04 14:54:33.138761: train Epoch: [1][  5/129]	Time  0.972 ( 4.160)	Data  0.001 ( 3.171)	Loss 2.1075e-01 (2.7335e-01) 
2023-06-04 14:54:39.716869: train Epoch: [1][  6/129]	Time  6.578 ( 4.506)	Data  5.592 ( 3.517)	Loss 2.2277e-01 (2.6612e-01) 
2023-06-04 14:54:40.685494: train Epoch: [1][  7/129]	Time  0.969 ( 4.064)	Data  0.001 ( 3.077)	Loss 2.1073e-01 (2.5920e-01) 
2023-06-04 14:54:47.475558: train Epoch: [1][  8/129]	Time  6.790 ( 4.367)	Data  5.819 ( 3.382)	Loss 2.5858e-01 (2.5913e-01) 
2023-06-04 14:54:48.462971: train Epoch: [1][  9/129]	Time  0.987 ( 4.029)	Data  0.001 ( 3.044)	Loss 2.3916e-01 (2.5713e-01) 
2023-06-04 14:54:55.269531: train Epoch: [1][ 10/129]	Time  6.807 ( 4.281)	Data  5.823 ( 3.297)	Loss 2.6682e-01 (2.5801e-01) 
2023-06-04 14:54:56.235546: train Epoch: [1][ 11/129]	Time  0.966 ( 4.005)	Data  0.001 ( 3.022)	Loss 2.4694e-01 (2.5709e-01) 
2023-06-04 14:55:03.011357: train Epoch: [1][ 12/129]	Time  6.776 ( 4.218)	Data  5.799 ( 3.236)	Loss 2.6115e-01 (2.5740e-01) 
2023-06-04 14:55:03.978965: train Epoch: [1][ 13/129]	Time  0.968 ( 3.986)	Data  0.001 ( 3.005)	Loss 2.5487e-01 (2.5722e-01) 
2023-06-04 14:55:10.536251: train Epoch: [1][ 14/129]	Time  6.557 ( 4.157)	Data  5.592 ( 3.177)	Loss 3.6761e-01 (2.6458e-01) 
2023-06-04 14:55:11.502535: train Epoch: [1][ 15/129]	Time  0.966 ( 3.958)	Data  0.001 ( 2.979)	Loss 3.8888e-01 (2.7235e-01) 
2023-06-04 14:55:18.450310: train Epoch: [1][ 16/129]	Time  6.948 ( 4.134)	Data  5.981 ( 3.155)	Loss 3.2390e-01 (2.7538e-01) 
2023-06-04 14:55:19.415921: train Epoch: [1][ 17/129]	Time  0.966 ( 3.958)	Data  0.001 ( 2.980)	Loss 2.4080e-01 (2.7346e-01) 
2023-06-04 14:55:26.218135: train Epoch: [1][ 18/129]	Time  6.802 ( 4.107)	Data  5.838 ( 3.130)	Loss 3.6613e-01 (2.7834e-01) 
2023-06-04 14:55:27.185727: train Epoch: [1][ 19/129]	Time  0.968 ( 3.950)	Data  0.001 ( 2.974)	Loss 2.7446e-01 (2.7814e-01) 
2023-06-04 14:55:33.770304: train Epoch: [1][ 20/129]	Time  6.585 ( 4.076)	Data  5.603 ( 3.099)	Loss 3.7231e-01 (2.8263e-01) 
2023-06-04 14:55:34.737498: train Epoch: [1][ 21/129]	Time  0.967 ( 3.935)	Data  0.001 ( 2.958)	Loss 4.4129e-01 (2.8984e-01) 
2023-06-04 14:55:41.263795: train Epoch: [1][ 22/129]	Time  6.526 ( 4.047)	Data  5.562 ( 3.071)	Loss 2.6750e-01 (2.8887e-01) 
2023-06-04 14:55:42.229958: train Epoch: [1][ 23/129]	Time  0.966 ( 3.919)	Data  0.001 ( 2.944)	Loss 2.1881e-01 (2.8595e-01) 
2023-06-04 14:55:48.790901: train Epoch: [1][ 24/129]	Time  6.561 ( 4.025)	Data  5.585 ( 3.049)	Loss 2.5369e-01 (2.8466e-01) 
2023-06-04 14:55:49.759311: train Epoch: [1][ 25/129]	Time  0.968 ( 3.907)	Data  0.001 ( 2.932)	Loss 2.6029e-01 (2.8372e-01) 
2023-06-04 14:55:56.575181: train Epoch: [1][ 26/129]	Time  6.816 ( 4.015)	Data  5.849 ( 3.040)	Loss 2.4200e-01 (2.8218e-01) 
2023-06-04 14:55:57.542642: train Epoch: [1][ 27/129]	Time  0.967 ( 3.906)	Data  0.001 ( 2.931)	Loss 2.4233e-01 (2.8075e-01) 
2023-06-04 14:56:04.130738: train Epoch: [1][ 28/129]	Time  6.588 ( 3.998)	Data  5.619 ( 3.024)	Loss 2.0338e-01 (2.7808e-01) 
2023-06-04 14:56:05.097244: train Epoch: [1][ 29/129]	Time  0.966 ( 3.897)	Data  0.001 ( 2.923)	Loss 3.1509e-01 (2.7932e-01) 
2023-06-04 14:56:11.587363: train Epoch: [1][ 30/129]	Time  6.490 ( 3.981)	Data  5.493 ( 3.006)	Loss 3.2310e-01 (2.8073e-01) 
2023-06-04 14:56:12.554567: train Epoch: [1][ 31/129]	Time  0.967 ( 3.887)	Data  0.001 ( 2.912)	Loss 1.9807e-01 (2.7815e-01) 
2023-06-04 14:56:19.412526: train Epoch: [1][ 32/129]	Time  6.858 ( 3.977)	Data  5.885 ( 3.002)	Loss 2.2136e-01 (2.7643e-01) 
2023-06-04 14:56:20.391349: train Epoch: [1][ 33/129]	Time  0.979 ( 3.889)	Data  0.001 ( 2.914)	Loss 2.9724e-01 (2.7704e-01) 
2023-06-04 14:56:27.168261: train Epoch: [1][ 34/129]	Time  6.777 ( 3.971)	Data  5.798 ( 2.997)	Loss 3.0519e-01 (2.7784e-01) 
2023-06-04 14:56:28.147278: train Epoch: [1][ 35/129]	Time  0.979 ( 3.888)	Data  0.001 ( 2.913)	Loss 2.3561e-01 (2.7667e-01) 
2023-06-04 14:56:34.750132: train Epoch: [1][ 36/129]	Time  6.603 ( 3.961)	Data  5.630 ( 2.987)	Loss 2.4861e-01 (2.7591e-01) 
2023-06-04 14:56:35.717284: train Epoch: [1][ 37/129]	Time  0.967 ( 3.883)	Data  0.001 ( 2.908)	Loss 2.9461e-01 (2.7640e-01) 
2023-06-04 14:56:42.381778: train Epoch: [1][ 38/129]	Time  6.664 ( 3.954)	Data  5.698 ( 2.980)	Loss 3.0024e-01 (2.7701e-01) 
2023-06-04 14:56:43.347526: train Epoch: [1][ 39/129]	Time  0.966 ( 3.879)	Data  0.001 ( 2.905)	Loss 2.4677e-01 (2.7626e-01) 
2023-06-04 14:56:50.064311: train Epoch: [1][ 40/129]	Time  6.717 ( 3.948)	Data  5.748 ( 2.975)	Loss 2.3833e-01 (2.7533e-01) 
2023-06-04 14:56:51.049158: train Epoch: [1][ 41/129]	Time  0.985 ( 3.878)	Data  0.001 ( 2.904)	Loss 2.2883e-01 (2.7423e-01) 
2023-06-04 14:56:57.571634: train Epoch: [1][ 42/129]	Time  6.522 ( 3.939)	Data  5.544 ( 2.965)	Loss 2.4997e-01 (2.7366e-01) 
2023-06-04 14:56:58.539660: train Epoch: [1][ 43/129]	Time  0.968 ( 3.872)	Data  0.001 ( 2.898)	Loss 1.9400e-01 (2.7185e-01) 
2023-06-04 14:57:05.084468: train Epoch: [1][ 44/129]	Time  6.545 ( 3.931)	Data  5.577 ( 2.957)	Loss 3.0818e-01 (2.7266e-01) 
2023-06-04 14:57:06.052018: train Epoch: [1][ 45/129]	Time  0.968 ( 3.867)	Data  0.001 ( 2.893)	Loss 2.0179e-01 (2.7112e-01) 
2023-06-04 14:57:12.700897: train Epoch: [1][ 46/129]	Time  6.649 ( 3.926)	Data  5.680 ( 2.952)	Loss 2.0544e-01 (2.6972e-01) 
2023-06-04 14:57:13.666737: train Epoch: [1][ 47/129]	Time  0.966 ( 3.864)	Data  0.001 ( 2.891)	Loss 2.4914e-01 (2.6929e-01) 
2023-06-04 14:57:20.181823: train Epoch: [1][ 48/129]	Time  6.515 ( 3.918)	Data  5.535 ( 2.945)	Loss 2.3797e-01 (2.6865e-01) 
2023-06-04 14:57:21.165795: train Epoch: [1][ 49/129]	Time  0.984 ( 3.860)	Data  0.001 ( 2.886)	Loss 2.7358e-01 (2.6875e-01) 
2023-06-04 14:57:27.978487: train Epoch: [1][ 50/129]	Time  6.813 ( 3.918)	Data  5.848 ( 2.944)	Loss 3.9943e-01 (2.7131e-01) 
2023-06-04 14:57:28.949585: train Epoch: [1][ 51/129]	Time  0.971 ( 3.861)	Data  0.001 ( 2.887)	Loss 2.4016e-01 (2.7071e-01) 
2023-06-04 14:57:35.709586: train Epoch: [1][ 52/129]	Time  6.760 ( 3.916)	Data  5.795 ( 2.942)	Loss 3.4988e-01 (2.7221e-01) 
2023-06-04 14:57:36.677082: train Epoch: [1][ 53/129]	Time  0.967 ( 3.861)	Data  0.001 ( 2.888)	Loss 3.1681e-01 (2.7303e-01) 
2023-06-04 14:57:43.254772: train Epoch: [1][ 54/129]	Time  6.578 ( 3.911)	Data  5.603 ( 2.937)	Loss 2.2501e-01 (2.7216e-01) 
2023-06-04 14:57:44.222022: train Epoch: [1][ 55/129]	Time  0.967 ( 3.858)	Data  0.001 ( 2.885)	Loss 2.2484e-01 (2.7132e-01) 
2023-06-04 14:57:50.761795: train Epoch: [1][ 56/129]	Time  6.540 ( 3.905)	Data  5.574 ( 2.932)	Loss 2.8405e-01 (2.7154e-01) 
2023-06-04 14:57:51.736545: train Epoch: [1][ 57/129]	Time  0.975 ( 3.854)	Data  0.001 ( 2.881)	Loss 3.1020e-01 (2.7221e-01) 
2023-06-04 14:57:58.150760: train Epoch: [1][ 58/129]	Time  6.414 ( 3.898)	Data  5.447 ( 2.925)	Loss 3.3271e-01 (2.7323e-01) 
2023-06-04 14:57:59.118835: train Epoch: [1][ 59/129]	Time  0.968 ( 3.849)	Data  0.001 ( 2.876)	Loss 2.3317e-01 (2.7256e-01) 
2023-06-04 14:58:05.799692: train Epoch: [1][ 60/129]	Time  6.681 ( 3.895)	Data  5.703 ( 2.922)	Loss 3.2852e-01 (2.7348e-01) 
2023-06-04 14:58:06.774812: train Epoch: [1][ 61/129]	Time  0.975 ( 3.848)	Data  0.001 ( 2.875)	Loss 2.3537e-01 (2.7287e-01) 
2023-06-04 14:58:13.413320: train Epoch: [1][ 62/129]	Time  6.638 ( 3.893)	Data  5.670 ( 2.920)	Loss 2.8159e-01 (2.7300e-01) 
2023-06-04 14:58:14.578135: train Epoch: [1][ 63/129]	Time  1.165 ( 3.850)	Data  0.200 ( 2.877)	Loss 2.3485e-01 (2.7241e-01) 
2023-06-04 14:58:20.871871: train Epoch: [1][ 64/129]	Time  6.294 ( 3.888)	Data  5.326 ( 2.915)	Loss 2.5582e-01 (2.7215e-01) 
2023-06-04 14:58:22.352769: train Epoch: [1][ 65/129]	Time  1.481 ( 3.851)	Data  0.515 ( 2.879)	Loss 2.7625e-01 (2.7222e-01) 
2023-06-04 14:58:28.300905: train Epoch: [1][ 66/129]	Time  5.948 ( 3.882)	Data  4.979 ( 2.910)	Loss 3.7374e-01 (2.7373e-01) 
2023-06-04 14:58:29.753361: train Epoch: [1][ 67/129]	Time  1.452 ( 3.847)	Data  0.474 ( 2.874)	Loss 2.1994e-01 (2.7294e-01) 
2023-06-04 14:58:35.987220: train Epoch: [1][ 68/129]	Time  6.234 ( 3.881)	Data  5.267 ( 2.909)	Loss 2.1260e-01 (2.7207e-01) 
2023-06-04 14:58:37.130537: train Epoch: [1][ 69/129]	Time  1.143 ( 3.842)	Data  0.176 ( 2.870)	Loss 2.1094e-01 (2.7119e-01) 
2023-06-04 14:58:43.795129: train Epoch: [1][ 70/129]	Time  6.665 ( 3.882)	Data  5.699 ( 2.910)	Loss 3.0691e-01 (2.7169e-01) 
2023-06-04 14:58:44.963506: train Epoch: [1][ 71/129]	Time  1.168 ( 3.844)	Data  0.204 ( 2.872)	Loss 2.1540e-01 (2.7091e-01) 
2023-06-04 14:58:51.456087: train Epoch: [1][ 72/129]	Time  6.493 ( 3.881)	Data  5.519 ( 2.908)	Loss 2.2087e-01 (2.7023e-01) 
2023-06-04 14:58:52.562963: train Epoch: [1][ 73/129]	Time  1.107 ( 3.843)	Data  0.130 ( 2.871)	Loss 2.1500e-01 (2.6948e-01) 
2023-06-04 14:58:59.034182: train Epoch: [1][ 74/129]	Time  6.471 ( 3.878)	Data  5.491 ( 2.906)	Loss 2.7338e-01 (2.6953e-01) 
2023-06-04 14:59:00.079522: train Epoch: [1][ 75/129]	Time  1.045 ( 3.841)	Data  0.078 ( 2.868)	Loss 2.0038e-01 (2.6862e-01) 
2023-06-04 14:59:06.594157: train Epoch: [1][ 76/129]	Time  6.515 ( 3.876)	Data  5.549 ( 2.903)	Loss 4.2000e-01 (2.7059e-01) 
2023-06-04 14:59:07.790814: train Epoch: [1][ 77/129]	Time  1.197 ( 3.841)	Data  0.232 ( 2.869)	Loss 2.6903e-01 (2.7057e-01) 
2023-06-04 14:59:14.294986: train Epoch: [1][ 78/129]	Time  6.504 ( 3.875)	Data  5.535 ( 2.903)	Loss 2.6573e-01 (2.7051e-01) 
2023-06-04 14:59:15.310423: train Epoch: [1][ 79/129]	Time  1.015 ( 3.839)	Data  0.051 ( 2.867)	Loss 3.1175e-01 (2.7102e-01) 
2023-06-04 14:59:22.029847: train Epoch: [1][ 80/129]	Time  6.719 ( 3.875)	Data  5.752 ( 2.903)	Loss 2.6848e-01 (2.7099e-01) 
2023-06-04 14:59:22.998905: train Epoch: [1][ 81/129]	Time  0.969 ( 3.839)	Data  0.001 ( 2.867)	Loss 2.1845e-01 (2.7035e-01) 
2023-06-04 14:59:29.622940: train Epoch: [1][ 82/129]	Time  6.624 ( 3.873)	Data  5.630 ( 2.901)	Loss 2.1074e-01 (2.6963e-01) 
2023-06-04 14:59:30.592869: train Epoch: [1][ 83/129]	Time  0.970 ( 3.838)	Data  0.001 ( 2.866)	Loss 2.6495e-01 (2.6958e-01) 
2023-06-04 14:59:37.357946: train Epoch: [1][ 84/129]	Time  6.765 ( 3.873)	Data  5.797 ( 2.901)	Loss 1.8780e-01 (2.6862e-01) 
2023-06-04 14:59:38.327196: train Epoch: [1][ 85/129]	Time  0.969 ( 3.839)	Data  0.001 ( 2.867)	Loss 2.6432e-01 (2.6857e-01) 
2023-06-04 14:59:42.962794: train Epoch: [1][ 86/129]	Time  4.636 ( 3.848)	Data  3.669 ( 2.876)	Loss 5.2851e-01 (2.7155e-01) 
2023-06-04 14:59:43.930550: train Epoch: [1][ 87/129]	Time  0.968 ( 3.815)	Data  0.001 ( 2.843)	Loss 2.1548e-01 (2.7092e-01) 
2023-06-04 14:59:50.104522: train Epoch: [1][ 88/129]	Time  6.174 ( 3.842)	Data  5.206 ( 2.870)	Loss 2.9386e-01 (2.7117e-01) 
2023-06-04 14:59:51.073306: train Epoch: [1][ 89/129]	Time  0.969 ( 3.810)	Data  0.001 ( 2.838)	Loss 3.7539e-01 (2.7233e-01) 
2023-06-04 14:59:57.562551: train Epoch: [1][ 90/129]	Time  6.489 ( 3.839)	Data  5.523 ( 2.868)	Loss 3.0760e-01 (2.7272e-01) 
2023-06-04 14:59:58.531492: train Epoch: [1][ 91/129]	Time  0.969 ( 3.808)	Data  0.001 ( 2.836)	Loss 2.3251e-01 (2.7228e-01) 
2023-06-04 15:00:04.904655: train Epoch: [1][ 92/129]	Time  6.373 ( 3.836)	Data  5.404 ( 2.864)	Loss 2.5869e-01 (2.7214e-01) 
2023-06-04 15:00:05.886057: train Epoch: [1][ 93/129]	Time  0.981 ( 3.805)	Data  0.001 ( 2.834)	Loss 2.2060e-01 (2.7159e-01) 
2023-06-04 15:00:12.486407: train Epoch: [1][ 94/129]	Time  6.600 ( 3.835)	Data  5.632 ( 2.863)	Loss 2.4914e-01 (2.7135e-01) 
2023-06-04 15:00:13.613829: train Epoch: [1][ 95/129]	Time  1.127 ( 3.807)	Data  0.161 ( 2.835)	Loss 2.4036e-01 (2.7103e-01) 
2023-06-04 15:00:19.970915: train Epoch: [1][ 96/129]	Time  6.357 ( 3.833)	Data  5.385 ( 2.861)	Loss 2.4055e-01 (2.7071e-01) 
2023-06-04 15:00:21.102423: train Epoch: [1][ 97/129]	Time  1.131 ( 3.805)	Data  0.162 ( 2.834)	Loss 2.3182e-01 (2.7032e-01) 
2023-06-04 15:00:27.586756: train Epoch: [1][ 98/129]	Time  6.484 ( 3.832)	Data  5.518 ( 2.861)	Loss 3.6604e-01 (2.7128e-01) 
2023-06-04 15:00:28.926292: train Epoch: [1][ 99/129]	Time  1.340 ( 3.807)	Data  0.370 ( 2.836)	Loss 1.6631e-01 (2.7023e-01) 
2023-06-04 15:00:35.121101: train Epoch: [1][100/129]	Time  6.195 ( 3.831)	Data  5.228 ( 2.859)	Loss 3.5080e-01 (2.7103e-01) 
2023-06-04 15:00:36.599177: train Epoch: [1][101/129]	Time  1.478 ( 3.808)	Data  0.506 ( 2.836)	Loss 4.2119e-01 (2.7250e-01) 
2023-06-04 15:00:42.876147: train Epoch: [1][102/129]	Time  6.277 ( 3.832)	Data  5.286 ( 2.860)	Loss 3.1425e-01 (2.7291e-01) 
2023-06-04 15:00:44.188733: train Epoch: [1][103/129]	Time  1.313 ( 3.808)	Data  0.332 ( 2.836)	Loss 2.5722e-01 (2.7276e-01) 
2023-06-04 15:00:50.472127: train Epoch: [1][104/129]	Time  6.283 ( 3.831)	Data  5.229 ( 2.859)	Loss 3.2929e-01 (2.7330e-01) 
2023-06-04 15:00:51.615934: train Epoch: [1][105/129]	Time  1.144 ( 3.806)	Data  0.165 ( 2.833)	Loss 2.4610e-01 (2.7304e-01) 
2023-06-04 15:00:57.942961: train Epoch: [1][106/129]	Time  6.327 ( 3.830)	Data  5.340 ( 2.857)	Loss 2.2926e-01 (2.7263e-01) 
2023-06-04 15:00:59.060085: train Epoch: [1][107/129]	Time  1.117 ( 3.804)	Data  0.150 ( 2.832)	Loss 2.9257e-01 (2.7282e-01) 
2023-06-04 15:01:05.660572: train Epoch: [1][108/129]	Time  6.600 ( 3.830)	Data  5.606 ( 2.857)	Loss 1.9469e-01 (2.7210e-01) 
2023-06-04 15:01:06.701234: train Epoch: [1][109/129]	Time  1.041 ( 3.805)	Data  0.074 ( 2.832)	Loss 2.1138e-01 (2.7155e-01) 
2023-06-04 15:01:13.036474: train Epoch: [1][110/129]	Time  6.335 ( 3.828)	Data  5.347 ( 2.854)	Loss 1.8089e-01 (2.7073e-01) 
2023-06-04 15:01:14.127894: train Epoch: [1][111/129]	Time  1.091 ( 3.803)	Data  0.112 ( 2.830)	Loss 2.4762e-01 (2.7052e-01) 
2023-06-04 15:01:19.309566: train Epoch: [1][112/129]	Time  5.182 ( 3.815)	Data  4.203 ( 2.842)	Loss 2.0119e-01 (2.6991e-01) 
2023-06-04 15:01:20.588979: train Epoch: [1][113/129]	Time  1.279 ( 3.793)	Data  0.301 ( 2.820)	Loss 2.0494e-01 (2.6934e-01) 
2023-06-04 15:01:26.710074: train Epoch: [1][114/129]	Time  6.121 ( 3.813)	Data  5.155 ( 2.840)	Loss 3.9272e-01 (2.7041e-01) 
2023-06-04 15:01:28.066848: train Epoch: [1][115/129]	Time  1.357 ( 3.792)	Data  0.391 ( 2.819)	Loss 1.9158e-01 (2.6973e-01) 
2023-06-04 15:01:34.298444: train Epoch: [1][116/129]	Time  6.232 ( 3.813)	Data  5.266 ( 2.840)	Loss 4.4378e-01 (2.7122e-01) 
2023-06-04 15:01:35.551913: train Epoch: [1][117/129]	Time  1.253 ( 3.791)	Data  0.286 ( 2.818)	Loss 2.8040e-01 (2.7130e-01) 
2023-06-04 15:01:41.791977: train Epoch: [1][118/129]	Time  6.240 ( 3.812)	Data  5.272 ( 2.839)	Loss 2.3807e-01 (2.7102e-01) 
2023-06-04 15:01:42.784732: train Epoch: [1][119/129]	Time  0.993 ( 3.788)	Data  0.025 ( 2.815)	Loss 2.6007e-01 (2.7093e-01) 
2023-06-04 15:01:49.219354: train Epoch: [1][120/129]	Time  6.435 ( 3.810)	Data  5.465 ( 2.837)	Loss 2.4706e-01 (2.7073e-01) 
2023-06-04 15:01:50.390115: train Epoch: [1][121/129]	Time  1.171 ( 3.789)	Data  0.205 ( 2.816)	Loss 3.0504e-01 (2.7101e-01) 
2023-06-04 15:01:56.653029: train Epoch: [1][122/129]	Time  6.263 ( 3.809)	Data  5.288 ( 2.836)	Loss 2.3082e-01 (2.7069e-01) 
2023-06-04 15:01:58.018891: train Epoch: [1][123/129]	Time  1.366 ( 3.789)	Data  0.400 ( 2.816)	Loss 2.7884e-01 (2.7075e-01) 
2023-06-04 15:02:04.086591: train Epoch: [1][124/129]	Time  6.068 ( 3.807)	Data  5.101 ( 2.835)	Loss 3.4280e-01 (2.7133e-01) 
2023-06-04 15:02:05.866094: train Epoch: [1][125/129]	Time  1.780 ( 3.791)	Data  0.813 ( 2.818)	Loss 3.3471e-01 (2.7183e-01) 
2023-06-04 15:02:11.604570: train Epoch: [1][126/129]	Time  5.738 ( 3.807)	Data  4.771 ( 2.834)	Loss 2.3920e-01 (2.7157e-01) 
2023-06-04 15:02:13.649910: train Epoch: [1][127/129]	Time  2.045 ( 3.793)	Data  1.076 ( 2.820)	Loss 2.5711e-01 (2.7146e-01) 
2023-06-04 15:02:17.540426: train Epoch: [1][128/129]	Time  3.891 ( 3.794)	Data  2.919 ( 2.821)	Loss 3.2564e-01 (2.7188e-01) 
2023-06-04 15:02:17.725231: Train Epoch done in 489.54931158002 s 
2023-06-04 15:02:21.641333: val Epoch: [1][ 0/72]	Time  3.184 ( 3.184)	Data  2.915 ( 2.915)	Loss 2.5713e-01 (2.5713e-01) 
2023-06-04 15:02:21.785553: val Epoch: [1][ 1/72]	Time  0.145 ( 1.664)	Data  0.001 ( 1.458)	Loss 3.4371e-01 (3.0042e-01) 
2023-06-04 15:02:24.083929: val Epoch: [1][ 2/72]	Time  2.298 ( 1.875)	Data  2.176 ( 1.698)	Loss 2.0192e-01 (2.6759e-01) 
2023-06-04 15:02:24.223096: val Epoch: [1][ 3/72]	Time  0.139 ( 1.441)	Data  0.017 ( 1.277)	Loss 2.4453e-01 (2.6182e-01) 
2023-06-04 15:02:26.650407: val Epoch: [1][ 4/72]	Time  2.427 ( 1.639)	Data  2.303 ( 1.483)	Loss 1.6634e-01 (2.4273e-01) 
2023-06-04 15:02:26.865942: val Epoch: [1][ 5/72]	Time  0.216 ( 1.401)	Data  0.080 ( 1.249)	Loss 3.1808e-01 (2.5529e-01) 
2023-06-04 15:02:29.183561: val Epoch: [1][ 6/72]	Time  2.318 ( 1.532)	Data  2.193 ( 1.384)	Loss 2.7658e-01 (2.5833e-01) 
2023-06-04 15:02:29.485222: val Epoch: [1][ 7/72]	Time  0.302 ( 1.378)	Data  0.178 ( 1.233)	Loss 2.5185e-01 (2.5752e-01) 
2023-06-04 15:02:31.786837: val Epoch: [1][ 8/72]	Time  2.302 ( 1.481)	Data  2.176 ( 1.338)	Loss 2.3971e-01 (2.5554e-01) 
2023-06-04 15:02:32.084280: val Epoch: [1][ 9/72]	Time  0.297 ( 1.363)	Data  0.168 ( 1.221)	Loss 5.0979e-01 (2.8097e-01) 
2023-06-04 15:02:34.354655: val Epoch: [1][10/72]	Time  2.270 ( 1.445)	Data  2.140 ( 1.304)	Loss 3.1842e-01 (2.8437e-01) 
2023-06-04 15:02:34.639245: val Epoch: [1][11/72]	Time  0.285 ( 1.348)	Data  0.154 ( 1.208)	Loss 2.5819e-01 (2.8219e-01) 
2023-06-04 15:02:36.850600: val Epoch: [1][12/72]	Time  2.211 ( 1.415)	Data  2.085 ( 1.276)	Loss 2.1486e-01 (2.7701e-01) 
2023-06-04 15:02:37.331473: val Epoch: [1][13/72]	Time  0.481 ( 1.348)	Data  0.356 ( 1.210)	Loss 4.7832e-01 (2.9139e-01) 
2023-06-04 15:02:39.318685: val Epoch: [1][14/72]	Time  1.987 ( 1.391)	Data  1.861 ( 1.254)	Loss 2.9392e-01 (2.9156e-01) 
2023-06-04 15:02:39.888790: val Epoch: [1][15/72]	Time  0.570 ( 1.339)	Data  0.445 ( 1.203)	Loss 2.2110e-01 (2.8715e-01) 
2023-06-04 15:02:41.956023: val Epoch: [1][16/72]	Time  2.067 ( 1.382)	Data  1.941 ( 1.246)	Loss 1.8155e-01 (2.8094e-01) 
2023-06-04 15:02:42.536647: val Epoch: [1][17/72]	Time  0.581 ( 1.338)	Data  0.455 ( 1.202)	Loss 2.4422e-01 (2.7890e-01) 
2023-06-04 15:02:44.519115: val Epoch: [1][18/72]	Time  1.982 ( 1.372)	Data  1.856 ( 1.237)	Loss 2.0840e-01 (2.7519e-01) 
2023-06-04 15:02:45.108318: val Epoch: [1][19/72]	Time  0.589 ( 1.333)	Data  0.464 ( 1.198)	Loss 4.9708e-01 (2.8629e-01) 
2023-06-04 15:02:47.165515: val Epoch: [1][20/72]	Time  2.057 ( 1.367)	Data  1.931 ( 1.233)	Loss 5.6859e-01 (2.9973e-01) 
2023-06-04 15:02:47.672413: val Epoch: [1][21/72]	Time  0.507 ( 1.328)	Data  0.382 ( 1.194)	Loss 2.6425e-01 (2.9812e-01) 
2023-06-04 15:02:49.704755: val Epoch: [1][22/72]	Time  2.032 ( 1.359)	Data  1.906 ( 1.225)	Loss 5.9873e-01 (3.1119e-01) 
2023-06-04 15:02:50.247523: val Epoch: [1][23/72]	Time  0.543 ( 1.325)	Data  0.418 ( 1.192)	Loss 3.5225e-01 (3.1290e-01) 
2023-06-04 15:02:52.198769: val Epoch: [1][24/72]	Time  1.951 ( 1.350)	Data  1.825 ( 1.217)	Loss 2.7854e-01 (3.1152e-01) 
2023-06-04 15:02:52.884645: val Epoch: [1][25/72]	Time  0.686 ( 1.324)	Data  0.561 ( 1.192)	Loss 2.5507e-01 (3.0935e-01) 
2023-06-04 15:02:54.768446: val Epoch: [1][26/72]	Time  1.884 ( 1.345)	Data  1.755 ( 1.213)	Loss 6.6086e-01 (3.2237e-01) 
2023-06-04 15:02:55.365646: val Epoch: [1][27/72]	Time  0.597 ( 1.318)	Data  0.476 ( 1.186)	Loss 1.3759e-01 (3.1577e-01) 
2023-06-04 15:02:57.322657: val Epoch: [1][28/72]	Time  1.957 ( 1.340)	Data  1.835 ( 1.209)	Loss 5.4154e-01 (3.2356e-01) 
2023-06-04 15:02:57.832322: val Epoch: [1][29/72]	Time  0.510 ( 1.312)	Data  0.389 ( 1.181)	Loss 1.5988e-01 (3.1810e-01) 
2023-06-04 15:02:59.930797: val Epoch: [1][30/72]	Time  2.098 ( 1.338)	Data  1.978 ( 1.207)	Loss 4.0369e-01 (3.2086e-01) 
2023-06-04 15:03:00.304125: val Epoch: [1][31/72]	Time  0.373 ( 1.308)	Data  0.253 ( 1.177)	Loss 2.2253e-01 (3.1779e-01) 
2023-06-04 15:03:02.434179: val Epoch: [1][32/72]	Time  2.130 ( 1.333)	Data  2.009 ( 1.202)	Loss 2.0564e-01 (3.1439e-01) 
2023-06-04 15:03:02.858735: val Epoch: [1][33/72]	Time  0.425 ( 1.306)	Data  0.304 ( 1.176)	Loss 6.5790e-01 (3.2449e-01) 
2023-06-04 15:03:05.087202: val Epoch: [1][34/72]	Time  2.228 ( 1.332)	Data  2.103 ( 1.202)	Loss 3.4258e-01 (3.2501e-01) 
2023-06-04 15:03:05.358513: val Epoch: [1][35/72]	Time  0.271 ( 1.303)	Data  0.151 ( 1.173)	Loss 1.8640e-01 (3.2116e-01) 
2023-06-04 15:03:07.584850: val Epoch: [1][36/72]	Time  2.226 ( 1.328)	Data  2.102 ( 1.198)	Loss 3.2506e-01 (3.2127e-01) 
2023-06-04 15:03:07.986502: val Epoch: [1][37/72]	Time  0.402 ( 1.303)	Data  0.277 ( 1.174)	Loss 3.1608e-01 (3.2113e-01) 
2023-06-04 15:03:10.184614: val Epoch: [1][38/72]	Time  2.198 ( 1.326)	Data  2.073 ( 1.197)	Loss 2.6774e-01 (3.1976e-01) 
2023-06-04 15:03:10.561407: val Epoch: [1][39/72]	Time  0.377 ( 1.303)	Data  0.252 ( 1.174)	Loss 1.8594e-01 (3.1641e-01) 
2023-06-04 15:03:12.609530: val Epoch: [1][40/72]	Time  2.048 ( 1.321)	Data  1.927 ( 1.192)	Loss 1.8205e-01 (3.1314e-01) 
2023-06-04 15:03:13.067896: val Epoch: [1][41/72]	Time  0.458 ( 1.300)	Data  0.338 ( 1.172)	Loss 2.5496e-01 (3.1175e-01) 
2023-06-04 15:03:15.177144: val Epoch: [1][42/72]	Time  2.109 ( 1.319)	Data  1.980 ( 1.190)	Loss 2.1263e-01 (3.0945e-01) 
2023-06-04 15:03:15.631479: val Epoch: [1][43/72]	Time  0.454 ( 1.299)	Data  0.334 ( 1.171)	Loss 1.7292e-01 (3.0634e-01) 
2023-06-04 15:03:17.724421: val Epoch: [1][44/72]	Time  2.093 ( 1.317)	Data  1.972 ( 1.189)	Loss 3.5253e-01 (3.0737e-01) 
2023-06-04 15:03:18.280368: val Epoch: [1][45/72]	Time  0.556 ( 1.300)	Data  0.435 ( 1.172)	Loss 1.7626e-01 (3.0452e-01) 
2023-06-04 15:03:20.285393: val Epoch: [1][46/72]	Time  2.005 ( 1.315)	Data  1.884 ( 1.188)	Loss 2.1016e-01 (3.0251e-01) 
2023-06-04 15:03:20.786576: val Epoch: [1][47/72]	Time  0.501 ( 1.299)	Data  0.380 ( 1.171)	Loss 4.1868e-01 (3.0493e-01) 
2023-06-04 15:03:22.857133: val Epoch: [1][48/72]	Time  2.071 ( 1.314)	Data  1.946 ( 1.187)	Loss 6.8786e-01 (3.1275e-01) 
2023-06-04 15:03:23.397190: val Epoch: [1][49/72]	Time  0.540 ( 1.299)	Data  0.415 ( 1.171)	Loss 3.0831e-01 (3.1266e-01) 
2023-06-04 15:03:25.334285: val Epoch: [1][50/72]	Time  1.937 ( 1.311)	Data  1.805 ( 1.184)	Loss 1.7781e-01 (3.1001e-01) 
2023-06-04 15:03:26.073661: val Epoch: [1][51/72]	Time  0.739 ( 1.300)	Data  0.607 ( 1.172)	Loss 4.0920e-01 (3.1192e-01) 
2023-06-04 15:03:27.846319: val Epoch: [1][52/72]	Time  1.773 ( 1.309)	Data  1.647 ( 1.181)	Loss 2.4754e-01 (3.1071e-01) 
2023-06-04 15:03:28.660770: val Epoch: [1][53/72]	Time  0.814 ( 1.300)	Data  0.691 ( 1.172)	Loss 4.7555e-01 (3.1376e-01) 
2023-06-04 15:03:30.359929: val Epoch: [1][54/72]	Time  1.699 ( 1.307)	Data  1.574 ( 1.180)	Loss 2.0386e-01 (3.1176e-01) 
2023-06-04 15:03:31.152354: val Epoch: [1][55/72]	Time  0.792 ( 1.298)	Data  0.668 ( 1.170)	Loss 1.9656e-01 (3.0970e-01) 
2023-06-04 15:03:32.828657: val Epoch: [1][56/72]	Time  1.676 ( 1.305)	Data  1.550 ( 1.177)	Loss 3.0682e-01 (3.0965e-01) 
2023-06-04 15:03:33.806246: val Epoch: [1][57/72]	Time  0.978 ( 1.299)	Data  0.857 ( 1.172)	Loss 5.4619e-01 (3.1373e-01) 
2023-06-04 15:03:35.265787: val Epoch: [1][58/72]	Time  1.460 ( 1.302)	Data  1.335 ( 1.174)	Loss 2.3283e-01 (3.1236e-01) 
2023-06-04 15:03:36.392517: val Epoch: [1][59/72]	Time  1.127 ( 1.299)	Data  1.003 ( 1.172)	Loss 2.8572e-01 (3.1192e-01) 
2023-06-04 15:03:37.868277: val Epoch: [1][60/72]	Time  1.476 ( 1.302)	Data  1.350 ( 1.174)	Loss 3.0381e-01 (3.1178e-01) 
2023-06-04 15:03:39.045328: val Epoch: [1][61/72]	Time  1.177 ( 1.300)	Data  1.056 ( 1.173)	Loss 2.7084e-01 (3.1112e-01) 
2023-06-04 15:03:40.424579: val Epoch: [1][62/72]	Time  1.379 ( 1.301)	Data  1.259 ( 1.174)	Loss 1.9531e-01 (3.0929e-01) 
2023-06-04 15:03:41.502130: val Epoch: [1][63/72]	Time  1.078 ( 1.298)	Data  0.958 ( 1.171)	Loss 3.0594e-01 (3.0923e-01) 
2023-06-04 15:03:42.864601: val Epoch: [1][64/72]	Time  1.362 ( 1.299)	Data  1.238 ( 1.172)	Loss 2.6806e-01 (3.0860e-01) 
2023-06-04 15:03:44.078995: val Epoch: [1][65/72]	Time  1.214 ( 1.297)	Data  1.094 ( 1.170)	Loss 4.6914e-01 (3.1103e-01) 
2023-06-04 15:03:45.462195: val Epoch: [1][66/72]	Time  1.383 ( 1.299)	Data  1.263 ( 1.172)	Loss 1.6020e-01 (3.0878e-01) 
2023-06-04 15:03:46.663070: val Epoch: [1][67/72]	Time  1.201 ( 1.297)	Data  1.080 ( 1.170)	Loss 2.4425e-01 (3.0783e-01) 
2023-06-04 15:03:48.071165: val Epoch: [1][68/72]	Time  1.408 ( 1.299)	Data  1.284 ( 1.172)	Loss 2.6037e-01 (3.0714e-01) 
2023-06-04 15:03:49.254053: val Epoch: [1][69/72]	Time  1.183 ( 1.297)	Data  1.062 ( 1.171)	Loss 2.8106e-01 (3.0677e-01) 
2023-06-04 15:03:50.720383: val Epoch: [1][70/72]	Time  1.466 ( 1.299)	Data  1.342 ( 1.173)	Loss 3.3183e-01 (3.0712e-01) 
2023-06-04 15:03:51.405815: val Epoch: [1][71/72]	Time  0.685 ( 1.291)	Data  0.564 ( 1.164)	Loss 1.8100e-01 (3.0537e-01) 
2023-06-04 15:03:51.717811: Epoch 1 :Val : ['ET : 0.5122787952423096', 'TC : 0.5729970932006836', 'WT : 0.689495325088501'] 
2023-06-04 15:03:51.720559: Epoch 1 :Val : ['ET : 0.5122787952423096', 'TC : 0.5729970932006836', 'WT : 0.689495325088501'] 
2023-06-04 15:03:51.722754: Saving the model with DSC 0.582578182220459 
2023-06-04 15:03:52.494053: Val epoch done in 94.76881266594864 s 
2023-06-04 15:03:52.503594: Batches per epoch:  129 
2023-06-04 15:04:01.692489: train Epoch: [2][  0/129]	Time  9.189 ( 9.189)	Data  7.853 ( 7.853)	Loss 1.9398e-01 (1.9398e-01) 
2023-06-04 15:04:02.679296: train Epoch: [2][  1/129]	Time  0.987 ( 5.088)	Data  0.001 ( 3.927)	Loss 2.6140e-01 (2.2769e-01) 
2023-06-04 15:04:08.981385: train Epoch: [2][  2/129]	Time  6.302 ( 5.493)	Data  5.334 ( 4.396)	Loss 3.4151e-01 (2.6563e-01) 
2023-06-04 15:04:09.961026: train Epoch: [2][  3/129]	Time  0.980 ( 4.364)	Data  0.001 ( 3.297)	Loss 2.6517e-01 (2.6552e-01) 
2023-06-04 15:04:16.839657: train Epoch: [2][  4/129]	Time  6.879 ( 4.867)	Data  5.906 ( 3.819)	Loss 1.8841e-01 (2.5010e-01) 
2023-06-04 15:04:17.808012: train Epoch: [2][  5/129]	Time  0.968 ( 4.217)	Data  0.001 ( 3.183)	Loss 3.0743e-01 (2.5965e-01) 
2023-06-04 15:04:24.387579: train Epoch: [2][  6/129]	Time  6.580 ( 4.555)	Data  5.612 ( 3.530)	Loss 2.7840e-01 (2.6233e-01) 
2023-06-04 15:04:25.355316: train Epoch: [2][  7/129]	Time  0.968 ( 4.106)	Data  0.001 ( 3.089)	Loss 1.6932e-01 (2.5070e-01) 
2023-06-04 15:04:32.150415: train Epoch: [2][  8/129]	Time  6.795 ( 4.405)	Data  5.815 ( 3.392)	Loss 3.0644e-01 (2.5690e-01) 
2023-06-04 15:04:33.117880: train Epoch: [2][  9/129]	Time  0.967 ( 4.061)	Data  0.001 ( 3.052)	Loss 2.8145e-01 (2.5935e-01) 
2023-06-04 15:04:39.799259: train Epoch: [2][ 10/129]	Time  6.681 ( 4.300)	Data  5.691 ( 3.292)	Loss 2.6108e-01 (2.5951e-01) 
2023-06-04 15:04:40.765432: train Epoch: [2][ 11/129]	Time  0.966 ( 4.022)	Data  0.001 ( 3.018)	Loss 2.0267e-01 (2.5477e-01) 
2023-06-04 15:04:47.347590: train Epoch: [2][ 12/129]	Time  6.582 ( 4.219)	Data  5.615 ( 3.218)	Loss 1.8143e-01 (2.4913e-01) 
2023-06-04 15:04:48.314818: train Epoch: [2][ 13/129]	Time  0.967 ( 3.986)	Data  0.001 ( 2.988)	Loss 2.5308e-01 (2.4941e-01) 
2023-06-04 15:04:55.076121: train Epoch: [2][ 14/129]	Time  6.761 ( 4.171)	Data  5.781 ( 3.174)	Loss 1.9787e-01 (2.4598e-01) 
2023-06-04 15:04:56.045185: train Epoch: [2][ 15/129]	Time  0.969 ( 3.971)	Data  0.001 ( 2.976)	Loss 1.9083e-01 (2.4253e-01) 
2023-06-04 15:05:02.451655: train Epoch: [2][ 16/129]	Time  6.406 ( 4.115)	Data  5.426 ( 3.120)	Loss 2.8570e-01 (2.4507e-01) 
2023-06-04 15:05:03.430483: train Epoch: [2][ 17/129]	Time  0.979 ( 3.940)	Data  0.001 ( 2.947)	Loss 3.4389e-01 (2.5056e-01) 
2023-06-04 15:05:10.124152: train Epoch: [2][ 18/129]	Time  6.694 ( 4.085)	Data  5.713 ( 3.092)	Loss 2.0600e-01 (2.4821e-01) 
2023-06-04 15:05:11.104629: train Epoch: [2][ 19/129]	Time  0.980 ( 3.930)	Data  0.001 ( 2.938)	Loss 2.7255e-01 (2.4943e-01) 
2023-06-04 15:05:17.575436: train Epoch: [2][ 20/129]	Time  6.471 ( 4.051)	Data  5.501 ( 3.060)	Loss 2.7414e-01 (2.5061e-01) 
2023-06-04 15:05:18.668309: train Epoch: [2][ 21/129]	Time  1.093 ( 3.917)	Data  0.126 ( 2.926)	Loss 1.6859e-01 (2.4688e-01) 
2023-06-04 15:05:25.037294: train Epoch: [2][ 22/129]	Time  6.369 ( 4.023)	Data  5.393 ( 3.034)	Loss 2.3347e-01 (2.4630e-01) 
2023-06-04 15:05:26.133103: train Epoch: [2][ 23/129]	Time  1.096 ( 3.901)	Data  0.127 ( 2.913)	Loss 2.3740e-01 (2.4593e-01) 
2023-06-04 15:05:32.510278: train Epoch: [2][ 24/129]	Time  6.377 ( 4.000)	Data  5.407 ( 3.012)	Loss 3.3382e-01 (2.4944e-01) 
2023-06-04 15:05:33.674512: train Epoch: [2][ 25/129]	Time  1.164 ( 3.891)	Data  0.196 ( 2.904)	Loss 2.0011e-01 (2.4754e-01) 
2023-06-04 15:05:39.909209: train Epoch: [2][ 26/129]	Time  6.235 ( 3.978)	Data  5.267 ( 2.992)	Loss 1.7259e-01 (2.4477e-01) 
2023-06-04 15:05:41.098546: train Epoch: [2][ 27/129]	Time  1.189 ( 3.878)	Data  0.221 ( 2.893)	Loss 2.0131e-01 (2.4322e-01) 
2023-06-04 15:05:47.591180: train Epoch: [2][ 28/129]	Time  6.493 ( 3.969)	Data  5.519 ( 2.983)	Loss 2.0357e-01 (2.4185e-01) 
2023-06-04 15:05:48.615071: train Epoch: [2][ 29/129]	Time  1.024 ( 3.870)	Data  0.057 ( 2.886)	Loss 2.6527e-01 (2.4263e-01) 
2023-06-04 15:05:55.011305: train Epoch: [2][ 30/129]	Time  6.396 ( 3.952)	Data  5.424 ( 2.968)	Loss 2.4187e-01 (2.4261e-01) 
2023-06-04 15:05:56.186366: train Epoch: [2][ 31/129]	Time  1.175 ( 3.865)	Data  0.173 ( 2.880)	Loss 2.6706e-01 (2.4337e-01) 
2023-06-04 15:06:02.395363: train Epoch: [2][ 32/129]	Time  6.209 ( 3.936)	Data  5.243 ( 2.952)	Loss 2.1911e-01 (2.4263e-01) 
2023-06-04 15:06:03.555392: train Epoch: [2][ 33/129]	Time  1.160 ( 3.854)	Data  0.193 ( 2.871)	Loss 2.8244e-01 (2.4380e-01) 
2023-06-04 15:06:10.092249: train Epoch: [2][ 34/129]	Time  6.537 ( 3.931)	Data  5.561 ( 2.948)	Loss 2.8585e-01 (2.4501e-01) 
2023-06-04 15:06:11.187519: train Epoch: [2][ 35/129]	Time  1.095 ( 3.852)	Data  0.128 ( 2.869)	Loss 1.6491e-01 (2.4278e-01) 
2023-06-04 15:06:17.336767: train Epoch: [2][ 36/129]	Time  6.149 ( 3.914)	Data  5.182 ( 2.932)	Loss 2.6909e-01 (2.4349e-01) 
2023-06-04 15:06:18.567539: train Epoch: [2][ 37/129]	Time  1.231 ( 3.844)	Data  0.262 ( 2.861)	Loss 1.9328e-01 (2.4217e-01) 
2023-06-04 15:06:24.700806: train Epoch: [2][ 38/129]	Time  6.133 ( 3.902)	Data  5.166 ( 2.921)	Loss 2.5117e-01 (2.4240e-01) 
2023-06-04 15:06:26.179231: train Epoch: [2][ 39/129]	Time  1.478 ( 3.842)	Data  0.474 ( 2.859)	Loss 2.4165e-01 (2.4238e-01) 
2023-06-04 15:06:32.194223: train Epoch: [2][ 40/129]	Time  6.015 ( 3.895)	Data  5.047 ( 2.913)	Loss 3.3233e-01 (2.4458e-01) 
2023-06-04 15:06:33.440949: train Epoch: [2][ 41/129]	Time  1.247 ( 3.832)	Data  0.276 ( 2.850)	Loss 1.9520e-01 (2.4340e-01) 
2023-06-04 15:06:39.647815: train Epoch: [2][ 42/129]	Time  6.207 ( 3.887)	Data  5.240 ( 2.906)	Loss 1.9701e-01 (2.4232e-01) 
2023-06-04 15:06:40.738088: train Epoch: [2][ 43/129]	Time  1.090 ( 3.824)	Data  0.121 ( 2.842)	Loss 3.0687e-01 (2.4379e-01) 
2023-06-04 15:06:47.015995: train Epoch: [2][ 44/129]	Time  6.278 ( 3.878)	Data  5.307 ( 2.897)	Loss 1.4713e-01 (2.4164e-01) 
2023-06-04 15:06:48.543113: train Epoch: [2][ 45/129]	Time  1.527 ( 3.827)	Data  0.537 ( 2.846)	Loss 2.6134e-01 (2.4207e-01) 
2023-06-04 15:06:54.448399: train Epoch: [2][ 46/129]	Time  5.905 ( 3.871)	Data  4.938 ( 2.890)	Loss 2.7226e-01 (2.4271e-01) 
2023-06-04 15:06:56.032423: train Epoch: [2][ 47/129]	Time  1.584 ( 3.824)	Data  0.613 ( 2.843)	Loss 1.7868e-01 (2.4138e-01) 
2023-06-04 15:07:01.989957: train Epoch: [2][ 48/129]	Time  5.958 ( 3.867)	Data  4.982 ( 2.886)	Loss 2.1247e-01 (2.4079e-01) 
2023-06-04 15:07:03.388754: train Epoch: [2][ 49/129]	Time  1.399 ( 3.818)	Data  0.432 ( 2.837)	Loss 1.6443e-01 (2.3926e-01) 
2023-06-04 15:07:09.378104: train Epoch: [2][ 50/129]	Time  5.989 ( 3.860)	Data  5.021 ( 2.880)	Loss 1.5769e-01 (2.3766e-01) 
2023-06-04 15:07:11.042758: train Epoch: [2][ 51/129]	Time  1.665 ( 3.818)	Data  0.698 ( 2.838)	Loss 2.4170e-01 (2.3774e-01) 
2023-06-04 15:07:17.105450: train Epoch: [2][ 52/129]	Time  6.063 ( 3.860)	Data  5.059 ( 2.880)	Loss 2.3346e-01 (2.3766e-01) 
2023-06-04 15:07:18.734989: train Epoch: [2][ 53/129]	Time  1.630 ( 3.819)	Data  0.658 ( 2.839)	Loss 2.8398e-01 (2.3852e-01) 
2023-06-04 15:07:24.497771: train Epoch: [2][ 54/129]	Time  5.763 ( 3.854)	Data  4.796 ( 2.875)	Loss 2.9973e-01 (2.3963e-01) 
2023-06-04 15:07:26.473108: train Epoch: [2][ 55/129]	Time  1.975 ( 3.821)	Data  1.001 ( 2.841)	Loss 1.8986e-01 (2.3874e-01) 
2023-06-04 15:07:32.109358: train Epoch: [2][ 56/129]	Time  5.636 ( 3.853)	Data  4.671 ( 2.873)	Loss 1.7943e-01 (2.3770e-01) 
2023-06-04 15:07:34.088769: train Epoch: [2][ 57/129]	Time  1.979 ( 3.820)	Data  1.012 ( 2.841)	Loss 2.5055e-01 (2.3792e-01) 
2023-06-04 15:07:39.627096: train Epoch: [2][ 58/129]	Time  5.538 ( 3.850)	Data  4.571 ( 2.870)	Loss 2.4786e-01 (2.3809e-01) 
2023-06-04 15:07:41.758386: train Epoch: [2][ 59/129]	Time  2.131 ( 3.821)	Data  1.163 ( 2.842)	Loss 1.9828e-01 (2.3743e-01) 
2023-06-04 15:07:47.419636: train Epoch: [2][ 60/129]	Time  5.661 ( 3.851)	Data  4.644 ( 2.871)	Loss 1.5249e-01 (2.3603e-01) 
2023-06-04 15:07:49.091263: train Epoch: [2][ 61/129]	Time  1.672 ( 3.816)	Data  0.703 ( 2.837)	Loss 1.9649e-01 (2.3540e-01) 
2023-06-04 15:07:54.796510: train Epoch: [2][ 62/129]	Time  5.705 ( 3.846)	Data  4.737 ( 2.867)	Loss 3.5334e-01 (2.3727e-01) 
2023-06-04 15:07:56.862339: train Epoch: [2][ 63/129]	Time  2.066 ( 3.818)	Data  1.093 ( 2.839)	Loss 1.4270e-01 (2.3579e-01) 
2023-06-04 15:08:02.475325: train Epoch: [2][ 64/129]	Time  5.613 ( 3.846)	Data  4.645 ( 2.867)	Loss 2.8170e-01 (2.3650e-01) 
2023-06-04 15:08:04.253418: train Epoch: [2][ 65/129]	Time  1.778 ( 3.814)	Data  0.809 ( 2.836)	Loss 1.2554e-01 (2.3482e-01) 
2023-06-04 15:08:10.120343: train Epoch: [2][ 66/129]	Time  5.867 ( 3.845)	Data  4.900 ( 2.866)	Loss 2.7835e-01 (2.3547e-01) 
2023-06-04 15:08:11.693843: train Epoch: [2][ 67/129]	Time  1.573 ( 3.812)	Data  0.606 ( 2.833)	Loss 2.1005e-01 (2.3509e-01) 
2023-06-04 15:08:17.702387: train Epoch: [2][ 68/129]	Time  6.009 ( 3.843)	Data  5.005 ( 2.865)	Loss 2.1293e-01 (2.3477e-01) 
2023-06-04 15:08:19.021287: train Epoch: [2][ 69/129]	Time  1.319 ( 3.807)	Data  0.346 ( 2.829)	Loss 2.1853e-01 (2.3454e-01) 
2023-06-04 15:08:25.144303: train Epoch: [2][ 70/129]	Time  6.123 ( 3.840)	Data  5.156 ( 2.861)	Loss 1.7329e-01 (2.3368e-01) 
2023-06-04 15:08:26.708838: train Epoch: [2][ 71/129]	Time  1.565 ( 3.808)	Data  0.591 ( 2.830)	Loss 2.9882e-01 (2.3458e-01) 
2023-06-04 15:08:32.612245: train Epoch: [2][ 72/129]	Time  5.903 ( 3.837)	Data  4.932 ( 2.859)	Loss 2.6738e-01 (2.3503e-01) 
2023-06-04 15:08:34.529393: train Epoch: [2][ 73/129]	Time  1.917 ( 3.811)	Data  0.948 ( 2.833)	Loss 2.1758e-01 (2.3479e-01) 
2023-06-04 15:08:40.214200: train Epoch: [2][ 74/129]	Time  5.685 ( 3.836)	Data  4.718 ( 2.858)	Loss 1.5859e-01 (2.3378e-01) 
2023-06-04 15:08:42.272147: train Epoch: [2][ 75/129]	Time  2.058 ( 3.813)	Data  1.089 ( 2.835)	Loss 1.6473e-01 (2.3287e-01) 
2023-06-04 15:08:48.286127: train Epoch: [2][ 76/129]	Time  6.014 ( 3.841)	Data  5.043 ( 2.863)	Loss 1.9774e-01 (2.3241e-01) 
2023-06-04 15:08:49.907277: train Epoch: [2][ 77/129]	Time  1.621 ( 3.813)	Dat