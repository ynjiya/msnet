2023-05-27 03:14:02.793220: Created model 
2023-05-27 03:14:02.794234: total number of trainable parameters 20757084 
2023-05-27 03:14:04.834879: <bound method EDiceLoss.metric of EDiceLoss()> 
2023-05-27 03:14:04.842085: Train dataset number of batch: 193 
2023-05-27 03:14:04.842221: Val dataset number of batch: 72 
2023-05-27 03:14:04.842263: Bench Test dataset number of batch: 25 
2023-05-27 03:14:04.842361: start training now! 
2023-05-27 03:14:04.842411: Batches per epoch:  193 
2023-05-27 03:14:16.743399: train Epoch: [0][  0/193]	Time 11.901 (11.901)	Data 10.906 (10.906)	Loss 8.9000e-01 (8.9000e-01) 
2023-05-27 03:14:17.646213: train Epoch: [0][  1/193]	Time  0.903 ( 6.402)	Data  0.001 ( 5.454)	Loss 8.7454e-01 (8.8227e-01) 
2023-05-27 03:14:26.996440: train Epoch: [0][  2/193]	Time  9.350 ( 7.385)	Data  8.455 ( 6.454)	Loss 7.9836e-01 (8.5430e-01) 
2023-05-27 03:14:27.821408: train Epoch: [0][  3/193]	Time  0.825 ( 5.745)	Data  0.001 ( 4.841)	Loss 8.1900e-01 (8.4547e-01) 
2023-05-27 03:14:37.186923: train Epoch: [0][  4/193]	Time  9.366 ( 6.469)	Data  8.539 ( 5.580)	Loss 8.3407e-01 (8.4319e-01) 
2023-05-27 03:14:38.042505: train Epoch: [0][  5/193]	Time  0.856 ( 5.533)	Data  0.001 ( 4.650)	Loss 7.9701e-01 (8.3549e-01) 
2023-05-27 03:14:47.148439: train Epoch: [0][  6/193]	Time  9.106 ( 6.044)	Data  8.230 ( 5.162)	Loss 8.4734e-01 (8.3719e-01) 
2023-05-27 03:14:48.125010: train Epoch: [0][  7/193]	Time  0.977 ( 5.410)	Data  0.001 ( 4.517)	Loss 8.0884e-01 (8.3364e-01) 
2023-05-27 03:14:57.345213: train Epoch: [0][  8/193]	Time  9.220 ( 5.834)	Data  8.310 ( 4.938)	Loss 7.5947e-01 (8.2540e-01) 
2023-05-27 03:14:58.309094: train Epoch: [0][  9/193]	Time  0.964 ( 5.347)	Data  0.001 ( 4.444)	Loss 8.3066e-01 (8.2593e-01) 
2023-05-27 03:15:07.548432: train Epoch: [0][ 10/193]	Time  9.239 ( 5.701)	Data  8.278 ( 4.793)	Loss 8.0895e-01 (8.2438e-01) 
2023-05-27 03:15:08.542720: train Epoch: [0][ 11/193]	Time  0.994 ( 5.308)	Data  0.001 ( 4.394)	Loss 7.9010e-01 (8.2153e-01) 
2023-05-27 03:15:17.559082: train Epoch: [0][ 12/193]	Time  9.016 ( 5.594)	Data  8.081 ( 4.677)	Loss 7.9025e-01 (8.1912e-01) 
2023-05-27 03:15:18.416887: train Epoch: [0][ 13/193]	Time  0.858 ( 5.255)	Data  0.001 ( 4.343)	Loss 7.6276e-01 (8.1510e-01) 
2023-05-27 03:15:27.771052: train Epoch: [0][ 14/193]	Time  9.354 ( 5.529)	Data  8.369 ( 4.612)	Loss 7.7092e-01 (8.1215e-01) 
2023-05-27 03:15:28.737619: train Epoch: [0][ 15/193]	Time  0.967 ( 5.243)	Data  0.001 ( 4.323)	Loss 7.2959e-01 (8.0699e-01) 
2023-05-27 03:15:37.846029: train Epoch: [0][ 16/193]	Time  9.108 ( 5.471)	Data  8.133 ( 4.547)	Loss 7.6869e-01 (8.0474e-01) 
2023-05-27 03:15:38.830156: train Epoch: [0][ 17/193]	Time  0.984 ( 5.222)	Data  0.001 ( 4.295)	Loss 7.8897e-01 (8.0386e-01) 
2023-05-27 03:15:47.773065: train Epoch: [0][ 18/193]	Time  8.943 ( 5.417)	Data  7.889 ( 4.484)	Loss 7.8843e-01 (8.0305e-01) 
2023-05-27 03:15:48.667048: train Epoch: [0][ 19/193]	Time  0.894 ( 5.191)	Data  0.001 ( 4.260)	Loss 7.2594e-01 (7.9919e-01) 
2023-05-27 03:15:57.770759: train Epoch: [0][ 20/193]	Time  9.104 ( 5.378)	Data  8.194 ( 4.447)	Loss 8.1023e-01 (7.9972e-01) 
2023-05-27 03:15:58.691502: train Epoch: [0][ 21/193]	Time  0.921 ( 5.175)	Data  0.054 ( 4.248)	Loss 7.0974e-01 (7.9563e-01) 
2023-05-27 03:16:07.593446: train Epoch: [0][ 22/193]	Time  8.902 ( 5.337)	Data  8.025 ( 4.412)	Loss 7.6909e-01 (7.9448e-01) 
2023-05-27 03:16:08.556303: train Epoch: [0][ 23/193]	Time  0.963 ( 5.155)	Data  0.077 ( 4.231)	Loss 7.4385e-01 (7.9237e-01) 
2023-05-27 03:16:17.574538: train Epoch: [0][ 24/193]	Time  9.018 ( 5.309)	Data  8.176 ( 4.389)	Loss 7.2201e-01 (7.8955e-01) 
2023-05-27 03:16:18.979414: train Epoch: [0][ 25/193]	Time  1.405 ( 5.159)	Data  0.489 ( 4.239)	Loss 7.4504e-01 (7.8784e-01) 
2023-05-27 03:16:28.083140: train Epoch: [0][ 26/193]	Time  9.104 ( 5.305)	Data  8.171 ( 4.385)	Loss 7.2399e-01 (7.8548e-01) 
2023-05-27 03:16:29.045285: train Epoch: [0][ 27/193]	Time  0.962 ( 5.150)	Data  0.001 ( 4.228)	Loss 7.3905e-01 (7.8382e-01) 
2023-05-27 03:16:38.394739: train Epoch: [0][ 28/193]	Time  9.349 ( 5.295)	Data  8.395 ( 4.372)	Loss 7.0950e-01 (7.8125e-01) 
2023-05-27 03:16:39.197363: train Epoch: [0][ 29/193]	Time  0.803 ( 5.145)	Data  0.001 ( 4.226)	Loss 7.5678e-01 (7.8044e-01) 
2023-05-27 03:16:48.292830: train Epoch: [0][ 30/193]	Time  9.095 ( 5.273)	Data  8.227 ( 4.355)	Loss 7.0655e-01 (7.7805e-01) 
2023-05-27 03:16:49.179546: train Epoch: [0][ 31/193]	Time  0.887 ( 5.136)	Data  0.033 ( 4.220)	Loss 6.7854e-01 (7.7495e-01) 
2023-05-27 03:16:58.234928: train Epoch: [0][ 32/193]	Time  9.055 ( 5.254)	Data  8.131 ( 4.339)	Loss 6.7738e-01 (7.7199e-01) 
2023-05-27 03:16:59.254042: train Epoch: [0][ 33/193]	Time  1.019 ( 5.130)	Data  0.139 ( 4.215)	Loss 6.6325e-01 (7.6879e-01) 
2023-05-27 03:17:07.814754: train Epoch: [0][ 34/193]	Time  8.561 ( 5.228)	Data  7.641 ( 4.313)	Loss 7.0404e-01 (7.6694e-01) 
2023-05-27 03:17:08.683907: train Epoch: [0][ 35/193]	Time  0.869 ( 5.107)	Data  0.001 ( 4.193)	Loss 7.5102e-01 (7.6650e-01) 
2023-05-27 03:17:17.065831: train Epoch: [0][ 36/193]	Time  8.382 ( 5.195)	Data  7.522 ( 4.283)	Loss 7.2173e-01 (7.6529e-01) 
2023-05-27 03:17:18.485993: train Epoch: [0][ 37/193]	Time  1.420 ( 5.096)	Data  0.468 ( 4.183)	Loss 6.4911e-01 (7.6223e-01) 
2023-05-27 03:17:27.365759: train Epoch: [0][ 38/193]	Time  8.880 ( 5.193)	Data  7.887 ( 4.278)	Loss 5.9620e-01 (7.5797e-01) 
2023-05-27 03:17:28.299228: train Epoch: [0][ 39/193]	Time  0.933 ( 5.086)	Data  0.001 ( 4.171)	Loss 6.6663e-01 (7.5569e-01) 
2023-05-27 03:17:37.254592: train Epoch: [0][ 40/193]	Time  8.955 ( 5.181)	Data  7.984 ( 4.264)	Loss 5.8806e-01 (7.5160e-01) 
2023-05-27 03:17:38.263789: train Epoch: [0][ 41/193]	Time  1.009 ( 5.081)	Data  0.001 ( 4.162)	Loss 5.7064e-01 (7.4729e-01) 
2023-05-27 03:17:47.204100: train Epoch: [0][ 42/193]	Time  8.940 ( 5.171)	Data  8.038 ( 4.252)	Loss 6.0440e-01 (7.4397e-01) 
2023-05-27 03:17:48.547080: train Epoch: [0][ 43/193]	Time  1.343 ( 5.084)	Data  0.374 ( 4.164)	Loss 6.2062e-01 (7.4117e-01) 
2023-05-27 03:17:57.458099: train Epoch: [0][ 44/193]	Time  8.911 ( 5.169)	Data  7.871 ( 4.247)	Loss 7.0173e-01 (7.4029e-01) 
2023-05-27 03:17:58.870550: train Epoch: [0][ 45/193]	Time  1.412 ( 5.088)	Data  0.533 ( 4.166)	Loss 7.0706e-01 (7.3957e-01) 
2023-05-27 03:18:07.405956: train Epoch: [0][ 46/193]	Time  8.535 ( 5.161)	Data  7.567 ( 4.238)	Loss 6.8706e-01 (7.3845e-01) 
2023-05-27 03:18:08.873962: train Epoch: [0][ 47/193]	Time  1.468 ( 5.084)	Data  0.554 ( 4.162)	Loss 6.1695e-01 (7.3592e-01) 
2023-05-27 03:18:17.829526: train Epoch: [0][ 48/193]	Time  8.956 ( 5.163)	Data  7.929 ( 4.238)	Loss 7.3036e-01 (7.3581e-01) 
2023-05-27 03:18:19.118088: train Epoch: [0][ 49/193]	Time  1.289 ( 5.086)	Data  0.436 ( 4.162)	Loss 6.3444e-01 (7.3378e-01) 
2023-05-27 03:18:28.034722: train Epoch: [0][ 50/193]	Time  8.917 ( 5.161)	Data  8.054 ( 4.239)	Loss 6.1763e-01 (7.3150e-01) 
2023-05-27 03:18:29.696367: train Epoch: [0][ 51/193]	Time  1.662 ( 5.093)	Data  0.739 ( 4.171)	Loss 5.5546e-01 (7.2812e-01) 
2023-05-27 03:18:38.941007: train Epoch: [0][ 52/193]	Time  9.245 ( 5.172)	Data  8.229 ( 4.248)	Loss 5.1578e-01 (7.2411e-01) 
2023-05-27 03:18:39.933393: train Epoch: [0][ 53/193]	Time  0.992 ( 5.094)	Data  0.114 ( 4.171)	Loss 6.6501e-01 (7.2301e-01) 
2023-05-27 03:18:48.649468: train Epoch: [0][ 54/193]	Time  8.716 ( 5.160)	Data  7.772 ( 4.237)	Loss 6.4574e-01 (7.2161e-01) 
2023-05-27 03:18:49.693808: train Epoch: [0][ 55/193]	Time  1.044 ( 5.087)	Data  0.204 ( 4.165)	Loss 4.8371e-01 (7.1736e-01) 
2023-05-27 03:18:59.267728: train Epoch: [0][ 56/193]	Time  9.574 ( 5.165)	Data  8.449 ( 4.240)	Loss 5.0685e-01 (7.1367e-01) 
2023-05-27 03:19:00.153644: train Epoch: [0][ 57/193]	Time  0.886 ( 5.092)	Data  0.001 ( 4.167)	Loss 5.5110e-01 (7.1087e-01) 
2023-05-27 03:19:09.143616: train Epoch: [0][ 58/193]	Time  8.990 ( 5.158)	Data  8.047 ( 4.233)	Loss 4.6956e-01 (7.0678e-01) 
2023-05-27 03:19:10.016980: train Epoch: [0][ 59/193]	Time  0.873 ( 5.086)	Data  0.001 ( 4.162)	Loss 6.4659e-01 (7.0577e-01) 
2023-05-27 03:19:19.260875: train Epoch: [0][ 60/193]	Time  9.244 ( 5.154)	Data  8.279 ( 4.230)	Loss 5.3313e-01 (7.0294e-01) 
2023-05-27 03:19:20.246802: train Epoch: [0][ 61/193]	Time  0.986 ( 5.087)	Data  0.001 ( 4.161)	Loss 4.9487e-01 (6.9959e-01) 
2023-05-27 03:19:29.496060: train Epoch: [0][ 62/193]	Time  9.249 ( 5.153)	Data  8.185 ( 4.225)	Loss 3.9134e-01 (6.9469e-01) 
2023-05-27 03:19:30.492633: train Epoch: [0][ 63/193]	Time  0.997 ( 5.088)	Data  0.001 ( 4.159)	Loss 4.4389e-01 (6.9077e-01) 
2023-05-27 03:19:39.478204: train Epoch: [0][ 64/193]	Time  8.986 ( 5.148)	Data  7.991 ( 4.218)	Loss 5.6027e-01 (6.8877e-01) 
2023-05-27 03:19:40.473253: train Epoch: [0][ 65/193]	Time  0.995 ( 5.085)	Data  0.001 ( 4.154)	Loss 4.9724e-01 (6.8587e-01) 
2023-05-27 03:19:49.506731: train Epoch: [0][ 66/193]	Time  9.033 ( 5.144)	Data  8.085 ( 4.213)	Loss 5.5362e-01 (6.8389e-01) 
2023-05-27 03:19:50.452907: train Epoch: [0][ 67/193]	Time  0.946 ( 5.083)	Data  0.001 ( 4.151)	Loss 6.4153e-01 (6.8327e-01) 
2023-05-27 03:19:59.958662: train Epoch: [0][ 68/193]	Time  9.506 ( 5.147)	Data  8.380 ( 4.212)	Loss 6.2215e-01 (6.8238e-01) 
2023-05-27 03:20:00.857975: train Epoch: [0][ 69/193]	Time  0.899 ( 5.086)	Data  0.001 ( 4.152)	Loss 5.3668e-01 (6.8030e-01) 
2023-05-27 03:20:09.581912: train Epoch: [0][ 70/193]	Time  8.724 ( 5.137)	Data  7.791 ( 4.203)	Loss 5.3839e-01 (6.7830e-01) 
2023-05-27 03:20:10.881058: train Epoch: [0][ 71/193]	Time  1.299 ( 5.084)	Data  0.335 ( 4.150)	Loss 4.8875e-01 (6.7567e-01) 
2023-05-27 03:20:18.967544: train Epoch: [0][ 72/193]	Time  8.086 ( 5.125)	Data  7.193 ( 4.191)	Loss 4.4667e-01 (6.7253e-01) 
2023-05-27 03:20:20.636951: train Epoch: [0][ 73/193]	Time  1.669 ( 5.078)	Data  0.706 ( 4.144)	Loss 3.8238e-01 (6.6861e-01) 
2023-05-27 03:20:28.590670: train Epoch: [0][ 74/193]	Time  7.954 ( 5.117)	Data  7.055 ( 4.183)	Loss 5.4281e-01 (6.6693e-01) 
2023-05-27 03:20:30.553978: train Epoch: [0][ 75/193]	Time  1.963 ( 5.075)	Data  1.161 ( 4.143)	Loss 4.9975e-01 (6.6473e-01) 
2023-05-27 03:20:37.939045: train Epoch: [0][ 76/193]	Time  7.385 ( 5.105)	Data  6.339 ( 4.172)	Loss 3.0373e-01 (6.6005e-01) 
2023-05-27 03:20:39.549843: train Epoch: [0][ 77/193]	Time  1.611 ( 5.060)	Data  0.571 ( 4.126)	Loss 3.9144e-01 (6.5660e-01) 
2023-05-27 03:20:47.707979: train Epoch: [0][ 78/193]	Time  8.158 ( 5.100)	Data  7.150 ( 4.164)	Loss 3.0762e-01 (6.5219e-01) 
2023-05-27 03:20:49.186628: train Epoch: [0][ 79/193]	Time  1.479 ( 5.054)	Data  0.601 ( 4.119)	Loss 4.8248e-01 (6.5006e-01) 
2023-05-27 03:20:57.816476: train Epoch: [0][ 80/193]	Time  8.630 ( 5.098)	Data  7.755 ( 4.164)	Loss 5.3246e-01 (6.4861e-01) 
2023-05-27 03:20:59.415545: train Epoch: [0][ 81/193]	Time  1.599 ( 5.056)	Data  0.701 ( 4.122)	Loss 5.4886e-01 (6.4740e-01) 
2023-05-27 03:21:07.948452: train Epoch: [0][ 82/193]	Time  8.533 ( 5.098)	Data  7.702 ( 4.165)	Loss 4.4342e-01 (6.4494e-01) 
2023-05-27 03:21:09.407614: train Epoch: [0][ 83/193]	Time  1.459 ( 5.054)	Data  0.613 ( 4.123)	Loss 4.1971e-01 (6.4226e-01) 
2023-05-27 03:21:17.703455: train Epoch: [0][ 84/193]	Time  8.296 ( 5.092)	Data  7.705 ( 4.165)	Loss 4.1728e-01 (6.3961e-01) 
2023-05-27 03:21:19.242307: train Epoch: [0][ 85/193]	Time  1.539 ( 5.051)	Data  0.965 ( 4.128)	Loss 5.4475e-01 (6.3851e-01) 
2023-05-27 03:21:28.320235: train Epoch: [0][ 86/193]	Time  9.078 ( 5.097)	Data  8.244 ( 4.175)	Loss 5.3951e-01 (6.3737e-01) 
2023-05-27 03:21:29.357114: train Epoch: [0][ 87/193]	Time  1.037 ( 5.051)	Data  0.119 ( 4.129)	Loss 3.3490e-01 (6.3393e-01) 
2023-05-27 03:21:38.925463: train Epoch: [0][ 88/193]	Time  9.568 ( 5.102)	Data  8.638 ( 4.180)	Loss 4.9859e-01 (6.3241e-01) 
2023-05-27 03:21:39.990001: train Epoch: [0][ 89/193]	Time  1.065 ( 5.057)	Data  0.001 ( 4.133)	Loss 3.5976e-01 (6.2938e-01) 
2023-05-27 03:21:49.257373: train Epoch: [0][ 90/193]	Time  9.267 ( 5.103)	Data  8.281 ( 4.179)	Loss 4.8707e-01 (6.2782e-01) 
2023-05-27 03:21:50.340620: train Epoch: [0][ 91/193]	Time  1.083 ( 5.060)	Data  0.001 ( 4.133)	Loss 3.2753e-01 (6.2455e-01) 
2023-05-27 03:21:59.150732: train Epoch: [0][ 92/193]	Time  8.810 ( 5.100)	Data  7.839 ( 4.173)	Loss 3.2097e-01 (6.2129e-01) 
2023-05-27 03:22:00.092121: train Epoch: [0][ 93/193]	Time  0.941 ( 5.056)	Data  0.001 ( 4.129)	Loss 3.9509e-01 (6.1888e-01) 
2023-05-27 03:22:09.525914: train Epoch: [0][ 94/193]	Time  9.434 ( 5.102)	Data  8.447 ( 4.174)	Loss 4.6986e-01 (6.1731e-01) 
2023-05-27 03:22:10.455161: train Epoch: [0][ 95/193]	Time  0.929 ( 5.058)	Data  0.001 ( 4.131)	Loss 3.8943e-01 (6.1494e-01) 
2023-05-27 03:22:19.418640: train Epoch: [0][ 96/193]	Time  8.963 ( 5.099)	Data  8.083 ( 4.172)	Loss 4.0570e-01 (6.1278e-01) 
2023-05-27 03:22:20.284627: train Epoch: [0][ 97/193]	Time  0.866 ( 5.056)	Data  0.001 ( 4.129)	Loss 6.0784e-01 (6.1273e-01) 
2023-05-27 03:22:29.752404: train Epoch: [0][ 98/193]	Time  9.468 ( 5.100)	Data  8.550 ( 4.174)	Loss 5.7592e-01 (6.1236e-01) 
2023-05-27 03:22:30.662406: train Epoch: [0][ 99/193]	Time  0.910 ( 5.058)	Data  0.001 ( 4.132)	Loss 5.4352e-01 (6.1167e-01) 
2023-05-27 03:22:40.327280: train Epoch: [0][100/193]	Time  9.665 ( 5.104)	Data  8.657 ( 4.177)	Loss 3.6641e-01 (6.0924e-01) 
2023-05-27 03:22:41.147207: train Epoch: [0][101/193]	Time  0.820 ( 5.062)	Data  0.001 ( 4.136)	Loss 4.8951e-01 (6.0807e-01) 
2023-05-27 03:22:50.976061: train Epoch: [0][102/193]	Time  9.829 ( 5.108)	Data  8.982 ( 4.183)	Loss 4.0219e-01 (6.0607e-01) 
2023-05-27 03:22:51.893265: train Epoch: [0][103/193]	Time  0.917 ( 5.068)	Data  0.001 ( 4.143)	Loss 3.5672e-01 (6.0367e-01) 
2023-05-27 03:23:00.123306: train Epoch: [0][104/193]	Time  8.230 ( 5.098)	Data  7.244 ( 4.172)	Loss 5.2289e-01 (6.0290e-01) 
2023-05-27 03:23:01.081394: train Epoch: [0][105/193]	Time  0.958 ( 5.059)	Data  0.001 ( 4.133)	Loss 5.5143e-01 (6.0242e-01) 
2023-05-27 03:23:08.397648: train Epoch: [0][106/193]	Time  7.316 ( 5.080)	Data  6.396 ( 4.154)	Loss 4.8220e-01 (6.0130e-01) 
2023-05-27 03:23:09.368529: train Epoch: [0][107/193]	Time  0.971 ( 5.042)	Data  0.001 ( 4.116)	Loss 5.3146e-01 (6.0065e-01) 
2023-05-27 03:23:18.359787: train Epoch: [0][108/193]	Time  8.991 ( 5.078)	Data  8.082 ( 4.152)	Loss 2.1207e-01 (5.9708e-01) 
2023-05-27 03:23:19.361982: train Epoch: [0][109/193]	Time  1.002 ( 5.041)	Data  0.001 ( 4.114)	Loss 6.1344e-01 (5.9723e-01) 
2023-05-27 03:23:28.514331: train Epoch: [0][110/193]	Time  9.152 ( 5.078)	Data  8.151 ( 4.151)	Loss 2.0170e-01 (5.9367e-01) 
2023-05-27 03:23:29.465190: train Epoch: [0][111/193]	Time  0.951 ( 5.041)	Data  0.001 ( 4.114)	Loss 3.5804e-01 (5.9157e-01) 
2023-05-27 03:23:38.531952: train Epoch: [0][112/193]	Time  9.067 ( 5.077)	Data  8.214 ( 4.150)	Loss 3.4822e-01 (5.8941e-01) 
2023-05-27 03:23:39.411398: train Epoch: [0][113/193]	Time  0.879 ( 5.040)	Data  0.001 ( 4.113)	Loss 3.7083e-01 (5.8749e-01) 
2023-05-27 03:23:48.390492: train Epoch: [0][114/193]	Time  8.979 ( 5.074)	Data  8.068 ( 4.148)	Loss 3.6327e-01 (5.8554e-01) 
2023-05-27 03:23:49.261585: train Epoch: [0][115/193]	Time  0.871 ( 5.038)	Data  0.001 ( 4.112)	Loss 4.5219e-01 (5.8440e-01) 
2023-05-27 03:23:58.231748: train Epoch: [0][116/193]	Time  8.970 ( 5.072)	Data  8.040 ( 4.146)	Loss 6.2135e-01 (5.8471e-01) 
2023-05-27 03:23:59.310776: train Epoch: [0][117/193]	Time  1.079 ( 5.038)	Data  0.001 ( 4.111)	Loss 5.0220e-01 (5.8401e-01) 
2023-05-27 03:24:08.755779: train Epoch: [0][118/193]	Time  9.445 ( 5.075)	Data  8.473 ( 4.147)	Loss 3.3438e-01 (5.8191e-01) 
2023-05-27 03:24:09.723487: train Epoch: [0][119/193]	Time  0.968 ( 5.041)	Data  0.001 ( 4.113)	Loss 2.6660e-01 (5.7929e-01) 
2023-05-27 03:24:19.107058: train Epoch: [0][120/193]	Time  9.384 ( 5.077)	Data  8.454 ( 4.149)	Loss 4.2867e-01 (5.7804e-01) 
2023-05-27 03:24:20.079380: train Epoch: [0][121/193]	Time  0.972 ( 5.043)	Data  0.001 ( 4.115)	Loss 3.6555e-01 (5.7630e-01) 
2023-05-27 03:24:28.919488: train Epoch: [0][122/193]	Time  8.840 ( 5.074)	Data  7.835 ( 4.145)	Loss 3.4660e-01 (5.7443e-01) 
2023-05-27 03:24:29.818290: train Epoch: [0][123/193]	Time  0.899 ( 5.040)	Data  0.001 ( 4.111)	Loss 5.1157e-01 (5.7393e-01) 
2023-05-27 03:24:39.254589: train Epoch: [0][124/193]	Time  9.436 ( 5.075)	Data  8.508 ( 4.147)	Loss 2.2194e-01 (5.7111e-01) 
2023-05-27 03:24:40.177129: train Epoch: [0][125/193]	Time  0.923 ( 5.042)	Data  0.001 ( 4.114)	Loss 3.7419e-01 (5.6955e-01) 
2023-05-27 03:24:49.029492: train Epoch: [0][126/193]	Time  8.852 ( 5.072)	Data  7.946 ( 4.144)	Loss 3.1135e-01 (5.6751e-01) 
2023-05-27 03:24:49.991312: train Epoch: [0][127/193]	Time  0.962 ( 5.040)	Data  0.001 ( 4.111)	Loss 2.2061e-01 (5.6480e-01) 
2023-05-27 03:24:59.200029: train Epoch: [0][128/193]	Time  9.209 ( 5.073)	Data  8.213 ( 4.143)	Loss 3.2684e-01 (5.6296e-01) 
2023-05-27 03:25:00.094692: train Epoch: [0][129/193]	Time  0.895 ( 5.040)	Data  0.001 ( 4.111)	Loss 3.3075e-01 (5.6117e-01) 
2023-05-27 03:25:09.098672: train Epoch: [0][130/193]	Time  9.004 ( 5.071)	Data  8.120 ( 4.142)	Loss 2.0174e-01 (5.5843e-01) 
2023-05-27 03:25:09.995518: train Epoch: [0][131/193]	Time  0.897 ( 5.039)	Data  0.001 ( 4.111)	Loss 2.7466e-01 (5.5628e-01) 
2023-05-27 03:25:19.239143: train Epoch: [0][132/193]	Time  9.244 ( 5.071)	Data  8.360 ( 4.143)	Loss 3.1370e-01 (5.5446e-01) 
2023-05-27 03:25:20.199725: train Epoch: [0][133/193]	Time  0.961 ( 5.040)	Data  0.001 ( 4.112)	Loss 3.1133e-01 (5.5264e-01) 
2023-05-27 03:25:29.414856: train Epoch: [0][134/193]	Time  9.215 ( 5.071)	Data  8.402 ( 4.143)	Loss 3.4431e-01 (5.5110e-01) 
2023-05-27 03:25:30.307970: train Epoch: [0][135/193]	Time  0.893 ( 5.040)	Data  0.001 ( 4.113)	Loss 2.4117e-01 (5.4882e-01) 
2023-05-27 03:25:39.937918: train Epoch: [0][136/193]	Time  9.630 ( 5.074)	Data  8.671 ( 4.146)	Loss 3.0996e-01 (5.4708e-01) 
2023-05-27 03:25:40.933293: train Epoch: [0][137/193]	Time  0.995 ( 5.044)	Data  0.001 ( 4.116)	Loss 1.7731e-01 (5.4440e-01) 
2023-05-27 03:25:49.428571: train Epoch: [0][138/193]	Time  8.495 ( 5.069)	Data  7.702 ( 4.142)	Loss 2.8132e-01 (5.4250e-01) 
2023-05-27 03:25:50.301769: train Epoch: [0][139/193]	Time  0.873 ( 5.039)	Data  0.001 ( 4.112)	Loss 3.8626e-01 (5.4139e-01) 
2023-05-27 03:26:00.154479: train Epoch: [0][140/193]	Time  9.853 ( 5.073)	Data  8.775 ( 4.145)	Loss 4.0718e-01 (5.4044e-01) 
2023-05-27 03:26:01.147381: train Epoch: [0][141/193]	Time  0.993 ( 5.044)	Data  0.001 ( 4.116)	Loss 2.7880e-01 (5.3859e-01) 
2023-05-27 03:26:09.609951: train Epoch: [0][142/193]	Time  8.463 ( 5.068)	Data  7.558 ( 4.140)	Loss 1.7846e-01 (5.3607e-01) 
2023-05-27 03:26:10.614666: train Epoch: [0][143/193]	Time  1.005 ( 5.040)	Data  0.001 ( 4.112)	Loss 3.2936e-01 (5.3464e-01) 
2023-05-27 03:26:19.580953: train Epoch: [0][144/193]	Time  8.966 ( 5.067)	Data  8.068 ( 4.139)	Loss 2.6882e-01 (5.3281e-01) 
2023-05-27 03:26:20.589325: train Epoch: [0][145/193]	Time  1.008 ( 5.039)	Data  0.001 ( 4.111)	Loss 1.6133e-01 (5.3026e-01) 
2023-05-27 03:26:29.341244: train Epoch: [0][146/193]	Time  8.752 ( 5.065)	Data  7.906 ( 4.136)	Loss 3.0264e-01 (5.2871e-01) 
2023-05-27 03:26:30.287626: train Epoch: [0][147/193]	Time  0.946 ( 5.037)	Data  0.001 ( 4.108)	Loss 2.6495e-01 (5.2693e-01) 
2023-05-27 03:26:39.418201: train Epoch: [0][148/193]	Time  9.131 ( 5.064)	Data  8.396 ( 4.137)	Loss 4.2986e-01 (5.2628e-01) 
2023-05-27 03:26:40.423869: train Epoch: [0][149/193]	Time  1.006 ( 5.037)	Data  0.179 ( 4.111)	Loss 4.1258e-01 (5.2552e-01) 
2023-05-27 03:26:49.606870: train Epoch: [0][150/193]	Time  9.183 ( 5.065)	Data  8.225 ( 4.138)	Loss 4.3209e-01 (5.2490e-01) 
2023-05-27 03:26:50.861828: train Epoch: [0][151/193]	Time  1.255 ( 5.040)	Data  0.338 ( 4.113)	Loss 2.4106e-01 (5.2304e-01) 
2023-05-27 03:26:59.908271: train Epoch: [0][152/193]	Time  9.046 ( 5.066)	Data  8.099 ( 4.139)	Loss 2.5835e-01 (5.2131e-01) 
2023-05-27 03:27:00.901067: train Epoch: [0][153/193]	Time  0.993 ( 5.039)	Data  0.051 ( 4.113)	Loss 2.5630e-01 (5.1958e-01) 
2023-05-27 03:27:10.362689: train Epoch: [0][154/193]	Time  9.462 ( 5.068)	Data  8.610 ( 4.142)	Loss 2.8031e-01 (5.1804e-01) 
2023-05-27 03:27:11.471791: train Epoch: [0][155/193]	Time  1.109 ( 5.042)	Data  0.001 ( 4.115)	Loss 3.8795e-01 (5.1721e-01) 
2023-05-27 03:27:20.730805: train Epoch: [0][156/193]	Time  9.259 ( 5.069)	Data  8.408 ( 4.142)	Loss 2.8961e-01 (5.1576e-01) 
2023-05-27 03:27:21.625085: train Epoch: [0][157/193]	Time  0.894 ( 5.043)	Data  0.001 ( 4.116)	Loss 6.4641e-01 (5.1658e-01) 
2023-05-27 03:27:30.982535: train Epoch: [0][158/193]	Time  9.357 ( 5.070)	Data  8.367 ( 4.143)	Loss 3.0495e-01 (5.1525e-01) 
2023-05-27 03:27:31.951109: train Epoch: [0][159/193]	Time  0.969 ( 5.044)	Data  0.001 ( 4.117)	Loss 2.4431e-01 (5.1356e-01) 
2023-05-27 03:27:40.941532: train Epoch: [0][160/193]	Time  8.990 ( 5.069)	Data  8.077 ( 4.142)	Loss 3.2786e-01 (5.1241e-01) 
2023-05-27 03:27:42.162857: train Epoch: [0][161/193]	Time  1.221 ( 5.045)	Data  0.306 ( 4.118)	Loss 4.5309e-01 (5.1204e-01) 
2023-05-27 03:27:50.641913: train Epoch: [0][162/193]	Time  8.479 ( 5.066)	Data  7.632 ( 4.139)	Loss 1.8977e-01 (5.1006e-01) 
2023-05-27 03:27:52.246007: train Epoch: [0][163/193]	Time  1.604 ( 5.045)	Data  0.626 ( 4.118)	Loss 2.1083e-01 (5.0824e-01) 
2023-05-27 03:28:00.851338: train Epoch: [0][164/193]	Time  8.605 ( 5.067)	Data  7.606 ( 4.139)	Loss 1.9800e-01 (5.0636e-01) 
2023-05-27 03:28:02.012394: train Epoch: [0][165/193]	Time  1.161 ( 5.043)	Data  0.232 ( 4.116)	Loss 2.4334e-01 (5.0477e-01) 
2023-05-27 03:28:10.499479: train Epoch: [0][166/193]	Time  8.487 ( 5.064)	Data  7.643 ( 4.137)	Loss 2.5605e-01 (5.0328e-01) 
2023-05-27 03:28:11.818365: train Epoch: [0][167/193]	Time  1.319 ( 5.042)	Data  0.492 ( 4.115)	Loss 1.9711e-01 (5.0146e-01) 
2023-05-27 03:28:20.805991: train Epoch: [0][168/193]	Time  8.988 ( 5.065)	Data  8.066 ( 4.138)	Loss 2.4238e-01 (4.9993e-01) 
2023-05-27 03:28:21.903341: train Epoch: [0][169/193]	Time  1.097 ( 5.042)	Data  0.107 ( 4.115)	Loss 6.0467e-01 (5.0054e-01) 
2023-05-27 03:28:30.925187: train Epoch: [0][170/193]	Time  9.022 ( 5.065)	Data  8.171 ( 4.138)	Loss 5.0462e-01 (5.0057e-01) 
2023-05-27 03:28:31.878998: train Epoch: [0][171/193]	Time  0.954 ( 5.041)	Data  0.001 ( 4.114)	Loss 3.2147e-01 (4.9953e-01) 
2023-05-27 03:28:40.853682: train Epoch: [0][172/193]	Time  8.975 ( 5.064)	Data  7.986 ( 4.137)	Loss 2.6464e-01 (4.9817e-01) 
2023-05-27 03:28:41.845764: train Epoch: [0][173/193]	Time  0.992 ( 5.040)	Data  0.001 ( 4.113)	Loss 4.3382e-01 (4.9780e-01) 
2023-05-27 03:28:50.631806: train Epoch: [0][174/193]	Time  8.786 ( 5.062)	Data  7.856 ( 4.134)	Loss 2.3160e-01 (4.9628e-01) 
2023-05-27 03:28:52.099740: train Epoch: [0][175/193]	Time  1.468 ( 5.041)	Data  0.623 ( 4.114)	Loss 2.8351e-01 (4.9507e-01) 
2023-05-27 03:29:01.161860: train Epoch: [0][176/193]	Time  9.062 ( 5.064)	Data  8.119 ( 4.137)	Loss 4.2354e-01 (4.9467e-01) 
2023-05-27 03:29:02.321087: train Epoch: [0][177/193]	Time  1.159 ( 5.042)	Data  0.164 ( 4.115)	Loss 1.6511e-01 (4.9281e-01) 
2023-05-27 03:29:11.770419: train Epoch: [0][178/193]	Time  9.449 ( 5.067)	Data  8.377 ( 4.139)	Loss 4.0966e-01 (4.9235e-01) 
2023-05-27 03:29:12.726551: train Epoch: [0][179/193]	Time  0.956 ( 5.044)	Data  0.001 ( 4.116)	Loss 2.9573e-01 (4.9126e-01) 
2023-05-27 03:29:21.264221: train Epoch: [0][180/193]	Time  8.538 ( 5.063)	Data  7.752 ( 4.136)	Loss 3.4287e-01 (4.9044e-01) 
2023-05-27 03:29:22.247861: train Epoch: [0][181/193]	Time  0.984 ( 5.041)	Data  0.068 ( 4.113)	Loss 3.5091e-01 (4.8967e-01) 
2023-05-27 03:29:31.082716: train Epoch: [0][182/193]	Time  8.835 ( 5.061)	Data  7.958 ( 4.134)	Loss 3.5484e-01 (4.8893e-01) 
2023-05-27 03:29:32.035774: train Epoch: [0][183/193]	Time  0.953 ( 5.039)	Data  0.110 ( 4.112)	Loss 2.2663e-01 (4.8751e-01) 
2023-05-27 03:29:41.093526: train Epoch: [0][184/193]	Time  9.058 ( 5.061)	Data  8.246 ( 4.135)	Loss 2.5392e-01 (4.8625e-01) 
2023-05-27 03:29:42.079619: train Epoch: [0][185/193]	Time  0.986 ( 5.039)	Data  0.139 ( 4.113)	Loss 3.7876e-01 (4.8567e-01) 
2023-05-27 03:29:51.216074: train Epoch: [0][186/193]	Time  9.136 ( 5.061)	Data  8.221 ( 4.135)	Loss 2.0421e-01 (4.8416e-01) 
2023-05-27 03:29:52.144490: train Epoch: [0][187/193]	Time  0.928 ( 5.039)	Data  0.001 ( 4.113)	Loss 5.8349e-01 (4.8469e-01) 
2023-05-27 03:30:01.229883: train Epoch: [0][188/193]	Time  9.085 ( 5.060)	Data  8.237 ( 4.135)	Loss 2.5863e-01 (4.8350e-01) 
2023-05-27 03:30:02.180247: train Epoch: [0][189/193]	Time  0.950 ( 5.039)	Data  0.001 ( 4.113)	Loss 3.3970e-01 (4.8274e-01) 
2023-05-27 03:30:10.892139: train Epoch: [0][190/193]	Time  8.712 ( 5.058)	Data  7.818 ( 4.133)	Loss 2.9557e-01 (4.8176e-01) 
2023-05-27 03:30:12.225391: train Epoch: [0][191/193]	Time  1.333 ( 5.038)	Data  0.502 ( 4.114)	Loss 1.4704e-01 (4.8002e-01) 
2023-05-27 03:30:20.265632: train Epoch: [0][192/193]	Time  8.040 ( 5.054)	Data  7.012 ( 4.129)	Loss 2.8246e-01 (4.7899e-01) 
2023-05-27 03:30:20.425642: Train Epoch done in 975.5832306540105 s 
2023-05-27 03:30:26.882023: val Epoch: [0][ 0/72]	Time  5.737 ( 5.737)	Data  5.338 ( 5.338)	Loss 2.9937e-01 (2.9937e-01) 
2023-05-27 03:30:27.196151: val Epoch: [0][ 1/72]	Time  0.314 ( 3.026)	Data  0.001 ( 2.669)	Loss 6.7381e-01 (4.8659e-01) 
2023-05-27 03:30:31.355726: val Epoch: [0][ 2/72]	Time  4.160 ( 3.404)	Data  3.990 ( 3.109)	Loss 2.2209e-01 (3.9843e-01) 
2023-05-27 03:30:32.297082: val Epoch: [0][ 3/72]	Time  0.941 ( 2.788)	Data  0.733 ( 2.515)	Loss 2.4703e-01 (3.6058e-01) 
2023-05-27 03:30:36.294511: val Epoch: [0][ 4/72]	Time  3.997 ( 3.030)	Data  3.827 ( 2.778)	Loss 1.7438e-01 (3.2334e-01) 
2023-05-27 03:30:37.368786: val Epoch: [0][ 5/72]	Time  1.074 ( 2.704)	Data  0.864 ( 2.459)	Loss 3.0932e-01 (3.2100e-01) 
2023-05-27 03:30:41.426448: val Epoch: [0][ 6/72]	Time  4.058 ( 2.897)	Data  3.809 ( 2.652)	Loss 2.2038e-01 (3.0663e-01) 
2023-05-27 03:30:42.617163: val Epoch: [0][ 7/72]	Time  1.191 ( 2.684)	Data  1.027 ( 2.449)	Loss 3.6541e-01 (3.1398e-01) 
2023-05-27 03:30:47.063683: val Epoch: [0][ 8/72]	Time  4.446 ( 2.880)	Data  4.240 ( 2.648)	Loss 1.6033e-01 (2.9690e-01) 
2023-05-27 03:30:47.570626: val Epoch: [0][ 9/72]	Time  0.507 ( 2.643)	Data  0.262 ( 2.409)	Loss 1.9381e-01 (2.8659e-01) 
2023-05-27 03:30:52.007248: val Epoch: [0][10/72]	Time  4.437 ( 2.806)	Data  4.268 ( 2.578)	Loss 1.6121e-01 (2.7520e-01) 
2023-05-27 03:30:52.527097: val Epoch: [0][11/72]	Time  0.520 ( 2.615)	Data  0.240 ( 2.383)	Loss 3.1730e-01 (2.7870e-01) 
2023-05-27 03:30:56.936203: val Epoch: [0][12/72]	Time  4.409 ( 2.753)	Data  4.226 ( 2.525)	Loss 2.2164e-01 (2.7432e-01) 
2023-05-27 03:30:57.688778: val Epoch: [0][13/72]	Time  0.753 ( 2.610)	Data  0.585 ( 2.386)	Loss 5.0300e-01 (2.9065e-01) 
2023-05-27 03:31:02.121523: val Epoch: [0][14/72]	Time  4.433 ( 2.732)	Data  4.281 ( 2.513)	Loss 2.2174e-01 (2.8606e-01) 
2023-05-27 03:31:02.767203: val Epoch: [0][15/72]	Time  0.646 ( 2.601)	Data  0.416 ( 2.382)	Loss 1.7136e-01 (2.7889e-01) 
2023-05-27 03:31:07.249060: val Epoch: [0][16/72]	Time  4.482 ( 2.712)	Data  4.253 ( 2.492)	Loss 2.4445e-01 (2.7686e-01) 
2023-05-27 03:31:07.630002: val Epoch: [0][17/72]	Time  0.381 ( 2.582)	Data  0.188 ( 2.364)	Loss 2.6574e-01 (2.7624e-01) 
2023-05-27 03:31:12.470520: val Epoch: [0][18/72]	Time  4.841 ( 2.701)	Data  4.660 ( 2.485)	Loss 3.5306e-01 (2.8029e-01) 
2023-05-27 03:31:12.962440: val Epoch: [0][19/72]	Time  0.492 ( 2.591)	Data  0.220 ( 2.371)	Loss 6.6201e-01 (2.9937e-01) 
2023-05-27 03:31:17.462298: val Epoch: [0][20/72]	Time  4.500 ( 2.682)	Data  4.267 ( 2.462)	Loss 3.5624e-01 (3.0208e-01) 
2023-05-27 03:31:18.275801: val Epoch: [0][21/72]	Time  0.813 ( 2.597)	Data  0.631 ( 2.378)	Loss 5.6098e-01 (3.1385e-01) 
2023-05-27 03:31:22.797262: val Epoch: [0][22/72]	Time  4.521 ( 2.681)	Data  4.290 ( 2.462)	Loss 1.4650e-01 (3.0657e-01) 
2023-05-27 03:31:22.997361: val Epoch: [0][23/72]	Time  0.200 ( 2.577)	Data  0.034 ( 2.360)	Loss 2.6373e-01 (3.0479e-01) 
2023-05-27 03:31:28.179156: val Epoch: [0][24/72]	Time  5.182 ( 2.681)	Data  4.900 ( 2.462)	Loss 6.9498e-01 (3.2040e-01) 
2023-05-27 03:31:28.450312: val Epoch: [0][25/72]	Time  0.271 ( 2.589)	Data  0.000 ( 2.367)	Loss 1.7322e-01 (3.1473e-01) 
2023-05-27 03:31:33.177747: val Epoch: [0][26/72]	Time  4.727 ( 2.668)	Data  4.544 ( 2.448)	Loss 2.9036e-01 (3.1383e-01) 
2023-05-27 03:31:33.332918: val Epoch: [0][27/72]	Time  0.155 ( 2.578)	Data  0.001 ( 2.361)	Loss 3.5645e-01 (3.1535e-01) 
2023-05-27 03:31:38.359564: val Epoch: [0][28/72]	Time  5.027 ( 2.663)	Data  4.862 ( 2.447)	Loss 4.5766e-01 (3.2026e-01) 
2023-05-27 03:31:38.606138: val Epoch: [0][29/72]	Time  0.247 ( 2.582)	Data  0.001 ( 2.365)	Loss 6.6307e-01 (3.3169e-01) 
2023-05-27 03:31:43.838946: val Epoch: [0][30/72]	Time  5.233 ( 2.668)	Data  4.999 ( 2.450)	Loss 3.1753e-01 (3.3123e-01) 
2023-05-27 03:31:44.021617: val Epoch: [0][31/72]	Time  0.183 ( 2.590)	Data  0.001 ( 2.374)	Loss 2.2993e-01 (3.2807e-01) 
2023-05-27 03:31:48.716667: val Epoch: [0][32/72]	Time  4.695 ( 2.654)	Data  4.515 ( 2.439)	Loss 2.6156e-01 (3.2605e-01) 
2023-05-27 03:31:48.967424: val Epoch: [0][33/72]	Time  0.251 ( 2.583)	Data  0.000 ( 2.367)	Loss 3.4415e-01 (3.2658e-01) 
2023-05-27 03:31:53.615974: val Epoch: [0][34/72]	Time  4.649 ( 2.642)	Data  4.504 ( 2.428)	Loss 1.4141e-01 (3.2129e-01) 
2023-05-27 03:31:53.780367: val Epoch: [0][35/72]	Time  0.164 ( 2.573)	Data  0.001 ( 2.361)	Loss 1.5992e-01 (3.1681e-01) 
2023-05-27 03:31:59.162707: val Epoch: [0][36/72]	Time  5.382 ( 2.649)	Data  5.161 ( 2.436)	Loss 5.2681e-01 (3.2248e-01) 
2023-05-27 03:31:59.379587: val Epoch: [0][37/72]	Time  0.217 ( 2.585)	Data  0.001 ( 2.372)	Loss 2.8267e-01 (3.2144e-01) 
2023-05-27 03:32:04.090734: val Epoch: [0][38/72]	Time  4.711 ( 2.640)	Data  4.524 ( 2.427)	Loss 1.7748e-01 (3.1775e-01) 
2023-05-27 03:32:04.356277: val Epoch: [0][39/72]	Time  0.266 ( 2.580)	Data  0.001 ( 2.367)	Loss 3.7773e-01 (3.1925e-01) 
2023-05-27 03:32:09.466483: val Epoch: [0][40/72]	Time  5.110 ( 2.642)	Data  4.941 ( 2.429)	Loss 4.5185e-01 (3.2248e-01) 
2023-05-27 03:32:09.747262: val Epoch: [0][41/72]	Time  0.281 ( 2.586)	Data  0.001 ( 2.372)	Loss 3.7076e-01 (3.2363e-01) 
2023-05-27 03:32:14.432772: val Epoch: [0][42/72]	Time  4.686 ( 2.635)	Data  4.355 ( 2.418)	Loss 2.0086e-01 (3.2077e-01) 
2023-05-27 03:32:14.682128: val Epoch: [0][43/72]	Time  0.249 ( 2.580)	Data  0.000 ( 2.363)	Loss 3.4220e-01 (3.2126e-01) 
2023-05-27 03:32:19.454028: val Epoch: [0][44/72]	Time  4.772 ( 2.629)	Data  4.610 ( 2.413)	Loss 3.9282e-01 (3.2285e-01) 
2023-05-27 03:32:19.718939: val Epoch: [0][45/72]	Time  0.265 ( 2.578)	Data  0.000 ( 2.360)	Loss 3.1884e-01 (3.2276e-01) 
2023-05-27 03:32:24.665436: val Epoch: [0][46/72]	Time  4.947 ( 2.628)	Data  4.685 ( 2.410)	Loss 2.2349e-01 (3.2065e-01) 
2023-05-27 03:32:24.918653: val Epoch: [0][47/72]	Time  0.253 ( 2.579)	Data  0.000 ( 2.360)	Loss 4.5505e-01 (3.2345e-01) 
2023-05-27 03:32:29.844387: val Epoch: [0][48/72]	Time  4.926 ( 2.627)	Data  4.736 ( 2.408)	Loss 1.9148e-01 (3.2076e-01) 
2023-05-27 03:32:30.169886: val Epoch: [0][49/72]	Time  0.326 ( 2.580)	Data  0.001 ( 2.360)	Loss 2.2860e-01 (3.1892e-01) 
2023-05-27 03:32:35.035521: val Epoch: [0][50/72]	Time  4.866 ( 2.625)	Data  4.706 ( 2.406)	Loss 2.9142e-01 (3.1838e-01) 
2023-05-27 03:32:35.292828: val Epoch: [0][51/72]	Time  0.257 ( 2.580)	Data  0.001 ( 2.360)	Loss 3.4579e-01 (3.1890e-01) 
2023-05-27 03:32:40.183631: val Epoch: [0][52/72]	Time  4.891 ( 2.623)	Data  4.746 ( 2.405)	Loss 2.5827e-01 (3.1776e-01) 
2023-05-27 03:32:40.336554: val Epoch: [0][53/72]	Time  0.153 ( 2.578)	Data  0.001 ( 2.360)	Loss 1.7972e-01 (3.1520e-01) 
2023-05-27 03:32:45.312525: val Epoch: [0][54/72]	Time  4.976 ( 2.621)	Data  4.797 ( 2.404)	Loss 3.3969e-01 (3.1565e-01) 
2023-05-27 03:32:45.583773: val Epoch: [0][55/72]	Time  0.271 ( 2.579)	Data  0.001 ( 2.362)	Loss 2.5466e-01 (3.1456e-01) 
2023-05-27 03:32:50.657093: val Epoch: [0][56/72]	Time  5.073 ( 2.623)	Data  4.894 ( 2.406)	Loss 3.2162e-01 (3.1468e-01) 
2023-05-27 03:32:50.960229: val Epoch: [0][57/72]	Time  0.303 ( 2.583)	Data  0.001 ( 2.364)	Loss 1.8229e-01 (3.1240e-01) 
2023-05-27 03:32:55.677839: val Epoch: [0][58/72]	Time  4.718 ( 2.619)	Data  4.549 ( 2.402)	Loss 1.6969e-01 (3.0998e-01) 
2023-05-27 03:32:55.923388: val Epoch: [0][59/72]	Time  0.246 ( 2.580)	Data  0.000 ( 2.361)	Loss 2.3351e-01 (3.0871e-01) 
2023-05-27 03:33:01.050934: val Epoch: [0][60/72]	Time  5.128 ( 2.621)	Data  4.889 ( 2.403)	Loss 2.4384e-01 (3.0764e-01) 
2023-05-27 03:33:01.242259: val Epoch: [0][61/72]	Time  0.191 ( 2.582)	Data  0.001 ( 2.364)	Loss 6.2121e-01 (3.1270e-01) 
2023-05-27 03:33:06.140924: val Epoch: [0][62/72]	Time  4.899 ( 2.619)	Data  4.728 ( 2.402)	Loss 2.0734e-01 (3.1103e-01) 
2023-05-27 03:33:06.380564: val Epoch: [0][63/72]	Time  0.240 ( 2.582)	Data  0.000 ( 2.364)	Loss 1.9737e-01 (3.0925e-01) 
2023-05-27 03:33:11.306248: val Epoch: [0][64/72]	Time  4.926 ( 2.618)	Data  4.701 ( 2.400)	Loss 5.3444e-01 (3.1272e-01) 
2023-05-27 03:33:11.546946: val Epoch: [0][65/72]	Time  0.241 ( 2.582)	Data  0.001 ( 2.364)	Loss 4.6571e-01 (3.1504e-01) 
2023-05-27 03:33:16.122301: val Epoch: [0][66/72]	Time  4.575 ( 2.612)	Data  4.357 ( 2.394)	Loss 1.7770e-01 (3.1299e-01) 
2023-05-27 03:33:16.403615: val Epoch: [0][67/72]	Time  0.281 ( 2.577)	Data  0.001 ( 2.358)	Loss 2.6706e-01 (3.1231e-01) 
2023-05-27 03:33:21.341890: val Epoch: [0][68/72]	Time  4.938 ( 2.612)	Data  4.717 ( 2.393)	Loss 3.1936e-01 (3.1241e-01) 
2023-05-27 03:33:21.615062: val Epoch: [0][69/72]	Time  0.273 ( 2.578)	Data  0.001 ( 2.358)	Loss 2.7906e-01 (3.1194e-01) 
2023-05-27 03:33:26.184026: val Epoch: [0][70/72]	Time  4.569 ( 2.606)	Data  4.406 ( 2.387)	Loss 1.9533e-01 (3.1029e-01) 
2023-05-27 03:33:26.450116: val Epoch: [0][71/72]	Time  0.266 ( 2.574)	Data  0.000 ( 2.354)	Loss 4.7577e-01 (3.1259e-01) 
2023-05-27 03:33:26.759282: Epoch 0 :Val : ['ET : 0.47360122203826904', 'TC : 0.5364977121353149', 'WT : 0.6567032337188721'] 
2023-05-27 03:33:26.764388: Epoch 0 :Val : ['ET : 0.47360122203826904', 'TC : 0.5364977121353149', 'WT : 0.6567032337188721'] 
2023-05-27 03:33:26.768365: Saving the model with DSC 0.5498034358024597 
2023-05-27 03:33:27.350878: Val epoch done in 186.9252281980007 s 
2023-05-27 03:33:27.358571: Batches per epoch:  193 
2023-05-27 03:33:38.411204: train Epoch: [1][  0/193]	Time 11.052 (11.052)	Data 10.176 (10.176)	Loss 2.3650e-01 (2.3650e-01) 
2023-05-27 03:33:39.311243: train Epoch: [1][  1/193]	Time  0.900 ( 5.976)	Data  0.001 ( 5.088)	Loss 2.3337e-01 (2.3494e-01) 
2023-05-27 03:33:48.273830: train Epoch: [1][  2/193]	Time  8.963 ( 6.972)	Data  8.001 ( 6.059)	Loss 2.5072e-01 (2.4020e-01) 
2023-05-27 03:33:49.242816: train Epoch: [1][  3/193]	Time  0.969 ( 5.471)	Data  0.001 ( 4.545)	Loss 2.6389e-01 (2.4612e-01) 
2023-05-27 03:33:58.874079: train Epoch: [1][  4/193]	Time  9.631 ( 6.303)	Data  8.722 ( 5.380)	Loss 2.2843e-01 (2.4258e-01) 
2023-05-27 03:33:59.840970: train Epoch: [1][  5/193]	Time  0.967 ( 5.414)	Data  0.001 ( 4.484)	Loss 4.2813e-01 (2.7351e-01) 
2023-05-27 03:34:08.725256: train Epoch: [1][  6/193]	Time  8.884 ( 5.909)	Data  7.931 ( 4.976)	Loss 1.8857e-01 (2.6137e-01) 
2023-05-27 03:34:09.610497: train Epoch: [1][  7/193]	Time  0.885 ( 5.281)	Data  0.001 ( 4.354)	Loss 2.2639e-01 (2.5700e-01) 
2023-05-27 03:34:18.680408: train Epoch: [1][  8/193]	Time  9.070 ( 5.702)	Data  8.215 ( 4.783)	Loss 1.4085e-01 (2.4409e-01) 
2023-05-27 03:34:19.669271: train Epoch: [1][  9/193]	Time  0.989 ( 5.231)	Data  0.001 ( 4.305)	Loss 3.2658e-01 (2.5234e-01) 
2023-05-27 03:34:29.486302: train Epoch: [1][ 10/193]	Time  9.817 ( 5.648)	Data  8.743 ( 4.708)	Loss 1.9205e-01 (2.4686e-01) 
2023-05-27 03:34:30.482301: train Epoch: [1][ 11/193]	Time  0.996 ( 5.260)	Data  0.001 ( 4.316)	Loss 2.1748e-01 (2.4441e-01) 
2023-05-27 03:34:39.350421: train Epoch: [1][ 12/193]	Time  8.868 ( 5.538)	Data  7.981 ( 4.598)	Loss 2.2727e-01 (2.4309e-01) 
2023-05-27 03:34:40.240209: train Epoch: [1][ 13/193]	Time  0.890 ( 5.206)	Data  0.001 ( 4.270)	Loss 2.6144e-01 (2.4440e-01) 
2023-05-27 03:34:49.682650: train Epoch: [1][ 14/193]	Time  9.442 ( 5.488)	Data  8.602 ( 4.558)	Loss 2.7490e-01 (2.4644e-01) 
2023-05-27 03:34:50.642013: train Epoch: [1][ 15/193]	Time  0.959 ( 5.205)	Data  0.001 ( 4.274)	Loss 2.2249e-01 (2.4494e-01) 
2023-05-27 03:35:00.151536: train Epoch: [1][ 16/193]	Time  9.510 ( 5.458)	Data  8.699 ( 4.534)	Loss 2.3095e-01 (2.4412e-01) 
2023-05-27 03:35:01.063518: train Epoch: [1][ 17/193]	Time  0.912 ( 5.206)	Data  0.001 ( 4.282)	Loss 1.9770e-01 (2.4154e-01) 
2023-05-27 03:35:10.124708: train Epoch: [1][ 18/193]	Time  9.061 ( 5.409)	Data  8.244 ( 4.491)	Loss 1.6174e-01 (2.3734e-01) 
2023-05-27 03:35:11.041418: train Epoch: [1][ 19/193]	Time  0.917 ( 5.184)	Data  0.001 ( 4.266)	Loss 3.5707e-01 (2.4333e-01) 
2023-05-27 03:35:20.213130: train Epoch: [1][ 20/193]	Time  9.172 ( 5.374)	Data  8.270 ( 4.457)	Loss 1.6762e-01 (2.3972e-01) 
2023-05-27 03:35:21.118896: train Epoch: [1][ 21/193]	Time  0.906 ( 5.171)	Data  0.001 ( 4.254)	Loss 2.3059e-01 (2.3931e-01) 
2023-05-27 03:35:30.381790: train Epoch: [1][ 22/193]	Time  9.263 ( 5.349)	Data  8.345 ( 4.432)	Loss 2.0331e-01 (2.3774e-01) 
2023-05-27 03:35:31.399874: train Epoch: [1][ 23/193]	Time  1.018 ( 5.168)	Data  0.001 ( 4.247)	Loss 2.1044e-01 (2.3660e-01) 
2023-05-27 03:35:40.645096: train Epoch: [1][ 24/193]	Time  9.245 ( 5.331)	Data  8.375 ( 4.413)	Loss 1.8950e-01 (2.3472e-01) 
2023-05-27 03:35:41.649263: train Epoch: [1][ 25/193]	Time  1.004 ( 5.165)	Data  0.001 ( 4.243)	Loss 4.3195e-01 (2.4231e-01) 
2023-05-27 03:35:50.663754: train Epoch: [1][ 26/193]	Time  9.014 ( 5.308)	Data  8.104 ( 4.386)	Loss 6.0389e-01 (2.5570e-01) 
2023-05-27 03:35:51.668575: train Epoch: [1][ 27/193]	Time  1.005 ( 5.154)	Data  0.001 ( 4.229)	Loss 3.0012e-01 (2.5728e-01) 
2023-05-27 03:36:00.874418: train Epoch: [1][ 28/193]	Time  9.206 ( 5.294)	Data  8.233 ( 4.367)	Loss 4.9811e-01 (2.6559e-01) 
2023-05-27 03:36:01.902133: train Epoch: [1][ 29/193]	Time  1.028 ( 5.151)	Data  0.001 ( 4.222)	Loss 2.5908e-01 (2.6537e-01) 
2023-05-27 03:36:10.982633: train Epoch: [1][ 30/193]	Time  9.081 ( 5.278)	Data  8.160 ( 4.349)	Loss 2.1267e-01 (2.6367e-01) 
2023-05-27 03:36:12.020592: train Epoch: [1][ 31/193]	Time  1.038 ( 5.146)	Data  0.001 ( 4.213)	Loss 1.6812e-01 (2.6069e-01) 
2023-05-27 03:36:21.232179: train Epoch: [1][ 32/193]	Time  9.212 ( 5.269)	Data  8.257 ( 4.336)	Loss 2.3671e-01 (2.5996e-01) 
2023-05-27 03:36:22.138762: train Epoch: [1][ 33/193]	Time  0.907 ( 5.141)	Data  0.001 ( 4.208)	Loss 2.4084e-01 (2.5940e-01) 
2023-05-27 03:36:30.077002: train Epoch: [1][ 34/193]	Time  7.938 ( 5.221)	Data  7.038 ( 4.289)	Loss 5.8623e-01 (2.6873e-01) 
2023-05-27 03:36:30.994608: train Epoch: [1][ 35/193]	Time  0.918 ( 5.101)	Data  0.001 ( 4.170)	Loss 2.1694e-01 (2.6730e-01) 
2023-05-27 03:36:40.088019: train Epoch: [1][ 36/193]	Time  9.093 ( 5.209)	Data  8.347 ( 4.283)	Loss 1.7102e-01 (2.6469e-01) 
2023-05-27 03:36:40.903953: train Epoch: [1][ 37/193]	Time  0.816 ( 5.093)	Data  0.001 ( 4.170)	Loss 2.9111e-01 (2.6539e-01) 
2023-05-27 03:36:50.269220: train Epoch: [1][ 38/193]	Time  9.365 ( 5.203)	Data  8.549 ( 4.282)	Loss 5.8764e-01 (2.7365e-01) 
2023-05-27 03:36:51.083248: train Epoch: [1][ 39/193]	Time  0.814 ( 5.093)	Data  0.001 ( 4.175)	Loss 2.4230e-01 (2.7287e-01) 
2023-05-27 03:36:59.880668: train Epoch: [1][ 40/193]	Time  8.797 ( 5.183)	Data  8.218 ( 4.274)	Loss 2.1347e-01 (2.7142e-01) 
2023-05-27 03:37:00.449906: train Epoch: [1][ 41/193]	Time  0.569 ( 5.074)	Data  0.001 ( 4.172)	Loss 2.0372e-01 (2.6981e-01) 
2023-05-27 03:37:09.778990: train Epoch: [1][ 42/193]	Time  9.329 ( 5.173)	Data  8.750 ( 4.279)	Loss 1.9667e-01 (2.6811e-01) 
2023-05-27 03:37:10.350194: train Epoch: [1][ 43/193]	Time  0.571 ( 5.068)	Data  0.001 ( 4.181)	Loss 2.5310e-01 (2.6777e-01) 
2023-05-27 03:37:20.132200: train Epoch: [1][ 44/193]	Time  9.782 ( 5.173)	Data  8.922 ( 4.287)	Loss 1.7096e-01 (2.6561e-01) 
2023-05-27 03:37:21.071702: train Epoch: [1][ 45/193]	Time  0.939 ( 5.081)	Data  0.001 ( 4.193)	Loss 2.9087e-01 (2.6616e-01) 
2023-05-27 03:37:30.020821: train Epoch: [1][ 46/193]	Time  8.949 ( 5.163)	Data  7.997 ( 4.274)	Loss 3.6938e-01 (2.6836e-01) 
2023-05-27 03:37:30.975975: train Epoch: [1][ 47/193]	Time  0.955 ( 5.075)	Data  0.001 ( 4.185)	Loss 1.8909e-01 (2.6671e-01) 
2023-05-27 03:37:40.134366: train Epoch: [1][ 48/193]	Time  9.158 ( 5.159)	Data  8.227 ( 4.268)	Loss 2.0336e-01 (2.6541e-01) 
2023-05-27 03:37:41.037792: train Epoch: [1][ 49/193]	Time  0.903 ( 5.074)	Data  0.001 ( 4.182)	Loss 3.1698e-01 (2.6645e-01) 
2023-05-27 03:37:50.247811: train Epoch: [1][ 50/193]	Time  9.210 ( 5.155)	Data  8.411 ( 4.265)	Loss 2.6481e-01 (2.6641e-01) 
2023-05-27 03:37:51.116940: train Epoch: [1][ 51/193]	Time  0.869 ( 5.072)	Data  0.001 ( 4.183)	Loss 3.3104e-01 (2.6766e-01) 
2023-05-27 03:38:00.699040: train Epoch: [1][ 52/193]	Time  9.582 ( 5.157)	Data  8.567 ( 4.266)	Loss 2.1781e-01 (2.6672e-01) 
2023-05-27 03:38:01.678464: train Epoch: [1][ 53/193]	Time  0.979 ( 5.080)	Data  0.001 ( 4.187)	Loss 3.3448e-01 (2.6797e-01) 
2023-05-27 03:38:10.731245: train Epoch: [1][ 54/193]	Time  9.053 ( 5.152)	Data  8.188 ( 4.260)	Loss 1.6791e-01 (2.6615e-01) 
2023-05-27 03:38:11.606691: train Epoch: [1][ 55/193]	Time  0.875 ( 5.076)	Data  0.001 ( 4.184)	Loss 1.6261e-01 (2.6430e-01) 
2023-05-27 03:38:21.209835: train Epoch: [1][ 56/193]	Time  9.603 ( 5.155)	Data  8.639 ( 4.262)	Loss 4.4824e-01 (2.6753e-01) 
2023-05-27 03:38:22.234965: train Epoch: [1][ 57/193]	Time  1.025 ( 5.084)	Data  0.001 ( 4.189)	Loss 2.4444e-01 (2.6713e-01) 
2023-05-27 03:38:31.283599: train Epoch: [1][ 58/193]	Time  9.049 ( 5.151)	Data  8.098 ( 4.255)	Loss 2.5319e-01 (2.6690e-01) 
2023-05-27 03:38:32.328178: train Epoch: [1][ 59/193]	Time  1.045 ( 5.083)	Data  0.001 ( 4.184)	Loss 2.2760e-01 (2.6624e-01) 
2023-05-27 03:38:41.738702: train Epoch: [1][ 60/193]	Time  9.411 ( 5.154)	Data  8.456 ( 4.254)	Loss 1.6489e-01 (2.6458e-01) 
2023-05-27 03:38:42.573053: train Epoch: [1][ 61/193]	Time  0.834 ( 5.084)	Data  0.001 ( 4.185)	Loss 1.2861e-01 (2.6239e-01) 
2023-05-27 03:38:51.637647: train Epoch: [1][ 62/193]	Time  9.065 ( 5.147)	Data  8.159 ( 4.248)	Loss 3.0794e-01 (2.6311e-01) 
2023-05-27 03:38:52.669767: train Epoch: [1][ 63/193]	Time  1.032 ( 5.083)	Data  0.001 ( 4.182)	Loss 1.4444e-01 (2.6125e-01) 
2023-05-27 03:39:01.395427: train Epoch: [1][ 64/193]	Time  8.726 ( 5.139)	Data  7.824 ( 4.238)	Loss 2.7438e-01 (2.6146e-01) 
2023-05-27 03:39:02.325109: train Epoch: [1][ 65/193]	Time  0.930 ( 5.075)	Data  0.001 ( 4.174)	Loss 3.0570e-01 (2.6213e-01) 
2023-05-27 03:39:11.745997: train Epoch: [1][ 66/193]	Time  9.421 ( 5.140)	Data  8.424 ( 4.237)	Loss 3.6880e-01 (2.6372e-01) 
2023-05-27 03:39:12.660126: train Epoch: [1][ 67/193]	Time  0.914 ( 5.078)	Data  0.001 ( 4.175)	Loss 3.8267e-01 (2.6547e-01) 
2023-05-27 03:39:21.476419: train Epoch: [1][ 68/193]	Time  8.816 ( 5.132)	Data  7.910 ( 4.229)	Loss 2.8858e-01 (2.6580e-01) 
2023-05-27 03:39:22.472192: train Epoch: [1][ 69/193]	Time  0.996 ( 5.073)	Data  0.001 ( 4.169)	Loss 3.0420e-01 (2.6635e-01) 
2023-05-27 03:39:31.266989: train Epoch: [1][ 70/193]	Time  8.795 ( 5.125)	Data  7.932 ( 4.222)	Loss 2.1014e-01 (2.6556e-01) 
2023-05-27 03:39:32.194806: train Epoch: [1][ 71/193]	Time  0.928 ( 5.067)	Data  0.001 ( 4.163)	Loss 2.7670e-01 (2.6571e-01) 
2023-05-27 03:39:41.213135: train Epoch: [1][ 72/193]	Time  9.018 ( 5.121)	Data  8.223 ( 4.219)	Loss 2.0091e-01 (2.6483e-01) 
2023-05-27 03:39:42.161779: train Epoch: [1][ 73/193]	Time  0.949 ( 5.065)	Data  0.001 ( 4.162)	Loss 1.2313e-01 (2.6291e-01) 
2023-05-27 03:39:50.304720: train Epoch: [1][ 74/193]	Time  8.143 ( 5.106)	Data  7.270 ( 4.203)	Loss 3.3761e-01 (2.6391e-01) 
2023-05-27 03:39:51.335046: train Epoch: [1][ 75/193]	Time  1.030 ( 5.052)	Data  0.001 ( 4.148)	Loss 2.2816e-01 (2.6344e-01) 
2023-05-27 03:40:00.299482: train Epoch: [1][ 76/193]	Time  8.964 ( 5.103)	Data  7.958 ( 4.197)	Loss 3.3816e-01 (2.6441e-01) 
2023-05-27 03:40:01.382203: train Epoch: [1][ 77/193]	Time  1.083 ( 5.052)	Data  0.001 ( 4.144)	Loss 1.7870e-01 (2.6331e-01) 
2023-05-27 03:40:10.135563: train Epoch: [1][ 78/193]	Time  8.753 ( 5.098)	Data  7.866 ( 4.191)	Loss 2.4870e-01 (2.6312e-01) 
2023-05-27 03:40:11.010465: train Epoch: [1][ 79/193]	Time  0.875 ( 5.046)	Data  0.001 ( 4.138)	Loss 1.8020e-01 (2.6209e-01) 
2023-05-27 03:40:20.658285: train Epoch: [1][ 80/193]	Time  9.648 ( 5.102)	Data  8.760 ( 4.195)	Loss 1.9396e-01 (2.6125e-01) 
2023-05-27 03:40:21.703265: train Epoch: [1][ 81/193]	Time  1.045 ( 5.053)	Data  0.001 ( 4.144)	Loss 2.5448e-01 (2.6116e-01) 
2023-05-27 03:40:30.879551: train Epoch: [1][ 82/193]	Time  9.176 ( 5.103)	Data  8.215 ( 4.193)	Loss 1.9607e-01 (2.6038e-01) 
2023-05-27 03:40:31.760812: train Epoch: [1][ 83/193]	Time  0.881 ( 5.052)	Data  0.001 ( 4.143)	Loss 2.1069e-01 (2.5979e-01) 
2023-05-27 03:40:40.984857: train Epoch: [1][ 84/193]	Time  9.224 ( 5.101)	Data  8.348 ( 4.193)	Loss 1.8019e-01 (2.5885e-01) 
2023-05-27 03:40:42.088923: train Epoch: [1][ 85/193]	Time  1.104 ( 5.055)	Data  0.001 ( 4.144)	Loss 2.2429e-01 (2.5845e-01) 
2023-05-27 03:40:51.311727: train Epoch: [1][ 86/193]	Time  9.223 ( 5.103)	Data  8.413 ( 4.193)	Loss 1.7269e-01 (2.5746e-01) 
2023-05-27 03:40:52.115417: train Epoch: [1][ 87/193]	Time  0.804 ( 5.054)	Data  0.001 ( 4.145)	Loss 1.5775e-01 (2.5633e-01) 
2023-05-27 03:41:01.947257: train Epoch: [1][ 88/193]	Time  9.832 ( 5.108)	Data  8.899 ( 4.199)	Loss 2.4878e-01 (2.5625e-01) 
2023-05-27 03:41:02.968543: train Epoch: [1][ 89/193]	Time  1.021 ( 5.062)	Data  0.001 ( 4.152)	Loss 2.5270e-01 (2.5621e-01) 
2023-05-27 03:41:12.206368: train Epoch: [1][ 90/193]	Time  9.238 ( 5.108)	Data  8.427 ( 4.199)	Loss 2.9918e-01 (2.5668e-01) 
2023-05-27 03:41:12.999167: train Epoch: [1][ 91/193]	Time  0.793 ( 5.061)	Data  0.001 ( 4.154)	Loss 3.6706e-01 (2.5788e-01) 
2023-05-27 03:41:22.442235: train Epoch: [1][ 92/193]	Time  9.443 ( 5.108)	Data  8.529 ( 4.201)	Loss 2.5597e-01 (2.5786e-01) 
2023-05-27 03:41:23.284711: train Epoch: [1][ 93/193]	Time  0.842 ( 5.063)	Data  0.001 ( 4.156)	Loss 3.4165e-01 (2.5875e-01) 
2023-05-27 03:41:32.517018: train Epoch: [1][ 94/193]	Time  9.232 ( 5.107)	Data  8.363 ( 4.200)	Loss 2.4554e-01 (2.5861e-01) 
2023-05-27 03:41:33.425390: train Epoch: [1][ 95/193]	Time  0.908 ( 5.063)	Data  0.001 ( 4.156)	Loss 2.0729e-01 (2.5808e-01) 
2023-05-27 03:41:43.194872: train Epoch: [1][ 96/193]	Time  9.769 ( 5.112)	Data  8.743 ( 4.204)	Loss 3.5073e-01 (2.5903e-01) 
2023-05-27 03:41:44.111877: train Epoch: [1][ 97/193]	Time  0.917 ( 5.069)	Data  0.001 ( 4.161)	Loss 1.7939e-01 (2.5822e-01) 
2023-05-27 03:41:53.254719: train Epoch: [1][ 98/193]	Time  9.143 ( 5.110)	Data  8.271 ( 4.202)	Loss 2.7441e-01 (2.5838e-01) 
2023-05-27 03:41:54.092351: train Epoch: [1][ 99/193]	Time  0.838 ( 5.067)	Data  0.001 ( 4.160)	Loss 2.8669e-01 (2.5867e-01) 
2023-05-27 03:42:03.805927: train Epoch: [1][100/193]	Time  9.714 ( 5.113)	Data  8.782 ( 4.206)	Loss 2.1257e-01 (2.5821e-01) 
2023-05-27 03:42:04.642503: train Epoch: [1][101/193]	Time  0.837 ( 5.071)	Data  0.001 ( 4.165)	Loss 2.2932e-01 (2.5793e-01) 
2023-05-27 03:42:13.190160: train Epoch: [1][102/193]	Time  8.548 ( 5.105)	Data  7.618 ( 4.198)	Loss 3.0509e-01 (2.5838e-01) 
2023-05-27 03:42:14.012634: train Epoch: [1][103/193]	Time  0.822 ( 5.064)	Data  0.001 ( 4.158)	Loss 2.2927e-01 (2.5810e-01) 
2023-05-27 03:42:22.117423: train Epoch: [1][104/193]	Time  8.105 ( 5.093)	Data  7.120 ( 4.186)	Loss 2.2304e-01 (2.5777e-01) 
2023-05-27 03:42:23.056753: train Epoch: [1][105/193]	Time  0.939 ( 5.054)	Data  0.001 ( 4.147)	Loss 4.6194e-01 (2.5970e-01) 
2023-05-27 03:42:31.417254: train Epoch: [1][106/193]	Time  8.360 ( 5.085)	Data  7.276 ( 4.176)	Loss 1.4102e-01 (2.5859e-01) 
2023-05-27 03:42:32.432615: train Epoch: [1][107/193]	Time  1.015 ( 5.047)	Data  0.001 ( 4.137)	Loss 1.3516e-01 (2.5744e-01) 
2023-05-27 03:42:41.500681: train Epoch: [1][108/193]	Time  9.068 ( 5.084)	Data  8.146 ( 4.174)	Loss 1.5809e-01 (2.5653e-01) 
2023-05-27 03:42:42.441846: train Epoch: [1][109/193]	Time  0.941 ( 5.046)	Data  0.001 ( 4.136)	Loss 1.4984e-01 (2.5556e-01) 
2023-05-27 03:42:51.464427: train Epoch: [1][110/193]	Time  9.023 ( 5.082)	Data  8.084 ( 4.172)	Loss 4.2804e-01 (2.5712e-01) 
2023-05-27 03:42:52.381541: train Epoch: [1][111/193]	Time  0.917 ( 5.045)	Data  0.001 ( 4.135)	Loss 2.3587e-01 (2.5693e-01) 
2023-05-27 03:43:01.585513: train Epoch: [1][112/193]	Time  9.204 ( 5.082)	Data  8.324 ( 4.172)	Loss 3.0990e-01 (2.5740e-01) 
2023-05-27 03:43:02.536987: train Epoch: [1][113/193]	Time  0.951 ( 5.045)	Data  0.001 ( 4.135)	Loss 2.4159e-01 (2.5726e-01) 
2023-05-27 03:43:11.299007: train Epoch: [1][114/193]	Time  8.762 ( 5.078)	Data  7.939 ( 4.168)	Loss 1.8010e-01 (2.5659e-01) 
2023-05-27 03:43:12.269526: train Epoch: [1][115/193]	Time  0.971 ( 5.042)	Data  0.001 ( 4.132)	Loss 2.9572e-01 (2.5692e-01) 
2023-05-27 03:43:21.518931: train Epoch: [1][116/193]	Time  9.249 ( 5.078)	Data  8.409 ( 4.169)	Loss 3.2882e-01 (2.5754e-01) 
2023-05-27 03:43:22.389251: train Epoch: [1][117/193]	Time  0.870 ( 5.043)	Data  0.001 ( 4.133)	Loss 4.5557e-01 (2.5922e-01) 
2023-05-27 03:43:31.756424: train Epoch: [1][118/193]	Time  9.367 ( 5.079)	Data  8.416 ( 4.169)	Loss 1.3675e-01 (2.5819e-01) 
2023-05-27 03:43:32.674112: train Epoch: [1][119/193]	Time  0.918 ( 5.044)	Data  0.001 ( 4.135)	Loss 1.7369e-01 (2.5748e-01) 
2023-05-27 03:43:41.904234: train Epoch: [1][120/193]	Time  9.230 ( 5.079)	Data  8.312 ( 4.169)	Loss 2.6750e-01 (2.5757e-01) 
2023-05-27 03:43:42.910309: train Epoch: [1][121/193]	Time  1.006 ( 5.045)	Data  0.001 ( 4.135)	Loss 2.9541e-01 (2.5788e-01) 
2023-05-27 03:43:52.027676: train Epoch: [1][122/193]	Time  9.117 ( 5.079)	Data  8.196 ( 4.168)	Loss 2.5594e-01 (2.5786e-01) 
2023-05-27 03:43:52.960220: train Epoch: [1][123/193]	Time  0.933 ( 5.045)	Data  0.001 ( 4.134)	Loss 2.0877e-01 (2.5746e-01) 
2023-05-27 03:44:02.277909: train Epoch: [1][124/193]	Time  9.318 ( 5.079)	Data  8.445 ( 4.169)	Loss 2.5619e-01 (2.5745e-01) 
2023-05-27 03:44:03.201513: train Epoch: [1][125/193]	Time  0.924 ( 5.046)	Data  0.001 ( 4.136)	Loss 2.6329e-01 (2.5750e-01) 
2023-05-27 03:44:12.392182: train Epoch: [1][126/193]	Time  9.191 ( 5.079)	Data  8.314 ( 4.169)	Loss 1.9931e-01 (2.5704e-01) 
2023-05-27 03:44:13.353497: train Epoch: [1][127/193]	Time  0.961 ( 5.047)	Data  0.001 ( 4.136)	Loss 2.4817e-01 (2.5697e-01) 
2023-05-27 03:44:22.794260: train Epoch: [1][128/193]	Time  9.441 ( 5.081)	Data  8.483 ( 4.170)	Loss 2.4769e-01 (2.5690e-01) 
2023-05-27 03:44:23.740039: train Epoch: [1][129/193]	Time  0.946 ( 5.049)	Data  0.001 ( 4.138)	Loss 5.2784e-01 (2.5899e-01) 
2023-05-27 03:44:33.445913: train Epoch: [1][130/193]	Time  9.706 ( 5.085)	Data  8.841 ( 4.174)	Loss 1.8656e-01 (2.5843e-01) 
2023-05-27 03:44:34.373867: train Epoch: [1][131/193]	Time  0.928 ( 5.053)	Data  0.001 ( 4.142)	Loss 2.2253e-01 (2.5816e-01) 
2023-05-27 03:44:43.453444: train Epoch: [1][132/193]	Time  9.080 ( 5.083)	Data  7.921 ( 4.171)	Loss 2.9158e-01 (2.5841e-01) 
2023-05-27 03:44:44.462678: train Epoch: [1][133/193]	Time  1.009 ( 5.053)	Data  0.001 ( 4.139)	Loss 2.1783e-01 (2.5811e-01) 
2023-05-27 03:44:53.712662: train Epoch: [1][134/193]	Time  9.250 ( 5.084)	Data  8.320 ( 4.170)	Loss 1.9064e-01 (2.5761e-01) 
2023-05-27 03:44:54.723111: train Epoch: [1][135/193]	Time  1.010 ( 5.054)	Data  0.001 ( 4.140)	Loss 1.2230e-01 (2.5661e-01) 
2023-05-27 03:45:03.442982: train Epoch: [1][136/193]	Time  8.720 ( 5.081)	Data  7.882 ( 4.167)	Loss 2.1481e-01 (2.5631e-01) 
2023-05-27 03:45:04.380258: train Epoch: [1][137/193]	Time  0.937 ( 5.051)	Data  0.001 ( 4.137)	Loss 2.2601e-01 (2.5609e-01) 
2023-05-27 03:45:13.553586: train Epoch: [1][138/193]	Time  9.173 ( 5.081)	Data  8.174 ( 4.166)	Loss 1.6399e-01 (2.5543e-01) 
2023-05-27 03:45:14.493073: train Epoch: [1][139/193]	Time  0.939 ( 5.051)	Data  0.001 ( 4.136)	Loss 3.4072e-01 (2.5604e-01) 
2023-05-27 03:45:23.385347: train Epoch: [1][140/193]	Time  8.892 ( 5.078)	Data  7.948 ( 4.163)	Loss 2.7441e-01 (2.5617e-01) 
2023-05-27 03:45:24.350801: train Epoch: [1][141/193]	Time  0.965 ( 5.049)	Data  0.001 ( 4.134)	Loss 3.6680e-01 (2.5695e-01) 
2023-05-27 03:45:33.004401: train Epoch: [1][142/193]	Time  8.654 ( 5.074)	Data  7.830 ( 4.160)	Loss 2.9877e-01 (2.5724e-01) 
2023-05-27 03:45:33.902121: train Epoch: [1][143/193]	Time  0.898 ( 5.045)	Data  0.001 ( 4.131)	Loss 4.8178e-01 (2.5880e-01) 
2023-05-27 03:45:43.576791: train Epoch: [1][144/193]	Time  9.675 ( 5.077)	Data  8.729 ( 4.163)	Loss 2.8965e-01 (2.5901e-01) 
2023-05-27 03:45:44.449267: train Epoch: [1][145/193]	Time  0.872 ( 5.049)	Data  0.001 ( 4.134)	Loss 1.9715e-01 (2.5859e-01) 
2023-05-27 03:45:53.210778: train Epoch: [1][146/193]	Time  8.761 ( 5.074)	Data  7.764 ( 4.159)	Loss 2.0706e-01 (2.5824e-01) 
2023-05-27 03:45:54.079870: train Epoch: [1][147/193]	Time  0.869 ( 5.045)	Data  0.001 ( 4.131)	Loss 4.7909e-01 (2.5973e-01) 
2023-05-27 03:46:03.764731: train Epoch: [1][148/193]	Time  9.685 ( 5.077)	Data  8.757 ( 4.162)	Loss 1.7295e-01 (2.5915e-01) 
2023-05-27 03:46:04.565030: train Epoch: [1][149/193]	Time  0.800 ( 5.048)	Data  0.001 ( 4.134)	Loss 3.1773e-01 (2.5954e-01) 
2023-05-27 03:46:13.739340: train Epoch: [1][150/193]	Time  9.174 ( 5.075)	Data  8.328 ( 4.162)	Loss 3.5943e-01 (2.6020e-01) 
2023-05-27 03:46:14.691839: train Epoch: [1][151/193]	Time  0.952 ( 5.048)	Data  0.001 ( 4.134)	Loss 2.9917e-01 (2.6045e-01) 
2023-05-27 03:46:23.842562: train Epoch: [1][152/193]	Time  9.151 ( 5.075)	Data  8.226 ( 4.161)	Loss 2.8053e-01 (2.6059e-01) 
2023-05-27 03:46:24.797934: train Epoch: [1][153/193]	Time  0.955 ( 5.048)	Data  0.001 ( 4.134)	Loss 3.1225e-01 (2.6092e-01) 
2023-05-27 03:46:34.456299: train Epoch: [1][154/193]	Time  9.658 ( 5.078)	Data  8.759 ( 4.164)	Loss 2.5175e-01 (2.6086e-01) 
2023-05-27 03:46:35.436102: train Epoch: [1][155/193]	Time  0.980 ( 5.052)	Data  0.001 ( 4.137)	Loss 2.0393e-01 (2.6050e-01) 
2023-05-27 03:46:44.848641: train Epoch: [1][156/193]	Time  9.413 ( 5.080)	Data  8.528 ( 4.165)	Loss 3.0472e-01 (2.6078e-01) 
2023-05-27 03:46:45.781268: train Epoch: [1][157/193]	Time  0.933 ( 5.053)	Data  0.001 ( 4.139)	Loss 3.4243e-01 (2.6130e-01) 
2023-05-27 03:46:55.291599: train Epoch: [1][158/193]	Time  9.510 ( 5.081)	Data  8.622 ( 4.167)	Loss 1.9436e-01 (2.6087e-01) 
2023-05-27 03:46:56.220976: train Epoch: [1][159/193]	Time  0.929 ( 5.055)	Data  0.001 ( 4.141)	Loss 2.0625e-01 (2.6053e-01) 
2023-05-27 03:47:05.381322: train Epoch: [1][160/193]	Time  9.160 ( 5.081)	Data  8.139 ( 4.166)	Loss 1.5698e-01 (2.5989e-01) 
2023-05-27 03:47:06.441108: train Epoch: [1][161/193]	Time  1.060 ( 5.056)	Data  0.001 ( 4.140)	Loss 1.5007e-01 (2.5921e-01) 
2023-05-27 03:47:16.093733: train Epoch: [1][162/193]	Time  9.653 ( 5.084)	Data  8.705 ( 4.168)	Loss 2.9964e-01 (2.5946e-01) 
2023-05-27 03:47:17.064278: train Epoch: [1][163/193]	Time  0.971 ( 5.059)	Data  0.001 ( 4.143)	Loss 2.3797e-01 (2.5933e-01) 
2023-05-27 03:47:26.206758: train Epoch: [1][164/193]	Time  9.142 ( 5.084)	Data  8.267 ( 4.168)	Loss 2.5589e-01 (2.5931e-01) 
2023-05-27 03:47:27.142699: train Epoch: [1][165/193]	Time  0.936 ( 5.059)	Data  0.001 ( 4.143)	Loss 2.6438e-01 (2.5934e-01) 
2023-05-27 03:47:36.101999: train Epoch: [1][166/193]	Time  8.959 ( 5.082)	Data  8.123 ( 4.166)	Loss 2.4081e-01 (2.5923e-01) 
2023-05-27 03:47:36.978882: train Epoch: [1][167/193]	Time  0.877 ( 5.057)	Data  0.001 ( 4.142)	Loss 1.9883e-01 (2.5887e-01) 
2023-05-27 03:47:45.974872: train Epoch: [1][168/193]	Time  8.996 ( 5.081)	Data  8.127 ( 4.165)	Loss 1.3084e-01 (2.5811e-01) 
2023-05-27 03:47:46.918027: train Epoch: [1][169/193]	Time  0.943 ( 5.056)	Data  0.001 ( 4.141)	Loss 1.8902e-01 (2.5770e-01) 
2023-05-27 03:47:55.886852: train Epoch: [1][170/193]	Time  8.969 ( 5.079)	Data  8.097 ( 4.164)	Loss 1.9819e-01 (2.5736e-01) 
2023-05-27 03:47:56.759523: train Epoch: [1][171/193]	Time  0.873 ( 5.055)	Data  0.001 ( 4.140)	Loss 2.0616e-01 (2.5706e-01) 
2023-05-27 03:48:06.439818: train Epoch: [1][172/193]	Time  9.680 ( 5.081)	Data  8.643 ( 4.166)	Loss 1.7848e-01 (2.5660e-01) 
2023-05-27 03:48:07.457720: train Epoch: [1][173/193]	Time  1.018 ( 5.058)	Data  0.001 ( 4.142)	Loss 3.7959e-01 (2.5731e-01) 
2023-05-27 03:48:16.582144: train Epoch: [1][174/193]	Time  9.124 ( 5.081)	Data  8.232 ( 4.165)	Loss 2.1631e-01 (2.5708e-01) 
2023-05-27 03:48:17.578377: train Epoch: [1][175/193]	Time  0.996 ( 5.058)	Data  0.001 ( 4.141)	Loss 1.4845e-01 (2.5646e-01) 
2023-05-27 03:48:26.874597: train Epoch: [1][176/193]	Time  9.296 ( 5.082)	Data  8.192 ( 4.164)	Loss 1.8927e-01 (2.5608e-01) 
2023-05-27 03:48:27.838626: train Epoch: [1][177/193]	Time  0.964 ( 5.059)	Data  0.001 ( 4.141)	Loss 1.8655e-01 (2.5569e-01) 
2023-05-27 03:48:37.233440: train Epoch: [1][178/193]	Time  9.395 ( 5.083)	Data  8.460 ( 4.165)	Loss 2.3915e-01 (2.5560e-01) 
2023-05-27 03:48:38.144200: train Epoch: [1][179/193]	Time  0.911 ( 5.060)	Data  0.001 ( 4.142)	Loss 1.8645e-01 (2.5521e-01) 
2023-05-27 03:48:47.337235: train Epoch: [1][180/193]	Time  9.193 ( 5.083)	Data  8.275 ( 4.165)	Loss 2.6384e-01 (2.5526e-01) 
2023-05-27 03:48:48.243540: train Epoch: [1][181/193]	Time  0.906 ( 5.060)	Data  0.001 ( 4.142)	Loss 3.3418e-01 (2.5569e-01) 
2023-05-27 03:48:58.054042: train Epoch: [1][182/193]	Time  9.810 ( 5.086)	Data  8.836 ( 4.168)	Loss 3.8705e-01 (2.5641e-01) 
2023-05-27 03:48:59.022641: train Epoch: [1][183/193]	Time  0.969 ( 5.063)	Data  0.001 ( 4.145)	Loss 3.1004e-01 (2.5670e-01) 
2023-05-27 03:49:07.922109: train Epoch: [1][184/193]	Time  8.899 ( 5.084)	Data  8.039 ( 4.166)	Loss 2.1526e-01 (2.5648e-01) 
2023-05-27 03:49:08.780842: train Epoch: [1][185/193]	Time  0.859 ( 5.061)	Data  0.001 ( 4.144)	Loss 1.6167e-01 (2.5597e-01) 
2023-05-27 03:49:18.291406: train Epoch: [1][186/193]	Time  9.511 ( 5.085)	Data  8.631 ( 4.168)	Loss 2.0535e-01 (2.5570e-01) 
2023-05-27 03:49:19.243511: train Epoch: [1][187/193]	Time  0.952 ( 5.063)	Data  0.001 ( 4.145)	Loss 1.8490e-01 (2.5532e-01) 
2023-05-27 03:49:28.675625: train Epoch: [1][188/193]	Time  9.432 ( 5.086)	Data  8.593 ( 4.169)	Loss 2.5064e-01 (2.5530e-01) 
2023-05-27 03:49:29.560977: train Epoch: [1][189/193]	Time  0.885 ( 5.064)	Data  0.001 ( 4.147)	Loss 2.8668e-01 (2.5546e-01) 
2023-05-27 03:49:38.740631: train Epoch: [1][190/193]	Time  9.180 ( 5.086)	Data  8.297 ( 4.169)	Loss 1.8127e-01 (2.5507e-01) 
2023-05-27 03:49:39.693777: train Epoch: [1][191/193]	Time  0.953 ( 5.064)	Data  0.001 ( 4.147)	Loss 2.0080e-01 (2.5479e-01) 
2023-05-27 03:49:47.856554: train Epoch: [1][192/193]	Time  8.163 ( 5.080)	Data  7.306 ( 4.163)	Loss 3.1204e-01 (2.5509e-01) 
2023-05-27 03:49:48.008835: Train Epoch done in 980.6503130339988 s 
2023-05-27 03:49:54.867427: val Epoch: [1][ 0/72]	Time  6.010 ( 6.010)	Data  5.653 ( 5.653)	Loss 3.0152e-01 (3.0152e-01) 
2023-05-27 03:49:55.102923: val Epoch: [1][ 1/72]	Time  0.236 ( 3.123)	Data  0.003 ( 2.828)	Loss 1.4699e-01 (2.2425e-01) 
2023-05-27 03:49:59.585562: val Epoch: [1][ 2/72]	Time  4.483 ( 3.576)	Data  4.244 ( 3.300)	Loss 2.8330e-01 (2.4394e-01) 
2023-05-27 03:49:59.817128: val Epoch: [1][ 3/72]	Time  0.232 ( 2.740)	Data  0.037 ( 2.484)	Loss 5.7115e-01 (3.2574e-01) 
2023-05-27 03:50:05.061144: val Epoch: [1][ 4/72]	Time  5.244 ( 3.241)	Data  4.978 ( 2.983)	Loss 2.9487e-01 (3.1957e-01) 
2023-05-27 03:50:05.316361: val Epoch: [1][ 5/72]	Time  0.255 ( 2.743)	Data  0.001 ( 2.486)	Loss 2.0486e-01 (3.0045e-01) 
2023-05-27 03:50:10.216938: val Epoch: [1][ 6/72]	Time  4.901 ( 3.051)	Data  4.709 ( 2.804)	Loss 5.2434e-01 (3.3243e-01) 
2023-05-27 03:50:10.671205: val Epoch: [1][ 7/72]	Time  0.454 ( 2.727)	Data  0.175 ( 2.475)	Loss 4.7030e-01 (3.4967e-01) 
2023-05-27 03:50:15.322880: val Epoch: [1][ 8/72]	Time  4.652 ( 2.941)	Data  4.451 ( 2.695)	Loss 2.4004e-01 (3.3749e-01) 
2023-05-27 03:50:15.906970: val Epoch: [1][ 9/72]	Time  0.584 ( 2.705)	Data  0.430 ( 2.468)	Loss 1.6600e-01 (3.2034e-01) 
2023-05-27 03:50:20.282934: val Epoch: [1][10/72]	Time  4.376 ( 2.857)	Data  4.209 ( 2.626)	Loss 2.7183e-01 (3.1593e-01) 
2023-05-27 03:50:21.014710: val Epoch: [1][11/72]	Time  0.732 ( 2.680)	Data  0.556 ( 2.454)	Loss 1.3636e-01 (3.0096e-01) 
2023-05-27 03:50:25.347219: val Epoch: [1][12/72]	Time  4.333 ( 2.807)	Data  4.054 ( 2.577)	Loss 3.7927e-01 (3.0699e-01) 
2023-05-27 03:50:26.086505: val Epoch: [1][13/72]	Time  0.739 ( 2.659)	Data  0.442 ( 2.424)	Loss 1.9865e-01 (2.9925e-01) 
2023-05-27 03:50:30.455231: val Epoch: [1][14/72]	Time  4.369 ( 2.773)	Data  4.194 ( 2.542)	Loss 2.2571e-01 (2.9435e-01) 
2023-05-27 03:50:31.425343: val Epoch: [1][15/72]	Time  0.970 ( 2.661)	Data  0.749 ( 2.430)	Loss 6.8648e-01 (3.1885e-01) 
2023-05-27 03:50:35.601956: val Epoch: [1][16/72]	Time  4.177 ( 2.750)	Data  3.864 ( 2.515)	Loss 1.2835e-01 (3.0765e-01) 
2023-05-27 03:50:36.575519: val Epoch: [1][17/72]	Time  0.974 ( 2.651)	Data  0.712 ( 2.414)	Loss 2.6094e-01 (3.0505e-01) 
2023-05-27 03:50:40.748504: val Epoch: [1][18/72]	Time  4.173 ( 2.731)	Data  3.990 ( 2.497)	Loss 2.9034e-01 (3.0428e-01) 
2023-05-27 03:50:41.606105: val Epoch: [1][19/72]	Time  0.858 ( 2.637)	Data  0.580 ( 2.402)	Loss 1.7764e-01 (2.9795e-01) 
2023-05-27 03:50:46.201289: val Epoch: [1][20/72]	Time  4.595 ( 2.731)	Data  4.287 ( 2.491)	Loss 2.7714e-01 (2.9696e-01) 
2023-05-27 03:50:46.650642: val Epoch: [1][21/72]	Time  0.449 ( 2.627)	Data  0.239 ( 2.389)	Loss 3.9718e-01 (3.0151e-01) 
2023-05-27 03:50:51.325379: val Epoch: [1][22/72]	Time  4.675 ( 2.716)	Data  4.410 ( 2.477)	Loss 1.6095e-01 (2.9540e-01) 
2023-05-27 03:50:51.813412: val Epoch: [1][23/72]	Time  0.488 ( 2.623)	Data  0.232 ( 2.383)	Loss 6.0220e-01 (3.0818e-01) 
2023-05-27 03:50:56.306266: val Epoch: [1][24/72]	Time  4.493 ( 2.698)	Data  4.214 ( 2.457)	Loss 1.3641e-01 (3.0131e-01) 
2023-05-27 03:50:56.887358: val Epoch: [1][25/72]	Time  0.581 ( 2.617)	Data  0.379 ( 2.377)	Loss 5.2343e-01 (3.0986e-01) 
2023-05-27 03:51:01.024120: val Epoch: [1][26/72]	Time  4.137 ( 2.673)	Data  3.929 ( 2.434)	Loss 3.2050e-01 (3.1025e-01) 
2023-05-27 03:51:02.118236: val Epoch: [1][27/72]	Time  1.094 ( 2.616)	Data  0.842 ( 2.377)	Loss 1.6979e-01 (3.0523e-01) 
2023-05-27 03:51:06.353359: val Epoch: [1][28/72]	Time  4.235 ( 2.672)	Data  4.082 ( 2.436)	Loss 1.4140e-01 (2.9958e-01) 
2023-05-27 03:51:07.064345: val Epoch: [1][29/72]	Time  0.711 ( 2.607)	Data  0.504 ( 2.372)	Loss 1.9154e-01 (2.9598e-01) 
2023-05-27 03:51:11.562982: val Epoch: [1][30/72]	Time  4.499 ( 2.668)	Data  4.219 ( 2.431)	Loss 2.7126e-01 (2.9518e-01) 
2023-05-27 03:51:12.361679: val Epoch: [1][31/72]	Time  0.799 ( 2.610)	Data  0.612 ( 2.374)	Loss 2.8379e-01 (2.9483e-01) 
2023-05-27 03:51:16.565952: val Epoch: [1][32/72]	Time  4.204 ( 2.658)	Data  3.999 ( 2.424)	Loss 2.0317e-01 (2.9205e-01) 
2023-05-27 03:51:17.168470: val Epoch: [1][33/72]	Time  0.603 ( 2.597)	Data  0.429 ( 2.365)	Loss 2.5690e-01 (2.9102e-01) 
2023-05-27 03:51:22.056244: val Epoch: [1][34/72]	Time  4.888 ( 2.663)	Data  4.634 ( 2.430)	Loss 6.2258e-01 (3.0049e-01) 
2023-05-27 03:51:22.352117: val Epoch: [1][35/72]	Time  0.296 ( 2.597)	Data  0.001 ( 2.362)	Loss 1.5336e-01 (2.9640e-01) 
2023-05-27 03:51:27.223568: val Epoch: [1][36/72]	Time  4.871 ( 2.659)	Data  4.704 ( 2.426)	Loss 1.8664e-01 (2.9344e-01) 
2023-05-27 03:51:27.439655: val Epoch: [1][37/72]	Time  0.216 ( 2.594)	Data  0.000 ( 2.362)	Loss 1.6784e-01 (2.9013e-01) 
2023-05-27 03:51:32.554694: val Epoch: [1][38/72]	Time  5.115 ( 2.659)	Data  4.956 ( 2.428)	Loss 2.9314e-01 (2.9021e-01) 
2023-05-27 03:51:32.850926: val Epoch: [1][39/72]	Time  0.296 ( 2.600)	Data  0.001 ( 2.368)	Loss 4.4878e-01 (2.9417e-01) 
2023-05-27 03:51:37.872149: val Epoch: [1][40/72]	Time  5.021 ( 2.659)	Data  4.764 ( 2.426)	Loss 2.7519e-01 (2.9371e-01) 
2023-05-27 03:51:38.072116: val Epoch: [1][41/72]	Time  0.200 ( 2.600)	Data  0.001 ( 2.368)	Loss 2.6320e-01 (2.9298e-01) 
2023-05-27 03:51:42.927328: val Epoch: [1][42/72]	Time  4.855 ( 2.653)	Data  4.592 ( 2.420)	Loss 2.6199e-01 (2.9226e-01) 
2023-05-27 03:51:43.220143: val Epoch: [1][43/72]	Time  0.293 ( 2.599)	Data  0.133 ( 2.368)	Loss 1.4438e-01 (2.8890e-01) 
2023-05-27 03:51:47.827578: val Epoch: [1][44/72]	Time  4.607 ( 2.644)	Data  4.344 ( 2.412)	Loss 1.6573e-01 (2.8616e-01) 
2023-05-27 03:51:48.484704: val Epoch: [1][45/72]	Time  0.657 ( 2.601)	Data  0.487 ( 2.370)	Loss 3.3701e-01 (2.8727e-01) 
2023-05-27 03:51:53.044763: val Epoch: [1][46/72]	Time  4.560 ( 2.642)	Data  4.278 ( 2.411)	Loss 1.6080e-01 (2.8458e-01) 
2023-05-27 03:51:53.577849: val Epoch: [1][47/72]	Time  0.533 ( 2.598)	Data  0.369 ( 2.368)	Loss 2.2204e-01 (2.8328e-01) 
2023-05-27 03:51:58.140766: val Epoch: [1][48/72]	Time  4.563 ( 2.638)	Data  4.349 ( 2.409)	Loss 4.1041e-01 (2.8587e-01) 
2023-05-27 03:51:58.750272: val Epoch: [1][49/72]	Time  0.609 ( 2.598)	Data  0.441 ( 2.369)	Loss 2.1551e-01 (2.8446e-01) 
2023-05-27 03:52:03.288710: val Epoch: [1][50/72]	Time  4.538 ( 2.636)	Data  4.224 ( 2.406)	Loss 2.2831e-01 (2.8336e-01) 
2023-05-27 03:52:03.671514: val Epoch: [1][51/72]	Time  0.383 ( 2.593)	Data  0.221 ( 2.364)	Loss 2.3919e-01 (2.8251e-01) 
2023-05-27 03:52:08.074149: val Epoch: [1][52/72]	Time  4.403 ( 2.627)	Data  4.255 ( 2.399)	Loss 2.4675e-01 (2.8184e-01) 
2023-05-27 03:52:08.810906: val Epoch: [1][53/72]	Time  0.737 ( 2.592)	Data  0.523 ( 2.365)	Loss 2.8967e-01 (2.8198e-01) 
2023-05-27 03:52:13.193831: val Epoch: [1][54/72]	Time  4.383 ( 2.624)	Data  4.187 ( 2.398)	Loss 1.7043e-01 (2.7995e-01) 
2023-05-27 03:52:13.859879: val Epoch: [1][55/72]	Time  0.666 ( 2.589)	Data  0.500 ( 2.364)	Loss 1.4868e-01 (2.7761e-01) 
2023-05-27 03:52:18.162297: val Epoch: [1][56/72]	Time  4.302 ( 2.619)	Data  4.026 ( 2.393)	Loss 1.6484e-01 (2.7563e-01) 
2023-05-27 03:52:19.286015: val Epoch: [1][57/72]	Time  1.124 ( 2.594)	Data  0.910 ( 2.367)	Loss 4.2439e-01 (2.7820e-01) 
2023-05-27 03:52:23.306305: val Epoch: [1][58/72]	Time  4.020 ( 2.618)	Data  3.815 ( 2.392)	Loss 1.5018e-01 (2.7603e-01) 
2023-05-27 03:52:24.326952: val Epoch: [1][59/72]	Time  1.021 ( 2.591)	Data  0.915 ( 2.367)	Loss 5.0283e-01 (2.7981e-01) 
2023-05-27 03:52:28.433347: val Epoch: [1][60/72]	Time  4.106 ( 2.616)	Data  3.941 ( 2.393)	Loss 2.0256e-01 (2.7854e-01) 
2023-05-27 03:52:29.449528: val Epoch: [1][61/72]	Time  1.016 ( 2.590)	Data  0.832 ( 2.368)	Loss 1.6701e-01 (2.7674e-01) 
2023-05-27 03:52:33.750691: val Epoch: [1][62/72]	Time  4.301 ( 2.617)	Data  4.122 ( 2.396)	Loss 2.9760e-01 (2.7707e-01) 
2023-05-27 03:52:34.366983: val Epoch: [1][63/72]	Time  0.616 ( 2.586)	Data  0.466 ( 2.366)	Loss 6.3430e-01 (2.8265e-01) 
2023-05-27 03:52:38.485996: val Epoch: [1][64/72]	Time  4.119 ( 2.610)	Data  4.003 ( 2.391)	Loss 1.8606e-01 (2.8117e-01) 
2023-05-27 03:52:39.501575: val Epoch: [1][65/72]	Time  1.016 ( 2.586)	Data  0.907 ( 2.368)	Loss 5.5344e-01 (2.8529e-01) 
2023-05-27 03:52:43.452328: val Epoch: [1][66/72]	Time  3.951 ( 2.606)	Data  3.840 ( 2.390)	Loss 2.5072e-01 (2.8478e-01) 
2023-05-27 03:52:44.579660: val Epoch: [1][67/72]	Time  1.127 ( 2.584)	Data  1.018 ( 2.370)	Loss 3.4360e-01 (2.8564e-01) 
2023-05-27 03:52:48.486960: val Epoch: [1][68/72]	Time  3.907 ( 2.603)	Data  3.798 ( 2.391)	Loss 2.3585e-01 (2.8492e-01) 
2023-05-27 03:52:49.616455: val Epoch: [1][69/72]	Time  1.129 ( 2.582)	Data  1.024 ( 2.371)	Loss 3.0197e-01 (2.8516e-01) 
2023-05-27 03:52:53.756327: val Epoch: [1][70/72]	Time  4.140 ( 2.604)	Data  3.974 ( 2.394)	Loss 3.2647e-01 (2.8575e-01) 
2023-05-27 03:52:54.794312: val Epoch: [1][71/72]	Time  1.038 ( 2.582)	Data  0.791 ( 2.372)	Loss 2.1174e-01 (2.8472e-01) 
2023-05-27 03:52:55.123554: Epoch 1 :Val : ['ET : 0.5406836271286011', 'TC : 0.5575794577598572', 'WT : 0.7135411500930786'] 
2023-05-27 03:52:55.126375: Epoch 1 :Val : ['ET : 0.5406836271286011', 'TC : 0.5575794577598572', 'WT : 0.7135411500930786'] 
2023-05-27 03:52:55.129296: Saving the model with DSC 0.595184326171875 
2023-05-27 03:52:55.953452: Val epoch done in 187.94460343799437 s 
2023-05-27 03:52:55.959349: Batches per epoch:  193 
2023-05-27 03:53:07.837527: train Epoch: [2][  0/193]	Time 11.878 (11.878)	Data 10.914 (10.914)	Loss 1.9089e-01 (1.9089e-01) 
2023-05-27 03:53:08.763415: train Epoch: [2][  1/193]	Time  0.926 ( 6.402)	Data  0.001 ( 5.457)	Loss 2.8787e-01 (2.3938e-01) 
2023-05-27 03:53:17.741910: train Epoch: [2][  2/193]	Time  8.978 ( 7.261)	Data  8.045 ( 6.320)	Loss 3.2792e-01 (2.6889e-01) 
2023-05-27 03:53:18.638736: train Epoch: [2][  3/193]	Time  0.897 ( 5.670)	Data  0.001 ( 4.740)	Loss 1.8338e-01 (2.4752e-01) 
2023-05-27 03:53:27.911772: train Epoch: [2][  4/193]	Time  9.273 ( 6.390)	Data  8.280 ( 5.448)	Loss 1.5806e-01 (2.2962e-01) 
2023-05-27 03:53:28.904688: train Epoch: [2][  5/193]	Time  0.993 ( 5.491)	Data  0.001 ( 4.540)	Loss 2.8737e-01 (2.3925e-01) 
2023-05-27 03:53:37.880700: train Epoch: [2][  6/193]	Time  8.976 ( 5.989)	Data  7.970 ( 5.030)	Loss 3.0076e-01 (2.4804e-01) 
2023-05-27 03:53:38.821409: train Epoch: [2][  7/193]	Time  0.941 ( 5.358)	Data  0.001 ( 4.402)	Loss 1.8905e-01 (2.4066e-01) 
2023-05-27 03:53:47.263317: train Epoch: [2][  8/193]	Time  8.442 ( 5.700)	Data  7.539 ( 4.750)	Loss 2.0756e-01 (2.3698e-01) 
2023-05-27 03:53:48.187207: train Epoch: [2][  9/193]	Time  0.924 ( 5.223)	Data  0.043 ( 4.279)	Loss 5.1006e-01 (2.6429e-01) 
2023-05-27 03:53:57.348279: train Epoch: [2][ 10/193]	Time  9.161 ( 5.581)	Data  8.308 ( 4.646)	Loss 1.6400e-01 (2.5517e-01) 
2023-05-27 03:53:58.206294: train Epoch: [2][ 11/193]	Time  0.858 ( 5.187)	Data  0.001 ( 4.259)	Loss 3.0273e-01 (2.5914e-01) 
2023-05-27 03:54:07.317986: train Epoch: [2][ 12/193]	Time  9.112 ( 5.489)	Data  8.318 ( 4.571)	Loss 2.2979e-01 (2.5688e-01) 
2023-05-27 03:54:08.150367: train Epoch: [2][ 13/193]	Time  0.832 ( 5.156)	Data  0.001 ( 4.244)	Loss 2.6653e-01 (2.5757e-01) 
2023-05-27 03:54:18.156458: train Epoch: [2][ 14/193]	Time 10.006 ( 5.480)	Data  9.036 ( 4.564)	Loss 2.3727e-01 (2.5622e-01) 
2023-05-27 03:54:19.171545: train Epoch: [2][ 15/193]	Time  1.015 ( 5.201)	Data  0.001 ( 4.279)	Loss 1.7930e-01 (2.5141e-01) 
2023-05-27 03:54:28.435223: train Epoch: [2][ 16/193]	Time  9.264 ( 5.440)	Data  8.358 ( 4.519)	Loss 1.9356e-01 (2.4801e-01) 
2023-05-27 03:54:29.333407: train Epoch: [2][ 17/193]	Time  0.898 ( 5.187)	Data  0.001 ( 4.268)	Loss 1.7344e-01 (2.4386e-01) 
2023-05-27 03:54:38.666463: train Epoch: [2][ 18/193]	Time  9.333 ( 5.406)	Data  8.451 ( 4.488)	Loss 5.3222e-01 (2.5904e-01) 
2023-05-27 03:54:39.600081: train Epoch: [2][ 19/193]	Time  0.934 ( 5.182)	Data  0.001 ( 4.263)	Loss 2.0259e-01 (2.5622e-01) 
2023-05-27 03:54:48.121535: train Epoch: [2][ 20/193]	Time  8.521 ( 5.341)	Data  7.626 ( 4.424)	Loss 3.1898e-01 (2.5921e-01) 
2023-05-27 03:54:49.012109: train Epoch: [2][ 21/193]	Time  0.891 ( 5.139)	Data  0.001 ( 4.223)	Loss 3.0367e-01 (2.6123e-01) 
2023-05-27 03:54:57.886376: train Epoch: [2][ 22/193]	Time  8.874 ( 5.301)	Data  8.068 ( 4.390)	Loss 2.9761e-01 (2.6281e-01) 
2023-05-27 03:54:58.720118: train Epoch: [2][ 23/193]	Time  0.834 ( 5.115)	Data  0.001 ( 4.207)	Loss 2.1509e-01 (2.6082e-01) 
2023-05-27 03:55:08.265661: train Epoch: [2][ 24/193]	Time  9.546 ( 5.292)	Data  8.571 ( 4.381)	Loss 2.6909e-01 (2.6115e-01) 
2023-05-27 03:55:09.185437: train Epoch: [2][ 25/193]	Time  0.920 ( 5.124)	Data  0.001 ( 4.213)	Loss 2.4497e-01 (2.6053e-01) 
2023-05-27 03:55:18.297107: train Epoch: [2][ 26/193]	Time  9.112 ( 5.272)	Data  8.090 ( 4.357)	Loss 2.4455e-01 (2.5994e-01) 
2023-05-27 03:55:19.267653: train Epoch: [2][ 27/193]	Time  0.971 ( 5.118)	Data  0.001 ( 4.201)	Loss 3.2814e-01 (2.6237e-01) 
2023-05-27 03:55:28.207677: train Epoch: [2][ 28/193]	Time  8.940 ( 5.250)	Data  8.119 ( 4.336)	Loss 2.4505e-01 (2.6178e-01) 
2023-05-27 03:55:29.176521: train Epoch: [2][ 29/193]	Time  0.969 ( 5.107)	Data  0.001 ( 4.192)	Loss 1.6032e-01 (2.5839e-01) 
2023-05-27 03:55:38.274360: train Epoch: [2][ 30/193]	Time  9.098 ( 5.236)	Data  8.234 ( 4.322)	Loss 2.4158e-01 (2.5785e-01) 
2023-05-27 03:55:39.234728: train Epoch: [2][ 31/193]	Time  0.960 ( 5.102)	Data  0.001 ( 4.187)	Loss 2.8398e-01 (2.5867e-01) 
2023-05-27 03:55:47.305973: train Epoch: [2][ 32/193]	Time  8.071 ( 5.192)	Data  7.060 ( 4.274)	Loss 1.9276e-01 (2.5667e-01) 
2023-05-27 03:55:48.300554: train Epoch: [2][ 33/193]	Time  0.995 ( 5.069)	Data  0.001 ( 4.148)	Loss 2.6674e-01 (2.5697e-01) 
2023-05-27 03:55:56.589014: train Epoch: [2][ 34/193]	Time  8.288 ( 5.161)	Data  7.409 ( 4.242)	Loss 2.2923e-01 (2.5617e-01) 
2023-05-27 03:55:57.602292: train Epoch: [2][ 35/193]	Time  1.013 ( 5.046)	Data  0.001 ( 4.124)	Loss 1.6388e-01 (2.5361e-01) 
2023-05-27 03:56:06.758549: train Epoch: [2][ 36/193]	Time  9.156 ( 5.157)	Data  8.239 ( 4.235)	Loss 2.1199e-01 (2.5249e-01) 
2023-05-27 03:56:07.693824: train Epoch: [2][ 37/193]	Time  0.935 ( 5.046)	Data  0.001 ( 4.124)	Loss 1.9012e-01 (2.5084e-01) 
2023-05-27 03:56:16.709508: train Epoch: [2][ 38/193]	Time  9.016 ( 5.147)	Data  8.111 ( 4.226)	Loss 2.9438e-01 (2.5196e-01) 
2023-05-27 03:56:17.695839: train Epoch: [2][ 39/193]	Time  0.986 ( 5.043)	Data  0.001 ( 4.120)	Loss 2.4084e-01 (2.5168e-01) 
2023-05-27 03:56:26.776239: train Epoch: [2][ 40/193]	Time  9.080 ( 5.142)	Data  8.183 ( 4.219)	Loss 5.4593e-01 (2.5886e-01) 
2023-05-27 03:56:27.754932: train Epoch: [2][ 41/193]	Time  0.979 ( 5.043)	Data  0.001 ( 4.119)	Loss 3.3051e-01 (2.6057e-01) 
2023-05-27 03:56:36.544750: train Epoch: [2][ 42/193]	Time  8.790 ( 5.130)	Data  7.898 ( 4.207)	Loss 3.0544e-01 (2.6161e-01) 
2023-05-27 03:56:37.514197: train Epoch: [2][ 43/193]	Time  0.969 ( 5.035)	Data  0.001 ( 4.111)	Loss 2.3960e-01 (2.6111e-01) 
2023-05-27 03:56:46.618131: train Epoch: [2][ 44/193]	Time  9.104 ( 5.126)	Data  8.049 ( 4.199)	Loss 4.0508e-01 (2.6431e-01) 
2023-05-27 03:56:47.625581: train Epoch: [2][ 45/193]	Time  1.007 ( 5.036)	Data  0.001 ( 4.107)	Loss 1.8602e-01 (2.6261e-01) 
2023-05-27 03:56:56.508713: train Epoch: [2][ 46/193]	Time  8.883 ( 5.118)	Data  8.033 ( 4.191)	Loss 2.6917e-01 (2.6275e-01) 
2023-05-27 03:56:57.451866: train Epoch: [2][ 47/193]	Time  0.943 ( 5.031)	Data  0.001 ( 4.104)	Loss 3.3381e-01 (2.6423e-01) 
2023-05-27 03:57:06.573868: train Epoch: [2][ 48/193]	Time  9.122 ( 5.115)	Data  8.281 ( 4.189)	Loss 2.3437e-01 (2.6362e-01) 
2023-05-27 03:57:07.528839: train Epoch: [2][ 49/193]	Time  0.955 ( 5.031)	Data  0.001 ( 4.105)	Loss 1.3765e-01 (2.6110e-01) 
2023-05-27 03:57:16.328737: train Epoch: [2][ 50/193]	Time  8.800 ( 5.105)	Data  7.854 ( 4.179)	Loss 1.5522e-01 (2.5902e-01) 
2023-05-27 03:57:17.213784: train Epoch: [2][ 51/193]	Time  0.885 ( 5.024)	Data  0.001 ( 4.098)	Loss 1.9984e-01 (2.5788e-01) 
2023-05-27 03:57:26.534651: train Epoch: [2][ 52/193]	Time  9.321 ( 5.105)	Data  8.309 ( 4.178)	Loss 1.9079e-01 (2.5662e-01) 
2023-05-27 03:57:27.448354: train Epoch: [2][ 53/193]	Time  0.914 ( 5.028)	Data  0.001 ( 4.100)	Loss 2.6331e-01 (2.5674e-01) 
2023-05-27 03:57:36.757491: train Epoch: [2][ 54/193]	Time  9.309 ( 5.105)	Data  8.369 ( 4.178)	Loss 3.8198e-01 (2.5902e-01) 
2023-05-27 03:57:37.828547: train Epoch: [2][ 55/193]	Time  1.071 ( 5.033)	Data  0.001 ( 4.103)	Loss 2.6879e-01 (2.5919e-01) 
2023-05-27 03:57:47.018025: train Epoch: [2][ 56/193]	Time  9.189 ( 5.106)	Data  8.349 ( 4.178)	Loss 3.9507e-01 (2.6158e-01) 
2023-05-27 03:57:47.919549: train Epoch: [2][ 57/193]	Time  0.902 ( 5.034)	Data  0.001 ( 4.106)	Loss 1.4034e-01 (2.5949e-01) 
2023-05-27 03:57:57.586720: train Epoch: [2][ 58/193]	Time  9.667 ( 5.112)	Data  8.699 ( 4.184)	Loss 2.4280e-01 (2.5920e-01) 
2023-05-27 03:57:58.528555: train Epoch: [2][ 59/193]	Time  0.942 ( 5.043)	Data  0.001 ( 4.114)	Loss 3.0980e-01 (2.6005e-01) 
2023-05-27 03:58:07.305694: train Epoch: [2][ 60/193]	Time  8.777 ( 5.104)	Data  7.789 ( 4.174)	Loss 2.1614e-01 (2.5933e-01) 
2023-05-27 03:58:08.290672: train Epoch: [2][ 61/193]	Time  0.985 ( 5.038)	Data  0.001 ( 4.107)	Loss 3.8054e-01 (2.6128e-01) 
2023-05-27 03:58:17.447426: train Epoch: [2][ 62/193]	Time  9.157 ( 5.103)	Data  8.252 ( 4.173)	Loss 1.5913e-01 (2.5966e-01) 
2023-05-27 03:58:18.419765: train Epoch: [2][ 63/193]	Time  0.972 ( 5.038)	Data  0.001 ( 4.108)	Loss 1.8633e-01 (2.5852e-01) 
2023-05-27 03:58:27.613441: train Epoch: [2][ 64/193]	Time  9.194 ( 5.102)	Data  8.208 ( 4.171)	Loss 1.7402e-01 (2.5722e-01) 
2023-05-27 03:58:28.559649: train Epoch: [2][ 65/193]	Time  0.946 ( 5.039)	Data  0.001 ( 4.107)	Loss 1.4585e-01 (2.5553e-01) 
2023-05-27 03:58:37.516672: train Epoch: [2][ 66/193]	Time  8.957 ( 5.098)	Data  7.877 ( 4.164)	Loss 2.3951e-01 (2.5529e-01) 
2023-05-27 03:58:38.409153: train Epoch: [2][ 67/193]	Time  0.892 ( 5.036)	Data  0.001 ( 4.102)	Loss 1.8788e-01 (2.5430e-01) 
2023-05-27 03:58:47.191605: train Epoch: [2][ 68/193]	Time  8.782 ( 5.090)	Data  7.946 ( 4.158)	Loss 2.8153e-01 (2.5469e-01) 
2023-05-27 03:58:48.108485: train Epoch: [2][ 69/193]	Time  0.917 ( 5.031)	Data  0.001 ( 4.099)	Loss 1.8333e-01 (2.5367e-01) 
2023-05-27 03:58:56.633641: train Epoch: [2][ 70/193]	Time  8.525 ( 5.080)	Data  7.569 ( 4.148)	Loss 2.2267e-01 (2.5324e-01) 
2023-05-27 03:58:57.499995: train Epoch: [2][ 71/193]	Time  0.866 ( 5.021)	Data  0.001 ( 4.090)	Loss 3.5607e-01 (2.5466e-01) 
2023-05-27 03:59:05.716969: train Epoch: [2][ 72/193]	Time  8.217 ( 5.065)	Data  7.301 ( 4.134)	Loss 2.6915e-01 (2.5486e-01) 
2023-05-27 03:59:06.673145: train Epoch: [2][ 73/193]	Time  0.956 ( 5.010)	Data  0.001 ( 4.078)	Loss 1.4740e-01 (2.5341e-01) 
2023-05-27 03:59:15.933376: train Epoch: [2][ 74/193]	Time  9.260 ( 5.066)	Data  8.270 ( 4.134)	Loss 2.1883e-01 (2.5295e-01) 
2023-05-27 03:59:16.773487: train Epoch: [2][ 75/193]	Time  0.840 ( 5.011)	Data  0.001 ( 4.080)	Loss 6.6580e-01 (2.5838e-01) 
2023-05-27 03:59:25.916984: train Epoch: [2][ 76/193]	Time  9.144 ( 5.064)	Data  8.295 ( 4.134)	Loss 2.2240e-01 (2.5791e-01) 
2023-05-27 03:59:26.824370: train Epoch: [2][ 77/193]	Time  0.907 ( 5.011)	Data  0.001 ( 4.081)	Loss 1.4295e-01 (2.5644e-01) 
2023-05-27 03:59:36.248298: train Epoch: [2][ 78/193]	Time  9.424 ( 5.067)	Data  8.483 ( 4.137)	Loss 1.9204e-01 (2.5563e-01) 
2023-05-27 03:59:37.203482: train Epoch: [2][ 79/193]	Time  0.955 ( 5.016)	Data  0.001 ( 4.085)	Loss 2.9804e-01 (2.5616e-01) 
2023-05-27 03:59:45.947034: train Epoch: [2][ 80/193]	Time  8.744 ( 5.062)	Data  7.909 ( 4.133)	Loss 1.9426e-01 (2.5539e-01) 
2023-05-27 03:59:46.816172: train Epoch: [2][ 81/193]	Time  0.869 ( 5.010)	Data  0.001 ( 4.082)	Loss 1.6111e-01 (2.5424e-01) 
2023-05-27 03:59:55.756158: train Epoch: [2][ 82/193]	Time  8.940 ( 5.058)	Data  8.131 ( 4.131)	Loss 1.3027e-01 (2.5275e-01) 
2023-05-27 03:59:56.732326: train Epoch: [2][ 83/193]	Time  0.976 ( 5.009)	Data  0.001 ( 4.082)	Loss 3.0340e-01 (2.5335e-01) 
2023-05-27 04:00:05.836435: train Epoch: [2][ 84/193]	Time  9.104 ( 5.057)	Data  8.204 ( 4.130)	Loss 2.0794e-01 (2.5282e-01) 
2023-05-27 04:00:06.773230: train Epoch: [2][ 85/193]	Time  0.937 ( 5.009)	Data  0.001 ( 4.082)	Loss 2.0304e-01 (2.5224e-01) 
2023-05-27 04:00:15.981550: train Epoch: [2][ 86/193]	Time  9.208 ( 5.058)	Data  8.212 ( 4.130)	Loss 1.7680e-01 (2.5137e-01) 
2023-05-27 04:00:16.853797: train Epoch: [2][ 87/193]	Time  0.872 ( 5.010)	Data  0.001 ( 4.083)	Loss 1.4800e-01 (2.5020e-01) 
2023-05-27 04:00:25.439042: train Epoch: [2][ 88/193]	Time  8.585 ( 5.050)	Data  7.628 ( 4.123)	Loss 1.2564e-01 (2.4880e-01) 
2023-05-27 04:00:26.349159: train Epoch: [2][ 89/193]	Time  0.910 ( 5.004)	Data  0.001 ( 4.077)	Loss 9.9815e-02 (2.4714e-01) 
2023-05-27 04:00:35.195303: train Epoch: [2][ 90/193]	Time  8.846 ( 5.047)	Data  8.013 ( 4.120)	Loss 1.7724e-01 (2.4637e-01) 
2023-05-27 04:00:36.182980: train Epoch: [2][ 91/193]	Time  0.988 ( 5.002)	Data  0.001 ( 4.075)	Loss 2.0889e-01 (2.4597e-01) 
2023-05-27 04:00:45.245565: train Epoch: [2][ 92/193]	Time  9.063 ( 5.046)	Data  8.185 ( 4.120)	Loss 1.7385e-01 (2.4519e-01) 
2023-05-27 04:00:46.114115: train Epoch: [2][ 93/193]	Time  0.869 ( 5.002)	Data  0.001 ( 4.076)	Loss 1.8935e-01 (2.4460e-01) 
2023-05-27 04:00:55.286044: train Epoch: [2][ 94/193]	Time  9.172 ( 5.046)	Data  8.101 ( 4.118)	Loss 1.2608e-01 (2.4335e-01) 
2023-05-27 04:00:56.286754: train Epoch: [2][ 95/193]	Time  1.001 ( 5.003)	Data  0.001 ( 4.075)	Loss 1.8161e-01 (2.4271e-01) 
2023-05-27 04:01:04.971196: train Epoch: [2][ 96/193]	Time  8.684 ( 5.041)	Data  7.784 ( 4.114)	Loss 1.6330e-01 (2.4189e-01) 
2023-05-27 04:01:05.856248: train Epoch: [2][ 97/193]	Time  0.885 ( 4.999)	Data  0.001 ( 4.072)	Loss 1.6672e-01 (2.4112e-01) 
2023-05-27 04:01:15.079062: train Epoch: [2][ 98/193]	Time  9.223 ( 5.042)	Data  8.323 ( 4.114)	Loss 1.6521e-01 (2.4035e-01) 
2023-05-27 04:01:16.048132: train Epoch: [2][ 99/193]	Time  0.969 ( 5.001)	Data  0.001 ( 4.073)	Loss 2.3194e-01 (2.4027e-01) 
2023-05-27 04:01:25.508147: train Epoch: [2][100/193]	Time  9.460 ( 5.045)	Data  8.504 ( 4.117)	Loss 1.6522e-01 (2.3953e-01) 
2023-05-27 04:01:26.458450: train Epoch: [2][101/193]	Time  0.950 ( 5.005)	Data  0.001 ( 4.077)	Loss 2.0108e-01 (2.3915e-01) 
2023-05-27 04:01:34.484969: train Epoch: [2][102/193]	Time  8.027 ( 5.034)	Data  7.082 ( 4.106)	Loss 2.3139e-01 (2.3907e-01) 
2023-05-27 04:01:35.505304: train Epoch: [2][103/193]	Time  1.020 ( 4.996)	Data  0.001 ( 4.067)	Loss 2.9757e-01 (2.3964e-01) 
2023-05-27 04:01:42.893815: train Epoch: [2][104/193]	Time  7.389 ( 5.018)	Data  6.555 ( 4.090)	Loss 1.1356e-01 (2.3844e-01) 
2023-05-27 04:01:43.903066: train Epoch: [2][105/193]	Time  1.009 ( 4.981)	Data  0.001 ( 4.052)	Loss 1.4475e-01 (2.3755e-01) 
2023-05-27 04:01:52.859359: train Epoch: [2][106/193]	Time  8.956 ( 5.018)	Data  7.936 ( 4.088)	Loss 1.4970e-01 (2.3673e-01) 
2023-05-27 04:01:53.748042: train Epoch: [2][107/193]	Time  0.889 ( 4.980)	Data  0.001 ( 4.050)	Loss 2.3115e-01 (2.3668e-01) 
2023-05-27 04:02:02.186996: train Epoch: [2][108/193]	Time  8.439 ( 5.011)	Data  7.594 ( 4.083)	Loss 2.1196e-01 (2.3645e-01) 
2023-05-27 04:02:03.085961: train Epoch: [2][109/193]	Time  0.899 ( 4.974)	Data  0.001 ( 4.046)	Loss 1.9254e-01 (2.3605e-01) 
2023-05-27 04:02:11.658373: train Epoch: [2][110/193]	Time  8.572 ( 5.006)	Data  7.642 ( 4.078)	Loss 2.7353e-01 (2.3639e-01) 
2023-05-27 04:02:12.606053: train Epoch: [2][111/193]	Time  0.948 ( 4.970)	Data  0.001 ( 4.042)	Loss 1.6676e-01 (2.3577e-01) 
2023-05-27 04:02:21.370087: train Epoch: [2][112/193]	Time  8.764 ( 5.004)	Data  7.896 ( 4.076)	Loss 1.6538e-01 (2.3515e-01) 
2023-05-27 04:02:22.343025: train Epoch: [2][113/193]	Time  0.973 ( 4.968)	Data  0.001 ( 4.040)	Loss 2.0963e-01 (2.3492e-01) 
2023-05-27 04:02:31.383936: train Epoch: [2][114/193]	Time  9.041 ( 5.004)	Data  8.149 ( 4.076)	Loss 3.6061e-01 (2.3602e-01) 
2023-05-27 04:02:32.406687: train Epoch: [2][115/193]	Time  1.023 ( 4.969)	Data  0.001 ( 4.041)	Loss 1.8677e-01 (2.3559e-01) 
2023-05-27 04:02:41.650351: train Epoch: [2][116/193]	Time  9.244 ( 5.006)	Data  8.305 ( 4.077)	Loss 2.3854e-01 (2.3562e-01) 
2023-05-27 04:02:42.567094: train Epoch: [2][117/193]	Time  0.917 ( 4.971)	Data  0.001 ( 4.042)	Loss 1.4461e-01 (2.3484e-01) 
2023-05-27 04:02:51.643477: train Epoch: [2][118/193]	Time  9.076 ( 5.006)	Data  8.200 ( 4.077)	Loss 2.2202e-01 (2.3474e-01) 
2023-05-27 04:02:52.550133: train Epoch: [2][119/193]	Time  0.907 ( 4.972)	Data  0.001 ( 4.043)	Loss 1.5009e-01 (2.3403e-01) 
2023-05-27 04:03:01.950807: train Epoch: [2][120/193]	Time  9.401 ( 5.008)	Data  8.445 ( 4.080)	Loss 1.6680e-01 (2.3348e-01) 
2023-05-27 04:03:02.813070: train Epoch: [2][121/193]	Time  0.862 ( 4.974)	Data  0.001 ( 4.046)	Loss 2.7678e-01 (2.3383e-01) 
2023-05-27 04:03:11.909376: train Epoch: [2][122/193]	Time  9.096 ( 5.008)	Data  8.188 ( 4.080)	Loss 3.3596e-01 (2.3466e-01) 
2023-05-27 04:03:12.778002: train Epoch: [2][123/193]	Time  0.869 ( 4.974)	Data  0.001 ( 4.047)	Loss 1.8220e-01 (2.3424e-01) 
2023-05-27 04:03:21.962350: train Epoch: [2][124/193]	Time  9.184 ( 5.008)	Data  8.133 ( 4.080)	Loss 2.7317e-01 (2.3455e-01) 
2023-05-27 04:03:22.856664: train Epoch: [2][125/193]	Time  0.894 ( 4.975)	Data  0.001 ( 4.047)	Loss 1.8463e-01 (2.3415e-01) 
2023-05-27 04:03:31.872832: train Epoch: [2][126/193]	Time  9.016 ( 5.007)	Data  8.176 ( 4.080)	Loss 1.7793e-01 (2.3371e-01) 
2023-05-27 04:03:32.667949: train Epoch: [2][127/193]	Time  0.795 ( 4.974)	Data  0.001 ( 4.048)	Loss 2.0130e-01 (2.3346e-01) 
2023-05-27 04:03:42.037142: train Epoch: [2][128/193]	Time  9.369 ( 5.008)	Data  8.527 ( 4.083)	Loss 1.6912e-01 (2.3296e-01) 
2023-05-27 04:03:42.842605: train Epoch: [2][129/193]	Time  0.805 ( 4.976)	Data  0.001 ( 4.051)	Loss 1.5580e-01 (2.3237e-01) 
2023-05-27 04:03:52.289078: train Epoch: [2][130/193]	Time  9.446 ( 5.010)	Data  8.527 ( 4.086)	Loss 1.3789e-01 (2.3164e-01) 
2023-05-27 04:03:53.339290: train Epoch: [2][131/193]	Time  1.050 ( 4.980)	Data  0.001 ( 4.055)	Loss 1.6683e-01 (2.3115e-01) 
2023-05-27 04:04:01.964110: train Epoch: [2][132/193]	Time  8.625 ( 5.008)	Data  7.729 ( 4.082)	Loss 2.6291e-01 (2.3139e-01) 
2023-05-27 04:04:02.889273: train Epoch: [2][133/193]	Time  0.925 ( 4.977)	Data  0.001 ( 4.052)	Loss 2.4766e-01 (2.3151e-01) 
2023-05-27 04:04:12.284095: train Epoch: [2][134/193]	Time  9.395 ( 5.010)	Data  8.453 ( 4.084)	Loss 2.0545e-01 (2.3132e-01) 
2023-05-27 04:04:13.306836: train Epoch: [2][135/193]	Time  1.023 ( 4.980)	Data  0.001 ( 4.054)	Loss 4.3092e-01 (2.3279e-01) 
2023-05-27 04:04:22.012899: train Epoch: [2][136/193]	Time  8.706 ( 5.008)	Data  7.804 ( 4.082)	Loss 1.0326e-01 (2.3184e-01) 
2023-05-27 04:04:23.065556: train Epoch: [2][137/193]	Time  1.053 ( 4.979)	Data  0.012 ( 4.052)	Loss 2.5915e-01 (2.3204e-01) 
2023-05-27 04:04:32.218470: train Epoch: [2][138/193]	Time  9.153 ( 5.009)	Data  8.133 ( 4.082)	Loss 2.9001e-01 (2.3246e-01) 
2023-05-27 04:04:33.174844: train Epoch: [2][139/193]	Time  0.956 ( 4.980)	Data  0.001 ( 4.052)	Loss 1.9645e-01 (2.3220e-01) 
2023-05-27 04:04:42.100228: train Epoch: [2][140/193]	Time  8.925 ( 5.008)	Data  8.003 ( 4.080)	Loss 3.7193e-01 (2.3319e-01) 
2023-05-27 04:04:43.084526: train Epoch: [2][141/193]	Time  0.984 ( 4.980)	Data  0.001 ( 4.052)	Loss 2.2202e-01 (2.3311e-01) 
2023-05-27 04:04:52.326331: train Epoch: [2][142/193]	Time  9.242 ( 5.010)	Data  8.257 ( 4.081)	Loss 4.5981e-01 (2.3470e-01) 
2023-05-27 04:04:53.297956: train Epoch: [2][143/193]	Time  0.972 ( 4.982)	Data  0.001 ( 4.053)	Loss 1.3903e-01 (2.3403e-01) 
2023-05-27 04:05:02.380557: train Epoch: [2][144/193]	Time  9.083 ( 5.010)	Data  8.105 ( 4.081)	Loss 1.1645e-01 (2.3322e-01) 
2023-05-27 04:05:03.429975: train Epoch: [2][145/193]	Time  1.049 ( 4.983)	Data  0.001 ( 4.053)	Loss 1.9169e-01 (2.3294e-01) 
2023-05-27 04:05:12.389736: train Epoch: [2][146/193]	Time  8.960 ( 5.010)	Data  8.028 ( 4.080)	Loss 1.3814e-01 (2.3229e-01) 
2023-05-27 04:05:13.293918: train Epoch: [2][147/193]	Time  0.904 ( 4.982)	Data  0.001 ( 4.052)	Loss 1.6672e-01 (2.3185e-01) 
2023-05-27 04:05:22.270776: train Epoch: [2][148/193]	Time  8.977 ( 5.009)	Data  8.133 ( 4.080)	Loss 4.0973e-01 (2.3304e-01) 
2023-05-27 04:05:23.213163: train Epoch: [2][149/193]	Time  0.942 ( 4.982)	Data  0.001 ( 4.052)	Loss 1.3137e-01 (2.3237e-01) 
2023-05-27 04:05:31.984672: train Epoch: [2][150/193]	Time  8.772 ( 5.007)	Data  7.775 ( 4.077)	Loss 3.0039e-01 (2.3282e-01) 
2023-05-27 04:05:32.994634: train Epoch: [2][151/193]	Time  1.010 ( 4.980)	Data  0.001 ( 4.050)	Loss 2.3957e-01 (2.3286e-01) 
2023-05-27 04:05:42.041470: train Epoch: [2][152/193]	Time  9.047 ( 5.007)	Data  8.113 ( 4.077)	Loss 2.3627e-01 (2.3288e-01) 
2023-05-27 04:05:43.025447: train Epoch: [2][153/193]	Time  0.984 ( 4.981)	Data  0.001 ( 4.050)	Loss 2.5462e-01 (2.3302e-01) 
2023-05-27 04:05:51.734768: train Epoch: [2][154/193]	Time  8.709 ( 5.005)	Data  7.892 ( 4.075)	Loss 4.2084e-01 (2.3424e-01) 
2023-05-27 04:05:52.552540: train Epoch: [2][155/193]	Time  0.818 ( 4.978)	Data  0.001 ( 4.049)	Loss 1.3514e-01 (2.3360e-01) 
2023-05-27 04:06:01.764218: train Epoch: [2][156/193]	Time  9.212 ( 5.005)	Data  8.317 ( 4.076)	Loss 2.4945e-01 (2.3370e-01) 
2023-05-27 04:06:02.731561: train Epoch: [2][157/193]	Time  0.967 ( 4.980)	Data  0.001 ( 4.050)	Loss 6.5939e-01 (2.3640e-01) 
2023-05-27 04:06:11.460332: train Epoch: [2][158/193]	Time  8.729 ( 5.003)	Data  7.793 ( 4.074)	Loss 2.3689e-01 (2.3640e-01) 
2023-05-27 04:06:12.338058: train Epoch: [2][159/193]	Time  0.878 ( 4.977)	Data  0.001 ( 4.049)	Loss 3.9867e-01 (2.3741e-01) 
2023-05-27 04:06:21.874225: train Epoch: [2][160/193]	Time  9.536 ( 5.006)	Data  8.659 ( 4.077)	Loss 3.4471e-01 (2.3808e-01) 
2023-05-27 04:06:22.818641: train Epoch: [2][161/193]	Time  0.944 ( 4.981)	Data  0.001 ( 4.052)	Loss 2.3625e-01 (2.3807e-01) 
2023-05-27 04:06:32.461877: train Epoch: [2][162/193]	Time  9.643 ( 5.009)	Data  8.714 ( 4.081)	Loss 2.0372e-01 (2.3786e-01) 
2023-05-27 04:06:33.483052: train Epoch: [2][163/193]	Time  1.021 ( 4.985)	Data  0.001 ( 4.056)	Loss 2.5479e-01 (2.3796e-01) 
2023-05-27 04:06:42.042950: train Epoch: [2][164/193]	Time  8.560 ( 5.007)	Data  7.778 ( 4.078)	Loss 4.0219e-01 (2.3896e-01) 
2023-05-27 04:06:42.936166: train Epoch: [2][165/193]	Time  0.893 ( 4.982)	Data  0.001 ( 4.054)	Loss 3.2749e-01 (2.3949e-01) 
2023-05-27 04:06:52.275311: train Epoch: [2][166/193]	Time  9.339 ( 5.008)	Data  8.504 ( 4.080)	Loss 3.6255e-01 (2.4023e-01) 
2023-05-27 04:06:53.144767: train Epoch: [2][167/193]	Time  0.869 ( 4.983)	Data  0.001 ( 4.056)	Loss 3.2578e-01 (2.4074e-01) 
2023-05-27 04:07:02.079023: train Epoch: [2][168/193]	Time  8.934 ( 5.007)	Data  8.015 ( 4.080)	Loss 2.0436e-01 (2.4052e-01) 
2023-05-27 04:07:03.022449: train Epoch: [2][169/193]	Time  0.943 ( 4.983)	Data  0.001 ( 4.056)	Loss 1.9268e-01 (2.4024e-01) 
2023-05-27 04:07:12.162355: train Epoch: [2][170/193]	Time  9.140 ( 5.007)	Data  8.191 ( 4.080)	Loss 2.6658e-01 (2.4039e-01) 
2023-05-27 04:07:13.166949: train Epoch: [2][171/193]	Time  1.005 ( 4.984)	Data  0.001 ( 4.056)	Loss 2.0776e-01 (2.4020e-01) 
2023-05-27 04:07:21.815535: train Epoch: [2][172/193]	Time  8.649 ( 5.005)	Data  7.740 ( 4.077)	Loss 4.3631e-01 (2.4134e-01) 
2023-05-27 04:07:22.840975: train Epoch: [2][173/193]	Time  1.025 ( 4.982)	Data  0.001 ( 4.054)	Loss 2.9027e-01 (2.4162e-01) 
2023-05-27 04:07:31.745363: train Epoch: [2][174/193]	Time  8.904 ( 5.004)	Data  8.055 ( 4.077)	Loss 2.1816e-01 (2.4148e-01) 
2023-05-27 04:07:32.655466: train Epoch: [2][175/193]	Time  0.910 ( 4.981)	Data  0.001 ( 4.054)	Loss 3.1769e-01 (2.4192e-01) 
2023-05-27 04:07:42.373837: train Epoch: [2][176/193]	Time  9.718 ( 5.008)	Data  8.859 ( 4.081)	Loss 1.1984e-01 (2.4123e-01) 
2023-05-27 04:07:43.255246: train Epoch: [2][177/193]	Time  0.881 ( 4.985)	Data  0.001 ( 4.058)	Loss 2.0654e-01 (2.4103e-01) 
2023-05-27 04:07:52.724850: train Epoch: [2][178/193]	Time  9.470 ( 5.010)	Data  8.404 ( 4.082)	Loss 4.4337e-01 (2.4216e-01) 
2023-05-27 04:07:53.774366: train Epoch: [2][179/193]	Time  1.050 ( 4.988)	Data  0.001 ( 4.059)	Loss 3.1177e-01 (2.4255e-01) 
2023-05-27 04:08:02.439587: train Epoch: [2][180/193]	Time  8.665 ( 5.008)	Data  7.757 ( 4.080)	Loss 2.7852e-01 (2.4275e-01) 
2023-05-27 04:08:03.268574: train Epoch: [2][181/193]	Time  0.829 ( 4.985)	Data  0.001 ( 4.057)	Loss 2.9737e-01 (2.4305e-01) 
2023-05-27 04:08:12.270900: train Epoch: [2][182/193]	Time  9.002 ( 5.007)	Data  8.239 ( 4.080)	Loss 1.9491e-01 (2.4279e-01) 
2023-05-27 04:08:13.023665: train Epoch: [2][183/193]	Time  0.753 ( 4.984)	Data  0.001 ( 4.058)	Loss 1.3368e-01 (2.4219e-01) 
2023-05-27 04:08:21.760142: train Epoch: [2][184/193]	Time  8.736 ( 5.004)	Data  7.806 ( 4.078)	Loss 1.7635e-01 (2.4184e-01) 
2023-05-27 04:08:22.677946: train Epoch: [2][185/193]	Time  0.918 ( 4.982)	Data  0.001 ( 4.056)	Loss 1.1549e-01 (2.4116e-01) 
2023-05-27 04:08:31.619130: train Epoch: [2][186/193]	Time  8.941 ( 5.004)	Data  8.163 ( 4.078)	Loss 1.5748e-01 (2.4071e-01) 
2023-05-27 04:08:32.397234: train Epoch: [2][187/193]	Time  0.778 ( 4.981)	Data  0.001 ( 4.057)	Loss 4.1651e-01 (2.4164e-01) 
2023-05-27 04:08:41.212287: train Epoch: [2][188/193]	Time  8.815 ( 5.001)	Data  8.241 ( 4.079)	Loss 1.8255e-01 (2.4133e-01) 
2023-05-27 04:08:41.783003: train Epoch: [2][189/193]	Time  0.571 ( 4.978)	Data  0.001 ( 4.057)	Loss 1.4527e-01 (2.4083e-01) 
2023-05-27 04:08:50.005090: train Epoch: [2][190/193]	Time  8.222 ( 4.995)	Data  7.655 ( 4.076)	Loss 1.5819e-01 (2.4039e-01) 
2023-05-27 04:08:50.578552: train Epoch: [2][191/193]	Time  0.573 ( 4.972)	Data  0.001 ( 4.055)	Loss 2.4566e-01 (2.4042e-01) 
2023-05-27 04:08:59.016115: train Epoch: [2][192/193]	Time  8.438 ( 4.990)	Data  7.596 ( 4.073)	Loss 3.5256e-01 (2.4100e-01) 
2023-05-27 04:08:59.190356: Train Epoch done in 963.231054428994 s 
2023-05-27 04:09:05.770650: val Epoch: [2][ 0/72]	Time  5.735 ( 5.735)	Data  5.447 ( 5.447)	Loss 2.8111e-01 (2.8111e-01) 
2023-05-27 04:09:05.974483: val Epoch: [2][ 1/72]	Time  0.204 ( 2.969)	Data  0.044 ( 2.745)	Loss 6.0232e-01 (4.4172e-01) 
2023-05-27 04:09:10.707244: val Epoch: [2][ 2/72]	Time  4.733 ( 3.557)	Data  4.534 ( 3.342)	Loss 1.6364e-01 (3.4902e-01) 
2023-05-27 04:09:10.972830: val Epoch: [2][ 3/72]	Time  0.266 ( 2.734)	Data  0.001 ( 2.507)	Loss 2.7374e-01 (3.3020e-01) 
2023-05-27 04:09:15.666670: val Epoch: [2][ 4/72]	Time  4.694 ( 3.126)	Data  4.521 ( 2.909)	Loss 2.5544e-01 (3.1525e-01) 
2023-05-27 04:09:16.389101: val Epoch: [2][ 5/72]	Time  0.722 ( 2.726)	Data  0.473 ( 2.503)	Loss 1.4599e-01 (2.8704e-01) 
2023-05-27 04:09:20.759749: val Epoch: [2][ 6/72]	Time  4.371 ( 2.961)	Data  4.213 ( 2.748)	Loss 4.6980e-01 (3.1315e-01) 
2023-05-27 04:09:21.316770: val Epoch: [2][ 7/72]	Time  0.557 ( 2.660)	Data  0.382 ( 2.452)	Loss 5.0573e-01 (3.3722e-01) 
2023-05-27 04:09:25.926433: val Epoch: [2][ 8/72]	Time  4.610 ( 2.877)	Data  4.322 ( 2.660)	Loss 3.7071e-01 (3.4094e-01) 
2023-05-27 04:09:26.503569: val Epoch: [2][ 9/72]	Time  0.577 ( 2.647)	Data  0.410 ( 2.435)	Loss 2.0939e-01 (3.2779e-01) 
2023-05-27 04:09:30.459607: val Epoch: [2][10/72]	Time  3.956 ( 2.766)	Data  3.743 ( 2.554)	Loss 2.9238e-01 (3.2457e-01) 
2023-05-27 04:09:31.526149: val Epoch: [2][11/72]	Time  1.067 ( 2.624)	Data  0.919 ( 2.417)	Loss 1.6365e-01 (3.1116e-01) 
2023-05-27 04:09:35.550770: val Epoch: [2][12/72]	Time  4.025 ( 2.732)	Data  3.719 ( 2.518)	Loss 1.5934e-01 (2.9948e-01) 
2023-05-27 04:09:36.653144: val Epoch: [2][13/72]	Time  1.102 ( 2.616)	Data  0.860 ( 2.399)	Loss 1.8700e-01 (2.9145e-01) 
2023-05-27 04:09:40.383208: val Epoch: [2][14/72]	Time  3.730 ( 2.690)	Data  3.439 ( 2.469)	Loss 1.7315e-01 (2.8356e-01) 
2023-05-27 04:09:41.797184: val Epoch: [2][15/72]	Time  1.414 ( 2.610)	Data  1.234 ( 2.391)	Loss 2.6951e-01 (2.8268e-01) 
2023-05-27 04:09:45.173514: val Epoch: [2][16/72]	Time  3.376 ( 2.655)	Data  3.223 ( 2.440)	Loss 3.0351e-01 (2.8391e-01) 
2023-05-27 04:09:46.787722: val Epoch: [2][17/72]	Time  1.614 ( 2.597)	Data  1.404 ( 2.383)	Loss 5.9063e-01 (3.0095e-01) 
2023-05-27 04:09:50.328814: val Epoch: [2][18/72]	Time  3.541 ( 2.647)	Data  3.392 ( 2.436)	Loss 2.7880e-01 (2.9978e-01) 
2023-05-27 04:09:51.569299: val Epoch: [2][19/72]	Time  1.240 ( 2.577)	Data  1.082 ( 2.368)	Loss 1.3621e-01 (2.9160e-01) 
2023-05-27 04:09:55.491011: val Epoch: [2][20/72]	Time  3.922 ( 2.641)	Data  3.751 ( 2.434)	Loss 6.9035e-01 (3.1059e-01) 
2023-05-27 04:09:56.707041: val Epoch: [2][21/72]	Time  1.216 ( 2.576)	Data  1.061 ( 2.372)	Loss 2.4102e-01 (3.0743e-01) 
2023-05-27 04:10:00.588647: val Epoch: [2][22/72]	Time  3.882 ( 2.633)	Data  3.704 ( 2.430)	Loss 3.0026e-01 (3.0712e-01) 
2023-05-27 04:10:01.829970: val Epoch: [2][23/72]	Time  1.241 ( 2.575)	Data  1.021 ( 2.371)	Loss 6.0856e-01 (3.1968e-01) 
2023-05-27 04:10:05.760086: val Epoch: [2][24/72]	Time  3.930 ( 2.629)	Data  3.700 ( 2.424)	Loss 2.9641e-01 (3.1875e-01) 
2023-05-27 04:10:07.122310: val Epoch: [2][25/72]	Time  1.362 ( 2.580)	Data  1.112 ( 2.374)	Loss 1.1202e-01 (3.1080e-01) 
2023-05-27 04:10:10.942238: val Epoch: [2][26/72]	Time  3.820 ( 2.626)	Data  3.561 ( 2.418)	Loss 1.7845e-01 (3.0589e-01) 
2023-05-27 04:10:12.074740: val Epoch: [2][27/72]	Time  1.133 ( 2.573)	Data  0.894 ( 2.363)	Loss 5.6359e-01 (3.1510e-01) 
2023-05-27 04:10:16.077033: val Epoch: [2][28/72]	Time  4.002 ( 2.622)	Data  3.724 ( 2.410)	Loss 5.9049e-01 (3.2459e-01) 
2023-05-27 04:10:17.052445: val Epoch: [2][29/72]	Time  0.975 ( 2.567)	Data  0.773 ( 2.356)	Loss 4.2489e-01 (3.2794e-01) 
2023-05-27 04:10:20.796280: val Epoch: [2][30/72]	Time  3.744 ( 2.605)	Data  3.482 ( 2.392)	Loss 1.3387e-01 (3.2168e-01) 
2023-05-27 04:10:22.404442: val Epoch: [2][31/72]	Time  1.608 ( 2.574)	Data  1.353 ( 2.359)	Loss 1.5714e-01 (3.1653e-01) 
2023-05-27 04:10:26.103247: val Epoch: [2][32/72]	Time  3.699 ( 2.608)	Data  3.532 ( 2.395)	Loss 2.4563e-01 (3.1439e-01) 
2023-05-27 04:10:27.342561: val Epoch: [2][33/72]	Time  1.239 ( 2.568)	Data  1.022 ( 2.355)	Loss 1.8550e-01 (3.1060e-01) 
2023-05-27 04:10:31.388013: val Epoch: [2][34/72]	Time  4.045 ( 2.610)	Data  3.743 ( 2.394)	Loss 1.8835e-01 (3.0710e-01) 
2023-05-27 04:10:32.201181: val Epoch: [2][35/72]	Time  0.813 ( 2.560)	Data  0.552 ( 2.343)	Loss 1.9238e-01 (3.0392e-01) 
2023-05-27 04:10:36.360785: val Epoch: [2][36/72]	Time  4.160 ( 2.603)	Data  3.938 ( 2.386)	Loss 2.4243e-01 (3.0225e-01) 
2023-05-27 04:10:37.379503: val Epoch: [2][37/72]	Time  1.019 ( 2.562)	Data  0.752 ( 2.343)	Loss 4.3864e-01 (3.0584e-01) 
2023-05-27 04:10:41.214620: val Epoch: [2][38/72]	Time  3.835 ( 2.594)	Data  3.662 ( 2.377)	Loss 2.7434e-01 (3.0504e-01) 
2023-05-27 04:10:42.391590: val Epoch: [2][39/72]	Time  1.177 ( 2.559)	Data  0.942 ( 2.341)	Loss 2.2306e-01 (3.0299e-01) 
2023-05-27 04:10:45.991631: val Epoch: [2][40/72]	Time  3.600 ( 2.584)	Data  3.433 ( 2.368)	Loss 1.4394e-01 (2.9911e-01) 
2023-05-27 04:10:47.246671: val Epoch: [2][41/72]	Time  1.255 ( 2.553)	Data  1.087 ( 2.337)	Loss 3.8983e-01 (3.0127e-01) 
2023-05-27 04:10:50.754420: val Epoch: [2][42/72]	Time  3.508 ( 2.575)	Data  3.351 ( 2.361)	Loss 2.0018e-01 (2.9892e-01) 
2023-05-27 04:10:52.278174: val Epoch: [2][43/72]	Time  1.524 ( 2.551)	Data  1.286 ( 2.336)	Loss 2.4464e-01 (2.9768e-01) 
2023-05-27 04:10:55.931175: val Epoch: [2][44/72]	Time  3.653 ( 2.575)	Data  3.345 ( 2.359)	Loss 5.8198e-01 (3.0400e-01) 
2023-05-27 04:10:57.467963: val Epoch: [2][45/72]	Time  1.537 ( 2.553)	Data  1.298 ( 2.336)	Loss 6.2165e-01 (3.1091e-01) 
2023-05-27 04:11:00.742723: val Epoch: [2][46/72]	Time  3.275 ( 2.568)	Data  3.074 ( 2.351)	Loss 2.1196e-01 (3.0880e-01) 
2023-05-27 04:11:02.863271: val Epoch: [2][47/72]	Time  2.121 ( 2.559)	Data  1.859 ( 2.341)	Loss 1.6065e-01 (3.0571e-01) 
2023-05-27 04:11:05.448727: val Epoch: [2][48/72]	Time  2.585 ( 2.559)	Data  2.440 ( 2.343)	Loss 2.8956e-01 (3.0538e-01) 
2023-05-27 04:11:07.807380: val Epoch: [2][49/72]	Time  2.359 ( 2.555)	Data  2.151 ( 2.339)	Loss 4.1978e-01 (3.0767e-01) 
2023-05-27 04:11:10.698788: val Epoch: [2][50/72]	Time  2.891 ( 2.562)	Data  2.601 ( 2.344)	Loss 2.6223e-01 (3.0678e-01) 
2023-05-27 04:11:12.574281: val Epoch: [2][51/72]	Time  1.875 ( 2.549)	Data  1.708 ( 2.332)	Loss 1.6382e-01 (3.0403e-01) 
2023-05-27 04:11:15.771310: val Epoch: [2][52/72]	Time  3.197 ( 2.561)	Data  2.930 ( 2.344)	Loss 1.6355e-01 (3.0138e-01) 
2023-05-27 04:11:17.830624: val Epoch: [2][53/72]	Time  2.059 ( 2.552)	Data  1.778 ( 2.333)	Loss 3.0650e-01 (3.0148e-01) 
2023-05-27 04:11:20.751603: val Epoch: [2][54/72]	Time  2.921 ( 2.558)	Data  2.748 ( 2.341)	Loss 1.2943e-01 (2.9835e-01) 
2023-05-27 04:11:22.700966: val Epoch: [2][55/72]	Time  1.949 ( 2.548)	Data  1.696 ( 2.329)	Loss 1.6431e-01 (2.9595e-01) 
2023-05-27 04:11:25.685733: val Epoch: [2][56/72]	Time  2.985 ( 2.555)	Data  2.823 ( 2.338)	Loss 3.7543e-01 (2.9735e-01) 
2023-05-27 04:11:27.633745: val Epoch: [2][57/72]	Time  1.948 ( 2.545)	Data  1.761 ( 2.328)	Loss 1.5814e-01 (2.9495e-01) 
2023-05-27 04:11:30.610216: val Epoch: [2][58/72]	Time  2.976 ( 2.552)	Data  2.808 ( 2.336)	Loss 2.0838e-01 (2.9348e-01) 
2023-05-27 04:11:32.772674: val Epoch: [2][59/72]	Time  2.162 ( 2.546)	Data  1.884 ( 2.328)	Loss 2.4130e-01 (2.9261e-01) 
2023-05-27 04:11:35.578398: val Epoch: [2][60/72]	Time  2.806 ( 2.550)	Data  2.600 ( 2.333)	Loss 1.0935e-01 (2.8961e-01) 
2023-05-27 04:11:37.786853: val Epoch: [2][61/72]	Time  2.208 ( 2.544)	Data  2.044 ( 2.328)	Loss 2.2825e-01 (2.8862e-01) 
2023-05-27 04:11:40.633901: val Epoch: [2][62/72]	Time  2.847 ( 2.549)	Data  2.565 ( 2.332)	Loss 3.5613e-01 (2.8969e-01) 
2023-05-27 04:11:42.692784: val Epoch: [2][63/72]	Time  2.059 ( 2.542)	Data  1.837 ( 2.324)	Loss 1.5968e-01 (2.8766e-01) 
2023-05-27 04:11:45.811279: val Epoch: [2][64/72]	Time  3.118 ( 2.550)	Data  2.842 ( 2.332)	Loss 5.1146e-01 (2.9110e-01) 
2023-05-27 04:11:47.729437: val Epoch: [2][65/72]	Time  1.918 ( 2.541)	Data  1.771 ( 2.324)	Loss 2.1209e-01 (2.8990e-01) 
2023-05-27 04:11:50.640792: val Epoch: [2][66/72]	Time  2.911 ( 2.546)	Data  2.626 ( 2.328)	Loss 1.3416e-01 (2.8758e-01) 
2023-05-27 04:11:52.669201: val Epoch: [2][67/72]	Time  2.028 ( 2.539)	Data  1.760 ( 2.320)	Loss 1.3406e-01 (2.8532e-01) 
2023-05-27 04:11:55.297390: val Epoch: [2][68/72]	Time  2.628 ( 2.540)	Data  2.476 ( 2.322)	Loss 1.5944e-01 (2.8350e-01) 
2023-05-27 04:11:57.573675: val Epoch: [2][69/72]	Time  2.276 ( 2.536)	Data  2.112 ( 2.319)	Loss 1.5895e-01 (2.8172e-01) 
2023-05-27 04:12:00.525218: val Epoch: [2][70/72]	Time  2.952 ( 2.542)	Data  2.732 ( 2.325)	Loss 1.9138e-01 (2.8045e-01) 
2023-05-27 04:12:02.429056: val Epoch: [2][71/72]	Time  1.904 ( 2.533)	Data  1.618 ( 2.315)	Loss 1.5751e-01 (2.7874e-01) 
2023-05-27 04:12:02.721340: Epoch 2 :Val : ['ET : 0.5366904735565186', 'TC : 0.5634239912033081', 'WT : 0.6851374506950378'] 
2023-05-27 04:12:02.722342: Epoch 2 :Val : ['ET : 0.5366904735565186', 'TC : 0.5634239912033081', 'WT : 0.6851374506950378'] 
2023-05-27 04:12:02.727805: Val epoch done in 183.53744264099805 s 
2023-05-27 04:12:02.736997: Batches per epoch:  193 
2023-05-27 04:12:14.541853: train Epoch: [3][  0/193]	Time 11.805 (11.805)	Data 10.978 (10.978)	Loss 3.9491e-01 (3.9491e-01) 
2023-05-27 04:12:15.529952: train Epoch: [3][  1/193]	Time  0.988 ( 6.396)	Data  0.001 ( 5.490)	Loss 1.4419e-01 (2.6955e-01) 
2023-05-27 04:12:24.979526: train Epoch: [3][  2/193]	Time  9.450 ( 7.414)	Data  8.378 ( 6.452)	Loss 1.7631e-01 (2.3847e-01) 
2023-05-27 04:12:25.843137: train Epoch: [3][  3/193]	Time  0.864 ( 5.776)	Data  0.001 ( 4.840)	Loss 2.8896e-01 (2.5110e-01) 
2023-05-27 04:12:34.775578: train Epoch: [3][  4/193]	Time  8.932 ( 6.408)	Data  8.005 ( 5.473)	Loss 2.5059e-01 (2.5099e-01) 
2023-05-27 04:12:35.743617: train Epoch: [3][  5/193]	Time  0.968 ( 5.501)	Data  0.001 ( 4.561)	Loss 1.9866e-01 (2.4227e-01) 
2023-05-27 04:12:44.774021: train Epoch: [3][  6/193]	Time  9.030 ( 6.005)	Data  8.148 ( 5.073)	Loss 1.4454e-01 (2.2831e-01) 
2023-05-27 04:12:45.774796: train Epoch: [3][  7/193]	Time  1.001 ( 5.380)	Data  0.001 ( 4.439)	Loss 1.0287e-01 (2.1263e-01) 
2023-05-27 04:12:54.825611: train Epoch: [3][  8/193]	Time  9.051 ( 5.788)	Data  8.134 ( 4.850)	Loss 1.9869e-01 (2.1108e-01) 
2023-05-27 04:12:55.805846: train Epoch: [3][  9/193]	Time  0.980 ( 5.307)	Data  0.001 ( 4.365)	Loss 2.7745e-01 (2.1772e-01) 
2023-05-27 04:13:04.876500: train Epoch: [3][ 10/193]	Time  9.071 ( 5.649)	Data  8.225 ( 4.716)	Loss 1.4307e-01 (2.1093e-01) 
2023-05-27 04:13:05.819903: train Epoch: [3][ 11/193]	Time  0.943 ( 5.257)	Data  0.001 ( 4.323)	Loss 1.0151e-01 (2.0181e-01) 
2023-05-27 04:13:14.847677: train Epoch: [3][ 12/193]	Time  9.028 ( 5.547)	Data  8.217 ( 4.622)	Loss 1.6193e-01 (1.9875e-01) 
2023-05-27 04:13:15.721218: train Epoch: [3][ 13/193]	Time  0.874 ( 5.213)	Data  0.001 ( 4.292)	Loss 1.3003e-01 (1.9384e-01) 
2023-05-27 04:13:24.595288: train Epoch: [3][ 14/193]	Time  8.874 ( 5.457)	Data  8.039 ( 4.542)	Loss 1.3484e-01 (1.8990e-01) 
2023-05-27 04:13:25.516039: train Epoch: [3][ 15/193]	Time  0.921 ( 5.174)	Data  0.001 ( 4.258)	Loss 1.7368e-01 (1.8889e-01) 
2023-05-27 04:13:34.761742: train Epoch: [3][ 16/193]	Time  9.246 ( 5.413)	Data  8.305 ( 4.496)	Loss 1.7269e-01 (1.8794e-01) 
2023-05-27 04:13:35.679577: train Epoch: [3][ 17/193]	Time  0.918 ( 5.163)	Data  0.001 ( 4.247)	Loss 1.6082e-01 (1.8643e-01) 
2023-05-27 04:13:44.734424: train Epoch: [3][ 18/193]	Time  9.055 ( 5.368)	Data  7.980 ( 4.443)	Loss 2.1093e-01 (1.8772e-01) 
2023-05-27 04:13:45.766279: train Epoch: [3][ 19/193]	Time  1.032 ( 5.151)	Data  0.001 ( 4.221)	Loss 1.6006e-01 (1.8634e-01) 
2023-05-27 04:13:54.489942: train Epoch: [3][ 20/193]	Time  8.724 ( 5.322)	Data  7.845 ( 4.394)	Loss 2.0990e-01 (1.8746e-01) 
2023-05-27 04:13:55.339040: train Epoch: [3][ 21/193]	Time  0.849 ( 5.118)	Data  0.001 ( 4.194)	Loss 2.7943e-01 (1.9164e-01) 
2023-05-27 04:14:04.312398: train Epoch: [3][ 22/193]	Time  8.973 ( 5.286)	Data  8.103 ( 4.364)	Loss 1.7090e-01 (1.9074e-01) 
2023-05-27 04:14:05.303108: train Epoch: [3][ 23/193]	Time  0.991 ( 5.107)	Data  0.001 ( 4.182)	Loss 2.0558e-01 (1.9136e-01) 
2023-05-27 04:14:14.064890: train Epoch: [3][ 24/193]	Time  8.762 ( 5.253)	Data  7.882 ( 4.330)	Loss 1.2332e-01 (1.8864e-01) 
2023-05-27 04:14:14.987732: train Epoch: [3][ 25/193]	Time  0.923 ( 5.087)	Data  0.001 ( 4.164)	Loss 2.1872e-01 (1.8979e-01) 
2023-05-27 04:14:24.125471: train Epoch: [3][ 26/193]	Time  9.138 ( 5.237)	Data  8.238 ( 4.314)	Loss 1.0130e-01 (1.8651e-01) 
2023-05-27 04:14:25.079083: train Epoch: [3][ 27/193]	Time  0.954 ( 5.084)	Data  0.001 ( 4.160)	Loss 2.4835e-01 (1.8872e-01) 
2023-05-27 04:14:34.201797: train Epoch: [3][ 28/193]	Time  9.123 ( 5.223)	Data  8.190 ( 4.299)	Loss 1.5444e-01 (1.8754e-01) 
2023-05-27 04:14:35.225682: train Epoch: [3][ 29/193]	Time  1.024 ( 5.083)	Data  0.001 ( 4.156)	Loss 1.1979e-01 (1.8528e-01) 
2023-05-27 04:14:44.408924: train Epoch: [3][ 30/193]	Time  9.183 ( 5.215)	Data  8.286 ( 4.289)	Loss 2.0770e-01 (1.8601e-01) 
2023-05-27 04:14:45.337703: train Epoch: [3][ 31/193]	Time  0.929 ( 5.081)	Data  0.001 ( 4.155)	Loss 2.8536e-01 (1.8911e-01) 
2023-05-27 04:14:54.854775: train Epoch: [3][ 32/193]	Time  9.517 ( 5.216)	Data  8.487 ( 4.287)	Loss 1.9787e-01 (1.8938e-01) 
2023-05-27 04:14:55.947569: train Epoch: [3][ 33/193]	Time  1.093 ( 5.094)	Data  0.001 ( 4.160)	Loss 1.2994e-01 (1.8763e-01) 
2023-05-27 04:15:04.288284: train Epoch: [3][ 34/193]	Time  8.341 ( 5.187)	Data  7.402 ( 4.253)	Loss 2.8671e-01 (1.9046e-01) 
2023-05-27 04:15:05.259546: train Epoch: [3][ 35/193]	Time  0.971 ( 5.070)	Data  0.001 ( 4.135)	Loss 1.5399e-01 (1.8945e-01) 
2023-05-27 04:15:12.773566: train Epoch: [3][ 36/193]	Time  7.514 ( 5.136)	Data  6.596 ( 4.202)	Loss 1.4597e-01 (1.8827e-01) 
2023-05-27 04:15:13.600280: train Epoch: [3][ 37/193]	Time  0.827 ( 5.023)	Data  0.001 ( 4.091)	Loss 1.5953e-01 (1.8751e-01) 
2023-05-27 04:15:22.639872: train Epoch: [3][ 38/193]	Time  9.040 ( 5.126)	Data  8.103 ( 4.194)	Loss 2.5068e-01 (1.8913e-01) 
2023-05-27 04:15:23.552017: train Epoch: [3][ 39/193]	Time  0.912 ( 5.020)	Data  0.001 ( 4.089)	Loss 1.5679e-01 (1.8833e-01) 
2023-05-27 04:15:33.149730: train Epoch: [3][ 40/193]	Time  9.598 ( 5.132)	Data  8.687 ( 4.201)	Loss 1.7461e-01 (1.8799e-01) 
2023-05-27 04:15:34.242532: train Epoch: [3][ 41/193]	Time  1.093 ( 5.036)	Data  0.001 ( 4.101)	Loss 1.7981e-01 (1.8780e-01) 
2023-05-27 04:15:43.147507: train Epoch: [3][ 42/193]	Time  8.905 ( 5.126)	Data  8.006 ( 4.192)	Loss 1.5166e-01 (1.8696e-01) 
2023-05-27 04:15:44.179314: train Epoch: [3][ 43/193]	Time  1.032 ( 5.033)	Data  0.001 ( 4.097)	Loss 1.2451e-01 (1.8554e-01) 
2023-05-27 04:15:53.889509: train Epoch: [3][ 44/193]	Time  9.710 ( 5.137)	Data  8.758 ( 4.200)	Loss 1.2995e-01 (1.8430e-01) 
2023-05-27 04:15:54.912603: train Epoch: [3][ 45/193]	Time  1.023 ( 5.047)	Data  0.001 ( 4.109)	Loss 1.6348e-01 (1.8385e-01) 
2023-05-27 04:16:04.141361: train Epoch: [3][ 46/193]	Time  9.229 ( 5.136)	Data  8.352 ( 4.199)	Loss 1.3641e-01 (1.8284e-01) 
2023-05-27 04:16:05.094355: train Epoch: [3][ 47/193]	Time  0.953 ( 5.049)	Data  0.001 ( 4.112)	Loss 1.3877e-01 (1.8192e-01) 
2023-05-27 04:16:14.184608: train Epoch: [3][ 48/193]	Time  9.090 ( 5.132)	Data  8.235 ( 4.196)	Loss 3.3626e-01 (1.8507e-01) 
2023-05-27 04:16:15.077981: train Epoch: [3][ 49/193]	Time  0.893 ( 5.047)	Data  0.001 ( 4.112)	Loss 1.8337e-01 (1.8504e-01) 
2023-05-27 04:16:24.624328: train Epoch: [3][ 50/193]	Time  9.546 ( 5.135)	Data  8.609 ( 4.200)	Loss 2.0408e-01 (1.8541e-01) 
2023-05-27 04:16:25.448901: train Epoch: [3][ 51/193]	Time  0.825 ( 5.052)	Data  0.001 ( 4.119)	Loss 2.1200e-01 (1.8592e-01) 
2023-05-27 04:16:34.327061: train Epoch: [3][ 52/193]	Time  8.878 ( 5.124)	Data  7.914 ( 4.191)	Loss 1.5939e-01 (1.8542e-01) 
2023-05-27 04:16:35.288349: train Epoch: [3][ 53/193]	Time  0.961 ( 5.047)	Data  0.001 ( 4.113)	Loss 2.7715e-01 (1.8712e-01) 
2023-05-27 04:16:44.260059: train Epoch: [3][ 54/193]	Time  8.972 ( 5.119)	Data  7.925 ( 4.183)	Loss 1.6025e-01 (1.8663e-01) 
2023-05-27 04:16:45.190962: train Epoch: [3][ 55/193]	Time  0.931 ( 5.044)	Data  0.001 ( 4.108)	Loss 2.0087e-01 (1.8689e-01) 
2023-05-27 04:16:54.219415: train Epoch: [3][ 56/193]	Time  9.028 ( 5.114)	Data  8.157 ( 4.179)	Loss 1.7719e-01 (1.8672e-01) 
2023-05-27 04:16:55.094654: train Epoch: [3][ 57/193]	Time  0.875 ( 5.041)	Data  0.001 ( 4.107)	Loss 2.9544e-01 (1.8859e-01) 
2023-05-27 04:17:04.462742: train Epoch: [3][ 58/193]	Time  9.368 ( 5.114)	Data  8.416 ( 4.180)	Loss 2.3904e-01 (1.8944e-01) 
2023-05-27 04:17:05.409353: train Epoch: [3][ 59/193]	Time  0.947 ( 5.045)	Data  0.001 ( 4.110)	Loss 2.0207e-01 (1.8966e-01) 
2023-05-27 04:17:14.517270: train Epoch: [3][ 60/193]	Time  9.108 ( 5.111)	Data  8.163 ( 4.177)	Loss 1.7046e-01 (1.8934e-01) 
2023-05-27 04:17:15.425979: train Epoch: [3][ 61/193]	Time  0.909 ( 5.043)	Data  0.001 ( 4.110)	Loss 1.6265e-01 (1.8891e-01) 
2023-05-27 04:17:24.313143: train Epoch: [3][ 62/193]	Time  8.887 ( 5.104)	Data  7.932 ( 4.170)	Loss 1.0447e-01 (1.8757e-01) 
2023-05-27 04:17:25.388258: train Epoch: [3][ 63/193]	Time  1.075 ( 5.041)	Data  0.001 ( 4.105)	Loss 2.0046e-01 (1.8777e-01) 
2023-05-27 04:17:34.264028: train Epoch: [3][ 64/193]	Time  8.876 ( 5.100)	Data  7.889 ( 4.163)	Loss 1.5638e-01 (1.8729e-01) 
2023-05-27 04:17:35.197814: train Epoch: [3][ 65/193]	Time  0.934 ( 5.037)	Data  0.001 ( 4.100)	Loss 1.5400e-01 (1.8678e-01) 
2023-05-27 04:17:44.715018: train Epoch: [3][ 66/193]	Time  9.517 ( 5.104)	Data  8.563 ( 4.167)	Loss 2.1576e-01 (1.8722e-01) 
2023-05-27 04:17:45.707160: train Epoch: [3][ 67/193]	Time  0.992 ( 5.044)	Data  0.001 ( 4.106)	Loss 3.1320e-01 (1.8907e-01) 
2023-05-27 04:17:54.728397: train Epoch: [3][ 68/193]	Time  9.021 ( 5.101)	Data  8.120 ( 4.164)	Loss 1.7149e-01 (1.8881e-01) 
2023-05-27 04:17:55.600733: train Epoch: [3][ 69/193]	Time  0.872 ( 5.041)	Data  0.001 ( 4.104)	Loss 3.4369e-01 (1.9103e-01) 
2023-05-27 04:18:04.554806: train Epoch: [3][ 70/193]	Time  8.954 ( 5.096)	Data  8.032 ( 4.160)	Loss 1.7593e-01 (1.9081e-01) 
2023-05-27 04:18:05.568835: train Epoch: [3][ 71/193]	Time  1.014 ( 5.039)	Data  0.001 ( 4.102)	Loss 1.3119e-01 (1.8999e-01) 
2023-05-27 04:18:12.613991: train Epoch: [3][ 72/193]	Time  7.045 ( 5.067)	Data  6.163 ( 4.130)	Loss 1.6152e-01 (1.8960e-01) 
2023-05-27 04:18:13.563074: train Epoch: [3][ 73/193]	Time  0.949 ( 5.011)	Data  0.001 ( 4.074)	Loss 2.8524e-01 (1.9089e-01) 
2023-05-27 04:18:22.291167: train Epoch: [3][ 74/193]	Time  8.728 ( 5.061)	Data  7.862 ( 4.125)	Loss 1.4986e-01 (1.9034e-01) 
2023-05-27 04:18:23.240140: train Epoch: [3][ 75/193]	Time  0.949 ( 5.007)	Data  0.001 ( 4.071)	Loss 2.1381e-01 (1.9065e-01) 
2023-05-27 04:18:32.584805: train Epoch: [3][ 76/193]	Time  9.345 ( 5.063)	Data  8.492 ( 4.128)	Loss 1.6023e-01 (1.9026e-01) 
2023-05-27 04:18:33.610659: train Epoch: [3][ 77/193]	Time  1.026 ( 5.011)	Data  0.001 ( 4.075)	Loss 1.9961e-01 (1.9038e-01) 
2023-05-27 04:18:42.614876: train Epoch: [3][ 78/193]	Time  9.004 ( 5.062)	Data  8.169 ( 4.127)	Loss 1.2837e-01 (1.8959e-01) 
2023-05-27 04:18:43.593865: train Epoch: [3][ 79/193]	Time  0.979 ( 5.011)	Data  0.001 ( 4.075)	Loss 3.1366e-01 (1.9114e-01) 
2023-05-27 04:18:52.599106: train Epoch: [3][ 80/193]	Time  9.005 ( 5.060)	Data  8.142 ( 4.125)	Loss 1.1549e-01 (1.9021e-01) 
2023-05-27 04:18:53.548751: train Epoch: [3][ 81/193]	Time  0.950 ( 5.010)	Data  0.001 ( 4.075)	Loss 2.2954e-01 (1.9069e-01) 
2023-05-27 04:19:03.282431: train Epoch: [3][ 82/193]	Time  9.734 ( 5.067)	Data  8.819 ( 4.132)	Loss 1.2066e-01 (1.8984e-01) 
2023-05-27 04:19:04.142389: train Epoch: [3][ 83/193]	Time  0.860 ( 5.017)	Data  0.001 ( 4.083)	Loss 2.8366e-01 (1.9096e-01) 
2023-05-27 04:19:13.399407: train Epoch: [3][ 84/193]	Time  9.257 ( 5.067)	Data  8.371 ( 4.134)	Loss 1.8748e-01 (1.9092e-01) 
2023-05-27 04:19:14.330510: train Epoch: [3][ 85/193]	Time  0.931 ( 5.019)	Data  0.001 ( 4.086)	Loss 1.8671e-01 (1.9087e-01) 
2023-05-27 04:19:23.935500: train Epoch: [3][ 86/193]	Time  9.605 ( 5.071)	Data  8.615 ( 4.138)	Loss 1.5383e-01 (1.9044e-01) 
2023-05-27 04:19:24.914969: train Epoch: [3][ 87/193]	Time  0.979 ( 5.025)	Data  0.001 ( 4.091)	Loss 2.1499e-01 (1.9072e-01) 
2023-05-27 04:19:33.613489: train Epoch: [3][ 88/193]	Time  8.699 ( 5.066)	Data  7.795 ( 4.132)	Loss 2.1735e-01 (1.9102e-01) 
2023-05-27 04:19:34.640707: train Epoch: [3][ 89/193]	Time  1.027 ( 5.021)	Data  0.001 ( 4.086)	Loss 5.0063e-01 (1.9446e-01) 
2023-05-27 04:19:44.112058: train Epoch: [3][ 90/193]	Time  9.471 ( 5.070)	Data  8.580 ( 4.136)	Loss 1.9495e-01 (1.9447e-01) 
2023-05-27 04:19:45.029293: train Epoch: [3][ 91/193]	Time  0.917 ( 5.025)	Data  0.001 ( 4.091)	Loss 1.1983e-01 (1.9366e-01) 
2023-05-27 04:19:54.391658: train Epoch: [3][ 92/193]	Time  9.362 ( 5.072)	Data  8.309 ( 4.136)	Loss 2.0889e-01 (1.9382e-01) 
2023-05-27 04:19:55.352903: train Epoch: [3][ 93/193]	Time  0.961 ( 5.028)	Data  0.001 ( 4.092)	Loss 1.6416e-01 (1.9351e-01) 
2023-05-27 04:20:03.709728: train Epoch: [3][ 94/193]	Time  8.357 ( 5.063)	Data  7.501 ( 4.128)	Loss 2.1090e-01 (1.9369e-01) 
2023-05-27 04:20:04.624494: train Epoch: [3][ 95/193]	Time  0.915 ( 5.020)	Data  0.001 ( 4.085)	Loss 2.1521e-01 (1.9391e-01) 
2023-05-27 04:20:14.136171: train Epoch: [3][ 96/193]	Time  9.512 ( 5.066)	Data  8.626 ( 4.132)	Loss 1.7627e-01 (1.9373e-01) 
2023-05-27 04:20:14.980734: train Epoch: [3][ 97/193]	Time  0.845 ( 5.023)	Data  0.001 ( 4.090)	Loss 2.6886e-01 (1.9450e-01) 
2023-05-27 04:20:24.184160: train Epoch: [3][ 98/193]	Time  9.203 ( 5.065)	Data  8.252 ( 4.132)	Loss 3.9831e-01 (1.9656e-01) 
2023-05-27 04:20:25.080355: train Epoch: [3][ 99/193]	Time  0.896 ( 5.023)	Data  0.001 ( 4.090)	Loss 1.5602e-01 (1.9615e-01) 
2023-05-27 04:20:34.082983: train Epoch: [3][100/193]	Time  9.003 ( 5.063)	Data  8.156 ( 4.131)	Loss 1.8524e-01 (1.9604e-01) 
2023-05-27 04:20:34.988529: train Epoch: [3][101/193]	Time  0.906 ( 5.022)	Data  0.001 ( 4.090)	Loss 1.4116e-01 (1.9550e-01) 
2023-05-27 04:20:43.468650: train Epoch: [3][102/193]	Time  8.480 ( 5.056)	Data  7.597 ( 4.124)	Loss 2.8685e-01 (1.9639e-01) 
2023-05-27 04:20:44.423178: train Epoch: [3][103/193]	Time  0.955 ( 5.016)	Data  0.001 ( 4.085)	Loss 5.6490e-01 (1.9993e-01) 
2023-05-27 04:20:52.061892: train Epoch: [3][104/193]	Time  7.639 ( 5.041)	Data  6.774 ( 4.110)	Loss 3.2341e-01 (2.0111e-01) 
2023-05-27 04:20:52.961209: train Epoch: [3][105/193]	Time  0.899 ( 5.002)	Data  0.001 ( 4.071)	Loss 3.2607e-01 (2.0229e-01) 
2023-05-27 04:21:02.445126: train Epoch: [3][106/193]	Time  9.484 ( 5.044)	Data  8.426 ( 4.112)	Loss 3.0590e-01 (2.0326e-01) 
2023-05-27 04:21:03.491845: train Epoch: [3][107/193]	Time  1.047 ( 5.007)	Data  0.001 ( 4.074)	Loss 3.4793e-01 (2.0460e-01) 
2023-05-27 04:21:12.341138: train Epoch: [3][108/193]	Time  8.849 ( 5.042)	Data  7.931 ( 4.109)	Loss 2.0020e-01 (2.0456e-01) 
2023-05-27 04:21:13.357898: train Epoch: [3][109/193]	Time  1.017 ( 5.006)	Data  0.001 ( 4.072)	Loss 3.3909e-01 (2.0578e-01) 
2023-05-27 04:21:21.776269: train Epoch: [3][110/193]	Time  8.418 ( 5.036)	Data  7.522 ( 4.103)	Loss 2.2690e-01 (2.0597e-01) 
2023-05-27 04:21:22.651316: train Epoch: [3][111/193]	Time  0.875 ( 4.999)	Data  0.001 ( 4.067)	Loss 1.6003e-01 (2.0556e-01) 
2023-05-27 04:21:32.633519: train Epoch: [3][112/193]	Time  9.982 ( 5.043)	Data  8.986 ( 4.110)	Loss 1.5907e-01 (2.0515e-01) 
2023-05-27 04:21:33.636437: train Epoch: [3][113/193]	Time  1.003 ( 5.008)	Data  0.001 ( 4.074)	Loss 3.1144e-01 (2.0608e-01) 
2023-05-27 04:21:42.618916: train Epoch: [3][114/193]	Time  8.982 ( 5.042)	Data  8.129 ( 4.109)	Loss 1.4085e-01 (2.0551e-01) 
2023-05-27 04:21:43.593680: train Epoch: [3][115/193]	Time  0.975 ( 5.007)	Data  0.001 ( 4.074)	Loss 2.2537e-01 (2.0568e-01) 
2023-05-27 04:21:52.973616: train Epoch: [3][116/193]	Time  9.380 ( 5.045)	Data  8.437 ( 4.111)	Loss 2.4976e-01 (2.0606e-01) 
2023-05-27 04:21:53.974348: train Epoch: [3][117/193]	Time  1.001 ( 5.010)	Data  0.001 ( 4.076)	Loss 1.3535e-01 (2.0546e-01) 
2023-05-27 04:22:03.116644: train Epoch: [3][118/193]	Time  9.142 ( 5.045)	Data  8.189 ( 4.111)	Loss 1.4189e-01 (2.0493e-01) 
2023-05-27 04:22:04.139163: train Epoch: [3][119/193]	Time  1.023 ( 5.012)	Data  0.001 ( 4.077)	Loss 1.8284e-01 (2.0474e-01) 
2023-05-27 04:22:13.083503: train Epoch: [3][120/193]	Time  8.944 ( 5.044)	Data  7.967 ( 4.109)	Loss 1.3811e-01 (2.0419e-01) 
2023-05-27 04:22:14.104823: train Epoch: [3][121/193]	Time  1.021 ( 5.011)	Data  0.001 ( 4.075)	Loss 1.4731e-01 (2.0373e-01) 
2023-05-27 04:22:23.427693: train Epoch: [3][122/193]	Time  9.323 ( 5.046)	Data  8.389 ( 4.110)	Loss 1.5427e-01 (2.0333e-01) 
2023-05-27 04:22:24.356933: train Epoch: [3][123/193]	Time  0.929 ( 5.013)	Data  0.001 ( 4.077)	Loss 1.7743e-01 (2.0312e-01) 
2023-05-27 04:22:33.807079: train Epoch: [3][124/193]	Time  9.450 ( 5.049)	Data  8.562 ( 4.113)	Loss 2.6353e-01 (2.0360e-01) 
2023-05-27 04:22:34.742772: train Epoch: [3][125/193]	Time  0.936 ( 5.016)	Data  0.001 ( 4.080)	Loss 1.4212e-01 (2.0311e-01) 
2023-05-27 04:22:44.115431: train Epoch: [3][126/193]	Time  9.373 ( 5.050)	Data  8.478 ( 4.115)	Loss 2.2301e-01 (2.0327e-01) 
2023-05-27 04:22:44.937748: train Epoch: [3][127/193]	Time  0.822 ( 5.017)	Data  0.001 ( 4.083)	Loss 1.4820e-01 (2.0284e-01) 
2023-05-27 04:22:54.734681: train Epoch: [3][128/193]	Time  9.797 ( 5.054)	Data  8.838 ( 4.120)	Loss 1.5305e-01 (2.0245e-01) 
2023-05-27 04:22:55.692889: train Epoch: [3][129/193]	Time  0.958 ( 5.023)	Data  0.001 ( 4.088)	Loss 1.4179e-01 (2.0199e-01) 
2023-05-27 04:23:04.834454: train Epoch: [3][130/193]	Time  9.142 ( 5.054)	Data  8.287 ( 4.120)	Loss 1.1365e-01 (2.0131e-01) 
2023-05-27 04:23:05.625424: train Epoch: [3][131/193]	Time  0.791 ( 5.022)	Data  0.001 ( 4.089)	Loss 2.7209e-01 (2.0185e-01) 
2023-05-27 04:23:15.111511: train Epoch: [3][132/193]	Time  9.486 ( 5.055)	Data  8.632 ( 4.123)	Loss 1.6339e-01 (2.0156e-01) 
2023-05-27 04:23:16.163584: train Epoch: [3][133/193]	Time  1.052 ( 5.026)	Data  0.001 ( 4.092)	Loss 1.1787e-01 (2.0093e-01) 
2023-05-27 04:23:25.265488: train Epoch: [3][134/193]	Time  9.102 ( 5.056)	Data  8.226 ( 4.123)	Loss 1.0783e-01 (2.0024e-01) 
2023-05-27 04:23:26.147484: train Epoch: [3][135/193]	Time  0.882 ( 5.025)	Data  0.001 ( 4.093)	Loss 2.3357e-01 (2.0049e-01) 
2023-05-27 04:23:35.307982: train Epoch: [3][136/193]	Time  9.161 ( 5.055)	Data  8.168 ( 4.122)	Loss 1.2240e-01 (1.9992e-01) 
2023-05-27 04:23:36.242423: train Epoch: [3][137/193]	Time  0.934 ( 5.025)	Data  0.001 ( 4.092)	Loss 1.5798e-01 (1.9962e-01) 
2023-05-27 04:23:45.608468: train Epoch: [3][138/193]	Time  9.366 ( 5.057)	Data  8.377 ( 4.123)	Loss 1.5529e-01 (1.9930e-01) 
2023-05-27 04:23:46.495334: train Epoch: [3][139/193]	Time  0.887 ( 5.027)	Data  0.001 ( 4.094)	Loss 1.2216e-01 (1.9875e-01) 
2023-05-27 04:23:55.272189: train Epoch: [3][140/193]	Time  8.777 ( 5.053)	Data  7.811 ( 4.120)	Loss 2.0942e-01 (1.9882e-01) 
2023-05-27 04:23:56.261889: train Epoch: [3][141/193]	Time  0.990 ( 5.025)	Data  0.001 ( 4.091)	Loss 8.8470e-02 (1.9804e-01) 
2023-05-27 04:24:04.988372: train Epoch: [3][142/193]	Time  8.726 ( 5.051)	Data  7.910 ( 4.118)	Loss 2.7846e-01 (1.9861e-01) 
2023-05-27 04:24:05.803652: train Epoch: [3][143/193]	Time  0.815 ( 5.021)	Data  0.001 ( 4.089)	Loss 2.2126e-01 (1.9876e-01) 
2023-05-27 04:24:14.686076: train Epoch: [3][144/193]	Time  8.882 ( 5.048)	Data  8.292 ( 4.118)	Loss 2.3727e-01 (1.9903e-01) 
2023-05-27 04:24:15.267700: train Epoch: [3][145/193]	Time  0.582 ( 5.017)	Data  0.001 ( 4.090)	Loss 1.5569e-01 (1.9873e-01) 
2023-05-27 04:24:24.790823: train Epoch: [3][146/193]	Time  9.523 ( 5.048)	Data  8.645 ( 4.121)	Loss 2.4689e-01 (1.9906e-01) 
2023-05-27 04:24:25.670105: train Epoch: [3][147/193]	Time  0.879 ( 5.020)	Data  0.001 ( 4.093)	Loss 4.1207e-01 (2.0050e-01) 
2023-05-27 04:24:35.594937: train Epoch: [3][148/193]	Time  9.925 ( 5.053)	Data  8.926 ( 4.126)	Loss 1.7501e-01 (2.0033e-01) 
2023-05-27 04:24:36.496401: train Epoch: [3][149/193]	Time  0.901 ( 5.025)	Data  0.001 ( 4.098)	Loss 1.2899e-01 (1.9985e-01) 
2023-05-27 04:24:45.736926: train Epoch: [3][150/193]	Time  9.241 ( 5.053)	Data  8.239 ( 4.126)	Loss 1.6462e-01 (1.9962e-01) 
2023-05-27 04:24:46.580969: train Epoch: [3][151/193]	Time  0.844 ( 5.025)	Data  0.001 ( 4.098)	Loss 1.2736e-01 (1.9914e-01) 
2023-05-27 04:24:55.746136: train Epoch: [3][152/193]	Time  9.165 ( 5.052)	Data  8.215 ( 4.125)	Loss 1.3424e-01 (1.9872e-01) 
2023-05-27 04:24:56.747964: train Epoch: [3][153/193]	Time  1.002 ( 5.026)	Data  0.001 ( 4.099)	Loss 1.2159e-01 (1.9822e-01) 
2023-05-27 04:25:06.007460: train Epoch: [3][154/193]	Time  9.259 ( 5.053)	Data  8.298 ( 4.126)	Loss 1.5416e-01 (1.9793e-01) 
2023-05-27 04:25:06.777274: train Epoch: [3][155/193]	Time  0.770 ( 5.026)	Data  0.001 ( 4.099)	Loss 1.3271e-01 (1.9752e-01) 
2023-05-27 04:25:16.051991: train Epoch: [3][156/193]	Time  9.275 ( 5.053)	Data  8.303 ( 4.126)	Loss 1.7696e-01 (1.9739e-01) 
2023-05-27 04:25:16.980585: train Epoch: [3][157/193]	Time  0.929 ( 5.027)	Data  0.001 ( 4.100)	Loss 1.2771e-01 (1.9694e-01) 
2023-05-27 04:25:26.562529: train Epoch: [3][158/193]	Time  9.582 ( 5.056)	Data  8.534 ( 4.128)	Loss 1.0638e-01 (1.9637e-01) 
2023-05-27 04:25:27.605994: train Epoch: [3][159/193]	Time  1.043 ( 5.030)	Data  0.001 ( 4.102)	Loss 1.4582e-01 (1.9606e-01) 
2023-05-27 04:25:36.203809: train Epoch: [3][160/193]	Time  8.598 ( 5.053)	Data  7.683 ( 4.124)	Loss 1.0086e-01 (1.9547e-01) 
2023-05-27 04:25:37.049281: train Epoch: [3][161/193]	Time  0.845 ( 5.027)	Data  0.001 ( 4.099)	Loss 1.4973e-01 (1.9519e-01) 
2023-05-27 04:25:46.449607: train Epoch: [3][162/193]	Time  9.400 ( 5.053)	Data  8.345 ( 4.125)	Loss 1.3236e-01 (1.9480e-01) 
2023-05-27 04:25:47.431987: train Epoch: [3][163/193]	Time  0.982 ( 5.029)	Data  0.001 ( 4.100)	Loss 2.6875e-01 (1.9525e-01) 
2023-05-27 04:25:56.182028: train Epoch: [3][164/193]	Time  8.750 ( 5.051)	Data  7.837 ( 4.122)	Loss 1.6265e-01 (1.9505e-01) 
2023-05-27 04:25:57.099423: train Epoch: [3][165/193]	Time  0.917 ( 5.026)	Data  0.001 ( 4.097)	Loss 1.0638e-01 (1.9452e-01) 
2023-05-27 04:26:06.531887: train Epoch: [3][166/193]	Time  9.432 ( 5.053)	Data  8.499 ( 4.124)	Loss 1.7109e-01 (1.9438e-01) 
2023-05-27 04:26:07.410872: train Epoch: [3][167/193]	Time  0.879 ( 5.028)	Data  0.001 ( 4.099)	Loss 2.1790e-01 (1.9452e-01) 
2023-05-27 04:26:17.183639: train Epoch: [3][168/193]	Time  9.773 ( 5.056)	Data  8.691 ( 4.126)	Loss 1.5845e-01 (1.9431e-01) 
2023-05-27 04:26:18.244113: train Epoch: [3][169/193]	Time  1.060 ( 5.032)	Data  0.001 ( 4.102)	Loss 5.7473e-01 (1.9654e-01) 
2023-05-27 04:26:26.778202: train Epoch: [3][170/193]	Time  8.534 ( 5.053)	Data  7.654 ( 4.123)	Loss 2.4050e-01 (1.9680e-01) 
2023-05-27 04:26:27.678596: train Epoch: [3][171/193]	Time  0.900 ( 5.029)	Data  0.001 ( 4.099)	Loss 1.8979e-01 (1.9676e-01) 
2023-05-27 04:26:36.525019: train Epoch: [3][172/193]	Time  8.846 ( 5.051)	Data  7.908 ( 4.121)	Loss 1.2964e-01 (1.9637e-01) 
2023-05-27 04:26:37.358274: train Epoch: [3][173/193]	Time  0.833 ( 5.027)	Data  0.001 ( 4.097)	Loss 1.5027e-01 (1.9611e-01) 
2023-05-27 04:26:46.682247: train Epoch: [3][174/193]	Time  9.324 ( 5.051)	Data  8.412 ( 4.122)	Loss 2.9947e-01 (1.9670e-01) 
2023-05-27 04:26:47.688651: train Epoch: [3][175/193]	Time  1.006 ( 5.028)	Data  0.001 ( 4.099)	Loss 1.7098e-01 (1.9655e-01) 
2023-05-27 04:26:57.031677: train Epoch: [3][176/193]	Time  9.343 ( 5.053)	Data  8.314 ( 4.122)	Loss 2.1752e-01 (1.9667e-01) 
2023-05-27 04:26:57.874416: train Epoch: [3][177/193]	Time  0.843 ( 5.029)	Data  0.001 ( 4.099)	Loss 2.0762e-01 (1.9673e-01) 
2023-05-27 04:27:07.113446: train Epoch: [3][178/193]	Time  9.239 ( 5.052)	Data  8.333 ( 4.123)	Loss 2.0632e-01 (1.9678e-01) 
2023-05-27 04:27:08.123720: train Epoch: [3][179/193]	Time  1.010 ( 5.030)	Data  0.001 ( 4.100)	Loss 1.9697e-01 (1.9679e-01) 
2023-05-27 04:27:16.905063: train Epoch: [3][180/193]	Time  8.781 ( 5.051)	Data  7.966 ( 4.121)	Loss 1.4261e-01 (1.9649e-01) 
2023-05-27 04:27:17.826205: train Epoch: [3][181/193]	Time  0.921 ( 5.028)	Data  0.001 ( 4.099)	Loss 2.4457e-01 (1.9675e-01) 
2023-05-27 04:27:26.592354: train Epoch: [3][182/193]	Time  8.766 ( 5.048)	Data  7.858 ( 4.119)	Loss 1.1850e-01 (1.9632e-01) 
2023-05-27 04:27:27.624879: train Epoch: [3][183/193]	Time  1.033 ( 5.027)	Data  0.001 ( 4.097)	Loss 1.5020e-01 (1.9607e-01) 
2023-05-27 04:27:36.963249: train Epoch: [3][184/193]	Time  9.338 ( 5.050)	Data  8.328 ( 4.120)	Loss 1.4299e-01 (1.9579e-01) 
2023-05-27 04:27:37.814096: train Epoch: [3][185/193]	Time  0.851 ( 5.027)	Data  0.001 ( 4.098)	Loss 1.5715e-01 (1.9558e-01) 
2023-05-27 04:27:47.184571: train Epoch: [3][186/193]	Time  9.370 ( 5.051)	Data  8.340 ( 4.120)	Loss 2.1108e-01 (1.9566e-01) 
2023-05-27 04:27:48.206727: train Epoch: [3][187/193]	Time  1.022 ( 5.029)	Data  0.001 ( 4.098)	Loss 2.8184e-01 (1.9612e-01) 
2023-05-27 04:27:57.139356: train Epoch: [3][188/193]	Time  8.933 ( 5.050)	Data  7.825 ( 4.118)	Loss 1.1835e-01 (1.9571e-01) 
2023-05-27 04:27:58.117720: train Epoch: [3][189/193]	Time  0.978 ( 5.028)	Data  0.001 ( 4.096)	Loss 1.4672e-01 (1.9545e-01) 
2023-05-27 04:28:06.706049: train Epoch: [3][190/193]	Time  8.588 ( 5.047)	Data  7.637 ( 4.115)	Loss 7.7506e-02 (1.9483e-01) 
2023-05-27 04:28:07.802966: train Epoch: [3][191/193]	Time  1.097 ( 5.026)	Data  0.001 ( 4.094)	Loss 1.6129e-01 (1.9466e-01) 
2023-05-27 04:28:15.732395: train Epoch: [3][192/193]	Time  7.929 ( 5.041)	Data  7.123 ( 4.109)	Loss 1.2377e-01 (1.9429e-01) 
2023-05-27 04:28:15.893802: Train Epoch done in 973.1568595909921 s 
2023-05-27 04:28:22.800954: val Epoch: [3][ 0/72]	Time  5.590 ( 5.590)	Data  5.297 ( 5.297)	Loss 9.9226e-02 (9.9226e-02) 
2023-05-27 04:28:23.198986: val Epoch: [3][ 1/72]	Time  0.398 ( 2.994)	Data  0.105 ( 2.701)	Loss 6.8683e-01 (3.9303e-01) 
2023-05-27 04:28:28.073941: val Epoch: [3][ 2/72]	Time  4.875 ( 3.621)	Data  4.627 ( 3.343)	Loss 1.9114e-01 (3.2573e-01) 
2023-05-27 04:28:28.310373: val Epoch: [3][ 3/72]	Time  0.236 ( 2.775)	Data  0.049 ( 2.519)	Loss 1.5435e-01 (2.8289e-01) 
2023-05-27 04:28:33.011945: val Epoch: [3][ 4/72]	Time  4.702 ( 3.160)	Data  4.548 ( 2.925)	Loss 1.6625e-01 (2.5956e-01) 
2023-05-27 04:28:33.417251: val Epoch: [3][ 5/72]	Time  0.405 ( 2.701)	Data  0.156 ( 2.464)	Loss 9.4786e-02 (2.3210e-01) 
2023-05-27 04:28:38.136270: val Epoch: [3][ 6/72]	Time  4.719 ( 2.989)	Data  4.556 ( 2.762)	Loss 1.0291e-01 (2.1364e-01) 
2023-05-27 04:28:38.351032: val Epoch: [3][ 7/72]	Time  0.215 ( 2.642)	Data  0.001 ( 2.417)	Loss 1.0549e-01 (2.0012e-01) 
2023-05-27 04:28:43.165804: val Epoch: [3][ 8/72]	Time  4.815 ( 2.884)	Data  4.546 ( 2.654)	Loss 1.0129e-01 (1.8914e-01) 
2023-05-27 04:28:43.398125: val Epoch: [3][ 9/72]	Time  0.232 ( 2.619)	Data  0.001 ( 2.388)	Loss 4.0482e-01 (2.1071e-01) 
2023-05-27 04:28:48.228889: val Epoch: [3][10/72]	Time  4.831 ( 2.820)	Data  4.602 ( 2.590)	Loss 1.1924e-01 (2.0239e-01) 
2023-05-27 04:28:48.383460: val Epoch: [3][11/72]	Time  0.155 ( 2.598)	Data  0.000 ( 2.374)	Loss 9.7852e-02 (1.9368e-01) 
2023-05-27 04:28:53.363799: val Epoch: [3][12/72]	Time  4.980 ( 2.781)	Data  4.748 ( 2.556)	Loss 1.9437e-01 (1.9373e-01) 
2023-05-27 04:28:53.598213: val Epoch: [3][13/72]	Time  0.234 ( 2.599)	Data  0.001 ( 2.374)	Loss 1.9052e-01 (1.9350e-01) 
2023-05-27 04:28:58.512738: val Epoch: [3][14/72]	Time  4.915 ( 2.753)	Data  4.641 ( 2.525)	Loss 1.8369e-01 (1.9285e-01) 
2023-05-27 04:28:58.788169: val Epoch: [3][15/72]	Time  0.275 ( 2.599)	Data  0.001 ( 2.367)	Loss 1.0901e-01 (1.8761e-01) 
2023-05-27 04:29:03.495092: val Epoch: [3][16/72]	Time  4.707 ( 2.723)	Data  4.549 ( 2.496)	Loss 1.5552e-01 (1.8572e-01) 
2023-05-27 04:29:03.749978: val Epoch: [3][17/72]	Time  0.255 ( 2.585)	Data  0.000 ( 2.357)	Loss 2.5091e-01 (1.8934e-01) 
2023-05-27 04:29:08.689933: val Epoch: [3][18/72]	Time  4.940 ( 2.709)	Data  4.666 ( 2.479)	Loss 1.9346e-01 (1.8956e-01) 
2023-05-27 04:29:08.988118: val Epoch: [3][19/72]	Time  0.298 ( 2.589)	Data  0.001 ( 2.355)	Loss 1.8208e-01 (1.8919e-01) 
2023-05-27 04:29:13.732265: val Epoch: [3][20/72]	Time  4.744 ( 2.691)	Data  4.578 ( 2.461)	Loss 3.5344e-01 (1.9701e-01) 
2023-05-27 04:29:14.045961: val Epoch: [3][21/72]	Time  0.314 ( 2.583)	Data  0.001 ( 2.349)	Loss 4.4054e-01 (2.0808e-01) 
2023-05-27 04:29:19.051838: val Epoch: [3][22/72]	Time  5.006 ( 2.689)	Data  4.845 ( 2.457)	Loss 2.3818e-01 (2.0939e-01) 
2023-05-27 04:29:19.297727: val Epoch: [3][23/72]	Time  0.246 ( 2.587)	Data  0.001 ( 2.355)	Loss 1.0663e-01 (2.0510e-01) 
2023-05-27 04:29:24.206465: val Epoch: [3][24/72]	Time  4.909 ( 2.680)	Data  4.632 ( 2.446)	Loss 1.3934e-01 (2.0247e-01) 
2023-05-27 04:29:24.514119: val Epoch: [3][25/72]	Time  0.308 ( 2.589)	Data  0.000 ( 2.352)	Loss 1.3316e-01 (1.9981e-01) 
2023-05-27 04:29:29.178412: val Epoch: [3][26/72]	Time  4.664 ( 2.665)	Data  4.497 ( 2.431)	Loss 1.2965e-01 (1.9721e-01) 
2023-05-27 04:29:29.431052: val Epoch: [3][27/72]	Time  0.253 ( 2.579)	Data  0.001 ( 2.345)	Loss 1.0940e-01 (1.9407e-01) 
2023-05-27 04:29:34.147156: val Epoch: [3][28/72]	Time  4.716 ( 2.653)	Data  4.547 ( 2.420)	Loss 1.3286e-01 (1.9196e-01) 
2023-05-27 04:29:34.386234: val Epoch: [3][29/72]	Time  0.239 ( 2.572)	Data  0.001 ( 2.340)	Loss 8.8329e-02 (1.8851e-01) 
2023-05-27 04:29:39.277287: val Epoch: [3][30/72]	Time  4.891 ( 2.647)	Data  4.615 ( 2.413)	Loss 2.6495e-01 (1.9097e-01) 
2023-05-27 04:29:39.441104: val Epoch: [3][31/72]	Time  0.164 ( 2.570)	Data  0.000 ( 2.338)	Loss 2.1621e-01 (1.9176e-01) 
2023-05-27 04:29:44.325429: val Epoch: [3][32/72]	Time  4.884 ( 2.640)	Data  4.719 ( 2.410)	Loss 1.5404e-01 (1.9062e-01) 
2023-05-27 04:29:44.567309: val Epoch: [3][33/72]	Time  0.242 ( 2.569)	Data  0.001 ( 2.339)	Loss 3.0257e-01 (1.9391e-01) 
2023-05-27 04:29:49.614097: val Epoch: [3][34/72]	Time  5.047 ( 2.640)	Data  4.790 ( 2.409)	Loss 5.6741e-01 (2.0458e-01) 
2023-05-27 04:29:49.786327: val Epoch: [3][35/72]	Time  0.172 ( 2.572)	Data  0.001 ( 2.342)	Loss 2.5040e-01 (2.0586e-01) 
2023-05-27 04:29:54.720555: val Epoch: [3][36/72]	Time  4.934 ( 2.635)	Data  4.766 ( 2.408)	Loss 4.3469e-01 (2.1204e-01) 
2023-05-27 04:29:54.959368: val Epoch: [3][37/72]	Time  0.239 ( 2.572)	Data  0.000 ( 2.344)	Loss 1.4282e-01 (2.1022e-01) 
2023-05-27 04:29:59.952504: val Epoch: [3][38/72]	Time  4.993 ( 2.634)	Data  4.702 ( 2.405)	Loss 9.5352e-02 (2.0727e-01) 
2023-05-27 04:30:00.238765: val Epoch: [3][39/72]	Time  0.286 ( 2.576)	Data  0.001 ( 2.345)	Loss 9.0096e-02 (2.0434e-01) 
2023-05-27 04:30:04.961577: val Epoch: [3][40/72]	Time  4.723 ( 2.628)	Data  4.478 ( 2.397)	Loss 1.7539e-01 (2.0364e-01) 
2023-05-27 04:30:05.133283: val Epoch: [3][41/72]	Time  0.172 ( 2.570)	Data  0.000 ( 2.340)	Loss 5.6624e-01 (2.1227e-01) 
2023-05-27 04:30:09.993057: val Epoch: [3][42/72]	Time  4.860 ( 2.623)	Data  4.710 ( 2.395)	Loss 1.7655e-01 (2.1144e-01) 
2023-05-27 04:30:10.248489: val Epoch: [3][43/72]	Time  0.255 ( 2.569)	Data  0.001 ( 2.340)	Loss 2.9352e-01 (2.1331e-01) 
2023-05-27 04:30:14.871917: val Epoch: [3][44/72]	Time  4.623 ( 2.615)	Data  4.461 ( 2.388)	Loss 1.9815e-01 (2.1297e-01) 
2023-05-27 04:30:15.165925: val Epoch: [3][45/72]	Time  0.294 ( 2.564)	Data  0.001 ( 2.336)	Loss 4.3790e-01 (2.1786e-01) 
2023-05-27 04:30:19.885713: val Epoch: [3][46/72]	Time  4.720 ( 2.610)	Data  4.548 ( 2.383)	Loss 1.3337e-01 (2.1606e-01) 
2023-05-27 04:30:20.076492: val Epoch: [3][47/72]	Time  0.191 ( 2.560)	Data  0.001 ( 2.333)	Loss 5.1745e-01 (2.2234e-01) 
2023-05-27 04:30:25.007869: val Epoch: [3][48/72]	Time  4.931 ( 2.608)	Data  4.636 ( 2.380)	Loss 1.1724e-01 (2.2020e-01) 
2023-05-27 04:30:25.308577: val Epoch: [3][49/72]	Time  0.301 ( 2.562)	Data  0.051 ( 2.334)	Loss 5.4223e-01 (2.2664e-01) 
2023-05-27 04:30:30.089242: val Epoch: [3][50/72]	Time  4.781 ( 2.605)	Data  4.528 ( 2.377)	Loss 1.9716e-01 (2.2606e-01) 
2023-05-27 04:30:30.400920: val Epoch: [3][51/72]	Time  0.312 ( 2.561)	Data  0.001 ( 2.331)	Loss 1.9022e-01 (2.2537e-01) 
2023-05-27 04:30:35.151305: val Epoch: [3][52/72]	Time  4.750 ( 2.603)	Data  4.560 ( 2.373)	Loss 1.8870e-01 (2.2468e-01) 
2023-05-27 04:30:35.383310: val Epoch: [3][53/72]	Time  0.232 ( 2.559)	Data  0.000 ( 2.329)	Loss 2.1621e-01 (2.2452e-01) 
2023-05-27 04:30:39.980716: val Epoch: [3][54/72]	Time  4.597 ( 2.596)	Data  4.395 ( 2.367)	Loss 1.8118e-01 (2.2373e-01) 
2023-05-27 04:30:40.264784: val Epoch: [3][55/72]	Time  0.284 ( 2.555)	Data  0.122 ( 2.326)	Loss 1.3392e-01 (2.2213e-01) 
2023-05-27 04:30:44.956285: val Epoch: [3][56/72]	Time  4.691 ( 2.592)	Data  4.513 ( 2.365)	Loss 1.4284e-01 (2.2074e-01) 
2023-05-27 04:30:45.188388: val Epoch: [3][57/72]	Time  0.232 ( 2.551)	Data  0.065 ( 2.325)	Loss 1.0554e-01 (2.1875e-01) 
2023-05-27 04:30:50.007502: val Epoch: [3][58/72]	Time  4.819 ( 2.590)	Data  4.665 ( 2.365)	Loss 4.4122e-01 (2.2252e-01) 
2023-05-27 04:30:50.288742: val Epoch: [3][59/72]	Time  0.281 ( 2.551)	Data  0.088 ( 2.327)	Loss 3.4604e-01 (2.2458e-01) 
2023-05-27 04:30:55.210439: val Epoch: [3][60/72]	Time  4.922 ( 2.590)	Data  4.646 ( 2.365)	Loss 1.5607e-01 (2.2346e-01) 
2023-05-27 04:30:55.464046: val Epoch: [3][61/72]	Time  0.254 ( 2.552)	Data  0.001 ( 2.327)	Loss 1.4367e-01 (2.2217e-01) 
2023-05-27 04:31:00.185829: val Epoch: [3][62/72]	Time  4.722 ( 2.587)	Data  4.480 ( 2.361)	Loss 1.1759e-01 (2.2051e-01) 
2023-05-27 04:31:00.492258: val Epoch: [3][63/72]	Time  0.306 ( 2.551)	Data  0.140 ( 2.326)	Loss 2.5807e-01 (2.2110e-01) 
2023-05-27 04:31:05.461983: val Epoch: [3][64/72]	Time  4.970 ( 2.588)	Data  4.782 ( 2.364)	Loss 2.3827e-01 (2.2136e-01) 
2023-05-27 04:31:05.726411: val Epoch: [3][65/72]	Time  0.264 ( 2.553)	Data  0.010 ( 2.328)	Loss 9.4404e-02 (2.1944e-01) 
2023-05-27 04:31:10.736847: val Epoch: [3][66/72]	Time  5.010 ( 2.590)	Data  4.757 ( 2.365)	Loss 1.2348e-01 (2.1801e-01) 
2023-05-27 04:31:11.057899: val Epoch: [3][67/72]	Time  0.321 ( 2.557)	Data  0.024 ( 2.330)	Loss 2.3057e-01 (2.1819e-01) 
2023-05-27 04:31:15.990262: val Epoch: [3][68/72]	Time  4.932 ( 2.591)	Data  4.724 ( 2.365)	Loss 8.7382e-02 (2.1630e-01) 
2023-05-27 04:31:16.175415: val Epoch: [3][69/72]	Time  0.185 ( 2.557)	Data  0.025 ( 2.331)	Loss 1.4455e-01 (2.1527e-01) 
2023-05-27 04:31:21.213600: val Epoch: [3][70/72]	Time  5.038 ( 2.592)	Data  4.772 ( 2.366)	Loss 1.4897e-01 (2.1434e-01) 
2023-05-27 04:31:21.382858: val Epoch: [3][71/72]	Time  0.169 ( 2.558)	Data  0.001 ( 2.333)	Loss 3.7574e-01 (2.1658e-01) 
2023-05-27 04:31:21.726887: Epoch 3 :Val : ['ET : 0.631171464920044', 'TC : 0.6323634386062622', 'WT : 0.7794392108917236'] 
2023-05-27 04:31:21.731180: Epoch 3 :Val : ['ET : 0.631171464920044', 'TC : 0.6323634386062622', 'WT : 0.7794392108917236'] 
2023-05-27 04:31:21.735085: Saving the model with DSC 0.6780966520309448 
2023-05-27 04:31:22.584411: Val epoch done in 186.69059217200265 s 
2023-05-27 04:31:22.594218: Batches per epoch:  193 
2023-05-27 04:31:34.683323: train Epoch: [4][  0/193]	Time 12.089 (12.089)	Data 11.100 (11.100)	Loss 1.5756e-01 (1.5756e-01) 
2023-05-27 04:31:35.682218: train Epoch: [4][  1/193]	Time  0.999 ( 6.544)	Data  0.001 ( 5.551)	Loss 1.5844e-01 (1.5800e-01) 
2023-05-27 04:31:45.433717: train Epoch: [4][  2/193]	Time  9.751 ( 7.613)	Data  8.899 ( 6.667)	Loss 1.9554e-01 (1.7051e-01) 
2023-05-27 04:31:46.357186: train Epoch: [4][  3/193]	Time  0.923 ( 5.941)	Data  0.001 ( 5.000)	Loss 1.7143e-01 (1.7074e-01) 
2023-05-27 04:31:55.337545: train Epoch: [4][  4/193]	Time  8.980 ( 6.549)	Data  8.097 ( 5.620)	Loss 1.1293e-01 (1.5918e-01) 
2023-05-27 04:31:56.252476: train Epoch: [4][  5/193]	Time  0.915 ( 5.610)	Data  0.001 ( 4.683)	Loss 2.4504e-01 (1.7349e-01) 
2023-05-27 04:32:05.530262: train Epoch: [4][  6/193]	Time  9.278 ( 6.134)	Data  8.410 ( 5.216)	Loss 1.0529e-01 (1.6375e-01) 
2023-05-27 04:32:06.572371: train Epoch: [4][  7/193]	Time  1.042 ( 5.497)	Data  0.001 ( 4.564)	Loss 1.5194e-01 (1.6227e-01) 
2023-05-27 04:32:15.426258: train Epoch: [4][  8/193]	Time  8.854 ( 5.870)	Data  7.999 ( 4.945)	Loss 2.4681e-01 (1.7167e-01) 
2023-05-27 04:32:16.384674: train Epoch: [4][  9/193]	Time  0.958 ( 5.379)	Data  0.001 ( 4.451)	Loss 5.0915e-02 (1.5959e-01) 
2023-05-27 04:32:25.841012: train Epoch: [4][ 10/193]	Time  9.456 ( 5.750)	Data  8.568 ( 4.825)	Loss 9.2164e-02 (1.5346e-01) 
2023-05-27 04:32:26.795084: train Epoch: [4][ 11/193]	Time  0.954 ( 5.350)	Data  0.001 ( 4.423)	Loss 1.1898e-01 (1.5059e-01) 
2023-05-27 04:32:36.141208: train Epoch: [4][ 12/193]	Time  9.346 ( 5.657)	Data  8.289 ( 4.721)	Loss 1.5966e-01 (1.5128e-01) 
2023-05-27 04:32:37.107349: train Epoch: [4][ 13/193]	Time  0.966 ( 5.322)	Data  0.001 ( 4.383)	Loss 1.4988e-01 (1.5118e-01) 
2023-05-27 04:32:46.223676: train Epoch: [4][ 14/193]	Time  9.116 ( 5.575)	Data  8.153 ( 4.635)	Loss 1.7014e-01 (1.5245e-01) 
2023-05-27 04:32:47.196634: train Epoch: [4][ 15/193]	Time  0.973 ( 5.288)	Data  0.001 ( 4.345)	Loss 2.3189e-01 (1.5741e-01) 
2023-05-27 04:32:56.305384: train Epoch: [4][ 16/193]	Time  9.109 ( 5.512)	Data  8.002 ( 4.560)	Loss 1.6253e-01 (1.5771e-01) 
2023-05-27 04:32:57.302482: train Epoch: [4][ 17/193]	Time  0.997 ( 5.262)	Data  0.001 ( 4.307)	Loss 1.1589e-01 (1.5539e-01) 
2023-05-27 04:33:06.315410: train Epoch: [4][ 18/193]	Time  9.013 ( 5.459)	Data  8.144 ( 4.509)	Loss 1.3197e-01 (1.5416e-01) 
2023-05-27 04:33:07.242398: train Epoch: [4][ 19/193]	Time  0.927 ( 5.232)	Data  0.001 ( 4.284)	Loss 1.7664e-01 (1.5528e-01) 
2023-05-27 04:33:16.232430: train Epoch: [4][ 20/193]	Time  8.990 ( 5.411)	Data  8.094 ( 4.465)	Loss 2.4332e-01 (1.5948e-01) 
2023-05-27 04:33:17.203831: train Epoch: [4][ 21/193]	Time  0.971 ( 5.210)	Data  0.001 ( 4.262)	Loss 1.6160e-01 (1.5957e-01) 
2023-05-27 04:33:26.568796: train Epoch: [4][ 22/193]	Time  9.365 ( 5.390)	Data  8.210 ( 4.434)	Loss 2.0671e-01 (1.6162e-01) 
2023-05-27 04:33:27.467843: train Epoch: [4][ 23/193]	Time  0.899 ( 5.203)	Data  0.001 ( 4.249)	Loss 9.5402e-02 (1.5886e-01) 
2023-05-27 04:33:36.279824: train Epoch: [4][ 24/193]	Time  8.812 ( 5.347)	Data  8.020 ( 4.400)	Loss 1.5478e-01 (1.5870e-01) 
2023-05-27 04:33:37.242746: train Epoch: [4][ 25/193]	Time  0.963 ( 5.179)	Data  0.001 ( 4.231)	Loss 1.3906e-01 (1.5794e-01) 
2023-05-27 04:33:46.012393: train Epoch: [4][ 26/193]	Time  8.770 ( 5.312)	Data  7.906 ( 4.367)	Loss 1.7503e-01 (1.5858e-01) 
2023-05-27 04:33:46.923025: train Epoch: [4][ 27/193]	Time  0.911 ( 5.155)	Data  0.001 ( 4.211)	Loss 1.1806e-01 (1.5713e-01) 
2023-05-27 04:33:56.423598: train Epoch: [4][ 28/193]	Time  9.501 ( 5.304)	Data  8.582 ( 4.362)	Loss 1.1259e-01 (1.5559e-01) 
2023-05-27 04:33:57.241789: train Epoch: [4][ 29/193]	Time  0.818 ( 5.155)	Data  0.001 ( 4.216)	Loss 1.5273e-01 (1.5550e-01) 
2023-05-27 04:34:06.876145: train Epoch: [4][ 30/193]	Time  9.634 ( 5.299)	Data  8.708 ( 4.361)	Loss 1.4576e-01 (1.5518e-01) 
2023-05-27 04:34:07.715674: train Epoch: [4][ 31/193]	Time  0.840 ( 5.160)	Data  0.001 ( 4.225)	Loss 2.5960e-01 (1.5845e-01) 
2023-05-27 04:34:17.237720: train Epoch: [4][ 32/193]	Time  9.522 ( 5.292)	Data  8.653 ( 4.359)	Loss 1.1724e-01 (1.5720e-01) 
2023-05-27 04:34:18.316003: train Epoch: [4][ 33/193]	Time  1.078 ( 5.168)	Data  0.001 ( 4.231)	Loss 3.6045e-01 (1.6318e-01) 
2023-05-27 04:34:26.048844: train Epoch: [4][ 34/193]	Time  7.733 ( 5.242)	Data  6.877 ( 4.306)	Loss 2.0205e-01 (1.6429e-01) 
2023-05-27 04:34:27.023347: train Epoch: [4][ 35/193]	Time  0.974 ( 5.123)	Data  0.001 ( 4.187)	Loss 1.3935e-01 (1.6359e-01) 
2023-05-27 04:34:36.135353: train Epoch: [4][ 36/193]	Time  9.112 ( 5.231)	Data  8.163 ( 4.294)	Loss 1.1409e-01 (1.6226e-01) 
2023-05-27 04:34:37.055599: train Epoch: [4][ 37/193]	Time  0.920 ( 5.117)	Data  0.001 ( 4.181)	Loss 1.8751e-01 (1.6292e-01) 
2023-05-27 04:34:46.204255: train Epoch: [4][ 38/193]	Time  9.149 ( 5.221)	Data  8.277 ( 4.286)	Loss 1.3024e-01 (1.6208e-01) 
2023-05-27 04:34:47.124582: train Epoch: [4][ 39/193]	Time  0.920 ( 5.113)	Data  0.001 ( 4.179)	Loss 1.4108e-01 (1.6156e-01) 
2023-05-27 04:34:56.352502: train Epoch: [4][ 40/193]	Time  9.228 ( 5.214)	Data  8.390 ( 4.282)	Loss 1.7048e-01 (1.6178e-01) 
2023-05-27 04:34:57.181045: train Epoch: [4][ 41/193]	Time  0.829 ( 5.109)	Data  0.001 ( 4.180)	Loss 1.1077e-01 (1.6056e-01) 
2023-05-27 04:35:06.816323: train Epoch: [4][ 42/193]	Time  9.635 ( 5.214)	Data  8.692 ( 4.285)	Loss 1.0210e-01 (1.5920e-01) 
2023-05-27 04:35:07.887443: train Epoch: [4][ 43/193]	Time  1.071 ( 5.120)	Data  0.001 ( 4.188)	Loss 2.3673e-01 (1.6096e-01) 
2023-05-27 04:35:17.313869: train Epoch: [4][ 44/193]	Time  9.426 ( 5.216)	Data  8.558 ( 4.285)	Loss 1.8591e-01 (1.6152e-01) 
2023-05-27 04:35:18.161194: train Epoch: [4][ 45/193]	Time  0.847 ( 5.121)	Data  0.001 ( 4.192)	Loss 2.3075e-01 (1.6302e-01) 
2023-05-27 04:35:27.646371: train Epoch: [4][ 46/193]	Time  9.485 ( 5.214)	Data  8.591 ( 4.285)	Loss 1.0554e-01 (1.6180e-01) 
2023-05-27 04:35:28.546572: train Epoch: [4][ 47/193]	Time  0.900 ( 5.124)	Data  0.001 ( 4.196)	Loss 1.7623e-01 (1.6210e-01) 
2023-05-27 04:35:38.261659: train Epoch: [4][ 48/193]	Time  9.715 ( 5.218)	Data  8.541 ( 4.285)	Loss 3.1481e-01 (1.6522e-01) 
2023-05-27 04:35:39.088888: train Epoch: [4][ 49/193]	Time  0.827 ( 5.130)	Data  0.001 ( 4.199)	Loss 2.8445e-01 (1.6760e-01) 
2023-05-27 04:35:48.509636: train Epoch: [4][ 50/193]	Time  9.421 ( 5.214)	Data  8.428 ( 4.282)	Loss 1.3249e-01 (1.6691e-01) 
2023-05-27 04:35:49.425878: train Epoch: [4][ 51/193]	Time  0.916 ( 5.131)	Data  0.001 ( 4.199)	Loss 1.9378e-01 (1.6743e-01) 
2023-05-27 04:35:58.917609: train Epoch: [4][ 52/193]	Time  9.492 ( 5.214)	Data  8.573 ( 4.282)	Loss 1.8789e-01 (1.6782e-01) 
2023-05-27 04:35:59.833766: train Epoch: [4][ 53/193]	Time  0.916 ( 5.134)	Data  0.001 ( 4.203)	Loss 1.6458e-01 (1.6776e-01) 
2023-05-27 04:36:09.312017: train Epoch: [4][ 54/193]	Time  9.478 ( 5.213)	Data  8.383 ( 4.279)	Loss 2.5039e-01 (1.6926e-01) 
2023-05-27 04:36:10.295590: train Epoch: [4][ 55/193]	Time  0.984 ( 5.138)	Data  0.001 ( 4.202)	Loss 1.6003e-01 (1.6909e-01) 
2023-05-27 04:36:19.178828: train Epoch: [4][ 56/193]	Time  8.883 ( 5.203)	Data  7.945 ( 4.268)	Loss 1.3979e-01 (1.6858e-01) 
2023-05-27 04:36:20.165296: train Epoch: [4][ 57/193]	Time  0.986 ( 5.131)	Data  0.001 ( 4.194)	Loss 1.0978e-01 (1.6757e-01) 
2023-05-27 04:36:29.434578: train Epoch: [4][ 58/193]	Time  9.269 ( 5.201)	Data  8.267 ( 4.263)	Loss 1.1441e-01 (1.6666e-01) 
2023-05-27 04:36:30.328218: train Epoch: [4][ 59/193]	Time  0.894 ( 5.129)	Data  0.001 ( 4.192)	Loss 1.3725e-01 (1.6617e-01) 
2023-05-27 04:36:39.845753: train Epoch: [4][ 60/193]	Time  9.518 ( 5.201)	Data  8.686 ( 4.266)	Loss 1.4192e-01 (1.6578e-01) 
2023-05-27 04:36:40.708082: train Epoch: [4][ 61/193]	Time  0.862 ( 5.131)	Data  0.001 ( 4.197)	Loss 1.1696e-01 (1.6499e-01) 
2023-05-27 04:36:49.977267: train Epoch: [4][ 62/193]	Time  9.269 ( 5.197)	Data  8.304 ( 4.262)	Loss 1.4475e-01 (1.6467e-01) 
2023-05-27 04:36:50.939022: train Epoch: [4][ 63/193]	Time  0.962 ( 5.130)	Data  0.001 ( 4.196)	Loss 1.5001e-01 (1.6444e-01) 
2023-05-27 04:37:00.033033: train Epoch: [4][ 64/193]	Time  9.094 ( 5.191)	Data  7.963 ( 4.254)	Loss 1.2477e-01 (1.6383e-01) 
2023-05-27 04:37:00.953951: train Epoch: [4][ 65/193]	Time  0.921 ( 5.127)	Data  0.001 ( 4.189)	Loss 1.2942e-01 (1.6331e-01) 
2023-05-27 04:37:09.715960: train Epoch: [4][ 66/193]	Time  8.762 ( 5.181)	Data  7.812 ( 4.243)	Loss 9.9564e-02 (1.6236e-01) 
2023-05-27 04:37:10.739511: train Epoch: [4][ 67/193]	Time  1.024 ( 5.120)	Data  0.001 ( 4.181)	Loss 1.6590e-01 (1.6241e-01) 
2023-05-27 04:37:19.617155: train Epoch: [4][ 68/193]	Time  8.878 ( 5.174)	Data  8.028 ( 4.237)	Loss 1.6062e-01 (1.6238e-01) 
2023-05-27 04:37:20.538723: train Epoch: [4][ 69/193]	Time  0.922 ( 5.113)	Data  0.001 ( 4.176)	Loss 1.4312e-01 (1.6211e-01) 
2023-05-27 04:37:28.423468: train Epoch: [4][ 70/193]	Time  7.885 ( 5.153)	Data  7.072 ( 4.217)	Loss 1.5338e-01 (1.6198e-01) 
2023-05-27 04:37:29.231810: train Epoch: [4][ 71/193]	Time  0.808 ( 5.092)	Data  0.001 ( 4.159)	Loss 1.0156e-01 (1.6115e-01) 
2023-05-27 04:37:37.879849: train Epoch: [4][ 72/193]	Time  8.648 ( 5.141)	Data  7.693 ( 4.207)	Loss 1.8708e-01 (1.6150e-01) 
2023-05-27 04:37:38.836752: train Epoch: [4][ 73/193]	Time  0.957 ( 5.084)	Data  0.001 ( 4.150)	Loss 1.8033e-01 (1.6175e-01) 
2023-05-27 04:37:48.183226: train Epoch: [4][ 74/193]	Time  9.346 ( 5.141)	Data  8.523 ( 4.208)	Loss 1.4368e-01 (1.6151e-01) 
2023-05-27 04:37:49.143834: train Epoch: [4][ 75/193]	Time  0.961 ( 5.086)	Data  0.001 ( 4.153)	Loss 1.2494e-01 (1.6103e-01) 
2023-05-27 04:37:58.564838: train Epoch: [4][ 76/193]	Time  9.421 ( 5.142)	Data  8.548 ( 4.210)	Loss 1.9066e-01 (1.6142e-01) 
2023-05-27 04:37:59.452470: train Epoch: [4][ 77/193]	Time  0.888 ( 5.088)	Data  0.001 ( 4.156)	Loss 1.5643e-01 (1.6135e-01) 
2023-05-27 04:38:08.547338: train Epoch: [4][ 78/193]	Time  9.095 ( 5.139)	Data  8.191 ( 4.207)	Loss 1.4752e-01 (1.6118e-01) 
2023-05-27 04:38:09.454579: train Epoch: [4][ 79/193]	Time  0.907 ( 5.086)	Data  0.001 ( 4.155)	Loss 4.5785e-01 (1.6489e-01) 
2023-05-27 04:38:18.200971: train Epoch: [4][ 80/193]	Time  8.746 ( 5.131)	Data  7.888 ( 4.201)	Loss 1.9884e-01 (1.6531e-01) 
2023-05-27 04:38:19.110816: train Epoch: [4][ 81/193]	Time  0.910 ( 5.079)	Data  0.001 ( 4.150)	Loss 1.6966e-01 (1.6536e-01) 
2023-05-27 04:38:28.721063: train Epoch: [4][ 82/193]	Time  9.610 ( 5.134)	Data  8.574 ( 4.203)	Loss 3.7276e-01 (1.6786e-01) 
2023-05-27 04:38:29.613674: train Epoch: [4][ 83/193]	Time  0.893 ( 5.084)	Data  0.001 ( 4.153)	Loss 1.3635e-01 (1.6748e-01) 
2023-05-27 04:38:38.681799: train Epoch: [4][ 84/193]	Time  9.068 ( 5.130)	Data  8.059 ( 4.199)	Loss 1.3063e-01 (1.6705e-01) 
2023-05-27 04:38:39.742543: train Epoch: [4][ 85/193]	Time  1.061 ( 5.083)	Data  0.001 ( 4.150)	Loss 1.7111e-01 (1.6710e-01) 
2023-05-27 04:38:48.858835: train Epoch: [4][ 86/193]	Time  9.116 ( 5.129)	Data  8.174 ( 4.196)	Loss 1.3259e-01 (1.6670e-01) 
2023-05-27 04:38:49.827029: train Epoch: [4][ 87/193]	Time  0.968 ( 5.082)	Data  0.001 ( 4.149)	Loss 1.5170e-01 (1.6653e-01) 
2023-05-27 04:38:59.079198: train Epoch: [4][ 88/193]	Time  9.252 ( 5.129)	Data  8.243 ( 4.195)	Loss 1.6128e-01 (1.6647e-01) 
2023-05-27 04:38:59.973104: train Epoch: [4][ 89/193]	Time  0.894 ( 5.082)	Data  0.001 ( 4.148)	Loss 2.2623e-01 (1.6713e-01) 
2023-05-27 04:39:08.593027: train Epoch: [4][ 90/193]	Time  8.620 ( 5.121)	Data  7.819 ( 4.188)	Loss 1.5848e-01 (1.6704e-01) 
2023-05-27 04:39:09.429701: train Epoch: [4][ 91/193]	Time  0.837 ( 5.074)	Data  0.001 ( 4.143)	Loss 1.4029e-01 (1.6675e-01) 
2023-05-27 04:39:18.956708: train Epoch: [4][ 92/193]	Time  9.527 ( 5.122)	Data  8.469 ( 4.189)	Loss 1.5993e-01 (1.6667e-01) 
2023-05-27 04:39:19.854783: train Epoch: [4][ 93/193]	Time  0.898 ( 5.077)	Data  0.001 ( 4.145)	Loss 1.7075e-01 (1.6672e-01) 
2023-05-27 04:39:28.661078: train Epoch: [4][ 94/193]	Time  8.806 ( 5.116)	Data  8.061 ( 4.186)	Loss 1.0410e-01 (1.6606e-01) 
2023-05-27 04:39:29.231114: train Epoch: [4][ 95/193]	Time  0.570 ( 5.069)	Data  0.001 ( 4.142)	Loss 1.7435e-01 (1.6615e-01) 
2023-05-27 04:39:38.730918: train Epoch: [4][ 96/193]	Time  9.500 ( 5.115)	Data  8.908 ( 4.192)	Loss 2.1736e-01 (1.6667e-01) 
2023-05-27 04:39:39.293180: train Epoch: [4][ 97/193]	Time  0.562 ( 5.068)	Data  0.001 ( 4.149)	Loss 1.5753e-01 (1.6658e-01) 
2023-05-27 04:39:48.987282: train Epoch: [4][ 98/193]	Time  9.694 ( 5.115)	Data  9.119 ( 4.199)	Loss 3.2261e-01 (1.6816e-01) 
2023-05-27 04:39:49.548358: train Epoch: [4][ 99/193]	Time  0.561 ( 5.070)	Data  0.001 ( 4.157)	Loss 1.6634e-01 (1.6814e-01) 
2023-05-27 04:39:59.047377: train Epoch: [4][100/193]	Time  9.499 ( 5.113)	Data  8.933 ( 4.204)	Loss 2.6346e-01 (1.6908e-01) 
2023-05-27 04:39:59.609990: train Epoch: [4][101/193]	Time  0.563 ( 5.069)	Data  0.001 ( 4.163)	Loss 1.4266e-01 (1.6882e-01) 
2023-05-27 04:40:08.390212: train Epoch: [4][102/193]	Time  8.780 ( 5.105)	Data  8.200 ( 4.202)	Loss 1.0265e-01 (1.6818e-01) 
2023-05-27 04:40:08.952053: train Epoch: [4][103/193]	Time  0.562 ( 5.061)	Data  0.001 ( 4.162)	Loss 1.6257e-01 (1.6813e-01) 
2023-05-27 04:40:17.778905: train Epoch: [4][104/193]	Time  8.827 ( 5.097)	Data  8.242 ( 4.201)	Loss 1.2621e-01 (1.6773e-01) 
2023-05-27 04:40:18.346894: train Epoch: [4][105/193]	Time  0.568 ( 5.054)	Data  0.001 ( 4.161)	Loss 1.0621e-01 (1.6715e-01) 
2023-05-27 04:40:27.606445: train Epoch: [4][106/193]	Time  9.260 ( 5.094)	Data  8.683 ( 4.203)	Loss 2.1659e-01 (1.6761e-01) 
2023-05-27 04:40:28.169663: train Epoch: [4][107/193]	Time  0.563 ( 5.052)	Data  0.001 ( 4.164)	Loss 1.4999e-01 (1.6745e-01) 
2023-05-27 04:40:37.631529: train Epoch: [4][108/193]	Time  9.462 ( 5.092)	Data  8.889 ( 4.208)	Loss 1.8898e-01 (1.6764e-01) 
2023-05-27 04:40:38.193768: train Epoch: [4][109/193]	Time  0.562 ( 5.051)	Data  0.001 ( 4.170)	Loss 1.1708e-01 (1.6718e-01) 
2023-05-27 04:40:47.555416: train Epoch: [4][110/193]	Time  9.362 ( 5.090)	Data  8.787 ( 4.211)	Loss 1.7369e-01 (1.6724e-01) 
2023-05-27 04:40:48.116834: train Epoch: [4][111/193]	Time  0.561 ( 5.049)	Data  0.001 ( 4.174)	Loss 3.3237e-01 (1.6872e-01) 
2023-05-27 04:40:57.865244: train Epoch: [4][112/193]	Time  9.748 ( 5.091)	Data  9.170 ( 4.218)	Loss 1.4911e-01 (1.6854e-01) 
2023-05-27 04:40:58.433033: train Epoch: [4][113/193]	Time  0.568 ( 5.051)	Data  0.001 ( 4.181)	Loss 1.1453e-01 (1.6807e-01) 
2023-05-27 04:41:07.911613: train Epoch: [4][114/193]	Time  9.479 ( 5.090)	Data  8.910 ( 4.222)	Loss 1.4304e-01 (1.6785e-01) 
2023-05-27 04:41:08.474195: train Epoch: [4][115/193]	Time  0.563 ( 5.051)	Data  0.001 ( 4.186)	Loss 1.4578e-01 (1.6766e-01) 
2023-05-27 04:41:18.289278: train Epoch: [4][116/193]	Time  9.815 ( 5.091)	Data  9.243 ( 4.229)	Loss 1.8919e-01 (1.6785e-01) 
2023-05-27 04:41:18.850912: train Epoch: [4][117/193]	Time  0.562 ( 5.053)	Data  0.001 ( 4.193)	Loss 1.2644e-01 (1.6749e-01) 
2023-05-27 04:41:28.724108: train Epoch: [4][118/193]	Time  9.873 ( 5.094)	Data  9.293 ( 4.236)	Loss 8.5185e-02 (1.6680e-01) 
2023-05-27 04:41:29.313955: train Epoch: [4][119/193]	Time  0.590 ( 5.056)	Data  0.001 ( 4.200)	Loss 1.1238e-01 (1.6635e-01) 
2023-05-27 04:41:38.460949: train Epoch: [4][120/193]	Time  9.147 ( 5.090)	Data  8.580 ( 4.237)	Loss 1.8757e-01 (1.6652e-01) 
2023-05-27 04:41:39.078702: train Epoch: [4][121/193]	Time  0.618 ( 5.053)	Data  0.001 ( 4.202)	Loss 1.9469e-01 (1.6676e-01) 
2023-05-27 04:41:48.954529: train Epoch: [4][122/193]	Time  9.876 ( 5.092)	Data  9.266 ( 4.243)	Loss 1.9594e-01 (1.6699e-01) 
2023-05-27 04:41:49.592735: train Epoch: [4][123/193]	Time  0.638 ( 5.056)	Data  0.006 ( 4.209)	Loss 1.2636e-01 (1.6667e-01) 
2023-05-27 04:41:58.652264: train Epoch: [4][124/193]	Time  9.060 ( 5.088)	Data  8.492 ( 4.243)	Loss 1.0066e-01 (1.6614e-01) 
2023-05-27 04:41:59.239165: train Epoch: [4][125/193]	Time  0.587 ( 5.053)	Data  0.001 ( 4.210)	Loss 2.8955e-01 (1.6712e-01) 
2023-05-27 04:42:08.671943: train Epoch: [4][126/193]	Time  9.433 ( 5.087)	Data  8.840 ( 4.246)	Loss 1.0305e-01 (1.6661e-01) 
2023-05-27 04:42:09.260475: train Epoch: [4][127/193]	Time  0.589 ( 5.052)	Data  0.001 ( 4.213)	Loss 1.0493e-01 (1.6613e-01) 
2023-05-27 04:42:18.858172: train Epoch: [4][128/193]	Time  9.598 ( 5.087)	Data  9.025 ( 4.250)	Loss 2.9825e-01 (1.6715e-01) 
2023-05-27 04:42:19.431204: train Epoch: [4][129/193]	Time  0.573 ( 5.053)	Data  0.001 ( 4.217)	Loss 3.0295e-01 (1.6820e-01) 
2023-05-27 04:42:28.828091: train Epoch: [4][130/193]	Time  9.397 ( 5.086)	Data  8.823 ( 4.253)	Loss 2.6053e-01 (1.6890e-01) 
2023-05-27 04:42:29.417718: train Epoch: [4][131/193]	Time  0.590 ( 5.052)	Data  0.001 ( 4.220)	Loss 1.1075e-01 (1.6846e-01) 
2023-05-27 04:42:39.367569: train Epoch: [4][132/193]	Time  9.950 ( 5.089)	Data  9.305 ( 4.259)	Loss 1.6170e-01 (1.6841e-01) 
2023-05-27 04:42:39.937422: train Epoch: [4][133/193]	Time  0.570 ( 5.055)	Data  0.001 ( 4.227)	Loss 1.2975e-01 (1.6812e-01) 
2023-05-27 04:42:49.745901: train Epoch: [4][134/193]	Time  9.808 ( 5.090)	Data  9.223 ( 4.264)	Loss 2.1458e-01 (1.6847e-01) 
2023-05-27 04:42:50.315838: train Epoch: [4][135/193]	Time  0.570 ( 5.057)	Data  0.001 ( 4.233)	Loss 1.0389e-01 (1.6799e-01) 
2023-05-27 04:43:00.075965: train Epoch: [4][136/193]	Time  9.760 ( 5.091)	Data  9.154 ( 4.268)	Loss 1.7377e-01 (1.6804e-01) 
2023-05-27 04:43:00.642402: train Epoch: [4][137/193]	Time  0.566 ( 5.058)	Data  0.001 ( 4.238)	Loss 1.1466e-01 (1.6765e-01) 
2023-05-27 04:43:10.108705: train Epoch: [4][138/193]	Time  9.466 ( 5.090)	Data  8.883 ( 4.271)	Loss 1.0352e-01 (1.6719e-01) 
2023-05-27 04:43:10.721527: train Epoch: [4][139/193]	Time  0.613 ( 5.058)	Data  0.001 ( 4.240)	Loss 1.4218e-01 (1.6701e-01) 
2023-05-27 04:43:19.196983: train Epoch: [4][140/193]	Time  8.475 ( 5.082)	Data  7.895 ( 4.266)	Loss 1.6585e-01 (1.6700e-01) 
2023-05-27 04:43:19.994963: train Epoch: [4][141/193]	Time  0.798 ( 5.052)	Data  0.217 ( 4.238)	Loss 1.8364e-01 (1.6712e-01) 
2023-05-27 04:43:29.151640: train Epoch: [4][142/193]	Time  9.157 ( 5.081)	Data  8.583 ( 4.268)	Loss 1.9677e-01 (1.6733e-01) 
2023-05-27 04:43:30.052966: train Epoch: [4][143/193]	Time  0.901 ( 5.052)	Data  0.335 ( 4.241)	Loss 1.7360e-01 (1.6737e-01) 
2023-05-27 04:43:39.287885: train Epoch: [4][144/193]	Time  9.235 ( 5.081)	Data  8.658 ( 4.271)	Loss 1.9402e-01 (1.6755e-01) 
2023-05-27 04:43:40.103098: train Epoch: [4][145/193]	Time  0.815 ( 5.051)	Data  0.251 ( 4.244)	Loss 1.2930e-01 (1.6729e-01) 
2023-05-27 04:43:49.212717: train Epoch: [4][146/193]	Time  9.110 ( 5.079)	Data  8.534 ( 4.273)	Loss 1.0195e-01 (1.6685e-01) 
2023-05-27 04:43:50.165790: train Epoch: [4][147/193]	Time  0.953 ( 5.051)	Data  0.366 ( 4.247)	Loss 1.3362e-01 (1.6662e-01) 
2023-05-27 04:43:58.903372: train Epoch: [4][148/193]	Time  8.738 ( 5.076)	Data  8.140 ( 4.273)	Loss 2.0052e-01 (1.6685e-01) 
2023-05-27 04:44:00.196039: train Epoch: [4][149/193]	Time  1.293 ( 5.051)	Data  0.722 ( 4.249)	Loss 2.5431e-01 (1.6743e-01) 
2023-05-27 04:44:09.020252: train Epoch: [4][150/193]	Time  8.824 ( 5.076)	Data  8.235 ( 4.275)	Loss 1.9748e-01 (1.6763e-01) 
2023-05-27 04:44:10.132128: train Epoch: [4][151/193]	Time  1.112 ( 5.050)	Data  0.543 ( 4.251)	Loss 1.1191e-01 (1.6726e-01) 
2023-05-27 04:44:19.061756: train Epoch: [4][152/193]	Time  8.930 ( 5.075)	Data  8.343 ( 4.278)	Loss 1.4669e-01 (1.6713e-01) 
2023-05-27 04:44:20.208641: train Epoch: [4][153/193]	Time  1.147 ( 5.049)	Data  0.582 ( 4.254)	Loss 1.5026e-01 (1.6702e-01) 
2023-05-27 04:44:28.969537: train Epoch: [4][154/193]	Time  8.761 ( 5.073)	Data  8.173 ( 4.279)	Loss 1.2095e-01 (1.6672e-01) 
2023-05-27 04:44:30.052148: train Epoch: [4][155/193]	Time  1.083 ( 5.048)	Data  0.521 ( 4.255)	Loss 1.8254e-01 (1.6682e-01) 
2023-05-27 04:44:38.897240: train Epoch: [4][156/193]	Time  8.845 ( 5.072)	Data  8.280 ( 4.281)	Loss 1.5548e-01 (1.6675e-01) 
2023-05-27 04:44:39.804509: train Epoch: [4][157/193]	Time  0.907 ( 5.046)	Data  0.345 ( 4.256)	Loss 1.5903e-01 (1.6670e-01) 
2023-05-27 04:44:49.345769: train Epoch: [4][158/193]	Time  9.541 ( 5.074)	Data  8.978 ( 4.285)	Loss 2.4142e-01 (1.6717e-01) 
2023-05-27 04:44:49.943532: train Epoch: [4][159/193]	Time  0.598 ( 5.046)	Data  0.038 ( 4.259)	Loss 1.4333e-01 (1.6702e-01) 
2023-05-27 04:44:59.179636: train Epoch: [4][160/193]	Time  9.236 ( 5.072)	Data  8.663 ( 4.286)	Loss 1.2612e-01 (1.6677e-01) 
2023-05-27 04:44:59.768217: train Epoch: [4][161/193]	Time  0.589 ( 5.044)	Data  0.029 ( 4.260)	Loss 1.2611e-01 (1.6652e-01) 
2023-05-27 04:45:08.859394: train Epoch: [4][162/193]	Time  9.091 ( 5.069)	Data  8.507 ( 4.286)	Loss 1.5074e-01 (1.6642e-01) 
2023-05-27 04:45:09.812347: train Epoch: [4][163/193]	Time  0.953 ( 5.044)	Data  0.392 ( 4.262)	Loss 1.6164e-01 (1.6639e-01) 
2023-05-27 04:45:19.101319: train Epoch: [4][164/193]	Time  9.289 ( 5.070)	Data  8.720 ( 4.289)	Loss 1.6583e-01 (1.6639e-01) 
2023-05-27 04:45:19.731301: train Epoch: [4][165/193]	Time  0.630 ( 5.043)	Data  0.062 ( 4.264)	Loss 1.3596e-01 (1.6621e-01) 
2023-05-27 04:45:28.705672: train Epoch: [4][166/193]	Time  8.974 ( 5.067)	Data  8.409 ( 4.289)	Loss 2.2466e-01 (1.6656e-01) 
2023-05-27 04:45:29.775347: train Epoch: [4][167/193]	Time  1.070 ( 5.043)	Data  0.498 ( 4.266)	Loss 1.3670e-01 (1.6638e-01) 
2023-05-27 04:45:38.796872: train Epoch: [4][168/193]	Time  9.022 ( 5.066)	Data  8.448 ( 4.291)	Loss 1.5143e-01 (1.6629e-01) 
2023-05-27 04:45:39.786019: train Epoch: [4][169/193]	Time  0.989 ( 5.042)	Data  0.417 ( 4.268)	Loss 4.2789e-01 (1.6783e-01) 
2023-05-27 04:45:48.721730: train Epoch: [4][170/193]	Time  8.936 ( 5.065)	Data  8.364 ( 4.292)	Loss 2.3406e-01 (1.6822e-01) 
2023-05-27 04:45:50.073027: train Epoch: [4][171/193]	Time  1.351 ( 5.043)	Data  0.792 ( 4.272)	Loss 1.2184e-01 (1.6795e-01) 
2023-05-27 04:45:58.818723: train Epoch: [4][172/193]	Time  8.746 ( 5.065)	Data  8.172 ( 4.294)	Loss 1.3548e-01 (1.6776e-01) 
2023-05-27 04:45:59.387868: train Epoch: [4][173/193]	Time  0.569 ( 5.039)	Data  0.001 ( 4.269)	Loss 1.4563e-01 (1.6763e-01) 
2023-05-27 04:46:08.545333: train Epoch: [4][174/193]	Time  9.157 ( 5.063)	Data  8.593 ( 4.294)	Loss 2.6719e-01 (1.6820e-01) 
2023-05-27 04:46:09.147325: train Epoch: [4][175/193]	Time  0.602 ( 5.037)	Data  0.042 ( 4.270)	Loss 4.1408e-01 (1.6960e-01) 
2023-05-27 04:46:18.448584: train Epoch: [4][176/193]	Time  9.301 ( 5.061)	Data  8.728 ( 4.295)	Loss 1.3615e-01 (1.6941e-01) 
2023-05-27 04:46:19.009333: train Epoch: [4][177/193]	Time  0.561 ( 5.036)	Data  0.001 ( 4.271)	Loss 1.6035e-01 (1.6936e-01) 
2023-05-27 04:46:28.784720: train Epoch: [4][178/193]	Time  9.775 ( 5.063)	Data  9.212 ( 4.299)	Loss 1.0056e-01 (1.6897e-01) 
2023-05-27 04:46:29.346670: train Epoch: [4][179/193]	Time  0.562 ( 5.038)	Data  0.001 ( 4.275)	Loss 1.3864e-01 (1.6881e-01) 
2023-05-27 04:46:38.694227: train Epoch: [4][180/193]	Time  9.348 ( 5.061)	Data  8.733 ( 4.299)	Loss 2.4878e-01 (1.6925e-01) 
2023-05-27 04:46:39.257691: train Epoch: [4][181/193]	Time  0.563 ( 5.037)	Data  0.001 ( 4.276)	Loss 9.6479e-02 (1.6885e-01) 
2023-05-27 04:46:48.757001: train Epoch: [4][182/193]	Time  9.499 ( 5.061)	Data  8.926 ( 4.301)	Loss 1.1261e-01 (1.6854e-01) 
2023-05-27 04:46:49.320356: train Epoch: [4][183/193]	Time  0.563 ( 5.037)	Data  0.001 ( 4.278)	Loss 1.2716e-01 (1.6832e-01) 
2023-05-27 04:46:58.599267: train Epoch: [4][184/193]	Time  9.279 ( 5.059)	Data  8.713 ( 4.302)	Loss 1.0568e-01 (1.6798e-01) 
2023-05-27 04:46:59.162338: train Epoch: [4][185/193]	Time  0.563 ( 5.035)	Data  0.001 ( 4.279)	Loss 2.0247e-01 (1.6816e-01) 
2023-05-27 04:47:08.216497: train Epoch: [4][186/193]	Time  9.054 ( 5.057)	Data  8.488 ( 4.301)	Loss 1.1400e-01 (1.6787e-01) 
2023-05-27 04:47:08.778107: train Epoch: [4][187/193]	Time  0.562 ( 5.033)	Data  0.001 ( 4.278)	Loss 1.1460e-01 (1.6759e-01) 
2023-05-27 04:47:17.944230: train Epoch: [4][188/193]	Time  9.166 ( 5.055)	Data  8.599 ( 4.301)	Loss 1.4419e-01 (1.6747e-01) 
2023-05-27 04:47:18.506106: train Epoch: [4][189/193]	Time  0.562 ( 5.031)	Data  0.001 ( 4.279)	Loss 1.6157e-01 (1.6743e-01) 
2023-05-27 04:47:27.759921: train Epoch: [4][190/193]	Time  9.254 ( 5.053)	Data  8.679 ( 4.302)	Loss 7.5705e-02 (1.6695e-01) 
2023-05-27 04:47:28.323812: train Epoch: [4][191/193]	Time  0.564 ( 5.030)	Data  0.001 ( 4.279)	Loss 1.6145e-01 (1.6693e-01) 
2023-05-27 04:47:36.636048: train Epoch: [4][192/193]	Time  8.312 ( 5.047)	Data  7.746 ( 4.297)	Loss 1.5519e-01 (1.6686e-01) 
2023-05-27 04:47:36.800603: Train Epoch done in 974.206480036999 s 
2023-05-27 04:47:43.807688: val Epoch: [4][ 0/72]	Time  5.870 ( 5.870)	Data  5.692 ( 5.692)	Loss 1.1032e-01 (1.1032e-01) 
2023-05-27 04:47:43.917160: val Epoch: [4][ 1/72]	Time  0.110 ( 2.990)	Data  0.001 ( 2.847)	Loss 3.6933e-01 (2.3982e-01) 
2023-05-27 04:47:48.877980: val Epoch: [4][ 2/72]	Time  4.961 ( 3.647)	Data  4.822 ( 3.505)	Loss 4.3984e-01 (3.0650e-01) 
2023-05-27 04:47:49.019011: val Epoch: [4][ 3/72]	Time  0.141 ( 2.770)	Data  0.001 ( 2.629)	Loss 1.6557e-01 (2.7126e-01) 
2023-05-27 04:47:54.090643: val Epoch: [4][ 4/72]	Time  5.072 ( 3.231)	Data  4.876 ( 3.078)	Loss 1.9199e-01 (2.5541e-01) 
2023-05-27 04:47:54.211398: val Epoch: [4][ 5/72]	Time  0.121 ( 2.712)	Data  0.001 ( 2.566)	Loss 8.5745e-02 (2.2713e-01) 
2023-05-27 04:47:59.111416: val Epoch: [4][ 6/72]	Time  4.900 ( 3.025)	Data  4.778 ( 2.882)	Loss 1.4377e-01 (2.1522e-01) 
2023-05-27 04:47:59.229329: val Epoch: [4][ 7/72]	Time  0.118 ( 2.661)	Data  0.001 ( 2.522)	Loss 2.6600e-01 (2.2157e-01) 
2023-05-27 04:48:04.420640: val Epoch: [4][ 8/72]	Time  5.191 ( 2.943)	Data  5.080 ( 2.806)	Loss 2.1146e-01 (2.2045e-01) 
2023-05-27 04:48:04.532115: val Epoch: [4][ 9/72]	Time  0.111 ( 2.659)	Data  0.001 ( 2.525)	Loss 1.3048e-01 (2.1145e-01) 
2023-05-27 04:48:09.370683: val Epoch: [4][10/72]	Time  4.839 ( 2.858)	Data  4.726 ( 2.725)	Loss 9.9968e-02 (2.0132e-01) 
2023-05-27 04:48:09.483766: val Epoch: [4][11/72]	Time  0.113 ( 2.629)	Data  0.001 ( 2.498)	Loss 1.6825e-01 (1.9856e-01) 
2023-05-27 04:48:14.376522: val Epoch: [4][12/72]	Time  4.893 ( 2.803)	Data  4.780 ( 2.674)	Loss 1.5078e-01 (1.9488e-01) 
2023-05-27 04:48:14.490221: val Epoch: [4][13/72]	Time  0.114 ( 2.611)	Data  0.001 ( 2.483)	Loss 1.0038e-01 (1.8813e-01) 
2023-05-27 04:48:19.542781: val Epoch: [4][14/72]	Time  5.053 ( 2.774)	Data  4.943 ( 2.647)	Loss 1.9890e-01 (1.8885e-01) 
2023-05-27 04:48:19.661894: val Epoch: [4][15/72]	Time  0.119 ( 2.608)	Data  0.001 ( 2.481)	Loss 1.6838e-01 (1.8757e-01) 
2023-05-27 04:48:24.275724: val Epoch: [4][16/72]	Time  4.614 ( 2.726)	Data  4.505 ( 2.600)	Loss 1.2245e-01 (1.8374e-01) 
2023-05-27 04:48:24.385303: val Epoch: [4][17/72]	Time  0.110 ( 2.580)	Data  0.001 ( 2.456)	Loss 2.2165e-01 (1.8585e-01) 
2023-05-27 04:48:29.457848: val Epoch: [4][18/72]	Time  5.073 ( 2.712)	Data  4.954 ( 2.588)	Loss 2.7702e-01 (1.9065e-01) 
2023-05-27 04:48:29.584638: val Epoch: [4][19/72]	Time  0.127 ( 2.582)	Data  0.001 ( 2.458)	Loss 3.1929e-01 (1.9708e-01) 
2023-05-27 04:48:34.292506: val Epoch: [4][20/72]	Time  4.708 ( 2.684)	Data  4.599 ( 2.560)	Loss 8.4896e-02 (1.9174e-01) 
2023-05-27 04:48:34.403042: val Epoch: [4][21/72]	Time  0.111 ( 2.567)	Data  0.001 ( 2.444)	Loss 1.6420e-01 (1.9049e-01) 
2023-05-27 04:48:39.377828: val Epoch: [4][22/72]	Time  4.975 ( 2.671)	Data  4.869 ( 2.549)	Loss 3.6956e-01 (1.9827e-01) 
2023-05-27 04:48:39.487439: val Epoch: [4][23/72]	Time  0.110 ( 2.565)	Data  0.001 ( 2.443)	Loss 1.1645e-01 (1.9486e-01) 
2023-05-27 04:48:44.412265: val Epoch: [4][24/72]	Time  4.925 ( 2.659)	Data  4.809 ( 2.538)	Loss 9.7033e-02 (1.9095e-01) 
2023-05-27 04:48:44.549364: val Epoch: [4][25/72]	Time  0.137 ( 2.562)	Data  0.002 ( 2.440)	Loss 8.1538e-02 (1.8674e-01) 
2023-05-27 04:48:49.457644: val Epoch: [4][26/72]	Time  4.908 ( 2.649)	Data  4.788 ( 2.527)	Loss 2.1664e-01 (1.8785e-01) 
2023-05-27 04:48:49.595545: val Epoch: [4][27/72]	Time  0.138 ( 2.559)	Data  0.001 ( 2.437)	Loss 1.8420e-01 (1.8772e-01) 
2023-05-27 04:48:54.552234: val Epoch: [4][28/72]	Time  4.957 ( 2.642)	Data  4.840 ( 2.520)	Loss 1.3669e-01 (1.8596e-01) 
2023-05-27 04:48:54.661025: val Epoch: [4][29/72]	Time  0.109 ( 2.557)	Data  0.001 ( 2.436)	Loss 5.8993e-01 (1.9942e-01) 
2023-05-27 04:48:59.462199: val Epoch: [4][30/72]	Time  4.801 ( 2.630)	Data  4.688 ( 2.508)	Loss 5.4430e-01 (2.1055e-01) 
2023-05-27 04:48:59.572844: val Epoch: [4][31/72]	Time  0.111 ( 2.551)	Data  0.001 ( 2.430)	Loss 1.0189e-01 (2.0715e-01) 
2023-05-27 04:49:04.446287: val Epoch: [4][32/72]	Time  4.873 ( 2.621)	Data  4.765 ( 2.501)	Loss 1.0298e-01 (2.0400e-01) 
2023-05-27 04:49:04.601566: val Epoch: [4][33/72]	Time  0.155 ( 2.549)	Data  0.042 ( 2.429)	Loss 1.3649e-01 (2.0201e-01) 
2023-05-27 04:49:09.638474: val Epoch: [4][34/72]	Time  5.037 ( 2.620)	Data  4.915 ( 2.500)	Loss 4.3479e-01 (2.0866e-01) 
2023-05-27 04:49:09.773845: val Epoch: [4][35/72]	Time  0.135 ( 2.551)	Data  0.001 ( 2.430)	Loss 8.8902e-02 (2.0534e-01) 
2023-05-27 04:49:14.546250: val Epoch: [4][36/72]	Time  4.772 ( 2.611)	Data  4.662 ( 2.491)	Loss 1.0991e-01 (2.0276e-01) 
2023-05-27 04:49:14.657027: val Epoch: [4][37/72]	Time  0.111 ( 2.545)	Data  0.001 ( 2.425)	Loss 2.7135e-01 (2.0456e-01) 
2023-05-27 04:49:19.543441: val Epoch: [4][38/72]	Time  4.886 ( 2.605)	Data  4.771 ( 2.485)	Loss 1.9167e-01 (2.0423e-01) 
2023-05-27 04:49:19.653701: val Epoch: [4][39/72]	Time  0.110 ( 2.543)	Data  0.001 ( 2.423)	Loss 1.3583e-01 (2.0252e-01) 
2023-05-27 04:49:24.522977: val Epoch: [4][40/72]	Time  4.869 ( 2.600)	Data  4.753 ( 2.480)	Loss 1.9818e-01 (2.0242e-01) 
2023-05-27 04:49:24.633351: val Epoch: [4][41/72]	Time  0.110 ( 2.540)	Data  0.001 ( 2.421)	Loss 1.2957e-01 (2.0068e-01) 
2023-05-27 04:49:29.459021: val Epoch: [4][42/72]	Time  4.826 ( 2.594)	Data  4.703 ( 2.474)	Loss 1.8812e-01 (2.0039e-01) 
2023-05-27 04:49:29.567789: val Epoch: [4][43/72]	Time  0.109 ( 2.537)	Data  0.001 ( 2.418)	Loss 2.5019e-01 (2.0152e-01) 
2023-05-27 04:49:34.640327: val Epoch: [4][44/72]	Time  5.073 ( 2.593)	Data  4.967 ( 2.474)	Loss 1.7245e-01 (2.0087e-01) 
2023-05-27 04:49:34.745781: val Epoch: [4][45/72]	Time  0.105 ( 2.539)	Data  0.001 ( 2.421)	Loss 9.8446e-02 (1.9865e-01) 
2023-05-27 04:49:39.648552: val Epoch: [4][46/72]	Time  4.903 ( 2.590)	Data  4.798 ( 2.471)	Loss 1.0974e-01 (1.9676e-01) 
2023-05-27 04:49:39.753486: val Epoch: [4][47/72]	Time  0.105 ( 2.538)	Data  0.000 ( 2.420)	Loss 5.7956e-01 (2.0473e-01) 
2023-05-27 04:49:44.984531: val Epoch: [4][48/72]	Time  5.231 ( 2.593)	Data  5.121 ( 2.475)	Loss 1.0960e-01 (2.0279e-01) 
2023-05-27 04:49:45.093687: val Epoch: [4][49/72]	Time  0.109 ( 2.543)	Data  0.000 ( 2.425)	Loss 1.5209e-01 (2.0178e-01) 
2023-05-27 04:49:50.041111: val Epoch: [4][50/72]	Time  4.947 ( 2.590)	Data  4.840 ( 2.473)	Loss 1.3937e-01 (2.0055e-01) 
2023-05-27 04:49:50.146355: val Epoch: [4][51/72]	Time  0.105 ( 2.542)	Data  0.000 ( 2.425)	Loss 8.9891e-02 (1.9842e-01) 
2023-05-27 04:49:54.964594: val Epoch: [4][52/72]	Time  4.818 ( 2.585)	Data  4.711 ( 2.468)	Loss 1.0584e-01 (1.9668e-01) 
2023-05-27 04:49:55.076621: val Epoch: [4][53/72]	Time  0.112 ( 2.540)	Data  0.001 ( 2.423)	Loss 9.6041e-02 (1.9481e-01) 
2023-05-27 04:49:59.819170: val Epoch: [4][54/72]	Time  4.743 ( 2.580)	Data  4.627 ( 2.463)	Loss 2.3269e-01 (1.9550e-01) 
2023-05-27 04:49:59.930873: val Epoch: [4][55/72]	Time  0.112 ( 2.536)	Data  0.001 ( 2.419)	Loss 1.2541e-01 (1.9425e-01) 
2023-05-27 04:50:04.945151: val Epoch: [4][56/72]	Time  5.014 ( 2.579)	Data  4.903 ( 2.462)	Loss 2.2547e-01 (1.9480e-01) 
2023-05-27 04:50:05.056649: val Epoch: [4][57/72]	Time  0.111 ( 2.537)	Data  0.001 ( 2.420)	Loss 1.2018e-01 (1.9351e-01) 
2023-05-27 04:50:10.218932: val Epoch: [4][58/72]	Time  5.162 ( 2.581)	Data  5.052 ( 2.464)	Loss 1.3346e-01 (1.9249e-01) 
2023-05-27 04:50:10.331007: val Epoch: [4][59/72]	Time  0.112 ( 2.540)	Data  0.001 ( 2.423)	Loss 1.4278e-01 (1.9167e-01) 
2023-05-27 04:50:15.195352: val Epoch: [4][60/72]	Time  4.864 ( 2.578)	Data  4.757 ( 2.462)	Loss 9.4198e-02 (1.9007e-01) 
2023-05-27 04:50:15.303132: val Epoch: [4][61/72]	Time  0.108 ( 2.538)	Data  0.001 ( 2.422)	Loss 9.1786e-02 (1.8848e-01) 
2023-05-27 04:50:20.064667: val Epoch: [4][62/72]	Time  4.762 ( 2.573)	Data  4.654 ( 2.457)	Loss 1.6235e-01 (1.8807e-01) 
2023-05-27 04:50:20.173051: val Epoch: [4][63/72]	Time  0.108 ( 2.535)	Data  0.001 ( 2.419)	Loss 6.8174e-01 (1.9578e-01) 
2023-05-27 04:50:25.406028: val Epoch: [4][64/72]	Time  5.233 ( 2.576)	Data  5.122 ( 2.461)	Loss 2.2702e-01 (1.9626e-01) 
2023-05-27 04:50:25.513946: val Epoch: [4][65/72]	Time  0.108 ( 2.539)	Data  0.001 ( 2.423)	Loss 4.3390e-01 (1.9986e-01) 
2023-05-27 04:50:30.423917: val Epoch: [4][66/72]	Time  4.910 ( 2.574)	Data  4.790 ( 2.459)	Loss 3.9655e-01 (2.0280e-01) 
2023-05-27 04:50:30.535481: val Epoch: [4][67/72]	Time  0.112 ( 2.538)	Data  0.001 ( 2.422)	Loss 2.0219e-01 (2.0279e-01) 
2023-05-27 04:50:35.677424: val Epoch: [4][68/72]	Time  5.142 ( 2.576)	Data  5.033 ( 2.460)	Loss 1.1414e-01 (2.0150e-01) 
2023-05-27 04:50:35.785935: val Epoch: [4][69/72]	Time  0.109 ( 2.541)	Data  0.001 ( 2.425)	Loss 1.9575e-01 (2.0142e-01) 
2023-05-27 04:50:40.441594: val Epoch: [4][70/72]	Time  4.656 ( 2.570)	Data  4.549 ( 2.455)	Loss 2.5052e-01 (2.0211e-01) 
2023-05-27 04:50:40.546926: val Epoch: [4][71/72]	Time  0.105 ( 2.536)	Data  0.000 ( 2.421)	Loss 5.1536e-01 (2.0646e-01) 
2023-05-27 04:50:40.819021: Epoch 4 :Val : ['ET : 0.6542715430259705', 'TC : 0.6421194076538086', 'WT : 0.78782719373703'] 
2023-05-27 04:50:40.821772: Epoch 4 :Val : ['ET : 0.6542715430259705', 'TC : 0.6421194076538086', 'WT : 0.78782719373703'] 
2023-05-27 04:50:40.823822: Saving the model with DSC 0.6860308647155762 
2023-05-27 04:50:41.535272: Val epoch done in 184.73465241699887 s 
2023-05-27 04:50:41.542097: Batches per epoch:  193 
2023-05-27 04:50:52.731301: train Epoch: [5][  0/193]	Time 11.189 (11.189)	Data 10.577 (10.577)	Loss 9.7406e-02 (9.7406e-02) 
2023-05-27 04:50:53.320951: train Epoch: [5][  1/193]	Time  0.590 ( 5.889)	Data  0.001 ( 5.289)	Loss 1.2047e-01 (1.0894e-01) 
2023-05-27 04:51:02.467430: train Epoch: [5][  2/193]	Time  9.146 ( 6.975)	Data  8.569 ( 6.383)	Loss 1.7446e-01 (1.3078e-01) 
2023-05-27 04:51:03.050741: train Epoch: [5][  3/193]	Time  0.583 ( 5.377)	Data  0.001 ( 4.787)	Loss 2.6733e-01 (1.6492e-01) 
2023-05-27 04:51:12.131809: train Epoch: [5][  4/193]	Time  9.081 ( 6.118)	Data  8.507 ( 5.531)	Loss 1.3698e-01 (1.5933e-01) 
2023-05-27 04:51:12.699193: train Epoch: [5][  5/193]	Time  0.567 ( 5.193)	Data  0.001 ( 4.610)	Loss 1.3910e-01 (1.5596e-01) 
2023-05-27 04:51:22.265364: train Epoch: [5][  6/193]	Time  9.566 ( 5.818)	Data  8.993 ( 5.236)	Loss 2.5864e-01 (1.7063e-01) 
2023-05-27 04:51:22.833733: train Epoch: [5][  7/193]	Time  0.568 ( 5.161)	Data  0.001 ( 4.581)	Loss 1.1281e-01 (1.6340e-01) 
2023-05-27 04:51:32.456879: train Epoch: [5][  8/193]	Time  9.623 ( 5.657)	Data  9.043 ( 5.077)	Loss 1.4600e-01 (1.6147e-01) 
2023-05-27 04:51:33.063895: train Epoch: [5][  9/193]	Time  0.607 ( 5.152)	Data  0.001 ( 4.570)	Loss 2.1581e-01 (1.6690e-01) 
2023-05-27 04:51:42.725231: train Epoch: [5][ 10/193]	Time  9.661 ( 5.562)	Data  9.044 ( 4.976)	Loss 1.7747e-01 (1.6786e-01) 
2023-05-27 04:51:43.293179: train Epoch: [5][ 11/193]	Time  0.568 ( 5.146)	Data  0.001 ( 4.562)	Loss 3.8792e-01 (1.8620e-01) 
2023-05-27 04:51:52.656908: train Epoch: [5][ 12/193]	Time  9.364 ( 5.470)	Data  8.794 ( 4.887)	Loss 1.4116e-01 (1.8273e-01) 
2023-05-27 04:51:53.234971: train Epoch: [5][ 13/193]	Time  0.578 ( 5.121)	Data  0.001 ( 4.538)	Loss 1.4862e-01 (1.8030e-01) 
2023-05-27 04:52:02.587723: train Epoch: [5][ 14/193]	Time  9.353 ( 5.403)	Data  8.777 ( 4.821)	Loss 1.1373e-01 (1.7586e-01) 
2023-05-27 04:52:03.190385: train Epoch: [5][ 15/193]	Time  0.603 ( 5.103)	Data  0.001 ( 4.520)	Loss 9.5676e-02 (1.7085e-01) 
2023-05-27 04:52:12.455976: train Epoch: [5][ 16/193]	Time  9.266 ( 5.348)	Data  8.692 ( 4.765)	Loss 1.1972e-01 (1.6784e-01) 
2023-05-27 04:52:13.106292: train Epoch: [5][ 17/193]	Time  0.650 ( 5.087)	Data  0.001 ( 4.500)	Loss 9.7260e-02 (1.6392e-01) 
2023-05-27 04:52:22.902597: train Epoch: [5][ 18/193]	Time  9.796 ( 5.335)	Data  9.214 ( 4.748)	Loss 1.4704e-01 (1.6303e-01) 
2023-05-27 04:52:23.475524: train Epoch: [5][ 19/193]	Time  0.573 ( 5.097)	Data  0.001 ( 4.511)	Loss 1.4020e-01 (1.6189e-01) 
2023-05-27 04:52:32.736564: train Epoch: [5][ 20/193]	Time  9.261 ( 5.295)	Data  8.687 ( 4.710)	Loss 2.3268e-01 (1.6526e-01) 
2023-05-27 04:52:33.325836: train Epoch: [5][ 21/193]	Time  0.589 ( 5.081)	Data  0.001 ( 4.496)	Loss 2.4135e-01 (1.6872e-01) 
2023-05-27 04:52:42.766181: train Epoch: [5][ 22/193]	Time  9.440 ( 5.271)	Data  8.874 ( 4.686)	Loss 1.8162e-01 (1.6928e-01) 
2023-05-27 04:52:43.346734: train Epoch: [5][ 23/193]	Time  0.581 ( 5.075)	Data  0.001 ( 4.491)	Loss 1.5352e-01 (1.6862e-01) 
2023-05-27 04:52:52.963254: train Epoch: [5][ 24/193]	Time  9.617 ( 5.257)	Data  9.044 ( 4.673)	Loss 1.4007e-01 (1.6748e-01) 
2023-05-27 04:52:53.536315: train Epoch: [5][ 25/193]	Time  0.573 ( 5.077)	Data  0.001 ( 4.493)	Loss 1.2523e-01 (1.6586e-01) 
2023-05-27 04:53:02.969640: train Epoch: [5][ 26/193]	Time  9.433 ( 5.238)	Data  8.834 ( 4.654)	Loss 1.8281e-01 (1.6648e-01) 
2023-05-27 04:53:03.567002: train Epoch: [5][ 27/193]	Time  0.597 ( 5.072)	Data  0.001 ( 4.488)	Loss 1.8362e-01 (1.6710e-01) 
2023-05-27 04:53:12.936378: train Epoch: [5][ 28/193]	Time  9.369 ( 5.220)	Data  8.794 ( 4.636)	Loss 9.8318e-02 (1.6472e-01) 
2023-05-27 04:53:13.502790: train Epoch: [5][ 29/193]	Time  0.566 ( 5.065)	Data  0.001 ( 4.482)	Loss 1.2916e-01 (1.6354e-01) 
2023-05-27 04:53:22.840918: train Epoch: [5][ 30/193]	Time  9.338 ( 5.203)	Data  8.759 ( 4.620)	Loss 1.5143e-01 (1.6315e-01) 
2023-05-27 04:53:23.403672: train Epoch: [5][ 31/193]	Time  0.563 ( 5.058)	Data  0.001 ( 4.476)	Loss 1.1550e-01 (1.6166e-01) 
2023-05-27 04:53:31.218798: train Epoch: [5][ 32/193]	Time  7.815 ( 5.142)	Data  7.237 ( 4.559)	Loss 1.4007e-01 (1.6101e-01) 
2023-05-27 04:53:31.790546: train Epoch: [5][ 33/193]	Time  0.572 ( 5.007)	Data  0.001 ( 4.425)	Loss 2.8422e-01 (1.6463e-01) 
2023-05-27 04:53:39.964227: train Epoch: [5][ 34/193]	Time  8.174 ( 5.098)	Data  7.600 ( 4.516)	Loss 2.1206e-01 (1.6598e-01) 
2023-05-27 04:53:40.539535: train Epoch: [5][ 35/193]	Time  0.575 ( 4.972)	Data  0.001 ( 4.390)	Loss 1.7396e-01 (1.6621e-01) 
2023-05-27 04:53:49.535331: train Epoch: [5][ 36/193]	Time  8.996 ( 5.081)	Data  8.430 ( 4.500)	Loss 1.2596e-01 (1.6512e-01) 
2023-05-27 04:53:50.108366: train Epoch: [5][ 37/193]	Time  0.573 ( 4.962)	Data  0.001 ( 4.381)	Loss 3.9123e-01 (1.7107e-01) 
2023-05-27 04:53:59.352482: train Epoch: [5][ 38/193]	Time  9.244 ( 5.072)	Data  8.681 ( 4.491)	Loss 2.0035e-01 (1.7182e-01) 
2023-05-27 04:53:59.917727: train Epoch: [5][ 39/193]	Time  0.565 ( 4.959)	Data  0.001 ( 4.379)	Loss 1.1364e-01 (1.7037e-01) 
2023-05-27 04:54:09.585755: train Epoch: [5][ 40/193]	Time  9.668 ( 5.074)	Data  9.103 ( 4.494)	Loss 1.3952e-01 (1.6961e-01) 
2023-05-27 04:54:10.154560: train Epoch: [5][ 41/193]	Time  0.569 ( 4.967)	Data  0.001 ( 4.387)	Loss 1.4847e-01 (1.6911e-01) 
2023-05-27 04:54:19.642460: train Epoch: [5][ 42/193]	Time  9.488 ( 5.072)	Data  8.917 ( 4.493)	Loss 1.5730e-01 (1.6883e-01) 
2023-05-27 04:54:20.213297: train Epoch: [5][ 43/193]	Time  0.571 ( 4.970)	Data  0.001 ( 4.391)	Loss 1.3699e-01 (1.6811e-01) 
2023-05-27 04:54:29.699082: train Epoch: [5][ 44/193]	Time  9.486 ( 5.070)	Data  8.908 ( 4.491)	Loss 1.7233e-01 (1.6820e-01) 
2023-05-27 04:54:30.276330: train Epoch: [5][ 45/193]	Time  0.577 ( 4.972)	Data  0.001 ( 4.393)	Loss 1.5156e-01 (1.6784e-01) 
2023-05-27 04:54:39.792324: train Epoch: [5][ 46/193]	Time  9.516 ( 5.069)	Data  8.947 ( 4.490)	Loss 2.4677e-01 (1.6952e-01) 
2023-05-27 04:54:40.363834: train Epoch: [5][ 47/193]	Time  0.572 ( 4.975)	Data  0.001 ( 4.397)	Loss 2.5053e-01 (1.7121e-01) 
2023-05-27 04:54:49.815207: train Epoch: [5][ 48/193]	Time  9.451 ( 5.067)	Data  8.887 ( 4.488)	Loss 1.4969e-01 (1.7077e-01) 
2023-05-27 04:54:50.381422: train Epoch: [5][ 49/193]	Time  0.566 ( 4.977)	Data  0.001 ( 4.399)	Loss 1.3402e-01 (1.7004e-01) 
2023-05-27 04:54:59.731795: train Epoch: [5][ 50/193]	Time  9.350 ( 5.063)	Data  8.767 ( 4.484)	Loss 2.4496e-01 (1.7150e-01) 
2023-05-27 04:55:00.311533: train Epoch: [5][ 51/193]	Time  0.580 ( 4.976)	Data  0.001 ( 4.398)	Loss 1.7088e-01 (1.7149e-01) 
2023-05-27 04:55:09.855022: train Epoch: [5][ 52/193]	Time  9.543 ( 5.062)	Data  8.966 ( 4.484)	Loss 1.0929e-01 (1.7032e-01) 
2023-05-27 04:55:10.423250: train Epoch: [5][ 53/193]	Time  0.568 ( 4.979)	Data  0.001 ( 4.401)	Loss 1.3946e-01 (1.6975e-01) 
2023-05-27 04:55:19.539302: train Epoch: [5][ 54/193]	Time  9.116 ( 5.054)	Data  8.553 ( 4.477)	Loss 1.0625e-01 (1.6859e-01) 
2023-05-27 04:55:20.101974: train Epoch: [5][ 55/193]	Time  0.563 ( 4.974)	Data  0.001 ( 4.397)	Loss 1.2597e-01 (1.6783e-01) 
2023-05-27 04:55:29.992016: train Epoch: [5][ 56/193]	Time  9.890 ( 5.061)	Data  9.328 ( 4.483)	Loss 1.7020e-01 (1.6787e-01) 
2023-05-27 04:55:30.555733: train Epoch: [5][ 57/193]	Time  0.564 ( 4.983)	Data  0.001 ( 4.406)	Loss 1.4714e-01 (1.6752e-01) 
2023-05-27 04:55:39.769997: train Epoch: [5][ 58/193]	Time  9.214 ( 5.055)	Data  8.650 ( 4.478)	Loss 9.4821e-02 (1.6628e-01) 
2023-05-27 04:55:40.339064: train Epoch: [5][ 59/193]	Time  0.569 ( 4.980)	Data  0.001 ( 4.403)	Loss 1.4878e-01 (1.6599e-01) 
2023-05-27 04:55:49.451973: train Epoch: [5][ 60/193]	Time  9.113 ( 5.048)	Data  8.550 ( 4.471)	Loss 1.2006e-01 (1.6524e-01) 
2023-05-27 04:55:50.015791: train Epoch: [5][ 61/193]	Time  0.564 ( 4.975)	Data  0.001 ( 4.399)	Loss 1.1797e-01 (1.6448e-01) 
2023-05-27 04:55:59.631494: train Epoch: [5][ 62/193]	Time  9.616 ( 5.049)	Data  9.049 ( 4.473)	Loss 1.5345e-01 (1.6430e-01) 
2023-05-27 04:56:00.196223: train Epoch: [5][ 63/193]	Time  0.565 ( 4.979)	Data  0.001 ( 4.403)	Loss 1.6383e-01 (1.6429e-01) 
2023-05-27 04:56:09.559895: train Epoch: [5][ 64/193]	Time  9.364 ( 5.046)	Data  8.801 ( 4.471)	Loss 1.5118e-01 (1.6409e-01) 
2023-05-27 04:56:10.125103: train Epoch: [5][ 65/193]	Time  0.565 ( 4.979)	Data  0.001 ( 4.403)	Loss 1.5862e-01 (1.6401e-01) 
2023-05-27 04:56:19.172573: train Epoch: [5][ 66/193]	Time  9.047 ( 5.039)	Data  8.481 ( 4.464)	Loss 1.6623e-01 (1.6404e-01) 
2023-05-27 04:56:19.738550: train Epoch: [5][ 67/193]	Time  0.566 ( 4.973)	Data  0.001 ( 4.398)	Loss 9.5945e-02 (1.6304e-01) 
2023-05-27 04:56:27.954929: train Epoch: [5][ 68/193]	Time  8.216 ( 5.020)	Data  7.643 ( 4.445)	Loss 1.7541e-01 (1.6322e-01) 
2023-05-27 04:56:28.517080: train Epoch: [5][ 69/193]	Time  0.562 ( 4.957)	Data  0.001 ( 4.382)	Loss 1.2371e-01 (1.6266e-01) 
2023-05-27 04:56:37.270933: train Epoch: [5][ 70/193]	Time  8.754 ( 5.010)	Data  8.181 ( 4.435)	Loss 1.5402e-01 (1.6253e-01) 
2023-05-27 04:56:37.872488: train Epoch: [5][ 71/193]	Time  0.602 ( 4.949)	Data  0.001 ( 4.374)	Loss 1.3482e-01 (1.6215e-01) 
2023-05-27 04:56:47.377376: train Epoch: [5][ 72/193]	Time  9.505 ( 5.011)	Data  8.938 ( 4.436)	Loss 1.0058e-01 (1.6131e-01) 
2023-05-27 04:56:47.950122: train Epoch: [5][ 73/193]	Time  0.573 ( 4.951)	Data  0.001 ( 4.376)	Loss 1.8638e-01 (1.6165e-01) 
2023-05-27 04:56:57.702312: train Epoch: [5][ 74/193]	Time  9.752 ( 5.015)	Data  9.180 ( 4.440)	Loss 1.4600e-01 (1.6144e-01) 
2023-05-27 04:56:58.285764: train Epoch: [5][ 75/193]	Time  0.583 ( 4.957)	Data  0.001 ( 4.382)	Loss 1.7731e-01 (1.6165e-01) 
2023-05-27 04:57:07.957125: train Epoch: [5][ 76/193]	Time  9.671 ( 5.018)	Data  9.069 ( 4.443)	Loss 1.4372e-01 (1.6141e-01) 
2023-05-27 04:57:08.525440: train Epoch: [5][ 77/193]	Time  0.568 ( 4.961)	Data  0.001 ( 4.386)	Loss 2.4643e-01 (1.6250e-01) 
2023-05-27 04:57:17.460810: train Epoch: [5][ 78/193]	Time  8.935 ( 5.012)	Data  8.334 ( 4.436)	Loss 2.7421e-01 (1.6392e-01) 
2023-05-27 04:57:18.025101: train Epoch: [5][ 79/193]	Time  0.564 ( 4.956)	Data  0.001 ( 4.380)	Loss 1.1786e-01 (1.6334e-01) 
2023-05-27 04:57:27.900755: train Epoch: [5][ 80/193]	Time  9.876 ( 5.017)	Data  9.299 ( 4.441)	Loss 1.2097e-01 (1.6282e-01) 
2023-05-27 04:57:28.466286: train Epoch: [5][ 81/193]	Time  0.566 ( 4.962)	Data  0.001 ( 4.387)	Loss 1.5558e-01 (1.6273e-01) 
2023-05-27 04:57:38.001127: train Epoch: [5][ 82/193]	Time  9.535 ( 5.018)	Data  8.969 ( 4.442)	Loss 1.9878e-01 (1.6316e-01) 
2023-05-27 04:57:38.565199: train Epoch: [5][ 83/193]	Time  0.564 ( 4.965)	Data  0.001 ( 4.389)	Loss 2.7199e-01 (1.6446e-01) 
2023-05-27 04:57:48.236516: train Epoch: [5][ 84/193]	Time  9.671 ( 5.020)	Data  9.102 ( 4.445)	Loss 1.0090e-01 (1.6371e-01) 
2023-05-27 04:57:48.808728: train Epoch: [5][ 85/193]	Time  0.572 ( 4.968)	Data  0.001 ( 4.393)	Loss 1.1606e-01 (1.6316e-01) 
2023-05-27 04:57:58.284373: train Epoch: [5][ 86/193]	Time  9.476 ( 5.020)	Data  8.912 ( 4.445)	Loss 1.5737e-01 (1.6309e-01) 
2023-05-27 04:57:58.850152: train Epoch: [5][ 87/193]	Time  0.566 ( 4.969)	Data  0.001 ( 4.395)	Loss 1.9478e-01 (1.6345e-01) 
2023-05-27 04:58:08.259910: train Epoch: [5][ 88/193]	Time  9.410 ( 5.019)	Data  8.846 ( 4.445)	Loss 1.6502e-01 (1.6347e-01) 
2023-05-27 04:58:08.823030: train Epoch: [5][ 89/193]	Time  0.563 ( 4.970)	Data  0.001 ( 4.395)	Loss 1.8350e-01 (1.6369e-01) 
2023-05-27 04:58:18.128457: train Epoch: [5][ 90/193]	Time  9.305 ( 5.017)	Data  8.735 ( 4.443)	Loss 1.7505e-01 (1.6382e-01) 
2023-05-27 04:58:18.708685: train Epoch: [5][ 91/193]	Time  0.580 ( 4.969)	Data  0.001 ( 4.395)	Loss 9.8661e-02 (1.6311e-01) 
2023-05-27 04:58:28.106028: train Epoch: [5][ 92/193]	Time  9.397 ( 5.017)	Data  8.834 ( 4.442)	Loss 1.5703e-01 (1.6304e-01) 
2023-05-27 04:58:28.672321: train Epoch: [5][ 93/193]	Time  0.566 ( 4.969)	Data  0.001 ( 4.395)	Loss 1.1069e-01 (1.6249e-01) 
2023-05-27 04:58:37.811049: train Epoch: [5][ 94/193]	Time  9.139 ( 5.013)	Data  8.576 ( 4.439)	Loss 1.9377e-01 (1.6281e-01) 
2023-05-27 04:58:38.377297: train Epoch: [5][ 95/193]	Time  0.566 ( 4.967)	Data  0.001 ( 4.393)	Loss 8.0602e-02 (1.6196e-01) 
2023-05-27 04:58:47.633916: train Epoch: [5][ 96/193]	Time  9.257 ( 5.011)	Data  8.686 ( 4.437)	Loss 3.0618e-01 (1.6345e-01) 
2023-05-27 04:58:48.196162: train Epoch: [5][ 97/193]	Time  0.562 ( 4.966)	Data  0.001 ( 4.392)	Loss 7.6463e-02 (1.6256e-01) 
2023-05-27 04:58:56.602499: train Epoch: [5][ 98/193]	Time  8.406 ( 5.001)	Data  7.836 ( 4.427)	Loss 2.0202e-01 (1.6296e-01) 
2023-05-27 04:58:57.181400: train Epoch: [5][ 99/193]	Time  0.579 ( 4.956)	Data  0.001 ( 4.382)	Loss 1.4060e-01 (1.6273e-01) 
2023-05-27 04:59:05.644359: train Epoch: [5][100/193]	Time  8.463 ( 4.991)	Data  7.854 ( 4.417)	Loss 1.6467e-01 (1.6275e-01) 
2023-05-27 04:59:06.236345: train Epoch: [5][101/193]	Time  0.592 ( 4.948)	Data  0.001 ( 4.373)	Loss 1.4678e-01 (1.6260e-01) 
2023-05-27 04:59:14.714862: train Epoch: [5][102/193]	Time  8.479 ( 4.982)	Data  7.902 ( 4.408)	Loss 1.2540e-01 (1.6223e-01) 
2023-05-27 04:59:15.281242: train Epoch: [5][103/193]	Time  0.566 ( 4.940)	Data  0.001 ( 4.365)	Loss 1.7423e-01 (1.6235e-01) 
2023-05-27 04:59:24.719054: train Epoch: [5][104/193]	Time  9.438 ( 4.983)	Data  8.866 ( 4.408)	Loss 2.2206e-01 (1.6292e-01) 
2023-05-27 04:59:25.287806: train Epoch: [5][105/193]	Time  0.569 ( 4.941)	Data  0.001 ( 4.367)	Loss 1.3674e-01 (1.6267e-01) 
2023-05-27 04:59:34.893857: train Epoch: [5][106/193]	Time  9.606 ( 4.985)	Data  9.042 ( 4.410)	Loss 1.4882e-01 (1.6254e-01) 
2023-05-27 04:59:35.459062: train Epoch: [5][107/193]	Time  0.565 ( 4.944)	Data  0.001 ( 4.370)	Loss 1.3995e-01 (1.6233e-01) 
2023-05-27 04:59:44.476956: train Epoch: [5][108/193]	Time  9.018 ( 4.981)	Data  8.452 ( 4.407)	Loss 2.3401e-01 (1.6299e-01) 
2023-05-27 04:59:45.042059: train Epoch: [5][109/193]	Time  0.565 ( 4.941)	Data  0.001 ( 4.367)	Loss 1.1590e-01 (1.6256e-01) 
2023-05-27 04:59:54.435976: train Epoch: [5][110/193]	Time  9.394 ( 4.981)	Data  8.824 ( 4.407)	Loss 1.6608e-01 (1.6259e-01) 
2023-05-27 04:59:54.999598: train Epoch: [5][111/193]	Time  0.564 ( 4.942)	Data  0.001 ( 4.368)	Loss 2.3921e-01 (1.6328e-01) 
2023-05-27 05:00:04.215278: train Epoch: [5][112/193]	Time  9.216 ( 4.979)	Data  8.642 ( 4.406)	Loss 1.3965e-01 (1.6307e-01) 
2023-05-27 05:00:04.779368: train Epoch: [5][113/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.367)	Loss 1.0528e-01 (1.6256e-01) 
2023-05-27 05:00:14.202970: train Epoch: [5][114/193]	Time  9.424 ( 4.980)	Data  8.858 ( 4.406)	Loss 1.4380e-01 (1.6240e-01) 
2023-05-27 05:00:14.769621: train Epoch: [5][115/193]	Time  0.567 ( 4.942)	Data  0.001 ( 4.368)	Loss 1.3297e-01 (1.6214e-01) 
2023-05-27 05:00:24.169298: train Epoch: [5][116/193]	Time  9.400 ( 4.980)	Data  8.835 ( 4.406)	Loss 1.1409e-01 (1.6173e-01) 
2023-05-27 05:00:24.736597: train Epoch: [5][117/193]	Time  0.567 ( 4.942)	Data  0.001 ( 4.369)	Loss 9.4776e-02 (1.6117e-01) 
2023-05-27 05:00:34.136115: train Epoch: [5][118/193]	Time  9.400 ( 4.980)	Data  8.823 ( 4.406)	Loss 1.5432e-01 (1.6111e-01) 
2023-05-27 05:00:34.710001: train Epoch: [5][119/193]	Time  0.574 ( 4.943)	Data  0.001 ( 4.370)	Loss 1.2750e-01 (1.6083e-01) 
2023-05-27 05:00:44.227642: train Epoch: [5][120/193]	Time  9.518 ( 4.981)	Data  8.945 ( 4.407)	Loss 1.1448e-01 (1.6045e-01) 
2023-05-27 05:00:44.797937: train Epoch: [5][121/193]	Time  0.570 ( 4.945)	Data  0.001 ( 4.371)	Loss 1.3739e-01 (1.6026e-01) 
2023-05-27 05:00:54.319325: train Epoch: [5][122/193]	Time  9.521 ( 4.982)	Data  8.952 ( 4.408)	Loss 1.8499e-01 (1.6046e-01) 
2023-05-27 05:00:54.884325: train Epoch: [5][123/193]	Time  0.565 ( 4.946)	Data  0.001 ( 4.373)	Loss 1.9553e-01 (1.6074e-01) 
2023-05-27 05:01:04.509918: train Epoch: [5][124/193]	Time  9.626 ( 4.984)	Data  9.062 ( 4.410)	Loss 9.9009e-02 (1.6025e-01) 
2023-05-27 05:01:05.080140: train Epoch: [5][125/193]	Time  0.570 ( 4.949)	Data  0.001 ( 4.375)	Loss 2.1978e-01 (1.6072e-01) 
2023-05-27 05:01:14.796948: train Epoch: [5][126/193]	Time  9.717 ( 4.986)	Data  9.153 ( 4.413)	Loss 8.2714e-02 (1.6011e-01) 
2023-05-27 05:01:15.361143: train Epoch: [5][127/193]	Time  0.564 ( 4.952)	Data  0.001 ( 4.379)	Loss 2.8785e-01 (1.6110e-01) 
2023-05-27 05:01:24.629048: train Epoch: [5][128/193]	Time  9.268 ( 4.985)	Data  8.684 ( 4.412)	Loss 1.0903e-01 (1.6070e-01) 
2023-05-27 05:01:25.192928: train Epoch: [5][129/193]	Time  0.564 ( 4.951)	Data  0.001 ( 4.378)	Loss 3.3516e-01 (1.6204e-01) 
2023-05-27 05:01:34.751362: train Epoch: [5][130/193]	Time  9.558 ( 4.986)	Data  8.993 ( 4.413)	Loss 2.8868e-01 (1.6301e-01) 
2023-05-27 05:01:35.314764: train Epoch: [5][131/193]	Time  0.563 ( 4.953)	Data  0.001 ( 4.380)	Loss 1.8003e-01 (1.6314e-01) 
2023-05-27 05:01:44.457958: train Epoch: [5][132/193]	Time  9.143 ( 4.984)	Data  8.579 ( 4.411)	Loss 1.8542e-01 (1.6330e-01) 
2023-05-27 05:01:45.020873: train Epoch: [5][133/193]	Time  0.563 ( 4.951)	Data  0.001 ( 4.379)	Loss 1.7757e-01 (1.6341e-01) 
2023-05-27 05:01:54.572209: train Epoch: [5][134/193]	Time  9.551 ( 4.985)	Data  8.983 ( 4.413)	Loss 1.1638e-01 (1.6306e-01) 
2023-05-27 05:01:55.136001: train Epoch: [5][135/193]	Time  0.564 ( 4.953)	Data  0.001 ( 4.380)	Loss 1.9063e-01 (1.6327e-01) 
2023-05-27 05:02:04.327924: train Epoch: [5][136/193]	Time  9.192 ( 4.984)	Data  8.608 ( 4.411)	Loss 2.3852e-01 (1.6381e-01) 
2023-05-27 05:02:04.892336: train Epoch: [5][137/193]	Time  0.564 ( 4.952)	Data  0.001 ( 4.379)	Loss 1.2185e-01 (1.6351e-01) 
2023-05-27 05:02:14.086180: train Epoch: [5][138/193]	Time  9.194 ( 4.982)	Data  8.630 ( 4.410)	Loss 1.7911e-01 (1.6362e-01) 
2023-05-27 05:02:14.655722: train Epoch: [5][139/193]	Time  0.570 ( 4.951)	Data  0.001 ( 4.378)	Loss 1.5611e-01 (1.6357e-01) 
2023-05-27 05:02:24.025591: train Epoch: [5][140/193]	Time  9.370 ( 4.982)	Data  8.799 ( 4.410)	Loss 1.1735e-01 (1.6324e-01) 
2023-05-27 05:02:24.591904: train Epoch: [5][141/193]	Time  0.566 ( 4.951)	Data  0.001 ( 4.378)	Loss 3.6922e-01 (1.6469e-01) 
2023-05-27 05:02:34.478101: train Epoch: [5][142/193]	Time  9.886 ( 4.986)	Data  9.321 ( 4.413)	Loss 2.0590e-01 (1.6498e-01) 
2023-05-27 05:02:35.059209: train Epoch: [5][143/193]	Time  0.581 ( 4.955)	Data  0.001 ( 4.382)	Loss 2.0997e-01 (1.6529e-01) 
2023-05-27 05:02:43.942194: train Epoch: [5][144/193]	Time  8.883 ( 4.982)	Data  8.317 ( 4.410)	Loss 1.4090e-01 (1.6512e-01) 
2023-05-27 05:02:44.506548: train Epoch: [5][145/193]	Time  0.564 ( 4.952)	Data  0.001 ( 4.379)	Loss 1.9787e-01 (1.6535e-01) 
2023-05-27 05:02:53.869197: train Epoch: [5][146/193]	Time  9.363 ( 4.982)	Data  8.791 ( 4.409)	Loss 1.1005e-01 (1.6497e-01) 
2023-05-27 05:02:54.447198: train Epoch: [5][147/193]	Time  0.578 ( 4.952)	Data  0.001 ( 4.380)	Loss 1.7633e-01 (1.6505e-01) 
2023-05-27 05:03:03.805547: train Epoch: [5][148/193]	Time  9.358 ( 4.982)	Data  8.794 ( 4.409)	Loss 2.2662e-01 (1.6546e-01) 
2023-05-27 05:03:04.370324: train Epoch: [5][149/193]	Time  0.565 ( 4.952)	Data  0.001 ( 4.380)	Loss 2.1031e-01 (1.6576e-01) 
2023-05-27 05:03:14.078807: train Epoch: [5][150/193]	Time  9.708 ( 4.984)	Data  9.144 ( 4.411)	Loss 2.7612e-01 (1.6649e-01) 
2023-05-27 05:03:14.642905: train Epoch: [5][151/193]	Time  0.564 ( 4.955)	Data  0.001 ( 4.382)	Loss 1.5607e-01 (1.6642e-01) 
2023-05-27 05:03:24.562323: train Epoch: [5][152/193]	Time  9.919 ( 4.987)	Data  9.352 ( 4.415)	Loss 1.4057e-01 (1.6625e-01) 
2023-05-27 05:03:25.136374: train Epoch: [5][153/193]	Time  0.574 ( 4.958)	Data  0.001 ( 4.386)	Loss 3.2151e-01 (1.6726e-01) 
2023-05-27 05:03:34.618478: train Epoch: [5][154/193]	Time  9.482 ( 4.988)	Data  8.918 ( 4.415)	Loss 1.0088e-01 (1.6683e-01) 
2023-05-27 05:03:35.182807: train Epoch: [5][155/193]	Time  0.564 ( 4.959)	Data  0.001 ( 4.387)	Loss 1.6877e-01 (1.6685e-01) 
2023-05-27 05:03:44.561631: train Epoch: [5][156/193]	Time  9.379 ( 4.987)	Data  8.810 ( 4.415)	Loss 1.4182e-01 (1.6669e-01) 
2023-05-27 05:03:45.125251: train Epoch: [5][157/193]	Time  0.564 ( 4.959)	Data  0.001 ( 4.387)	Loss 1.9231e-01 (1.6685e-01) 
2023-05-27 05:03:54.751094: train Epoch: [5][158/193]	Time  9.626 ( 4.989)	Data  9.060 ( 4.417)	Loss 1.6211e-01 (1.6682e-01) 
2023-05-27 05:03:55.329153: train Epoch: [5][159/193]	Time  0.578 ( 4.961)	Data  0.001 ( 4.389)	Loss 1.3889e-01 (1.6665e-01) 
2023-05-27 05:04:04.928255: train Epoch: [5][160/193]	Time  9.599 ( 4.990)	Data  9.036 ( 4.418)	Loss 2.6715e-01 (1.6727e-01) 
2023-05-27 05:04:05.490849: train Epoch: [5][161/193]	Time  0.563 ( 4.963)	Data  0.001 ( 4.391)	Loss 2.1606e-01 (1.6757e-01) 
2023-05-27 05:04:14.538880: train Epoch: [5][162/193]	Time  9.048 ( 4.988)	Data  8.484 ( 4.416)	Loss 1.1770e-01 (1.6727e-01) 
2023-05-27 05:04:15.102419: train Epoch: [5][163/193]	Time  0.564 ( 4.961)	Data  0.001 ( 4.389)	Loss 1.6257e-01 (1.6724e-01) 
2023-05-27 05:04:24.425286: train Epoch: [5][164/193]	Time  9.323 ( 4.987)	Data  8.753 ( 4.415)	Loss 1.5968e-01 (1.6719e-01) 
2023-05-27 05:04:24.991372: train Epoch: [5][165/193]	Time  0.566 ( 4.961)	Data  0.001 ( 4.389)	Loss 2.8794e-01 (1.6792e-01) 
2023-05-27 05:04:34.380135: train Epoch: [5][166/193]	Time  9.389 ( 4.987)	Data  8.824 ( 4.415)	Loss 2.0740e-01 (1.6815e-01) 
2023-05-27 05:04:34.943841: train Epoch: [5][167/193]	Time  0.564 ( 4.961)	Data  0.001 ( 4.389)	Loss 1.4404e-01 (1.6801e-01) 
2023-05-27 05:04:44.359083: train Epoch: [5][168/193]	Time  9.415 ( 4.987)	Data  8.851 ( 4.415)	Loss 1.9061e-01 (1.6814e-01) 
2023-05-27 05:04:44.921454: train Epoch: [5][169/193]	Time  0.562 ( 4.961)	Data  0.001 ( 4.389)	Loss 1.4794e-01 (1.6803e-01) 
2023-05-27 05:04:54.426785: train Epoch: [5][170/193]	Time  9.505 ( 4.988)	Data  8.939 ( 4.416)	Loss 1.1728e-01 (1.6773e-01) 
2023-05-27 05:04:55.005537: train Epoch: [5][171/193]	Time  0.579 ( 4.962)	Data  0.001 ( 4.390)	Loss 7.0409e-02 (1.6716e-01) 
2023-05-27 05:05:04.457905: train Epoch: [5][172/193]	Time  9.452 ( 4.988)	Data  8.889 ( 4.416)	Loss 1.9173e-01 (1.6731e-01) 
2023-05-27 05:05:05.021930: train Epoch: [5][173/193]	Time  0.564 ( 4.963)	Data  0.001 ( 4.391)	Loss 1.5597e-01 (1.6724e-01) 
2023-05-27 05:05:14.625777: train Epoch: [5][174/193]	Time  9.604 ( 4.989)	Data  9.031 ( 4.418)	Loss 1.8512e-01 (1.6734e-01) 
2023-05-27 05:05:15.191954: train Epoch: [5][175/193]	Time  0.566 ( 4.964)	Data  0.001 ( 4.392)	Loss 1.5811e-01 (1.6729e-01) 
2023-05-27 05:05:24.970031: train Epoch: [5][176/193]	Time  9.778 ( 4.991)	Data  9.198 ( 4.420)	Loss 2.0770e-01 (1.6752e-01) 
2023-05-27 05:05:25.581049: train Epoch: [5][177/193]	Time  0.611 ( 4.967)	Data  0.001 ( 4.395)	Loss 1.2425e-01 (1.6728e-01) 
2023-05-27 05:05:34.906464: train Epoch: [5][178/193]	Time  9.325 ( 4.991)	Data  8.758 ( 4.419)	Loss 8.3526e-02 (1.6681e-01) 
2023-05-27 05:05:35.492603: train Epoch: [5][179/193]	Time  0.586 ( 4.966)	Data  0.001 ( 4.395)	Loss 1.3261e-01 (1.6662e-01) 
2023-05-27 05:05:44.602129: train Epoch: [5][180/193]	Time  9.109 ( 4.989)	Data  8.534 ( 4.417)	Loss 2.8488e-01 (1.6727e-01) 
2023-05-27 05:05:45.207752: train Epoch: [5][181/193]	Time  0.606 ( 4.965)	Data  0.002 ( 4.393)	Loss 2.2838e-01 (1.6761e-01) 
2023-05-27 05:05:55.010793: train Epoch: [5][182/193]	Time  9.803 ( 4.992)	Data  9.207 ( 4.420)	Loss 2.1671e-01 (1.6787e-01) 
2023-05-27 05:05:55.625925: train Epoch: [5][183/193]	Time  0.615 ( 4.968)	Data  0.001 ( 4.396)	Loss 1.2659e-01 (1.6765e-01) 
2023-05-27 05:06:04.887121: train Epoch: [5][184/193]	Time  9.261 ( 4.991)	Data  8.689 ( 4.419)	Loss 9.0120e-02 (1.6723e-01) 
2023-05-27 05:06:05.458742: train Epoch: [5][185/193]	Time  0.572 ( 4.967)	Data  0.001 ( 4.395)	Loss 1.6068e-01 (1.6720e-01) 
2023-05-27 05:06:14.967829: train Epoch: [5][186/193]	Time  9.509 ( 4.992)	Data  8.946 ( 4.419)	Loss 1.6490e-01 (1.6718e-01) 
2023-05-27 05:06:15.539176: train Epoch: [5][187/193]	Time  0.571 ( 4.968)	Data  0.001 ( 4.396)	Loss 1.6332e-01 (1.6716e-01) 
2023-05-27 05:06:24.936996: train Epoch: [5][188/193]	Time  9.398 ( 4.992)	Data  8.787 ( 4.419)	Loss 1.6922e-01 (1.6717e-01) 
2023-05-27 05:06:25.509411: train Epoch: [5][189/193]	Time  0.572 ( 4.968)	Data  0.001 ( 4.396)	Loss 1.2654e-01 (1.6696e-01) 
2023-05-27 05:06:33.765551: train Epoch: [5][190/193]	Time  8.256 ( 4.985)	Data  7.672 ( 4.413)	Loss 1.5452e-01 (1.6690e-01) 
2023-05-27 05:06:34.358720: train Epoch: [5][191/193]	Time  0.593 ( 4.963)	Data  0.001 ( 4.390)	Loss 1.6270e-01 (1.6687e-01) 
2023-05-27 05:06:42.167414: train Epoch: [5][192/193]	Time  7.809 ( 4.977)	Data  7.243 ( 4.405)	Loss 1.1416e-01 (1.6660e-01) 
2023-05-27 05:06:42.317003: Train Epoch done in 960.7749484629894 s 
2023-05-27 05:06:48.984684: val Epoch: [5][ 0/72]	Time  5.729 ( 5.729)	Data  5.567 ( 5.567)	Loss 5.3781e-01 (5.3781e-01) 
2023-05-27 05:06:49.098271: val Epoch: [5][ 1/72]	Time  0.114 ( 2.921)	Data  0.001 ( 2.784)	Loss 1.1391e-01 (3.2586e-01) 
2023-05-27 05:06:53.826353: val Epoch: [5][ 2/72]	Time  4.728 ( 3.523)	Data  4.619 ( 3.396)	Loss 9.1067e-02 (2.4760e-01) 
2023-05-27 05:06:53.935261: val Epoch: [5][ 3/72]	Time  0.109 ( 2.670)	Data  0.000 ( 2.547)	Loss 2.4476e-01 (2.4689e-01) 
2023-05-27 05:06:59.102000: val Epoch: [5][ 4/72]	Time  5.167 ( 3.169)	Data  5.056 ( 3.049)	Loss 1.4636e-01 (2.2678e-01) 
2023-05-27 05:06:59.211688: val Epoch: [5][ 5/72]	Time  0.110 ( 2.659)	Data  0.001 ( 2.541)	Loss 1.8291e-01 (2.1947e-01) 
2023-05-27 05:07:04.093217: val Epoch: [5][ 6/72]	Time  4.882 ( 2.977)	Data  4.773 ( 2.860)	Loss 2.6219e-01 (2.2557e-01) 
2023-05-27 05:07:04.201256: val Epoch: [5][ 7/72]	Time  0.108 ( 2.618)	Data  0.001 ( 2.502)	Loss 2.4393e-01 (2.2787e-01) 
2023-05-27 05:07:09.151673: val Epoch: [5][ 8/72]	Time  4.950 ( 2.877)	Data  4.842 ( 2.762)	Loss 3.8911e-01 (2.4578e-01) 
2023-05-27 05:07:09.259764: val Epoch: [5][ 9/72]	Time  0.108 ( 2.600)	Data  0.000 ( 2.486)	Loss 4.3365e-01 (2.6457e-01) 
2023-05-27 05:07:14.108899: val Epoch: [5][10/72]	Time  4.849 ( 2.805)	Data  4.741 ( 2.691)	Loss 1.2743e-01 (2.5210e-01) 
2023-05-27 05:07:14.216569: val Epoch: [5][11/72]	Time  0.108 ( 2.580)	Data  0.000 ( 2.467)	Loss 1.8918e-01 (2.4686e-01) 
2023-05-27 05:07:19.088556: val Epoch: [5][12/72]	Time  4.872 ( 2.756)	Data  4.763 ( 2.644)	Loss 9.4175e-02 (2.3511e-01) 
2023-05-27 05:07:19.196456: val Epoch: [5][13/72]	Time  0.108 ( 2.567)	Data  0.000 ( 2.455)	Loss 1.3684e-01 (2.2809e-01) 
2023-05-27 05:07:24.369100: val Epoch: [5][14/72]	Time  5.173 ( 2.741)	Data  5.065 ( 2.629)	Loss 1.2924e-01 (2.2150e-01) 
2023-05-27 05:07:24.476536: val Epoch: [5][15/72]	Time  0.107 ( 2.576)	Data  0.000 ( 2.465)	Loss 3.4653e-01 (2.2932e-01) 
2023-05-27 05:07:29.818707: val Epoch: [5][16/72]	Time  5.342 ( 2.739)	Data  5.193 ( 2.625)	Loss 2.6601e-01 (2.3148e-01) 
2023-05-27 05:07:29.944300: val Epoch: [5][17/72]	Time  0.126 ( 2.594)	Data  0.001 ( 2.479)	Loss 8.7105e-02 (2.2346e-01) 
2023-05-27 05:07:34.917823: val Epoch: [5][18/72]	Time  4.974 ( 2.719)	Data  4.857 ( 2.604)	Loss 9.2261e-02 (2.1655e-01) 
2023-05-27 05:07:35.031023: val Epoch: [5][19/72]	Time  0.113 ( 2.589)	Data  0.001 ( 2.474)	Loss 1.0504e-01 (2.1098e-01) 
2023-05-27 05:07:40.242620: val Epoch: [5][20/72]	Time  5.212 ( 2.714)	Data  5.097 ( 2.599)	Loss 4.1842e-01 (2.2085e-01) 
2023-05-27 05:07:40.349917: val Epoch: [5][21/72]	Time  0.107 ( 2.595)	Data  0.001 ( 2.481)	Loss 1.0056e-01 (2.1539e-01) 
2023-05-27 05:07:45.127655: val Epoch: [5][22/72]	Time  4.778 ( 2.690)	Data  4.670 ( 2.576)	Loss 3.6368e-01 (2.2183e-01) 
2023-05-27 05:07:45.234286: val Epoch: [5][23/72]	Time  0.107 ( 2.582)	Data  0.000 ( 2.469)	Loss 1.2488e-01 (2.1779e-01) 
2023-05-27 05:07:50.160495: val Epoch: [5][24/72]	Time  4.926 ( 2.676)	Data  4.819 ( 2.563)	Loss 1.7895e-01 (2.1624e-01) 
2023-05-27 05:07:50.268396: val Epoch: [5][25/72]	Time  0.108 ( 2.577)	Data  0.000 ( 2.464)	Loss 1.0246e-01 (2.1186e-01) 
2023-05-27 05:07:55.333447: val Epoch: [5][26/72]	Time  5.065 ( 2.670)	Data  4.957 ( 2.557)	Loss 4.3090e-01 (2.1998e-01) 
2023-05-27 05:07:55.442804: val Epoch: [5][27/72]	Time  0.109 ( 2.578)	Data  0.001 ( 2.465)	Loss 1.6628e-01 (2.1806e-01) 
2023-05-27 05:08:00.387296: val Epoch: [5][28/72]	Time  4.944 ( 2.660)	Data  4.819 ( 2.546)	Loss 1.6132e-01 (2.1610e-01) 
2023-05-27 05:08:00.501007: val Epoch: [5][29/72]	Time  0.114 ( 2.575)	Data  0.001 ( 2.462)	Loss 1.7843e-01 (2.1485e-01) 
2023-05-27 05:08:05.518417: val Epoch: [5][30/72]	Time  5.017 ( 2.654)	Data  4.902 ( 2.540)	Loss 3.8579e-01 (2.2036e-01) 
2023-05-27 05:08:05.631407: val Epoch: [5][31/72]	Time  0.113 ( 2.574)	Data  0.001 ( 2.461)	Loss 1.8829e-01 (2.1936e-01) 
2023-05-27 05:08:10.642203: val Epoch: [5][32/72]	Time  5.011 ( 2.648)	Data  4.899 ( 2.535)	Loss 1.0666e-01 (2.1594e-01) 
2023-05-27 05:08:10.753213: val Epoch: [5][33/72]	Time  0.111 ( 2.573)	Data  0.001 ( 2.460)	Loss 9.4532e-02 (2.1237e-01) 
2023-05-27 05:08:15.696429: val Epoch: [5][34/72]	Time  4.943 ( 2.641)	Data  4.831 ( 2.528)	Loss 2.0584e-01 (2.1219e-01) 
2023-05-27 05:08:15.807848: val Epoch: [5][35/72]	Time  0.111 ( 2.571)	Data  0.001 ( 2.458)	Loss 2.8935e-01 (2.1433e-01) 
2023-05-27 05:08:20.752671: val Epoch: [5][36/72]	Time  4.945 ( 2.635)	Data  4.753 ( 2.520)	Loss 1.3891e-01 (2.1229e-01) 
2023-05-27 05:08:20.936994: val Epoch: [5][37/72]	Time  0.184 ( 2.571)	Data  0.002 ( 2.454)	Loss 2.4014e-01 (2.1302e-01) 
2023-05-27 05:08:25.596883: val Epoch: [5][38/72]	Time  4.660 ( 2.624)	Data  4.531 ( 2.507)	Loss 1.1751e-01 (2.1057e-01) 
2023-05-27 05:08:25.729916: val Epoch: [5][39/72]	Time  0.133 ( 2.562)	Data  0.001 ( 2.444)	Loss 1.1044e-01 (2.0807e-01) 
2023-05-27 05:08:30.360654: val Epoch: [5][40/72]	Time  4.631 ( 2.612)	Data  4.522 ( 2.495)	Loss 1.2977e-01 (2.0616e-01) 
2023-05-27 05:08:30.481386: val Epoch: [5][41/72]	Time  0.121 ( 2.553)	Data  0.000 ( 2.436)	Loss 1.2714e-01 (2.0428e-01) 
2023-05-27 05:08:35.236844: val Epoch: [5][42/72]	Time  4.755 ( 2.604)	Data  4.641 ( 2.487)	Loss 1.3901e-01 (2.0276e-01) 
2023-05-27 05:08:35.351764: val Epoch: [5][43/72]	Time  0.115 ( 2.548)	Data  0.001 ( 2.430)	Loss 1.6325e-01 (2.0186e-01) 
2023-05-27 05:08:40.158530: val Epoch: [5][44/72]	Time  4.807 ( 2.598)	Data  4.694 ( 2.481)	Loss 4.9372e-01 (2.0835e-01) 
2023-05-27 05:08:40.270316: val Epoch: [5][45/72]	Time  0.112 ( 2.544)	Data  0.001 ( 2.427)	Loss 1.6928e-01 (2.0750e-01) 
2023-05-27 05:08:45.312308: val Epoch: [5][46/72]	Time  5.042 ( 2.597)	Data  4.890 ( 2.479)	Loss 7.1119e-02 (2.0460e-01) 
2023-05-27 05:08:45.445582: val Epoch: [5][47/72]	Time  0.133 ( 2.546)	Data  0.002 ( 2.427)	Loss 5.8961e-01 (2.1262e-01) 
2023-05-27 05:08:50.223371: val Epoch: [5][48/72]	Time  4.778 ( 2.591)	Data  4.638 ( 2.473)	Loss 1.2737e-01 (2.1088e-01) 
2023-05-27 05:08:50.350737: val Epoch: [5][49/72]	Time  0.127 ( 2.542)	Data  0.001 ( 2.423)	Loss 2.2483e-01 (2.1116e-01) 
2023-05-27 05:08:55.325093: val Epoch: [5][50/72]	Time  4.974 ( 2.590)	Data  4.860 ( 2.471)	Loss 1.4541e-01 (2.0987e-01) 
2023-05-27 05:08:55.437409: val Epoch: [5][51/72]	Time  0.112 ( 2.542)	Data  0.001 ( 2.423)	Loss 2.7777e-01 (2.1118e-01) 
2023-05-27 05:09:00.418907: val Epoch: [5][52/72]	Time  4.981 ( 2.588)	Data  4.834 ( 2.469)	Loss 2.3706e-01 (2.1166e-01) 
2023-05-27 05:09:00.550269: val Epoch: [5][53/72]	Time  0.131 ( 2.542)	Data  0.013 ( 2.423)	Loss 1.8112e-01 (2.1110e-01) 
2023-05-27 05:09:05.376446: val Epoch: [5][54/72]	Time  4.826 ( 2.584)	Data  4.695 ( 2.465)	Loss 1.0668e-01 (2.0920e-01) 
2023-05-27 05:09:05.549755: val Epoch: [5][55/72]	Time  0.173 ( 2.541)	Data  0.003 ( 2.421)	Loss 1.5706e-01 (2.0827e-01) 
2023-05-27 05:09:10.424768: val Epoch: [5][56/72]	Time  4.875 ( 2.582)	Data  4.693 ( 2.461)	Loss 2.1539e-01 (2.0839e-01) 
2023-05-27 05:09:10.576044: val Epoch: [5][57/72]	Time  0.151 ( 2.540)	Data  0.001 ( 2.418)	Loss 5.0101e-01 (2.1344e-01) 
2023-05-27 05:09:15.374713: val Epoch: [5][58/72]	Time  4.799 ( 2.578)	Data  4.677 ( 2.457)	Loss 1.6865e-01 (2.1268e-01) 
2023-05-27 05:09:15.490161: val Epoch: [5][59/72]	Time  0.115 ( 2.537)	Data  0.001 ( 2.416)	Loss 4.3291e-01 (2.1635e-01) 
2023-05-27 05:09:20.215918: val Epoch: [5][60/72]	Time  4.726 ( 2.573)	Data  4.605 ( 2.452)	Loss 2.5284e-01 (2.1695e-01) 
2023-05-27 05:09:20.351096: val Epoch: [5][61/72]	Time  0.135 ( 2.534)	Data  0.001 ( 2.412)	Loss 1.0009e-01 (2.1506e-01) 
2023-05-27 05:09:25.195990: val Epoch: [5][62/72]	Time  4.845 ( 2.570)	Data  4.736 ( 2.449)	Loss 2.4303e-01 (2.1551e-01) 
2023-05-27 05:09:25.303461: val Epoch: [5][63/72]	Time  0.107 ( 2.532)	Data  0.001 ( 2.411)	Loss 4.5436e-01 (2.1924e-01) 
2023-05-27 05:09:29.704230: val Epoch: [5][64/72]	Time  4.401 ( 2.561)	Data  4.293 ( 2.440)	Loss 1.1849e-01 (2.1769e-01) 
2023-05-27 05:09:29.811568: val Epoch: [5][65/72]	Time  0.107 ( 2.524)	Data  0.001 ( 2.403)	Loss 1.4100e-01 (2.1653e-01) 
2023-05-27 05:09:34.602848: val Epoch: [5][66/72]	Time  4.791 ( 2.557)	Data  4.674 ( 2.437)	Loss 1.1894e-01 (2.1507e-01) 
2023-05-27 05:09:34.714234: val Epoch: [5][67/72]	Time  0.111 ( 2.521)	Data  0.001 ( 2.401)	Loss 2.5572e-01 (2.1567e-01) 
2023-05-27 05:09:39.610389: val Epoch: [5][68/72]	Time  4.896 ( 2.556)	Data  4.785 ( 2.435)	Loss 8.1222e-02 (2.1372e-01) 
2023-05-27 05:09:39.721865: val Epoch: [5][69/72]	Time  0.111 ( 2.521)	Data  0.000 ( 2.400)	Loss 8.2966e-02 (2.1185e-01) 
2023-05-27 05:09:44.434493: val Epoch: [5][70/72]	Time  4.713 ( 2.552)	Data  4.601 ( 2.431)	Loss 9.5078e-02 (2.1021e-01) 
2023-05-27 05:09:44.544147: val Epoch: [5][71/72]	Time  0.110 ( 2.518)	Data  0.000 ( 2.398)	Loss 1.5453e-01 (2.0944e-01) 
2023-05-27 05:09:44.824260: Epoch 5 :Val : ['ET : 0.6095278263092041', 'TC : 0.6286875605583191', 'WT : 0.7894083857536316'] 
2023-05-27 05:09:44.826943: Epoch 5 :Val : ['ET : 0.6095278263092041', 'TC : 0.6286875605583191', 'WT : 0.7894083857536316'] 
2023-05-27 05:09:44.829070: Val epoch done in 182.51208049200068 s 
2023-05-27 05:09:44.834824: Batches per epoch:  193 
2023-05-27 05:09:56.090654: train Epoch: [6][  0/193]	Time 11.256 (11.256)	Data 10.654 (10.654)	Loss 1.2325e-01 (1.2325e-01) 
2023-05-27 05:09:56.673221: train Epoch: [6][  1/193]	Time  0.583 ( 5.919)	Data  0.001 ( 5.328)	Loss 3.8719e-01 (2.5522e-01) 
2023-05-27 05:10:06.335146: train Epoch: [6][  2/193]	Time  9.662 ( 7.167)	Data  9.089 ( 6.582)	Loss 1.1046e-01 (2.0697e-01) 
2023-05-27 05:10:06.898239: train Epoch: [6][  3/193]	Time  0.563 ( 5.516)	Data  0.001 ( 4.936)	Loss 1.9006e-01 (2.0274e-01) 
2023-05-27 05:10:16.273392: train Epoch: [6][  4/193]	Time  9.375 ( 6.288)	Data  8.796 ( 5.708)	Loss 2.5344e-01 (2.1288e-01) 
2023-05-27 05:10:16.843110: train Epoch: [6][  5/193]	Time  0.570 ( 5.335)	Data  0.001 ( 4.757)	Loss 1.4950e-01 (2.0232e-01) 
2023-05-27 05:10:26.227248: train Epoch: [6][  6/193]	Time  9.384 ( 5.913)	Data  8.771 ( 5.331)	Loss 1.7746e-01 (1.9877e-01) 
2023-05-27 05:10:26.790094: train Epoch: [6][  7/193]	Time  0.563 ( 5.244)	Data  0.001 ( 4.664)	Loss 1.1801e-01 (1.8867e-01) 
2023-05-27 05:10:36.167930: train Epoch: [6][  8/193]	Time  9.378 ( 5.704)	Data  8.787 ( 5.122)	Loss 1.4154e-01 (1.8344e-01) 
2023-05-27 05:10:36.734816: train Epoch: [6][  9/193]	Time  0.567 ( 5.190)	Data  0.001 ( 4.610)	Loss 1.3494e-01 (1.7859e-01) 
2023-05-27 05:10:46.285463: train Epoch: [6][ 10/193]	Time  9.551 ( 5.586)	Data  8.988 ( 5.008)	Loss 3.2874e-01 (1.9224e-01) 
2023-05-27 05:10:46.853274: train Epoch: [6][ 11/193]	Time  0.568 ( 5.168)	Data  0.001 ( 4.591)	Loss 1.1373e-01 (1.8569e-01) 
2023-05-27 05:10:56.056755: train Epoch: [6][ 12/193]	Time  9.203 ( 5.479)	Data  8.638 ( 4.902)	Loss 3.2077e-01 (1.9609e-01) 
2023-05-27 05:10:56.620872: train Epoch: [6][ 13/193]	Time  0.564 ( 5.128)	Data  0.001 ( 4.552)	Loss 1.8197e-01 (1.9508e-01) 
2023-05-27 05:11:05.805058: train Epoch: [6][ 14/193]	Time  9.184 ( 5.398)	Data  8.621 ( 4.823)	Loss 2.0437e-01 (1.9570e-01) 
2023-05-27 05:11:06.369433: train Epoch: [6][ 15/193]	Time  0.564 ( 5.096)	Data  0.001 ( 4.522)	Loss 2.3194e-01 (1.9796e-01) 
2023-05-27 05:11:15.739309: train Epoch: [6][ 16/193]	Time  9.370 ( 5.347)	Data  8.800 ( 4.774)	Loss 1.3064e-01 (1.9400e-01) 
2023-05-27 05:11:16.308331: train Epoch: [6][ 17/193]	Time  0.569 ( 5.082)	Data  0.001 ( 4.508)	Loss 1.7750e-01 (1.9308e-01) 
2023-05-27 05:11:25.593817: train Epoch: [6][ 18/193]	Time  9.285 ( 5.303)	Data  8.706 ( 4.729)	Loss 3.2728e-01 (2.0015e-01) 
2023-05-27 05:11:26.156428: train Epoch: [6][ 19/193]	Time  0.563 ( 5.066)	Data  0.001 ( 4.493)	Loss 1.7882e-01 (1.9908e-01) 
2023-05-27 05:11:35.510813: train Epoch: [6][ 20/193]	Time  9.354 ( 5.270)	Data  8.757 ( 4.696)	Loss 1.9304e-01 (1.9879e-01) 
2023-05-27 05:11:36.073750: train Epoch: [6][ 21/193]	Time  0.563 ( 5.056)	Data  0.001 ( 4.483)	Loss 1.0337e-01 (1.9446e-01) 
2023-05-27 05:11:45.284029: train Epoch: [6][ 22/193]	Time  9.210 ( 5.237)	Data  8.642 ( 4.663)	Loss 1.2438e-01 (1.9141e-01) 
2023-05-27 05:11:45.846553: train Epoch: [6][ 23/193]	Time  0.563 ( 5.042)	Data  0.001 ( 4.469)	Loss 1.3375e-01 (1.8901e-01) 
2023-05-27 05:11:55.286574: train Epoch: [6][ 24/193]	Time  9.440 ( 5.218)	Data  8.877 ( 4.645)	Loss 3.3788e-01 (1.9496e-01) 
2023-05-27 05:11:55.851584: train Epoch: [6][ 25/193]	Time  0.565 ( 5.039)	Data  0.001 ( 4.467)	Loss 7.1619e-02 (1.9022e-01) 
2023-05-27 05:12:05.236390: train Epoch: [6][ 26/193]	Time  9.385 ( 5.200)	Data  8.821 ( 4.628)	Loss 3.1674e-01 (1.9490e-01) 
2023-05-27 05:12:05.799779: train Epoch: [6][ 27/193]	Time  0.563 ( 5.034)	Data  0.001 ( 4.463)	Loss 1.7817e-01 (1.9431e-01) 
2023-05-27 05:12:15.250165: train Epoch: [6][ 28/193]	Time  9.450 ( 5.187)	Data  8.882 ( 4.615)	Loss 1.6521e-01 (1.9330e-01) 
2023-05-27 05:12:15.814152: train Epoch: [6][ 29/193]	Time  0.564 ( 5.033)	Data  0.001 ( 4.461)	Loss 1.6855e-01 (1.9248e-01) 
2023-05-27 05:12:24.770131: train Epoch: [6][ 30/193]	Time  8.956 ( 5.159)	Data  8.355 ( 4.587)	Loss 1.4967e-01 (1.9110e-01) 
2023-05-27 05:12:25.333010: train Epoch: [6][ 31/193]	Time  0.563 ( 5.016)	Data  0.001 ( 4.444)	Loss 1.5827e-01 (1.9007e-01) 
2023-05-27 05:12:32.714362: train Epoch: [6][ 32/193]	Time  7.381 ( 5.087)	Data  6.809 ( 4.515)	Loss 1.0820e-01 (1.8759e-01) 
2023-05-27 05:12:33.278228: train Epoch: [6][ 33/193]	Time  0.564 ( 4.954)	Data  0.001 ( 4.383)	Loss 9.1571e-02 (1.8477e-01) 
2023-05-27 05:12:42.690743: train Epoch: [6][ 34/193]	Time  9.413 ( 5.082)	Data  8.842 ( 4.510)	Loss 2.0423e-01 (1.8532e-01) 
2023-05-27 05:12:43.252736: train Epoch: [6][ 35/193]	Time  0.562 ( 4.956)	Data  0.001 ( 4.385)	Loss 1.5864e-01 (1.8458e-01) 
2023-05-27 05:12:52.318955: train Epoch: [6][ 36/193]	Time  9.066 ( 5.067)	Data  8.492 ( 4.496)	Loss 1.3535e-01 (1.8325e-01) 
2023-05-27 05:12:52.887625: train Epoch: [6][ 37/193]	Time  0.569 ( 4.949)	Data  0.001 ( 4.377)	Loss 1.1280e-01 (1.8140e-01) 
2023-05-27 05:13:02.406392: train Epoch: [6][ 38/193]	Time  9.519 ( 5.066)	Data  8.944 ( 4.495)	Loss 3.5965e-01 (1.8597e-01) 
2023-05-27 05:13:02.968386: train Epoch: [6][ 39/193]	Time  0.562 ( 4.953)	Data  0.001 ( 4.382)	Loss 1.0896e-01 (1.8404e-01) 
2023-05-27 05:13:12.427644: train Epoch: [6][ 40/193]	Time  9.459 ( 5.063)	Data  8.896 ( 4.492)	Loss 1.2114e-01 (1.8251e-01) 
2023-05-27 05:13:12.991456: train Epoch: [6][ 41/193]	Time  0.564 ( 4.956)	Data  0.001 ( 4.385)	Loss 1.7613e-01 (1.8236e-01) 
2023-05-27 05:13:22.071534: train Epoch: [6][ 42/193]	Time  9.080 ( 5.052)	Data  8.512 ( 4.481)	Loss 1.8158e-01 (1.8234e-01) 
2023-05-27 05:13:22.639545: train Epoch: [6][ 43/193]	Time  0.568 ( 4.950)	Data  0.001 ( 4.379)	Loss 1.4854e-01 (1.8157e-01) 
2023-05-27 05:13:31.790003: train Epoch: [6][ 44/193]	Time  9.150 ( 5.043)	Data  8.576 ( 4.473)	Loss 1.3660e-01 (1.8057e-01) 
2023-05-27 05:13:32.351846: train Epoch: [6][ 45/193]	Time  0.562 ( 4.946)	Data  0.001 ( 4.376)	Loss 1.2660e-01 (1.7940e-01) 
2023-05-27 05:13:41.765451: train Epoch: [6][ 46/193]	Time  9.414 ( 5.041)	Data  8.840 ( 4.471)	Loss 1.2634e-01 (1.7827e-01) 
2023-05-27 05:13:42.329149: train Epoch: [6][ 47/193]	Time  0.564 ( 4.948)	Data  0.001 ( 4.377)	Loss 4.3946e-01 (1.8371e-01) 
2023-05-27 05:13:51.300905: train Epoch: [6][ 48/193]	Time  8.972 ( 5.030)	Data  8.408 ( 4.460)	Loss 1.4587e-01 (1.8294e-01) 
2023-05-27 05:13:51.863568: train Epoch: [6][ 49/193]	Time  0.563 ( 4.941)	Data  0.001 ( 4.370)	Loss 1.0698e-01 (1.8142e-01) 
2023-05-27 05:14:00.917508: train Epoch: [6][ 50/193]	Time  9.054 ( 5.021)	Data  8.490 ( 4.451)	Loss 8.5122e-02 (1.7953e-01) 
2023-05-27 05:14:01.480000: train Epoch: [6][ 51/193]	Time  0.562 ( 4.935)	Data  0.001 ( 4.366)	Loss 8.6676e-02 (1.7774e-01) 
2023-05-27 05:14:11.111506: train Epoch: [6][ 52/193]	Time  9.632 ( 5.024)	Data  9.068 ( 4.454)	Loss 2.5048e-01 (1.7912e-01) 
2023-05-27 05:14:11.676985: train Epoch: [6][ 53/193]	Time  0.565 ( 4.942)	Data  0.001 ( 4.372)	Loss 2.3720e-01 (1.8019e-01) 
2023-05-27 05:14:20.933911: train Epoch: [6][ 54/193]	Time  9.257 ( 5.020)	Data  8.692 ( 4.450)	Loss 2.0685e-01 (1.8068e-01) 
2023-05-27 05:14:21.499122: train Epoch: [6][ 55/193]	Time  0.565 ( 4.940)	Data  0.001 ( 4.371)	Loss 2.1252e-01 (1.8125e-01) 
2023-05-27 05:14:30.562673: train Epoch: [6][ 56/193]	Time  9.064 ( 5.013)	Data  8.494 ( 4.443)	Loss 9.8077e-02 (1.7979e-01) 
2023-05-27 05:14:31.126925: train Epoch: [6][ 57/193]	Time  0.564 ( 4.936)	Data  0.001 ( 4.367)	Loss 1.5497e-01 (1.7936e-01) 
2023-05-27 05:14:40.929544: train Epoch: [6][ 58/193]	Time  9.803 ( 5.019)	Data  9.238 ( 4.449)	Loss 1.5413e-01 (1.7893e-01) 
2023-05-27 05:14:41.491232: train Epoch: [6][ 59/193]	Time  0.562 ( 4.944)	Data  0.001 ( 4.375)	Loss 1.4422e-01 (1.7835e-01) 
2023-05-27 05:14:50.988964: train Epoch: [6][ 60/193]	Time  9.498 ( 5.019)	Data  8.936 ( 4.450)	Loss 1.3032e-01 (1.7757e-01) 
2023-05-27 05:14:51.553400: train Epoch: [6][ 61/193]	Time  0.564 ( 4.947)	Data  0.001 ( 4.378)	Loss 1.7120e-01 (1.7746e-01) 
2023-05-27 05:15:00.999212: train Epoch: [6][ 62/193]	Time  9.446 ( 5.018)	Data  8.883 ( 4.450)	Loss 1.9803e-01 (1.7779e-01) 
2023-05-27 05:15:01.561695: train Epoch: [6][ 63/193]	Time  0.562 ( 4.949)	Data  0.001 ( 4.380)	Loss 1.2288e-01 (1.7693e-01) 
2023-05-27 05:15:10.264516: train Epoch: [6][ 64/193]	Time  8.703 ( 5.007)	Data  8.140 ( 4.438)	Loss 2.3865e-01 (1.7788e-01) 
2023-05-27 05:15:10.829008: train Epoch: [6][ 65/193]	Time  0.564 ( 4.939)	Data  0.001 ( 4.371)	Loss 2.5160e-01 (1.7900e-01) 
2023-05-27 05:15:19.494205: train Epoch: [6][ 66/193]	Time  8.665 ( 4.995)	Data  8.098 ( 4.426)	Loss 1.9534e-01 (1.7924e-01) 
2023-05-27 05:15:20.059184: train Epoch: [6][ 67/193]	Time  0.565 ( 4.930)	Data  0.001 ( 4.361)	Loss 1.3788e-01 (1.7863e-01) 
2023-05-27 05:15:29.514045: train Epoch: [6][ 68/193]	Time  9.455 ( 4.995)	Data  8.891 ( 4.427)	Loss 1.6621e-01 (1.7845e-01) 
2023-05-27 05:15:30.090419: train Epoch: [6][ 69/193]	Time  0.576 ( 4.932)	Data  0.001 ( 4.364)	Loss 1.6951e-01 (1.7833e-01) 
2023-05-27 05:15:39.539032: train Epoch: [6][ 70/193]	Time  9.449 ( 4.996)	Data  8.849 ( 4.427)	Loss 1.1948e-01 (1.7750e-01) 
2023-05-27 05:15:40.164282: train Epoch: [6][ 71/193]	Time  0.625 ( 4.935)	Data  0.001 ( 4.365)	Loss 4.2228e-01 (1.8090e-01) 
2023-05-27 05:15:49.653624: train Epoch: [6][ 72/193]	Time  9.489 ( 4.998)	Data  8.916 ( 4.428)	Loss 9.4122e-02 (1.7971e-01) 
2023-05-27 05:15:50.231289: train Epoch: [6][ 73/193]	Time  0.578 ( 4.938)	Data  0.001 ( 4.368)	Loss 9.6406e-02 (1.7858e-01) 
2023-05-27 05:16:00.143329: train Epoch: [6][ 74/193]	Time  9.912 ( 5.004)	Data  9.315 ( 4.434)	Loss 1.8805e-01 (1.7871e-01) 
2023-05-27 05:16:00.719138: train Epoch: [6][ 75/193]	Time  0.576 ( 4.946)	Data  0.001 ( 4.376)	Loss 1.0730e-01 (1.7777e-01) 
2023-05-27 05:16:09.888540: train Epoch: [6][ 76/193]	Time  9.169 ( 5.001)	Data  8.579 ( 4.430)	Loss 9.4756e-02 (1.7669e-01) 
2023-05-27 05:16:10.466752: train Epoch: [6][ 77/193]	Time  0.578 ( 4.944)	Data  0.001 ( 4.373)	Loss 1.1403e-01 (1.7589e-01) 
2023-05-27 05:16:19.935318: train Epoch: [6][ 78/193]	Time  9.469 ( 5.001)	Data  8.885 ( 4.431)	Loss 9.4341e-02 (1.7486e-01) 
2023-05-27 05:16:20.505484: train Epoch: [6][ 79/193]	Time  0.570 ( 4.946)	Data  0.001 ( 4.375)	Loss 2.6235e-01 (1.7595e-01) 
2023-05-27 05:16:29.870115: train Epoch: [6][ 80/193]	Time  9.365 ( 5.000)	Data  8.763 ( 4.429)	Loss 1.6190e-01 (1.7578e-01) 
2023-05-27 05:16:30.432113: train Epoch: [6][ 81/193]	Time  0.562 ( 4.946)	Data  0.001 ( 4.375)	Loss 1.5043e-01 (1.7547e-01) 
2023-05-27 05:16:39.907597: train Epoch: [6][ 82/193]	Time  9.476 ( 5.001)	Data  8.906 ( 4.430)	Loss 1.8017e-01 (1.7552e-01) 
2023-05-27 05:16:40.474588: train Epoch: [6][ 83/193]	Time  0.567 ( 4.948)	Data  0.001 ( 4.377)	Loss 1.2907e-01 (1.7497e-01) 
2023-05-27 05:16:49.718637: train Epoch: [6][ 84/193]	Time  9.244 ( 4.999)	Data  8.668 ( 4.428)	Loss 1.7181e-01 (1.7493e-01) 
2023-05-27 05:16:50.281443: train Epoch: [6][ 85/193]	Time  0.563 ( 4.947)	Data  0.001 ( 4.376)	Loss 1.8823e-01 (1.7509e-01) 
2023-05-27 05:16:59.507692: train Epoch: [6][ 86/193]	Time  9.226 ( 4.996)	Data  8.632 ( 4.425)	Loss 9.0566e-02 (1.7412e-01) 
2023-05-27 05:17:00.070584: train Epoch: [6][ 87/193]	Time  0.563 ( 4.946)	Data  0.001 ( 4.375)	Loss 2.0635e-01 (1.7448e-01) 
2023-05-27 05:17:09.561646: train Epoch: [6][ 88/193]	Time  9.491 ( 4.997)	Data  8.926 ( 4.426)	Loss 1.6621e-01 (1.7439e-01) 
2023-05-27 05:17:10.133697: train Epoch: [6][ 89/193]	Time  0.572 ( 4.948)	Data  0.001 ( 4.377)	Loss 2.3495e-01 (1.7506e-01) 
2023-05-27 05:17:19.940295: train Epoch: [6][ 90/193]	Time  9.807 ( 5.001)	Data  9.244 ( 4.430)	Loss 4.8201e-01 (1.7844e-01) 
2023-05-27 05:17:20.502763: train Epoch: [6][ 91/193]	Time  0.562 ( 4.953)	Data  0.001 ( 4.382)	Loss 1.9264e-01 (1.7859e-01) 
2023-05-27 05:17:29.519689: train Epoch: [6][ 92/193]	Time  9.017 ( 4.997)	Data  8.453 ( 4.426)	Loss 2.3164e-01 (1.7916e-01) 
2023-05-27 05:17:30.083428: train Epoch: [6][ 93/193]	Time  0.564 ( 4.949)	Data  0.001 ( 4.379)	Loss 1.8488e-01 (1.7922e-01) 
2023-05-27 05:17:39.786868: train Epoch: [6][ 94/193]	Time  9.703 ( 4.999)	Data  9.122 ( 4.429)	Loss 1.4975e-01 (1.7891e-01) 
2023-05-27 05:17:40.349513: train Epoch: [6][ 95/193]	Time  0.563 ( 4.953)	Data  0.001 ( 4.383)	Loss 1.5259e-01 (1.7864e-01) 
2023-05-27 05:17:49.894998: train Epoch: [6][ 96/193]	Time  9.545 ( 5.001)	Data  8.982 ( 4.430)	Loss 1.5565e-01 (1.7840e-01) 
2023-05-27 05:17:50.459321: train Epoch: [6][ 97/193]	Time  0.564 ( 4.955)	Data  0.001 ( 4.385)	Loss 1.9530e-01 (1.7857e-01) 
2023-05-27 05:17:58.761407: train Epoch: [6][ 98/193]	Time  8.302 ( 4.989)	Data  7.740 ( 4.419)	Loss 1.5001e-01 (1.7828e-01) 
2023-05-27 05:17:59.323313: train Epoch: [6][ 99/193]	Time  0.562 ( 4.945)	Data  0.001 ( 4.375)	Loss 1.3368e-01 (1.7784e-01) 
2023-05-27 05:18:07.354896: train Epoch: [6][100/193]	Time  8.032 ( 4.975)	Data  7.463 ( 4.405)	Loss 1.6895e-01 (1.7775e-01) 
2023-05-27 05:18:07.919157: train Epoch: [6][101/193]	Time  0.564 ( 4.932)	Data  0.001 ( 4.362)	Loss 2.6293e-01 (1.7858e-01) 
2023-05-27 05:18:16.409997: train Epoch: [6][102/193]	Time  8.491 ( 4.967)	Data  7.926 ( 4.397)	Loss 2.1085e-01 (1.7890e-01) 
2023-05-27 05:18:16.973871: train Epoch: [6][103/193]	Time  0.564 ( 4.924)	Data  0.001 ( 4.354)	Loss 1.1326e-01 (1.7827e-01) 
2023-05-27 05:18:26.564035: train Epoch: [6][104/193]	Time  9.590 ( 4.969)	Data  9.021 ( 4.399)	Loss 2.3596e-01 (1.7882e-01) 
2023-05-27 05:18:27.129284: train Epoch: [6][105/193]	Time  0.565 ( 4.927)	Data  0.001 ( 4.357)	Loss 1.6570e-01 (1.7869e-01) 
2023-05-27 05:18:36.458778: train Epoch: [6][106/193]	Time  9.329 ( 4.968)	Data  8.756 ( 4.398)	Loss 1.0504e-01 (1.7800e-01) 
2023-05-27 05:18:37.026718: train Epoch: [6][107/193]	Time  0.568 ( 4.928)	Data  0.001 ( 4.358)	Loss 2.5134e-01 (1.7868e-01) 
2023-05-27 05:18:46.349814: train Epoch: [6][108/193]	Time  9.323 ( 4.968)	Data  8.757 ( 4.398)	Loss 1.2081e-01 (1.7815e-01) 
2023-05-27 05:18:46.915897: train Epoch: [6][109/193]	Time  0.566 ( 4.928)	Data  0.001 ( 4.358)	Loss 1.8670e-01 (1.7823e-01) 
2023-05-27 05:18:56.108277: train Epoch: [6][110/193]	Time  9.192 ( 4.966)	Data  8.627 ( 4.396)	Loss 1.4246e-01 (1.7791e-01) 
2023-05-27 05:18:56.674531: train Epoch: [6][111/193]	Time  0.566 ( 4.927)	Data  0.001 ( 4.357)	Loss 1.7594e-01 (1.7789e-01) 
2023-05-27 05:19:05.898741: train Epoch: [6][112/193]	Time  9.224 ( 4.965)	Data  8.660 ( 4.395)	Loss 1.0219e-01 (1.7722e-01) 
2023-05-27 05:19:06.462984: train Epoch: [6][113/193]	Time  0.564 ( 4.927)	Data  0.001 ( 4.357)	Loss 1.1788e-01 (1.7670e-01) 
2023-05-27 05:19:15.331333: train Epoch: [6][114/193]	Time  8.868 ( 4.961)	Data  8.295 ( 4.391)	Loss 1.2178e-01 (1.7622e-01) 
2023-05-27 05:19:15.894592: train Epoch: [6][115/193]	Time  0.563 ( 4.923)	Data  0.001 ( 4.353)	Loss 1.9112e-01 (1.7635e-01) 
2023-05-27 05:19:25.258097: train Epoch: [6][116/193]	Time  9.364 ( 4.961)	Data  8.795 ( 4.391)	Loss 1.5706e-01 (1.7619e-01) 
2023-05-27 05:19:25.827736: train Epoch: [6][117/193]	Time  0.570 ( 4.924)	Data  0.001 ( 4.354)	Loss 2.8604e-01 (1.7712e-01) 
2023-05-27 05:19:34.945802: train Epoch: [6][118/193]	Time  9.118 ( 4.959)	Data  8.555 ( 4.389)	Loss 1.7777e-01 (1.7712e-01) 
2023-05-27 05:19:35.509859: train Epoch: [6][119/193]	Time  0.564 ( 4.922)	Data  0.001 ( 4.353)	Loss 1.9904e-01 (1.7730e-01) 
2023-05-27 05:19:44.813995: train Epoch: [6][120/193]	Time  9.304 ( 4.958)	Data  8.738 ( 4.389)	Loss 1.8561e-01 (1.7737e-01) 
2023-05-27 05:19:45.379698: train Epoch: [6][121/193]	Time  0.566 ( 4.922)	Data  0.001 ( 4.353)	Loss 1.0559e-01 (1.7679e-01) 
2023-05-27 05:19:54.579142: train Epoch: [6][122/193]	Time  9.199 ( 4.957)	Data  8.627 ( 4.388)	Loss 1.3775e-01 (1.7647e-01) 
2023-05-27 05:19:55.142030: train Epoch: [6][123/193]	Time  0.563 ( 4.922)	Data  0.001 ( 4.352)	Loss 1.5648e-01 (1.7631e-01) 
2023-05-27 05:20:04.486548: train Epoch: [6][124/193]	Time  9.344 ( 4.957)	Data  8.757 ( 4.388)	Loss 1.2099e-01 (1.7586e-01) 
2023-05-27 05:20:05.067432: train Epoch: [6][125/193]	Time  0.581 ( 4.922)	Data  0.001 ( 4.353)	Loss 2.0327e-01 (1.7608e-01) 
2023-05-27 05:20:14.154829: train Epoch: [6][126/193]	Time  9.087 ( 4.955)	Data  8.518 ( 4.386)	Loss 2.2023e-01 (1.7643e-01) 
2023-05-27 05:20:14.726213: train Epoch: [6][127/193]	Time  0.571 ( 4.921)	Data  0.001 ( 4.351)	Loss 1.6490e-01 (1.7634e-01) 
2023-05-27 05:20:24.108673: train Epoch: [6][128/193]	Time  9.382 ( 4.956)	Data  8.816 ( 4.386)	Loss 2.1170e-01 (1.7661e-01) 
2023-05-27 05:20:24.709146: train Epoch: [6][129/193]	Time  0.600 ( 4.922)	Data  0.001 ( 4.352)	Loss 1.3583e-01 (1.7630e-01) 
2023-05-27 05:20:34.013820: train Epoch: [6][130/193]	Time  9.305 ( 4.956)	Data  8.732 ( 4.386)	Loss 1.4976e-01 (1.7610e-01) 
2023-05-27 05:20:34.577173: train Epoch: [6][131/193]	Time  0.563 ( 4.922)	Data  0.001 ( 4.352)	Loss 1.0288e-01 (1.7554e-01) 
2023-05-27 05:20:43.860732: train Epoch: [6][132/193]	Time  9.284 ( 4.955)	Data  8.684 ( 4.385)	Loss 1.1102e-01 (1.7506e-01) 
2023-05-27 05:20:44.436173: train Epoch: [6][133/193]	Time  0.575 ( 4.922)	Data  0.001 ( 4.352)	Loss 1.7080e-01 (1.7503e-01) 
2023-05-27 05:20:53.592448: train Epoch: [6][134/193]	Time  9.156 ( 4.954)	Data  8.578 ( 4.384)	Loss 1.2710e-01 (1.7467e-01) 
2023-05-27 05:20:54.172179: train Epoch: [6][135/193]	Time  0.580 ( 4.922)	Data  0.001 ( 4.351)	Loss 1.7575e-01 (1.7468e-01) 
2023-05-27 05:21:03.723563: train Epoch: [6][136/193]	Time  9.551 ( 4.955)	Data  8.967 ( 4.385)	Loss 1.6808e-01 (1.7463e-01) 
2023-05-27 05:21:04.297084: train Epoch: [6][137/193]	Time  0.574 ( 4.924)	Data  0.001 ( 4.353)	Loss 1.8337e-01 (1.7469e-01) 
2023-05-27 05:21:13.494646: train Epoch: [6][138/193]	Time  9.198 ( 4.954)	Data  8.626 ( 4.384)	Loss 1.6315e-01 (1.7461e-01) 
2023-05-27 05:21:14.058524: train Epoch: [6][139/193]	Time  0.564 ( 4.923)	Data  0.001 ( 4.353)	Loss 3.2379e-01 (1.7568e-01) 
2023-05-27 05:21:23.230250: train Epoch: [6][140/193]	Time  9.172 ( 4.953)	Data  8.577 ( 4.383)	Loss 2.0219e-01 (1.7586e-01) 
2023-05-27 05:21:23.794415: train Epoch: [6][141/193]	Time  0.564 ( 4.922)	Data  0.001 ( 4.352)	Loss 4.0231e-01 (1.7746e-01) 
2023-05-27 05:21:33.227875: train Epoch: [6][142/193]	Time  9.433 ( 4.954)	Data  8.858 ( 4.383)	Loss 2.3405e-01 (1.7785e-01) 
2023-05-27 05:21:33.790638: train Epoch: [6][143/193]	Time  0.563 ( 4.923)	Data  0.001 ( 4.353)	Loss 2.2056e-01 (1.7815e-01) 
2023-05-27 05:21:43.540591: train Epoch: [6][144/193]	Time  9.750 ( 4.957)	Data  9.169 ( 4.386)	Loss 9.7111e-02 (1.7759e-01) 
2023-05-27 05:21:44.104152: train Epoch: [6][145/193]	Time  0.564 ( 4.926)	Data  0.001 ( 4.356)	Loss 3.0056e-01 (1.7843e-01) 
2023-05-27 05:21:53.629076: train Epoch: [6][146/193]	Time  9.525 ( 4.958)	Data  8.954 ( 4.387)	Loss 1.0070e-01 (1.7791e-01) 
2023-05-27 05:21:54.196248: train Epoch: [6][147/193]	Time  0.567 ( 4.928)	Data  0.001 ( 4.358)	Loss 1.4946e-01 (1.7771e-01) 
2023-05-27 05:22:03.637090: train Epoch: [6][148/193]	Time  9.441 ( 4.958)	Data  8.875 ( 4.388)	Loss 1.6582e-01 (1.7763e-01) 
2023-05-27 05:22:04.202993: train Epoch: [6][149/193]	Time  0.566 ( 4.929)	Data  0.001 ( 4.359)	Loss 1.4927e-01 (1.7744e-01) 
2023-05-27 05:22:13.889458: train Epoch: [6][150/193]	Time  9.686 ( 4.961)	Data  9.118 ( 4.390)	Loss 1.4270e-01 (1.7721e-01) 
2023-05-27 05:22:14.459762: train Epoch: [6][151/193]	Time  0.570 ( 4.932)	Data  0.001 ( 4.361)	Loss 1.2219e-01 (1.7685e-01) 
2023-05-27 05:22:24.364375: train Epoch: [6][152/193]	Time  9.905 ( 4.964)	Data  9.329 ( 4.394)	Loss 1.5282e-01 (1.7670e-01) 
2023-05-27 05:22:24.932185: train Epoch: [6][153/193]	Time  0.568 ( 4.936)	Data  0.001 ( 4.365)	Loss 1.5388e-01 (1.7655e-01) 
2023-05-27 05:22:34.264265: train Epoch: [6][154/193]	Time  9.332 ( 4.964)	Data  8.762 ( 4.394)	Loss 1.2536e-01 (1.7622e-01) 
2023-05-27 05:22:34.827693: train Epoch: [6][155/193]	Time  0.563 ( 4.936)	Data  0.001 ( 4.365)	Loss 1.8715e-01 (1.7629e-01) 
2023-05-27 05:22:44.336238: train Epoch: [6][156/193]	Time  9.509 ( 4.965)	Data  8.939 ( 4.395)	Loss 2.2707e-01 (1.7661e-01) 
2023-05-27 05:22:44.905112: train Epoch: [6][157/193]	Time  0.569 ( 4.937)	Data  0.001 ( 4.367)	Loss 2.4939e-01 (1.7707e-01) 
2023-05-27 05:22:54.007157: train Epoch: [6][158/193]	Time  9.102 ( 4.963)	Data  8.532 ( 4.393)	Loss 9.6855e-02 (1.7657e-01) 
2023-05-27 05:22:54.577606: train Epoch: [6][159/193]	Time  0.570 ( 4.936)	Data  0.001 ( 4.366)	Loss 1.4798e-01 (1.7639e-01) 
2023-05-27 05:23:03.819487: train Epoch: [6][160/193]	Time  9.242 ( 4.963)	Data  8.673 ( 4.392)	Loss 2.1776e-01 (1.7664e-01) 
2023-05-27 05:23:04.389628: train Epoch: [6][161/193]	Time  0.570 ( 4.936)	Data  0.001 ( 4.365)	Loss 1.2096e-01 (1.7630e-01) 
2023-05-27 05:23:13.771892: train Epoch: [6][162/193]	Time  9.382 ( 4.963)	Data  8.806 ( 4.392)	Loss 1.9726e-01 (1.7643e-01) 
2023-05-27 05:23:14.341949: train Epoch: [6][163/193]	Time  0.570 ( 4.936)	Data  0.001 ( 4.366)	Loss 1.2402e-01 (1.7611e-01) 
2023-05-27 05:23:23.485073: train Epoch: [6][164/193]	Time  9.143 ( 4.962)	Data  8.578 ( 4.391)	Loss 7.9989e-02 (1.7553e-01) 
2023-05-27 05:23:24.053830: train Epoch: [6][165/193]	Time  0.569 ( 4.935)	Data  0.001 ( 4.365)	Loss 1.9877e-01 (1.7567e-01) 
2023-05-27 05:23:33.233320: train Epoch: [6][166/193]	Time  9.179 ( 4.960)	Data  8.616 ( 4.390)	Loss 1.3168e-01 (1.7540e-01) 
2023-05-27 05:23:33.797861: train Epoch: [6][167/193]	Time  0.565 ( 4.934)	Data  0.001 ( 4.364)	Loss 2.2480e-01 (1.7570e-01) 
2023-05-27 05:23:43.382011: train Epoch: [6][168/193]	Time  9.584 ( 4.962)	Data  9.020 ( 4.392)	Loss 1.1874e-01 (1.7536e-01) 
2023-05-27 05:23:43.946138: train Epoch: [6][169/193]	Time  0.564 ( 4.936)	Data  0.001 ( 4.366)	Loss 1.1591e-01 (1.7501e-01) 
2023-05-27 05:23:53.189803: train Epoch: [6][170/193]	Time  9.244 ( 4.961)	Data  8.682 ( 4.391)	Loss 1.4457e-01 (1.7483e-01) 
2023-05-27 05:23:53.753477: train Epoch: [6][171/193]	Time  0.564 ( 4.936)	Data  0.001 ( 4.366)	Loss 1.1921e-01 (1.7451e-01) 
2023-05-27 05:24:02.784517: train Epoch: [6][172/193]	Time  9.031 ( 4.959)	Data  8.456 ( 4.389)	Loss 1.6079e-01 (1.7443e-01) 
2023-05-27 05:24:03.347206: train Epoch: [6][173/193]	Time  0.563 ( 4.934)	Data  0.001 ( 4.364)	Loss 2.2908e-01 (1.7474e-01) 
2023-05-27 05:24:12.773169: train Epoch: [6][174/193]	Time  9.426 ( 4.960)	Data  8.864 ( 4.390)	Loss 1.2664e-01 (1.7447e-01) 
2023-05-27 05:24:13.336820: train Epoch: [6][175/193]	Time  0.564 ( 4.935)	Data  0.001 ( 4.365)	Loss 1.2158e-01 (1.7417e-01) 
2023-05-27 05:24:22.795300: train Epoch: [6][176/193]	Time  9.458 ( 4.960)	Data  8.895 ( 4.390)	Loss 1.6915e-01 (1.7414e-01) 
2023-05-27 05:24:23.360199: train Epoch: [6][177/193]	Time  0.565 ( 4.936)	Data  0.001 ( 4.366)	Loss 9.4432e-02 (1.7369e-01) 
2023-05-27 05:24:32.650366: train Epoch: [6][178/193]	Time  9.290 ( 4.960)	Data  8.726 ( 4.390)	Loss 1.6126e-01 (1.7362e-01) 
2023-05-27 05:24:33.321968: train Epoch: [6][179/193]	Time  0.672 ( 4.936)	Data  0.001 ( 4.366)	Loss 1.6293e-01 (1.7356e-01) 
2023-05-27 05:24:43.014575: train Epoch: [6][180/193]	Time  9.693 ( 4.962)	Data  9.124 ( 4.392)	Loss 1.1892e-01 (1.7326e-01) 
2023-05-27 05:24:43.578163: train Epoch: [6][181/193]	Time  0.564 ( 4.938)	Data  0.001 ( 4.368)	Loss 1.1763e-01 (1.7296e-01) 
2023-05-27 05:24:52.939449: train Epoch: [6][182/193]	Time  9.361 ( 4.962)	Data  8.789 ( 4.392)	Loss 9.4581e-02 (1.7253e-01) 
2023-05-27 05:24:53.504191: train Epoch: [6][183/193]	Time  0.565 ( 4.938)	Data  0.001 ( 4.368)	Loss 1.6414e-01 (1.7248e-01) 
2023-05-27 05:25:02.728370: train Epoch: [6][184/193]	Time  9.224 ( 4.962)	Data  8.658 ( 4.391)	Loss 8.0928e-02 (1.7199e-01) 
2023-05-27 05:25:03.304305: train Epoch: [6][185/193]	Time  0.576 ( 4.938)	Data  0.001 ( 4.368)	Loss 1.5961e-01 (1.7192e-01) 
2023-05-27 05:25:12.564216: train Epoch: [6][186/193]	Time  9.260 ( 4.961)	Data  8.691 ( 4.391)	Loss 1.0783e-01 (1.7158e-01) 
2023-05-27 05:25:13.127742: train Epoch: [6][187/193]	Time  0.564 ( 4.938)	Data  0.001 ( 4.367)	Loss 2.2314e-01 (1.7185e-01) 
2023-05-27 05:25:22.433870: train Epoch: [6][188/193]	Time  9.306 ( 4.961)	Data  8.742 ( 4.391)	Loss 2.4089e-01 (1.7222e-01) 
2023-05-27 05:25:22.996867: train Epoch: [6][189/193]	Time  0.563 ( 4.938)	Data  0.001 ( 4.367)	Loss 1.5764e-01 (1.7214e-01) 
2023-05-27 05:25:31.907393: train Epoch: [6][190/193]	Time  8.911 ( 4.958)	Data  8.321 ( 4.388)	Loss 1.0778e-01 (1.7180e-01) 
2023-05-27 05:25:32.473474: train Epoch: [6][191/193]	Time  0.566 ( 4.936)	Data  0.001 ( 4.365)	Loss 1.1968e-01 (1.7153e-01) 
2023-05-27 05:25:40.482443: train Epoch: [6][192/193]	Time  8.009 ( 4.952)	Data  7.445 ( 4.381)	Loss 1.2922e-01 (1.7131e-01) 
2023-05-27 05:25:40.616309: Train Epoch done in 955.7815144650085 s 
2023-05-27 05:25:47.488156: val Epoch: [6][ 0/72]	Time  6.115 ( 6.115)	Data  5.799 ( 5.799)	Loss 5.6127e-01 (5.6127e-01) 
2023-05-27 05:25:47.606572: val Epoch: [6][ 1/72]	Time  0.118 ( 3.117)	Data  0.001 ( 2.900)	Loss 1.8239e-01 (3.7183e-01) 
2023-05-27 05:25:52.142789: val Epoch: [6][ 2/72]	Time  4.536 ( 3.590)	Data  4.425 ( 3.408)	Loss 3.3627e-01 (3.5998e-01) 
2023-05-27 05:25:52.255877: val Epoch: [6][ 3/72]	Time  0.113 ( 2.721)	Data  0.001 ( 2.556)	Loss 1.8283e-01 (3.1569e-01) 
2023-05-27 05:25:57.533053: val Epoch: [6][ 4/72]	Time  5.277 ( 3.232)	Data  5.158 ( 3.077)	Loss 4.1039e-01 (3.3463e-01) 
2023-05-27 05:25:57.641015: val Epoch: [6][ 5/72]	Time  0.108 ( 2.711)	Data  0.001 ( 2.564)	Loss 1.9120e-01 (3.1073e-01) 
2023-05-27 05:26:02.595228: val Epoch: [6][ 6/72]	Time  4.954 ( 3.032)	Data  4.845 ( 2.890)	Loss 1.1413e-01 (2.8264e-01) 
2023-05-27 05:26:02.718070: val Epoch: [6][ 7/72]	Time  0.123 ( 2.668)	Data  0.001 ( 2.529)	Loss 4.3234e-01 (3.0135e-01) 
2023-05-27 05:26:07.591769: val Epoch: [6][ 8/72]	Time  4.874 ( 2.913)	Data  4.766 ( 2.777)	Loss 2.4307e-01 (2.9488e-01) 
2023-05-27 05:26:07.698074: val Epoch: [6][ 9/72]	Time  0.106 ( 2.633)	Data  0.001 ( 2.500)	Loss 7.6581e-02 (2.7305e-01) 
2023-05-27 05:26:12.737594: val Epoch: [6][10/72]	Time  5.040 ( 2.851)	Data  4.919 ( 2.720)	Loss 7.8481e-02 (2.5536e-01) 
2023-05-27 05:26:12.861876: val Epoch: [6][11/72]	Time  0.124 ( 2.624)	Data  0.001 ( 2.493)	Loss 8.5101e-02 (2.4117e-01) 
2023-05-27 05:26:17.885282: val Epoch: [6][12/72]	Time  5.023 ( 2.809)	Data  4.911 ( 2.679)	Loss 4.1161e-01 (2.5428e-01) 
2023-05-27 05:26:17.995595: val Epoch: [6][13/72]	Time  0.110 ( 2.616)	Data  0.001 ( 2.488)	Loss 1.5623e-01 (2.4728e-01) 
2023-05-27 05:26:22.695691: val Epoch: [6][14/72]	Time  4.700 ( 2.755)	Data  4.591 ( 2.628)	Loss 8.2297e-02 (2.3628e-01) 
2023-05-27 05:26:22.804713: val Epoch: [6][15/72]	Time  0.109 ( 2.589)	Data  0.001 ( 2.464)	Loss 2.5782e-01 (2.3763e-01) 
2023-05-27 05:26:27.874611: val Epoch: [6][16/72]	Time  5.070 ( 2.735)	Data  4.952 ( 2.610)	Loss 1.6190e-01 (2.3317e-01) 
2023-05-27 05:26:27.982984: val Epoch: [6][17/72]	Time  0.108 ( 2.589)	Data  0.001 ( 2.465)	Loss 1.6831e-01 (2.2957e-01) 
2023-05-27 05:26:32.799961: val Epoch: [6][18/72]	Time  4.817 ( 2.707)	Data  4.707 ( 2.583)	Loss 1.2879e-01 (2.2426e-01) 
2023-05-27 05:26:32.931343: val Epoch: [6][19/72]	Time  0.131 ( 2.578)	Data  0.001 ( 2.454)	Loss 7.7923e-02 (2.1695e-01) 
2023-05-27 05:26:37.895227: val Epoch: [6][20/72]	Time  4.964 ( 2.692)	Data  4.856 ( 2.568)	Loss 8.5033e-02 (2.1067e-01) 
2023-05-27 05:26:38.003783: val Epoch: [6][21/72]	Time  0.109 ( 2.574)	Data  0.001 ( 2.452)	Loss 9.9398e-02 (2.0561e-01) 
2023-05-27 05:26:42.697677: val Epoch: [6][22/72]	Time  4.694 ( 2.666)	Data  4.576 ( 2.544)	Loss 9.0421e-02 (2.0060e-01) 
2023-05-27 05:26:42.806276: val Epoch: [6][23/72]	Time  0.109 ( 2.560)	Data  0.001 ( 2.438)	Loss 9.5449e-02 (1.9622e-01) 
2023-05-27 05:26:47.672019: val Epoch: [6][24/72]	Time  4.866 ( 2.652)	Data  4.746 ( 2.530)	Loss 6.6181e-01 (2.1484e-01) 
2023-05-27 05:26:47.791111: val Epoch: [6][25/72]	Time  0.119 ( 2.555)	Data  0.001 ( 2.433)	Loss 3.3592e-01 (2.1950e-01) 
2023-05-27 05:26:52.720646: val Epoch: [6][26/72]	Time  4.930 ( 2.643)	Data  4.768 ( 2.520)	Loss 1.0401e-01 (2.1522e-01) 
2023-05-27 05:26:52.844813: val Epoch: [6][27/72]	Time  0.124 ( 2.553)	Data  0.002 ( 2.430)	Loss 9.2728e-02 (2.1085e-01) 
2023-05-27 05:26:57.481538: val Epoch: [6][28/72]	Time  4.637 ( 2.624)	Data  4.509 ( 2.501)	Loss 1.3034e-01 (2.0807e-01) 
2023-05-27 05:26:57.594755: val Epoch: [6][29/72]	Time  0.113 ( 2.541)	Data  0.001 ( 2.418)	Loss 1.4870e-01 (2.0609e-01) 
2023-05-27 05:27:02.689987: val Epoch: [6][30/72]	Time  5.095 ( 2.623)	Data  4.983 ( 2.501)	Loss 7.9563e-02 (2.0201e-01) 
2023-05-27 05:27:02.818678: val Epoch: [6][31/72]	Time  0.129 ( 2.545)	Data  0.001 ( 2.423)	Loss 2.2819e-01 (2.0283e-01) 
2023-05-27 05:27:07.723354: val Epoch: [6][32/72]	Time  4.905 ( 2.617)	Data  4.794 ( 2.495)	Loss 9.4560e-02 (1.9955e-01) 
2023-05-27 05:27:07.833183: val Epoch: [6][33/72]	Time  0.110 ( 2.543)	Data  0.001 ( 2.421)	Loss 9.6666e-02 (1.9652e-01) 
2023-05-27 05:27:12.534327: val Epoch: [6][34/72]	Time  4.701 ( 2.605)	Data  4.594 ( 2.483)	Loss 1.6646e-01 (1.9566e-01) 
2023-05-27 05:27:12.639428: val Epoch: [6][35/72]	Time  0.105 ( 2.535)	Data  0.000 ( 2.414)	Loss 2.4489e-01 (1.9703e-01) 
2023-05-27 05:27:17.623922: val Epoch: [6][36/72]	Time  4.984 ( 2.601)	Data  4.879 ( 2.481)	Loss 1.1933e-01 (1.9493e-01) 
2023-05-27 05:27:17.732491: val Epoch: [6][37/72]	Time  0.109 ( 2.536)	Data  0.001 ( 2.416)	Loss 8.1132e-02 (1.9194e-01) 
2023-05-27 05:27:23.015526: val Epoch: [6][38/72]	Time  5.283 ( 2.606)	Data  5.123 ( 2.485)	Loss 6.1383e-01 (2.0275e-01) 
2023-05-27 05:27:23.170113: val Epoch: [6][39/72]	Time  0.155 ( 2.545)	Data  0.002 ( 2.423)	Loss 9.6313e-02 (2.0009e-01) 
2023-05-27 05:27:27.717848: val Epoch: [6][40/72]	Time  4.548 ( 2.594)	Data  4.404 ( 2.471)	Loss 1.4587e-01 (1.9877e-01) 
2023-05-27 05:27:27.834622: val Epoch: [6][41/72]	Time  0.117 ( 2.535)	Data  0.001 ( 2.412)	Loss 2.1859e-01 (1.9924e-01) 
2023-05-27 05:27:32.884861: val Epoch: [6][42/72]	Time  5.050 ( 2.593)	Data  4.921 ( 2.471)	Loss 1.5319e-01 (1.9817e-01) 
2023-05-27 05:27:32.993228: val Epoch: [6][43/72]	Time  0.108 ( 2.537)	Data  0.001 ( 2.415)	Loss 1.0874e-01 (1.9614e-01) 
2023-05-27 05:27:38.102085: val Epoch: [6][44/72]	Time  5.109 ( 2.594)	Data  5.004 ( 2.472)	Loss 1.7097e-01 (1.9558e-01) 
2023-05-27 05:27:38.206012: val Epoch: [6][45/72]	Time  0.104 ( 2.540)	Data  0.000 ( 2.418)	Loss 2.4365e-01 (1.9662e-01) 
2023-05-27 05:27:43.245430: val Epoch: [6][46/72]	Time  5.039 ( 2.593)	Data  4.933 ( 2.472)	Loss 1.1700e-01 (1.9493e-01) 
2023-05-27 05:27:43.351946: val Epoch: [6][47/72]	Time  0.107 ( 2.541)	Data  0.000 ( 2.421)	Loss 5.5604e-01 (2.0245e-01) 
2023-05-27 05:27:48.049780: val Epoch: [6][48/72]	Time  4.698 ( 2.585)	Data  4.587 ( 2.465)	Loss 9.0917e-02 (2.0018e-01) 
2023-05-27 05:27:48.157499: val Epoch: [6][49/72]	Time  0.108 ( 2.536)	Data  0.000 ( 2.415)	Loss 2.5940e-01 (2.0136e-01) 
2023-05-27 05:27:52.958061: val Epoch: [6][50/72]	Time  4.801 ( 2.580)	Data  4.693 ( 2.460)	Loss 1.0193e-01 (1.9941e-01) 
2023-05-27 05:27:53.065223: val Epoch: [6][51/72]	Time  0.107 ( 2.533)	Data  0.001 ( 2.413)	Loss 1.1008e-01 (1.9769e-01) 
2023-05-27 05:27:57.876337: val Epoch: [6][52/72]	Time  4.811 ( 2.576)	Data  4.699 ( 2.456)	Loss 2.6129e-01 (1.9889e-01) 
2023-05-27 05:27:57.988374: val Epoch: [6][53/72]	Time  0.112 ( 2.530)	Data  0.001 ( 2.410)	Loss 2.3373e-01 (1.9954e-01) 
2023-05-27 05:28:02.881715: val Epoch: [6][54/72]	Time  4.893 ( 2.573)	Data  4.788 ( 2.454)	Loss 5.5827e-01 (2.0606e-01) 
2023-05-27 05:28:02.988798: val Epoch: [6][55/72]	Time  0.107 ( 2.529)	Data  0.000 ( 2.410)	Loss 1.1991e-01 (2.0452e-01) 
2023-05-27 05:28:07.882697: val Epoch: [6][56/72]	Time  4.894 ( 2.570)	Data  4.789 ( 2.452)	Loss 1.8675e-01 (2.0421e-01) 
2023-05-27 05:28:07.987155: val Epoch: [6][57/72]	Time  0.104 ( 2.528)	Data  0.000 ( 2.409)	Loss 1.3323e-01 (2.0299e-01) 
2023-05-27 05:28:12.797895: val Epoch: [6][58/72]	Time  4.811 ( 2.567)	Data  4.695 ( 2.448)	Loss 1.2146e-01 (2.0161e-01) 
2023-05-27 05:28:12.910513: val Epoch: [6][59/72]	Time  0.113 ( 2.526)	Data  0.001 ( 2.407)	Loss 8.6096e-02 (1.9968e-01) 
2023-05-27 05:28:17.698777: val Epoch: [6][60/72]	Time  4.788 ( 2.563)	Data  4.678 ( 2.445)	Loss 1.6013e-01 (1.9903e-01) 
2023-05-27 05:28:17.809180: val Epoch: [6][61/72]	Time  0.110 ( 2.523)	Data  0.001 ( 2.405)	Loss 2.3844e-01 (1.9967e-01) 
2023-05-27 05:28:22.669154: val Epoch: [6][62/72]	Time  4.860 ( 2.560)	Data  4.750 ( 2.442)	Loss 1.4495e-01 (1.9880e-01) 
2023-05-27 05:28:22.779208: val Epoch: [6][63/72]	Time  0.110 ( 2.522)	Data  0.000 ( 2.404)	Loss 1.7134e-01 (1.9837e-01) 
2023-05-27 05:28:27.895490: val Epoch: [6][64/72]	Time  5.116 ( 2.562)	Data  5.004 ( 2.444)	Loss 1.9238e-01 (1.9828e-01) 
2023-05-27 05:28:28.007426: val Epoch: [6][65/72]	Time  0.112 ( 2.525)	Data  0.001 ( 2.407)	Loss 1.4628e-01 (1.9749e-01) 
2023-05-27 05:28:32.897007: val Epoch: [6][66/72]	Time  4.890 ( 2.560)	Data  4.776 ( 2.443)	Loss 1.4659e-01 (1.9673e-01) 
2023-05-27 05:28:33.166851: val Epoch: [6][67/72]	Time  0.270 ( 2.526)	Data  0.149 ( 2.409)	Loss 1.7689e-01 (1.9644e-01) 
2023-05-27 05:28:38.103390: val Epoch: [6][68/72]	Time  4.937 ( 2.561)	Data  4.829 ( 2.444)	Loss 2.1399e-01 (1.9669e-01) 
2023-05-27 05:28:38.262305: val Epoch: [6][69/72]	Time  0.159 ( 2.527)	Data  0.054 ( 2.410)	Loss 3.9105e-01 (1.9947e-01) 
2023-05-27 05:28:43.008971: val Epoch: [6][70/72]	Time  4.747 ( 2.558)	Data  4.639 ( 2.441)	Loss 9.6781e-02 (1.9802e-01) 
2023-05-27 05:28:43.220715: val Epoch: [6][71/72]	Time  0.212 ( 2.526)	Data  0.104 ( 2.409)	Loss 1.3131e-01 (1.9710e-01) 
2023-05-27 05:28:43.492462: Epoch 6 :Val : ['ET : 0.6709086894989014', 'TC : 0.6611829400062561', 'WT : 0.7942171096801758'] 
2023-05-27 05:28:43.493030: Epoch 6 :Val : ['ET : 0.6709086894989014', 'TC : 0.6611829400062561', 'WT : 0.7942171096801758'] 
2023-05-27 05:28:43.495029: Saving the model with DSC 0.6959185004234314 
2023-05-27 05:28:44.249242: Val epoch done in 183.63292021499365 s 
2023-05-27 05:28:44.271270: Batches per epoch:  193 
2023-05-27 05:28:55.540517: train Epoch: [7][  0/193]	Time 11.269 (11.269)	Data 10.393 (10.393)	Loss 2.1343e-01 (2.1343e-01) 
2023-05-27 05:28:56.119937: train Epoch: [7][  1/193]	Time  0.579 ( 5.924)	Data  0.001 ( 5.197)	Loss 1.9273e-01 (2.0308e-01) 
2023-05-27 05:29:05.006773: train Epoch: [7][  2/193]	Time  8.887 ( 6.912)	Data  8.316 ( 6.236)	Loss 1.6367e-01 (1.8994e-01) 
2023-05-27 05:29:05.586221: train Epoch: [7][  3/193]	Time  0.579 ( 5.329)	Data  0.001 ( 4.678)	Loss 2.0199e-01 (1.9296e-01) 
2023-05-27 05:29:15.181888: train Epoch: [7][  4/193]	Time  9.596 ( 6.182)	Data  9.023 ( 5.547)	Loss 1.4550e-01 (1.8347e-01) 
2023-05-27 05:29:15.756783: train Epoch: [7][  5/193]	Time  0.575 ( 5.248)	Data  0.001 ( 4.622)	Loss 1.9264e-01 (1.8499e-01) 
2023-05-27 05:29:25.252313: train Epoch: [7][  6/193]	Time  9.496 ( 5.854)	Data  8.918 ( 5.236)	Loss 1.7504e-01 (1.8357e-01) 
2023-05-27 05:29:25.858023: train Epoch: [7][  7/193]	Time  0.606 ( 5.198)	Data  0.001 ( 4.582)	Loss 1.2040e-01 (1.7568e-01) 
2023-05-27 05:29:35.333769: train Epoch: [7][  8/193]	Time  9.476 ( 5.674)	Data  8.904 ( 5.062)	Loss 1.1479e-01 (1.6891e-01) 
2023-05-27 05:29:35.906408: train Epoch: [7][  9/193]	Time  0.573 ( 5.163)	Data  0.001 ( 4.556)	Loss 1.2958e-01 (1.6498e-01) 
2023-05-27 05:29:45.295546: train Epoch: [7][ 10/193]	Time  9.389 ( 5.548)	Data  8.820 ( 4.944)	Loss 1.0962e-01 (1.5994e-01) 
2023-05-27 05:29:45.898145: train Epoch: [7][ 11/193]	Time  0.603 ( 5.136)	Data  0.001 ( 4.532)	Loss 8.7239e-02 (1.5389e-01) 
2023-05-27 05:29:55.339679: train Epoch: [7][ 12/193]	Time  9.442 ( 5.467)	Data  8.863 ( 4.865)	Loss 1.4826e-01 (1.5345e-01) 
2023-05-27 05:29:55.911187: train Epoch: [7][ 13/193]	Time  0.571 ( 5.117)	Data  0.001 ( 4.517)	Loss 1.6244e-01 (1.5409e-01) 
2023-05-27 05:30:05.665837: train Epoch: [7][ 14/193]	Time  9.755 ( 5.426)	Data  9.163 ( 4.827)	Loss 1.6365e-01 (1.5473e-01) 
2023-05-27 05:30:06.236826: train Epoch: [7][ 15/193]	Time  0.571 ( 5.123)	Data  0.001 ( 4.525)	Loss 1.5683e-01 (1.5486e-01) 
2023-05-27 05:30:15.676413: train Epoch: [7][ 16/193]	Time  9.440 ( 5.377)	Data  8.844 ( 4.780)	Loss 8.8911e-02 (1.5098e-01) 
2023-05-27 05:30:16.248593: train Epoch: [7][ 17/193]	Time  0.572 ( 5.110)	Data  0.001 ( 4.514)	Loss 1.3853e-01 (1.5029e-01) 
2023-05-27 05:30:25.649450: train Epoch: [7][ 18/193]	Time  9.401 ( 5.336)	Data  8.832 ( 4.741)	Loss 1.4821e-01 (1.5018e-01) 
2023-05-27 05:30:26.212479: train Epoch: [7][ 19/193]	Time  0.563 ( 5.097)	Data  0.001 ( 4.504)	Loss 2.0365e-01 (1.5286e-01) 
2023-05-27 05:30:35.957969: train Epoch: [7][ 20/193]	Time  9.745 ( 5.318)	Data  9.174 ( 4.727)	Loss 1.8785e-01 (1.5452e-01) 
2023-05-27 05:30:36.537655: train Epoch: [7][ 21/193]	Time  0.580 ( 5.103)	Data  0.001 ( 4.512)	Loss 2.2866e-01 (1.5789e-01) 
2023-05-27 05:30:46.123739: train Epoch: [7][ 22/193]	Time  9.586 ( 5.298)	Data  8.987 ( 4.706)	Loss 1.9151e-01 (1.5935e-01) 
2023-05-27 05:30:46.685558: train Epoch: [7][ 23/193]	Time  0.562 ( 5.101)	Data  0.001 ( 4.510)	Loss 1.0105e-01 (1.5692e-01) 
2023-05-27 05:30:55.892203: train Epoch: [7][ 24/193]	Time  9.207 ( 5.265)	Data  8.637 ( 4.675)	Loss 1.2520e-01 (1.5566e-01) 
2023-05-27 05:30:56.470802: train Epoch: [7][ 25/193]	Time  0.579 ( 5.085)	Data  0.001 ( 4.496)	Loss 1.3595e-01 (1.5490e-01) 
2023-05-27 05:31:06.018595: train Epoch: [7][ 26/193]	Time  9.548 ( 5.250)	Data  8.976 ( 4.662)	Loss 3.6317e-01 (1.6261e-01) 
2023-05-27 05:31:06.581532: train Epoch: [7][ 27/193]	Time  0.563 ( 5.082)	Data  0.001 ( 4.495)	Loss 1.4743e-01 (1.6207e-01) 
2023-05-27 05:31:16.288617: train Epoch: [7][ 28/193]	Time  9.707 ( 5.242)	Data  9.090 ( 4.654)	Loss 2.7734e-01 (1.6604e-01) 
2023-05-27 05:31:16.852938: train Epoch: [7][ 29/193]	Time  0.564 ( 5.086)	Data  0.001 ( 4.498)	Loss 9.4533e-02 (1.6366e-01) 
2023-05-27 05:31:25.281186: train Epoch: [7][ 30/193]	Time  8.428 ( 5.194)	Data  7.863 ( 4.607)	Loss 1.0250e-01 (1.6169e-01) 
2023-05-27 05:31:25.878412: train Epoch: [7][ 31/193]	Time  0.597 ( 5.050)	Data  0.001 ( 4.463)	Loss 1.9785e-01 (1.6282e-01) 
2023-05-27 05:31:34.654519: train Epoch: [7][ 32/193]	Time  8.776 ( 5.163)	Data  8.212 ( 4.577)	Loss 8.1704e-02 (1.6036e-01) 
2023-05-27 05:31:35.219507: train Epoch: [7][ 33/193]	Time  0.565 ( 5.028)	Data  0.001 ( 4.442)	Loss 2.1839e-01 (1.6207e-01) 
2023-05-27 05:31:44.556925: train Epoch: [7][ 34/193]	Time  9.337 ( 5.151)	Data  8.763 ( 4.566)	Loss 1.5301e-01 (1.6181e-01) 
2023-05-27 05:31:45.123818: train Epoch: [7][ 35/193]	Time  0.567 ( 5.024)	Data  0.001 ( 4.439)	Loss 1.8693e-01 (1.6251e-01) 
2023-05-27 05:31:54.292893: train Epoch: [7][ 36/193]	Time  9.169 ( 5.136)	Data  8.594 ( 4.551)	Loss 8.9240e-02 (1.6053e-01) 
2023-05-27 05:31:54.861350: train Epoch: [7][ 37/193]	Time  0.568 ( 5.016)	Data  0.001 ( 4.431)	Loss 1.3681e-01 (1.5990e-01) 
2023-05-27 05:32:04.149851: train Epoch: [7][ 38/193]	Time  9.288 ( 5.125)	Data  8.725 ( 4.541)	Loss 2.0289e-01 (1.6100e-01) 
2023-05-27 05:32:04.712032: train Epoch: [7][ 39/193]	Time  0.562 ( 5.011)	Data  0.001 ( 4.428)	Loss 7.8013e-02 (1.5893e-01) 
2023-05-27 05:32:14.023186: train Epoch: [7][ 40/193]	Time  9.311 ( 5.116)	Data  8.748 ( 4.533)	Loss 1.1455e-01 (1.5785e-01) 
2023-05-27 05:32:14.586586: train Epoch: [7][ 41/193]	Time  0.563 ( 5.007)	Data  0.001 ( 4.425)	Loss 9.9731e-02 (1.5646e-01) 
2023-05-27 05:32:24.081489: train Epoch: [7][ 42/193]	Time  9.495 ( 5.112)	Data  8.915 ( 4.530)	Loss 1.4185e-01 (1.5612e-01) 
2023-05-27 05:32:24.651646: train Epoch: [7][ 43/193]	Time  0.570 ( 5.009)	Data  0.001 ( 4.427)	Loss 9.6969e-02 (1.5478e-01) 
2023-05-27 05:32:34.395503: train Epoch: [7][ 44/193]	Time  9.744 ( 5.114)	Data  9.174 ( 4.532)	Loss 1.6431e-01 (1.5499e-01) 
2023-05-27 05:32:34.966844: train Epoch: [7][ 45/193]	Time  0.571 ( 5.015)	Data  0.001 ( 4.434)	Loss 1.7233e-01 (1.5537e-01) 
2023-05-27 05:32:44.362134: train Epoch: [7][ 46/193]	Time  9.395 ( 5.108)	Data  8.830 ( 4.527)	Loss 1.0469e-01 (1.5429e-01) 
2023-05-27 05:32:44.926424: train Epoch: [7][ 47/193]	Time  0.564 ( 5.014)	Data  0.001 ( 4.433)	Loss 8.2010e-02 (1.5278e-01) 
2023-05-27 05:32:54.349958: train Epoch: [7][ 48/193]	Time  9.424 ( 5.104)	Data  8.859 ( 4.523)	Loss 1.7483e-01 (1.5323e-01) 
2023-05-27 05:32:54.914582: train Epoch: [7][ 49/193]	Time  0.565 ( 5.013)	Data  0.001 ( 4.433)	Loss 1.7919e-01 (1.5375e-01) 
2023-05-27 05:33:04.258656: train Epoch: [7][ 50/193]	Time  9.344 ( 5.098)	Data  8.775 ( 4.518)	Loss 1.3501e-01 (1.5339e-01) 
2023-05-27 05:33:04.827420: train Epoch: [7][ 51/193]	Time  0.569 ( 5.011)	Data  0.001 ( 4.431)	Loss 1.2330e-01 (1.5281e-01) 
2023-05-27 05:33:13.944128: train Epoch: [7][ 52/193]	Time  9.117 ( 5.088)	Data  8.540 ( 4.509)	Loss 1.1581e-01 (1.5211e-01) 
2023-05-27 05:33:14.508523: train Epoch: [7][ 53/193]	Time  0.564 ( 5.004)	Data  0.001 ( 4.425)	Loss 1.9347e-01 (1.5287e-01) 
2023-05-27 05:33:23.901610: train Epoch: [7][ 54/193]	Time  9.393 ( 5.084)	Data  8.828 ( 4.505)	Loss 1.3995e-01 (1.5264e-01) 
2023-05-27 05:33:24.467250: train Epoch: [7][ 55/193]	Time  0.566 ( 5.003)	Data  0.001 ( 4.425)	Loss 1.4729e-01 (1.5254e-01) 
2023-05-27 05:33:34.226128: train Epoch: [7][ 56/193]	Time  9.759 ( 5.087)	Data  9.195 ( 4.509)	Loss 1.2300e-01 (1.5203e-01) 
2023-05-27 05:33:34.790449: train Epoch: [7][ 57/193]	Time  0.564 ( 5.009)	Data  0.001 ( 4.431)	Loss 3.3162e-01 (1.5512e-01) 
2023-05-27 05:33:43.800884: train Epoch: [7][ 58/193]	Time  9.010 ( 5.077)	Data  8.446 ( 4.499)	Loss 1.5512e-01 (1.5512e-01) 
2023-05-27 05:33:44.366323: train Epoch: [7][ 59/193]	Time  0.565 ( 5.002)	Data  0.001 ( 4.424)	Loss 1.4692e-01 (1.5499e-01) 
2023-05-27 05:33:53.718462: train Epoch: [7][ 60/193]	Time  9.352 ( 5.073)	Data  8.788 ( 4.495)	Loss 1.5219e-01 (1.5494e-01) 
2023-05-27 05:33:54.283444: train Epoch: [7][ 61/193]	Time  0.565 ( 5.000)	Data  0.001 ( 4.423)	Loss 9.9936e-02 (1.5405e-01) 
2023-05-27 05:34:02.298003: train Epoch: [7][ 62/193]	Time  8.015 ( 5.048)	Data  7.443 ( 4.471)	Loss 1.2764e-01 (1.5363e-01) 
2023-05-27 05:34:02.862352: train Epoch: [7][ 63/193]	Time  0.564 ( 4.978)	Data  0.001 ( 4.401)	Loss 2.4221e-01 (1.5502e-01) 
2023-05-27 05:34:11.660569: train Epoch: [7][ 64/193]	Time  8.798 ( 5.037)	Data  8.234 ( 4.460)	Loss 1.2438e-01 (1.5455e-01) 
2023-05-27 05:34:12.227804: train Epoch: [7][ 65/193]	Time  0.567 ( 4.969)	Data  0.001 ( 4.392)	Loss 1.6284e-01 (1.5467e-01) 
2023-05-27 05:34:21.469305: train Epoch: [7][ 66/193]	Time  9.242 ( 5.033)	Data  8.676 ( 4.456)	Loss 1.3643e-01 (1.5440e-01) 
2023-05-27 05:34:22.036246: train Epoch: [7][ 67/193]	Time  0.567 ( 4.967)	Data  0.001 ( 4.391)	Loss 2.0303e-01 (1.5511e-01) 
2023-05-27 05:34:30.966640: train Epoch: [7][ 68/193]	Time  8.930 ( 5.025)	Data  8.358 ( 4.448)	Loss 1.4079e-01 (1.5491e-01) 
2023-05-27 05:34:31.539516: train Epoch: [7][ 69/193]	Time  0.573 ( 4.961)	Data  0.001 ( 4.385)	Loss 8.9946e-02 (1.5398e-01) 
2023-05-27 05:34:40.583831: train Epoch: [7][ 70/193]	Time  9.044 ( 5.018)	Data  8.474 ( 4.442)	Loss 1.3783e-01 (1.5375e-01) 
2023-05-27 05:34:41.150393: train Epoch: [7][ 71/193]	Time  0.567 ( 4.957)	Data  0.001 ( 4.381)	Loss 1.3716e-01 (1.5352e-01) 
2023-05-27 05:34:50.435190: train Epoch: [7][ 72/193]	Time  9.285 ( 5.016)	Data  8.710 ( 4.440)	Loss 1.2534e-01 (1.5313e-01) 
2023-05-27 05:34:51.001558: train Epoch: [7][ 73/193]	Time  0.566 ( 4.956)	Data  0.001 ( 4.380)	Loss 1.5514e-01 (1.5316e-01) 
2023-05-27 05:34:59.843035: train Epoch: [7][ 74/193]	Time  8.841 ( 5.008)	Data  8.278 ( 4.432)	Loss 1.7200e-01 (1.5341e-01) 
2023-05-27 05:35:00.406472: train Epoch: [7][ 75/193]	Time  0.563 ( 4.949)	Data  0.001 ( 4.374)	Loss 9.9733e-02 (1.5271e-01) 
2023-05-27 05:35:09.654359: train Epoch: [7][ 76/193]	Time  9.248 ( 5.005)	Data  8.685 ( 4.430)	Loss 1.3652e-01 (1.5250e-01) 
2023-05-27 05:35:10.219358: train Epoch: [7][ 77/193]	Time  0.565 ( 4.948)	Data  0.001 ( 4.373)	Loss 9.4121e-02 (1.5175e-01) 
2023-05-27 05:35:19.578607: train Epoch: [7][ 78/193]	Time  9.359 ( 5.004)	Data  8.797 ( 4.429)	Loss 9.0796e-02 (1.5098e-01) 
2023-05-27 05:35:20.142764: train Epoch: [7][ 79/193]	Time  0.564 ( 4.948)	Data  0.001 ( 4.374)	Loss 1.6664e-01 (1.5117e-01) 
2023-05-27 05:35:29.121061: train Epoch: [7][ 80/193]	Time  8.978 ( 4.998)	Data  8.408 ( 4.423)	Loss 8.9382e-02 (1.5041e-01) 
2023-05-27 05:35:29.685142: train Epoch: [7][ 81/193]	Time  0.564 ( 4.944)	Data  0.001 ( 4.369)	Loss 1.1714e-01 (1.5000e-01) 
2023-05-27 05:35:38.995684: train Epoch: [7][ 82/193]	Time  9.311 ( 4.997)	Data  8.717 ( 4.422)	Loss 2.2121e-01 (1.5086e-01) 
2023-05-27 05:35:39.562673: train Epoch: [7][ 83/193]	Time  0.567 ( 4.944)	Data  0.001 ( 4.369)	Loss 3.6830e-01 (1.5345e-01) 
2023-05-27 05:35:48.970404: train Epoch: [7][ 84/193]	Time  9.408 ( 4.996)	Data  8.838 ( 4.422)	Loss 1.3853e-01 (1.5327e-01) 
2023-05-27 05:35:49.542264: train Epoch: [7][ 85/193]	Time  0.572 ( 4.945)	Data  0.001 ( 4.370)	Loss 8.3095e-02 (1.5246e-01) 
2023-05-27 05:35:59.058831: train Epoch: [7][ 86/193]	Time  9.517 ( 4.998)	Data  8.942 ( 4.423)	Loss 1.1382e-01 (1.5201e-01) 
2023-05-27 05:35:59.636789: train Epoch: [7][ 87/193]	Time  0.578 ( 4.947)	Data  0.001 ( 4.373)	Loss 2.8939e-01 (1.5358e-01) 
2023-05-27 05:36:08.915660: train Epoch: [7][ 88/193]	Time  9.279 ( 4.996)	Data  8.700 ( 4.421)	Loss 1.2811e-01 (1.5329e-01) 
2023-05-27 05:36:09.496964: train Epoch: [7][ 89/193]	Time  0.581 ( 4.947)	Data  0.001 ( 4.372)	Loss 1.4340e-01 (1.5318e-01) 
2023-05-27 05:36:19.165785: train Epoch: [7][ 90/193]	Time  9.669 ( 4.999)	Data  9.090 ( 4.424)	Loss 1.0553e-01 (1.5266e-01) 
2023-05-27 05:36:19.745589: train Epoch: [7][ 91/193]	Time  0.580 ( 4.951)	Data  0.001 ( 4.376)	Loss 6.2028e-02 (1.5167e-01) 
2023-05-27 05:36:29.056957: train Epoch: [7][ 92/193]	Time  9.311 ( 4.998)	Data  8.733 ( 4.423)	Loss 1.0081e-01 (1.5112e-01) 
2023-05-27 05:36:29.667735: train Epoch: [7][ 93/193]	Time  0.611 ( 4.951)	Data  0.001 ( 4.376)	Loss 1.4398e-01 (1.5105e-01) 
2023-05-27 05:36:38.990662: train Epoch: [7][ 94/193]	Time  9.323 ( 4.997)	Data  8.750 ( 4.422)	Loss 8.5605e-02 (1.5036e-01) 
2023-05-27 05:36:39.581990: train Epoch: [7][ 95/193]	Time  0.591 ( 4.951)	Data  0.001 ( 4.376)	Loss 9.2702e-02 (1.4976e-01) 
2023-05-27 05:36:49.331429: train Epoch: [7][ 96/193]	Time  9.749 ( 5.001)	Data  9.174 ( 4.425)	Loss 9.8450e-02 (1.4923e-01) 
2023-05-27 05:36:49.902706: train Epoch: [7][ 97/193]	Time  0.571 ( 4.955)	Data  0.001 ( 4.380)	Loss 1.2079e-01 (1.4894e-01) 
2023-05-27 05:36:58.574279: train Epoch: [7][ 98/193]	Time  8.672 ( 4.993)	Data  8.098 ( 4.418)	Loss 1.2246e-01 (1.4867e-01) 
2023-05-27 05:36:59.160185: train Epoch: [7][ 99/193]	Time  0.586 ( 4.949)	Data  0.001 ( 4.373)	Loss 1.4510e-01 (1.4864e-01) 
2023-05-27 05:37:07.353809: train Epoch: [7][100/193]	Time  8.194 ( 4.981)	Data  7.619 ( 4.406)	Loss 1.2377e-01 (1.4839e-01) 
2023-05-27 05:37:07.915504: train Epoch: [7][101/193]	Time  0.562 ( 4.938)	Data  0.001 ( 4.362)	Loss 1.5816e-01 (1.4849e-01) 
2023-05-27 05:37:17.292900: train Epoch: [7][102/193]	Time  9.377 ( 4.981)	Data  8.808 ( 4.406)	Loss 1.7064e-01 (1.4870e-01) 
2023-05-27 05:37:17.854778: train Epoch: [7][103/193]	Time  0.562 ( 4.938)	Data  0.001 ( 4.363)	Loss 9.6612e-02 (1.4820e-01) 
2023-05-27 05:37:27.081935: train Epoch: [7][104/193]	Time  9.227 ( 4.979)	Data  8.644 ( 4.404)	Loss 1.3476e-01 (1.4807e-01) 
2023-05-27 05:37:27.660368: train Epoch: [7][105/193]	Time  0.578 ( 4.938)	Data  0.001 ( 4.362)	Loss 1.1794e-01 (1.4779e-01) 
2023-05-27 05:37:37.023975: train Epoch: [7][106/193]	Time  9.364 ( 4.979)	Data  8.746 ( 4.403)	Loss 1.6325e-01 (1.4793e-01) 
2023-05-27 05:37:37.640086: train Epoch: [7][107/193]	Time  0.616 ( 4.939)	Data  0.001 ( 4.363)	Loss 1.0458e-01 (1.4753e-01) 
2023-05-27 05:37:47.119014: train Epoch: [7][108/193]	Time  9.479 ( 4.980)	Data  8.899 ( 4.404)	Loss 9.9346e-02 (1.4709e-01) 
2023-05-27 05:37:47.716720: train Epoch: [7][109/193]	Time  0.598 ( 4.940)	Data  0.001 ( 4.364)	Loss 1.9860e-01 (1.4756e-01) 
2023-05-27 05:37:56.972857: train Epoch: [7][110/193]	Time  9.256 ( 4.979)	Data  8.671 ( 4.403)	Loss 1.2855e-01 (1.4739e-01) 
2023-05-27 05:37:57.549083: train Epoch: [7][111/193]	Time  0.576 ( 4.940)	Data  0.001 ( 4.364)	Loss 1.8183e-01 (1.4769e-01) 
2023-05-27 05:38:07.028536: train Epoch: [7][112/193]	Time  9.479 ( 4.980)	Data  8.910 ( 4.404)	Loss 1.3400e-01 (1.4757e-01) 
2023-05-27 05:38:07.603873: train Epoch: [7][113/193]	Time  0.575 ( 4.942)	Data  0.001 ( 4.365)	Loss 1.4701e-01 (1.4757e-01) 
2023-05-27 05:38:16.656079: train Epoch: [7][114/193]	Time  9.052 ( 4.977)	Data  8.421 ( 4.401)	Loss 1.2094e-01 (1.4734e-01) 
2023-05-27 05:38:17.255536: train Epoch: [7][115/193]	Time  0.599 ( 4.940)	Data  0.001 ( 4.363)	Loss 9.1719e-02 (1.4686e-01) 
2023-05-27 05:38:26.619889: train Epoch: [7][116/193]	Time  9.364 ( 4.977)	Data  8.787 ( 4.400)	Loss 1.6205e-01 (1.4699e-01) 
2023-05-27 05:38:27.185801: train Epoch: [7][117/193]	Time  0.566 ( 4.940)	Data  0.001 ( 4.363)	Loss 1.5416e-01 (1.4705e-01) 
2023-05-27 05:38:36.494563: train Epoch: [7][118/193]	Time  9.309 ( 4.977)	Data  8.726 ( 4.400)	Loss 1.7136e-01 (1.4725e-01) 
2023-05-27 05:38:37.260977: train Epoch: [7][119/193]	Time  0.766 ( 4.942)	Data  0.198 ( 4.365)	Loss 2.6075e-01 (1.4820e-01) 
2023-05-27 05:38:45.963605: train Epoch: [7][120/193]	Time  8.703 ( 4.973)	Data  8.119 ( 4.396)	Loss 1.1299e-01 (1.4791e-01) 
2023-05-27 05:38:47.237796: train Epoch: [7][121/193]	Time  1.274 ( 4.942)	Data  0.703 ( 4.366)	Loss 1.0892e-01 (1.4759e-01) 
2023-05-27 05:38:55.471759: train Epoch: [7][122/193]	Time  8.234 ( 4.969)	Data  7.664 ( 4.392)	Loss 1.0823e-01 (1.4727e-01) 
2023-05-27 05:38:57.461162: train Epoch: [7][123/193]	Time  1.989 ( 4.945)	Data  1.417 ( 4.368)	Loss 8.9515e-02 (1.4680e-01) 
2023-05-27 05:39:05.235525: train Epoch: [7][124/193]	Time  7.774 ( 4.968)	Data  7.201 ( 4.391)	Loss 1.3498e-01 (1.4671e-01) 
2023-05-27 05:39:07.263896: train Epoch: [7][125/193]	Time  2.028 ( 4.944)	Data  1.458 ( 4.368)	Loss 1.3384e-01 (1.4660e-01) 
2023-05-27 05:39:15.717025: train Epoch: [7][126/193]	Time  8.453 ( 4.972)	Data  7.879 ( 4.395)	Loss 1.9017e-01 (1.4695e-01) 
2023-05-27 05:39:17.278079: train Epoch: [7][127/193]	Time  1.561 ( 4.945)	Data  0.984 ( 4.369)	Loss 1.5355e-01 (1.4700e-01) 
2023-05-27 05:39:25.606878: train Epoch: [7][128/193]	Time  8.329 ( 4.972)	Data  7.759 ( 4.395)	Loss 1.9558e-01 (1.4738e-01) 
2023-05-27 05:39:27.405253: train Epoch: [7][129/193]	Time  1.798 ( 4.947)	Data  1.218 ( 4.371)	Loss 1.4244e-01 (1.4734e-01) 
2023-05-27 05:39:35.801049: train Epoch: [7][130/193]	Time  8.396 ( 4.974)	Data  7.824 ( 4.397)	Loss 1.9805e-01 (1.4772e-01) 
2023-05-27 05:39:37.554055: train Epoch: [7][131/193]	Time  1.753 ( 4.949)	Data  1.176 ( 4.373)	Loss 1.3844e-01 (1.4765e-01) 
2023-05-27 05:39:46.162525: train Epoch: [7][132/193]	Time  8.608 ( 4.977)	Data  8.036 ( 4.400)	Loss 1.2558e-01 (1.4749e-01) 
2023-05-27 05:39:47.218806: train Epoch: [7][133/193]	Time  1.056 ( 4.947)	Data  0.422 ( 4.370)	Loss 9.1966e-02 (1.4707e-01) 
2023-05-27 05:39:56.368045: train Epoch: [7][134/193]	Time  9.149 ( 4.978)	Data  8.571 ( 4.402)	Loss 2.3747e-01 (1.4774e-01) 
2023-05-27 05:39:56.983649: train Epoch: [7][135/193]	Time  0.616 ( 4.946)	Data  0.001 ( 4.369)	Loss 1.2818e-01 (1.4760e-01) 
2023-05-27 05:40:05.536941: train Epoch: [7][136/193]	Time  8.553 ( 4.973)	Data  7.979 ( 4.396)	Loss 1.9043e-01 (1.4791e-01) 
2023-05-27 05:40:06.506581: train Epoch: [7][137/193]	Time  0.970 ( 4.944)	Data  0.370 ( 4.366)	Loss 1.1706e-01 (1.4769e-01) 
2023-05-27 05:40:15.520032: train Epoch: [7][138/193]	Time  9.013 ( 4.973)	Data  8.428 ( 4.396)	Loss 1.6711e-01 (1.4783e-01) 
2023-05-27 05:40:16.193353: train Epoch: [7][139/193]	Time  0.673 ( 4.942)	Data  0.094 ( 4.365)	Loss 1.1771e-01 (1.4761e-01) 
2023-05-27 05:40:25.341422: train Epoch: [7][140/193]	Time  9.148 ( 4.972)	Data  8.570 ( 4.395)	Loss 1.5717e-01 (1.4768e-01) 
2023-05-27 05:40:26.102457: train Epoch: [7][141/193]	Time  0.761 ( 4.942)	Data  0.195 ( 4.365)	Loss 2.4217e-01 (1.4835e-01) 
2023-05-27 05:40:35.476000: train Epoch: [7][142/193]	Time  9.374 ( 4.973)	Data  8.796 ( 4.396)	Loss 1.8339e-01 (1.4859e-01) 
2023-05-27 05:40:36.392618: train Epoch: [7][143/193]	Time  0.917 ( 4.945)	Data  0.340 ( 4.368)	Loss 1.2811e-01 (1.4845e-01) 
2023-05-27 05:40:45.317765: train Epoch: [7][144/193]	Time  8.925 ( 4.973)	Data  8.331 ( 4.395)	Loss 2.5962e-01 (1.4922e-01) 
2023-05-27 05:40:46.231764: train Epoch: [7][145/193]	Time  0.914 ( 4.945)	Data  0.335 ( 4.367)	Loss 1.5354e-01 (1.4925e-01) 
2023-05-27 05:40:55.099893: train Epoch: [7][146/193]	Time  8.868 ( 4.972)	Data  8.281 ( 4.394)	Loss 1.9916e-01 (1.4959e-01) 
2023-05-27 05:40:55.889853: train Epoch: [7][147/193]	Time  0.790 ( 4.943)	Data  0.217 ( 4.366)	Loss 1.2226e-01 (1.4940e-01) 
2023-05-27 05:41:05.147036: train Epoch: [7][148/193]	Time  9.257 ( 4.972)	Data  8.644 ( 4.395)	Loss 1.0242e-01 (1.4909e-01) 
2023-05-27 05:41:05.734085: train Epoch: [7][149/193]	Time  0.587 ( 4.943)	Data  0.010 ( 4.365)	Loss 1.3635e-01 (1.4900e-01) 
2023-05-27 05:41:14.722865: train Epoch: [7][150/193]	Time  8.989 ( 4.970)	Data  8.409 ( 4.392)	Loss 1.0851e-01 (1.4873e-01) 
2023-05-27 05:41:15.306275: train Epoch: [7][151/193]	Time  0.583 ( 4.941)	Data  0.001 ( 4.363)	Loss 1.3065e-01 (1.4861e-01) 
2023-05-27 05:41:24.809206: train Epoch: [7][152/193]	Time  9.503 ( 4.971)	Data  8.905 ( 4.393)	Loss 1.0440e-01 (1.4832e-01) 
2023-05-27 05:41:25.373286: train Epoch: [7][153/193]	Time  0.564 ( 4.942)	Data  0.001 ( 4.364)	Loss 1.5657e-01 (1.4838e-01) 
2023-05-27 05:41:34.484261: train Epoch: [7][154/193]	Time  9.111 ( 4.969)	Data  8.541 ( 4.391)	Loss 1.1080e-01 (1.4814e-01) 
2023-05-27 05:41:35.119417: train Epoch: [7][155/193]	Time  0.635 ( 4.941)	Data  0.059 ( 4.364)	Loss 1.1955e-01 (1.4795e-01) 
2023-05-27 05:41:44.055551: train Epoch: [7][156/193]	Time  8.936 ( 4.967)	Data  8.366 ( 4.389)	Loss 1.3553e-01 (1.4787e-01) 
2023-05-27 05:41:45.133356: train Epoch: [7][157/193]	Time  1.078 ( 4.942)	Data  0.492 ( 4.364)	Loss 1.3862e-01 (1.4781e-01) 
2023-05-27 05:41:53.392775: train Epoch: [7][158/193]	Time  8.259 ( 4.963)	Data  7.687 ( 4.385)	Loss 9.0411e-02 (1.4745e-01) 
2023-05-27 05:41:55.069167: train Epoch: [7][159/193]	Time  1.676 ( 4.942)	Data  1.111 ( 4.365)	Loss 1.0596e-01 (1.4719e-01) 
2023-05-27 05:42:03.570696: train Epoch: [7][160/193]	Time  8.502 ( 4.965)	Data  7.931 ( 4.387)	Loss 1.7259e-01 (1.4735e-01) 
2023-05-27 05:42:04.828710: train Epoch: [7][161/193]	Time  1.258 ( 4.942)	Data  0.672 ( 4.364)	Loss 1.0251e-01 (1.4707e-01) 
2023-05-27 05:42:13.692537: train Epoch: [7][162/193]	Time  8.864 ( 4.966)	Data  8.293 ( 4.388)	Loss 9.8031e-02 (1.4677e-01) 
2023-05-27 05:42:14.732710: train Epoch: [7][163/193]	Time  1.040 ( 4.942)	Data  0.464 ( 4.364)	Loss 1.1934e-01 (1.4661e-01) 
2023-05-27 05:42:23.716912: train Epoch: [7][164/193]	Time  8.984 ( 4.966)	Data  8.416 ( 4.389)	Loss 1.3983e-01 (1.4657e-01) 
2023-05-27 05:42:24.969435: train Epoch: [7][165/193]	Time  1.253 ( 4.944)	Data  0.659 ( 4.366)	Loss 1.1040e-01 (1.4635e-01) 
2023-05-27 05:42:33.713284: train Epoch: [7][166/193]	Time  8.744 ( 4.967)	Data  8.170 ( 4.389)	Loss 1.2167e-01 (1.4620e-01) 
2023-05-27 05:42:34.949628: train Epoch: [7][167/193]	Time  1.236 ( 4.945)	Data  0.661 ( 4.367)	Loss 1.2296e-01 (1.4606e-01) 
2023-05-27 05:42:44.132354: train Epoch: [7][168/193]	Time  9.183 ( 4.970)	Data  8.607 ( 4.392)	Loss 1.4104e-01 (1.4603e-01) 
2023-05-27 05:42:44.939557: train Epoch: [7][169/193]	Time  0.807 ( 4.945)	Data  0.151 ( 4.367)	Loss 1.5887e-01 (1.4611e-01) 
2023-05-27 05:42:54.033191: train Epoch: [7][170/193]	Time  9.094 ( 4.969)	Data  8.525 ( 4.391)	Loss 1.2648e-01 (1.4599e-01) 
2023-05-27 05:42:55.006697: train Epoch: [7][171/193]	Time  0.974 ( 4.946)	Data  0.407 ( 4.368)	Loss 1.0824e-01 (1.4577e-01) 
2023-05-27 05:43:03.818949: train Epoch: [7][172/193]	Time  8.812 ( 4.968)	Data  8.246 ( 4.391)	Loss 1.4634e-01 (1.4578e-01) 
2023-05-27 05:43:04.592768: train Epoch: [7][173/193]	Time  0.774 ( 4.944)	Data  0.204 ( 4.367)	Loss 1.6695e-01 (1.4590e-01) 
2023-05-27 05:43:13.516651: train Epoch: [7][174/193]	Time  8.924 ( 4.967)	Data  8.307 ( 4.389)	Loss 1.0102e-01 (1.4564e-01) 
2023-05-27 05:43:14.564883: train Epoch: [7][175/193]	Time  1.048 ( 4.945)	Data  0.477 ( 4.367)	Loss 1.4690e-01 (1.4565e-01) 
2023-05-27 05:43:23.350772: train Epoch: [7][176/193]	Time  8.786 ( 4.967)	Data  8.215 ( 4.389)	Loss 1.2002e-01 (1.4550e-01) 
2023-05-27 05:43:24.551677: train Epoch: [7][177/193]	Time  1.201 ( 4.945)	Data  0.633 ( 4.367)	Loss 2.1839e-01 (1.4591e-01) 
2023-05-27 05:43:33.512344: train Epoch: [7][178/193]	Time  8.961 ( 4.968)	Data  8.363 ( 4.390)	Loss 1.5181e-01 (1.4595e-01) 
2023-05-27 05:43:34.566506: train Epoch: [7][179/193]	Time  1.054 ( 4.946)	Data  0.492 ( 4.368)	Loss 1.0891e-01 (1.4574e-01) 
2023-05-27 05:43:43.309795: train Epoch: [7][180/193]	Time  8.743 ( 4.967)	Data  8.167 ( 4.389)	Loss 9.8587e-02 (1.4548e-01) 
2023-05-27 05:43:44.447166: train Epoch: [7][181/193]	Time  1.137 ( 4.946)	Data  0.574 ( 4.368)	Loss 3.1139e-01 (1.4639e-01) 
2023-05-27 05:43:53.187690: train Epoch: [7][182/193]	Time  8.741 ( 4.967)	Data  8.174 ( 4.389)	Loss 1.3802e-01 (1.4635e-01) 
2023-05-27 05:43:54.484042: train Epoch: [7][183/193]	Time  1.296 ( 4.947)	Data  0.735 ( 4.369)	Loss 1.6025e-01 (1.4642e-01) 
2023-05-27 05:44:03.197686: train Epoch: [7][184/193]	Time  8.714 ( 4.967)	Data  8.137 ( 4.389)	Loss 8.0755e-02 (1.4607e-01) 
2023-05-27 05:44:04.231145: train Epoch: [7][185/193]	Time  1.033 ( 4.946)	Data  0.472 ( 4.368)	Loss 9.4266e-02 (1.4579e-01) 
2023-05-27 05:44:13.123277: train Epoch: [7][186/193]	Time  8.892 ( 4.967)	Data  8.310 ( 4.389)	Loss 1.3491e-01 (1.4573e-01) 
2023-05-27 05:44:13.963049: train Epoch: [7][187/193]	Time  0.840 ( 4.945)	Data  0.244 ( 4.367)	Loss 2.3055e-01 (1.4618e-01) 
2023-05-27 05:44:22.576503: train Epoch: [7][188/193]	Time  8.613 ( 4.965)	Data  8.038 ( 4.387)	Loss 2.0068e-01 (1.4647e-01) 
2023-05-27 05:44:24.194521: train Epoch: [7][189/193]	Time  1.618 ( 4.947)	Data  1.055 ( 4.369)	Loss 1.6011e-01 (1.4654e-01) 
2023-05-27 05:44:32.353893: train Epoch: [7][190/193]	Time  8.159 ( 4.964)	Data  7.583 ( 4.386)	Loss 1.0660e-01 (1.4633e-01) 
2023-05-27 05:44:34.473828: train Epoch: [7][191/193]	Time  2.120 ( 4.949)	Data  1.550 ( 4.371)	Loss 1.3129e-01 (1.4625e-01) 
2023-05-27 05:44:41.299135: train Epoch: [7][192/193]	Time  6.825 ( 4.959)	Data  6.245 ( 4.381)	Loss 1.0659e-01 (1.4605e-01) 
2023-05-27 05:44:41.424765: Train Epoch done in 957.1535539080069 s 
2023-05-27 05:44:47.897682: val Epoch: [7][ 0/72]	Time  5.718 ( 5.718)	Data  5.535 ( 5.535)	Loss 3.2400e-01 (3.2400e-01) 
2023-05-27 05:44:48.104908: val Epoch: [7][ 1/72]	Time  0.208 ( 2.963)	Data  0.096 ( 2.815)	Loss 4.0431e-01 (3.6416e-01) 
2023-05-27 05:44:52.687395: val Epoch: [7][ 2/72]	Time  4.582 ( 3.503)	Data  4.471 ( 3.367)	Loss 1.6031e-01 (2.9621e-01) 
2023-05-27 05:44:52.931322: val Epoch: [7][ 3/72]	Time  0.244 ( 2.688)	Data  0.133 ( 2.559)	Loss 8.0786e-02 (2.4235e-01) 
2023-05-27 05:44:57.765196: val Epoch: [7][ 4/72]	Time  4.834 ( 3.117)	Data  4.722 ( 2.991)	Loss 1.1812e-01 (2.1751e-01) 
2023-05-27 05:44:57.928329: val Epoch: [7][ 5/72]	Time  0.163 ( 2.625)	Data  0.051 ( 2.501)	Loss 1.7335e-01 (2.1015e-01) 
2023-05-27 05:45:02.744791: val Epoch: [7][ 6/72]	Time  4.816 ( 2.938)	Data  4.700 ( 2.815)	Loss 2.5743e-01 (2.1690e-01) 
2023-05-27 05:45:03.157879: val Epoch: [7][ 7/72]	Time  0.413 ( 2.622)	Data  0.300 ( 2.501)	Loss 2.3414e-01 (2.1906e-01) 
2023-05-27 05:45:07.942408: val Epoch: [7][ 8/72]	Time  4.785 ( 2.863)	Data  4.673 ( 2.742)	Loss 1.2552e-01 (2.0866e-01) 
2023-05-27 05:45:08.205896: val Epoch: [7][ 9/72]	Time  0.263 ( 2.603)	Data  0.152 ( 2.483)	Loss 1.0851e-01 (1.9865e-01) 
2023-05-27 05:45:13.013838: val Epoch: [7][10/72]	Time  4.808 ( 2.803)	Data  4.697 ( 2.685)	Loss 1.9090e-01 (1.9795e-01) 
2023-05-27 05:45:13.321031: val Epoch: [7][11/72]	Time  0.307 ( 2.595)	Data  0.196 ( 2.477)	Loss 1.0107e-01 (1.8987e-01) 
2023-05-27 05:45:17.873217: val Epoch: [7][12/72]	Time  4.552 ( 2.746)	Data  4.438 ( 2.628)	Loss 1.6531e-01 (1.8798e-01) 
2023-05-27 05:45:18.363312: val Epoch: [7][13/72]	Time  0.490 ( 2.585)	Data  0.382 ( 2.468)	Loss 9.5901e-02 (1.8141e-01) 
2023-05-27 05:45:22.958680: val Epoch: [7][14/72]	Time  4.595 ( 2.719)	Data  4.487 ( 2.602)	Loss 1.9221e-01 (1.8213e-01) 
2023-05-27 05:45:23.635694: val Epoch: [7][15/72]	Time  0.677 ( 2.591)	Data  0.569 ( 2.475)	Loss 2.3806e-01 (1.8562e-01) 
2023-05-27 05:45:28.043737: val Epoch: [7][16/72]	Time  4.408 ( 2.698)	Data  4.296 ( 2.582)	Loss 1.3563e-01 (1.8268e-01) 
2023-05-27 05:45:28.672378: val Epoch: [7][17/72]	Time  0.629 ( 2.583)	Data  0.521 ( 2.468)	Loss 1.9383e-01 (1.8330e-01) 
2023-05-27 05:45:33.044381: val Epoch: [7][18/72]	Time  4.372 ( 2.677)	Data  4.264 ( 2.562)	Loss 1.5584e-01 (1.8186e-01) 
2023-05-27 05:45:33.778628: val Epoch: [7][19/72]	Time  0.734 ( 2.580)	Data  0.625 ( 2.465)	Loss 1.2828e-01 (1.7918e-01) 
2023-05-27 05:45:38.112884: val Epoch: [7][20/72]	Time  4.334 ( 2.663)	Data  4.225 ( 2.549)	Loss 1.9874e-01 (1.8011e-01) 
2023-05-27 05:45:38.628507: val Epoch: [7][21/72]	Time  0.516 ( 2.566)	Data  0.406 ( 2.452)	Loss 7.8264e-02 (1.7548e-01) 
2023-05-27 05:45:43.165924: val Epoch: [7][22/72]	Time  4.537 ( 2.652)	Data  4.428 ( 2.538)	Loss 1.2667e-01 (1.7336e-01) 
2023-05-27 05:45:43.640364: val Epoch: [7][23/72]	Time  0.474 ( 2.561)	Data  0.366 ( 2.447)	Loss 3.3674e-01 (1.8016e-01) 
2023-05-27 05:45:48.163900: val Epoch: [7][24/72]	Time  4.524 ( 2.639)	Data  4.408 ( 2.526)	Loss 7.7034e-02 (1.7604e-01) 
2023-05-27 05:45:48.698026: val Epoch: [7][25/72]	Time  0.534 ( 2.558)	Data  0.422 ( 2.445)	Loss 1.2485e-01 (1.7407e-01) 
2023-05-27 05:45:53.165087: val Epoch: [7][26/72]	Time  4.467 ( 2.629)	Data  4.355 ( 2.515)	Loss 5.5537e-01 (1.8819e-01) 
2023-05-27 05:45:53.805842: val Epoch: [7][27/72]	Time  0.641 ( 2.558)	Data  0.529 ( 2.445)	Loss 6.6209e-01 (2.0512e-01) 
2023-05-27 05:45:58.448034: val Epoch: [7][28/72]	Time  4.642 ( 2.630)	Data  4.528 ( 2.516)	Loss 1.1004e-01 (2.0184e-01) 
2023-05-27 05:45:58.921145: val Epoch: [7][29/72]	Time  0.473 ( 2.558)	Data  0.365 ( 2.445)	Loss 1.2051e-01 (1.9913e-01) 
2023-05-27 05:46:03.541577: val Epoch: [7][30/72]	Time  4.620 ( 2.625)	Data  4.508 ( 2.511)	Loss 1.8695e-01 (1.9874e-01) 
2023-05-27 05:46:03.650275: val Epoch: [7][31/72]	Time  0.109 ( 2.546)	Data  0.001 ( 2.433)	Loss 8.8790e-02 (1.9530e-01) 
2023-05-27 05:46:08.615756: val Epoch: [7][32/72]	Time  4.965 ( 2.619)	Data  4.857 ( 2.506)	Loss 7.6824e-02 (1.9171e-01) 
2023-05-27 05:46:08.724439: val Epoch: [7][33/72]	Time  0.109 ( 2.545)	Data  0.000 ( 2.433)	Loss 1.1548e-01 (1.8947e-01) 
2023-05-27 05:46:13.621777: val Epoch: [7][34/72]	Time  4.897 ( 2.613)	Data  4.788 ( 2.500)	Loss 9.3505e-02 (1.8673e-01) 
2023-05-27 05:46:13.729954: val Epoch: [7][35/72]	Time  0.108 ( 2.543)	Data  0.000 ( 2.430)	Loss 1.1362e-01 (1.8469e-01) 
2023-05-27 05:46:18.848679: val Epoch: [7][36/72]	Time  5.119 ( 2.613)	Data  5.011 ( 2.500)	Loss 1.6478e-01 (1.8416e-01) 
2023-05-27 05:46:18.957284: val Epoch: [7][37/72]	Time  0.109 ( 2.547)	Data  0.001 ( 2.434)	Loss 9.8663e-02 (1.8191e-01) 
2023-05-27 05:46:23.550975: val Epoch: [7][38/72]	Time  4.594 ( 2.599)	Data  4.485 ( 2.487)	Loss 8.4236e-02 (1.7940e-01) 
2023-05-27 05:46:23.810437: val Epoch: [7][39/72]	Time  0.259 ( 2.541)	Data  0.146 ( 2.428)	Loss 4.1440e-01 (1.8528e-01) 
2023-05-27 05:46:28.444045: val Epoch: [7][40/72]	Time  4.634 ( 2.592)	Data  4.524 ( 2.480)	Loss 7.5021e-02 (1.8259e-01) 
2023-05-27 05:46:28.805079: val Epoch: [7][41/72]	Time  0.361 ( 2.539)	Data  0.253 ( 2.427)	Loss 2.2500e-01 (1.8360e-01) 
2023-05-27 05:46:33.499541: val Epoch: [7][42/72]	Time  4.694 ( 2.589)	Data  4.582 ( 2.477)	Loss 3.3818e-01 (1.8719e-01) 
2023-05-27 05:46:33.889522: val Epoch: [7][43/72]	Time  0.390 ( 2.539)	Data  0.281 ( 2.427)	Loss 6.2550e-01 (1.9715e-01) 
2023-05-27 05:46:38.654435: val Epoch: [7][44/72]	Time  4.765 ( 2.588)	Data  4.656 ( 2.476)	Loss 1.7325e-01 (1.9662e-01) 
2023-05-27 05:46:39.137862: val Epoch: [7][45/72]	Time  0.483 ( 2.543)	Data  0.374 ( 2.431)	Loss 1.2295e-01 (1.9502e-01) 
2023-05-27 05:46:43.380788: val Epoch: [7][46/72]	Time  4.243 ( 2.579)	Data  4.134 ( 2.467)	Loss 1.1829e-01 (1.9339e-01) 
2023-05-27 05:46:44.179657: val Epoch: [7][47/72]	Time  0.799 ( 2.542)	Data  0.691 ( 2.430)	Loss 1.7175e-01 (1.9294e-01) 
2023-05-27 05:46:48.221406: val Epoch: [7][48/72]	Time  4.042 ( 2.572)	Data  3.933 ( 2.460)	Loss 1.0923e-01 (1.9123e-01) 
2023-05-27 05:46:49.151497: val Epoch: [7][49/72]	Time  0.930 ( 2.539)	Data  0.822 ( 2.428)	Loss 1.2565e-01 (1.8992e-01) 
2023-05-27 05:46:53.363570: val Epoch: [7][50/72]	Time  4.212 ( 2.572)	Data  4.104 ( 2.461)	Loss 8.4927e-02 (1.8786e-01) 
2023-05-27 05:46:54.252394: val Epoch: [7][51/72]	Time  0.889 ( 2.540)	Data  0.777 ( 2.428)	Loss 1.3077e-01 (1.8676e-01) 
2023-05-27 05:46:58.145149: val Epoch: [7][52/72]	Time  3.893 ( 2.565)	Data  3.781 ( 2.454)	Loss 5.2651e-01 (1.9317e-01) 
2023-05-27 05:46:59.492194: val Epoch: [7][53/72]	Time  1.347 ( 2.543)	Data  1.237 ( 2.431)	Loss 2.1129e-01 (1.9351e-01) 
2023-05-27 05:47:03.041692: val Epoch: [7][54/72]	Time  3.549 ( 2.561)	Data  3.438 ( 2.450)	Loss 1.9519e-01 (1.9354e-01) 
2023-05-27 05:47:04.248003: val Epoch: [7][55/72]	Time  1.206 ( 2.537)	Data  1.096 ( 2.425)	Loss 1.0642e-01 (1.9198e-01) 
2023-05-27 05:47:07.968192: val Epoch: [7][56/72]	Time  3.720 ( 2.558)	Data  3.608 ( 2.446)	Loss 9.7426e-02 (1.9032e-01) 
2023-05-27 05:47:09.381384: val Epoch: [7][57/72]	Time  1.413 ( 2.538)	Data  1.299 ( 2.426)	Loss 5.8829e-01 (1.9718e-01) 
2023-05-27 05:47:12.928138: val Epoch: [7][58/72]	Time  3.547 ( 2.555)	Data  3.439 ( 2.443)	Loss 1.1422e-01 (1.9578e-01) 
2023-05-27 05:47:14.502986: val Epoch: [7][59/72]	Time  1.575 ( 2.539)	Data  1.451 ( 2.427)	Loss 2.4961e-01 (1.9668e-01) 
2023-05-27 05:47:18.001166: val Epoch: [7][60/72]	Time  3.498 ( 2.554)	Data  3.385 ( 2.443)	Loss 8.1959e-02 (1.9480e-01) 
2023-05-27 05:47:19.324229: val Epoch: [7][61/72]	Time  1.323 ( 2.535)	Data  1.204 ( 2.423)	Loss 8.5361e-02 (1.9303e-01) 
2023-05-27 05:47:23.153966: val Epoch: [7][62/72]	Time  3.830 ( 2.555)	Data  3.721 ( 2.443)	Loss 3.7849e-01 (1.9597e-01) 
2023-05-27 05:47:24.506602: val Epoch: [7][63/72]	Time  1.353 ( 2.536)	Data  1.223 ( 2.424)	Loss 2.3778e-01 (1.9663e-01) 
2023-05-27 05:47:28.318603: val Epoch: [7][64/72]	Time  3.812 ( 2.556)	Data  3.704 ( 2.444)	Loss 1.2268e-01 (1.9549e-01) 
2023-05-27 05:47:29.453200: val Epoch: [7][65/72]	Time  1.135 ( 2.534)	Data  1.023 ( 2.422)	Loss 9.0482e-02 (1.9390e-01) 
2023-05-27 05:47:33.292715: val Epoch: [7][66/72]	Time  3.840 ( 2.554)	Data  3.728 ( 2.442)	Loss 9.4640e-02 (1.9242e-01) 
2023-05-27 05:47:34.609124: val Epoch: [7][67/72]	Time  1.316 ( 2.536)	Data  1.188 ( 2.423)	Loss 2.1254e-01 (1.9271e-01) 
2023-05-27 05:47:38.294236: val Epoch: [7][68/72]	Time  3.685 ( 2.552)	Data  3.571 ( 2.440)	Loss 1.8843e-01 (1.9265e-01) 
2023-05-27 05:47:39.462676: val Epoch: [7][69/72]	Time  1.168 ( 2.533)	Data  1.058 ( 2.420)	Loss 2.0736e-01 (1.9286e-01) 
2023-05-27 05:47:43.259480: val Epoch: [7][70/72]	Time  3.797 ( 2.550)	Data  3.685 ( 2.438)	Loss 8.0480e-02 (1.9128e-01) 
2023-05-27 05:47:44.470260: val Epoch: [7][71/72]	Time  1.211 ( 2.532)	Data  1.094 ( 2.419)	Loss 1.3354e-01 (1.9048e-01) 
2023-05-27 05:47:44.790133: Epoch 7 :Val : ['ET : 0.6645709276199341', 'TC : 0.6970536112785339', 'WT : 0.8015635013580322'] 
2023-05-27 05:47:44.791139: Epoch 7 :Val : ['ET : 0.6645709276199341', 'TC : 0.6970536112785339', 'WT : 0.8015635013580322'] 
2023-05-27 05:47:44.796499: Saving the model with DSC 0.7149874567985535 
2023-05-27 05:47:45.672725: Val epoch done in 184.24794721599028 s 
2023-05-27 05:47:45.711727: Batches per epoch:  193 
2023-05-27 05:47:56.203499: train Epoch: [8][  0/193]	Time 10.491 (10.491)	Data  9.880 ( 9.880)	Loss 1.4085e-01 (1.4085e-01) 
2023-05-27 05:47:56.774868: train Epoch: [8][  1/193]	Time  0.571 ( 5.531)	Data  0.001 ( 4.940)	Loss 1.3035e-01 (1.3560e-01) 
2023-05-27 05:48:06.291329: train Epoch: [8][  2/193]	Time  9.516 ( 6.860)	Data  8.935 ( 6.272)	Loss 8.0205e-02 (1.1713e-01) 
2023-05-27 05:48:06.861104: train Epoch: [8][  3/193]	Time  0.570 ( 5.287)	Data  0.001 ( 4.704)	Loss 1.1640e-01 (1.1695e-01) 
2023-05-27 05:48:16.042136: train Epoch: [8][  4/193]	Time  9.181 ( 6.066)	Data  8.610 ( 5.485)	Loss 1.1476e-01 (1.1651e-01) 
2023-05-27 05:48:16.606034: train Epoch: [8][  5/193]	Time  0.564 ( 5.149)	Data  0.001 ( 4.571)	Loss 1.1519e-01 (1.1629e-01) 
2023-05-27 05:48:25.712049: train Epoch: [8][  6/193]	Time  9.106 ( 5.714)	Data  8.535 ( 5.137)	Loss 1.4586e-01 (1.2052e-01) 
2023-05-27 05:48:26.283098: train Epoch: [8][  7/193]	Time  0.571 ( 5.071)	Data  0.001 ( 4.495)	Loss 4.0951e-01 (1.5664e-01) 
2023-05-27 05:48:35.471248: train Epoch: [8][  8/193]	Time  9.188 ( 5.529)	Data  8.620 ( 4.954)	Loss 1.3963e-01 (1.5475e-01) 
2023-05-27 05:48:36.040693: train Epoch: [8][  9/193]	Time  0.569 ( 5.033)	Data  0.001 ( 4.458)	Loss 1.4394e-01 (1.5367e-01) 
2023-05-27 05:48:45.514703: train Epoch: [8][ 10/193]	Time  9.474 ( 5.437)	Data  8.904 ( 4.863)	Loss 1.0032e-01 (1.4882e-01) 
2023-05-27 05:48:46.084607: train Epoch: [8][ 11/193]	Time  0.570 ( 5.031)	Data  0.001 ( 4.457)	Loss 1.5620e-01 (1.4943e-01) 
2023-05-27 05:48:55.219778: train Epoch: [8][ 12/193]	Time  9.135 ( 5.347)	Data  8.558 ( 4.773)	Loss 1.2569e-01 (1.4761e-01) 
2023-05-27 05:48:55.782855: train Epoch: [8][ 13/193]	Time  0.563 ( 5.005)	Data  0.001 ( 4.432)	Loss 8.6656e-02 (1.4325e-01) 
2023-05-27 05:49:04.824841: train Epoch: [8][ 14/193]	Time  9.042 ( 5.274)	Data  8.478 ( 4.702)	Loss 1.2939e-01 (1.4233e-01) 
2023-05-27 05:49:05.625852: train Epoch: [8][ 15/193]	Time  0.801 ( 4.995)	Data  0.236 ( 4.423)	Loss 1.4810e-01 (1.4269e-01) 
2023-05-27 05:49:14.861526: train Epoch: [8][ 16/193]	Time  9.236 ( 5.244)	Data  8.673 ( 4.673)	Loss 1.4017e-01 (1.4254e-01) 
2023-05-27 05:49:15.781919: train Epoch: [8][ 17/193]	Time  0.920 ( 5.004)	Data  0.358 ( 4.433)	Loss 1.6822e-01 (1.4397e-01) 
2023-05-27 05:49:24.686687: train Epoch: [8][ 18/193]	Time  8.905 ( 5.209)	Data  8.328 ( 4.638)	Loss 1.5798e-01 (1.4471e-01) 
2023-05-27 05:49:25.877251: train Epoch: [8][ 19/193]	Time  1.191 ( 5.008)	Data  0.627 ( 4.437)	Loss 1.0348e-01 (1.4264e-01) 
2023-05-27 05:49:34.863036: train Epoch: [8][ 20/193]	Time  8.986 ( 5.198)	Data  8.418 ( 4.627)	Loss 1.5943e-01 (1.4344e-01) 
2023-05-27 05:49:35.928685: train Epoch: [8][ 21/193]	Time  1.066 ( 5.010)	Data  0.487 ( 4.439)	Loss 1.7576e-01 (1.4491e-01) 
2023-05-27 05:49:44.492334: train Epoch: [8][ 22/193]	Time  8.564 ( 5.164)	Data  8.000 ( 4.594)	Loss 1.7853e-01 (1.4637e-01) 
2023-05-27 05:49:45.543161: train Epoch: [8][ 23/193]	Time  1.051 ( 4.993)	Data  0.489 ( 4.423)	Loss 1.4834e-01 (1.4646e-01) 
2023-05-27 05:49:54.107003: train Epoch: [8][ 24/193]	Time  8.564 ( 5.136)	Data  7.998 ( 4.566)	Loss 9.9142e-02 (1.4456e-01) 
2023-05-27 05:49:55.847699: train Epoch: [8][ 25/193]	Time  1.741 ( 5.005)	Data  1.174 ( 4.435)	Loss 1.3923e-01 (1.4436e-01) 
2023-05-27 05:50:03.854801: train Epoch: [8][ 26/193]	Time  8.007 ( 5.116)	Data  7.439 ( 4.546)	Loss 1.2212e-01 (1.4353e-01) 
2023-05-27 05:50:05.764613: train Epoch: [8][ 27/193]	Time  1.910 ( 5.002)	Data  1.341 ( 4.432)	Loss 2.0295e-01 (1.4566e-01) 
2023-05-27 05:50:14.039970: train Epoch: [8][ 28/193]	Time  8.275 ( 5.115)	Data  7.707 ( 4.545)	Loss 1.8765e-01 (1.4710e-01) 
2023-05-27 05:50:15.761526: train Epoch: [8][ 29/193]	Time  1.722 ( 5.002)	Data  1.157 ( 4.432)	Loss 9.8432e-02 (1.4548e-01) 
2023-05-27 05:50:23.144708: train Epoch: [8][ 30/193]	Time  7.383 ( 5.078)	Data  6.781 ( 4.508)	Loss 1.9581e-01 (1.4711e-01) 
2023-05-27 05:50:24.160208: train Epoch: [8][ 31/193]	Time  1.015 ( 4.952)	Data  0.452 ( 4.381)	Loss 2.1181e-01 (1.4913e-01) 
2023-05-27 05:50:32.697114: train Epoch: [8][ 32/193]	Time  8.537 ( 5.060)	Data  7.962 ( 4.490)	Loss 1.3680e-01 (1.4875e-01) 
2023-05-27 05:50:33.646842: train Epoch: [8][ 33/193]	Time  0.950 ( 4.939)	Data  0.387 ( 4.369)	Loss 9.8000e-02 (1.4726e-01) 
2023-05-27 05:50:42.734890: train Epoch: [8][ 34/193]	Time  9.088 ( 5.058)	Data  8.526 ( 4.488)	Loss 1.1627e-01 (1.4638e-01) 
2023-05-27 05:50:43.608320: train Epoch: [8][ 35/193]	Time  0.873 ( 4.942)	Data  0.311 ( 4.372)	Loss 1.7114e-01 (1.4706e-01) 
2023-05-27 05:50:52.899773: train Epoch: [8][ 36/193]	Time  9.291 ( 5.059)	Data  8.727 ( 4.489)	Loss 1.1531e-01 (1.4621e-01) 
2023-05-27 05:50:53.462607: train Epoch: [8][ 37/193]	Time  0.563 ( 4.941)	Data  0.001 ( 4.371)	Loss 1.4930e-01 (1.4629e-01) 
2023-05-27 05:51:02.965429: train Epoch: [8][ 38/193]	Time  9.503 ( 5.058)	Data  8.931 ( 4.488)	Loss 1.8242e-01 (1.4721e-01) 
2023-05-27 05:51:03.528737: train Epoch: [8][ 39/193]	Time  0.563 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.2873e-01 (1.4675e-01) 
2023-05-27 05:51:12.767121: train Epoch: [8][ 40/193]	Time  9.238 ( 5.050)	Data  8.663 ( 4.481)	Loss 8.3166e-02 (1.4520e-01) 
2023-05-27 05:51:13.330307: train Epoch: [8][ 41/193]	Time  0.563 ( 4.943)	Data  0.001 ( 4.374)	Loss 1.4992e-01 (1.4531e-01) 
2023-05-27 05:51:22.646141: train Epoch: [8][ 42/193]	Time  9.316 ( 5.045)	Data  8.753 ( 4.476)	Loss 2.4115e-01 (1.4754e-01) 
2023-05-27 05:51:23.440532: train Epoch: [8][ 43/193]	Time  0.794 ( 4.948)	Data  0.232 ( 4.379)	Loss 2.0311e-01 (1.4880e-01) 
2023-05-27 05:51:32.646000: train Epoch: [8][ 44/193]	Time  9.205 ( 5.043)	Data  8.637 ( 4.474)	Loss 1.4208e-01 (1.4865e-01) 
2023-05-27 05:51:33.519027: train Epoch: [8][ 45/193]	Time  0.873 ( 4.952)	Data  0.304 ( 4.383)	Loss 1.2039e-01 (1.4804e-01) 
2023-05-27 05:51:42.541573: train Epoch: [8][ 46/193]	Time  9.023 ( 5.039)	Data  8.454 ( 4.470)	Loss 9.6861e-02 (1.4695e-01) 
2023-05-27 05:51:43.112157: train Epoch: [8][ 47/193]	Time  0.571 ( 4.946)	Data  0.001 ( 4.377)	Loss 1.0142e-01 (1.4600e-01) 
2023-05-27 05:51:52.198303: train Epoch: [8][ 48/193]	Time  9.086 ( 5.030)	Data  8.508 ( 4.461)	Loss 1.2140e-01 (1.4550e-01) 
2023-05-27 05:51:52.779721: train Epoch: [8][ 49/193]	Time  0.581 ( 4.941)	Data  0.013 ( 4.372)	Loss 1.9251e-01 (1.4644e-01) 
2023-05-27 05:52:02.276248: train Epoch: [8][ 50/193]	Time  9.497 ( 5.031)	Data  8.932 ( 4.461)	Loss 1.5882e-01 (1.4668e-01) 
2023-05-27 05:52:02.841244: train Epoch: [8][ 51/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.376)	Loss 9.2077e-02 (1.4563e-01) 
2023-05-27 05:52:12.034850: train Epoch: [8][ 52/193]	Time  9.194 ( 5.025)	Data  8.631 ( 4.456)	Loss 1.1220e-01 (1.4500e-01) 
2023-05-27 05:52:12.657020: train Epoch: [8][ 53/193]	Time  0.622 ( 4.943)	Data  0.058 ( 4.375)	Loss 1.1956e-01 (1.4453e-01) 
2023-05-27 05:52:21.996553: train Epoch: [8][ 54/193]	Time  9.340 ( 5.023)	Data  8.770 ( 4.454)	Loss 1.3020e-01 (1.4427e-01) 
2023-05-27 05:52:22.565727: train Epoch: [8][ 55/193]	Time  0.569 ( 4.944)	Data  0.001 ( 4.375)	Loss 1.1264e-01 (1.4371e-01) 
2023-05-27 05:52:31.964811: train Epoch: [8][ 56/193]	Time  9.399 ( 5.022)	Data  8.827 ( 4.453)	Loss 8.7772e-02 (1.4272e-01) 
2023-05-27 05:52:32.535517: train Epoch: [8][ 57/193]	Time  0.571 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.4575e-01 (1.4278e-01) 
2023-05-27 05:52:41.880683: train Epoch: [8][ 58/193]	Time  9.345 ( 5.020)	Data  8.768 ( 4.451)	Loss 1.2070e-01 (1.4240e-01) 
2023-05-27 05:52:42.450786: train Epoch: [8][ 59/193]	Time  0.570 ( 4.946)	Data  0.001 ( 4.377)	Loss 1.2935e-01 (1.4218e-01) 
2023-05-27 05:52:51.187074: train Epoch: [8][ 60/193]	Time  8.736 ( 5.008)	Data  8.173 ( 4.439)	Loss 1.4733e-01 (1.4227e-01) 
2023-05-27 05:52:51.769186: train Epoch: [8][ 61/193]	Time  0.582 ( 4.936)	Data  0.001 ( 4.367)	Loss 1.4551e-01 (1.4232e-01) 
2023-05-27 05:52:59.981064: train Epoch: [8][ 62/193]	Time  8.212 ( 4.988)	Data  7.648 ( 4.419)	Loss 1.8396e-01 (1.4298e-01) 
2023-05-27 05:53:00.977792: train Epoch: [8][ 63/193]	Time  0.997 ( 4.926)	Data  0.432 ( 4.357)	Loss 1.2618e-01 (1.4272e-01) 
2023-05-27 05:53:09.737114: train Epoch: [8][ 64/193]	Time  8.759 ( 4.985)	Data  8.196 ( 4.416)	Loss 2.3351e-01 (1.4412e-01) 
2023-05-27 05:53:11.403522: train Epoch: [8][ 65/193]	Time  1.666 ( 4.935)	Data  1.096 ( 4.366)	Loss 1.4737e-01 (1.4417e-01) 
2023-05-27 05:53:19.553063: train Epoch: [8][ 66/193]	Time  8.150 ( 4.983)	Data  7.585 ( 4.414)	Loss 1.6320e-01 (1.4445e-01) 
2023-05-27 05:53:20.898696: train Epoch: [8][ 67/193]	Time  1.346 ( 4.929)	Data  0.772 ( 4.360)	Loss 1.1594e-01 (1.4403e-01) 
2023-05-27 05:53:29.391854: train Epoch: [8][ 68/193]	Time  8.493 ( 4.981)	Data  7.912 ( 4.412)	Loss 1.1280e-01 (1.4358e-01) 
2023-05-27 05:53:31.007904: train Epoch: [8][ 69/193]	Time  1.616 ( 4.933)	Data  1.038 ( 4.363)	Loss 1.3022e-01 (1.4339e-01) 
2023-05-27 05:53:39.645568: train Epoch: [8][ 70/193]	Time  8.638 ( 4.985)	Data  8.067 ( 4.416)	Loss 2.3549e-01 (1.4468e-01) 
2023-05-27 05:53:41.069369: train Epoch: [8][ 71/193]	Time  1.424 ( 4.936)	Data  0.860 ( 4.366)	Loss 1.5978e-01 (1.4489e-01) 
2023-05-27 05:53:49.642694: train Epoch: [8][ 72/193]	Time  8.573 ( 4.985)	Data  8.009 ( 4.416)	Loss 1.1895e-01 (1.4454e-01) 
2023-05-27 05:53:50.861943: train Epoch: [8][ 73/193]	Time  1.219 ( 4.934)	Data  0.651 ( 4.365)	Loss 1.2688e-01 (1.4430e-01) 
2023-05-27 05:53:58.889965: train Epoch: [8][ 74/193]	Time  8.028 ( 4.976)	Data  7.463 ( 4.407)	Loss 1.0020e-01 (1.4371e-01) 
2023-05-27 05:54:01.129685: train Epoch: [8][ 75/193]	Time  2.240 ( 4.940)	Data  1.668 ( 4.371)	Loss 1.3170e-01 (1.4355e-01) 
2023-05-27 05:54:09.112438: train Epoch: [8][ 76/193]	Time  7.983 ( 4.979)	Data  7.418 ( 4.410)	Loss 1.5210e-01 (1.4367e-01) 
2023-05-27 05:54:10.969462: train Epoch: [8][ 77/193]	Time  1.857 ( 4.939)	Data  1.287 ( 4.370)	Loss 9.9850e-02 (1.4310e-01) 
2023-05-27 05:54:19.125675: train Epoch: [8][ 78/193]	Time  8.156 ( 4.980)	Data  7.573 ( 4.411)	Loss 8.7980e-02 (1.4241e-01) 
2023-05-27 05:54:20.854849: train Epoch: [8][ 79/193]	Time  1.729 ( 4.939)	Data  1.159 ( 4.370)	Loss 1.1513e-01 (1.4206e-01) 
2023-05-27 05:54:29.262452: train Epoch: [8][ 80/193]	Time  8.408 ( 4.982)	Data  7.830 ( 4.413)	Loss 1.6264e-01 (1.4232e-01) 
2023-05-27 05:54:30.851573: train Epoch: [8][ 81/193]	Time  1.589 ( 4.941)	Data  1.022 ( 4.371)	Loss 8.5590e-02 (1.4163e-01) 
2023-05-27 05:54:39.270875: train Epoch: [8][ 82/193]	Time  8.419 ( 4.983)	Data  7.847 ( 4.413)	Loss 1.2791e-01 (1.4146e-01) 
2023-05-27 05:54:41.180210: train Epoch: [8][ 83/193]	Time  1.909 ( 4.946)	Data  1.346 ( 4.377)	Loss 1.5928e-01 (1.4167e-01) 
2023-05-27 05:54:49.323856: train Epoch: [8][ 84/193]	Time  8.144 ( 4.984)	Data  7.577 ( 4.414)	Loss 8.8815e-02 (1.4105e-01) 
2023-05-27 05:54:51.241970: train Epoch: [8][ 85/193]	Time  1.918 ( 4.948)	Data  1.355 ( 4.379)	Loss 1.8131e-01 (1.4152e-01) 
2023-05-27 05:54:59.551601: train Epoch: [8][ 86/193]	Time  8.310 ( 4.987)	Data  7.735 ( 4.417)	Loss 1.3770e-01 (1.4148e-01) 
2023-05-27 05:55:01.252158: train Epoch: [8][ 87/193]	Time  1.701 ( 4.949)	Data  1.126 ( 4.380)	Loss 5.4823e-02 (1.4049e-01) 
2023-05-27 05:55:09.999171: train Epoch: [8][ 88/193]	Time  8.747 ( 4.992)	Data  8.175 ( 4.423)	Loss 1.4659e-01 (1.4056e-01) 
2023-05-27 05:55:11.523761: train Epoch: [8][ 89/193]	Time  1.525 ( 4.953)	Data  0.953 ( 4.384)	Loss 1.6151e-01 (1.4079e-01) 
2023-05-27 05:55:19.734302: train Epoch: [8][ 90/193]	Time  8.211 ( 4.989)	Data  7.647 ( 4.420)	Loss 1.0853e-01 (1.4044e-01) 
2023-05-27 05:55:21.320642: train Epoch: [8][ 91/193]	Time  1.586 ( 4.952)	Data  1.023 ( 4.383)	Loss 1.1133e-01 (1.4012e-01) 
2023-05-27 05:55:30.007543: train Epoch: [8][ 92/193]	Time  8.687 ( 4.992)	Data  8.121 ( 4.423)	Loss 1.0753e-01 (1.3977e-01) 
2023-05-27 05:55:30.801832: train Epoch: [8][ 93/193]	Time  0.794 ( 4.948)	Data  0.231 ( 4.379)	Loss 9.0078e-02 (1.3924e-01) 
2023-05-27 05:55:39.857733: train Epoch: [8][ 94/193]	Time  9.056 ( 4.991)	Data  8.491 ( 4.422)	Loss 1.3268e-01 (1.3917e-01) 
2023-05-27 05:55:41.167613: train Epoch: [8][ 95/193]	Time  1.310 ( 4.953)	Data  0.744 ( 4.384)	Loss 1.2273e-01 (1.3900e-01) 
2023-05-27 05:55:48.958949: train Epoch: [8][ 96/193]	Time  7.791 ( 4.982)	Data  7.225 ( 4.413)	Loss 1.1230e-01 (1.3873e-01) 
2023-05-27 05:55:50.024134: train Epoch: [8][ 97/193]	Time  1.065 ( 4.942)	Data  0.499 ( 4.373)	Loss 1.0561e-01 (1.3839e-01) 
2023-05-27 05:55:56.185081: train Epoch: [8][ 98/193]	Time  6.161 ( 4.954)	Data  5.589 ( 4.385)	Loss 1.3040e-01 (1.3831e-01) 
2023-05-27 05:55:57.479975: train Epoch: [8][ 99/193]	Time  1.295 ( 4.918)	Data  0.732 ( 4.349)	Loss 1.0721e-01 (1.3800e-01) 
2023-05-27 05:56:06.144230: train Epoch: [8][100/193]	Time  8.664 ( 4.955)	Data  8.093 ( 4.386)	Loss 1.1309e-01 (1.3775e-01) 
2023-05-27 05:56:07.637848: train Epoch: [8][101/193]	Time  1.494 ( 4.921)	Data  0.930 ( 4.352)	Loss 1.1966e-01 (1.3757e-01) 
2023-05-27 05:56:16.067870: train Epoch: [8][102/193]	Time  8.430 ( 4.955)	Data  7.859 ( 4.386)	Loss 2.7695e-01 (1.3893e-01) 
2023-05-27 05:56:17.395772: train Epoch: [8][103/193]	Time  1.328 ( 4.920)	Data  0.760 ( 4.351)	Loss 1.1751e-01 (1.3872e-01) 
2023-05-27 05:56:26.022313: train Epoch: [8][104/193]	Time  8.627 ( 4.955)	Data  8.055 ( 4.386)	Loss 8.3966e-02 (1.3820e-01) 
2023-05-27 05:56:27.162177: train Epoch: [8][105/193]	Time  1.140 ( 4.919)	Data  0.566 ( 4.350)	Loss 1.1463e-01 (1.3798e-01) 
2023-05-27 05:56:36.550280: train Epoch: [8][106/193]	Time  9.388 ( 4.961)	Data  8.810 ( 4.392)	Loss 1.6380e-01 (1.3822e-01) 
2023-05-27 05:56:37.115228: train Epoch: [8][107/193]	Time  0.565 ( 4.920)	Data  0.001 ( 4.351)	Loss 1.1648e-01 (1.3802e-01) 
2023-05-27 05:56:46.141160: train Epoch: [8][108/193]	Time  9.026 ( 4.958)	Data  8.452 ( 4.389)	Loss 9.4963e-02 (1.3762e-01) 
2023-05-27 05:56:46.826574: train Epoch: [8][109/193]	Time  0.685 ( 4.919)	Data  0.116 ( 4.350)	Loss 1.3284e-01 (1.3758e-01) 
2023-05-27 05:56:56.076303: train Epoch: [8][110/193]	Time  9.250 ( 4.958)	Data  8.681 ( 4.389)	Loss 7.3614e-02 (1.3700e-01) 
2023-05-27 05:56:56.730862: train Epoch: [8][111/193]	Time  0.655 ( 4.920)	Data  0.089 ( 4.351)	Loss 2.1459e-01 (1.3769e-01) 
2023-05-27 05:57:05.924313: train Epoch: [8][112/193]	Time  9.193 ( 4.958)	Data  8.627 ( 4.389)	Loss 1.2922e-01 (1.3762e-01) 
2023-05-27 05:57:06.547638: train Epoch: [8][113/193]	Time  0.623 ( 4.920)	Data  0.059 ( 4.351)	Loss 1.8534e-01 (1.3804e-01) 
2023-05-27 05:57:15.778551: train Epoch: [8][114/193]	Time  9.231 ( 4.957)	Data  8.666 ( 4.388)	Loss 3.2800e-01 (1.3969e-01) 
2023-05-27 05:57:16.704499: train Epoch: [8][115/193]	Time  0.926 ( 4.922)	Data  0.348 ( 4.353)	Loss 8.9197e-02 (1.3925e-01) 
2023-05-27 05:57:25.963243: train Epoch: [8][116/193]	Time  9.259 ( 4.959)	Data  8.689 ( 4.390)	Loss 1.2534e-01 (1.3914e-01) 
2023-05-27 05:57:26.548346: train Epoch: [8][117/193]	Time  0.585 ( 4.922)	Data  0.022 ( 4.353)	Loss 1.3947e-01 (1.3914e-01) 
2023-05-27 05:57:35.623643: train Epoch: [8][118/193]	Time  9.075 ( 4.957)	Data  8.511 ( 4.388)	Loss 1.2271e-01 (1.3900e-01) 
2023-05-27 05:57:36.300246: train Epoch: [8][119/193]	Time  0.677 ( 4.922)	Data  0.113 ( 4.353)	Loss 8.7625e-02 (1.3857e-01) 
2023-05-27 05:57:45.594402: train Epoch: [8][120/193]	Time  9.294 ( 4.958)	Data  8.728 ( 4.389)	Loss 1.8204e-01 (1.3893e-01) 
2023-05-27 05:57:46.169173: train Epoch: [8][121/193]	Time  0.575 ( 4.922)	Data  0.001 ( 4.353)	Loss 9.2652e-02 (1.3855e-01) 
2023-05-27 05:57:55.202315: train Epoch: [8][122/193]	Time  9.033 ( 4.955)	Data  8.467 ( 4.386)	Loss 1.7872e-01 (1.3888e-01) 
2023-05-27 05:57:56.388290: train Epoch: [8][123/193]	Time  1.186 ( 4.925)	Data  0.621 ( 4.356)	Loss 4.2103e-01 (1.4115e-01) 
2023-05-27 05:58:05.272655: train Epoch: [8][124/193]	Time  8.884 ( 4.956)	Data  8.318 ( 4.388)	Loss 2.2049e-01 (1.4179e-01) 
2023-05-27 05:58:06.476049: train Epoch: [8][125/193]	Time  1.203 ( 4.927)	Data  0.637 ( 4.358)	Loss 1.8095e-01 (1.4210e-01) 
2023-05-27 05:58:15.377176: train Epoch: [8][126/193]	Time  8.901 ( 4.958)	Data  8.334 ( 4.389)	Loss 1.0357e-01 (1.4180e-01) 
2023-05-27 05:58:16.665404: train Epoch: [8][127/193]	Time  1.288 ( 4.929)	Data  0.712 ( 4.360)	Loss 1.1027e-01 (1.4155e-01) 
2023-05-27 05:58:25.567285: train Epoch: [8][128/193]	Time  8.902 ( 4.960)	Data  8.332 ( 4.391)	Loss 1.8736e-01 (1.4191e-01) 
2023-05-27 05:58:26.617108: train Epoch: [8][129/193]	Time  1.050 ( 4.930)	Data  0.475 ( 4.361)	Loss 1.2649e-01 (1.4179e-01) 
2023-05-27 05:58:35.963425: train Epoch: [8][130/193]	Time  9.346 ( 4.964)	Data  8.781 ( 4.395)	Loss 2.1239e-01 (1.4233e-01) 
2023-05-27 05:58:36.543215: train Epoch: [8][131/193]	Time  0.580 ( 4.931)	Data  0.001 ( 4.362)	Loss 9.8669e-02 (1.4200e-01) 
2023-05-27 05:58:45.831822: train Epoch: [8][132/193]	Time  9.289 ( 4.963)	Data  8.717 ( 4.394)	Loss 2.2265e-01 (1.4260e-01) 
2023-05-27 05:58:46.434935: train Epoch: [8][133/193]	Time  0.603 ( 4.931)	Data  0.001 ( 4.361)	Loss 1.6666e-01 (1.4278e-01) 
2023-05-27 05:58:55.282698: train Epoch: [8][134/193]	Time  8.848 ( 4.960)	Data  8.285 ( 4.391)	Loss 1.0876e-01 (1.4253e-01) 
2023-05-27 05:58:55.966235: train Epoch: [8][135/193]	Time  0.684 ( 4.928)	Data  0.104 ( 4.359)	Loss 1.3858e-01 (1.4250e-01) 
2023-05-27 05:59:05.181354: train Epoch: [8][136/193]	Time  9.215 ( 4.960)	Data  8.640 ( 4.390)	Loss 2.1747e-01 (1.4305e-01) 
2023-05-27 05:59:05.801732: train Epoch: [8][137/193]	Time  0.620 ( 4.928)	Data  0.050 ( 4.359)	Loss 1.5598e-01 (1.4314e-01) 
2023-05-27 05:59:14.999941: train Epoch: [8][138/193]	Time  9.198 ( 4.959)	Data  8.634 ( 4.390)	Loss 1.0939e-01 (1.4290e-01) 
2023-05-27 05:59:16.071837: train Epoch: [8][139/193]	Time  1.072 ( 4.931)	Data  0.501 ( 4.362)	Loss 1.2047e-01 (1.4274e-01) 
2023-05-27 05:59:24.952617: train Epoch: [8][140/193]	Time  8.881 ( 4.959)	Data  8.308 ( 4.390)	Loss 3.5397e-01 (1.4424e-01) 
2023-05-27 05:59:26.600174: train Epoch: [8][141/193]	Time  1.648 ( 4.936)	Data  1.074 ( 4.366)	Loss 1.3991e-01 (1.4421e-01) 
2023-05-27 05:59:35.053356: train Epoch: [8][142/193]	Time  8.453 ( 4.960)	Data  7.888 ( 4.391)	Loss 1.5562e-01 (1.4429e-01) 
2023-05-27 05:59:37.002542: train Epoch: [8][143/193]	Time  1.949 ( 4.940)	Data  1.348 ( 4.370)	Loss 1.3402e-01 (1.4421e-01) 
2023-05-27 05:59:44.481004: train Epoch: [8][144/193]	Time  7.478 ( 4.957)	Data  6.914 ( 4.387)	Loss 8.7022e-02 (1.4382e-01) 
2023-05-27 05:59:46.636682: train Epoch: [8][145/193]	Time  2.156 ( 4.938)	Data  1.583 ( 4.368)	Loss 1.3194e-01 (1.4374e-01) 
2023-05-27 05:59:54.635328: train Epoch: [8][146/193]	Time  7.999 ( 4.959)	Data  7.412 ( 4.389)	Loss 1.6516e-01 (1.4388e-01) 
2023-05-27 05:59:56.647331: train Epoch: [8][147/193]	Time  2.012 ( 4.939)	Data  1.445 ( 4.369)	Loss 1.5794e-01 (1.4398e-01) 
2023-05-27 06:00:04.434097: train Epoch: [8][148/193]	Time  7.787 ( 4.958)	Data  7.225 ( 4.388)	Loss 1.6047e-01 (1.4409e-01) 
2023-05-27 06:00:06.564755: train Epoch: [8][149/193]	Time  2.131 ( 4.939)	Data  1.568 ( 4.369)	Loss 1.5375e-01 (1.4415e-01) 
2023-05-27 06:00:14.473169: train Epoch: [8][150/193]	Time  7.908 ( 4.959)	Data  7.337 ( 4.389)	Loss 1.5351e-01 (1.4422e-01) 
2023-05-27 06:00:16.423947: train Epoch: [8][151/193]	Time  1.951 ( 4.939)	Data  1.388 ( 4.369)	Loss 1.8947e-01 (1.4451e-01) 
2023-05-27 06:00:24.410313: train Epoch: [8][152/193]	Time  7.986 ( 4.959)	Data  7.402 ( 4.389)	Loss 3.0745e-01 (1.4558e-01) 
2023-05-27 06:00:26.516439: train Epoch: [8][153/193]	Time  2.106 ( 4.940)	Data  1.542 ( 4.371)	Loss 1.2125e-01 (1.4542e-01) 
2023-05-27 06:00:34.041220: train Epoch: [8][154/193]	Time  7.525 ( 4.957)	Data  6.960 ( 4.387)	Loss 1.4851e-01 (1.4544e-01) 
2023-05-27 06:00:36.956767: train Epoch: [8][155/193]	Time  2.916 ( 4.944)	Data  2.350 ( 4.374)	Loss 1.8911e-01 (1.4572e-01) 
2023-05-27 06:00:44.293520: train Epoch: [8][156/193]	Time  7.337 ( 4.959)	Data  6.757 ( 4.390)	Loss 8.3824e-02 (1.4533e-01) 
2023-05-27 06:00:46.957499: train Epoch: [8][157/193]	Time  2.664 ( 4.945)	Data  2.096 ( 4.375)	Loss 2.3383e-01 (1.4589e-01) 
2023-05-27 06:00:54.020130: train Epoch: [8][158/193]	Time  7.063 ( 4.958)	Data  6.484 ( 4.388)	Loss 1.7638e-01 (1.4608e-01) 
2023-05-27 06:00:56.886085: train Epoch: [8][159/193]	Time  2.866 ( 4.945)	Data  2.301 ( 4.375)	Loss 2.1971e-01 (1.4654e-01) 
2023-05-27 06:01:03.713387: train Epoch: [8][160/193]	Time  6.827 ( 4.957)	Data  6.261 ( 4.387)	Loss 9.3793e-02 (1.4621e-01) 
2023-05-27 06:01:06.535916: train Epoch: [8][161/193]	Time  2.823 ( 4.943)	Data  2.256 ( 4.374)	Loss 1.0508e-01 (1.4596e-01) 
2023-05-27 06:01:13.288678: train Epoch: [8][162/193]	Time  6.753 ( 4.954)	Data  6.186 ( 4.385)	Loss 1.3408e-01 (1.4588e-01) 
2023-05-27 06:01:16.217209: train Epoch: [8][163/193]	Time  2.929 ( 4.942)	Data  2.365 ( 4.373)	Loss 1.5928e-01 (1.4597e-01) 
2023-05-27 06:01:23.190553: train Epoch: [8][164/193]	Time  6.973 ( 4.954)	Data  6.400 ( 4.385)	Loss 9.0863e-02 (1.4563e-01) 
2023-05-27 06:01:25.895077: train Epoch: [8][165/193]	Time  2.705 ( 4.941)	Data  2.141 ( 4.371)	Loss 2.1482e-01 (1.4605e-01) 
2023-05-27 06:01:33.111958: train Epoch: [8][166/193]	Time  7.217 ( 4.954)	Data  6.643 ( 4.385)	Loss 1.2438e-01 (1.4592e-01) 
2023-05-27 06:01:35.524752: train Epoch: [8][167/193]	Time  2.413 ( 4.939)	Data  1.849 ( 4.370)	Loss 1.0797e-01 (1.4569e-01) 
2023-05-27 06:01:43.281555: train Epoch: [8][168/193]	Time  7.757 ( 4.956)	Data  7.183 ( 4.387)	Loss 2.9968e-01 (1.4660e-01) 
2023-05-27 06:01:45.087648: train Epoch: [8][169/193]	Time  1.806 ( 4.937)	Data  1.238 ( 4.368)	Loss 1.9405e-01 (1.4688e-01) 
2023-05-27 06:01:53.276113: train Epoch: [8][170/193]	Time  8.188 ( 4.957)	Data  7.617 ( 4.387)	Loss 3.5550e-01 (1.4810e-01) 
2023-05-27 06:01:55.106580: train Epoch: [8][171/193]	Time  1.830 ( 4.938)	Data  1.257 ( 4.369)	Loss 1.8628e-01 (1.4833e-01) 
2023-05-27 06:02:03.699080: train Epoch: [8][172/193]	Time  8.592 ( 4.959)	Data  8.024 ( 4.390)	Loss 3.2201e-01 (1.4933e-01) 
2023-05-27 06:02:04.928375: train Epoch: [8][173/193]	Time  1.229 ( 4.938)	Data  0.661 ( 4.368)	Loss 1.2014e-01 (1.4916e-01) 
2023-05-27 06:02:13.484995: train Epoch: [8][174/193]	Time  8.557 ( 4.959)	Data  7.984 ( 4.389)	Loss 1.4236e-01 (1.4912e-01) 
2023-05-27 06:02:15.066617: train Epoch: [8][175/193]	Time  1.582 ( 4.940)	Data  1.019 ( 4.370)	Loss 2.5325e-01 (1.4971e-01) 
2023-05-27 06:02:23.879102: train Epoch: [8][176/193]	Time  8.812 ( 4.961)	Data  8.206 ( 4.392)	Loss 2.0696e-01 (1.5004e-01) 
2023-05-27 06:02:24.911718: train Epoch: [8][177/193]	Time  1.033 ( 4.939)	Data  0.461 ( 4.370)	Loss 3.4941e-01 (1.5116e-01) 
2023-05-27 06:02:33.593731: train Epoch: [8][178/193]	Time  8.682 ( 4.960)	Data  8.082 ( 4.390)	Loss 1.5840e-01 (1.5120e-01) 
2023-05-27 06:02:34.754982: train Epoch: [8][179/193]	Time  1.161 ( 4.939)	Data  0.599 ( 4.369)	Loss 1.2385e-01 (1.5105e-01) 
2023-05-27 06:02:43.575573: train Epoch: [8][180/193]	Time  8.821 ( 4.961)	Data  8.243 ( 4.391)	Loss 1.4250e-01 (1.5100e-01) 
2023-05-27 06:02:44.724292: train Epoch: [8][181/193]	Time  1.149 ( 4.940)	Data  0.586 ( 4.370)	Loss 1.6863e-01 (1.5110e-01) 
2023-05-27 06:02:53.654287: train Epoch: [8][182/193]	Time  8.930 ( 4.961)	Data  8.330 ( 4.391)	Loss 1.5153e-01 (1.5110e-01) 
2023-05-27 06:02:54.822953: train Epoch: [8][183/193]	Time  1.169 ( 4.941)	Data  0.597 ( 4.371)	Loss 1.1991e-01 (1.5093e-01) 
2023-05-27 06:03:03.893911: train Epoch: [8][184/193]	Time  9.071 ( 4.963)	Data  8.487 ( 4.393)	Loss 1.8351e-01 (1.5110e-01) 
2023-05-27 06:03:04.829665: train Epoch: [8][185/193]	Time  0.936 ( 4.941)	Data  0.372 ( 4.371)	Loss 1.3305e-01 (1.5101e-01) 
2023-05-27 06:03:13.984937: train Epoch: [8][186/193]	Time  9.155 ( 4.964)	Data  8.574 ( 4.394)	Loss 1.1388e-01 (1.5081e-01) 
2023-05-27 06:03:14.956800: train Epoch: [8][187/193]	Time  0.972 ( 4.943)	Data  0.408 ( 4.373)	Loss 3.0569e-01 (1.5163e-01) 
2023-05-27 06:03:23.597664: train Epoch: [8][188/193]	Time  8.641 ( 4.962)	Data  8.062 ( 4.392)	Loss 1.6833e-01 (1.5172e-01) 
2023-05-27 06:03:24.815139: train Epoch: [8][189/193]	Time  1.217 ( 4.943)	Data  0.653 ( 4.373)	Loss 1.2905e-01 (1.5160e-01) 
2023-05-27 06:03:33.602867: train Epoch: [8][190/193]	Time  8.788 ( 4.963)	Data  8.215 ( 4.393)	Loss 1.3015e-01 (1.5149e-01) 
2023-05-27 06:03:34.671495: train Epoch: [8][191/193]	Time  1.069 ( 4.942)	Data  0.503 ( 4.372)	Loss 1.8667e-01 (1.5167e-01) 
2023-05-27 06:03:42.731145: train Epoch: [8][192/193]	Time  8.060 ( 4.959)	Data  7.497 ( 4.389)	Loss 9.7645e-02 (1.5139e-01) 
2023-05-27 06:03:42.863822: Train Epoch done in 957.1521481179952 s 
2023-05-27 06:03:49.071112: val Epoch: [8][ 0/72]	Time  5.389 ( 5.389)	Data  5.232 ( 5.232)	Loss 1.1908e-01 (1.1908e-01) 
2023-05-27 06:03:49.204340: val Epoch: [8][ 1/72]	Time  0.133 ( 2.761)	Data  0.025 ( 2.629)	Loss 1.0363e-01 (1.1136e-01) 
2023-05-27 06:03:54.113128: val Epoch: [8][ 2/72]	Time  4.909 ( 3.477)	Data  4.790 ( 3.349)	Loss 4.1609e-01 (2.1293e-01) 
2023-05-27 06:03:54.252599: val Epoch: [8][ 3/72]	Time  0.139 ( 2.643)	Data  0.025 ( 2.518)	Loss 1.6290e-01 (2.0042e-01) 
2023-05-27 06:03:59.073895: val Epoch: [8][ 4/72]	Time  4.821 ( 3.078)	Data  4.711 ( 2.957)	Loss 2.4849e-01 (2.1004e-01) 
2023-05-27 06:03:59.182065: val Epoch: [8][ 5/72]	Time  0.108 ( 2.583)	Data  0.000 ( 2.464)	Loss 9.7204e-02 (1.9123e-01) 
2023-05-27 06:04:04.269100: val Epoch: [8][ 6/72]	Time  5.087 ( 2.941)	Data  4.981 ( 2.823)	Loss 8.4697e-02 (1.7601e-01) 
2023-05-27 06:04:04.374110: val Epoch: [8][ 7/72]	Time  0.105 ( 2.587)	Data  0.000 ( 2.471)	Loss 1.2693e-01 (1.6988e-01) 
2023-05-27 06:04:09.080421: val Epoch: [8][ 8/72]	Time  4.706 ( 2.822)	Data  4.601 ( 2.707)	Loss 1.8931e-01 (1.7204e-01) 
2023-05-27 06:04:09.233213: val Epoch: [8][ 9/72]	Time  0.153 ( 2.555)	Data  0.048 ( 2.441)	Loss 8.6005e-02 (1.6343e-01) 
2023-05-27 06:04:14.107256: val Epoch: [8][10/72]	Time  4.874 ( 2.766)	Data  4.769 ( 2.653)	Loss 2.5376e-01 (1.7164e-01) 
2023-05-27 06:04:14.211895: val Epoch: [8][11/72]	Time  0.105 ( 2.544)	Data  0.000 ( 2.432)	Loss 8.0683e-02 (1.6406e-01) 
2023-05-27 06:04:19.022830: val Epoch: [8][12/72]	Time  4.811 ( 2.719)	Data  4.705 ( 2.607)	Loss 5.6459e-01 (1.9487e-01) 
2023-05-27 06:04:19.269356: val Epoch: [8][13/72]	Time  0.247 ( 2.542)	Data  0.142 ( 2.431)	Loss 6.1773e-01 (2.2508e-01) 
2023-05-27 06:04:23.900656: val Epoch: [8][14/72]	Time  4.631 ( 2.681)	Data  4.526 ( 2.570)	Loss 1.0110e-01 (2.1681e-01) 
2023-05-27 06:04:24.102261: val Epoch: [8][15/72]	Time  0.202 ( 2.526)	Data  0.095 ( 2.416)	Loss 6.9263e-02 (2.0759e-01) 
2023-05-27 06:04:28.985640: val Epoch: [8][16/72]	Time  4.883 ( 2.665)	Data  4.775 ( 2.554)	Loss 1.8338e-01 (2.0617e-01) 
2023-05-27 06:04:29.237337: val Epoch: [8][17/72]	Time  0.252 ( 2.531)	Data  0.146 ( 2.421)	Loss 2.1415e-01 (2.0661e-01) 
2023-05-27 06:04:34.127046: val Epoch: [8][18/72]	Time  4.890 ( 2.655)	Data  4.784 ( 2.545)	Loss 2.4674e-01 (2.0872e-01) 
2023-05-27 06:04:34.336747: val Epoch: [8][19/72]	Time  0.210 ( 2.533)	Data  0.104 ( 2.423)	Loss 2.5592e-01 (2.1108e-01) 
2023-05-27 06:04:39.238457: val Epoch: [8][20/72]	Time  4.902 ( 2.646)	Data  4.794 ( 2.536)	Loss 1.4434e-01 (2.0790e-01) 
2023-05-27 06:04:39.391988: val Epoch: [8][21/72]	Time  0.154 ( 2.532)	Data  0.049 ( 2.423)	Loss 1.7857e-01 (2.0657e-01) 
2023-05-27 06:04:44.282420: val Epoch: [8][22/72]	Time  4.890 ( 2.635)	Data  4.780 ( 2.525)	Loss 3.7925e-01 (2.1408e-01) 
2023-05-27 06:04:44.406138: val Epoch: [8][23/72]	Time  0.124 ( 2.530)	Data  0.016 ( 2.421)	Loss 1.7241e-01 (2.1234e-01) 
2023-05-27 06:04:49.366829: val Epoch: [8][24/72]	Time  4.961 ( 2.627)	Data  4.855 ( 2.518)	Loss 2.6597e-01 (2.1449e-01) 
2023-05-27 06:04:49.595934: val Epoch: [8][25/72]	Time  0.229 ( 2.535)	Data  0.124 ( 2.426)	Loss 8.9993e-02 (2.0970e-01) 
2023-05-27 06:04:53.925474: val Epoch: [8][26/72]	Time  4.330 ( 2.602)	Data  4.224 ( 2.493)	Loss 9.1198e-02 (2.0531e-01) 
2023-05-27 06:04:54.610608: val Epoch: [8][27/72]	Time  0.685 ( 2.533)	Data  0.579 ( 2.424)	Loss 1.2743e-01 (2.0253e-01) 
2023-05-27 06:04:58.778967: val Epoch: [8][28/72]	Time  4.168 ( 2.590)	Data  4.063 ( 2.481)	Loss 7.7743e-02 (1.9823e-01) 
2023-05-27 06:04:59.599375: val Epoch: [8][29/72]	Time  0.820 ( 2.531)	Data  0.715 ( 2.422)	Loss 2.0762e-01 (1.9854e-01) 
2023-05-27 06:05:03.878098: val Epoch: [8][30/72]	Time  4.279 ( 2.587)	Data  4.174 ( 2.478)	Loss 1.6675e-01 (1.9751e-01) 
2023-05-27 06:05:04.413083: val Epoch: [8][31/72]	Time  0.535 ( 2.523)	Data  0.427 ( 2.414)	Loss 1.4403e-01 (1.9584e-01) 
2023-05-27 06:05:09.052554: val Epoch: [8][32/72]	Time  4.639 ( 2.587)	Data  4.534 ( 2.479)	Loss 1.1728e-01 (1.9346e-01) 
2023-05-27 06:05:09.531554: val Epoch: [8][33/72]	Time  0.479 ( 2.525)	Data  0.373 ( 2.417)	Loss 4.7485e-01 (2.0174e-01) 
2023-05-27 06:05:13.887404: val Epoch: [8][34/72]	Time  4.356 ( 2.577)	Data  4.250 ( 2.469)	Loss 1.4109e-01 (2.0000e-01) 
2023-05-27 06:05:14.556372: val Epoch: [8][35/72]	Time  0.669 ( 2.524)	Data  0.561 ( 2.416)	Loss 1.0565e-01 (1.9738e-01) 
2023-05-27 06:05:18.499882: val Epoch: [8][36/72]	Time  3.944 ( 2.563)	Data  3.838 ( 2.454)	Loss 8.9234e-02 (1.9446e-01) 
2023-05-27 06:05:19.788854: val Epoch: [8][37/72]	Time  1.289 ( 2.529)	Data  1.184 ( 2.421)	Loss 2.4252e-01 (1.9573e-01) 
2023-05-27 06:05:23.746936: val Epoch: [8][38/72]	Time  3.958 ( 2.566)	Data  3.852 ( 2.458)	Loss 1.9069e-01 (1.9560e-01) 
2023-05-27 06:05:25.002577: val Epoch: [8][39/72]	Time  1.256 ( 2.533)	Data  1.150 ( 2.425)	Loss 9.4634e-02 (1.9307e-01) 
2023-05-27 06:05:28.617585: val Epoch: [8][40/72]	Time  3.615 ( 2.559)	Data  3.505 ( 2.451)	Loss 1.3417e-01 (1.9164e-01) 
2023-05-27 06:05:30.080229: val Epoch: [8][41/72]	Time  1.463 ( 2.533)	Data  1.352 ( 2.425)	Loss 9.1765e-02 (1.8926e-01) 
2023-05-27 06:05:33.689100: val Epoch: [8][42/72]	Time  3.609 ( 2.558)	Data  3.500 ( 2.450)	Loss 2.5777e-01 (1.9085e-01) 
2023-05-27 06:05:34.916488: val Epoch: [8][43/72]	Time  1.227 ( 2.528)	Data  1.111 ( 2.420)	Loss 1.3232e-01 (1.8952e-01) 
2023-05-27 06:05:38.875725: val Epoch: [8][44/72]	Time  3.959 ( 2.560)	Data  3.851 ( 2.452)	Loss 4.2605e-01 (1.9478e-01) 
2023-05-27 06:05:40.011281: val Epoch: [8][45/72]	Time  1.136 ( 2.529)	Data  1.028 ( 2.421)	Loss 3.1067e-01 (1.9730e-01) 
2023-05-27 06:05:43.909765: val Epoch: [8][46/72]	Time  3.898 ( 2.558)	Data  3.790 ( 2.450)	Loss 1.9216e-01 (1.9719e-01) 
2023-05-27 06:05:45.232244: val Epoch: [8][47/72]	Time  1.322 ( 2.532)	Data  1.215 ( 2.424)	Loss 2.6587e-01 (1.9862e-01) 
2023-05-27 06:05:48.812042: val Epoch: [8][48/72]	Time  3.580 ( 2.554)	Data  3.472 ( 2.445)	Loss 3.5513e-01 (2.0181e-01) 
2023-05-27 06:05:50.408583: val Epoch: [8][49/72]	Time  1.597 ( 2.535)	Data  1.488 ( 2.426)	Loss 1.6661e-01 (2.0111e-01) 
2023-05-27 06:05:53.717417: val Epoch: [8][50/72]	Time  3.309 ( 2.550)	Data  3.201 ( 2.441)	Loss 3.0879e-01 (2.0322e-01) 
2023-05-27 06:05:55.546535: val Epoch: [8][51/72]	Time  1.829 ( 2.536)	Data  1.721 ( 2.428)	Loss 1.1752e-01 (2.0157e-01) 
2023-05-27 06:05:58.715164: val Epoch: [8][52/72]	Time  3.169 ( 2.548)	Data  3.061 ( 2.440)	Loss 3.8604e-01 (2.0505e-01) 
2023-05-27 06:06:00.482516: val Epoch: [8][53/72]	Time  1.767 ( 2.533)	Data  1.656 ( 2.425)	Loss 9.2440e-02 (2.0297e-01) 
2023-05-27 06:06:03.825392: val Epoch: [8][54/72]	Time  3.343 ( 2.548)	Data  3.235 ( 2.440)	Loss 2.0928e-01 (2.0308e-01) 
2023-05-27 06:06:05.503007: val Epoch: [8][55/72]	Time  1.678 ( 2.533)	Data  1.561 ( 2.424)	Loss 1.4034e-01 (2.0196e-01) 
2023-05-27 06:06:08.910637: val Epoch: [8][56/72]	Time  3.408 ( 2.548)	Data  3.302 ( 2.439)	Loss 1.1556e-01 (2.0045e-01) 
2023-05-27 06:06:10.815462: val Epoch: [8][57/72]	Time  1.905 ( 2.537)	Data  1.792 ( 2.428)	Loss 7.9715e-02 (1.9836e-01) 
2023-05-27 06:06:14.105555: val Epoch: [8][58/72]	Time  3.290 ( 2.550)	Data  3.180 ( 2.441)	Loss 1.3625e-01 (1.9731e-01) 
2023-05-27 06:06:15.911842: val Epoch: [8][59/72]	Time  1.806 ( 2.537)	Data  1.687 ( 2.428)	Loss 1.2396e-01 (1.9609e-01) 
2023-05-27 06:06:18.907302: val Epoch: [8][60/72]	Time  2.995 ( 2.545)	Data  2.882 ( 2.436)	Loss 9.8326e-02 (1.9449e-01) 
2023-05-27 06:06:20.690425: val Epoch: [8][61/72]	Time  1.783 ( 2.532)	Data  1.653 ( 2.423)	Loss 9.2763e-02 (1.9285e-01) 
2023-05-27 06:06:23.848729: val Epoch: [8][62/72]	Time  3.158 ( 2.542)	Data  3.053 ( 2.433)	Loss 1.2964e-01 (1.9184e-01) 
2023-05-27 06:06:25.964808: val Epoch: [8][63/72]	Time  2.116 ( 2.536)	Data  1.989 ( 2.426)	Loss 2.0694e-01 (1.9208e-01) 
2023-05-27 06:06:28.800252: val Epoch: [8][64/72]	Time  2.835 ( 2.540)	Data  2.730 ( 2.431)	Loss 3.8757e-01 (1.9509e-01) 
2023-05-27 06:06:30.689799: val Epoch: [8][65/72]	Time  1.890 ( 2.530)	Data  1.767 ( 2.421)	Loss 9.8956e-02 (1.9363e-01) 
2023-05-27 06:06:33.901119: val Epoch: [8][66/72]	Time  3.211 ( 2.541)	Data  3.104 ( 2.431)	Loss 7.1736e-02 (1.9181e-01) 
2023-05-27 06:06:35.872452: val Epoch: [8][67/72]	Time  1.971 ( 2.532)	Data  1.866 ( 2.423)	Loss 5.5514e-01 (1.9715e-01) 
2023-05-27 06:06:38.901325: val Epoch: [8][68/72]	Time  3.029 ( 2.539)	Data  2.922 ( 2.430)	Loss 2.6000e-01 (1.9806e-01) 
2023-05-27 06:06:41.183317: val Epoch: [8][69/72]	Time  2.282 ( 2.536)	Data  2.157 ( 2.426)	Loss 1.5561e-01 (1.9746e-01) 
2023-05-27 06:06:43.743500: val Epoch: [8][70/72]	Time  2.560 ( 2.536)	Data  2.455 ( 2.427)	Loss 1.8468e-01 (1.9728e-01) 
2023-05-27 06:06:45.614666: val Epoch: [8][71/72]	Time  1.871 ( 2.527)	Data  1.765 ( 2.417)	Loss 1.6503e-01 (1.9683e-01) 
2023-05-27 06:06:45.905901: Epoch 8 :Val : ['ET : 0.6571743488311768', 'TC : 0.6430927515029907', 'WT : 0.8020925521850586'] 
2023-05-27 06:06:45.906538: Epoch 8 :Val : ['ET : 0.6571743488311768', 'TC : 0.6430927515029907', 'WT : 0.8020925521850586'] 
2023-05-27 06:06:45.915195: Val epoch done in 183.05137291899882 s 
2023-05-27 06:06:45.930451: Batches per epoch:  193 
2023-05-27 06:06:57.073972: train Epoch: [9][  0/193]	Time 11.143 (11.143)	Data 10.559 (10.559)	Loss 1.3609e-01 (1.3609e-01) 
2023-05-27 06:06:57.638508: train Epoch: [9][  1/193]	Time  0.565 ( 5.854)	Data  0.001 ( 5.280)	Loss 1.5406e-01 (1.4507e-01) 
2023-05-27 06:07:06.834866: train Epoch: [9][  2/193]	Time  9.196 ( 6.968)	Data  8.623 ( 6.394)	Loss 3.1666e-01 (2.0227e-01) 
2023-05-27 06:07:07.398921: train Epoch: [9][  3/193]	Time  0.564 ( 5.367)	Data  0.001 ( 4.796)	Loss 1.5955e-01 (1.9159e-01) 
2023-05-27 06:07:16.901492: train Epoch: [9][  4/193]	Time  9.503 ( 6.194)	Data  8.940 ( 5.625)	Loss 1.5354e-01 (1.8398e-01) 
2023-05-27 06:07:17.473016: train Epoch: [9][  5/193]	Time  0.572 ( 5.257)	Data  0.001 ( 4.687)	Loss 1.7566e-01 (1.8259e-01) 
2023-05-27 06:07:26.919826: train Epoch: [9][  6/193]	Time  9.447 ( 5.856)	Data  8.884 ( 5.287)	Loss 1.6035e-01 (1.7941e-01) 
2023-05-27 06:07:27.483288: train Epoch: [9][  7/193]	Time  0.563 ( 5.194)	Data  0.001 ( 4.626)	Loss 1.3429e-01 (1.7377e-01) 
2023-05-27 06:07:36.821510: train Epoch: [9][  8/193]	Time  9.338 ( 5.655)	Data  8.765 ( 5.086)	Loss 9.3443e-02 (1.6485e-01) 
2023-05-27 06:07:37.389097: train Epoch: [9][  9/193]	Time  0.568 ( 5.146)	Data  0.001 ( 4.577)	Loss 1.3061e-01 (1.6143e-01) 
2023-05-27 06:07:46.675346: train Epoch: [9][ 10/193]	Time  9.286 ( 5.522)	Data  8.713 ( 4.953)	Loss 1.2523e-01 (1.5813e-01) 
2023-05-27 06:07:47.244255: train Epoch: [9][ 11/193]	Time  0.569 ( 5.109)	Data  0.001 ( 4.541)	Loss 1.1427e-01 (1.5448e-01) 
2023-05-27 06:07:56.678118: train Epoch: [9][ 12/193]	Time  9.434 ( 5.442)	Data  8.861 ( 4.873)	Loss 1.1927e-01 (1.5177e-01) 
2023-05-27 06:07:57.247678: train Epoch: [9][ 13/193]	Time  0.570 ( 5.094)	Data  0.001 ( 4.525)	Loss 1.3627e-01 (1.5066e-01) 
2023-05-27 06:08:06.368336: train Epoch: [9][ 14/193]	Time  9.121 ( 5.363)	Data  8.553 ( 4.793)	Loss 3.9859e-01 (1.6719e-01) 
2023-05-27 06:08:06.938024: train Epoch: [9][ 15/193]	Time  0.570 ( 5.063)	Data  0.001 ( 4.494)	Loss 1.0689e-01 (1.6342e-01) 
2023-05-27 06:08:16.667807: train Epoch: [9][ 16/193]	Time  9.730 ( 5.337)	Data  9.156 ( 4.768)	Loss 8.0650e-02 (1.5855e-01) 
2023-05-27 06:08:17.237229: train Epoch: [9][ 17/193]	Time  0.569 ( 5.073)	Data  0.001 ( 4.503)	Loss 2.5038e-01 (1.6366e-01) 
2023-05-27 06:08:26.378741: train Epoch: [9][ 18/193]	Time  9.142 ( 5.287)	Data  8.577 ( 4.718)	Loss 8.5295e-02 (1.5953e-01) 
2023-05-27 06:08:26.943579: train Epoch: [9][ 19/193]	Time  0.565 ( 5.051)	Data  0.001 ( 4.482)	Loss 1.1254e-01 (1.5718e-01) 
2023-05-27 06:08:36.178969: train Epoch: [9][ 20/193]	Time  9.235 ( 5.250)	Data  8.662 ( 4.681)	Loss 1.6363e-01 (1.5749e-01) 
2023-05-27 06:08:36.746127: train Epoch: [9][ 21/193]	Time  0.567 ( 5.037)	Data  0.001 ( 4.468)	Loss 2.4265e-01 (1.6136e-01) 
2023-05-27 06:08:45.984545: train Epoch: [9][ 22/193]	Time  9.238 ( 5.220)	Data  8.673 ( 4.651)	Loss 8.3498e-02 (1.5797e-01) 
2023-05-27 06:08:46.549678: train Epoch: [9][ 23/193]	Time  0.565 ( 5.026)	Data  0.001 ( 4.457)	Loss 1.2239e-01 (1.5649e-01) 
2023-05-27 06:08:55.853794: train Epoch: [9][ 24/193]	Time  9.304 ( 5.197)	Data  8.740 ( 4.629)	Loss 3.0305e-01 (1.6235e-01) 
2023-05-27 06:08:56.418084: train Epoch: [9][ 25/193]	Time  0.564 ( 5.019)	Data  0.001 ( 4.451)	Loss 8.1336e-02 (1.5924e-01) 
2023-05-27 06:09:05.344581: train Epoch: [9][ 26/193]	Time  8.926 ( 5.163)	Data  8.361 ( 4.595)	Loss 1.5196e-01 (1.5897e-01) 
2023-05-27 06:09:05.909040: train Epoch: [9][ 27/193]	Time  0.564 ( 4.999)	Data  0.001 ( 4.431)	Loss 1.6873e-01 (1.5932e-01) 
2023-05-27 06:09:14.711571: train Epoch: [9][ 28/193]	Time  8.803 ( 5.130)	Data  8.237 ( 4.563)	Loss 2.7456e-01 (1.6329e-01) 
2023-05-27 06:09:15.277202: train Epoch: [9][ 29/193]	Time  0.566 ( 4.978)	Data  0.001 ( 4.410)	Loss 1.4720e-01 (1.6276e-01) 
2023-05-27 06:09:23.521870: train Epoch: [9][ 30/193]	Time  8.245 ( 5.084)	Data  7.669 ( 4.516)	Loss 2.3447e-01 (1.6507e-01) 
2023-05-27 06:09:24.086822: train Epoch: [9][ 31/193]	Time  0.565 ( 4.942)	Data  0.001 ( 4.374)	Loss 1.8855e-01 (1.6580e-01) 
2023-05-27 06:09:32.944566: train Epoch: [9][ 32/193]	Time  8.858 ( 5.061)	Data  8.294 ( 4.493)	Loss 1.7916e-01 (1.6621e-01) 
2023-05-27 06:09:34.221145: train Epoch: [9][ 33/193]	Time  1.277 ( 4.950)	Data  0.714 ( 4.382)	Loss 1.1409e-01 (1.6467e-01) 
2023-05-27 06:09:43.084252: train Epoch: [9][ 34/193]	Time  8.863 ( 5.062)	Data  8.279 ( 4.493)	Loss 1.3731e-01 (1.6389e-01) 
2023-05-27 06:09:44.020812: train Epoch: [9][ 35/193]	Time  0.937 ( 4.947)	Data  0.357 ( 4.379)	Loss 9.3545e-02 (1.6194e-01) 
2023-05-27 06:09:52.878847: train Epoch: [9][ 36/193]	Time  8.858 ( 5.053)	Data  8.294 ( 4.484)	Loss 7.9666e-02 (1.5971e-01) 
2023-05-27 06:09:53.536825: train Epoch: [9][ 37/193]	Time  0.658 ( 4.937)	Data  0.094 ( 4.369)	Loss 1.5052e-01 (1.5947e-01) 
2023-05-27 06:10:03.244868: train Epoch: [9][ 38/193]	Time  9.708 ( 5.059)	Data  9.144 ( 4.491)	Loss 1.2196e-01 (1.5851e-01) 
2023-05-27 06:10:03.807526: train Epoch: [9][ 39/193]	Time  0.563 ( 4.947)	Data  0.001 ( 4.379)	Loss 1.6219e-01 (1.5860e-01) 
2023-05-27 06:10:13.354899: train Epoch: [9][ 40/193]	Time  9.547 ( 5.059)	Data  8.924 ( 4.490)	Loss 2.0037e-01 (1.5962e-01) 
2023-05-27 06:10:13.931646: train Epoch: [9][ 41/193]	Time  0.577 ( 4.952)	Data  0.001 ( 4.383)	Loss 1.4752e-01 (1.5933e-01) 
2023-05-27 06:10:22.981972: train Epoch: [9][ 42/193]	Time  9.050 ( 5.048)	Data  8.483 ( 4.478)	Loss 1.1440e-01 (1.5829e-01) 
2023-05-27 06:10:23.545310: train Epoch: [9][ 43/193]	Time  0.563 ( 4.946)	Data  0.001 ( 4.377)	Loss 1.5259e-01 (1.5816e-01) 
2023-05-27 06:10:32.966194: train Epoch: [9][ 44/193]	Time  9.421 ( 5.045)	Data  8.857 ( 4.476)	Loss 2.2924e-01 (1.5974e-01) 
2023-05-27 06:10:33.531364: train Epoch: [9][ 45/193]	Time  0.565 ( 4.948)	Data  0.001 ( 4.379)	Loss 1.1352e-01 (1.5873e-01) 
2023-05-27 06:10:42.997876: train Epoch: [9][ 46/193]	Time  9.467 ( 5.044)	Data  8.895 ( 4.475)	Loss 2.2033e-01 (1.6004e-01) 
2023-05-27 06:10:43.565347: train Epoch: [9][ 47/193]	Time  0.567 ( 4.951)	Data  0.001 ( 4.382)	Loss 1.2677e-01 (1.5935e-01) 
2023-05-27 06:10:52.552181: train Epoch: [9][ 48/193]	Time  8.987 ( 5.033)	Data  8.417 ( 4.464)	Loss 1.0370e-01 (1.5822e-01) 
2023-05-27 06:10:53.120737: train Epoch: [9][ 49/193]	Time  0.569 ( 4.944)	Data  0.001 ( 4.375)	Loss 1.6772e-01 (1.5841e-01) 
2023-05-27 06:11:03.027150: train Epoch: [9][ 50/193]	Time  9.906 ( 5.041)	Data  9.326 ( 4.472)	Loss 7.8774e-02 (1.5684e-01) 
2023-05-27 06:11:03.598752: train Epoch: [9][ 51/193]	Time  0.572 ( 4.955)	Data  0.001 ( 4.386)	Loss 1.4352e-01 (1.5659e-01) 
2023-05-27 06:11:12.544310: train Epoch: [9][ 52/193]	Time  8.946 ( 5.030)	Data  8.371 ( 4.461)	Loss 1.6690e-01 (1.5678e-01) 
2023-05-27 06:11:13.114752: train Epoch: [9][ 53/193]	Time  0.570 ( 4.948)	Data  0.001 ( 4.379)	Loss 1.5534e-01 (1.5676e-01) 
2023-05-27 06:11:22.320829: train Epoch: [9][ 54/193]	Time  9.206 ( 5.025)	Data  8.633 ( 4.456)	Loss 1.7020e-01 (1.5700e-01) 
2023-05-27 06:11:22.892846: train Epoch: [9][ 55/193]	Time  0.572 ( 4.946)	Data  0.001 ( 4.376)	Loss 2.0463e-01 (1.5785e-01) 
2023-05-27 06:11:32.095221: train Epoch: [9][ 56/193]	Time  9.202 ( 5.020)	Data  8.634 ( 4.451)	Loss 1.1921e-01 (1.5717e-01) 
2023-05-27 06:11:32.681911: train Epoch: [9][ 57/193]	Time  0.587 ( 4.944)	Data  0.001 ( 4.374)	Loss 1.2844e-01 (1.5668e-01) 
2023-05-27 06:11:40.510429: train Epoch: [9][ 58/193]	Time  7.828 ( 4.993)	Data  7.243 ( 4.423)	Loss 2.5264e-01 (1.5830e-01) 
2023-05-27 06:11:41.082648: train Epoch: [9][ 59/193]	Time  0.572 ( 4.919)	Data  0.001 ( 4.349)	Loss 2.2129e-01 (1.5935e-01) 
2023-05-27 06:11:49.536702: train Epoch: [9][ 60/193]	Time  8.454 ( 4.977)	Data  7.871 ( 4.407)	Loss 8.3382e-02 (1.5811e-01) 
2023-05-27 06:11:50.115804: train Epoch: [9][ 61/193]	Time  0.579 ( 4.906)	Data  0.001 ( 4.336)	Loss 1.4832e-01 (1.5795e-01) 
2023-05-27 06:11:59.272563: train Epoch: [9][ 62/193]	Time  9.157 ( 4.974)	Data  8.593 ( 4.403)	Loss 1.1643e-01 (1.5729e-01) 
2023-05-27 06:12:00.041150: train Epoch: [9][ 63/193]	Time  0.769 ( 4.908)	Data  0.190 ( 4.338)	Loss 1.6613e-01 (1.5743e-01) 
2023-05-27 06:12:09.147539: train Epoch: [9][ 64/193]	Time  9.106 ( 4.973)	Data  8.529 ( 4.402)	Loss 2.4450e-01 (1.5877e-01) 
2023-05-27 06:12:09.882552: train Epoch: [9][ 65/193]	Time  0.735 ( 4.908)	Data  0.167 ( 4.338)	Loss 1.3026e-01 (1.5834e-01) 
2023-05-27 06:12:19.126994: train Epoch: [9][ 66/193]	Time  9.244 ( 4.973)	Data  8.675 ( 4.403)	Loss 1.2748e-01 (1.5788e-01) 
2023-05-27 06:12:19.690717: train Epoch: [9][ 67/193]	Time  0.564 ( 4.908)	Data  0.001 ( 4.338)	Loss 2.2084e-01 (1.5880e-01) 
2023-05-27 06:12:29.117401: train Epoch: [9][ 68/193]	Time  9.427 ( 4.974)	Data  8.863 ( 4.404)	Loss 1.3258e-01 (1.5842e-01) 
2023-05-27 06:12:29.680996: train Epoch: [9][ 69/193]	Time  0.564 ( 4.911)	Data  0.001 ( 4.341)	Loss 1.5060e-01 (1.5831e-01) 
2023-05-27 06:12:39.341630: train Epoch: [9][ 70/193]	Time  9.661 ( 4.978)	Data  9.065 ( 4.407)	Loss 2.7480e-01 (1.5995e-01) 
2023-05-27 06:12:39.908472: train Epoch: [9][ 71/193]	Time  0.567 ( 4.916)	Data  0.001 ( 4.346)	Loss 2.4254e-01 (1.6110e-01) 
2023-05-27 06:12:49.152184: train Epoch: [9][ 72/193]	Time  9.244 ( 4.976)	Data  8.681 ( 4.405)	Loss 1.3062e-01 (1.6068e-01) 
2023-05-27 06:12:49.715560: train Epoch: [9][ 73/193]	Time  0.563 ( 4.916)	Data  0.001 ( 4.346)	Loss 1.8076e-01 (1.6095e-01) 
2023-05-27 06:12:58.781273: train Epoch: [9][ 74/193]	Time  9.066 ( 4.971)	Data  8.502 ( 4.401)	Loss 1.1803e-01 (1.6038e-01) 
2023-05-27 06:12:59.345274: train Epoch: [9][ 75/193]	Time  0.564 ( 4.913)	Data  0.001 ( 4.343)	Loss 2.1179e-01 (1.6106e-01) 
2023-05-27 06:13:08.765281: train Epoch: [9][ 76/193]	Time  9.420 ( 4.972)	Data  8.840 ( 4.402)	Loss 1.1941e-01 (1.6052e-01) 
2023-05-27 06:13:09.329059: train Epoch: [9][ 77/193]	Time  0.564 ( 4.915)	Data  0.001 ( 4.345)	Loss 1.5149e-01 (1.6040e-01) 
2023-05-27 06:13:18.707927: train Epoch: [9][ 78/193]	Time  9.379 ( 4.972)	Data  8.804 ( 4.402)	Loss 1.9146e-01 (1.6079e-01) 
2023-05-27 06:13:19.274194: train Epoch: [9][ 79/193]	Time  0.566 ( 4.917)	Data  0.001 ( 4.347)	Loss 9.9019e-02 (1.6002e-01) 
2023-05-27 06:13:28.394127: train Epoch: [9][ 80/193]	Time  9.120 ( 4.969)	Data  8.556 ( 4.399)	Loss 1.3425e-01 (1.5970e-01) 
2023-05-27 06:13:29.119977: train Epoch: [9][ 81/193]	Time  0.726 ( 4.917)	Data  0.163 ( 4.347)	Loss 1.9527e-01 (1.6014e-01) 
2023-05-27 06:13:38.755419: train Epoch: [9][ 82/193]	Time  9.635 ( 4.974)	Data  9.071 ( 4.404)	Loss 2.1841e-01 (1.6084e-01) 
2023-05-27 06:13:39.319062: train Epoch: [9][ 83/193]	Time  0.564 ( 4.921)	Data  0.001 ( 4.352)	Loss 7.4163e-02 (1.5981e-01) 
2023-05-27 06:13:48.668621: train Epoch: [9][ 84/193]	Time  9.350 ( 4.973)	Data  8.786 ( 4.404)	Loss 2.0989e-01 (1.6040e-01) 
2023-05-27 06:13:49.443003: train Epoch: [9][ 85/193]	Time  0.774 ( 4.925)	Data  0.211 ( 4.355)	Loss 1.5886e-01 (1.6038e-01) 
2023-05-27 06:13:59.047623: train Epoch: [9][ 86/193]	Time  9.605 ( 4.978)	Data  9.041 ( 4.409)	Loss 1.3433e-01 (1.6008e-01) 
2023-05-27 06:13:59.616304: train Epoch: [9][ 87/193]	Time  0.569 ( 4.928)	Data  0.001 ( 4.359)	Loss 7.6965e-02 (1.5913e-01) 
2023-05-27 06:14:08.725490: train Epoch: [9][ 88/193]	Time  9.109 ( 4.975)	Data  8.534 ( 4.406)	Loss 1.6491e-01 (1.5920e-01) 
2023-05-27 06:14:09.299146: train Epoch: [9][ 89/193]	Time  0.574 ( 4.926)	Data  0.001 ( 4.357)	Loss 1.0952e-01 (1.5865e-01) 
2023-05-27 06:14:18.910917: train Epoch: [9][ 90/193]	Time  9.612 ( 4.978)	Data  9.040 ( 4.408)	Loss 1.7579e-01 (1.5884e-01) 
2023-05-27 06:14:19.482962: train Epoch: [9][ 91/193]	Time  0.572 ( 4.930)	Data  0.001 ( 4.360)	Loss 1.1025e-01 (1.5831e-01) 
2023-05-27 06:14:28.815281: train Epoch: [9][ 92/193]	Time  9.332 ( 4.977)	Data  8.761 ( 4.408)	Loss 1.6467e-01 (1.5838e-01) 
2023-05-27 06:14:29.680382: train Epoch: [9][ 93/193]	Time  0.865 ( 4.934)	Data  0.292 ( 4.364)	Loss 1.2503e-01 (1.5802e-01) 
2023-05-27 06:14:37.222219: train Epoch: [9][ 94/193]	Time  7.542 ( 4.961)	Data  6.973 ( 4.391)	Loss 7.8406e-02 (1.5718e-01) 
2023-05-27 06:14:38.467987: train Epoch: [9][ 95/193]	Time  1.246 ( 4.922)	Data  0.641 ( 4.352)	Loss 1.1748e-01 (1.5677e-01) 
2023-05-27 06:14:45.509268: train Epoch: [9][ 96/193]	Time  7.041 ( 4.944)	Data  6.478 ( 4.374)	Loss 1.0449e-01 (1.5623e-01) 
2023-05-27 06:14:46.611360: train Epoch: [9][ 97/193]	Time  1.102 ( 4.905)	Data  0.531 ( 4.335)	Loss 2.0151e-01 (1.5669e-01) 
2023-05-27 06:14:54.712815: train Epoch: [9][ 98/193]	Time  8.101 ( 4.937)	Data  7.530 ( 4.367)	Loss 1.1044e-01 (1.5623e-01) 
2023-05-27 06:14:55.918940: train Epoch: [9][ 99/193]	Time  1.206 ( 4.900)	Data  0.637 ( 4.330)	Loss 1.9748e-01 (1.5664e-01) 
2023-05-27 06:15:04.878521: train Epoch: [9][100/193]	Time  8.960 ( 4.940)	Data  8.386 ( 4.370)	Loss 1.9023e-01 (1.5697e-01) 
2023-05-27 06:15:06.182202: train Epoch: [9][101/193]	Time  1.304 ( 4.904)	Data  0.707 ( 4.334)	Loss 1.4003e-01 (1.5680e-01) 
2023-05-27 06:15:14.923094: train Epoch: [9][102/193]	Time  8.741 ( 4.942)	Data  8.169 ( 4.371)	Loss 1.1117e-01 (1.5636e-01) 
2023-05-27 06:15:16.344277: train Epoch: [9][103/193]	Time  1.421 ( 4.908)	Data  0.845 ( 4.337)	Loss 9.3754e-02 (1.5576e-01) 
2023-05-27 06:15:24.883670: train Epoch: [9][104/193]	Time  8.539 ( 4.942)	Data  7.968 ( 4.372)	Loss 1.4872e-01 (1.5569e-01) 
2023-05-27 06:15:26.315087: train Epoch: [9][105/193]	Time  1.431 ( 4.909)	Data  0.852 ( 4.339)	Loss 1.1232e-01 (1.5528e-01) 
2023-05-27 06:15:35.103992: train Epoch: [9][106/193]	Time  8.789 ( 4.946)	Data  8.222 ( 4.375)	Loss 1.9042e-01 (1.5561e-01) 
2023-05-27 06:15:36.620601: train Epoch: [9][107/193]	Time  1.517 ( 4.914)	Data  0.944 ( 4.343)	Loss 1.6369e-01 (1.5569e-01) 
2023-05-27 06:15:45.261035: train Epoch: [9][108/193]	Time  8.640 ( 4.948)	Data  8.063 ( 4.377)	Loss 1.3105e-01 (1.5546e-01) 
2023-05-27 06:15:46.687879: train Epoch: [9][109/193]	Time  1.427 ( 4.916)	Data  0.843 ( 4.345)	Loss 1.1160e-01 (1.5506e-01) 
2023-05-27 06:15:55.685328: train Epoch: [9][110/193]	Time  8.997 ( 4.953)	Data  8.413 ( 4.382)	Loss 1.8064e-01 (1.5529e-01) 
2023-05-27 06:15:56.932468: train Epoch: [9][111/193]	Time  1.247 ( 4.920)	Data  0.601 ( 4.348)	Loss 1.6429e-01 (1.5537e-01) 
2023-05-27 06:16:05.801325: train Epoch: [9][112/193]	Time  8.869 ( 4.955)	Data  8.279 ( 4.383)	Loss 1.2780e-01 (1.5513e-01) 
2023-05-27 06:16:06.961036: train Epoch: [9][113/193]	Time  1.160 ( 4.921)	Data  0.593 ( 4.350)	Loss 8.8277e-02 (1.5454e-01) 
2023-05-27 06:16:15.457225: train Epoch: [9][114/193]	Time  8.496 ( 4.952)	Data  7.931 ( 4.381)	Loss 6.9408e-02 (1.5380e-01) 
2023-05-27 06:16:16.915436: train Epoch: [9][115/193]	Time  1.458 ( 4.922)	Data  0.866 ( 4.351)	Loss 1.0983e-01 (1.5342e-01) 
2023-05-27 06:16:25.659360: train Epoch: [9][116/193]	Time  8.744 ( 4.955)	Data  8.106 ( 4.383)	Loss 1.0120e-01 (1.5298e-01) 
2023-05-27 06:16:26.925921: train Epoch: [9][117/193]	Time  1.267 ( 4.924)	Data  0.695 ( 4.351)	Loss 1.4034e-01 (1.5287e-01) 
2023-05-27 06:16:35.354280: train Epoch: [9][118/193]	Time  8.428 ( 4.953)	Data  7.838 ( 4.381)	Loss 1.3146e-01 (1.5269e-01) 
2023-05-27 06:16:36.923209: train Epoch: [9][119/193]	Time  1.569 ( 4.925)	Data  0.999 ( 4.353)	Loss 1.0304e-01 (1.5228e-01) 
2023-05-27 06:16:45.585332: train Epoch: [9][120/193]	Time  8.662 ( 4.956)	Data  8.092 ( 4.383)	Loss 9.8442e-02 (1.5183e-01) 
2023-05-27 06:16:47.094970: train Epoch: [9][121/193]	Time  1.510 ( 4.928)	Data  0.939 ( 4.355)	Loss 1.6124e-01 (1.5191e-01) 
2023-05-27 06:16:55.713202: train Epoch: [9][122/193]	Time  8.618 ( 4.958)	Data  8.036 ( 4.385)	Loss 1.4180e-01 (1.5183e-01) 
2023-05-27 06:16:57.096905: train Epoch: [9][123/193]	Time  1.384 ( 4.929)	Data  0.815 ( 4.356)	Loss 1.8220e-01 (1.5207e-01) 
2023-05-27 06:17:05.825906: train Epoch: [9][124/193]	Time  8.729 ( 4.959)	Data  8.158 ( 4.387)	Loss 1.3365e-01 (1.5192e-01) 
2023-05-27 06:17:07.143501: train Epoch: [9][125/193]	Time  1.318 ( 4.930)	Data  0.750 ( 4.358)	Loss 1.1360e-01 (1.5162e-01) 
2023-05-27 06:17:16.011536: train Epoch: [9][126/193]	Time  8.868 ( 4.961)	Data  8.198 ( 4.388)	Loss 9.2161e-02 (1.5115e-01) 
2023-05-27 06:17:17.096667: train Epoch: [9][127/193]	Time  1.085 ( 4.931)	Data  0.520 ( 4.358)	Loss 8.2469e-02 (1.5061e-01) 
2023-05-27 06:17:26.056293: train Epoch: [9][128/193]	Time  8.960 ( 4.962)	Data  8.341 ( 4.389)	Loss 1.1486e-01 (1.5034e-01) 
2023-05-27 06:17:27.195731: train Epoch: [9][129/193]	Time  1.139 ( 4.933)	Data  0.563 ( 4.359)	Loss 1.2326e-01 (1.5013e-01) 
2023-05-27 06:17:35.681103: train Epoch: [9][130/193]	Time  8.485 ( 4.960)	Data  7.920 ( 4.387)	Loss 1.5834e-01 (1.5019e-01) 
2023-05-27 06:17:37.098932: train Epoch: [9][131/193]	Time  1.418 ( 4.933)	Data  0.855 ( 4.360)	Loss 1.1630e-01 (1.4993e-01) 
2023-05-27 06:17:45.932594: train Epoch: [9][132/193]	Time  8.834 ( 4.962)	Data  8.255 ( 4.389)	Loss 1.1776e-01 (1.4969e-01) 
2023-05-27 06:17:47.150412: train Epoch: [9][133/193]	Time  1.218 ( 4.934)	Data  0.654 ( 4.361)	Loss 1.2582e-01 (1.4951e-01) 
2023-05-27 06:17:55.314772: train Epoch: [9][134/193]	Time  8.164 ( 4.958)	Data  7.585 ( 4.385)	Loss 9.6075e-02 (1.4912e-01) 
2023-05-27 06:17:56.846113: train Epoch: [9][135/193]	Time  1.531 ( 4.933)	Data  0.968 ( 4.360)	Loss 8.6694e-02 (1.4866e-01) 
2023-05-27 06:18:05.211103: train Epoch: [9][136/193]	Time  8.365 ( 4.958)	Data  7.776 ( 4.385)	Loss 8.5284e-02 (1.4820e-01) 
2023-05-27 06:18:06.740310: train Epoch: [9][137/193]	Time  1.529 ( 4.933)	Data  0.958 ( 4.360)	Loss 1.5063e-01 (1.4821e-01) 
2023-05-27 06:18:14.733828: train Epoch: [9][138/193]	Time  7.994 ( 4.955)	Data  7.429 ( 4.382)	Loss 8.9871e-02 (1.4780e-01) 
2023-05-27 06:18:16.621182: train Epoch: [9][139/193]	Time  1.887 ( 4.933)	Data  1.319 ( 4.360)	Loss 1.5908e-01 (1.4788e-01) 
2023-05-27 06:18:24.939331: train Epoch: [9][140/193]	Time  8.318 ( 4.958)	Data  7.732 ( 4.384)	Loss 2.8498e-01 (1.4885e-01) 
2023-05-27 06:18:26.697963: train Epoch: [9][141/193]	Time  1.759 ( 4.935)	Data  1.190 ( 4.362)	Loss 2.0851e-01 (1.4927e-01) 
2023-05-27 06:18:35.127591: train Epoch: [9][142/193]	Time  8.430 ( 4.959)	Data  7.853 ( 4.386)	Loss 1.3668e-01 (1.4918e-01) 
2023-05-27 06:18:37.102537: train Epoch: [9][143/193]	Time  1.975 ( 4.939)	Data  1.406 ( 4.365)	Loss 1.8985e-01 (1.4946e-01) 
2023-05-27 06:18:44.578991: train Epoch: [9][144/193]	Time  7.476 ( 4.956)	Data  6.904 ( 4.383)	Loss 1.5869e-01 (1.4953e-01) 
2023-05-27 06:18:47.107635: train Epoch: [9][145/193]	Time  2.529 ( 4.940)	Data  1.960 ( 4.366)	Loss 1.6813e-01 (1.4965e-01) 
2023-05-27 06:18:54.395993: train Epoch: [9][146/193]	Time  7.288 ( 4.956)	Data  6.707 ( 4.382)	Loss 8.7181e-02 (1.4923e-01) 
2023-05-27 06:18:57.015987: train Epoch: [9][147/193]	Time  2.620 ( 4.940)	Data  2.056 ( 4.367)	Loss 1.1061e-01 (1.4897e-01) 
2023-05-27 06:19:04.096966: train Epoch: [9][148/193]	Time  7.081 ( 4.954)	Data  6.515 ( 4.381)	Loss 1.4351e-01 (1.4893e-01) 
2023-05-27 06:19:07.070887: train Epoch: [9][149/193]	Time  2.974 ( 4.941)	Data  2.401 ( 4.368)	Loss 1.0150e-01 (1.4861e-01) 
2023-05-27 06:19:13.735290: train Epoch: [9][150/193]	Time  6.664 ( 4.952)	Data  6.100 ( 4.379)	Loss 1.5106e-01 (1.4863e-01) 
2023-05-27 06:19:17.145174: train Epoch: [9][151/193]	Time  3.410 ( 4.942)	Data  2.844 ( 4.369)	Loss 1.4627e-01 (1.4862e-01) 
2023-05-27 06:19:23.586759: train Epoch: [9][152/193]	Time  6.442 ( 4.952)	Data  5.876 ( 4.379)	Loss 7.3209e-02 (1.4812e-01) 
2023-05-27 06:19:27.369370: train Epoch: [9][153/193]	Time  3.783 ( 4.944)	Data  3.209 ( 4.371)	Loss 1.0446e-01 (1.4784e-01) 
2023-05-27 06:19:33.510070: train Epoch: [9][154/193]	Time  6.141 ( 4.952)	Data  5.576 ( 4.379)	Loss 1.2112e-01 (1.4767e-01) 
2023-05-27 06:19:37.185511: train Epoch: [9][155/193]	Time  3.675 ( 4.944)	Data  3.079 ( 4.371)	Loss 2.2483e-01 (1.4816e-01) 
2023-05-27 06:19:43.435805: train Epoch: [9][156/193]	Time  6.250 ( 4.952)	Data  5.684 ( 4.379)	Loss 2.8950e-01 (1.4906e-01) 
2023-05-27 06:19:47.004847: train Epoch: [9][157/193]	Time  3.569 ( 4.944)	Data  2.996 ( 4.370)	Loss 1.0735e-01 (1.4880e-01) 
2023-05-27 06:19:53.430931: train Epoch: [9][158/193]	Time  6.426 ( 4.953)	Data  5.860 ( 4.380)	Loss 2.2502e-01 (1.4928e-01) 
2023-05-27 06:19:57.170239: train Epoch: [9][159/193]	Time  3.739 ( 4.945)	Data  3.174 ( 4.372)	Loss 1.7806e-01 (1.4946e-01) 
2023-05-27 06:20:03.306235: train Epoch: [9][160/193]	Time  6.136 ( 4.953)	Data  5.571 ( 4.380)	Loss 1.4372e-01 (1.4942e-01) 
2023-05-27 06:20:07.314410: train Epoch: [9][161/193]	Time  4.008 ( 4.947)	Data  3.427 ( 4.374)	Loss 1.9543e-01 (1.4971e-01) 
2023-05-27 06:20:12.895746: train Epoch: [9][162/193]	Time  5.581 ( 4.951)	Data  5.018 ( 4.378)	Loss 1.2919e-01 (1.4958e-01) 
2023-05-27 06:20:17.041251: train Epoch: [9][163/193]	Time  4.146 ( 4.946)	Data  3.572 ( 4.373)	Loss 1.7044e-01 (1.4971e-01) 
2023-05-27 06:20:22.860029: train Epoch: [9][164/193]	Time  5.819 ( 4.951)	Data  5.257 ( 4.378)	Loss 1.3663e-01 (1.4963e-01) 
2023-05-27 06:20:26.546522: train Epoch: [9][165/193]	Time  3.686 ( 4.943)	Data  3.114 ( 4.371)	Loss 2.3945e-01 (1.5017e-01) 
2023-05-27 06:20:32.744408: train Epoch: [9][166/193]	Time  6.198 ( 4.951)	Data  5.634 ( 4.378)	Loss 1.3269e-01 (1.5006e-01) 
2023-05-27 06:20:36.719227: train Epoch: [9][167/193]	Time  3.975 ( 4.945)	Data  3.353 ( 4.372)	Loss 1.7042e-01 (1.5019e-01) 
2023-05-27 06:20:42.701843: train Epoch: [9][168/193]	Time  5.983 ( 4.951)	Data  5.417 ( 4.378)	Loss 3.7203e-01 (1.5150e-01) 
2023-05-27 06:20:46.068803: train Epoch: [9][169/193]	Time  3.367 ( 4.942)	Data  2.802 ( 4.369)	Loss 9.5987e-02 (1.5117e-01) 
2023-05-27 06:20:52.750604: train Epoch: [9][170/193]	Time  6.682 ( 4.952)	Data  6.110 ( 4.379)	Loss 2.2404e-01 (1.5160e-01) 
2023-05-27 06:20:55.462622: train Epoch: [9][171/193]	Time  2.712 ( 4.939)	Data  2.133 ( 4.366)	Loss 1.5392e-01 (1.5161e-01) 
2023-05-27 06:21:02.573940: train Epoch: [9][172/193]	Time  7.111 ( 4.952)	Data  6.546 ( 4.379)	Loss 1.8066e-01 (1.5178e-01) 
2023-05-27 06:21:05.398571: train Epoch: [9][173/193]	Time  2.825 ( 4.939)	Data  2.253 ( 4.366)	Loss 1.2134e-01 (1.5160e-01) 
2023-05-27 06:21:12.512395: train Epoch: [9][174/193]	Time  7.114 ( 4.952)	Data  6.538 ( 4.379)	Loss 2.5572e-01 (1.5220e-01) 
2023-05-27 06:21:15.599566: train Epoch: [9][175/193]	Time  3.087 ( 4.941)	Data  2.523 ( 4.368)	Loss 9.8305e-02 (1.5189e-01) 
2023-05-27 06:21:22.468331: train Epoch: [9][176/193]	Time  6.869 ( 4.952)	Data  6.305 ( 4.379)	Loss 1.0071e-01 (1.5160e-01) 
2023-05-27 06:21:25.902403: train Epoch: [9][177/193]	Time  3.434 ( 4.944)	Data  2.862 ( 4.371)	Loss 1.0477e-01 (1.5134e-01) 
2023-05-27 06:21:31.888340: train Epoch: [9][178/193]	Time  5.986 ( 4.949)	Data  5.423 ( 4.377)	Loss 7.4853e-02 (1.5091e-01) 
2023-05-27 06:21:35.919203: train Epoch: [9][179/193]	Time  4.031 ( 4.944)	Data  3.453 ( 4.372)	Loss 1.2396e-01 (1.5076e-01) 
2023-05-27 06:21:41.638999: train Epoch: [9][180/193]	Time  5.720 ( 4.949)	Data  5.154 ( 4.376)	Loss 1.4070e-01 (1.5071e-01) 
2023-05-27 06:21:45.915225: train Epoch: [9][181/193]	Time  4.276 ( 4.945)	Data  3.709 ( 4.372)	Loss 9.8074e-02 (1.5042e-01) 
2023-05-27 06:21:51.954884: train Epoch: [9][182/193]	Time  6.040 ( 4.951)	Data  5.470 ( 4.378)	Loss 2.5370e-01 (1.5098e-01) 
2023-05-27 06:21:55.904250: train Epoch: [9][183/193]	Time  3.949 ( 4.946)	Data  3.386 ( 4.373)	Loss 2.2523e-01 (1.5139e-01) 
2023-05-27 06:22:02.021835: train Epoch: [9][184/193]	Time  6.118 ( 4.952)	Data  5.546 ( 4.379)	Loss 2.5723e-01 (1.5196e-01) 
2023-05-27 06:22:05.755220: train Epoch: [9][185/193]	Time  3.733 ( 4.945)	Data  3.133 ( 4.372)	Loss 1.2849e-01 (1.5183e-01) 
2023-05-27 06:22:11.977784: train Epoch: [9][186/193]	Time  6.223 ( 4.952)	Data  5.657 ( 4.379)	Loss 1.2861e-01 (1.5171e-01) 
2023-05-27 06:22:15.653556: train Epoch: [9][187/193]	Time  3.676 ( 4.945)	Data  3.112 ( 4.373)	Loss 1.0570e-01 (1.5146e-01) 
2023-05-27 06:22:21.368373: train Epoch: [9][188/193]	Time  5.715 ( 4.949)	Data  5.150 ( 4.377)	Loss 1.3351e-01 (1.5137e-01) 
2023-05-27 06:22:25.352679: train Epoch: [9][189/193]	Time  3.984 ( 4.944)	Data  3.421 ( 4.372)	Loss 9.1859e-02 (1.5106e-01) 
2023-05-27 06:22:31.573831: train Epoch: [9][190/193]	Time  6.221 ( 4.951)	Data  5.660 ( 4.378)	Loss 8.1182e-02 (1.5069e-01) 
2023-05-27 06:22:35.164789: train Epoch: [9][191/193]	Time  3.591 ( 4.944)	Data  3.020 ( 4.371)	Loss 1.9845e-01 (1.5094e-01) 
2023-05-27 06:22:40.652990: train Epoch: [9][192/193]	Time  5.488 ( 4.947)	Data  4.925 ( 4.374)	Loss 1.4434e-01 (1.5090e-01) 
2023-05-27 06:22:40.785329: Train Epoch done in 954.8549100650125 s 
2023-05-27 06:22:47.737436: val Epoch: [9][ 0/72]	Time  5.734 ( 5.734)	Data  5.570 ( 5.570)	Loss 6.4582e-01 (6.4582e-01) 
2023-05-27 06:22:47.851380: val Epoch: [9][ 1/72]	Time  0.114 ( 2.924)	Data  0.002 ( 2.786)	Loss 3.7223e-01 (5.0902e-01) 
2023-05-27 06:22:52.666342: val Epoch: [9][ 2/72]	Time  4.815 ( 3.554)	Data  4.691 ( 3.421)	Loss 7.5651e-02 (3.6457e-01) 
2023-05-27 06:22:52.779834: val Epoch: [9][ 3/72]	Time  0.113 ( 2.694)	Data  0.001 ( 2.566)	Loss 1.3048e-01 (3.0605e-01) 
2023-05-27 06:22:57.547139: val Epoch: [9][ 4/72]	Time  4.767 ( 3.109)	Data  4.644 ( 2.982)	Loss 2.1809e-01 (2.8846e-01) 
2023-05-27 06:22:57.659950: val Epoch: [9][ 5/72]	Time  0.113 ( 2.609)	Data  0.001 ( 2.485)	Loss 1.1400e-01 (2.5938e-01) 
2023-05-27 06:23:02.570187: val Epoch: [9][ 6/72]	Time  4.910 ( 2.938)	Data  4.795 ( 2.815)	Loss 1.5352e-01 (2.4426e-01) 
2023-05-27 06:23:02.680545: val Epoch: [9][ 7/72]	Time  0.110 ( 2.585)	Data  0.000 ( 2.463)	Loss 2.9228e-01 (2.5026e-01) 
2023-05-27 06:23:07.671739: val Epoch: [9][ 8/72]	Time  4.991 ( 2.852)	Data  4.884 ( 2.732)	Loss 5.0370e-01 (2.7842e-01) 
2023-05-27 06:23:07.779560: val Epoch: [9][ 9/72]	Time  0.108 ( 2.578)	Data  0.000 ( 2.459)	Loss 1.1755e-01 (2.6233e-01) 
2023-05-27 06:23:12.579989: val Epoch: [9][10/72]	Time  4.800 ( 2.780)	Data  4.690 ( 2.662)	Loss 2.0547e-01 (2.5716e-01) 
2023-05-27 06:23:12.690543: val Epoch: [9][11/72]	Time  0.111 ( 2.557)	Data  0.001 ( 2.440)	Loss 5.9041e-01 (2.8493e-01) 
2023-05-27 06:23:17.727445: val Epoch: [9][12/72]	Time  5.037 ( 2.748)	Data  4.927 ( 2.631)	Loss 3.8430e-01 (2.9258e-01) 
2023-05-27 06:23:17.944368: val Epoch: [9][13/72]	Time  0.217 ( 2.567)	Data  0.104 ( 2.451)	Loss 1.3724e-01 (2.8148e-01) 
2023-05-27 06:23:22.707085: val Epoch: [9][14/72]	Time  4.763 ( 2.714)	Data  4.650 ( 2.597)	Loss 1.7469e-01 (2.7436e-01) 
2023-05-27 06:23:22.946101: val Epoch: [9][15/72]	Time  0.239 ( 2.559)	Data  0.128 ( 2.443)	Loss 6.5475e-02 (2.6131e-01) 
2023-05-27 06:23:27.844081: val Epoch: [9][16/72]	Time  4.898 ( 2.696)	Data  4.772 ( 2.580)	Loss 2.3983e-01 (2.6004e-01) 
2023-05-27 06:23:27.955152: val Epoch: [9][17/72]	Time  0.111 ( 2.553)	Data  0.001 ( 2.437)	Loss 2.0271e-01 (2.5686e-01) 
2023-05-27 06:23:32.987547: val Epoch: [9][18/72]	Time  5.032 ( 2.683)	Data  4.877 ( 2.565)	Loss 1.4767e-01 (2.5111e-01) 
2023-05-27 06:23:33.099914: val Epoch: [9][19/72]	Time  0.112 ( 2.555)	Data  0.001 ( 2.437)	Loss 1.9936e-01 (2.4852e-01) 
2023-05-27 06:23:38.164886: val Epoch: [9][20/72]	Time  5.065 ( 2.674)	Data  4.945 ( 2.556)	Loss 8.0885e-02 (2.4054e-01) 
2023-05-27 06:23:38.272999: val Epoch: [9][21/72]	Time  0.108 ( 2.558)	Data  0.001 ( 2.440)	Loss 4.5294e-01 (2.5020e-01) 
2023-05-27 06:23:43.078332: val Epoch: [9][22/72]	Time  4.805 ( 2.655)	Data  4.680 ( 2.538)	Loss 1.3182e-01 (2.4505e-01) 
2023-05-27 06:23:43.204833: val Epoch: [9][23/72]	Time  0.127 ( 2.550)	Data  0.001 ( 2.432)	Loss 2.4384e-01 (2.4500e-01) 
2023-05-27 06:23:47.879546: val Epoch: [9][24/72]	Time  4.675 ( 2.635)	Data  4.550 ( 2.517)	Loss 7.7816e-02 (2.3831e-01) 
2023-05-27 06:23:48.339026: val Epoch: [9][25/72]	Time  0.459 ( 2.551)	Data  0.345 ( 2.433)	Loss 1.2580e-01 (2.3398e-01) 
2023-05-27 06:23:52.693816: val Epoch: [9][26/72]	Time  4.355 ( 2.618)	Data  4.242 ( 2.500)	Loss 2.7093e-01 (2.3535e-01) 
2023-05-27 06:23:53.375023: val Epoch: [9][27/72]	Time  0.681 ( 2.549)	Data  0.558 ( 2.431)	Loss 8.2073e-02 (2.2988e-01) 
2023-05-27 06:23:57.796908: val Epoch: [9][28/72]	Time  4.422 ( 2.614)	Data  4.313 ( 2.496)	Loss 3.4963e-01 (2.3401e-01) 
2023-05-27 06:23:58.427087: val Epoch: [9][29/72]	Time  0.630 ( 2.547)	Data  0.522 ( 2.430)	Loss 1.3543e-01 (2.3072e-01) 
2023-05-27 06:24:02.516256: val Epoch: [9][30/72]	Time  4.089 ( 2.597)	Data  3.978 ( 2.480)	Loss 1.0011e-01 (2.2651e-01) 
2023-05-27 06:24:03.372347: val Epoch: [9][31/72]	Time  0.856 ( 2.543)	Data  0.716 ( 2.425)	Loss 1.2287e-01 (2.2327e-01) 
2023-05-27 06:24:07.547050: val Epoch: [9][32/72]	Time  4.175 ( 2.592)	Data  4.065 ( 2.474)	Loss 2.5224e-01 (2.2415e-01) 
2023-05-27 06:24:08.125303: val Epoch: [9][33/72]	Time  0.578 ( 2.533)	Data  0.466 ( 2.415)	Loss 1.0414e-01 (2.2062e-01) 
2023-05-27 06:24:12.448705: val Epoch: [9][34/72]	Time  4.323 ( 2.584)	Data  4.204 ( 2.466)	Loss 7.9105e-02 (2.1657e-01) 
2023-05-27 06:24:13.113099: val Epoch: [9][35/72]	Time  0.664 ( 2.531)	Data  0.535 ( 2.413)	Loss 9.4575e-02 (2.1319e-01) 
2023-05-27 06:24:17.807658: val Epoch: [9][36/72]	Time  4.695 ( 2.589)	Data  4.570 ( 2.471)	Loss 9.5808e-02 (2.1001e-01) 
2023-05-27 06:24:18.354909: val Epoch: [9][37/72]	Time  0.547 ( 2.536)	Data  0.426 ( 2.417)	Loss 2.8475e-01 (2.1198e-01) 
2023-05-27 06:24:22.841662: val Epoch: [9][38/72]	Time  4.487 ( 2.586)	Data  4.370 ( 2.467)	Loss 1.1842e-01 (2.0958e-01) 
2023-05-27 06:24:23.387324: val Epoch: [9][39/72]	Time  0.546 ( 2.535)	Data  0.432 ( 2.416)	Loss 2.0659e-01 (2.0951e-01) 
2023-05-27 06:24:28.253144: val Epoch: [9][40/72]	Time  4.866 ( 2.591)	Data  4.738 ( 2.473)	Loss 1.3898e-01 (2.0779e-01) 
2023-05-27 06:24:28.458222: val Epoch: [9][41/72]	Time  0.205 ( 2.535)	Data  0.082 ( 2.416)	Loss 9.4959e-02 (2.0510e-01) 
2023-05-27 06:24:33.242388: val Epoch: [9][42/72]	Time  4.784 ( 2.587)	Data  4.674 ( 2.469)	Loss 9.8103e-02 (2.0261e-01) 
2023-05-27 06:24:33.374747: val Epoch: [9][43/72]	Time  0.132 ( 2.531)	Data  0.022 ( 2.413)	Loss 8.2434e-02 (1.9988e-01) 
2023-05-27 06:24:38.361766: val Epoch: [9][44/72]	Time  4.987 ( 2.586)	Data  4.808 ( 2.466)	Loss 9.0838e-02 (1.9746e-01) 
2023-05-27 06:24:38.650476: val Epoch: [9][45/72]	Time  0.289 ( 2.536)	Data  0.176 ( 2.416)	Loss 2.8615e-01 (1.9939e-01) 
2023-05-27 06:24:43.359499: val Epoch: [9][46/72]	Time  4.709 ( 2.582)	Data  4.596 ( 2.463)	Loss 1.0596e-01 (1.9740e-01) 
2023-05-27 06:24:43.594454: val Epoch: [9][47/72]	Time  0.235 ( 2.533)	Data  0.089 ( 2.413)	Loss 1.0117e-01 (1.9539e-01) 
2023-05-27 06:24:48.493213: val Epoch: [9][48/72]	Time  4.899 ( 2.581)	Data  4.743 ( 2.461)	Loss 7.4573e-02 (1.9293e-01) 
2023-05-27 06:24:48.648496: val Epoch: [9][49/72]	Time  0.155 ( 2.533)	Data  0.001 ( 2.412)	Loss 1.3254e-01 (1.9172e-01) 
2023-05-27 06:24:53.546239: val Epoch: [9][50/72]	Time  4.898 ( 2.579)	Data  4.776 ( 2.458)	Loss 1.6809e-01 (1.9126e-01) 
2023-05-27 06:24:53.658113: val Epoch: [9][51/72]	Time  0.112 ( 2.532)	Data  0.001 ( 2.411)	Loss 1.5524e-01 (1.9056e-01) 
2023-05-27 06:24:58.651177: val Epoch: [9][52/72]	Time  4.993 ( 2.578)	Data  4.885 ( 2.457)	Loss 3.6297e-01 (1.9382e-01) 
2023-05-27 06:24:58.758417: val Epoch: [9][53/72]	Time  0.107 ( 2.532)	Data  0.000 ( 2.412)	Loss 3.2226e-01 (1.9619e-01) 
2023-05-27 06:25:03.944288: val Epoch: [9][54/72]	Time  5.186 ( 2.581)	Data  5.057 ( 2.460)	Loss 1.3916e-01 (1.9516e-01) 
2023-05-27 06:25:04.058700: val Epoch: [9][55/72]	Time  0.114 ( 2.537)	Data  0.001 ( 2.416)	Loss 4.2549e-01 (1.9927e-01) 
2023-05-27 06:25:08.779961: val Epoch: [9][56/72]	Time  4.721 ( 2.575)	Data  4.609 ( 2.455)	Loss 7.7879e-02 (1.9714e-01) 
2023-05-27 06:25:08.893232: val Epoch: [9][57/72]	Time  0.113 ( 2.533)	Data  0.001 ( 2.412)	Loss 4.5531e-01 (2.0159e-01) 
2023-05-27 06:25:13.783989: val Epoch: [9][58/72]	Time  4.891 ( 2.573)	Data  4.783 ( 2.452)	Loss 9.1237e-02 (1.9972e-01) 
2023-05-27 06:25:13.892650: val Epoch: [9][59/72]	Time  0.109 ( 2.531)	Data  0.001 ( 2.412)	Loss 1.2678e-01 (1.9851e-01) 
2023-05-27 06:25:18.687805: val Epoch: [9][60/72]	Time  4.795 ( 2.569)	Data  4.683 ( 2.449)	Loss 6.1106e-02 (1.9625e-01) 
2023-05-27 06:25:18.800146: val Epoch: [9][61/72]	Time  0.112 ( 2.529)	Data  0.001 ( 2.409)	Loss 1.2128e-01 (1.9504e-01) 
2023-05-27 06:25:23.564016: val Epoch: [9][62/72]	Time  4.764 ( 2.564)	Data  4.657 ( 2.445)	Loss 8.9375e-02 (1.9337e-01) 
2023-05-27 06:25:23.670908: val Epoch: [9][63/72]	Time  0.107 ( 2.526)	Data  0.001 ( 2.407)	Loss 4.0917e-01 (1.9674e-01) 
2023-05-27 06:25:28.531973: val Epoch: [9][64/72]	Time  4.861 ( 2.562)	Data  4.754 ( 2.443)	Loss 2.4769e-01 (1.9752e-01) 
2023-05-27 06:25:28.640009: val Epoch: [9][65/72]	Time  0.108 ( 2.525)	Data  0.000 ( 2.406)	Loss 3.2427e-01 (1.9944e-01) 
2023-05-27 06:25:33.585546: val Epoch: [9][66/72]	Time  4.946 ( 2.561)	Data  4.829 ( 2.442)	Loss 4.7986e-01 (2.0363e-01) 
2023-05-27 06:25:33.702618: val Epoch: [9][67/72]	Time  0.117 ( 2.525)	Data  0.001 ( 2.406)	Loss 2.5857e-01 (2.0444e-01) 
2023-05-27 06:25:38.848046: val Epoch: [9][68/72]	Time  5.145 ( 2.563)	Data  5.034 ( 2.444)	Loss 1.1304e-01 (2.0311e-01) 
2023-05-27 06:25:38.959348: val Epoch: [9][69/72]	Time  0.111 ( 2.528)	Data  0.000 ( 2.409)	Loss 1.5026e-01 (2.0236e-01) 
2023-05-27 06:25:43.755827: val Epoch: [9][70/72]	Time  4.796 ( 2.560)	Data  4.689 ( 2.441)	Loss 9.1429e-02 (2.0079e-01) 
2023-05-27 06:25:43.863265: val Epoch: [9][71/72]	Time  0.107 ( 2.526)	Data  0.000 ( 2.408)	Loss 1.0266e-01 (1.9943e-01) 
2023-05-27 06:25:44.291064: Epoch 9 :Val : ['ET : 0.6201350688934326', 'TC : 0.6554418206214905', 'WT : 0.8035339117050171'] 
2023-05-27 06:25:44.292117: Epoch 9 :Val : ['ET : 0.6201350688934326', 'TC : 0.6554418206214905', 'WT : 0.8035339117050171'] 
2023-05-27 06:25:44.297323: Val epoch done in 183.512003789976 s 
2023-05-27 06:25:44.303233: Batches per epoch:  193 
2023-05-27 06:25:55.339701: train Epoch: [10][  0/193]	Time 11.036 (11.036)	Data 10.443 (10.443)	Loss 1.9847e-01 (1.9847e-01) 
2023-05-27 06:25:55.904265: train Epoch: [10][  1/193]	Time  0.565 ( 5.800)	Data  0.001 ( 5.222)	Loss 2.2059e-01 (2.0953e-01) 
2023-05-27 06:26:05.141665: train Epoch: [10][  2/193]	Time  9.237 ( 6.946)	Data  8.674 ( 6.372)	Loss 1.6251e-01 (1.9386e-01) 
2023-05-27 06:26:05.705567: train Epoch: [10][  3/193]	Time  0.564 ( 5.351)	Data  0.001 ( 4.780)	Loss 2.1717e-01 (1.9969e-01) 
2023-05-27 06:26:14.971743: train Epoch: [10][  4/193]	Time  9.266 ( 6.134)	Data  8.703 ( 5.564)	Loss 9.9395e-02 (1.7963e-01) 
2023-05-27 06:26:15.535685: train Epoch: [10][  5/193]	Time  0.564 ( 5.205)	Data  0.001 ( 4.637)	Loss 1.2228e-01 (1.7007e-01) 
2023-05-27 06:26:24.647192: train Epoch: [10][  6/193]	Time  9.112 ( 5.763)	Data  8.549 ( 5.196)	Loss 1.1813e-01 (1.6265e-01) 
2023-05-27 06:26:25.210871: train Epoch: [10][  7/193]	Time  0.564 ( 5.113)	Data  0.001 ( 4.546)	Loss 1.8778e-01 (1.6579e-01) 
2023-05-27 06:26:34.508374: train Epoch: [10][  8/193]	Time  9.297 ( 5.578)	Data  8.728 ( 5.011)	Loss 1.9210e-01 (1.6871e-01) 
2023-05-27 06:26:35.072963: train Epoch: [10][  9/193]	Time  0.565 ( 5.077)	Data  0.001 ( 4.510)	Loss 8.9959e-02 (1.6084e-01) 
2023-05-27 06:26:44.650724: train Epoch: [10][ 10/193]	Time  9.578 ( 5.486)	Data  9.015 ( 4.920)	Loss 1.6442e-01 (1.6116e-01) 
2023-05-27 06:26:45.213012: train Epoch: [10][ 11/193]	Time  0.562 ( 5.076)	Data  0.001 ( 4.510)	Loss 1.2893e-01 (1.5848e-01) 
2023-05-27 06:26:54.641981: train Epoch: [10][ 12/193]	Time  9.429 ( 5.411)	Data  8.863 ( 4.845)	Loss 7.3585e-02 (1.5195e-01) 
2023-05-27 06:26:55.206125: train Epoch: [10][ 13/193]	Time  0.564 ( 5.064)	Data  0.001 ( 4.499)	Loss 1.9190e-01 (1.5480e-01) 
2023-05-27 06:27:04.944607: train Epoch: [10][ 14/193]	Time  9.738 ( 5.376)	Data  9.176 ( 4.810)	Loss 3.6540e-01 (1.6884e-01) 
2023-05-27 06:27:05.508811: train Epoch: [10][ 15/193]	Time  0.564 ( 5.075)	Data  0.001 ( 4.510)	Loss 2.6828e-01 (1.7506e-01) 
2023-05-27 06:27:14.808257: train Epoch: [10][ 16/193]	Time  9.299 ( 5.324)	Data  8.736 ( 4.758)	Loss 2.0568e-01 (1.7686e-01) 
2023-05-27 06:27:15.374723: train Epoch: [10][ 17/193]	Time  0.566 ( 5.060)	Data  0.001 ( 4.494)	Loss 1.2134e-01 (1.7377e-01) 
2023-05-27 06:27:24.732468: train Epoch: [10][ 18/193]	Time  9.358 ( 5.286)	Data  8.790 ( 4.720)	Loss 1.8220e-01 (1.7422e-01) 
2023-05-27 06:27:25.295562: train Epoch: [10][ 19/193]	Time  0.563 ( 5.050)	Data  0.001 ( 4.484)	Loss 1.1987e-01 (1.7150e-01) 
2023-05-27 06:27:34.525495: train Epoch: [10][ 20/193]	Time  9.230 ( 5.249)	Data  8.666 ( 4.683)	Loss 9.1891e-02 (1.6771e-01) 
2023-05-27 06:27:35.088015: train Epoch: [10][ 21/193]	Time  0.563 ( 5.036)	Data  0.001 ( 4.471)	Loss 1.2491e-01 (1.6576e-01) 
2023-05-27 06:27:44.741193: train Epoch: [10][ 22/193]	Time  9.653 ( 5.236)	Data  9.089 ( 4.671)	Loss 2.0151e-01 (1.6732e-01) 
2023-05-27 06:27:45.303934: train Epoch: [10][ 23/193]	Time  0.563 ( 5.042)	Data  0.001 ( 4.477)	Loss 1.3008e-01 (1.6577e-01) 
2023-05-27 06:27:54.543993: train Epoch: [10][ 24/193]	Time  9.240 ( 5.210)	Data  8.671 ( 4.644)	Loss 1.1283e-01 (1.6365e-01) 
2023-05-27 06:27:55.112854: train Epoch: [10][ 25/193]	Time  0.569 ( 5.031)	Data  0.001 ( 4.466)	Loss 1.2129e-01 (1.6202e-01) 
2023-05-27 06:28:04.149647: train Epoch: [10][ 26/193]	Time  9.037 ( 5.179)	Data  8.465 ( 4.614)	Loss 8.3905e-02 (1.5913e-01) 
2023-05-27 06:28:04.718361: train Epoch: [10][ 27/193]	Time  0.569 ( 5.015)	Data  0.001 ( 4.449)	Loss 1.6039e-01 (1.5917e-01) 
2023-05-27 06:28:13.359512: train Epoch: [10][ 28/193]	Time  8.641 ( 5.140)	Data  8.057 ( 4.574)	Loss 1.0900e-01 (1.5744e-01) 
2023-05-27 06:28:13.932994: train Epoch: [10][ 29/193]	Time  0.573 ( 4.988)	Data  0.001 ( 4.421)	Loss 1.7777e-01 (1.5812e-01) 
2023-05-27 06:28:22.955176: train Epoch: [10][ 30/193]	Time  9.022 ( 5.118)	Data  8.450 ( 4.551)	Loss 1.1150e-01 (1.5662e-01) 
2023-05-27 06:28:23.527648: train Epoch: [10][ 31/193]	Time  0.572 ( 4.976)	Data  0.001 ( 4.409)	Loss 1.2366e-01 (1.5559e-01) 
2023-05-27 06:28:32.879166: train Epoch: [10][ 32/193]	Time  9.352 ( 5.108)	Data  8.782 ( 4.542)	Loss 1.1564e-01 (1.5437e-01) 
2023-05-27 06:28:33.449762: train Epoch: [10][ 33/193]	Time  0.571 ( 4.975)	Data  0.001 ( 4.408)	Loss 1.5331e-01 (1.5434e-01) 
2023-05-27 06:28:43.032466: train Epoch: [10][ 34/193]	Time  9.583 ( 5.107)	Data  9.013 ( 4.540)	Loss 2.2919e-01 (1.5648e-01) 
2023-05-27 06:28:43.601029: train Epoch: [10][ 35/193]	Time  0.569 ( 4.980)	Data  0.001 ( 4.413)	Loss 1.0116e-01 (1.5495e-01) 
2023-05-27 06:28:53.175031: train Epoch: [10][ 36/193]	Time  9.574 ( 5.105)	Data  8.997 ( 4.537)	Loss 1.2795e-01 (1.5422e-01) 
2023-05-27 06:28:53.737705: train Epoch: [10][ 37/193]	Time  0.563 ( 4.985)	Data  0.001 ( 4.418)	Loss 9.0538e-02 (1.5254e-01) 
2023-05-27 06:29:02.913578: train Epoch: [10][ 38/193]	Time  9.176 ( 5.093)	Data  8.613 ( 4.526)	Loss 2.1053e-01 (1.5403e-01) 
2023-05-27 06:29:03.478169: train Epoch: [10][ 39/193]	Time  0.565 ( 4.979)	Data  0.001 ( 4.412)	Loss 1.3952e-01 (1.5366e-01) 
2023-05-27 06:29:12.587066: train Epoch: [10][ 40/193]	Time  9.109 ( 5.080)	Data  8.547 ( 4.513)	Loss 1.7762e-01 (1.5425e-01) 
2023-05-27 06:29:13.150191: train Epoch: [10][ 41/193]	Time  0.563 ( 4.973)	Data  0.001 ( 4.406)	Loss 9.8140e-02 (1.5291e-01) 
2023-05-27 06:29:23.268869: train Epoch: [10][ 42/193]	Time 10.119 ( 5.092)	Data  9.554 ( 4.526)	Loss 1.2902e-01 (1.5236e-01) 
2023-05-27 06:29:23.833072: train Epoch: [10][ 43/193]	Time  0.564 ( 4.989)	Data  0.001 ( 4.423)	Loss 1.4288e-01 (1.5214e-01) 
2023-05-27 06:29:33.068595: train Epoch: [10][ 44/193]	Time  9.236 ( 5.084)	Data  8.672 ( 4.517)	Loss 1.5244e-01 (1.5215e-01) 
2023-05-27 06:29:33.635541: train Epoch: [10][ 45/193]	Time  0.567 ( 4.985)	Data  0.001 ( 4.419)	Loss 9.7809e-02 (1.5097e-01) 
2023-05-27 06:29:42.675098: train Epoch: [10][ 46/193]	Time  9.040 ( 5.072)	Data  8.468 ( 4.505)	Loss 7.5043e-02 (1.4935e-01) 
2023-05-27 06:29:43.239841: train Epoch: [10][ 47/193]	Time  0.565 ( 4.978)	Data  0.001 ( 4.411)	Loss 8.9359e-02 (1.4810e-01) 
2023-05-27 06:29:52.373315: train Epoch: [10][ 48/193]	Time  9.133 ( 5.063)	Data  8.570 ( 4.496)	Loss 1.0539e-01 (1.4723e-01) 
2023-05-27 06:29:52.936635: train Epoch: [10][ 49/193]	Time  0.563 ( 4.973)	Data  0.001 ( 4.406)	Loss 7.5210e-02 (1.4579e-01) 
2023-05-27 06:30:02.577103: train Epoch: [10][ 50/193]	Time  9.640 ( 5.064)	Data  9.078 ( 4.498)	Loss 1.8677e-01 (1.4659e-01) 
2023-05-27 06:30:03.141375: train Epoch: [10][ 51/193]	Time  0.564 ( 4.978)	Data  0.001 ( 4.411)	Loss 1.0778e-01 (1.4585e-01) 
2023-05-27 06:30:12.152618: train Epoch: [10][ 52/193]	Time  9.011 ( 5.054)	Data  8.448 ( 4.487)	Loss 8.5498e-02 (1.4471e-01) 
2023-05-27 06:30:12.719144: train Epoch: [10][ 53/193]	Time  0.567 ( 4.971)	Data  0.001 ( 4.404)	Loss 2.4353e-01 (1.4654e-01) 
2023-05-27 06:30:21.974248: train Epoch: [10][ 54/193]	Time  9.255 ( 5.049)	Data  8.691 ( 4.482)	Loss 1.2630e-01 (1.4617e-01) 
2023-05-27 06:30:22.539472: train Epoch: [10][ 55/193]	Time  0.565 ( 4.968)	Data  0.001 ( 4.402)	Loss 8.5506e-02 (1.4509e-01) 
2023-05-27 06:30:30.885184: train Epoch: [10][ 56/193]	Time  8.346 ( 5.028)	Data  7.771 ( 4.461)	Loss 9.7020e-02 (1.4424e-01) 
2023-05-27 06:30:31.467147: train Epoch: [10][ 57/193]	Time  0.582 ( 4.951)	Data  0.001 ( 4.384)	Loss 3.7159e-01 (1.4816e-01) 
2023-05-27 06:30:40.339842: train Epoch: [10][ 58/193]	Time  8.873 ( 5.018)	Data  8.301 ( 4.451)	Loss 7.4893e-02 (1.4692e-01) 
2023-05-27 06:30:40.902864: train Epoch: [10][ 59/193]	Time  0.563 ( 4.943)	Data  0.001 ( 4.377)	Loss 1.2730e-01 (1.4659e-01) 
2023-05-27 06:30:50.215619: train Epoch: [10][ 60/193]	Time  9.313 ( 5.015)	Data  8.748 ( 4.448)	Loss 1.1748e-01 (1.4612e-01) 
2023-05-27 06:30:50.782715: train Epoch: [10][ 61/193]	Time  0.567 ( 4.943)	Data  0.001 ( 4.377)	Loss 6.8956e-02 (1.4487e-01) 
2023-05-27 06:31:00.610787: train Epoch: [10][ 62/193]	Time  9.828 ( 5.021)	Data  9.264 ( 4.454)	Loss 1.1537e-01 (1.4440e-01) 
2023-05-27 06:31:01.173536: train Epoch: [10][ 63/193]	Time  0.563 ( 4.951)	Data  0.001 ( 4.385)	Loss 2.1109e-01 (1.4545e-01) 
2023-05-27 06:31:10.153912: train Epoch: [10][ 64/193]	Time  8.980 ( 5.013)	Data  8.415 ( 4.447)	Loss 1.0125e-01 (1.4477e-01) 
2023-05-27 06:31:10.734280: train Epoch: [10][ 65/193]	Time  0.580 ( 4.946)	Data  0.001 ( 4.379)	Loss 1.1916e-01 (1.4438e-01) 
2023-05-27 06:31:19.514913: train Epoch: [10][ 66/193]	Time  8.781 ( 5.003)	Data  8.210 ( 4.436)	Loss 1.3898e-01 (1.4430e-01) 
2023-05-27 06:31:20.077981: train Epoch: [10][ 67/193]	Time  0.563 ( 4.938)	Data  0.001 ( 4.371)	Loss 1.1145e-01 (1.4381e-01) 
2023-05-27 06:31:29.231247: train Epoch: [10][ 68/193]	Time  9.153 ( 4.999)	Data  8.589 ( 4.432)	Loss 7.1258e-02 (1.4276e-01) 
2023-05-27 06:31:29.796607: train Epoch: [10][ 69/193]	Time  0.565 ( 4.936)	Data  0.001 ( 4.369)	Loss 8.7461e-02 (1.4197e-01) 
2023-05-27 06:31:39.267133: train Epoch: [10][ 70/193]	Time  9.471 ( 4.999)	Data  8.906 ( 4.433)	Loss 1.3435e-01 (1.4187e-01) 
2023-05-27 06:31:39.846054: train Epoch: [10][ 71/193]	Time  0.579 ( 4.938)	Data  0.001 ( 4.371)	Loss 1.7055e-01 (1.4226e-01) 
2023-05-27 06:31:49.298399: train Epoch: [10][ 72/193]	Time  9.452 ( 5.000)	Data  8.888 ( 4.433)	Loss 1.0404e-01 (1.4174e-01) 
2023-05-27 06:31:49.860929: train Epoch: [10][ 73/193]	Time  0.563 ( 4.940)	Data  0.001 ( 4.373)	Loss 1.2628e-01 (1.4153e-01) 
2023-05-27 06:31:59.250740: train Epoch: [10][ 74/193]	Time  9.390 ( 4.999)	Data  8.827 ( 4.433)	Loss 9.6838e-02 (1.4094e-01) 
2023-05-27 06:31:59.815153: train Epoch: [10][ 75/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.374)	Loss 9.5472e-02 (1.4034e-01) 
2023-05-27 06:32:09.090492: train Epoch: [10][ 76/193]	Time  9.275 ( 4.997)	Data  8.701 ( 4.431)	Loss 9.2679e-02 (1.3972e-01) 
2023-05-27 06:32:09.661922: train Epoch: [10][ 77/193]	Time  0.571 ( 4.940)	Data  0.001 ( 4.374)	Loss 2.1815e-01 (1.4072e-01) 
2023-05-27 06:32:18.515826: train Epoch: [10][ 78/193]	Time  8.854 ( 4.990)	Data  8.291 ( 4.423)	Loss 9.7557e-02 (1.4018e-01) 
2023-05-27 06:32:19.079365: train Epoch: [10][ 79/193]	Time  0.564 ( 4.935)	Data  0.001 ( 4.368)	Loss 8.4861e-02 (1.3949e-01) 
2023-05-27 06:32:28.783868: train Epoch: [10][ 80/193]	Time  9.704 ( 4.994)	Data  9.142 ( 4.427)	Loss 1.3455e-01 (1.3943e-01) 
2023-05-27 06:32:29.348231: train Epoch: [10][ 81/193]	Time  0.564 ( 4.940)	Data  0.001 ( 4.373)	Loss 9.3044e-02 (1.3886e-01) 
2023-05-27 06:32:39.094765: train Epoch: [10][ 82/193]	Time  9.747 ( 4.997)	Data  9.172 ( 4.431)	Loss 1.7164e-01 (1.3925e-01) 
2023-05-27 06:32:39.664597: train Epoch: [10][ 83/193]	Time  0.570 ( 4.945)	Data  0.001 ( 4.378)	Loss 9.0619e-02 (1.3868e-01) 
2023-05-27 06:32:49.058193: train Epoch: [10][ 84/193]	Time  9.394 ( 4.997)	Data  8.820 ( 4.430)	Loss 7.3107e-02 (1.3790e-01) 
2023-05-27 06:32:49.624685: train Epoch: [10][ 85/193]	Time  0.566 ( 4.946)	Data  0.001 ( 4.379)	Loss 1.1809e-01 (1.3767e-01) 
2023-05-27 06:32:58.531602: train Epoch: [10][ 86/193]	Time  8.907 ( 4.991)	Data  8.344 ( 4.425)	Loss 8.9330e-02 (1.3712e-01) 
2023-05-27 06:32:59.097127: train Epoch: [10][ 87/193]	Time  0.566 ( 4.941)	Data  0.001 ( 4.374)	Loss 8.4856e-02 (1.3652e-01) 
2023-05-27 06:33:08.387101: train Epoch: [10][ 88/193]	Time  9.290 ( 4.990)	Data  8.720 ( 4.423)	Loss 1.2049e-01 (1.3634e-01) 
2023-05-27 06:33:08.950928: train Epoch: [10][ 89/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.374)	Loss 8.0684e-02 (1.3573e-01) 
2023-05-27 06:33:18.271204: train Epoch: [10][ 90/193]	Time  9.320 ( 4.989)	Data  8.756 ( 4.422)	Loss 1.2495e-01 (1.3561e-01) 
2023-05-27 06:33:18.836346: train Epoch: [10][ 91/193]	Time  0.565 ( 4.941)	Data  0.001 ( 4.374)	Loss 6.6605e-02 (1.3486e-01) 
2023-05-27 06:33:28.531565: train Epoch: [10][ 92/193]	Time  9.695 ( 4.992)	Data  9.122 ( 4.425)	Loss 1.4328e-01 (1.3495e-01) 
2023-05-27 06:33:29.106561: train Epoch: [10][ 93/193]	Time  0.575 ( 4.945)	Data  0.001 ( 4.378)	Loss 1.1780e-01 (1.3477e-01) 
2023-05-27 06:33:37.693526: train Epoch: [10][ 94/193]	Time  8.587 ( 4.983)	Data  8.007 ( 4.416)	Loss 1.4174e-01 (1.3484e-01) 
2023-05-27 06:33:38.263165: train Epoch: [10][ 95/193]	Time  0.570 ( 4.937)	Data  0.001 ( 4.370)	Loss 1.3330e-01 (1.3482e-01) 
2023-05-27 06:33:46.213206: train Epoch: [10][ 96/193]	Time  7.950 ( 4.968)	Data  7.386 ( 4.401)	Loss 1.5245e-01 (1.3500e-01) 
2023-05-27 06:33:46.777446: train Epoch: [10][ 97/193]	Time  0.564 ( 4.923)	Data  0.001 ( 4.356)	Loss 7.9434e-02 (1.3444e-01) 
2023-05-27 06:33:55.117808: train Epoch: [10][ 98/193]	Time  8.340 ( 4.958)	Data  7.776 ( 4.391)	Loss 3.5206e-01 (1.3664e-01) 
2023-05-27 06:33:55.682902: train Epoch: [10][ 99/193]	Time  0.565 ( 4.914)	Data  0.001 ( 4.347)	Loss 1.1807e-01 (1.3645e-01) 
2023-05-27 06:34:05.262382: train Epoch: [10][100/193]	Time  9.579 ( 4.960)	Data  9.011 ( 4.393)	Loss 1.0067e-01 (1.3610e-01) 
2023-05-27 06:34:05.830404: train Epoch: [10][101/193]	Time  0.568 ( 4.917)	Data  0.001 ( 4.350)	Loss 1.3836e-01 (1.3612e-01) 
2023-05-27 06:34:15.119440: train Epoch: [10][102/193]	Time  9.289 ( 4.959)	Data  8.723 ( 4.393)	Loss 6.8868e-02 (1.3547e-01) 
2023-05-27 06:34:15.683729: train Epoch: [10][103/193]	Time  0.564 ( 4.917)	Data  0.001 ( 4.350)	Loss 1.3762e-01 (1.3549e-01) 
2023-05-27 06:34:25.392034: train Epoch: [10][104/193]	Time  9.708 ( 4.963)	Data  9.136 ( 4.396)	Loss 1.3602e-01 (1.3549e-01) 
2023-05-27 06:34:25.955624: train Epoch: [10][105/193]	Time  0.564 ( 4.921)	Data  0.001 ( 4.355)	Loss 1.1477e-01 (1.3530e-01) 
2023-05-27 06:34:35.280511: train Epoch: [10][106/193]	Time  9.325 ( 4.962)	Data  8.711 ( 4.395)	Loss 1.0047e-01 (1.3497e-01) 
2023-05-27 06:34:35.843430: train Epoch: [10][107/193]	Time  0.563 ( 4.922)	Data  0.001 ( 4.355)	Loss 1.4047e-01 (1.3502e-01) 
2023-05-27 06:34:45.230310: train Epoch: [10][108/193]	Time  9.387 ( 4.963)	Data  8.813 ( 4.395)	Loss 1.3535e-01 (1.3502e-01) 
2023-05-27 06:34:45.797714: train Epoch: [10][109/193]	Time  0.567 ( 4.923)	Data  0.001 ( 4.355)	Loss 9.7035e-02 (1.3468e-01) 
2023-05-27 06:34:55.105344: train Epoch: [10][110/193]	Time  9.308 ( 4.962)	Data  8.736 ( 4.395)	Loss 1.2844e-01 (1.3462e-01) 
2023-05-27 06:34:55.676821: train Epoch: [10][111/193]	Time  0.571 ( 4.923)	Data  0.001 ( 4.356)	Loss 1.0122e-01 (1.3432e-01) 
2023-05-27 06:35:05.328806: train Epoch: [10][112/193]	Time  9.652 ( 4.965)	Data  9.080 ( 4.398)	Loss 8.3930e-02 (1.3388e-01) 
2023-05-27 06:35:05.893639: train Epoch: [10][113/193]	Time  0.565 ( 4.926)	Data  0.001 ( 4.359)	Loss 1.5614e-01 (1.3407e-01) 
2023-05-27 06:35:15.449504: train Epoch: [10][114/193]	Time  9.556 ( 4.966)	Data  8.974 ( 4.399)	Loss 1.1905e-01 (1.3394e-01) 
2023-05-27 06:35:16.019767: train Epoch: [10][115/193]	Time  0.570 ( 4.929)	Data  0.001 ( 4.361)	Loss 8.3978e-02 (1.3351e-01) 
2023-05-27 06:35:25.677701: train Epoch: [10][116/193]	Time  9.658 ( 4.969)	Data  9.088 ( 4.402)	Loss 9.1554e-02 (1.3315e-01) 
2023-05-27 06:35:26.250336: train Epoch: [10][117/193]	Time  0.573 ( 4.932)	Data  0.001 ( 4.364)	Loss 2.9379e-01 (1.3451e-01) 
2023-05-27 06:35:36.125454: train Epoch: [10][118/193]	Time  9.875 ( 4.973)	Data  9.303 ( 4.406)	Loss 5.6989e-02 (1.3386e-01) 
2023-05-27 06:35:36.703512: train Epoch: [10][119/193]	Time  0.578 ( 4.937)	Data  0.001 ( 4.369)	Loss 1.3162e-01 (1.3384e-01) 
2023-05-27 06:35:46.460616: train Epoch: [10][120/193]	Time  9.757 ( 4.977)	Data  9.192 ( 4.409)	Loss 1.0173e-01 (1.3358e-01) 
2023-05-27 06:35:47.038475: train Epoch: [10][121/193]	Time  0.578 ( 4.940)	Data  0.001 ( 4.373)	Loss 1.4719e-01 (1.3369e-01) 
2023-05-27 06:35:56.762203: train Epoch: [10][122/193]	Time  9.724 ( 4.979)	Data  9.149 ( 4.412)	Loss 1.4357e-01 (1.3377e-01) 
2023-05-27 06:35:57.367196: train Epoch: [10][123/193]	Time  0.605 ( 4.944)	Data  0.001 ( 4.376)	Loss 9.9300e-02 (1.3349e-01) 
2023-05-27 06:36:06.704541: train Epoch: [10][124/193]	Time  9.337 ( 4.979)	Data  8.766 ( 4.411)	Loss 1.5049e-01 (1.3363e-01) 
2023-05-27 06:36:07.308148: train Epoch: [10][125/193]	Time  0.604 ( 4.944)	Data  0.001 ( 4.376)	Loss 1.8773e-01 (1.3406e-01) 
2023-05-27 06:36:16.461086: train Epoch: [10][126/193]	Time  9.153 ( 4.978)	Data  8.580 ( 4.409)	Loss 1.3572e-01 (1.3407e-01) 
2023-05-27 06:36:17.041983: train Epoch: [10][127/193]	Time  0.581 ( 4.943)	Data  0.001 ( 4.375)	Loss 1.0065e-01 (1.3381e-01) 
2023-05-27 06:36:26.263018: train Epoch: [10][128/193]	Time  9.221 ( 4.976)	Data  8.653 ( 4.408)	Loss 9.0553e-02 (1.3348e-01) 
2023-05-27 06:36:26.831713: train Epoch: [10][129/193]	Time  0.569 ( 4.943)	Data  0.001 ( 4.374)	Loss 1.2744e-01 (1.3343e-01) 
2023-05-27 06:36:35.872883: train Epoch: [10][130/193]	Time  9.041 ( 4.974)	Data  8.468 ( 4.405)	Loss 7.6820e-02 (1.3300e-01) 
2023-05-27 06:36:36.440335: train Epoch: [10][131/193]	Time  0.567 ( 4.940)	Data  0.001 ( 4.372)	Loss 9.2784e-02 (1.3269e-01) 
2023-05-27 06:36:45.961446: train Epoch: [10][132/193]	Time  9.521 ( 4.975)	Data  8.951 ( 4.406)	Loss 9.1104e-02 (1.3238e-01) 
2023-05-27 06:36:46.529219: train Epoch: [10][133/193]	Time  0.568 ( 4.942)	Data  0.001 ( 4.374)	Loss 8.9730e-02 (1.3206e-01) 
2023-05-27 06:36:55.694072: train Epoch: [10][134/193]	Time  9.165 ( 4.973)	Data  8.597 ( 4.405)	Loss 1.3418e-01 (1.3208e-01) 
2023-05-27 06:36:56.263271: train Epoch: [10][135/193]	Time  0.569 ( 4.941)	Data  0.001 ( 4.372)	Loss 1.3162e-01 (1.3207e-01) 
2023-05-27 06:37:05.454386: train Epoch: [10][136/193]	Time  9.191 ( 4.972)	Data  8.619 ( 4.403)	Loss 2.2039e-01 (1.3272e-01) 
2023-05-27 06:37:06.035161: train Epoch: [10][137/193]	Time  0.581 ( 4.940)	Data  0.001 ( 4.372)	Loss 6.8101e-02 (1.3225e-01) 
2023-05-27 06:37:15.131346: train Epoch: [10][138/193]	Time  9.096 ( 4.970)	Data  8.532 ( 4.401)	Loss 7.4561e-02 (1.3183e-01) 
2023-05-27 06:37:15.696238: train Epoch: [10][139/193]	Time  0.565 ( 4.939)	Data  0.001 ( 4.370)	Loss 1.0718e-01 (1.3166e-01) 
2023-05-27 06:37:25.654286: train Epoch: [10][140/193]	Time  9.958 ( 4.974)	Data  9.386 ( 4.406)	Loss 1.3116e-01 (1.3166e-01) 
2023-05-27 06:37:26.223875: train Epoch: [10][141/193]	Time  0.570 ( 4.943)	Data  0.001 ( 4.375)	Loss 9.9150e-02 (1.3143e-01) 
2023-05-27 06:37:35.445716: train Epoch: [10][142/193]	Time  9.222 ( 4.973)	Data  8.641 ( 4.404)	Loss 7.3272e-02 (1.3102e-01) 
2023-05-27 06:37:36.025465: train Epoch: [10][143/193]	Time  0.580 ( 4.943)	Data  0.001 ( 4.374)	Loss 1.0005e-01 (1.3080e-01) 
2023-05-27 06:37:45.145722: train Epoch: [10][144/193]	Time  9.120 ( 4.971)	Data  8.550 ( 4.403)	Loss 9.8168e-02 (1.3058e-01) 
2023-05-27 06:37:45.709569: train Epoch: [10][145/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.372)	Loss 1.0128e-01 (1.3038e-01) 
2023-05-27 06:37:55.161040: train Epoch: [10][146/193]	Time  9.451 ( 4.972)	Data  8.886 ( 4.403)	Loss 1.5196e-01 (1.3053e-01) 
2023-05-27 06:37:55.725087: train Epoch: [10][147/193]	Time  0.564 ( 4.942)	Data  0.001 ( 4.373)	Loss 1.1480e-01 (1.3042e-01) 
2023-05-27 06:38:05.052552: train Epoch: [10][148/193]	Time  9.327 ( 4.971)	Data  8.764 ( 4.403)	Loss 1.2803e-01 (1.3040e-01) 
2023-05-27 06:38:05.620032: train Epoch: [10][149/193]	Time  0.567 ( 4.942)	Data  0.001 ( 4.374)	Loss 1.3835e-01 (1.3046e-01) 
2023-05-27 06:38:15.205362: train Epoch: [10][150/193]	Time  9.585 ( 4.973)	Data  9.017 ( 4.404)	Loss 8.5850e-02 (1.3016e-01) 
2023-05-27 06:38:15.792431: train Epoch: [10][151/193]	Time  0.587 ( 4.944)	Data  0.001 ( 4.375)	Loss 1.1036e-01 (1.3003e-01) 
2023-05-27 06:38:25.245736: train Epoch: [10][152/193]	Time  9.453 ( 4.973)	Data  8.870 ( 4.405)	Loss 8.9464e-02 (1.2977e-01) 
2023-05-27 06:38:25.837337: train Epoch: [10][153/193]	Time  0.592 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.7528e-01 (1.3006e-01) 
2023-05-27 06:38:35.052752: train Epoch: [10][154/193]	Time  9.215 ( 4.973)	Data  8.643 ( 4.404)	Loss 2.1456e-01 (1.3061e-01) 
2023-05-27 06:38:35.630945: train Epoch: [10][155/193]	Time  0.578 ( 4.944)	Data  0.001 ( 4.375)	Loss 1.7881e-01 (1.3092e-01) 
2023-05-27 06:38:44.722354: train Epoch: [10][156/193]	Time  9.091 ( 4.971)	Data  8.526 ( 4.402)	Loss 1.0921e-01 (1.3078e-01) 
2023-05-27 06:38:45.294792: train Epoch: [10][157/193]	Time  0.572 ( 4.943)	Data  0.001 ( 4.374)	Loss 1.6234e-01 (1.3098e-01) 
2023-05-27 06:38:54.507115: train Epoch: [10][158/193]	Time  9.212 ( 4.970)	Data  8.647 ( 4.401)	Loss 1.7254e-01 (1.3124e-01) 
2023-05-27 06:38:55.072865: train Epoch: [10][159/193]	Time  0.566 ( 4.942)	Data  0.001 ( 4.373)	Loss 2.2401e-01 (1.3182e-01) 
2023-05-27 06:39:04.822109: train Epoch: [10][160/193]	Time  9.749 ( 4.972)	Data  9.181 ( 4.403)	Loss 1.1229e-01 (1.3170e-01) 
2023-05-27 06:39:05.393114: train Epoch: [10][161/193]	Time  0.571 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.2321e-01 (1.3164e-01) 
2023-05-27 06:39:14.609858: train Epoch: [10][162/193]	Time  9.217 ( 4.971)	Data  8.653 ( 4.402)	Loss 1.3964e-01 (1.3169e-01) 
2023-05-27 06:39:15.197734: train Epoch: [10][163/193]	Time  0.588 ( 4.944)	Data  0.001 ( 4.375)	Loss 9.1803e-02 (1.3145e-01) 
2023-05-27 06:39:24.580945: train Epoch: [10][164/193]	Time  9.383 ( 4.971)	Data  8.820 ( 4.402)	Loss 1.0102e-01 (1.3127e-01) 
2023-05-27 06:39:25.158259: train Epoch: [10][165/193]	Time  0.577 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.3965e-01 (1.3132e-01) 
2023-05-27 06:39:34.494698: train Epoch: [10][166/193]	Time  9.336 ( 4.971)	Data  8.773 ( 4.402)	Loss 1.4235e-01 (1.3138e-01) 
2023-05-27 06:39:35.060364: train Epoch: [10][167/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.0080e-01 (1.3120e-01) 
2023-05-27 06:39:44.185869: train Epoch: [10][168/193]	Time  9.126 ( 4.970)	Data  8.561 ( 4.401)	Loss 1.5030e-01 (1.3131e-01) 
2023-05-27 06:39:44.749201: train Epoch: [10][169/193]	Time  0.563 ( 4.944)	Data  0.001 ( 4.375)	Loss 1.3880e-01 (1.3136e-01) 
2023-05-27 06:39:54.295336: train Epoch: [10][170/193]	Time  9.546 ( 4.971)	Data  8.973 ( 4.402)	Loss 1.8426e-01 (1.3167e-01) 
2023-05-27 06:39:54.858797: train Epoch: [10][171/193]	Time  0.563 ( 4.945)	Data  0.001 ( 4.376)	Loss 9.6493e-02 (1.3146e-01) 
2023-05-27 06:40:04.111287: train Epoch: [10][172/193]	Time  9.252 ( 4.970)	Data  8.688 ( 4.401)	Loss 9.0824e-02 (1.3123e-01) 
2023-05-27 06:40:04.677676: train Epoch: [10][173/193]	Time  0.566 ( 4.945)	Data  0.001 ( 4.376)	Loss 1.6083e-01 (1.3140e-01) 
2023-05-27 06:40:14.236267: train Epoch: [10][174/193]	Time  9.559 ( 4.971)	Data  8.994 ( 4.402)	Loss 1.1897e-01 (1.3133e-01) 
2023-05-27 06:40:14.801998: train Epoch: [10][175/193]	Time  0.566 ( 4.946)	Data  0.001 ( 4.377)	Loss 1.5969e-01 (1.3149e-01) 
2023-05-27 06:40:24.192040: train Epoch: [10][176/193]	Time  9.390 ( 4.971)	Data  8.827 ( 4.402)	Loss 1.2552e-01 (1.3145e-01) 
2023-05-27 06:40:24.769914: train Epoch: [10][177/193]	Time  0.578 ( 4.946)	Data  0.001 ( 4.378)	Loss 1.4417e-01 (1.3153e-01) 
2023-05-27 06:40:34.145288: train Epoch: [10][178/193]	Time  9.375 ( 4.971)	Data  8.812 ( 4.402)	Loss 1.1947e-01 (1.3146e-01) 
2023-05-27 06:40:34.734183: train Epoch: [10][179/193]	Time  0.589 ( 4.947)	Data  0.001 ( 4.378)	Loss 1.3619e-01 (1.3148e-01) 
2023-05-27 06:40:44.237434: train Epoch: [10][180/193]	Time  9.503 ( 4.972)	Data  8.924 ( 4.403)	Loss 3.1181e-01 (1.3248e-01) 
2023-05-27 06:40:44.848466: train Epoch: [10][181/193]	Time  0.611 ( 4.948)	Data  0.001 ( 4.379)	Loss 2.1228e-01 (1.3292e-01) 
2023-05-27 06:40:54.374074: train Epoch: [10][182/193]	Time  9.526 ( 4.973)	Data  8.951 ( 4.404)	Loss 1.6315e-01 (1.3308e-01) 
2023-05-27 06:40:54.955205: train Epoch: [10][183/193]	Time  0.581 ( 4.949)	Data  0.001 ( 4.380)	Loss 9.1832e-02 (1.3286e-01) 
2023-05-27 06:41:04.337415: train Epoch: [10][184/193]	Time  9.382 ( 4.973)	Data  8.811 ( 4.404)	Loss 1.5660e-01 (1.3299e-01) 
2023-05-27 06:41:04.912964: train Epoch: [10][185/193]	Time  0.576 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.3170e-01 (1.3298e-01) 
2023-05-27 06:41:14.320541: train Epoch: [10][186/193]	Time  9.408 ( 4.973)	Data  8.828 ( 4.404)	Loss 9.7582e-02 (1.3279e-01) 
2023-05-27 06:41:14.926062: train Epoch: [10][187/193]	Time  0.606 ( 4.950)	Data  0.001 ( 4.381)	Loss 2.7980e-01 (1.3357e-01) 
2023-05-27 06:41:24.745738: train Epoch: [10][188/193]	Time  9.820 ( 4.976)	Data  9.206 ( 4.406)	Loss 1.0940e-01 (1.3345e-01) 
2023-05-27 06:41:25.324852: train Epoch: [10][189/193]	Time  0.579 ( 4.953)	Data  0.001 ( 4.383)	Loss 1.3613e-01 (1.3346e-01) 
2023-05-27 06:41:34.448381: train Epoch: [10][190/193]	Time  9.124 ( 4.975)	Data  8.520 ( 4.405)	Loss 1.5278e-01 (1.3356e-01) 
2023-05-27 06:41:35.017575: train Epoch: [10][191/193]	Time  0.569 ( 4.952)	Data  0.001 ( 4.382)	Loss 2.4851e-01 (1.3416e-01) 
2023-05-27 06:41:42.739080: train Epoch: [10][192/193]	Time  7.722 ( 4.966)	Data  7.148 ( 4.396)	Loss 1.5501e-01 (1.3427e-01) 
2023-05-27 06:41:42.894826: Train Epoch done in 958.5916035550181 s 
2023-05-27 06:41:49.812280: val Epoch: [10][ 0/72]	Time  5.982 ( 5.982)	Data  5.726 ( 5.726)	Loss 1.4385e-01 (1.4385e-01) 
2023-05-27 06:41:49.924591: val Epoch: [10][ 1/72]	Time  0.112 ( 3.047)	Data  0.001 ( 2.863)	Loss 6.0614e-02 (1.0223e-01) 
2023-05-27 06:41:54.731362: val Epoch: [10][ 2/72]	Time  4.807 ( 3.634)	Data  4.696 ( 3.474)	Loss 3.6043e-01 (1.8830e-01) 
2023-05-27 06:41:54.843566: val Epoch: [10][ 3/72]	Time  0.112 ( 2.753)	Data  0.001 ( 2.606)	Loss 6.8701e-02 (1.5840e-01) 
2023-05-27 06:41:59.857602: val Epoch: [10][ 4/72]	Time  5.014 ( 3.206)	Data  4.903 ( 3.065)	Loss 1.9605e-01 (1.6593e-01) 
2023-05-27 06:41:59.969132: val Epoch: [10][ 5/72]	Time  0.112 ( 2.690)	Data  0.001 ( 2.554)	Loss 1.7851e-01 (1.6803e-01) 
2023-05-27 06:42:05.016479: val Epoch: [10][ 6/72]	Time  5.047 ( 3.027)	Data  4.936 ( 2.895)	Loss 1.4300e-01 (1.6445e-01) 
2023-05-27 06:42:05.127637: val Epoch: [10][ 7/72]	Time  0.111 ( 2.662)	Data  0.001 ( 2.533)	Loss 7.0250e-02 (1.5267e-01) 
2023-05-27 06:42:10.041264: val Epoch: [10][ 8/72]	Time  4.914 ( 2.912)	Data  4.798 ( 2.785)	Loss 1.0930e-01 (1.4786e-01) 
2023-05-27 06:42:10.155980: val Epoch: [10][ 9/72]	Time  0.115 ( 2.633)	Data  0.001 ( 2.506)	Loss 1.8693e-01 (1.5176e-01) 
2023-05-27 06:42:14.876153: val Epoch: [10][10/72]	Time  4.720 ( 2.822)	Data  4.607 ( 2.697)	Loss 7.7326e-02 (1.4500e-01) 
2023-05-27 06:42:14.985563: val Epoch: [10][11/72]	Time  0.109 ( 2.596)	Data  0.001 ( 2.472)	Loss 6.6960e-02 (1.3849e-01) 
2023-05-27 06:42:20.033744: val Epoch: [10][12/72]	Time  5.048 ( 2.785)	Data  4.943 ( 2.662)	Loss 8.4808e-02 (1.3436e-01) 
2023-05-27 06:42:20.143303: val Epoch: [10][13/72]	Time  0.110 ( 2.594)	Data  0.001 ( 2.472)	Loss 1.2612e-01 (1.3377e-01) 
2023-05-27 06:42:24.823793: val Epoch: [10][14/72]	Time  4.680 ( 2.733)	Data  4.575 ( 2.612)	Loss 1.0281e-01 (1.3171e-01) 
2023-05-27 06:42:24.928708: val Epoch: [10][15/72]	Time  0.105 ( 2.569)	Data  0.001 ( 2.449)	Loss 1.9334e-01 (1.3556e-01) 
2023-05-27 06:42:29.572572: val Epoch: [10][16/72]	Time  4.644 ( 2.691)	Data  4.535 ( 2.572)	Loss 1.6654e-01 (1.3738e-01) 
2023-05-27 06:42:29.815539: val Epoch: [10][17/72]	Time  0.243 ( 2.555)	Data  0.132 ( 2.436)	Loss 7.8405e-02 (1.3411e-01) 
2023-05-27 06:42:34.366376: val Epoch: [10][18/72]	Time  4.551 ( 2.660)	Data  4.439 ( 2.542)	Loss 7.1199e-02 (1.3080e-01) 
2023-05-27 06:42:34.933700: val Epoch: [10][19/72]	Time  0.567 ( 2.555)	Data  0.460 ( 2.438)	Loss 1.4705e-01 (1.3161e-01) 
2023-05-27 06:42:39.351252: val Epoch: [10][20/72]	Time  4.418 ( 2.644)	Data  4.310 ( 2.527)	Loss 1.4607e-01 (1.3230e-01) 
2023-05-27 06:42:39.822675: val Epoch: [10][21/72]	Time  0.471 ( 2.545)	Data  0.364 ( 2.429)	Loss 1.1151e-01 (1.3135e-01) 
2023-05-27 06:42:44.407605: val Epoch: [10][22/72]	Time  4.585 ( 2.634)	Data  4.480 ( 2.518)	Loss 1.0606e-01 (1.3025e-01) 
2023-05-27 06:42:44.625492: val Epoch: [10][23/72]	Time  0.218 ( 2.533)	Data  0.112 ( 2.418)	Loss 8.3383e-02 (1.2830e-01) 
2023-05-27 06:42:49.609682: val Epoch: [10][24/72]	Time  4.984 ( 2.631)	Data  4.879 ( 2.516)	Loss 1.6660e-01 (1.2983e-01) 
2023-05-27 06:42:49.714604: val Epoch: [10][25/72]	Time  0.105 ( 2.534)	Data  0.001 ( 2.419)	Loss 9.3089e-02 (1.2842e-01) 
2023-05-27 06:42:54.392581: val Epoch: [10][26/72]	Time  4.678 ( 2.613)	Data  4.573 ( 2.499)	Loss 9.7503e-02 (1.2727e-01) 
2023-05-27 06:42:54.642298: val Epoch: [10][27/72]	Time  0.250 ( 2.529)	Data  0.145 ( 2.415)	Loss 1.2079e-01 (1.2704e-01) 
2023-05-27 06:42:59.353387: val Epoch: [10][28/72]	Time  4.711 ( 2.604)	Data  4.602 ( 2.490)	Loss 7.1647e-02 (1.2513e-01) 
2023-05-27 06:42:59.736115: val Epoch: [10][29/72]	Time  0.383 ( 2.530)	Data  0.273 ( 2.416)	Loss 4.0310e-01 (1.3440e-01) 
2023-05-27 06:43:04.384836: val Epoch: [10][30/72]	Time  4.649 ( 2.599)	Data  4.542 ( 2.485)	Loss 9.5021e-02 (1.3313e-01) 
2023-05-27 06:43:04.998712: val Epoch: [10][31/72]	Time  0.614 ( 2.537)	Data  0.505 ( 2.423)	Loss 1.1176e-01 (1.3246e-01) 
2023-05-27 06:43:09.404057: val Epoch: [10][32/72]	Time  4.405 ( 2.593)	Data  4.298 ( 2.480)	Loss 3.6048e-01 (1.3937e-01) 
2023-05-27 06:43:09.744877: val Epoch: [10][33/72]	Time  0.341 ( 2.527)	Data  0.233 ( 2.414)	Loss 1.0313e-01 (1.3830e-01) 
2023-05-27 06:43:14.238462: val Epoch: [10][34/72]	Time  4.494 ( 2.583)	Data  4.386 ( 2.470)	Loss 7.2843e-02 (1.3643e-01) 
2023-05-27 06:43:14.779178: val Epoch: [10][35/72]	Time  0.541 ( 2.526)	Data  0.433 ( 2.414)	Loss 8.5621e-02 (1.3502e-01) 
2023-05-27 06:43:19.360230: val Epoch: [10][36/72]	Time  4.581 ( 2.582)	Data  4.474 ( 2.469)	Loss 6.3794e-02 (1.3310e-01) 
2023-05-27 06:43:19.714247: val Epoch: [10][37/72]	Time  0.354 ( 2.523)	Data  0.247 ( 2.411)	Loss 1.4245e-01 (1.3334e-01) 
2023-05-27 06:43:24.702320: val Epoch: [10][38/72]	Time  4.988 ( 2.586)	Data  4.881 ( 2.474)	Loss 3.0900e-01 (1.3785e-01) 
2023-05-27 06:43:24.809825: val Epoch: [10][39/72]	Time  0.108 ( 2.524)	Data  0.000 ( 2.412)	Loss 7.0955e-02 (1.3617e-01) 
2023-05-27 06:43:30.105800: val Epoch: [10][40/72]	Time  5.296 ( 2.592)	Data  5.188 ( 2.480)	Loss 9.9360e-02 (1.3528e-01) 
2023-05-27 06:43:30.212976: val Epoch: [10][41/72]	Time  0.107 ( 2.533)	Data  0.000 ( 2.421)	Loss 1.7756e-01 (1.3628e-01) 
2023-05-27 06:43:35.223485: val Epoch: [10][42/72]	Time  5.011 ( 2.591)	Data  4.902 ( 2.479)	Loss 8.6339e-02 (1.3512e-01) 
2023-05-27 06:43:35.330743: val Epoch: [10][43/72]	Time  0.107 ( 2.534)	Data  0.000 ( 2.422)	Loss 1.2129e-01 (1.3481e-01) 
2023-05-27 06:43:40.048348: val Epoch: [10][44/72]	Time  4.718 ( 2.583)	Data  4.608 ( 2.471)	Loss 9.0701e-02 (1.3383e-01) 
2023-05-27 06:43:40.159606: val Epoch: [10][45/72]	Time  0.111 ( 2.529)	Data  0.000 ( 2.417)	Loss 1.6964e-01 (1.3461e-01) 
2023-05-27 06:43:45.240770: val Epoch: [10][46/72]	Time  5.081 ( 2.583)	Data  4.964 ( 2.471)	Loss 2.3033e-01 (1.3664e-01) 
2023-05-27 06:43:45.355028: val Epoch: [10][47/72]	Time  0.114 ( 2.532)	Data  0.001 ( 2.420)	Loss 1.4125e-01 (1.3674e-01) 
2023-05-27 06:43:50.330328: val Epoch: [10][48/72]	Time  4.975 ( 2.582)	Data  4.867 ( 2.470)	Loss 9.2953e-02 (1.3585e-01) 
2023-05-27 06:43:50.441878: val Epoch: [10][49/72]	Time  0.112 ( 2.532)	Data  0.001 ( 2.420)	Loss 6.9887e-02 (1.3453e-01) 
2023-05-27 06:43:55.375780: val Epoch: [10][50/72]	Time  4.934 ( 2.579)	Data  4.825 ( 2.468)	Loss 1.5317e-01 (1.3489e-01) 
2023-05-27 06:43:55.483798: val Epoch: [10][51/72]	Time  0.108 ( 2.532)	Data  0.001 ( 2.420)	Loss 6.6017e-01 (1.4499e-01) 
2023-05-27 06:44:00.421810: val Epoch: [10][52/72]	Time  4.938 ( 2.577)	Data  4.826 ( 2.466)	Loss 2.2886e-01 (1.4658e-01) 
2023-05-27 06:44:00.533809: val Epoch: [10][53/72]	Time  0.112 ( 2.532)	Data  0.001 ( 2.420)	Loss 8.9566e-02 (1.4552e-01) 
2023-05-27 06:44:05.349221: val Epoch: [10][54/72]	Time  4.815 ( 2.573)	Data  4.700 ( 2.461)	Loss 1.8357e-01 (1.4621e-01) 
2023-05-27 06:44:05.459914: val Epoch: [10][55/72]	Time  0.111 ( 2.529)	Data  0.001 ( 2.417)	Loss 8.8486e-02 (1.4518e-01) 
2023-05-27 06:44:10.324995: val Epoch: [10][56/72]	Time  4.865 ( 2.570)	Data  4.757 ( 2.458)	Loss 8.9862e-02 (1.4421e-01) 
2023-05-27 06:44:10.433569: val Epoch: [10][57/72]	Time  0.109 ( 2.528)	Data  0.000 ( 2.416)	Loss 4.7987e-01 (1.5000e-01) 
2023-05-27 06:44:15.207714: val Epoch: [10][58/72]	Time  4.774 ( 2.566)	Data  4.666 ( 2.454)	Loss 2.1761e-01 (1.5114e-01) 
2023-05-27 06:44:15.317976: val Epoch: [10][59/72]	Time  0.110 ( 2.525)	Data  0.000 ( 2.413)	Loss 1.5398e-01 (1.5119e-01) 
2023-05-27 06:44:20.173104: val Epoch: [10][60/72]	Time  4.855 ( 2.563)	Data  4.747 ( 2.452)	Loss 2.2830e-01 (1.5246e-01) 
2023-05-27 06:44:20.280755: val Epoch: [10][61/72]	Time  0.108 ( 2.523)	Data  0.001 ( 2.412)	Loss 1.4173e-01 (1.5228e-01) 
2023-05-27 06:44:25.037195: val Epoch: [10][62/72]	Time  4.756 ( 2.559)	Data  4.648 ( 2.448)	Loss 3.6207e-01 (1.5561e-01) 
2023-05-27 06:44:25.145609: val Epoch: [10][63/72]	Time  0.108 ( 2.521)	Data  0.001 ( 2.409)	Loss 2.2281e-01 (1.5666e-01) 
2023-05-27 06:44:30.240044: val Epoch: [10][64/72]	Time  5.094 ( 2.560)	Data  4.981 ( 2.449)	Loss 4.5138e-01 (1.6120e-01) 
2023-05-27 06:44:30.351455: val Epoch: [10][65/72]	Time  0.111 ( 2.523)	Data  0.000 ( 2.412)	Loss 1.2290e-01 (1.6062e-01) 
2023-05-27 06:44:35.417939: val Epoch: [10][66/72]	Time  5.066 ( 2.561)	Data  4.957 ( 2.450)	Loss 1.8349e-01 (1.6096e-01) 
2023-05-27 06:44:35.526491: val Epoch: [10][67/72]	Time  0.109 ( 2.525)	Data  0.001 ( 2.414)	Loss 3.8963e-01 (1.6432e-01) 
2023-05-27 06:44:40.397656: val Epoch: [10][68/72]	Time  4.871 ( 2.559)	Data  4.763 ( 2.448)	Loss 6.0055e-01 (1.7064e-01) 
2023-05-27 06:44:40.505685: val Epoch: [10][69/72]	Time  0.108 ( 2.524)	Data  0.000 ( 2.413)	Loss 8.4186e-02 (1.6941e-01) 
2023-05-27 06:44:45.420539: val Epoch: [10][70/72]	Time  4.915 ( 2.558)	Data  4.806 ( 2.447)	Loss 3.7591e-01 (1.7232e-01) 
2023-05-27 06:44:45.525187: val Epoch: [10][71/72]	Time  0.105 ( 2.524)	Data  0.000 ( 2.413)	Loss 1.0178e-01 (1.7134e-01) 
2023-05-27 06:44:45.841143: Epoch 10 :Val : ['ET : 0.6935467720031738', 'TC : 0.7218626141548157', 'WT : 0.8185081481933594'] 
2023-05-27 06:44:45.844297: Epoch 10 :Val : ['ET : 0.6935467720031738', 'TC : 0.7218626141548157', 'WT : 0.8185081481933594'] 
2023-05-27 06:44:45.847984: Saving the model with DSC 0.7387878894805908 
2023-05-27 06:44:46.742942: Val epoch done in 183.84812153197709 s 
2023-05-27 06:44:46.810536: Batches per epoch:  193 
2023-05-27 06:44:58.145520: train Epoch: [11][  0/193]	Time 11.335 (11.335)	Data 10.752 (10.752)	Loss 1.2920e-01 (1.2920e-01) 
2023-05-27 06:44:58.709370: train Epoch: [11][  1/193]	Time  0.564 ( 5.949)	Data  0.001 ( 5.377)	Loss 1.4500e-01 (1.3710e-01) 
2023-05-27 06:45:07.513047: train Epoch: [11][  2/193]	Time  8.804 ( 6.901)	Data  8.242 ( 6.332)	Loss 1.0001e-01 (1.2474e-01) 
2023-05-27 06:45:08.075445: train Epoch: [11][  3/193]	Time  0.562 ( 5.316)	Data  0.001 ( 4.749)	Loss 1.2423e-01 (1.2461e-01) 
2023-05-27 06:45:17.267507: train Epoch: [11][  4/193]	Time  9.192 ( 6.091)	Data  8.627 ( 5.525)	Loss 1.0566e-01 (1.2082e-01) 
2023-05-27 06:45:17.905841: train Epoch: [11][  5/193]	Time  0.638 ( 5.182)	Data  0.076 ( 4.616)	Loss 8.7190e-02 (1.1522e-01) 
2023-05-27 06:45:27.151306: train Epoch: [11][  6/193]	Time  9.245 ( 5.763)	Data  8.679 ( 5.197)	Loss 1.2986e-01 (1.1731e-01) 
2023-05-27 06:45:27.713727: train Epoch: [11][  7/193]	Time  0.562 ( 5.113)	Data  0.001 ( 4.547)	Loss 1.1751e-01 (1.1733e-01) 
2023-05-27 06:45:37.151994: train Epoch: [11][  8/193]	Time  9.438 ( 5.593)	Data  8.877 ( 5.028)	Loss 1.1553e-01 (1.1713e-01) 
2023-05-27 06:45:37.714723: train Epoch: [11][  9/193]	Time  0.563 ( 5.090)	Data  0.001 ( 4.526)	Loss 1.1372e-01 (1.1679e-01) 
2023-05-27 06:45:46.931803: train Epoch: [11][ 10/193]	Time  9.217 ( 5.466)	Data  8.642 ( 4.900)	Loss 1.6737e-01 (1.2139e-01) 
2023-05-27 06:45:47.658011: train Epoch: [11][ 11/193]	Time  0.726 ( 5.071)	Data  0.149 ( 4.504)	Loss 1.4584e-01 (1.2343e-01) 
2023-05-27 06:45:57.026548: train Epoch: [11][ 12/193]	Time  9.369 ( 5.401)	Data  8.806 ( 4.835)	Loss 1.1071e-01 (1.2245e-01) 
2023-05-27 06:45:57.756215: train Epoch: [11][ 13/193]	Time  0.730 ( 5.068)	Data  0.167 ( 4.501)	Loss 1.2285e-01 (1.2248e-01) 
2023-05-27 06:46:07.629132: train Epoch: [11][ 14/193]	Time  9.873 ( 5.388)	Data  9.302 ( 4.821)	Loss 1.1023e-01 (1.2166e-01) 
2023-05-27 06:46:08.190838: train Epoch: [11][ 15/193]	Time  0.562 ( 5.086)	Data  0.001 ( 4.520)	Loss 1.6698e-01 (1.2449e-01) 
2023-05-27 06:46:17.376514: train Epoch: [11][ 16/193]	Time  9.186 ( 5.327)	Data  8.620 ( 4.761)	Loss 9.5888e-02 (1.2281e-01) 
2023-05-27 06:46:17.950817: train Epoch: [11][ 17/193]	Time  0.574 ( 5.063)	Data  0.001 ( 4.497)	Loss 1.1660e-01 (1.2246e-01) 
2023-05-27 06:46:27.215244: train Epoch: [11][ 18/193]	Time  9.264 ( 5.284)	Data  8.700 ( 4.718)	Loss 1.9490e-01 (1.2628e-01) 
2023-05-27 06:46:27.777302: train Epoch: [11][ 19/193]	Time  0.562 ( 5.048)	Data  0.001 ( 4.482)	Loss 3.6724e-01 (1.3833e-01) 
2023-05-27 06:46:37.343061: train Epoch: [11][ 20/193]	Time  9.566 ( 5.263)	Data  9.002 ( 4.697)	Loss 1.1212e-01 (1.3708e-01) 
2023-05-27 06:46:37.907122: train Epoch: [11][ 21/193]	Time  0.564 ( 5.050)	Data  0.001 ( 4.484)	Loss 1.3398e-01 (1.3694e-01) 
2023-05-27 06:46:47.303044: train Epoch: [11][ 22/193]	Time  9.396 ( 5.239)	Data  8.808 ( 4.672)	Loss 1.0870e-01 (1.3571e-01) 
2023-05-27 06:46:47.869303: train Epoch: [11][ 23/193]	Time  0.566 ( 5.044)	Data  0.001 ( 4.477)	Loss 1.2515e-01 (1.3527e-01) 
2023-05-27 06:46:57.477153: train Epoch: [11][ 24/193]	Time  9.608 ( 5.227)	Data  9.045 ( 4.660)	Loss 9.8548e-02 (1.3380e-01) 
2023-05-27 06:46:58.040359: train Epoch: [11][ 25/193]	Time  0.563 ( 5.047)	Data  0.001 ( 4.481)	Loss 1.5319e-01 (1.3455e-01) 
2023-05-27 06:47:06.637703: train Epoch: [11][ 26/193]	Time  8.597 ( 5.179)	Data  8.035 ( 4.612)	Loss 9.1448e-02 (1.3295e-01) 
2023-05-27 06:47:07.201306: train Epoch: [11][ 27/193]	Time  0.564 ( 5.014)	Data  0.001 ( 4.448)	Loss 9.5926e-02 (1.3163e-01) 
2023-05-27 06:47:15.233712: train Epoch: [11][ 28/193]	Time  8.032 ( 5.118)	Data  7.465 ( 4.552)	Loss 9.9915e-02 (1.3053e-01) 
2023-05-27 06:47:15.813035: train Epoch: [11][ 29/193]	Time  0.579 ( 4.967)	Data  0.001 ( 4.400)	Loss 1.2035e-01 (1.3019e-01) 
2023-05-27 06:47:24.844152: train Epoch: [11][ 30/193]	Time  9.031 ( 5.098)	Data  8.463 ( 4.531)	Loss 8.6191e-02 (1.2878e-01) 
2023-05-27 06:47:25.501227: train Epoch: [11][ 31/193]	Time  0.657 ( 4.959)	Data  0.088 ( 4.392)	Loss 7.1199e-02 (1.2698e-01) 
2023-05-27 06:47:34.721514: train Epoch: [11][ 32/193]	Time  9.220 ( 5.088)	Data  8.646 ( 4.521)	Loss 1.0372e-01 (1.2627e-01) 
2023-05-27 06:47:35.406614: train Epoch: [11][ 33/193]	Time  0.685 ( 4.959)	Data  0.121 ( 4.392)	Loss 9.2869e-02 (1.2529e-01) 
2023-05-27 06:47:44.502206: train Epoch: [11][ 34/193]	Time  9.096 ( 5.077)	Data  8.527 ( 4.510)	Loss 1.2801e-01 (1.2537e-01) 
2023-05-27 06:47:45.173645: train Epoch: [11][ 35/193]	Time  0.671 ( 4.955)	Data  0.089 ( 4.387)	Loss 1.1969e-01 (1.2521e-01) 
2023-05-27 06:47:53.956934: train Epoch: [11][ 36/193]	Time  8.783 ( 5.058)	Data  8.220 ( 4.491)	Loss 7.3982e-02 (1.2382e-01) 
2023-05-27 06:47:55.165883: train Epoch: [11][ 37/193]	Time  1.209 ( 4.957)	Data  0.642 ( 4.389)	Loss 1.3671e-01 (1.2416e-01) 
2023-05-27 06:48:03.785418: train Epoch: [11][ 38/193]	Time  8.620 ( 5.051)	Data  8.055 ( 4.483)	Loss 2.2416e-01 (1.2673e-01) 
2023-05-27 06:48:04.841365: train Epoch: [11][ 39/193]	Time  1.056 ( 4.951)	Data  0.492 ( 4.384)	Loss 1.1642e-01 (1.2647e-01) 
2023-05-27 06:48:13.465115: train Epoch: [11][ 40/193]	Time  8.624 ( 5.040)	Data  8.049 ( 4.473)	Loss 1.2068e-01 (1.2633e-01) 
2023-05-27 06:48:14.550977: train Epoch: [11][ 41/193]	Time  1.086 ( 4.946)	Data  0.507 ( 4.379)	Loss 8.8657e-02 (1.2543e-01) 
2023-05-27 06:48:23.507491: train Epoch: [11][ 42/193]	Time  8.957 ( 5.039)	Data  8.381 ( 4.472)	Loss 1.0906e-01 (1.2505e-01) 
2023-05-27 06:48:24.809055: train Epoch: [11][ 43/193]	Time  1.302 ( 4.954)	Data  0.737 ( 4.387)	Loss 1.3201e-01 (1.2521e-01) 
2023-05-27 06:48:33.536103: train Epoch: [11][ 44/193]	Time  8.727 ( 5.038)	Data  8.161 ( 4.471)	Loss 1.8601e-01 (1.2656e-01) 
2023-05-27 06:48:34.554681: train Epoch: [11][ 45/193]	Time  1.019 ( 4.951)	Data  0.453 ( 4.383)	Loss 5.0971e-02 (1.2492e-01) 
2023-05-27 06:48:43.436321: train Epoch: [11][ 46/193]	Time  8.882 ( 5.035)	Data  8.306 ( 4.467)	Loss 9.4668e-02 (1.2427e-01) 
2023-05-27 06:48:44.381738: train Epoch: [11][ 47/193]	Time  0.945 ( 4.949)	Data  0.361 ( 4.381)	Loss 1.2192e-01 (1.2422e-01) 
2023-05-27 06:48:53.154309: train Epoch: [11][ 48/193]	Time  8.773 ( 5.027)	Data  8.209 ( 4.459)	Loss 1.2732e-01 (1.2429e-01) 
2023-05-27 06:48:54.333058: train Epoch: [11][ 49/193]	Time  1.179 ( 4.950)	Data  0.615 ( 4.383)	Loss 8.6833e-02 (1.2354e-01) 
2023-05-27 06:49:03.232426: train Epoch: [11][ 50/193]	Time  8.899 ( 5.028)	Data  8.335 ( 4.460)	Loss 1.4808e-01 (1.2402e-01) 
2023-05-27 06:49:03.978242: train Epoch: [11][ 51/193]	Time  0.746 ( 4.946)	Data  0.183 ( 4.378)	Loss 9.7013e-02 (1.2350e-01) 
2023-05-27 06:49:12.910211: train Epoch: [11][ 52/193]	Time  8.932 ( 5.021)	Data  8.358 ( 4.453)	Loss 1.9953e-01 (1.2493e-01) 
2023-05-27 06:49:14.119196: train Epoch: [11][ 53/193]	Time  1.209 ( 4.950)	Data  0.645 ( 4.382)	Loss 1.1529e-01 (1.2476e-01) 
2023-05-27 06:49:21.728422: train Epoch: [11][ 54/193]	Time  7.609 ( 4.998)	Data  7.039 ( 4.431)	Loss 8.7393e-02 (1.2408e-01) 
2023-05-27 06:49:22.833105: train Epoch: [11][ 55/193]	Time  1.105 ( 4.929)	Data  0.533 ( 4.361)	Loss 1.3133e-01 (1.2421e-01) 
2023-05-27 06:49:31.594202: train Epoch: [11][ 56/193]	Time  8.761 ( 4.996)	Data  8.197 ( 4.428)	Loss 1.3293e-01 (1.2436e-01) 
2023-05-27 06:49:32.771981: train Epoch: [11][ 57/193]	Time  1.178 ( 4.930)	Data  0.615 ( 4.363)	Loss 1.0824e-01 (1.2408e-01) 
2023-05-27 06:49:41.438198: train Epoch: [11][ 58/193]	Time  8.666 ( 4.994)	Data  8.103 ( 4.426)	Loss 1.8706e-01 (1.2515e-01) 
2023-05-27 06:49:42.795193: train Epoch: [11][ 59/193]	Time  1.357 ( 4.933)	Data  0.787 ( 4.365)	Loss 1.3655e-01 (1.2534e-01) 
2023-05-27 06:49:51.456630: train Epoch: [11][ 60/193]	Time  8.661 ( 4.994)	Data  8.098 ( 4.427)	Loss 7.8793e-02 (1.2458e-01) 
2023-05-27 06:49:52.710258: train Epoch: [11][ 61/193]	Time  1.254 ( 4.934)	Data  0.689 ( 4.366)	Loss 1.4053e-01 (1.2483e-01) 
2023-05-27 06:50:01.322501: train Epoch: [11][ 62/193]	Time  8.612 ( 4.992)	Data  8.042 ( 4.425)	Loss 1.1780e-01 (1.2472e-01) 
2023-05-27 06:50:02.406182: train Epoch: [11][ 63/193]	Time  1.084 ( 4.931)	Data  0.519 ( 4.364)	Loss 1.5414e-01 (1.2518e-01) 
2023-05-27 06:50:10.571271: train Epoch: [11][ 64/193]	Time  8.165 ( 4.981)	Data  7.601 ( 4.413)	Loss 9.6416e-02 (1.2474e-01) 
2023-05-27 06:50:11.743234: train Epoch: [11][ 65/193]	Time  1.172 ( 4.923)	Data  0.608 ( 4.356)	Loss 8.0642e-02 (1.2407e-01) 
2023-05-27 06:50:20.319132: train Epoch: [11][ 66/193]	Time  8.576 ( 4.978)	Data  7.972 ( 4.410)	Loss 1.0392e-01 (1.2377e-01) 
2023-05-27 06:50:21.823187: train Epoch: [11][ 67/193]	Time  1.504 ( 4.927)	Data  0.941 ( 4.359)	Loss 1.6066e-01 (1.2431e-01) 
2023-05-27 06:50:30.130676: train Epoch: [11][ 68/193]	Time  8.307 ( 4.976)	Data  7.712 ( 4.407)	Loss 8.0862e-02 (1.2368e-01) 
2023-05-27 06:50:31.617647: train Epoch: [11][ 69/193]	Time  1.487 ( 4.926)	Data  0.924 ( 4.358)	Loss 1.2415e-01 (1.2369e-01) 
2023-05-27 06:50:40.127085: train Epoch: [11][ 70/193]	Time  8.509 ( 4.976)	Data  7.921 ( 4.408)	Loss 1.9762e-01 (1.2473e-01) 
2023-05-27 06:50:41.439354: train Epoch: [11][ 71/193]	Time  1.312 ( 4.925)	Data  0.750 ( 4.357)	Loss 5.3256e-02 (1.2374e-01) 
2023-05-27 06:50:50.527174: train Epoch: [11][ 72/193]	Time  9.088 ( 4.982)	Data  8.520 ( 4.414)	Loss 1.2118e-01 (1.2370e-01) 
2023-05-27 06:50:51.283579: train Epoch: [11][ 73/193]	Time  0.756 ( 4.925)	Data  0.195 ( 4.357)	Loss 6.3136e-02 (1.2288e-01) 
2023-05-27 06:51:00.691904: train Epoch: [11][ 74/193]	Time  9.408 ( 4.985)	Data  8.838 ( 4.417)	Loss 1.1576e-01 (1.2279e-01) 
2023-05-27 06:51:01.252647: train Epoch: [11][ 75/193]	Time  0.561 ( 4.927)	Data  0.001 ( 4.359)	Loss 1.2293e-01 (1.2279e-01) 
2023-05-27 06:51:11.031635: train Epoch: [11][ 76/193]	Time  9.779 ( 4.990)	Data  9.198 ( 4.421)	Loss 1.1831e-01 (1.2273e-01) 
2023-05-27 06:51:11.599764: train Epoch: [11][ 77/193]	Time  0.568 ( 4.933)	Data  0.001 ( 4.365)	Loss 7.6273e-02 (1.2214e-01) 
2023-05-27 06:51:21.009622: train Epoch: [11][ 78/193]	Time  9.410 ( 4.990)	Data  8.839 ( 4.421)	Loss 1.8653e-01 (1.2295e-01) 
2023-05-27 06:51:21.572600: train Epoch: [11][ 79/193]	Time  0.563 ( 4.935)	Data  0.001 ( 4.366)	Loss 9.0031e-02 (1.2254e-01) 
2023-05-27 06:51:30.504607: train Epoch: [11][ 80/193]	Time  8.932 ( 4.984)	Data  8.357 ( 4.415)	Loss 9.5230e-02 (1.2220e-01) 
2023-05-27 06:51:31.148571: train Epoch: [11][ 81/193]	Time  0.644 ( 4.931)	Data  0.071 ( 4.362)	Loss 8.0470e-02 (1.2170e-01) 
2023-05-27 06:51:40.863402: train Epoch: [11][ 82/193]	Time  9.715 ( 4.989)	Data  9.072 ( 4.419)	Loss 1.9407e-01 (1.2257e-01) 
2023-05-27 06:51:41.426193: train Epoch: [11][ 83/193]	Time  0.563 ( 4.936)	Data  0.001 ( 4.367)	Loss 1.1441e-01 (1.2247e-01) 
2023-05-27 06:51:50.913452: train Epoch: [11][ 84/193]	Time  9.487 ( 4.989)	Data  8.910 ( 4.420)	Loss 1.1176e-01 (1.2234e-01) 
2023-05-27 06:51:51.480974: train Epoch: [11][ 85/193]	Time  0.568 ( 4.938)	Data  0.001 ( 4.369)	Loss 1.1608e-01 (1.2227e-01) 
2023-05-27 06:52:00.797766: train Epoch: [11][ 86/193]	Time  9.317 ( 4.988)	Data  8.727 ( 4.419)	Loss 2.2587e-01 (1.2346e-01) 
2023-05-27 06:52:01.361847: train Epoch: [11][ 87/193]	Time  0.564 ( 4.938)	Data  0.001 ( 4.369)	Loss 1.6190e-01 (1.2390e-01) 
2023-05-27 06:52:11.149614: train Epoch: [11][ 88/193]	Time  9.788 ( 4.993)	Data  9.215 ( 4.423)	Loss 1.7002e-01 (1.2442e-01) 
2023-05-27 06:52:11.719219: train Epoch: [11][ 89/193]	Time  0.570 ( 4.943)	Data  0.001 ( 4.374)	Loss 1.2881e-01 (1.2447e-01) 
2023-05-27 06:52:20.843271: train Epoch: [11][ 90/193]	Time  9.124 ( 4.989)	Data  8.549 ( 4.420)	Loss 1.1031e-01 (1.2431e-01) 
2023-05-27 06:52:21.407347: train Epoch: [11][ 91/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.372)	Loss 7.4367e-02 (1.2377e-01) 
2023-05-27 06:52:30.778349: train Epoch: [11][ 92/193]	Time  9.371 ( 4.989)	Data  8.784 ( 4.419)	Loss 1.2511e-01 (1.2378e-01) 
2023-05-27 06:52:31.344405: train Epoch: [11][ 93/193]	Time  0.566 ( 4.942)	Data  0.001 ( 4.372)	Loss 1.6075e-01 (1.2418e-01) 
2023-05-27 06:52:40.242013: train Epoch: [11][ 94/193]	Time  8.898 ( 4.983)	Data  8.287 ( 4.413)	Loss 1.1399e-01 (1.2407e-01) 
2023-05-27 06:52:40.812692: train Epoch: [11][ 95/193]	Time  0.571 ( 4.938)	Data  0.001 ( 4.367)	Loss 8.7175e-02 (1.2368e-01) 
2023-05-27 06:52:48.829643: train Epoch: [11][ 96/193]	Time  8.017 ( 4.969)	Data  7.427 ( 4.399)	Loss 1.6935e-01 (1.2415e-01) 
2023-05-27 06:52:49.410120: train Epoch: [11][ 97/193]	Time  0.580 ( 4.924)	Data  0.001 ( 4.354)	Loss 8.4928e-02 (1.2375e-01) 
2023-05-27 06:52:57.965628: train Epoch: [11][ 98/193]	Time  8.556 ( 4.961)	Data  7.979 ( 4.391)	Loss 1.8572e-01 (1.2438e-01) 
2023-05-27 06:52:58.533643: train Epoch: [11][ 99/193]	Time  0.568 ( 4.917)	Data  0.001 ( 4.347)	Loss 4.1328e-01 (1.2727e-01) 
2023-05-27 06:53:08.422571: train Epoch: [11][100/193]	Time  9.889 ( 4.966)	Data  9.306 ( 4.396)	Loss 1.4921e-01 (1.2749e-01) 
2023-05-27 06:53:08.987285: train Epoch: [11][101/193]	Time  0.565 ( 4.923)	Data  0.001 ( 4.353)	Loss 1.4429e-01 (1.2765e-01) 
2023-05-27 06:53:18.311674: train Epoch: [11][102/193]	Time  9.324 ( 4.966)	Data  8.752 ( 4.395)	Loss 1.0436e-01 (1.2743e-01) 
2023-05-27 06:53:18.876697: train Epoch: [11][103/193]	Time  0.565 ( 4.924)	Data  0.001 ( 4.353)	Loss 1.7666e-01 (1.2790e-01) 
2023-05-27 06:53:28.617906: train Epoch: [11][104/193]	Time  9.741 ( 4.970)	Data  9.175 ( 4.399)	Loss 1.1205e-01 (1.2775e-01) 
2023-05-27 06:53:29.195246: train Epoch: [11][105/193]	Time  0.577 ( 4.928)	Data  0.001 ( 4.358)	Loss 1.4030e-01 (1.2787e-01) 
2023-05-27 06:53:38.446475: train Epoch: [11][106/193]	Time  9.251 ( 4.969)	Data  8.678 ( 4.398)	Loss 1.0324e-01 (1.2764e-01) 
2023-05-27 06:53:39.011584: train Epoch: [11][107/193]	Time  0.565 ( 4.928)	Data  0.001 ( 4.357)	Loss 1.0989e-01 (1.2747e-01) 
2023-05-27 06:53:48.759785: train Epoch: [11][108/193]	Time  9.748 ( 4.972)	Data  9.176 ( 4.402)	Loss 1.4375e-01 (1.2762e-01) 
2023-05-27 06:53:49.330823: train Epoch: [11][109/193]	Time  0.571 ( 4.932)	Data  0.001 ( 4.362)	Loss 6.1549e-02 (1.2702e-01) 
2023-05-27 06:53:59.048723: train Epoch: [11][110/193]	Time  9.718 ( 4.975)	Data  9.145 ( 4.405)	Loss 1.0562e-01 (1.2683e-01) 
2023-05-27 06:53:59.627156: train Epoch: [11][111/193]	Time  0.578 ( 4.936)	Data  0.001 ( 4.365)	Loss 8.5519e-02 (1.2646e-01) 
2023-05-27 06:54:08.794684: train Epoch: [11][112/193]	Time  9.168 ( 4.973)	Data  8.599 ( 4.403)	Loss 1.4405e-01 (1.2661e-01) 
2023-05-27 06:54:09.370754: train Epoch: [11][113/193]	Time  0.576 ( 4.935)	Data  0.001 ( 4.364)	Loss 1.1368e-01 (1.2650e-01) 
2023-05-27 06:54:19.072155: train Epoch: [11][114/193]	Time  9.701 ( 4.976)	Data  9.131 ( 4.406)	Loss 1.3246e-01 (1.2655e-01) 
2023-05-27 06:54:19.657048: train Epoch: [11][115/193]	Time  0.585 ( 4.938)	Data  0.001 ( 4.368)	Loss 8.6746e-02 (1.2621e-01) 
2023-05-27 06:54:28.924265: train Epoch: [11][116/193]	Time  9.267 ( 4.975)	Data  8.704 ( 4.405)	Loss 8.5293e-02 (1.2586e-01) 
2023-05-27 06:54:29.488659: train Epoch: [11][117/193]	Time  0.564 ( 4.938)	Data  0.001 ( 4.367)	Loss 2.0444e-01 (1.2653e-01) 
2023-05-27 06:54:39.195759: train Epoch: [11][118/193]	Time  9.707 ( 4.978)	Data  9.135 ( 4.407)	Loss 1.0611e-01 (1.2635e-01) 
2023-05-27 06:54:39.773369: train Epoch: [11][119/193]	Time  0.578 ( 4.941)	Data  0.001 ( 4.371)	Loss 1.1065e-01 (1.2622e-01) 
2023-05-27 06:54:49.439336: train Epoch: [11][120/193]	Time  9.666 ( 4.980)	Data  9.089 ( 4.410)	Loss 7.6402e-02 (1.2581e-01) 
2023-05-27 06:54:50.011755: train Epoch: [11][121/193]	Time  0.572 ( 4.944)	Data  0.001 ( 4.374)	Loss 1.7316e-01 (1.2620e-01) 
2023-05-27 06:54:59.572526: train Epoch: [11][122/193]	Time  9.561 ( 4.982)	Data  8.991 ( 4.411)	Loss 1.5123e-01 (1.2640e-01) 
2023-05-27 06:55:00.139538: train Epoch: [11][123/193]	Time  0.567 ( 4.946)	Data  0.001 ( 4.376)	Loss 8.2702e-02 (1.2605e-01) 
2023-05-27 06:55:09.834519: train Epoch: [11][124/193]	Time  9.695 ( 4.984)	Data  9.126 ( 4.414)	Loss 1.5278e-01 (1.2626e-01) 
2023-05-27 06:55:10.402436: train Epoch: [11][125/193]	Time  0.568 ( 4.949)	Data  0.001 ( 4.379)	Loss 8.3579e-02 (1.2593e-01) 
2023-05-27 06:55:19.859113: train Epoch: [11][126/193]	Time  9.457 ( 4.985)	Data  8.891 ( 4.414)	Loss 8.3790e-02 (1.2559e-01) 
2023-05-27 06:55:20.420870: train Epoch: [11][127/193]	Time  0.562 ( 4.950)	Data  0.001 ( 4.380)	Loss 7.1242e-02 (1.2517e-01) 
2023-05-27 06:55:29.549039: train Epoch: [11][128/193]	Time  9.128 ( 4.982)	Data  8.556 ( 4.412)	Loss 1.2844e-01 (1.2519e-01) 
2023-05-27 06:55:30.112242: train Epoch: [11][129/193]	Time  0.563 ( 4.948)	Data  0.001 ( 4.378)	Loss 9.7298e-02 (1.2498e-01) 
2023-05-27 06:55:39.913561: train Epoch: [11][130/193]	Time  9.801 ( 4.986)	Data  9.238 ( 4.415)	Loss 1.1973e-01 (1.2494e-01) 
2023-05-27 06:55:40.475976: train Epoch: [11][131/193]	Time  0.562 ( 4.952)	Data  0.001 ( 4.382)	Loss 1.6131e-01 (1.2522e-01) 
2023-05-27 06:55:49.995725: train Epoch: [11][132/193]	Time  9.520 ( 4.986)	Data  8.957 ( 4.416)	Loss 1.4049e-01 (1.2533e-01) 
2023-05-27 06:55:50.557920: train Epoch: [11][133/193]	Time  0.562 ( 4.953)	Data  0.001 ( 4.383)	Loss 7.0690e-02 (1.2492e-01) 
2023-05-27 06:55:59.773547: train Epoch: [11][134/193]	Time  9.216 ( 4.985)	Data  8.651 ( 4.415)	Loss 1.7229e-01 (1.2527e-01) 
2023-05-27 06:56:00.344122: train Epoch: [11][135/193]	Time  0.571 ( 4.952)	Data  0.001 ( 4.382)	Loss 1.4067e-01 (1.2539e-01) 
2023-05-27 06:56:09.707893: train Epoch: [11][136/193]	Time  9.364 ( 4.985)	Data  8.790 ( 4.414)	Loss 1.1259e-01 (1.2529e-01) 
2023-05-27 06:56:10.283833: train Epoch: [11][137/193]	Time  0.576 ( 4.953)	Data  0.001 ( 4.382)	Loss 9.2968e-02 (1.2506e-01) 
2023-05-27 06:56:20.152282: train Epoch: [11][138/193]	Time  9.868 ( 4.988)	Data  9.306 ( 4.418)	Loss 1.2143e-01 (1.2503e-01) 
2023-05-27 06:56:20.718663: train Epoch: [11][139/193]	Time  0.566 ( 4.956)	Data  0.001 ( 4.386)	Loss 1.5679e-01 (1.2526e-01) 
2023-05-27 06:56:30.842564: train Epoch: [11][140/193]	Time 10.124 ( 4.993)	Data  9.557 ( 4.423)	Loss 8.4070e-02 (1.2497e-01) 
2023-05-27 06:56:31.417542: train Epoch: [11][141/193]	Time  0.575 ( 4.962)	Data  0.001 ( 4.392)	Loss 1.0634e-01 (1.2484e-01) 
2023-05-27 06:56:40.474740: train Epoch: [11][142/193]	Time  9.057 ( 4.991)	Data  8.470 ( 4.420)	Loss 7.9737e-02 (1.2452e-01) 
2023-05-27 06:56:41.062749: train Epoch: [11][143/193]	Time  0.588 ( 4.960)	Data  0.001 ( 4.390)	Loss 1.4028e-01 (1.2463e-01) 
2023-05-27 06:56:50.138184: train Epoch: [11][144/193]	Time  9.075 ( 4.988)	Data  8.502 ( 4.418)	Loss 1.8917e-01 (1.2508e-01) 
2023-05-27 06:56:50.708550: train Epoch: [11][145/193]	Time  0.570 ( 4.958)	Data  0.001 ( 4.388)	Loss 1.1144e-01 (1.2498e-01) 
2023-05-27 06:57:00.197279: train Epoch: [11][146/193]	Time  9.489 ( 4.989)	Data  8.923 ( 4.419)	Loss 1.3247e-01 (1.2503e-01) 
2023-05-27 06:57:00.775505: train Epoch: [11][147/193]	Time  0.578 ( 4.959)	Data  0.001 ( 4.389)	Loss 1.4447e-01 (1.2516e-01) 
2023-05-27 06:57:10.757684: train Epoch: [11][148/193]	Time  9.982 ( 4.993)	Data  9.400 ( 4.422)	Loss 2.1875e-01 (1.2579e-01) 
2023-05-27 06:57:11.370022: train Epoch: [11][149/193]	Time  0.612 ( 4.964)	Data  0.001 ( 4.393)	Loss 1.7830e-01 (1.2614e-01) 
2023-05-27 06:57:20.844003: train Epoch: [11][150/193]	Time  9.474 ( 4.994)	Data  8.899 ( 4.423)	Loss 8.8093e-02 (1.2589e-01) 
2023-05-27 06:57:21.418387: train Epoch: [11][151/193]	Time  0.574 ( 4.965)	Data  0.001 ( 4.394)	Loss 9.3352e-02 (1.2568e-01) 
2023-05-27 06:57:30.979675: train Epoch: [11][152/193]	Time  9.561 ( 4.995)	Data  8.988 ( 4.424)	Loss 3.4147e-01 (1.2709e-01) 
2023-05-27 06:57:31.543347: train Epoch: [11][153/193]	Time  0.564 ( 4.966)	Data  0.001 ( 4.395)	Loss 1.3243e-01 (1.2712e-01) 
2023-05-27 06:57:41.116210: train Epoch: [11][154/193]	Time  9.573 ( 4.996)	Data  8.993 ( 4.425)	Loss 1.9953e-01 (1.2759e-01) 
2023-05-27 06:57:41.679278: train Epoch: [11][155/193]	Time  0.563 ( 4.967)	Data  0.001 ( 4.396)	Loss 1.1896e-01 (1.2753e-01) 
2023-05-27 06:57:50.652611: train Epoch: [11][156/193]	Time  8.973 ( 4.993)	Data  8.400 ( 4.422)	Loss 1.3810e-01 (1.2760e-01) 
2023-05-27 06:57:51.217053: train Epoch: [11][157/193]	Time  0.564 ( 4.965)	Data  0.001 ( 4.394)	Loss 1.1466e-01 (1.2752e-01) 
2023-05-27 06:58:00.683622: train Epoch: [11][158/193]	Time  9.467 ( 4.993)	Data  8.896 ( 4.422)	Loss 3.7349e-01 (1.2907e-01) 
2023-05-27 06:58:01.250398: train Epoch: [11][159/193]	Time  0.567 ( 4.965)	Data  0.001 ( 4.395)	Loss 1.2777e-01 (1.2906e-01) 
2023-05-27 06:58:10.911432: train Epoch: [11][160/193]	Time  9.661 ( 4.994)	Data  9.089 ( 4.424)	Loss 1.5971e-01 (1.2925e-01) 
2023-05-27 06:58:11.481439: train Epoch: [11][161/193]	Time  0.570 ( 4.967)	Data  0.001 ( 4.396)	Loss 1.4889e-01 (1.2937e-01) 
2023-05-27 06:58:20.818722: train Epoch: [11][162/193]	Time  9.337 ( 4.994)	Data  8.764 ( 4.423)	Loss 1.4645e-01 (1.2947e-01) 
2023-05-27 06:58:21.381924: train Epoch: [11][163/193]	Time  0.563 ( 4.967)	Data  0.001 ( 4.396)	Loss 1.4204e-01 (1.2955e-01) 
2023-05-27 06:58:30.722363: train Epoch: [11][164/193]	Time  9.340 ( 4.993)	Data  8.777 ( 4.423)	Loss 1.1205e-01 (1.2944e-01) 
2023-05-27 06:58:31.285982: train Epoch: [11][165/193]	Time  0.564 ( 4.967)	Data  0.001 ( 4.396)	Loss 2.3509e-01 (1.3008e-01) 
2023-05-27 06:58:40.412021: train Epoch: [11][166/193]	Time  9.126 ( 4.992)	Data  8.561 ( 4.421)	Loss 1.0582e-01 (1.2994e-01) 
2023-05-27 06:58:40.989731: train Epoch: [11][167/193]	Time  0.578 ( 4.965)	Data  0.001 ( 4.395)	Loss 1.0541e-01 (1.2979e-01) 
2023-05-27 06:58:50.494883: train Epoch: [11][168/193]	Time  9.505 ( 4.992)	Data  8.940 ( 4.422)	Loss 1.4126e-01 (1.2986e-01) 
2023-05-27 06:58:51.064549: train Epoch: [11][169/193]	Time  0.570 ( 4.966)	Data  0.001 ( 4.396)	Loss 1.3080e-01 (1.2986e-01) 
2023-05-27 06:59:00.648501: train Epoch: [11][170/193]	Time  9.584 ( 4.993)	Data  9.010 ( 4.423)	Loss 1.7182e-01 (1.3011e-01) 
2023-05-27 06:59:01.216648: train Epoch: [11][171/193]	Time  0.568 ( 4.967)	Data  0.001 ( 4.397)	Loss 1.5078e-01 (1.3023e-01) 
2023-05-27 06:59:10.606174: train Epoch: [11][172/193]	Time  9.390 ( 4.993)	Data  8.809 ( 4.422)	Loss 1.3205e-01 (1.3024e-01) 
2023-05-27 06:59:11.173733: train Epoch: [11][173/193]	Time  0.568 ( 4.968)	Data  0.001 ( 4.397)	Loss 1.3041e-01 (1.3024e-01) 
2023-05-27 06:59:20.386748: train Epoch: [11][174/193]	Time  9.213 ( 4.992)	Data  8.636 ( 4.421)	Loss 1.5695e-01 (1.3039e-01) 
2023-05-27 06:59:20.950902: train Epoch: [11][175/193]	Time  0.564 ( 4.967)	Data  0.001 ( 4.396)	Loss 1.2370e-01 (1.3035e-01) 
2023-05-27 06:59:30.240341: train Epoch: [11][176/193]	Time  9.289 ( 4.991)	Data  8.711 ( 4.420)	Loss 9.8710e-02 (1.3018e-01) 
2023-05-27 06:59:30.812339: train Epoch: [11][177/193]	Time  0.572 ( 4.966)	Data  0.001 ( 4.396)	Loss 1.9298e-01 (1.3053e-01) 
2023-05-27 06:59:40.115408: train Epoch: [11][178/193]	Time  9.303 ( 4.991)	Data  8.721 ( 4.420)	Loss 1.6455e-01 (1.3072e-01) 
2023-05-27 06:59:40.682477: train Epoch: [11][179/193]	Time  0.567 ( 4.966)	Data  0.001 ( 4.395)	Loss 1.2085e-01 (1.3066e-01) 
2023-05-27 06:59:49.985850: train Epoch: [11][180/193]	Time  9.303 ( 4.990)	Data  8.740 ( 4.419)	Loss 8.9808e-02 (1.3044e-01) 
2023-05-27 06:59:50.548390: train Epoch: [11][181/193]	Time  0.563 ( 4.966)	Data  0.001 ( 4.395)	Loss 1.6547e-01 (1.3063e-01) 
2023-05-27 06:59:59.758550: train Epoch: [11][182/193]	Time  9.210 ( 4.989)	Data  8.644 ( 4.418)	Loss 1.8626e-01 (1.3093e-01) 
2023-05-27 07:00:00.321780: train Epoch: [11][183/193]	Time  0.563 ( 4.965)	Data  0.001 ( 4.394)	Loss 6.6082e-02 (1.3058e-01) 
2023-05-27 07:00:09.744349: train Epoch: [11][184/193]	Time  9.423 ( 4.989)	Data  8.848 ( 4.418)	Loss 2.6039e-01 (1.3128e-01) 
2023-05-27 07:00:10.312191: train Epoch: [11][185/193]	Time  0.568 ( 4.965)	Data  0.001 ( 4.395)	Loss 1.7737e-01 (1.3153e-01) 
2023-05-27 07:00:19.905661: train Epoch: [11][186/193]	Time  9.593 ( 4.990)	Data  9.029 ( 4.419)	Loss 1.4030e-01 (1.3158e-01) 
2023-05-27 07:00:20.470772: train Epoch: [11][187/193]	Time  0.565 ( 4.966)	Data  0.001 ( 4.396)	Loss 1.2198e-01 (1.3153e-01) 
2023-05-27 07:00:30.304121: train Epoch: [11][188/193]	Time  9.833 ( 4.992)	Data  9.264 ( 4.422)	Loss 1.7583e-01 (1.3176e-01) 
2023-05-27 07:00:30.869424: train Epoch: [11][189/193]	Time  0.565 ( 4.969)	Data  0.001 ( 4.398)	Loss 1.2739e-01 (1.3174e-01) 
2023-05-27 07:00:39.614694: train Epoch: [11][190/193]	Time  8.745 ( 4.988)	Data  8.161 ( 4.418)	Loss 8.7594e-02 (1.3151e-01) 
2023-05-27 07:00:40.189505: train Epoch: [11][191/193]	Time  0.575 ( 4.966)	Data  0.001 ( 4.395)	Loss 1.2076e-01 (1.3145e-01) 
2023-05-27 07:00:48.325576: train Epoch: [11][192/193]	Time  8.136 ( 4.982)	Data  7.538 ( 4.411)	Loss 1.5538e-01 (1.3158e-01) 
2023-05-27 07:00:48.500431: Train Epoch done in 961.6899599619792 s 
2023-05-27 07:00:55.085707: val Epoch: [11][ 0/72]	Time  5.823 ( 5.823)	Data  5.649 ( 5.649)	Loss 1.1932e-01 (1.1932e-01) 
2023-05-27 07:00:55.202268: val Epoch: [11][ 1/72]	Time  0.117 ( 2.970)	Data  0.001 ( 2.825)	Loss 1.4507e-01 (1.3220e-01) 
2023-05-27 07:01:00.001505: val Epoch: [11][ 2/72]	Time  4.799 ( 3.580)	Data  4.678 ( 3.443)	Loss 1.0195e-01 (1.2211e-01) 
2023-05-27 07:01:00.123137: val Epoch: [11][ 3/72]	Time  0.122 ( 2.715)	Data  0.001 ( 2.582)	Loss 9.3014e-02 (1.1484e-01) 
2023-05-27 07:01:05.098717: val Epoch: [11][ 4/72]	Time  4.976 ( 3.167)	Data  4.850 ( 3.036)	Loss 3.6065e-01 (1.6400e-01) 
2023-05-27 07:01:05.213881: val Epoch: [11][ 5/72]	Time  0.115 ( 2.659)	Data  0.001 ( 2.530)	Loss 1.3665e-01 (1.5944e-01) 
2023-05-27 07:01:10.259673: val Epoch: [11][ 6/72]	Time  5.046 ( 3.000)	Data  4.939 ( 2.874)	Loss 1.9100e-01 (1.6395e-01) 
2023-05-27 07:01:10.367073: val Epoch: [11][ 7/72]	Time  0.107 ( 2.638)	Data  0.001 ( 2.515)	Loss 2.3930e-01 (1.7337e-01) 
2023-05-27 07:01:15.292557: val Epoch: [11][ 8/72]	Time  4.925 ( 2.892)	Data  4.818 ( 2.771)	Loss 1.9583e-01 (1.7586e-01) 
2023-05-27 07:01:15.399741: val Epoch: [11][ 9/72]	Time  0.107 ( 2.614)	Data  0.001 ( 2.494)	Loss 9.5792e-02 (1.6786e-01) 
2023-05-27 07:01:20.165262: val Epoch: [11][10/72]	Time  4.766 ( 2.809)	Data  4.659 ( 2.691)	Loss 3.6209e-01 (1.8551e-01) 
2023-05-27 07:01:20.272915: val Epoch: [11][11/72]	Time  0.108 ( 2.584)	Data  0.000 ( 2.466)	Loss 1.0274e-01 (1.7862e-01) 
2023-05-27 07:01:25.164001: val Epoch: [11][12/72]	Time  4.891 ( 2.762)	Data  4.784 ( 2.645)	Loss 8.7845e-02 (1.7163e-01) 
2023-05-27 07:01:25.271081: val Epoch: [11][13/72]	Time  0.107 ( 2.572)	Data  0.000 ( 2.456)	Loss 1.8262e-01 (1.7242e-01) 
2023-05-27 07:01:30.349212: val Epoch: [11][14/72]	Time  5.078 ( 2.739)	Data  4.966 ( 2.623)	Loss 1.2789e-01 (1.6945e-01) 
2023-05-27 07:01:30.458841: val Epoch: [11][15/72]	Time  0.110 ( 2.575)	Data  0.000 ( 2.459)	Loss 1.2272e-01 (1.6653e-01) 
2023-05-27 07:01:35.573761: val Epoch: [11][16/72]	Time  5.115 ( 2.724)	Data  5.000 ( 2.609)	Loss 4.7554e-01 (1.8471e-01) 
2023-05-27 07:01:35.694643: val Epoch: [11][17/72]	Time  0.121 ( 2.580)	Data  0.001 ( 2.464)	Loss 3.4581e-01 (1.9366e-01) 
2023-05-27 07:01:40.439254: val Epoch: [11][18/72]	Time  4.745 ( 2.694)	Data  4.637 ( 2.578)	Loss 2.3815e-01 (1.9600e-01) 
2023-05-27 07:01:40.547345: val Epoch: [11][19/72]	Time  0.108 ( 2.564)	Data  0.001 ( 2.449)	Loss 1.1803e-01 (1.9210e-01) 
2023-05-27 07:01:45.598655: val Epoch: [11][20/72]	Time  5.051 ( 2.683)	Data  4.943 ( 2.568)	Loss 1.7576e-01 (1.9132e-01) 
2023-05-27 07:01:45.710297: val Epoch: [11][21/72]	Time  0.112 ( 2.566)	Data  0.001 ( 2.451)	Loss 1.7470e-01 (1.9057e-01) 
2023-05-27 07:01:50.395302: val Epoch: [11][22/72]	Time  4.685 ( 2.658)	Data  4.566 ( 2.543)	Loss 7.4815e-02 (1.8553e-01) 
2023-05-27 07:01:50.508030: val Epoch: [11][23/72]	Time  0.113 ( 2.552)	Data  0.001 ( 2.437)	Loss 2.1719e-01 (1.8685e-01) 
2023-05-27 07:01:55.256383: val Epoch: [11][24/72]	Time  4.748 ( 2.640)	Data  4.640 ( 2.525)	Loss 1.2167e-01 (1.8425e-01) 
2023-05-27 07:01:55.364724: val Epoch: [11][25/72]	Time  0.108 ( 2.542)	Data  0.001 ( 2.428)	Loss 4.5969e-01 (1.9484e-01) 
2023-05-27 07:02:00.201498: val Epoch: [11][26/72]	Time  4.837 ( 2.627)	Data  4.718 ( 2.513)	Loss 9.7770e-02 (1.9125e-01) 
2023-05-27 07:02:00.371721: val Epoch: [11][27/72]	Time  0.170 ( 2.540)	Data  0.063 ( 2.426)	Loss 4.7421e-01 (2.0135e-01) 
2023-05-27 07:02:05.085578: val Epoch: [11][28/72]	Time  4.714 ( 2.615)	Data  4.558 ( 2.499)	Loss 9.3666e-02 (1.9764e-01) 
2023-05-27 07:02:05.375988: val Epoch: [11][29/72]	Time  0.290 ( 2.537)	Data  0.146 ( 2.421)	Loss 9.9560e-02 (1.9437e-01) 
2023-05-27 07:02:10.294400: val Epoch: [11][30/72]	Time  4.918 ( 2.614)	Data  4.807 ( 2.498)	Loss 8.9855e-02 (1.9100e-01) 
2023-05-27 07:02:10.426508: val Epoch: [11][31/72]	Time  0.132 ( 2.536)	Data  0.025 ( 2.420)	Loss 8.0067e-02 (1.8753e-01) 
2023-05-27 07:02:15.245403: val Epoch: [11][32/72]	Time  4.819 ( 2.606)	Data  4.706 ( 2.490)	Loss 1.7129e-01 (1.8704e-01) 
2023-05-27 07:02:15.458071: val Epoch: [11][33/72]	Time  0.213 ( 2.535)	Data  0.104 ( 2.420)	Loss 4.2484e-01 (1.9403e-01) 
2023-05-27 07:02:20.158359: val Epoch: [11][34/72]	Time  4.700 ( 2.597)	Data  4.585 ( 2.481)	Loss 9.6002e-02 (1.9123e-01) 
2023-05-27 07:02:20.412964: val Epoch: [11][35/72]	Time  0.255 ( 2.532)	Data  0.136 ( 2.416)	Loss 8.1443e-02 (1.8818e-01) 
2023-05-27 07:02:25.320259: val Epoch: [11][36/72]	Time  4.907 ( 2.596)	Data  4.794 ( 2.480)	Loss 1.6727e-01 (1.8762e-01) 
2023-05-27 07:02:25.627870: val Epoch: [11][37/72]	Time  0.308 ( 2.536)	Data  0.200 ( 2.420)	Loss 1.7167e-01 (1.8720e-01) 
2023-05-27 07:02:30.318872: val Epoch: [11][38/72]	Time  4.691 ( 2.591)	Data  4.579 ( 2.476)	Loss 8.1667e-02 (1.8449e-01) 
2023-05-27 07:02:30.600574: val Epoch: [11][39/72]	Time  0.282 ( 2.533)	Data  0.174 ( 2.418)	Loss 1.9319e-01 (1.8471e-01) 
2023-05-27 07:02:35.278870: val Epoch: [11][40/72]	Time  4.678 ( 2.586)	Data  4.504 ( 2.469)	Loss 1.5827e-01 (1.8406e-01) 
2023-05-27 07:02:35.754589: val Epoch: [11][41/72]	Time  0.476 ( 2.536)	Data  0.364 ( 2.419)	Loss 2.3736e-01 (1.8533e-01) 
2023-05-27 07:02:40.462636: val Epoch: [11][42/72]	Time  4.708 ( 2.586)	Data  4.598 ( 2.470)	Loss 8.4812e-02 (1.8300e-01) 
2023-05-27 07:02:40.803322: val Epoch: [11][43/72]	Time  0.341 ( 2.535)	Data  0.230 ( 2.419)	Loss 5.2981e-01 (1.9088e-01) 
2023-05-27 07:02:45.695115: val Epoch: [11][44/72]	Time  4.892 ( 2.587)	Data  4.781 ( 2.471)	Loss 1.2289e-01 (1.8937e-01) 
2023-05-27 07:02:45.801909: val Epoch: [11][45/72]	Time  0.107 ( 2.533)	Data  0.000 ( 2.418)	Loss 1.2709e-01 (1.8801e-01) 
2023-05-27 07:02:50.733651: val Epoch: [11][46/72]	Time  4.932 ( 2.584)	Data  4.817 ( 2.469)	Loss 1.3675e-01 (1.8692e-01) 
2023-05-27 07:02:50.845605: val Epoch: [11][47/72]	Time  0.112 ( 2.533)	Data  0.001 ( 2.417)	Loss 7.4179e-02 (1.8457e-01) 
2023-05-27 07:02:55.986266: val Epoch: [11][48/72]	Time  5.141 ( 2.586)	Data  5.034 ( 2.471)	Loss 2.1480e-01 (1.8519e-01) 
2023-05-27 07:02:56.093836: val Epoch: [11][49/72]	Time  0.108 ( 2.537)	Data  0.000 ( 2.421)	Loss 1.1210e-01 (1.8373e-01) 
2023-05-27 07:03:00.821482: val Epoch: [11][50/72]	Time  4.728 ( 2.580)	Data  4.615 ( 2.464)	Loss 1.7440e-01 (1.8355e-01) 
2023-05-27 07:03:00.930369: val Epoch: [11][51/72]	Time  0.109 ( 2.532)	Data  0.000 ( 2.417)	Loss 1.8667e-01 (1.8361e-01) 
2023-05-27 07:03:05.904732: val Epoch: [11][52/72]	Time  4.974 ( 2.578)	Data  4.866 ( 2.463)	Loss 1.2422e-01 (1.8249e-01) 
2023-05-27 07:03:06.012033: val Epoch: [11][53/72]	Time  0.107 ( 2.532)	Data  0.000 ( 2.417)	Loss 1.1337e-01 (1.8121e-01) 
2023-05-27 07:03:11.456438: val Epoch: [11][54/72]	Time  5.444 ( 2.585)	Data  5.337 ( 2.471)	Loss 2.5053e-01 (1.8247e-01) 
2023-05-27 07:03:11.564728: val Epoch: [11][55/72]	Time  0.108 ( 2.541)	Data  0.001 ( 2.426)	Loss 7.3075e-02 (1.8051e-01) 
2023-05-27 07:03:16.455810: val Epoch: [11][56/72]	Time  4.891 ( 2.582)	Data  4.780 ( 2.468)	Loss 5.2627e-01 (1.8658e-01) 
2023-05-27 07:03:16.567500: val Epoch: [11][57/72]	Time  0.112 ( 2.540)	Data  0.001 ( 2.425)	Loss 2.1311e-01 (1.8704e-01) 
2023-05-27 07:03:21.739479: val Epoch: [11][58/72]	Time  5.172 ( 2.584)	Data  5.061 ( 2.470)	Loss 3.7163e-01 (1.9016e-01) 
2023-05-27 07:03:21.850955: val Epoch: [11][59/72]	Time  0.111 ( 2.543)	Data  0.001 ( 2.429)	Loss 1.6130e-01 (1.8968e-01) 
2023-05-27 07:03:26.771227: val Epoch: [11][60/72]	Time  4.920 ( 2.582)	Data  4.808 ( 2.468)	Loss 1.7008e-01 (1.8936e-01) 
2023-05-27 07:03:26.882191: val Epoch: [11][61/72]	Time  0.111 ( 2.542)	Data  0.001 ( 2.428)	Loss 6.4559e-02 (1.8735e-01) 
2023-05-27 07:03:31.856867: val Epoch: [11][62/72]	Time  4.975 ( 2.581)	Data  4.863 ( 2.467)	Loss 9.1934e-02 (1.8583e-01) 
2023-05-27 07:03:31.968477: val Epoch: [11][63/72]	Time  0.112 ( 2.542)	Data  0.001 ( 2.428)	Loss 3.9744e-01 (1.8914e-01) 
2023-05-27 07:03:36.825652: val Epoch: [11][64/72]	Time  4.857 ( 2.578)	Data  4.746 ( 2.464)	Loss 1.9125e-01 (1.8917e-01) 
2023-05-27 07:03:36.936929: val Epoch: [11][65/72]	Time  0.111 ( 2.541)	Data  0.001 ( 2.426)	Loss 1.1767e-01 (1.8809e-01) 
2023-05-27 07:03:41.535842: val Epoch: [11][66/72]	Time  4.599 ( 2.571)	Data  4.488 ( 2.457)	Loss 1.7078e-01 (1.8783e-01) 
2023-05-27 07:03:41.647216: val Epoch: [11][67/72]	Time  0.111 ( 2.535)	Data  0.001 ( 2.421)	Loss 1.1487e-01 (1.8676e-01) 
2023-05-27 07:03:46.464246: val Epoch: [11][68/72]	Time  4.817 ( 2.568)	Data  4.700 ( 2.454)	Loss 7.6493e-02 (1.8516e-01) 
2023-05-27 07:03:46.579467: val Epoch: [11][69/72]	Time  0.115 ( 2.533)	Data  0.000 ( 2.419)	Loss 2.5132e-01 (1.8611e-01) 
2023-05-27 07:03:51.455740: val Epoch: [11][70/72]	Time  4.876 ( 2.566)	Data  4.767 ( 2.452)	Loss 1.8654e-01 (1.8611e-01) 
2023-05-27 07:03:51.565211: val Epoch: [11][71/72]	Time  0.109 ( 2.532)	Data  0.000 ( 2.418)	Loss 9.2069e-02 (1.8481e-01) 
2023-05-27 07:03:51.842317: Epoch 11 :Val : ['ET : 0.6486930251121521', 'TC : 0.6957099437713623', 'WT : 0.7922145128250122'] 
2023-05-27 07:03:51.844958: Epoch 11 :Val : ['ET : 0.6486930251121521', 'TC : 0.6957099437713623', 'WT : 0.7922145128250122'] 
2023-05-27 07:03:51.846913: Val epoch done in 183.34648667700822 s 
2023-05-27 07:03:51.852550: Batches per epoch:  193 
2023-05-27 07:04:02.770929: train Epoch: [12][  0/193]	Time 10.918 (10.918)	Data 10.314 (10.314)	Loss 1.6765e-01 (1.6765e-01) 
2023-05-27 07:04:03.349314: train Epoch: [12][  1/193]	Time  0.578 ( 5.748)	Data  0.001 ( 5.158)	Loss 1.3646e-01 (1.5205e-01) 
2023-05-27 07:04:12.701216: train Epoch: [12][  2/193]	Time  9.352 ( 6.949)	Data  8.781 ( 6.365)	Loss 2.0752e-01 (1.7054e-01) 
2023-05-27 07:04:13.287524: train Epoch: [12][  3/193]	Time  0.586 ( 5.359)	Data  0.001 ( 4.774)	Loss 1.3837e-01 (1.6250e-01) 
2023-05-27 07:04:22.272087: train Epoch: [12][  4/193]	Time  8.985 ( 6.084)	Data  8.420 ( 5.504)	Loss 1.3935e-01 (1.5787e-01) 
2023-05-27 07:04:22.875063: train Epoch: [12][  5/193]	Time  0.603 ( 5.170)	Data  0.037 ( 4.592)	Loss 9.6069e-02 (1.4757e-01) 
2023-05-27 07:04:32.399705: train Epoch: [12][  6/193]	Time  9.525 ( 5.792)	Data  8.946 ( 5.214)	Loss 1.5922e-01 (1.4923e-01) 
2023-05-27 07:04:33.026895: train Epoch: [12][  7/193]	Time  0.627 ( 5.147)	Data  0.037 ( 4.567)	Loss 1.2116e-01 (1.4572e-01) 
2023-05-27 07:04:42.206190: train Epoch: [12][  8/193]	Time  9.179 ( 5.595)	Data  8.607 ( 5.016)	Loss 8.9979e-02 (1.3953e-01) 
2023-05-27 07:04:43.240999: train Epoch: [12][  9/193]	Time  1.035 ( 5.139)	Data  0.470 ( 4.561)	Loss 9.8596e-02 (1.3544e-01) 
2023-05-27 07:04:52.130670: train Epoch: [12][ 10/193]	Time  8.890 ( 5.480)	Data  8.313 ( 4.902)	Loss 1.5502e-01 (1.3722e-01) 
2023-05-27 07:04:52.916603: train Epoch: [12][ 11/193]	Time  0.786 ( 5.089)	Data  0.208 ( 4.511)	Loss 1.4138e-01 (1.3756e-01) 
2023-05-27 07:05:02.608873: train Epoch: [12][ 12/193]	Time  9.692 ( 5.443)	Data  9.096 ( 4.864)	Loss 9.8368e-02 (1.3455e-01) 
2023-05-27 07:05:03.179923: train Epoch: [12][ 13/193]	Time  0.571 ( 5.095)	Data  0.001 ( 4.516)	Loss 1.0849e-01 (1.3269e-01) 
2023-05-27 07:05:12.209842: train Epoch: [12][ 14/193]	Time  9.030 ( 5.357)	Data  8.466 ( 4.780)	Loss 1.4173e-01 (1.3329e-01) 
2023-05-27 07:05:12.790606: train Epoch: [12][ 15/193]	Time  0.581 ( 5.059)	Data  0.001 ( 4.481)	Loss 2.2081e-01 (1.3876e-01) 
2023-05-27 07:05:22.303385: train Epoch: [12][ 16/193]	Time  9.513 ( 5.321)	Data  8.935 ( 4.743)	Loss 1.2103e-01 (1.3772e-01) 
2023-05-27 07:05:22.875897: train Epoch: [12][ 17/193]	Time  0.573 ( 5.057)	Data  0.001 ( 4.480)	Loss 2.0856e-01 (1.4165e-01) 
2023-05-27 07:05:32.445732: train Epoch: [12][ 18/193]	Time  9.570 ( 5.294)	Data  9.002 ( 4.718)	Loss 1.3651e-01 (1.4138e-01) 
2023-05-27 07:05:33.025106: train Epoch: [12][ 19/193]	Time  0.579 ( 5.059)	Data  0.001 ( 4.482)	Loss 4.4138e-01 (1.5638e-01) 
2023-05-27 07:05:42.560115: train Epoch: [12][ 20/193]	Time  9.535 ( 5.272)	Data  8.948 ( 4.694)	Loss 9.0335e-02 (1.5324e-01) 
2023-05-27 07:05:43.124143: train Epoch: [12][ 21/193]	Time  0.564 ( 5.058)	Data  0.001 ( 4.481)	Loss 4.6279e-02 (1.4837e-01) 
2023-05-27 07:05:52.626529: train Epoch: [12][ 22/193]	Time  9.502 ( 5.251)	Data  8.931 ( 4.675)	Loss 1.6589e-01 (1.4914e-01) 
2023-05-27 07:05:53.200131: train Epoch: [12][ 23/193]	Time  0.574 ( 5.056)	Data  0.001 ( 4.480)	Loss 1.3689e-01 (1.4863e-01) 
2023-05-27 07:06:02.553543: train Epoch: [12][ 24/193]	Time  9.353 ( 5.228)	Data  8.740 ( 4.650)	Loss 1.0929e-01 (1.4705e-01) 
2023-05-27 07:06:03.136169: train Epoch: [12][ 25/193]	Time  0.583 ( 5.049)	Data  0.001 ( 4.471)	Loss 1.0906e-01 (1.4559e-01) 
2023-05-27 07:06:11.153212: train Epoch: [12][ 26/193]	Time  8.017 ( 5.159)	Data  7.433 ( 4.581)	Loss 8.5703e-02 (1.4337e-01) 
2023-05-27 07:06:11.718767: train Epoch: [12][ 27/193]	Time  0.566 ( 4.995)	Data  0.001 ( 4.418)	Loss 1.5423e-01 (1.4376e-01) 
2023-05-27 07:06:21.303282: train Epoch: [12][ 28/193]	Time  9.585 ( 5.153)	Data  9.017 ( 4.576)	Loss 1.0424e-01 (1.4240e-01) 
2023-05-27 07:06:21.878691: train Epoch: [12][ 29/193]	Time  0.575 ( 5.001)	Data  0.001 ( 4.424)	Loss 1.7062e-01 (1.4334e-01) 
2023-05-27 07:06:31.144375: train Epoch: [12][ 30/193]	Time  9.266 ( 5.138)	Data  8.664 ( 4.560)	Loss 7.5931e-02 (1.4116e-01) 
2023-05-27 07:06:31.755762: train Epoch: [12][ 31/193]	Time  0.611 ( 4.997)	Data  0.001 ( 4.418)	Loss 1.0976e-01 (1.4018e-01) 
2023-05-27 07:06:41.338038: train Epoch: [12][ 32/193]	Time  9.582 ( 5.136)	Data  9.008 ( 4.557)	Loss 1.0795e-01 (1.3921e-01) 
2023-05-27 07:06:41.916157: train Epoch: [12][ 33/193]	Time  0.578 ( 5.002)	Data  0.001 ( 4.423)	Loss 1.1296e-01 (1.3843e-01) 
2023-05-27 07:06:51.085220: train Epoch: [12][ 34/193]	Time  9.169 ( 5.121)	Data  8.600 ( 4.542)	Loss 2.3490e-01 (1.4119e-01) 
2023-05-27 07:06:51.660935: train Epoch: [12][ 35/193]	Time  0.576 ( 4.995)	Data  0.001 ( 4.416)	Loss 1.0014e-01 (1.4005e-01) 
2023-05-27 07:07:00.967111: train Epoch: [12][ 36/193]	Time  9.306 ( 5.111)	Data  8.728 ( 4.533)	Loss 6.5667e-02 (1.3804e-01) 
2023-05-27 07:07:01.545617: train Epoch: [12][ 37/193]	Time  0.579 ( 4.992)	Data  0.001 ( 4.414)	Loss 2.3137e-01 (1.4050e-01) 
2023-05-27 07:07:11.054712: train Epoch: [12][ 38/193]	Time  9.509 ( 5.108)	Data  8.948 ( 4.530)	Loss 8.4407e-02 (1.3906e-01) 
2023-05-27 07:07:11.631368: train Epoch: [12][ 39/193]	Time  0.577 ( 4.994)	Data  0.001 ( 4.417)	Loss 1.0390e-01 (1.3818e-01) 
2023-05-27 07:07:21.099513: train Epoch: [12][ 40/193]	Time  9.468 ( 5.104)	Data  8.903 ( 4.526)	Loss 2.0579e-01 (1.3983e-01) 
2023-05-27 07:07:21.672280: train Epoch: [12][ 41/193]	Time  0.573 ( 4.996)	Data  0.001 ( 4.418)	Loss 1.2316e-01 (1.3943e-01) 
2023-05-27 07:07:31.187104: train Epoch: [12][ 42/193]	Time  9.515 ( 5.101)	Data  8.890 ( 4.522)	Loss 7.9654e-02 (1.3804e-01) 
2023-05-27 07:07:31.763160: train Epoch: [12][ 43/193]	Time  0.576 ( 4.998)	Data  0.001 ( 4.419)	Loss 1.6390e-01 (1.3863e-01) 
2023-05-27 07:07:40.972259: train Epoch: [12][ 44/193]	Time  9.209 ( 5.092)	Data  8.642 ( 4.513)	Loss 1.2607e-01 (1.3835e-01) 
2023-05-27 07:07:41.549769: train Epoch: [12][ 45/193]	Time  0.578 ( 4.993)	Data  0.001 ( 4.415)	Loss 1.4997e-01 (1.3860e-01) 
2023-05-27 07:07:51.241854: train Epoch: [12][ 46/193]	Time  9.692 ( 5.093)	Data  9.120 ( 4.515)	Loss 1.2217e-01 (1.3825e-01) 
2023-05-27 07:07:51.804931: train Epoch: [12][ 47/193]	Time  0.563 ( 4.999)	Data  0.001 ( 4.421)	Loss 2.8056e-01 (1.4122e-01) 
2023-05-27 07:08:01.569899: train Epoch: [12][ 48/193]	Time  9.765 ( 5.096)	Data  9.195 ( 4.519)	Loss 2.1169e-01 (1.4266e-01) 
2023-05-27 07:08:02.133912: train Epoch: [12][ 49/193]	Time  0.564 ( 5.006)	Data  0.001 ( 4.428)	Loss 1.1200e-01 (1.4204e-01) 
2023-05-27 07:08:10.080439: train Epoch: [12][ 50/193]	Time  7.947 ( 5.063)	Data  7.382 ( 4.486)	Loss 9.2983e-02 (1.4108e-01) 
2023-05-27 07:08:10.645450: train Epoch: [12][ 51/193]	Time  0.565 ( 4.977)	Data  0.001 ( 4.400)	Loss 1.6668e-01 (1.4157e-01) 
2023-05-27 07:08:19.575460: train Epoch: [12][ 52/193]	Time  8.930 ( 5.051)	Data  8.367 ( 4.475)	Loss 1.0181e-01 (1.4082e-01) 
2023-05-27 07:08:20.141268: train Epoch: [12][ 53/193]	Time  0.566 ( 4.968)	Data  0.001 ( 4.392)	Loss 2.9468e-01 (1.4367e-01) 
2023-05-27 07:08:29.135093: train Epoch: [12][ 54/193]	Time  8.994 ( 5.041)	Data  8.421 ( 4.465)	Loss 6.4979e-02 (1.4224e-01) 
2023-05-27 07:08:29.706745: train Epoch: [12][ 55/193]	Time  0.572 ( 4.962)	Data  0.001 ( 4.386)	Loss 1.4001e-01 (1.4220e-01) 
2023-05-27 07:08:39.092431: train Epoch: [12][ 56/193]	Time  9.386 ( 5.039)	Data  8.823 ( 4.463)	Loss 1.5682e-01 (1.4246e-01) 
2023-05-27 07:08:39.657231: train Epoch: [12][ 57/193]	Time  0.565 ( 4.962)	Data  0.001 ( 4.386)	Loss 9.6293e-02 (1.4166e-01) 
2023-05-27 07:08:49.305616: train Epoch: [12][ 58/193]	Time  9.648 ( 5.042)	Data  9.083 ( 4.466)	Loss 1.7720e-01 (1.4226e-01) 
2023-05-27 07:08:49.871797: train Epoch: [12][ 59/193]	Time  0.566 ( 4.967)	Data  0.001 ( 4.392)	Loss 1.1322e-01 (1.4178e-01) 
2023-05-27 07:08:59.450245: train Epoch: [12][ 60/193]	Time  9.578 ( 5.043)	Data  9.005 ( 4.467)	Loss 1.2401e-01 (1.4149e-01) 
2023-05-27 07:09:00.014075: train Epoch: [12][ 61/193]	Time  0.564 ( 4.970)	Data  0.001 ( 4.395)	Loss 2.2913e-01 (1.4290e-01) 
2023-05-27 07:09:08.894173: train Epoch: [12][ 62/193]	Time  8.880 ( 5.032)	Data  8.317 ( 4.457)	Loss 1.8588e-01 (1.4358e-01) 
2023-05-27 07:09:09.459246: train Epoch: [12][ 63/193]	Time  0.565 ( 4.963)	Data  0.001 ( 4.388)	Loss 1.3196e-01 (1.4340e-01) 
2023-05-27 07:09:18.585308: train Epoch: [12][ 64/193]	Time  9.126 ( 5.027)	Data  8.551 ( 4.452)	Loss 1.3306e-01 (1.4324e-01) 
2023-05-27 07:09:19.148889: train Epoch: [12][ 65/193]	Time  0.564 ( 4.959)	Data  0.001 ( 4.384)	Loss 1.4642e-01 (1.4329e-01) 
2023-05-27 07:09:28.817868: train Epoch: [12][ 66/193]	Time  9.669 ( 5.029)	Data  9.003 ( 4.453)	Loss 1.0561e-01 (1.4273e-01) 
2023-05-27 07:09:29.382347: train Epoch: [12][ 67/193]	Time  0.564 ( 4.964)	Data  0.001 ( 4.388)	Loss 3.2264e-01 (1.4538e-01) 
2023-05-27 07:09:38.649378: train Epoch: [12][ 68/193]	Time  9.267 ( 5.026)	Data  8.687 ( 4.450)	Loss 7.6983e-02 (1.4438e-01) 
2023-05-27 07:09:39.224920: train Epoch: [12][ 69/193]	Time  0.576 ( 4.962)	Data  0.001 ( 4.387)	Loss 1.3419e-01 (1.4424e-01) 
2023-05-27 07:09:49.141429: train Epoch: [12][ 70/193]	Time  9.917 ( 5.032)	Data  9.354 ( 4.457)	Loss 9.5851e-02 (1.4356e-01) 
2023-05-27 07:09:49.706434: train Epoch: [12][ 71/193]	Time  0.565 ( 4.970)	Data  0.001 ( 4.395)	Loss 1.1607e-01 (1.4317e-01) 
2023-05-27 07:09:59.231303: train Epoch: [12][ 72/193]	Time  9.525 ( 5.033)	Data  8.944 ( 4.457)	Loss 1.2532e-01 (1.4293e-01) 
2023-05-27 07:09:59.795919: train Epoch: [12][ 73/193]	Time  0.565 ( 4.972)	Data  0.001 ( 4.397)	Loss 1.3928e-01 (1.4288e-01) 
2023-05-27 07:10:09.383228: train Epoch: [12][ 74/193]	Time  9.587 ( 5.034)	Data  9.024 ( 4.458)	Loss 1.8894e-01 (1.4350e-01) 
2023-05-27 07:10:09.945881: train Epoch: [12][ 75/193]	Time  0.563 ( 4.975)	Data  0.001 ( 4.400)	Loss 3.8010e-01 (1.4661e-01) 
2023-05-27 07:10:19.350396: train Epoch: [12][ 76/193]	Time  9.405 ( 5.032)	Data  8.842 ( 4.458)	Loss 1.7719e-01 (1.4701e-01) 
2023-05-27 07:10:19.914100: train Epoch: [12][ 77/193]	Time  0.564 ( 4.975)	Data  0.001 ( 4.400)	Loss 1.5272e-01 (1.4708e-01) 
2023-05-27 07:10:29.255695: train Epoch: [12][ 78/193]	Time  9.342 ( 5.030)	Data  8.747 ( 4.455)	Loss 8.7275e-02 (1.4632e-01) 
2023-05-27 07:10:29.834339: train Epoch: [12][ 79/193]	Time  0.579 ( 4.975)	Data  0.001 ( 4.400)	Loss 2.2568e-01 (1.4731e-01) 
2023-05-27 07:10:38.641078: train Epoch: [12][ 80/193]	Time  8.807 ( 5.022)	Data  8.238 ( 4.447)	Loss 1.1532e-01 (1.4692e-01) 
2023-05-27 07:10:39.207695: train Epoch: [12][ 81/193]	Time  0.567 ( 4.968)	Data  0.001 ( 4.393)	Loss 2.1792e-01 (1.4778e-01) 
2023-05-27 07:10:48.313572: train Epoch: [12][ 82/193]	Time  9.106 ( 5.018)	Data  8.535 ( 4.443)	Loss 1.5539e-01 (1.4788e-01) 
2023-05-27 07:10:48.882308: train Epoch: [12][ 83/193]	Time  0.569 ( 4.965)	Data  0.001 ( 4.390)	Loss 8.9623e-02 (1.4718e-01) 
2023-05-27 07:10:58.348228: train Epoch: [12][ 84/193]	Time  9.466 ( 5.018)	Data  8.897 ( 4.443)	Loss 1.1175e-01 (1.4677e-01) 
2023-05-27 07:10:58.964650: train Epoch: [12][ 85/193]	Time  0.616 ( 4.966)	Data  0.001 ( 4.391)	Loss 1.2439e-01 (1.4651e-01) 
2023-05-27 07:11:08.103548: train Epoch: [12][ 86/193]	Time  9.139 ( 5.014)	Data  8.571 ( 4.439)	Loss 1.1882e-01 (1.4619e-01) 
2023-05-27 07:11:08.671604: train Epoch: [12][ 87/193]	Time  0.568 ( 4.964)	Data  0.001 ( 4.389)	Loss 6.7538e-02 (1.4529e-01) 
2023-05-27 07:11:17.747848: train Epoch: [12][ 88/193]	Time  9.076 ( 5.010)	Data  8.509 ( 4.435)	Loss 2.1225e-01 (1.4605e-01) 
2023-05-27 07:11:18.314993: train Epoch: [12][ 89/193]	Time  0.567 ( 4.961)	Data  0.001 ( 4.386)	Loss 1.2125e-01 (1.4577e-01) 
2023-05-27 07:11:27.866361: train Epoch: [12][ 90/193]	Time  9.551 ( 5.011)	Data  8.981 ( 4.436)	Loss 1.8613e-01 (1.4621e-01) 
2023-05-27 07:11:28.438999: train Epoch: [12][ 91/193]	Time  0.573 ( 4.963)	Data  0.001 ( 4.388)	Loss 1.6286e-01 (1.4640e-01) 
2023-05-27 07:11:37.987884: train Epoch: [12][ 92/193]	Time  9.549 ( 5.012)	Data  8.971 ( 4.437)	Loss 1.5603e-01 (1.4650e-01) 
2023-05-27 07:11:38.554747: train Epoch: [12][ 93/193]	Time  0.567 ( 4.965)	Data  0.001 ( 4.390)	Loss 1.3294e-01 (1.4635e-01) 
2023-05-27 07:11:46.764196: train Epoch: [12][ 94/193]	Time  8.209 ( 4.999)	Data  7.647 ( 4.425)	Loss 8.8694e-02 (1.4575e-01) 
2023-05-27 07:11:47.328937: train Epoch: [12][ 95/193]	Time  0.565 ( 4.953)	Data  0.001 ( 4.378)	Loss 1.0585e-01 (1.4533e-01) 
2023-05-27 07:11:55.314736: train Epoch: [12][ 96/193]	Time  7.986 ( 4.984)	Data  7.421 ( 4.410)	Loss 1.7796e-01 (1.4567e-01) 
2023-05-27 07:11:55.878832: train Epoch: [12][ 97/193]	Time  0.564 ( 4.939)	Data  0.001 ( 4.365)	Loss 7.7696e-02 (1.4497e-01) 
2023-05-27 07:12:04.541623: train Epoch: [12][ 98/193]	Time  8.663 ( 4.977)	Data  8.091 ( 4.403)	Loss 9.2115e-02 (1.4444e-01) 
2023-05-27 07:12:05.104206: train Epoch: [12][ 99/193]	Time  0.563 ( 4.933)	Data  0.001 ( 4.358)	Loss 1.1613e-01 (1.4416e-01) 
2023-05-27 07:12:14.017679: train Epoch: [12][100/193]	Time  8.913 ( 4.972)	Data  8.339 ( 4.398)	Loss 1.7238e-01 (1.4444e-01) 
2023-05-27 07:12:14.605253: train Epoch: [12][101/193]	Time  0.588 ( 4.929)	Data  0.001 ( 4.355)	Loss 7.7341e-02 (1.4378e-01) 
2023-05-27 07:12:23.659301: train Epoch: [12][102/193]	Time  9.054 ( 4.969)	Data  8.478 ( 4.395)	Loss 8.3908e-02 (1.4320e-01) 
2023-05-27 07:12:24.239600: train Epoch: [12][103/193]	Time  0.580 ( 4.927)	Data  0.001 ( 4.353)	Loss 9.4341e-02 (1.4273e-01) 
2023-05-27 07:12:33.529919: train Epoch: [12][104/193]	Time  9.290 ( 4.968)	Data  8.712 ( 4.394)	Loss 1.0437e-01 (1.4236e-01) 
2023-05-27 07:12:34.129942: train Epoch: [12][105/193]	Time  0.600 ( 4.927)	Data  0.001 ( 4.353)	Loss 1.1647e-01 (1.4212e-01) 
2023-05-27 07:12:43.424785: train Epoch: [12][106/193]	Time  9.295 ( 4.968)	Data  8.706 ( 4.393)	Loss 7.3124e-02 (1.4147e-01) 
2023-05-27 07:12:44.007620: train Epoch: [12][107/193]	Time  0.583 ( 4.927)	Data  0.001 ( 4.353)	Loss 1.1583e-01 (1.4124e-01) 
2023-05-27 07:12:53.351208: train Epoch: [12][108/193]	Time  9.344 ( 4.968)	Data  8.771 ( 4.393)	Loss 1.0290e-01 (1.4088e-01) 
2023-05-27 07:12:53.948242: train Epoch: [12][109/193]	Time  0.597 ( 4.928)	Data  0.001 ( 4.353)	Loss 2.0013e-01 (1.4142e-01) 
2023-05-27 07:13:03.657621: train Epoch: [12][110/193]	Time  9.709 ( 4.971)	Data  9.136 ( 4.396)	Loss 1.0114e-01 (1.4106e-01) 
2023-05-27 07:13:04.235205: train Epoch: [12][111/193]	Time  0.578 ( 4.932)	Data  0.001 ( 4.357)	Loss 5.5613e-02 (1.4030e-01) 
2023-05-27 07:13:13.889510: train Epoch: [12][112/193]	Time  9.654 ( 4.974)	Data  9.078 ( 4.399)	Loss 1.2602e-01 (1.4017e-01) 
2023-05-27 07:13:14.451861: train Epoch: [12][113/193]	Time  0.562 ( 4.935)	Data  0.001 ( 4.360)	Loss 1.8027e-01 (1.4052e-01) 
2023-05-27 07:13:23.468603: train Epoch: [12][114/193]	Time  9.017 ( 4.971)	Data  8.443 ( 4.396)	Loss 1.4605e-01 (1.4057e-01) 
2023-05-27 07:13:24.032811: train Epoch: [12][115/193]	Time  0.564 ( 4.933)	Data  0.001 ( 4.358)	Loss 2.3789e-01 (1.4141e-01) 
2023-05-27 07:13:33.577976: train Epoch: [12][116/193]	Time  9.545 ( 4.972)	Data  8.975 ( 4.397)	Loss 8.8364e-02 (1.4096e-01) 
2023-05-27 07:13:34.140820: train Epoch: [12][117/193]	Time  0.563 ( 4.935)	Data  0.001 ( 4.360)	Loss 1.7347e-01 (1.4123e-01) 
2023-05-27 07:13:43.626466: train Epoch: [12][118/193]	Time  9.486 ( 4.973)	Data  8.922 ( 4.398)	Loss 1.2901e-01 (1.4113e-01) 
2023-05-27 07:13:44.189149: train Epoch: [12][119/193]	Time  0.563 ( 4.936)	Data  0.001 ( 4.362)	Loss 1.9143e-01 (1.4155e-01) 
2023-05-27 07:13:53.634983: train Epoch: [12][120/193]	Time  9.446 ( 4.973)	Data  8.862 ( 4.399)	Loss 7.8139e-02 (1.4102e-01) 
2023-05-27 07:13:54.197177: train Epoch: [12][121/193]	Time  0.562 ( 4.937)	Data  0.001 ( 4.363)	Loss 1.3310e-01 (1.4096e-01) 
2023-05-27 07:14:03.463539: train Epoch: [12][122/193]	Time  9.266 ( 4.972)	Data  8.673 ( 4.398)	Loss 1.1219e-01 (1.4073e-01) 
2023-05-27 07:14:04.026183: train Epoch: [12][123/193]	Time  0.563 ( 4.937)	Data  0.001 ( 4.363)	Loss 1.1056e-01 (1.4048e-01) 
2023-05-27 07:14:13.045402: train Epoch: [12][124/193]	Time  9.019 ( 4.970)	Data  8.455 ( 4.395)	Loss 1.7076e-01 (1.4072e-01) 
2023-05-27 07:14:13.619737: train Epoch: [12][125/193]	Time  0.574 ( 4.935)	Data  0.001 ( 4.360)	Loss 9.3453e-02 (1.4035e-01) 
2023-05-27 07:14:23.433336: train Epoch: [12][126/193]	Time  9.814 ( 4.973)	Data  9.244 ( 4.399)	Loss 1.4216e-01 (1.4036e-01) 
2023-05-27 07:14:23.997311: train Epoch: [12][127/193]	Time  0.564 ( 4.939)	Data  0.001 ( 4.364)	Loss 1.3086e-01 (1.4029e-01) 
2023-05-27 07:14:33.696859: train Epoch: [12][128/193]	Time  9.700 ( 4.976)	Data  9.125 ( 4.401)	Loss 8.5069e-02 (1.3986e-01) 
2023-05-27 07:14:34.260213: train Epoch: [12][129/193]	Time  0.563 ( 4.942)	Data  0.001 ( 4.368)	Loss 1.5957e-01 (1.4001e-01) 
2023-05-27 07:14:43.576946: train Epoch: [12][130/193]	Time  9.317 ( 4.975)	Data  8.753 ( 4.401)	Loss 1.3887e-01 (1.4000e-01) 
2023-05-27 07:14:44.142196: train Epoch: [12][131/193]	Time  0.565 ( 4.942)	Data  0.001 ( 4.368)	Loss 1.0714e-01 (1.3976e-01) 
2023-05-27 07:14:54.209807: train Epoch: [12][132/193]	Time 10.068 ( 4.980)	Data  9.506 ( 4.406)	Loss 2.4607e-01 (1.4055e-01) 
2023-05-27 07:14:54.774989: train Epoch: [12][133/193]	Time  0.565 ( 4.947)	Data  0.001 ( 4.373)	Loss 1.1293e-01 (1.4035e-01) 
2023-05-27 07:15:04.141935: train Epoch: [12][134/193]	Time  9.367 ( 4.980)	Data  8.803 ( 4.406)	Loss 1.8174e-01 (1.4066e-01) 
2023-05-27 07:15:04.706556: train Epoch: [12][135/193]	Time  0.565 ( 4.947)	Data  0.001 ( 4.374)	Loss 1.2618e-01 (1.4055e-01) 
2023-05-27 07:15:13.745595: train Epoch: [12][136/193]	Time  9.039 ( 4.977)	Data  8.471 ( 4.404)	Loss 1.3911e-01 (1.4054e-01) 
2023-05-27 07:15:14.317674: train Epoch: [12][137/193]	Time  0.572 ( 4.945)	Data  0.001 ( 4.372)	Loss 1.0423e-01 (1.4028e-01) 
2023-05-27 07:15:23.515818: train Epoch: [12][138/193]	Time  9.198 ( 4.976)	Data  8.608 ( 4.402)	Loss 8.7047e-02 (1.3989e-01) 
2023-05-27 07:15:24.114744: train Epoch: [12][139/193]	Time  0.599 ( 4.945)	Data  0.001 ( 4.371)	Loss 1.3058e-01 (1.3983e-01) 
2023-05-27 07:15:33.497192: train Epoch: [12][140/193]	Time  9.382 ( 4.976)	Data  8.809 ( 4.402)	Loss 1.5918e-01 (1.3996e-01) 
2023-05-27 07:15:34.062007: train Epoch: [12][141/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.371)	Loss 7.5761e-02 (1.3951e-01) 
2023-05-27 07:15:43.625105: train Epoch: [12][142/193]	Time  9.563 ( 4.977)	Data  8.960 ( 4.403)	Loss 1.1388e-01 (1.3933e-01) 
2023-05-27 07:15:44.195125: train Epoch: [12][143/193]	Time  0.570 ( 4.947)	Data  0.001 ( 4.373)	Loss 1.4815e-01 (1.3939e-01) 
2023-05-27 07:15:53.685704: train Epoch: [12][144/193]	Time  9.491 ( 4.978)	Data  8.891 ( 4.404)	Loss 2.4795e-01 (1.4014e-01) 
2023-05-27 07:15:54.248718: train Epoch: [12][145/193]	Time  0.563 ( 4.948)	Data  0.001 ( 4.374)	Loss 1.2079e-01 (1.4001e-01) 
2023-05-27 07:16:03.502635: train Epoch: [12][146/193]	Time  9.254 ( 4.977)	Data  8.683 ( 4.403)	Loss 2.3955e-01 (1.4069e-01) 
2023-05-27 07:16:04.070071: train Epoch: [12][147/193]	Time  0.567 ( 4.947)	Data  0.001 ( 4.373)	Loss 9.8652e-02 (1.4040e-01) 
2023-05-27 07:16:13.737672: train Epoch: [12][148/193]	Time  9.668 ( 4.979)	Data  9.101 ( 4.405)	Loss 1.4784e-01 (1.4045e-01) 
2023-05-27 07:16:14.300267: train Epoch: [12][149/193]	Time  0.563 ( 4.950)	Data  0.001 ( 4.376)	Loss 1.4975e-01 (1.4051e-01) 
2023-05-27 07:16:23.925539: train Epoch: [12][150/193]	Time  9.625 ( 4.981)	Data  9.064 ( 4.407)	Loss 1.9763e-01 (1.4089e-01) 
2023-05-27 07:16:24.486982: train Epoch: [12][151/193]	Time  0.561 ( 4.952)	Data  0.001 ( 4.378)	Loss 2.4280e-01 (1.4156e-01) 
2023-05-27 07:16:33.445918: train Epoch: [12][152/193]	Time  8.959 ( 4.978)	Data  8.398 ( 4.404)	Loss 9.6930e-02 (1.4127e-01) 
2023-05-27 07:16:34.009841: train Epoch: [12][153/193]	Time  0.564 ( 4.949)	Data  0.001 ( 4.376)	Loss 1.0829e-01 (1.4106e-01) 
2023-05-27 07:16:43.263627: train Epoch: [12][154/193]	Time  9.254 ( 4.977)	Data  8.692 ( 4.403)	Loss 1.0439e-01 (1.4082e-01) 
2023-05-27 07:16:43.826090: train Epoch: [12][155/193]	Time  0.562 ( 4.949)	Data  0.001 ( 4.375)	Loss 9.3771e-02 (1.4052e-01) 
2023-05-27 07:16:53.152159: train Epoch: [12][156/193]	Time  9.326 ( 4.976)	Data  8.751 ( 4.403)	Loss 1.4324e-01 (1.4054e-01) 
2023-05-27 07:16:53.714085: train Epoch: [12][157/193]	Time  0.562 ( 4.948)	Data  0.001 ( 4.375)	Loss 2.1426e-01 (1.4100e-01) 
2023-05-27 07:17:02.848469: train Epoch: [12][158/193]	Time  9.134 ( 4.975)	Data  8.521 ( 4.401)	Loss 1.2471e-01 (1.4090e-01) 
2023-05-27 07:17:03.411062: train Epoch: [12][159/193]	Time  0.563 ( 4.947)	Data  0.001 ( 4.374)	Loss 1.5488e-01 (1.4099e-01) 
2023-05-27 07:17:13.372646: train Epoch: [12][160/193]	Time  9.962 ( 4.978)	Data  9.398 ( 4.405)	Loss 9.5725e-02 (1.4071e-01) 
2023-05-27 07:17:13.935606: train Epoch: [12][161/193]	Time  0.563 ( 4.951)	Data  0.001 ( 4.378)	Loss 1.2625e-01 (1.4062e-01) 
2023-05-27 07:17:23.603405: train Epoch: [12][162/193]	Time  9.668 ( 4.980)	Data  9.086 ( 4.407)	Loss 1.2859e-01 (1.4054e-01) 
2023-05-27 07:17:24.183298: train Epoch: [12][163/193]	Time  0.580 ( 4.953)	Data  0.001 ( 4.380)	Loss 1.1742e-01 (1.4040e-01) 
2023-05-27 07:17:33.545477: train Epoch: [12][164/193]	Time  9.362 ( 4.980)	Data  8.798 ( 4.407)	Loss 1.8298e-01 (1.4066e-01) 
2023-05-27 07:17:34.109280: train Epoch: [12][165/193]	Time  0.564 ( 4.953)	Data  0.001 ( 4.380)	Loss 7.8236e-02 (1.4028e-01) 
2023-05-27 07:17:43.332875: train Epoch: [12][166/193]	Time  9.224 ( 4.979)	Data  8.654 ( 4.406)	Loss 1.5776e-01 (1.4039e-01) 
2023-05-27 07:17:43.896369: train Epoch: [12][167/193]	Time  0.563 ( 4.953)	Data  0.001 ( 4.379)	Loss 1.5836e-01 (1.4050e-01) 
2023-05-27 07:17:53.647204: train Epoch: [12][168/193]	Time  9.751 ( 4.981)	Data  9.179 ( 4.408)	Loss 1.0524e-01 (1.4029e-01) 
2023-05-27 07:17:54.219189: train Epoch: [12][169/193]	Time  0.572 ( 4.955)	Data  0.001 ( 4.382)	Loss 8.5591e-02 (1.3997e-01) 
2023-05-27 07:18:03.548511: train Epoch: [12][170/193]	Time  9.329 ( 4.981)	Data  8.768 ( 4.408)	Loss 3.1684e-01 (1.4100e-01) 
2023-05-27 07:18:04.109598: train Epoch: [12][171/193]	Time  0.561 ( 4.955)	Data  0.001 ( 4.382)	Loss 1.0448e-01 (1.4079e-01) 
2023-05-27 07:18:13.298608: train Epoch: [12][172/193]	Time  9.189 ( 4.979)	Data  8.621 ( 4.406)	Loss 7.6794e-02 (1.4042e-01) 
2023-05-27 07:18:13.859895: train Epoch: [12][173/193]	Time  0.561 ( 4.954)	Data  0.001 ( 4.381)	Loss 1.3071e-01 (1.4036e-01) 
2023-05-27 07:18:23.373465: train Epoch: [12][174/193]	Time  9.514 ( 4.980)	Data  8.942 ( 4.407)	Loss 2.5218e-01 (1.4100e-01) 
2023-05-27 07:18:23.935803: train Epoch: [12][175/193]	Time  0.562 ( 4.955)	Data  0.001 ( 4.382)	Loss 1.7221e-01 (1.4118e-01) 
2023-05-27 07:18:33.278844: train Epoch: [12][176/193]	Time  9.343 ( 4.980)	Data  8.772 ( 4.407)	Loss 1.4882e-01 (1.4122e-01) 
2023-05-27 07:18:33.842991: train Epoch: [12][177/193]	Time  0.564 ( 4.955)	Data  0.001 ( 4.382)	Loss 1.0917e-01 (1.4104e-01) 
2023-05-27 07:18:43.574704: train Epoch: [12][178/193]	Time  9.732 ( 4.982)	Data  9.168 ( 4.409)	Loss 9.2867e-02 (1.4077e-01) 
2023-05-27 07:18:44.138082: train Epoch: [12][179/193]	Time  0.563 ( 4.957)	Data  0.001 ( 4.384)	Loss 1.6656e-01 (1.4092e-01) 
2023-05-27 07:18:53.554929: train Epoch: [12][180/193]	Time  9.417 ( 4.982)	Data  8.854 ( 4.409)	Loss 1.0531e-01 (1.4072e-01) 
2023-05-27 07:18:54.118855: train Epoch: [12][181/193]	Time  0.564 ( 4.958)	Data  0.001 ( 4.385)	Loss 9.0774e-02 (1.4044e-01) 
2023-05-27 07:19:03.470635: train Epoch: [12][182/193]	Time  9.352 ( 4.982)	Data  8.785 ( 4.409)	Loss 1.3582e-01 (1.4042e-01) 
2023-05-27 07:19:04.040177: train Epoch: [12][183/193]	Time  0.570 ( 4.958)	Data  0.001 ( 4.385)	Loss 8.5692e-02 (1.4012e-01) 
2023-05-27 07:19:13.416906: train Epoch: [12][184/193]	Time  9.377 ( 4.981)	Data  8.804 ( 4.409)	Loss 1.2448e-01 (1.4004e-01) 
2023-05-27 07:19:13.980805: train Epoch: [12][185/193]	Time  0.564 ( 4.958)	Data  0.001 ( 4.385)	Loss 1.1311e-01 (1.3989e-01) 
2023-05-27 07:19:23.491711: train Epoch: [12][186/193]	Time  9.511 ( 4.982)	Data  8.943 ( 4.410)	Loss 1.5980e-01 (1.4000e-01) 
2023-05-27 07:19:24.059224: train Epoch: [12][187/193]	Time  0.568 ( 4.959)	Data  0.001 ( 4.386)	Loss 1.6095e-01 (1.4011e-01) 
2023-05-27 07:19:33.484924: train Epoch: [12][188/193]	Time  9.426 ( 4.982)	Data  8.857 ( 4.410)	Loss 1.3812e-01 (1.4010e-01) 
2023-05-27 07:19:34.054599: train Epoch: [12][189/193]	Time  0.570 ( 4.959)	Data  0.001 ( 4.387)	Loss 1.4368e-01 (1.4012e-01) 
2023-05-27 07:19:43.520263: train Epoch: [12][190/193]	Time  9.466 ( 4.983)	Data  8.897 ( 4.410)	Loss 1.9285e-01 (1.4039e-01) 
2023-05-27 07:19:44.091929: train Epoch: [12][191/193]	Time  0.572 ( 4.960)	Data  0.001 ( 4.387)	Loss 1.3317e-01 (1.4036e-01) 
2023-05-27 07:19:52.110569: train Epoch: [12][192/193]	Time  8.019 ( 4.975)	Data  7.450 ( 4.403)	Loss 1.4107e-01 (1.4036e-01) 
2023-05-27 07:19:52.235400: Train Epoch done in 960.3828810470004 s 
2023-05-27 07:19:58.753103: val Epoch: [12][ 0/72]	Time  5.729 ( 5.729)	Data  5.414 ( 5.414)	Loss 3.3729e-01 (3.3729e-01) 
2023-05-27 07:19:58.883529: val Epoch: [12][ 1/72]	Time  0.130 ( 2.930)	Data  0.001 ( 2.707)	Loss 7.8088e-02 (2.0769e-01) 
2023-05-27 07:20:03.385758: val Epoch: [12][ 2/72]	Time  4.502 ( 3.454)	Data  4.366 ( 3.260)	Loss 7.7104e-02 (1.6416e-01) 
2023-05-27 07:20:04.057862: val Epoch: [12][ 3/72]	Time  0.672 ( 2.758)	Data  0.542 ( 2.581)	Loss 9.7795e-02 (1.4757e-01) 
2023-05-27 07:20:08.281401: val Epoch: [12][ 4/72]	Time  4.224 ( 3.051)	Data  4.095 ( 2.884)	Loss 2.1911e-01 (1.6188e-01) 
2023-05-27 07:20:09.046985: val Epoch: [12][ 5/72]	Time  0.766 ( 2.670)	Data  0.633 ( 2.508)	Loss 1.4298e-01 (1.5873e-01) 
2023-05-27 07:20:13.183897: val Epoch: [12][ 6/72]	Time  4.137 ( 2.880)	Data  4.032 ( 2.726)	Loss 1.4988e-01 (1.5746e-01) 
2023-05-27 07:20:14.085084: val Epoch: [12][ 7/72]	Time  0.901 ( 2.633)	Data  0.793 ( 2.484)	Loss 5.4711e-01 (2.0617e-01) 
2023-05-27 07:20:18.146093: val Epoch: [12][ 8/72]	Time  4.061 ( 2.791)	Data  3.951 ( 2.647)	Loss 1.7676e-01 (2.0290e-01) 
2023-05-27 07:20:19.320286: val Epoch: [12][ 9/72]	Time  1.174 ( 2.630)	Data  1.020 ( 2.485)	Loss 1.6423e-01 (1.9904e-01) 
2023-05-27 07:20:22.955259: val Epoch: [12][10/72]	Time  3.635 ( 2.721)	Data  3.529 ( 2.580)	Loss 1.0480e-01 (1.9047e-01) 
2023-05-27 07:20:24.194151: val Epoch: [12][11/72]	Time  1.239 ( 2.597)	Data  1.116 ( 2.458)	Loss 1.3810e-01 (1.8610e-01) 
2023-05-27 07:20:27.832774: val Epoch: [12][12/72]	Time  3.639 ( 2.678)	Data  3.533 ( 2.540)	Loss 2.3059e-01 (1.8953e-01) 
2023-05-27 07:20:29.046845: val Epoch: [12][13/72]	Time  1.214 ( 2.573)	Data  1.108 ( 2.438)	Loss 8.8854e-02 (1.8234e-01) 
2023-05-27 07:20:32.846493: val Epoch: [12][14/72]	Time  3.800 ( 2.655)	Data  3.695 ( 2.522)	Loss 2.3214e-01 (1.8566e-01) 
2023-05-27 07:20:34.103086: val Epoch: [12][15/72]	Time  1.257 ( 2.567)	Data  1.150 ( 2.436)	Loss 9.3096e-02 (1.7987e-01) 
2023-05-27 07:20:37.864653: val Epoch: [12][16/72]	Time  3.762 ( 2.638)	Data  3.656 ( 2.508)	Loss 9.6327e-02 (1.7496e-01) 
2023-05-27 07:20:39.030458: val Epoch: [12][17/72]	Time  1.166 ( 2.556)	Data  1.056 ( 2.427)	Loss 9.4146e-02 (1.7047e-01) 
2023-05-27 07:20:43.022297: val Epoch: [12][18/72]	Time  3.992 ( 2.631)	Data  3.883 ( 2.504)	Loss 1.9021e-01 (1.7151e-01) 
2023-05-27 07:20:44.158317: val Epoch: [12][19/72]	Time  1.136 ( 2.557)	Data  1.021 ( 2.430)	Loss 8.7360e-02 (1.6730e-01) 
2023-05-27 07:20:48.055000: val Epoch: [12][20/72]	Time  3.897 ( 2.621)	Data  3.781 ( 2.494)	Loss 6.8993e-02 (1.6262e-01) 
2023-05-27 07:20:49.276155: val Epoch: [12][21/72]	Time  1.221 ( 2.557)	Data  1.108 ( 2.431)	Loss 3.8106e-01 (1.7255e-01) 
2023-05-27 07:20:52.810941: val Epoch: [12][22/72]	Time  3.535 ( 2.599)	Data  3.426 ( 2.474)	Loss 8.3020e-02 (1.6865e-01) 
2023-05-27 07:20:54.444626: val Epoch: [12][23/72]	Time  1.634 ( 2.559)	Data  1.523 ( 2.435)	Loss 3.4015e-01 (1.7580e-01) 
2023-05-27 07:20:57.696927: val Epoch: [12][24/72]	Time  3.252 ( 2.587)	Data  3.141 ( 2.463)	Loss 3.4593e-01 (1.8260e-01) 
2023-05-27 07:20:59.369577: val Epoch: [12][25/72]	Time  1.673 ( 2.552)	Data  1.555 ( 2.428)	Loss 9.1777e-02 (1.7911e-01) 
2023-05-27 07:21:02.679706: val Epoch: [12][26/72]	Time  3.310 ( 2.580)	Data  3.198 ( 2.457)	Loss 8.5842e-02 (1.7566e-01) 
2023-05-27 07:21:04.411194: val Epoch: [12][27/72]	Time  1.731 ( 2.550)	Data  1.619 ( 2.427)	Loss 7.3177e-02 (1.7200e-01) 
2023-05-27 07:21:07.729497: val Epoch: [12][28/72]	Time  3.318 ( 2.576)	Data  3.207 ( 2.454)	Loss 3.8635e-01 (1.7939e-01) 
2023-05-27 07:21:09.458140: val Epoch: [12][29/72]	Time  1.729 ( 2.548)	Data  1.618 ( 2.426)	Loss 1.3271e-01 (1.7783e-01) 
2023-05-27 07:21:12.559358: val Epoch: [12][30/72]	Time  3.101 ( 2.566)	Data  2.991 ( 2.444)	Loss 6.1659e-02 (1.7409e-01) 
2023-05-27 07:21:14.257980: val Epoch: [12][31/72]	Time  1.699 ( 2.539)	Data  1.583 ( 2.417)	Loss 7.1417e-02 (1.7088e-01) 
2023-05-27 07:21:17.681213: val Epoch: [12][32/72]	Time  3.423 ( 2.565)	Data  3.313 ( 2.444)	Loss 1.2076e-01 (1.6936e-01) 
2023-05-27 07:21:19.403112: val Epoch: [12][33/72]	Time  1.722 ( 2.541)	Data  1.552 ( 2.418)	Loss 2.1698e-01 (1.7076e-01) 
2023-05-27 07:21:22.515425: val Epoch: [12][34/72]	Time  3.112 ( 2.557)	Data  3.005 ( 2.435)	Loss 6.2587e-02 (1.6767e-01) 
2023-05-27 07:21:24.604024: val Epoch: [12][35/72]	Time  2.089 ( 2.544)	Data  1.984 ( 2.422)	Loss 1.4061e-01 (1.6692e-01) 
2023-05-27 07:21:27.710677: val Epoch: [12][36/72]	Time  3.107 ( 2.559)	Data  3.002 ( 2.438)	Loss 2.2719e-01 (1.6855e-01) 
2023-05-27 07:21:29.527794: val Epoch: [12][37/72]	Time  1.817 ( 2.540)	Data  1.711 ( 2.419)	Loss 9.8816e-02 (1.6671e-01) 
2023-05-27 07:21:32.419956: val Epoch: [12][38/72]	Time  2.892 ( 2.549)	Data  2.781 ( 2.428)	Loss 5.9670e-02 (1.6397e-01) 
2023-05-27 07:21:34.558813: val Epoch: [12][39/72]	Time  2.139 ( 2.538)	Data  2.019 ( 2.418)	Loss 1.4566e-01 (1.6351e-01) 
2023-05-27 07:21:37.496906: val Epoch: [12][40/72]	Time  2.938 ( 2.548)	Data  2.833 ( 2.428)	Loss 1.5829e-01 (1.6338e-01) 
2023-05-27 07:21:39.358738: val Epoch: [12][41/72]	Time  1.862 ( 2.532)	Data  1.745 ( 2.412)	Loss 8.4860e-02 (1.6151e-01) 
2023-05-27 07:21:42.391184: val Epoch: [12][42/72]	Time  3.032 ( 2.543)	Data  2.925 ( 2.424)	Loss 1.0907e-01 (1.6029e-01) 
2023-05-27 07:21:44.618396: val Epoch: [12][43/72]	Time  2.227 ( 2.536)	Data  2.120 ( 2.417)	Loss 1.2308e-01 (1.5945e-01) 
2023-05-27 07:21:47.413707: val Epoch: [12][44/72]	Time  2.795 ( 2.542)	Data  2.690 ( 2.423)	Loss 6.6874e-01 (1.7076e-01) 
2023-05-27 07:21:49.713955: val Epoch: [12][45/72]	Time  2.300 ( 2.537)	Data  2.149 ( 2.417)	Loss 6.9179e-02 (1.6856e-01) 
2023-05-27 07:21:52.381905: val Epoch: [12][46/72]	Time  2.668 ( 2.540)	Data  2.560 ( 2.420)	Loss 5.6371e-01 (1.7696e-01) 
2023-05-27 07:21:54.567425: val Epoch: [12][47/72]	Time  2.186 ( 2.532)	Data  2.078 ( 2.413)	Loss 1.7905e-01 (1.7701e-01) 
2023-05-27 07:21:57.216019: val Epoch: [12][48/72]	Time  2.649 ( 2.535)	Data  2.543 ( 2.415)	Loss 7.0404e-02 (1.7483e-01) 
2023-05-27 07:21:59.598908: val Epoch: [12][49/72]	Time  2.383 ( 2.531)	Data  2.276 ( 2.413)	Loss 2.3040e-01 (1.7594e-01) 
2023-05-27 07:22:02.286800: val Epoch: [12][50/72]	Time  2.688 ( 2.535)	Data  2.583 ( 2.416)	Loss 4.3384e-01 (1.8100e-01) 
2023-05-27 07:22:04.934197: val Epoch: [12][51/72]	Time  2.647 ( 2.537)	Data  2.528 ( 2.418)	Loss 1.1390e-01 (1.7971e-01) 
2023-05-27 07:22:07.320456: val Epoch: [12][52/72]	Time  2.386 ( 2.534)	Data  2.281 ( 2.416)	Loss 1.7296e-01 (1.7958e-01) 
2023-05-27 07:22:10.070664: val Epoch: [12][53/72]	Time  2.750 ( 2.538)	Data  2.639 ( 2.420)	Loss 6.9223e-01 (1.8907e-01) 
2023-05-27 07:22:12.207659: val Epoch: [12][54/72]	Time  2.137 ( 2.531)	Data  2.032 ( 2.413)	Loss 7.1755e-02 (1.8694e-01) 
2023-05-27 07:22:15.149158: val Epoch: [12][55/72]	Time  2.942 ( 2.538)	Data  2.837 ( 2.420)	Loss 1.5005e-01 (1.8628e-01) 
2023-05-27 07:22:16.930274: val Epoch: [12][56/72]	Time  1.781 ( 2.525)	Data  1.675 ( 2.407)	Loss 1.1389e-01 (1.8501e-01) 
2023-05-27 07:22:20.437731: val Epoch: [12][57/72]	Time  3.507 ( 2.542)	Data  3.398 ( 2.424)	Loss 1.5230e-01 (1.8445e-01) 
2023-05-27 07:22:21.782977: val Epoch: [12][58/72]	Time  1.345 ( 2.521)	Data  1.238 ( 2.404)	Loss 6.0086e-02 (1.8234e-01) 
2023-05-27 07:22:25.350841: val Epoch: [12][59/72]	Time  3.568 ( 2.539)	Data  3.463 ( 2.422)	Loss 9.3233e-02 (1.8086e-01) 
2023-05-27 07:22:26.722543: val Epoch: [12][60/72]	Time  1.372 ( 2.520)	Data  1.266 ( 2.403)	Loss 1.2087e-01 (1.7987e-01) 
2023-05-27 07:22:30.414475: val Epoch: [12][61/72]	Time  3.692 ( 2.539)	Data  3.584 ( 2.422)	Loss 1.1531e-01 (1.7883e-01) 
2023-05-27 07:22:31.796829: val Epoch: [12][62/72]	Time  1.382 ( 2.520)	Data  1.275 ( 2.404)	Loss 1.2287e-01 (1.7794e-01) 
2023-05-27 07:22:35.422893: val Epoch: [12][63/72]	Time  3.626 ( 2.537)	Data  3.515 ( 2.421)	Loss 9.9500e-02 (1.7672e-01) 
2023-05-27 07:22:37.047446: val Epoch: [12][64/72]	Time  1.625 ( 2.523)	Data  1.514 ( 2.407)	Loss 7.6699e-02 (1.7518e-01) 
2023-05-27 07:22:40.390244: val Epoch: [12][65/72]	Time  3.343 ( 2.536)	Data  3.235 ( 2.420)	Loss 6.7651e-02 (1.7355e-01) 
2023-05-27 07:22:41.910068: val Epoch: [12][66/72]	Time  1.520 ( 2.521)	Data  1.413 ( 2.405)	Loss 1.7708e-01 (1.7360e-01) 
2023-05-27 07:22:45.622864: val Epoch: [12][67/72]	Time  3.713 ( 2.538)	Data  3.608 ( 2.422)	Loss 3.8296e-01 (1.7668e-01) 
2023-05-27 07:22:46.602634: val Epoch: [12][68/72]	Time  0.980 ( 2.516)	Data  0.874 ( 2.400)	Loss 7.0244e-02 (1.7514e-01) 
2023-05-27 07:22:50.538049: val Epoch: [12][69/72]	Time  3.935 ( 2.536)	Data  3.830 ( 2.420)	Loss 1.3312e-01 (1.7454e-01) 
2023-05-27 07:22:51.384030: val Epoch: [12][70/72]	Time  0.846 ( 2.512)	Data  0.741 ( 2.397)	Loss 1.5732e-01 (1.7430e-01) 
2023-05-27 07:22:54.812965: val Epoch: [12][71/72]	Time  3.429 ( 2.525)	Data  3.323 ( 2.409)	Loss 8.8154e-02 (1.7310e-01) 
2023-05-27 07:22:55.113683: Epoch 12 :Val : ['ET : 0.7011967897415161', 'TC : 0.7120991945266724', 'WT : 0.8078659772872925'] 
2023-05-27 07:22:55.116396: Epoch 12 :Val : ['ET : 0.7011967897415161', 'TC : 0.7120991945266724', 'WT : 0.8078659772872925'] 
2023-05-27 07:22:55.118647: Val epoch done in 182.88325356697896 s 
2023-05-27 07:22:55.125899: Batches per epoch:  193 
2023-05-27 07:23:06.027325: train Epoch: [13][  0/193]	Time 10.901 (10.901)	Data 10.303 (10.303)	Loss 1.0496e-01 (1.0496e-01) 
2023-05-27 07:23:06.592311: train Epoch: [13][  1/193]	Time  0.565 ( 5.733)	Data  0.001 ( 5.152)	Loss 7.5004e-02 (8.9981e-02) 
2023-05-27 07:23:16.085331: train Epoch: [13][  2/193]	Time  9.493 ( 6.986)	Data  8.920 ( 6.408)	Loss 1.3984e-01 (1.0660e-01) 
2023-05-27 07:23:16.652125: train Epoch: [13][  3/193]	Time  0.567 ( 5.381)	Data  0.001 ( 4.806)	Loss 2.1592e-01 (1.3393e-01) 
2023-05-27 07:23:25.875182: train Epoch: [13][  4/193]	Time  9.223 ( 6.150)	Data  8.660 ( 5.577)	Loss 1.2699e-01 (1.3254e-01) 
2023-05-27 07:23:26.439159: train Epoch: [13][  5/193]	Time  0.564 ( 5.219)	Data  0.001 ( 4.648)	Loss 7.9123e-02 (1.2364e-01) 
2023-05-27 07:23:36.061598: train Epoch: [13][  6/193]	Time  9.622 ( 5.848)	Data  9.056 ( 5.277)	Loss 2.6422e-01 (1.4372e-01) 
2023-05-27 07:23:36.625375: train Epoch: [13][  7/193]	Time  0.564 ( 5.187)	Data  0.001 ( 4.618)	Loss 1.0150e-01 (1.3844e-01) 
2023-05-27 07:23:46.510869: train Epoch: [13][  8/193]	Time  9.885 ( 5.709)	Data  9.320 ( 5.140)	Loss 1.1854e-01 (1.3623e-01) 
2023-05-27 07:23:47.104792: train Epoch: [13][  9/193]	Time  0.594 ( 5.198)	Data  0.001 ( 4.626)	Loss 9.3340e-02 (1.3194e-01) 
2023-05-27 07:23:56.520375: train Epoch: [13][ 10/193]	Time  9.416 ( 5.581)	Data  8.842 ( 5.010)	Loss 2.4664e-01 (1.4237e-01) 
2023-05-27 07:23:57.089222: train Epoch: [13][ 11/193]	Time  0.569 ( 5.164)	Data  0.001 ( 4.592)	Loss 8.6931e-02 (1.3775e-01) 
2023-05-27 07:24:07.041099: train Epoch: [13][ 12/193]	Time  9.952 ( 5.532)	Data  9.349 ( 4.958)	Loss 1.1734e-01 (1.3618e-01) 
2023-05-27 07:24:07.611245: train Epoch: [13][ 13/193]	Time  0.570 ( 5.177)	Data  0.001 ( 4.604)	Loss 1.5895e-01 (1.3781e-01) 
2023-05-27 07:24:16.649723: train Epoch: [13][ 14/193]	Time  9.038 ( 5.435)	Data  8.472 ( 4.862)	Loss 5.9264e-02 (1.3257e-01) 
2023-05-27 07:24:17.230463: train Epoch: [13][ 15/193]	Time  0.581 ( 5.132)	Data  0.001 ( 4.558)	Loss 9.9736e-02 (1.3052e-01) 
2023-05-27 07:24:26.616663: train Epoch: [13][ 16/193]	Time  9.386 ( 5.382)	Data  8.790 ( 4.807)	Loss 1.4698e-01 (1.3149e-01) 
2023-05-27 07:24:27.189657: train Epoch: [13][ 17/193]	Time  0.573 ( 5.115)	Data  0.001 ( 4.540)	Loss 2.1045e-01 (1.3587e-01) 
2023-05-27 07:24:36.382221: train Epoch: [13][ 18/193]	Time  9.193 ( 5.329)	Data  8.621 ( 4.755)	Loss 9.3927e-02 (1.3367e-01) 
2023-05-27 07:24:36.970553: train Epoch: [13][ 19/193]	Time  0.588 ( 5.092)	Data  0.001 ( 4.517)	Loss 9.2858e-02 (1.3163e-01) 
2023-05-27 07:24:46.275970: train Epoch: [13][ 20/193]	Time  9.305 ( 5.293)	Data  8.728 ( 4.718)	Loss 1.8740e-01 (1.3428e-01) 
2023-05-27 07:24:46.843484: train Epoch: [13][ 21/193]	Time  0.567 ( 5.078)	Data  0.001 ( 4.503)	Loss 1.0313e-01 (1.3287e-01) 
2023-05-27 07:24:55.993282: train Epoch: [13][ 22/193]	Time  9.150 ( 5.255)	Data  8.586 ( 4.681)	Loss 1.7097e-01 (1.3452e-01) 
2023-05-27 07:24:56.558375: train Epoch: [13][ 23/193]	Time  0.565 ( 5.060)	Data  0.001 ( 4.486)	Loss 7.8261e-02 (1.3218e-01) 
2023-05-27 07:25:05.135541: train Epoch: [13][ 24/193]	Time  8.577 ( 5.200)	Data  8.005 ( 4.627)	Loss 1.0807e-01 (1.3121e-01) 
2023-05-27 07:25:05.737113: train Epoch: [13][ 25/193]	Time  0.602 ( 5.023)	Data  0.001 ( 4.449)	Loss 1.0602e-01 (1.3024e-01) 
2023-05-27 07:25:14.124926: train Epoch: [13][ 26/193]	Time  8.388 ( 5.148)	Data  7.811 ( 4.573)	Loss 9.1396e-02 (1.2881e-01) 
2023-05-27 07:25:14.693493: train Epoch: [13][ 27/193]	Time  0.569 ( 4.985)	Data  0.001 ( 4.410)	Loss 7.4177e-02 (1.2685e-01) 
2023-05-27 07:25:24.043995: train Epoch: [13][ 28/193]	Time  9.350 ( 5.135)	Data  8.785 ( 4.561)	Loss 9.6385e-02 (1.2580e-01) 
2023-05-27 07:25:24.617168: train Epoch: [13][ 29/193]	Time  0.573 ( 4.983)	Data  0.001 ( 4.409)	Loss 1.3541e-01 (1.2612e-01) 
2023-05-27 07:25:34.053424: train Epoch: [13][ 30/193]	Time  9.436 ( 5.127)	Data  8.860 ( 4.552)	Loss 9.5407e-02 (1.2513e-01) 
2023-05-27 07:25:34.632674: train Epoch: [13][ 31/193]	Time  0.579 ( 4.985)	Data  0.001 ( 4.410)	Loss 1.1890e-01 (1.2494e-01) 
2023-05-27 07:25:44.367471: train Epoch: [13][ 32/193]	Time  9.735 ( 5.129)	Data  9.165 ( 4.554)	Loss 8.5490e-02 (1.2374e-01) 
2023-05-27 07:25:44.939322: train Epoch: [13][ 33/193]	Time  0.572 ( 4.994)	Data  0.001 ( 4.420)	Loss 1.8225e-01 (1.2546e-01) 
2023-05-27 07:25:54.763766: train Epoch: [13][ 34/193]	Time  9.824 ( 5.132)	Data  9.258 ( 4.558)	Loss 1.2509e-01 (1.2545e-01) 
2023-05-27 07:25:55.340756: train Epoch: [13][ 35/193]	Time  0.577 ( 5.006)	Data  0.001 ( 4.432)	Loss 1.7261e-01 (1.2676e-01) 
2023-05-27 07:26:04.970683: train Epoch: [13][ 36/193]	Time  9.630 ( 5.131)	Data  9.055 ( 4.557)	Loss 1.8678e-01 (1.2838e-01) 
2023-05-27 07:26:05.533436: train Epoch: [13][ 37/193]	Time  0.563 ( 5.011)	Data  0.001 ( 4.437)	Loss 8.9167e-02 (1.2735e-01) 
2023-05-27 07:26:14.701365: train Epoch: [13][ 38/193]	Time  9.168 ( 5.117)	Data  8.595 ( 4.544)	Loss 1.1555e-01 (1.2705e-01) 
2023-05-27 07:26:15.278374: train Epoch: [13][ 39/193]	Time  0.577 ( 5.004)	Data  0.001 ( 4.430)	Loss 1.2842e-01 (1.2708e-01) 
2023-05-27 07:26:24.597779: train Epoch: [13][ 40/193]	Time  9.319 ( 5.109)	Data  8.747 ( 4.535)	Loss 1.8127e-01 (1.2841e-01) 
2023-05-27 07:26:25.173885: train Epoch: [13][ 41/193]	Time  0.576 ( 5.001)	Data  0.001 ( 4.427)	Loss 9.5337e-02 (1.2762e-01) 
2023-05-27 07:26:34.351942: train Epoch: [13][ 42/193]	Time  9.178 ( 5.098)	Data  8.612 ( 4.525)	Loss 1.9322e-01 (1.2914e-01) 
2023-05-27 07:26:34.915564: train Epoch: [13][ 43/193]	Time  0.564 ( 4.995)	Data  0.001 ( 4.422)	Loss 1.2948e-01 (1.2915e-01) 
2023-05-27 07:26:44.557691: train Epoch: [13][ 44/193]	Time  9.642 ( 5.098)	Data  9.076 ( 4.525)	Loss 1.2723e-01 (1.2911e-01) 
2023-05-27 07:26:45.141143: train Epoch: [13][ 45/193]	Time  0.583 ( 5.000)	Data  0.001 ( 4.427)	Loss 1.1310e-01 (1.2876e-01) 
2023-05-27 07:26:54.280631: train Epoch: [13][ 46/193]	Time  9.139 ( 5.088)	Data  8.575 ( 4.515)	Loss 1.2277e-01 (1.2863e-01) 
2023-05-27 07:26:54.842725: train Epoch: [13][ 47/193]	Time  0.562 ( 4.994)	Data  0.001 ( 4.421)	Loss 8.2772e-02 (1.2768e-01) 
2023-05-27 07:27:03.526728: train Epoch: [13][ 48/193]	Time  8.684 ( 5.069)	Data  8.102 ( 4.496)	Loss 1.0376e-01 (1.2719e-01) 
2023-05-27 07:27:04.090666: train Epoch: [13][ 49/193]	Time  0.564 ( 4.979)	Data  0.001 ( 4.406)	Loss 9.7352e-02 (1.2659e-01) 
2023-05-27 07:27:12.827459: train Epoch: [13][ 50/193]	Time  8.737 ( 5.053)	Data  8.173 ( 4.480)	Loss 1.4540e-01 (1.2696e-01) 
2023-05-27 07:27:13.421173: train Epoch: [13][ 51/193]	Time  0.594 ( 4.967)	Data  0.031 ( 4.395)	Loss 8.4197e-02 (1.2614e-01) 
2023-05-27 07:27:22.632806: train Epoch: [13][ 52/193]	Time  9.212 ( 5.047)	Data  8.647 ( 4.475)	Loss 1.1611e-01 (1.2595e-01) 
2023-05-27 07:27:23.221632: train Epoch: [13][ 53/193]	Time  0.589 ( 4.965)	Data  0.026 ( 4.392)	Loss 5.8858e-02 (1.2471e-01) 
2023-05-27 07:27:32.645284: train Epoch: [13][ 54/193]	Time  9.424 ( 5.046)	Data  8.857 ( 4.474)	Loss 1.6881e-01 (1.2551e-01) 
2023-05-27 07:27:33.207991: train Epoch: [13][ 55/193]	Time  0.563 ( 4.966)	Data  0.001 ( 4.394)	Loss 1.2728e-01 (1.2554e-01) 
2023-05-27 07:27:42.393953: train Epoch: [13][ 56/193]	Time  9.186 ( 5.040)	Data  8.621 ( 4.468)	Loss 1.3045e-01 (1.2563e-01) 
2023-05-27 07:27:42.970016: train Epoch: [13][ 57/193]	Time  0.576 ( 4.963)	Data  0.001 ( 4.391)	Loss 1.1984e-01 (1.2553e-01) 
2023-05-27 07:27:52.325227: train Epoch: [13][ 58/193]	Time  9.355 ( 5.037)	Data  8.786 ( 4.465)	Loss 9.3051e-02 (1.2498e-01) 
2023-05-27 07:27:52.887935: train Epoch: [13][ 59/193]	Time  0.563 ( 4.963)	Data  0.001 ( 4.391)	Loss 3.2493e-01 (1.2831e-01) 
2023-05-27 07:28:02.282540: train Epoch: [13][ 60/193]	Time  9.395 ( 5.035)	Data  8.820 ( 4.464)	Loss 5.6770e-02 (1.2714e-01) 
2023-05-27 07:28:02.850178: train Epoch: [13][ 61/193]	Time  0.568 ( 4.963)	Data  0.001 ( 4.392)	Loss 9.4292e-02 (1.2661e-01) 
2023-05-27 07:28:11.511014: train Epoch: [13][ 62/193]	Time  8.661 ( 5.022)	Data  8.092 ( 4.450)	Loss 9.0273e-02 (1.2603e-01) 
2023-05-27 07:28:12.083272: train Epoch: [13][ 63/193]	Time  0.572 ( 4.952)	Data  0.001 ( 4.381)	Loss 9.2965e-02 (1.2551e-01) 
2023-05-27 07:28:21.760764: train Epoch: [13][ 64/193]	Time  9.677 ( 5.025)	Data  9.106 ( 4.454)	Loss 1.1230e-01 (1.2531e-01) 
2023-05-27 07:28:22.330465: train Epoch: [13][ 65/193]	Time  0.570 ( 4.958)	Data  0.001 ( 4.386)	Loss 1.5427e-01 (1.2575e-01) 
2023-05-27 07:28:31.501547: train Epoch: [13][ 66/193]	Time  9.171 ( 5.021)	Data  8.603 ( 4.449)	Loss 1.1255e-01 (1.2555e-01) 
2023-05-27 07:28:32.067216: train Epoch: [13][ 67/193]	Time  0.566 ( 4.955)	Data  0.001 ( 4.384)	Loss 7.8769e-02 (1.2486e-01) 
2023-05-27 07:28:40.746031: train Epoch: [13][ 68/193]	Time  8.679 ( 5.009)	Data  8.081 ( 4.437)	Loss 8.1012e-02 (1.2423e-01) 
2023-05-27 07:28:41.310093: train Epoch: [13][ 69/193]	Time  0.564 ( 4.945)	Data  0.001 ( 4.374)	Loss 1.4457e-01 (1.2452e-01) 
2023-05-27 07:28:50.794285: train Epoch: [13][ 70/193]	Time  9.484 ( 5.009)	Data  8.919 ( 4.438)	Loss 4.4264e-02 (1.2339e-01) 
2023-05-27 07:28:51.358747: train Epoch: [13][ 71/193]	Time  0.564 ( 4.948)	Data  0.001 ( 4.376)	Loss 3.7035e-01 (1.2682e-01) 
2023-05-27 07:29:00.569554: train Epoch: [13][ 72/193]	Time  9.211 ( 5.006)	Data  8.646 ( 4.435)	Loss 9.2649e-02 (1.2635e-01) 
2023-05-27 07:29:01.133658: train Epoch: [13][ 73/193]	Time  0.564 ( 4.946)	Data  0.001 ( 4.375)	Loss 1.1097e-01 (1.2614e-01) 
2023-05-27 07:29:10.177918: train Epoch: [13][ 74/193]	Time  9.044 ( 5.001)	Data  8.475 ( 4.429)	Loss 1.0673e-01 (1.2588e-01) 
2023-05-27 07:29:10.748957: train Epoch: [13][ 75/193]	Time  0.571 ( 4.942)	Data  0.001 ( 4.371)	Loss 7.8288e-02 (1.2526e-01) 
2023-05-27 07:29:20.585946: train Epoch: [13][ 76/193]	Time  9.837 ( 5.006)	Data  9.261 ( 4.435)	Loss 1.2675e-01 (1.2528e-01) 
2023-05-27 07:29:21.155440: train Epoch: [13][ 77/193]	Time  0.569 ( 4.949)	Data  0.001 ( 4.378)	Loss 9.3825e-02 (1.2487e-01) 
2023-05-27 07:29:30.646770: train Epoch: [13][ 78/193]	Time  9.491 ( 5.007)	Data  8.921 ( 4.435)	Loss 3.4135e-01 (1.2761e-01) 
2023-05-27 07:29:31.227010: train Epoch: [13][ 79/193]	Time  0.580 ( 4.951)	Data  0.001 ( 4.380)	Loss 9.4054e-02 (1.2719e-01) 
2023-05-27 07:29:40.879594: train Epoch: [13][ 80/193]	Time  9.653 ( 5.009)	Data  9.089 ( 4.438)	Loss 1.1014e-01 (1.2698e-01) 
2023-05-27 07:29:41.451486: train Epoch: [13][ 81/193]	Time  0.572 ( 4.955)	Data  0.001 ( 4.384)	Loss 1.0798e-01 (1.2675e-01) 
2023-05-27 07:29:51.004426: train Epoch: [13][ 82/193]	Time  9.553 ( 5.011)	Data  8.987 ( 4.439)	Loss 1.4454e-01 (1.2697e-01) 
2023-05-27 07:29:51.571442: train Epoch: [13][ 83/193]	Time  0.567 ( 4.958)	Data  0.001 ( 4.387)	Loss 1.6618e-01 (1.2743e-01) 
2023-05-27 07:30:01.215583: train Epoch: [13][ 84/193]	Time  9.644 ( 5.013)	Data  9.080 ( 4.442)	Loss 2.5544e-01 (1.2894e-01) 
2023-05-27 07:30:01.781090: train Epoch: [13][ 85/193]	Time  0.566 ( 4.961)	Data  0.001 ( 4.390)	Loss 1.2294e-01 (1.2887e-01) 
2023-05-27 07:30:10.784777: train Epoch: [13][ 86/193]	Time  9.004 ( 5.008)	Data  8.431 ( 4.437)	Loss 1.3995e-01 (1.2900e-01) 
2023-05-27 07:30:11.349966: train Epoch: [13][ 87/193]	Time  0.565 ( 4.957)	Data  0.001 ( 4.386)	Loss 6.9874e-02 (1.2833e-01) 
2023-05-27 07:30:21.071995: train Epoch: [13][ 88/193]	Time  9.722 ( 5.011)	Data  9.152 ( 4.440)	Loss 1.0359e-01 (1.2805e-01) 
2023-05-27 07:30:21.652186: train Epoch: [13][ 89/193]	Time  0.580 ( 4.961)	Data  0.001 ( 4.390)	Loss 1.1249e-01 (1.2787e-01) 
2023-05-27 07:30:31.248546: train Epoch: [13][ 90/193]	Time  9.596 ( 5.012)	Data  9.031 ( 4.441)	Loss 9.1567e-02 (1.2748e-01) 
2023-05-27 07:30:31.828392: train Epoch: [13][ 91/193]	Time  0.580 ( 4.964)	Data  0.001 ( 4.393)	Loss 1.1313e-01 (1.2732e-01) 
2023-05-27 07:30:40.385354: train Epoch: [13][ 92/193]	Time  8.557 ( 5.003)	Data  7.985 ( 4.432)	Loss 7.0268e-02 (1.2671e-01) 
2023-05-27 07:30:40.954098: train Epoch: [13][ 93/193]	Time  0.569 ( 4.956)	Data  0.001 ( 4.385)	Loss 1.7209e-01 (1.2719e-01) 
2023-05-27 07:30:49.311720: train Epoch: [13][ 94/193]	Time  8.358 ( 4.991)	Data  7.763 ( 4.420)	Loss 1.5050e-01 (1.2743e-01) 
2023-05-27 07:30:49.879910: train Epoch: [13][ 95/193]	Time  0.568 ( 4.945)	Data  0.001 ( 4.374)	Loss 1.1553e-01 (1.2731e-01) 
2023-05-27 07:30:58.676471: train Epoch: [13][ 96/193]	Time  8.797 ( 4.985)	Data  8.217 ( 4.414)	Loss 1.0821e-01 (1.2711e-01) 
2023-05-27 07:30:59.261210: train Epoch: [13][ 97/193]	Time  0.585 ( 4.940)	Data  0.001 ( 4.369)	Loss 8.4691e-02 (1.2668e-01) 
2023-05-27 07:31:08.927449: train Epoch: [13][ 98/193]	Time  9.666 ( 4.988)	Data  9.102 ( 4.417)	Loss 9.6361e-02 (1.2637e-01) 
2023-05-27 07:31:09.504872: train Epoch: [13][ 99/193]	Time  0.577 ( 4.944)	Data  0.001 ( 4.372)	Loss 1.3264e-01 (1.2644e-01) 
2023-05-27 07:31:18.723517: train Epoch: [13][100/193]	Time  9.219 ( 4.986)	Data  8.654 ( 4.415)	Loss 1.0643e-01 (1.2624e-01) 
2023-05-27 07:31:19.298947: train Epoch: [13][101/193]	Time  0.575 ( 4.943)	Data  0.001 ( 4.371)	Loss 1.0523e-01 (1.2603e-01) 
2023-05-27 07:31:28.854073: train Epoch: [13][102/193]	Time  9.555 ( 4.988)	Data  8.986 ( 4.416)	Loss 1.3465e-01 (1.2612e-01) 
2023-05-27 07:31:29.432985: train Epoch: [13][103/193]	Time  0.579 ( 4.945)	Data  0.001 ( 4.374)	Loss 9.4402e-02 (1.2581e-01) 
2023-05-27 07:31:39.034750: train Epoch: [13][104/193]	Time  9.602 ( 4.990)	Data  9.022 ( 4.418)	Loss 1.0068e-01 (1.2557e-01) 
2023-05-27 07:31:39.612258: train Epoch: [13][105/193]	Time  0.578 ( 4.948)	Data  0.001 ( 4.376)	Loss 7.3944e-02 (1.2509e-01) 
2023-05-27 07:31:48.454746: train Epoch: [13][106/193]	Time  8.842 ( 4.984)	Data  8.273 ( 4.413)	Loss 8.4881e-02 (1.2471e-01) 
2023-05-27 07:31:49.047745: train Epoch: [13][107/193]	Time  0.593 ( 4.944)	Data  0.001 ( 4.372)	Loss 1.6863e-01 (1.2512e-01) 
2023-05-27 07:31:58.868994: train Epoch: [13][108/193]	Time  9.821 ( 4.988)	Data  9.245 ( 4.417)	Loss 9.8469e-02 (1.2487e-01) 
2023-05-27 07:31:59.438577: train Epoch: [13][109/193]	Time  0.570 ( 4.948)	Data  0.001 ( 4.377)	Loss 2.0292e-01 (1.2558e-01) 
2023-05-27 07:32:08.727482: train Epoch: [13][110/193]	Time  9.289 ( 4.987)	Data  8.715 ( 4.416)	Loss 1.0908e-01 (1.2543e-01) 
2023-05-27 07:32:09.300630: train Epoch: [13][111/193]	Time  0.573 ( 4.948)	Data  0.001 ( 4.376)	Loss 7.3800e-02 (1.2497e-01) 
2023-05-27 07:32:18.592340: train Epoch: [13][112/193]	Time  9.292 ( 4.986)	Data  8.722 ( 4.415)	Loss 1.3870e-01 (1.2509e-01) 
2023-05-27 07:32:19.164902: train Epoch: [13][113/193]	Time  0.573 ( 4.948)	Data  0.001 ( 4.376)	Loss 1.3086e-01 (1.2514e-01) 
2023-05-27 07:32:29.064674: train Epoch: [13][114/193]	Time  9.900 ( 4.991)	Data  9.316 ( 4.419)	Loss 8.2667e-02 (1.2477e-01) 
2023-05-27 07:32:29.656655: train Epoch: [13][115/193]	Time  0.592 ( 4.953)	Data  0.001 ( 4.381)	Loss 8.9305e-02 (1.2447e-01) 
2023-05-27 07:32:38.719067: train Epoch: [13][116/193]	Time  9.062 ( 4.988)	Data  8.496 ( 4.416)	Loss 1.0284e-01 (1.2428e-01) 
2023-05-27 07:32:39.308432: train Epoch: [13][117/193]	Time  0.589 ( 4.951)	Data  0.001 ( 4.379)	Loss 1.2330e-01 (1.2428e-01) 
2023-05-27 07:32:48.624141: train Epoch: [13][118/193]	Time  9.316 ( 4.987)	Data  8.734 ( 4.415)	Loss 1.1466e-01 (1.2419e-01) 
2023-05-27 07:32:49.335237: train Epoch: [13][119/193]	Time  0.711 ( 4.952)	Data  0.001 ( 4.378)	Loss 1.3317e-01 (1.2427e-01) 
2023-05-27 07:32:58.381871: train Epoch: [13][120/193]	Time  9.047 ( 4.986)	Data  8.468 ( 4.412)	Loss 9.8511e-02 (1.2406e-01) 
2023-05-27 07:32:58.954821: train Epoch: [13][121/193]	Time  0.573 ( 4.949)	Data  0.001 ( 4.376)	Loss 1.1742e-01 (1.2400e-01) 
2023-05-27 07:33:08.368727: train Epoch: [13][122/193]	Time  9.414 ( 4.986)	Data  8.843 ( 4.412)	Loss 1.8879e-01 (1.2453e-01) 
2023-05-27 07:33:08.968898: train Epoch: [13][123/193]	Time  0.600 ( 4.950)	Data  0.001 ( 4.377)	Loss 1.7509e-01 (1.2494e-01) 
2023-05-27 07:33:18.035722: train Epoch: [13][124/193]	Time  9.067 ( 4.983)	Data  8.495 ( 4.410)	Loss 6.3288e-02 (1.2444e-01) 
2023-05-27 07:33:18.607630: train Epoch: [13][125/193]	Time  0.572 ( 4.948)	Data  0.001 ( 4.375)	Loss 1.0753e-01 (1.2431e-01) 
2023-05-27 07:33:27.858560: train Epoch: [13][126/193]	Time  9.251 ( 4.982)	Data  8.685 ( 4.409)	Loss 1.4980e-01 (1.2451e-01) 
2023-05-27 07:33:28.436457: train Epoch: [13][127/193]	Time  0.578 ( 4.948)	Data  0.001 ( 4.374)	Loss 7.5824e-02 (1.2413e-01) 
2023-05-27 07:33:37.963781: train Epoch: [13][128/193]	Time  9.527 ( 4.983)	Data  8.929 ( 4.410)	Loss 7.3397e-02 (1.2374e-01) 
2023-05-27 07:33:38.529089: train Epoch: [13][129/193]	Time  0.565 ( 4.949)	Data  0.001 ( 4.376)	Loss 2.8113e-01 (1.2495e-01) 
2023-05-27 07:33:48.104609: train Epoch: [13][130/193]	Time  9.576 ( 4.985)	Data  8.982 ( 4.411)	Loss 8.6523e-02 (1.2465e-01) 
2023-05-27 07:33:48.672621: train Epoch: [13][131/193]	Time  0.568 ( 4.951)	Data  0.001 ( 4.377)	Loss 1.1556e-01 (1.2458e-01) 
2023-05-27 07:33:57.415725: train Epoch: [13][132/193]	Time  8.743 ( 4.980)	Data  8.173 ( 4.406)	Loss 7.9336e-02 (1.2424e-01) 
2023-05-27 07:33:57.992453: train Epoch: [13][133/193]	Time  0.577 ( 4.947)	Data  0.001 ( 4.373)	Loss 2.2079e-01 (1.2496e-01) 
2023-05-27 07:34:07.742160: train Epoch: [13][134/193]	Time  9.750 ( 4.982)	Data  9.170 ( 4.409)	Loss 6.0912e-02 (1.2449e-01) 
2023-05-27 07:34:08.313148: train Epoch: [13][135/193]	Time  0.571 ( 4.950)	Data  0.001 ( 4.376)	Loss 3.0315e-01 (1.2580e-01) 
2023-05-27 07:34:17.885851: train Epoch: [13][136/193]	Time  9.573 ( 4.984)	Data  8.993 ( 4.410)	Loss 1.2886e-01 (1.2583e-01) 
2023-05-27 07:34:18.449278: train Epoch: [13][137/193]	Time  0.563 ( 4.952)	Data  0.001 ( 4.378)	Loss 1.1735e-01 (1.2576e-01) 
2023-05-27 07:34:27.607729: train Epoch: [13][138/193]	Time  9.158 ( 4.982)	Data  8.590 ( 4.408)	Loss 1.1814e-01 (1.2571e-01) 
2023-05-27 07:34:28.179556: train Epoch: [13][139/193]	Time  0.572 ( 4.950)	Data  0.001 ( 4.377)	Loss 7.7756e-02 (1.2537e-01) 
2023-05-27 07:34:37.300951: train Epoch: [13][140/193]	Time  9.121 ( 4.980)	Data  8.543 ( 4.406)	Loss 7.8482e-02 (1.2504e-01) 
2023-05-27 07:34:37.896833: train Epoch: [13][141/193]	Time  0.596 ( 4.949)	Data  0.001 ( 4.375)	Loss 1.7522e-01 (1.2539e-01) 
2023-05-27 07:34:47.444576: train Epoch: [13][142/193]	Time  9.548 ( 4.981)	Data  8.952 ( 4.407)	Loss 9.6488e-02 (1.2519e-01) 
2023-05-27 07:34:48.033744: train Epoch: [13][143/193]	Time  0.589 ( 4.951)	Data  0.001 ( 4.377)	Loss 1.3766e-01 (1.2527e-01) 
2023-05-27 07:34:57.509393: train Epoch: [13][144/193]	Time  9.476 ( 4.982)	Data  8.900 ( 4.408)	Loss 1.1467e-01 (1.2520e-01) 
2023-05-27 07:34:58.113934: train Epoch: [13][145/193]	Time  0.605 ( 4.952)	Data  0.001 ( 4.378)	Loss 8.7425e-02 (1.2494e-01) 
2023-05-27 07:35:07.161778: train Epoch: [13][146/193]	Time  9.048 ( 4.980)	Data  8.474 ( 4.406)	Loss 1.4998e-01 (1.2511e-01) 
2023-05-27 07:35:07.762307: train Epoch: [13][147/193]	Time  0.601 ( 4.950)	Data  0.001 ( 4.376)	Loss 7.0087e-02 (1.2474e-01) 
2023-05-27 07:35:17.111087: train Epoch: [13][148/193]	Time  9.349 ( 4.980)	Data  8.772 ( 4.405)	Loss 1.4949e-01 (1.2491e-01) 
2023-05-27 07:35:17.675904: train Epoch: [13][149/193]	Time  0.565 ( 4.950)	Data  0.001 ( 4.376)	Loss 7.9151e-02 (1.2460e-01) 
2023-05-27 07:35:27.139517: train Epoch: [13][150/193]	Time  9.464 ( 4.980)	Data  8.883 ( 4.406)	Loss 1.3360e-01 (1.2466e-01) 
2023-05-27 07:35:27.703562: train Epoch: [13][151/193]	Time  0.564 ( 4.951)	Data  0.001 ( 4.377)	Loss 8.4866e-02 (1.2440e-01) 
2023-05-27 07:35:37.324374: train Epoch: [13][152/193]	Time  9.621 ( 4.982)	Data  9.010 ( 4.407)	Loss 1.1722e-01 (1.2435e-01) 
2023-05-27 07:35:37.891142: train Epoch: [13][153/193]	Time  0.567 ( 4.953)	Data  0.001 ( 4.378)	Loss 7.2888e-02 (1.2402e-01) 
2023-05-27 07:35:46.921943: train Epoch: [13][154/193]	Time  9.031 ( 4.979)	Data  8.462 ( 4.405)	Loss 1.4467e-01 (1.2415e-01) 
2023-05-27 07:35:47.501184: train Epoch: [13][155/193]	Time  0.579 ( 4.951)	Data  0.001 ( 4.377)	Loss 1.1699e-01 (1.2410e-01) 
2023-05-27 07:35:57.275742: train Epoch: [13][156/193]	Time  9.775 ( 4.982)	Data  9.209 ( 4.407)	Loss 1.1312e-01 (1.2403e-01) 
2023-05-27 07:35:57.843398: train Epoch: [13][157/193]	Time  0.568 ( 4.954)	Data  0.001 ( 4.379)	Loss 6.6769e-02 (1.2367e-01) 
2023-05-27 07:36:07.187995: train Epoch: [13][158/193]	Time  9.345 ( 4.982)	Data  8.781 ( 4.407)	Loss 1.0418e-01 (1.2355e-01) 
2023-05-27 07:36:07.754244: train Epoch: [13][159/193]	Time  0.566 ( 4.954)	Data  0.001 ( 4.380)	Loss 6.9326e-02 (1.2321e-01) 
2023-05-27 07:36:17.592116: train Epoch: [13][160/193]	Time  9.838 ( 4.984)	Data  9.269 ( 4.410)	Loss 5.3614e-02 (1.2278e-01) 
2023-05-27 07:36:18.155990: train Epoch: [13][161/193]	Time  0.564 ( 4.957)	Data  0.001 ( 4.383)	Loss 7.8195e-02 (1.2250e-01) 
2023-05-27 07:36:27.452627: train Epoch: [13][162/193]	Time  9.297 ( 4.984)	Data  8.733 ( 4.409)	Loss 1.7667e-01 (1.2284e-01) 
2023-05-27 07:36:28.018419: train Epoch: [13][163/193]	Time  0.566 ( 4.957)	Data  0.001 ( 4.383)	Loss 1.0197e-01 (1.2271e-01) 
2023-05-27 07:36:37.622439: train Epoch: [13][164/193]	Time  9.604 ( 4.985)	Data  9.033 ( 4.411)	Loss 8.7231e-02 (1.2249e-01) 
2023-05-27 07:36:38.191636: train Epoch: [13][165/193]	Time  0.569 ( 4.958)	Data  0.001 ( 4.384)	Loss 1.5430e-01 (1.2269e-01) 
2023-05-27 07:36:47.476474: train Epoch: [13][166/193]	Time  9.285 ( 4.984)	Data  8.716 ( 4.410)	Loss 1.5546e-01 (1.2288e-01) 
2023-05-27 07:36:48.046644: train Epoch: [13][167/193]	Time  0.570 ( 4.958)	Data  0.001 ( 4.384)	Loss 8.7126e-02 (1.2267e-01) 
2023-05-27 07:36:57.634140: train Epoch: [13][168/193]	Time  9.587 ( 4.985)	Data  9.019 ( 4.411)	Loss 1.1752e-01 (1.2264e-01) 
2023-05-27 07:36:58.206957: train Epoch: [13][169/193]	Time  0.573 ( 4.959)	Data  0.001 ( 4.385)	Loss 1.1646e-01 (1.2260e-01) 
2023-05-27 07:37:08.116269: train Epoch: [13][170/193]	Time  9.909 ( 4.988)	Data  9.333 ( 4.414)	Loss 1.3399e-01 (1.2267e-01) 
2023-05-27 07:37:08.683692: train Epoch: [13][171/193]	Time  0.567 ( 4.963)	Data  0.001 ( 4.389)	Loss 1.2875e-01 (1.2270e-01) 
2023-05-27 07:37:18.042959: train Epoch: [13][172/193]	Time  9.359 ( 4.988)	Data  8.794 ( 4.414)	Loss 2.0374e-01 (1.2317e-01) 
2023-05-27 07:37:18.614743: train Epoch: [13][173/193]	Time  0.572 ( 4.963)	Data  0.001 ( 4.389)	Loss 8.7804e-02 (1.2297e-01) 
2023-05-27 07:37:27.789033: train Epoch: [13][174/193]	Time  9.174 ( 4.987)	Data  8.610 ( 4.413)	Loss 1.0333e-01 (1.2286e-01) 
2023-05-27 07:37:28.402569: train Epoch: [13][175/193]	Time  0.614 ( 4.962)	Data  0.001 ( 4.388)	Loss 1.1149e-01 (1.2279e-01) 
2023-05-27 07:37:38.121206: train Epoch: [13][176/193]	Time  9.719 ( 4.989)	Data  9.150 ( 4.415)	Loss 2.6872e-01 (1.2362e-01) 
2023-05-27 07:37:38.687343: train Epoch: [13][177/193]	Time  0.566 ( 4.964)	Data  0.001 ( 4.390)	Loss 9.1562e-02 (1.2344e-01) 
2023-05-27 07:37:48.104568: train Epoch: [13][178/193]	Time  9.417 ( 4.989)	Data  8.850 ( 4.415)	Loss 1.3299e-01 (1.2349e-01) 
2023-05-27 07:37:48.669366: train Epoch: [13][179/193]	Time  0.565 ( 4.964)	Data  0.001 ( 4.390)	Loss 7.7974e-02 (1.2324e-01) 
2023-05-27 07:37:58.041322: train Epoch: [13][180/193]	Time  9.372 ( 4.988)	Data  8.793 ( 4.415)	Loss 1.3311e-01 (1.2329e-01) 
2023-05-27 07:37:58.605673: train Epoch: [13][181/193]	Time  0.564 ( 4.964)	Data  0.001 ( 4.390)	Loss 1.0316e-01 (1.2318e-01) 
2023-05-27 07:38:08.309184: train Epoch: [13][182/193]	Time  9.703 ( 4.990)	Data  9.127 ( 4.416)	Loss 8.6434e-02 (1.2298e-01) 
2023-05-27 07:38:08.888685: train Epoch: [13][183/193]	Time  0.580 ( 4.966)	Data  0.001 ( 4.392)	Loss 1.2212e-01 (1.2298e-01) 
2023-05-27 07:38:17.873439: train Epoch: [13][184/193]	Time  8.985 ( 4.988)	Data  8.411 ( 4.414)	Loss 1.2656e-01 (1.2299e-01) 
2023-05-27 07:38:18.444433: train Epoch: [13][185/193]	Time  0.571 ( 4.964)	Data  0.001 ( 4.390)	Loss 7.6234e-02 (1.2274e-01) 
2023-05-27 07:38:27.894980: train Epoch: [13][186/193]	Time  9.451 ( 4.988)	Data  8.885 ( 4.414)	Loss 1.1272e-01 (1.2269e-01) 
2023-05-27 07:38:28.458314: train Epoch: [13][187/193]	Time  0.563 ( 4.965)	Data  0.001 ( 4.391)	Loss 2.7878e-01 (1.2352e-01) 
2023-05-27 07:38:37.797475: train Epoch: [13][188/193]	Time  9.339 ( 4.988)	Data  8.762 ( 4.414)	Loss 1.4790e-01 (1.2365e-01) 
2023-05-27 07:38:38.364290: train Epoch: [13][189/193]	Time  0.567 ( 4.964)	Data  0.001 ( 4.391)	Loss 1.0956e-01 (1.2357e-01) 
2023-05-27 07:38:47.225509: train Epoch: [13][190/193]	Time  8.861 ( 4.985)	Data  8.297 ( 4.411)	Loss 1.7831e-01 (1.2386e-01) 
2023-05-27 07:38:47.789567: train Epoch: [13][191/193]	Time  0.564 ( 4.962)	Data  0.001 ( 4.388)	Loss 7.1148e-02 (1.2359e-01) 
2023-05-27 07:38:55.806981: train Epoch: [13][192/193]	Time  8.017 ( 4.978)	Data  7.444 ( 4.404)	Loss 1.0375e-01 (1.2348e-01) 
2023-05-27 07:38:55.962626: Train Epoch done in 960.8367613470182 s 
2023-05-27 07:39:02.305973: val Epoch: [13][ 0/72]	Time  5.588 ( 5.588)	Data  5.408 ( 5.408)	Loss 1.0677e-01 (1.0677e-01) 
2023-05-27 07:39:02.569676: val Epoch: [13][ 1/72]	Time  0.264 ( 2.926)	Data  0.145 ( 2.777)	Loss 1.9613e-01 (1.5145e-01) 
2023-05-27 07:39:07.228482: val Epoch: [13][ 2/72]	Time  4.659 ( 3.503)	Data  4.548 ( 3.367)	Loss 1.4174e-01 (1.4821e-01) 
2023-05-27 07:39:07.452364: val Epoch: [13][ 3/72]	Time  0.224 ( 2.684)	Data  0.113 ( 2.553)	Loss 8.0467e-02 (1.3128e-01) 
2023-05-27 07:39:12.320645: val Epoch: [13][ 4/72]	Time  4.868 ( 3.120)	Data  4.756 ( 2.994)	Loss 6.7959e-02 (1.1861e-01) 
2023-05-27 07:39:12.741587: val Epoch: [13][ 5/72]	Time  0.421 ( 2.671)	Data  0.294 ( 2.544)	Loss 2.9470e-01 (1.4796e-01) 
2023-05-27 07:39:17.383371: val Epoch: [13][ 6/72]	Time  4.642 ( 2.952)	Data  4.534 ( 2.828)	Loss 1.1039e-01 (1.4259e-01) 
2023-05-27 07:39:17.581534: val Epoch: [13][ 7/72]	Time  0.198 ( 2.608)	Data  0.090 ( 2.486)	Loss 1.4691e-01 (1.4313e-01) 
2023-05-27 07:39:22.180635: val Epoch: [13][ 8/72]	Time  4.599 ( 2.829)	Data  4.487 ( 2.708)	Loss 1.5639e-01 (1.4461e-01) 
2023-05-27 07:39:22.494146: val Epoch: [13][ 9/72]	Time  0.314 ( 2.578)	Data  0.204 ( 2.458)	Loss 7.9328e-02 (1.3808e-01) 
2023-05-27 07:39:27.320196: val Epoch: [13][10/72]	Time  4.826 ( 2.782)	Data  4.718 ( 2.663)	Loss 7.8903e-02 (1.3270e-01) 
2023-05-27 07:39:27.703652: val Epoch: [13][11/72]	Time  0.383 ( 2.582)	Data  0.255 ( 2.463)	Loss 4.5903e-01 (1.5989e-01) 
2023-05-27 07:39:32.227955: val Epoch: [13][12/72]	Time  4.524 ( 2.732)	Data  4.417 ( 2.613)	Loss 1.9065e-01 (1.6226e-01) 
2023-05-27 07:39:32.668576: val Epoch: [13][13/72]	Time  0.441 ( 2.568)	Data  0.325 ( 2.450)	Loss 1.1092e-01 (1.5859e-01) 
2023-05-27 07:39:37.271353: val Epoch: [13][14/72]	Time  4.603 ( 2.704)	Data  4.495 ( 2.586)	Loss 4.9426e-01 (1.8097e-01) 
2023-05-27 07:39:37.829191: val Epoch: [13][15/72]	Time  0.558 ( 2.569)	Data  0.445 ( 2.452)	Loss 1.7658e-01 (1.8070e-01) 
2023-05-27 07:39:42.592462: val Epoch: [13][16/72]	Time  4.763 ( 2.698)	Data  4.656 ( 2.582)	Loss 7.4753e-02 (1.7446e-01) 
2023-05-27 07:39:42.699515: val Epoch: [13][17/72]	Time  0.107 ( 2.555)	Data  0.000 ( 2.438)	Loss 6.6065e-02 (1.6844e-01) 
2023-05-27 07:39:47.712366: val Epoch: [13][18/72]	Time  5.013 ( 2.684)	Data  4.905 ( 2.568)	Loss 3.5103e-01 (1.7805e-01) 
2023-05-27 07:39:47.819652: val Epoch: [13][19/72]	Time  0.107 ( 2.555)	Data  0.001 ( 2.440)	Loss 7.0763e-02 (1.7269e-01) 
2023-05-27 07:39:52.752121: val Epoch: [13][20/72]	Time  4.932 ( 2.668)	Data  4.824 ( 2.553)	Loss 9.6572e-02 (1.6906e-01) 
2023-05-27 07:39:52.859833: val Epoch: [13][21/72]	Time  0.108 ( 2.552)	Data  0.000 ( 2.437)	Loss 6.1062e-02 (1.6415e-01) 
2023-05-27 07:39:58.054032: val Epoch: [13][22/72]	Time  5.194 ( 2.667)	Data  5.079 ( 2.552)	Loss 7.4131e-02 (1.6024e-01) 
2023-05-27 07:39:58.172841: val Epoch: [13][23/72]	Time  0.119 ( 2.561)	Data  0.001 ( 2.446)	Loss 1.3187e-01 (1.5906e-01) 
2023-05-27 07:40:03.268011: val Epoch: [13][24/72]	Time  5.095 ( 2.662)	Data  4.970 ( 2.547)	Loss 9.1045e-02 (1.5634e-01) 
2023-05-27 07:40:03.390747: val Epoch: [13][25/72]	Time  0.123 ( 2.564)	Data  0.001 ( 2.449)	Loss 8.7313e-02 (1.5368e-01) 
2023-05-27 07:40:08.190524: val Epoch: [13][26/72]	Time  4.800 ( 2.647)	Data  4.687 ( 2.532)	Loss 1.4898e-01 (1.5351e-01) 
2023-05-27 07:40:08.317214: val Epoch: [13][27/72]	Time  0.127 ( 2.557)	Data  0.001 ( 2.441)	Loss 2.1480e-01 (1.5570e-01) 
2023-05-27 07:40:13.437546: val Epoch: [13][28/72]	Time  5.120 ( 2.645)	Data  4.987 ( 2.529)	Loss 3.4578e-01 (1.6225e-01) 
2023-05-27 07:40:13.559299: val Epoch: [13][29/72]	Time  0.122 ( 2.561)	Data  0.001 ( 2.445)	Loss 4.8289e-01 (1.7294e-01) 
2023-05-27 07:40:18.388659: val Epoch: [13][30/72]	Time  4.829 ( 2.635)	Data  4.682 ( 2.517)	Loss 8.1309e-02 (1.6998e-01) 
2023-05-27 07:40:18.503458: val Epoch: [13][31/72]	Time  0.115 ( 2.556)	Data  0.001 ( 2.438)	Loss 1.0205e-01 (1.6786e-01) 
2023-05-27 07:40:23.438864: val Epoch: [13][32/72]	Time  4.935 ( 2.628)	Data  4.823 ( 2.511)	Loss 5.6843e-02 (1.6450e-01) 
2023-05-27 07:40:23.589541: val Epoch: [13][33/72]	Time  0.151 ( 2.555)	Data  0.044 ( 2.438)	Loss 9.5299e-02 (1.6246e-01) 
2023-05-27 07:40:28.532457: val Epoch: [13][34/72]	Time  4.943 ( 2.623)	Data  4.836 ( 2.507)	Loss 1.1384e-01 (1.6107e-01) 
2023-05-27 07:40:28.730687: val Epoch: [13][35/72]	Time  0.198 ( 2.556)	Data  0.084 ( 2.439)	Loss 2.1227e-01 (1.6249e-01) 
2023-05-27 07:40:34.090483: val Epoch: [13][36/72]	Time  5.360 ( 2.632)	Data  5.149 ( 2.513)	Loss 9.5539e-02 (1.6069e-01) 
2023-05-27 07:40:34.252760: val Epoch: [13][37/72]	Time  0.162 ( 2.567)	Data  0.002 ( 2.446)	Loss 8.7692e-02 (1.5876e-01) 
2023-05-27 07:40:38.819968: val Epoch: [13][38/72]	Time  4.567 ( 2.618)	Data  4.455 ( 2.498)	Loss 1.6132e-01 (1.5883e-01) 
2023-05-27 07:40:39.053115: val Epoch: [13][39/72]	Time  0.233 ( 2.558)	Data  0.075 ( 2.437)	Loss 1.9236e-01 (1.5967e-01) 
2023-05-27 07:40:43.840211: val Epoch: [13][40/72]	Time  4.787 ( 2.613)	Data  4.650 ( 2.491)	Loss 9.6626e-02 (1.5813e-01) 
2023-05-27 07:40:43.950673: val Epoch: [13][41/72]	Time  0.110 ( 2.553)	Data  0.001 ( 2.432)	Loss 6.2660e-02 (1.5586e-01) 
2023-05-27 07:40:48.719877: val Epoch: [13][42/72]	Time  4.769 ( 2.605)	Data  4.657 ( 2.484)	Loss 7.7035e-02 (1.5402e-01) 
2023-05-27 07:40:49.000580: val Epoch: [13][43/72]	Time  0.281 ( 2.552)	Data  0.171 ( 2.431)	Loss 1.3025e-01 (1.5348e-01) 
2023-05-27 07:40:53.773358: val Epoch: [13][44/72]	Time  4.773 ( 2.601)	Data  4.660 ( 2.481)	Loss 1.7369e-01 (1.5393e-01) 
2023-05-27 07:40:54.091766: val Epoch: [13][45/72]	Time  0.318 ( 2.552)	Data  0.201 ( 2.431)	Loss 1.3568e-01 (1.5354e-01) 
2023-05-27 07:40:58.803721: val Epoch: [13][46/72]	Time  4.712 ( 2.598)	Data  4.601 ( 2.477)	Loss 1.6571e-01 (1.5380e-01) 
2023-05-27 07:40:59.269656: val Epoch: [13][47/72]	Time  0.466 ( 2.553)	Data  0.359 ( 2.433)	Loss 3.6225e-01 (1.5814e-01) 
2023-05-27 07:41:03.686874: val Epoch: [13][48/72]	Time  4.417 ( 2.591)	Data  4.306 ( 2.471)	Loss 1.4221e-01 (1.5781e-01) 
2023-05-27 07:41:04.341896: val Epoch: [13][49/72]	Time  0.655 ( 2.552)	Data  0.529 ( 2.433)	Loss 1.5649e-01 (1.5779e-01) 
2023-05-27 07:41:08.607393: val Epoch: [13][50/72]	Time  4.266 ( 2.586)	Data  4.155 ( 2.466)	Loss 1.0912e-01 (1.5683e-01) 
2023-05-27 07:41:09.271175: val Epoch: [13][51/72]	Time  0.664 ( 2.549)	Data  0.553 ( 2.430)	Loss 2.1893e-01 (1.5803e-01) 
2023-05-27 07:41:13.541716: val Epoch: [13][52/72]	Time  4.271 ( 2.582)	Data  4.159 ( 2.462)	Loss 9.3227e-02 (1.5680e-01) 
2023-05-27 07:41:14.188396: val Epoch: [13][53/72]	Time  0.647 ( 2.546)	Data  0.539 ( 2.427)	Loss 9.8174e-02 (1.5572e-01) 
2023-05-27 07:41:18.449673: val Epoch: [13][54/72]	Time  4.261 ( 2.577)	Data  4.139 ( 2.458)	Loss 9.4972e-02 (1.5461e-01) 
2023-05-27 07:41:19.257918: val Epoch: [13][55/72]	Time  0.808 ( 2.545)	Data  0.682 ( 2.426)	Loss 7.1084e-02 (1.5312e-01) 
2023-05-27 07:41:23.349130: val Epoch: [13][56/72]	Time  4.091 ( 2.572)	Data  3.979 ( 2.453)	Loss 4.5226e-01 (1.5837e-01) 
2023-05-27 07:41:24.333943: val Epoch: [13][57/72]	Time  0.985 ( 2.545)	Data  0.874 ( 2.426)	Loss 1.2823e-01 (1.5785e-01) 
2023-05-27 07:41:28.637344: val Epoch: [13][58/72]	Time  4.303 ( 2.575)	Data  4.193 ( 2.456)	Loss 6.8272e-02 (1.5633e-01) 
2023-05-27 07:41:29.527988: val Epoch: [13][59/72]	Time  0.891 ( 2.547)	Data  0.780 ( 2.428)	Loss 3.2689e-01 (1.5917e-01) 
2023-05-27 07:41:33.528341: val Epoch: [13][60/72]	Time  4.000 ( 2.571)	Data  3.887 ( 2.452)	Loss 5.8348e-02 (1.5752e-01) 
2023-05-27 07:41:34.488471: val Epoch: [13][61/72]	Time  0.960 ( 2.545)	Data  0.848 ( 2.426)	Loss 7.1356e-02 (1.5613e-01) 
2023-05-27 07:41:38.967512: val Epoch: [13][62/72]	Time  4.479 ( 2.575)	Data  4.368 ( 2.457)	Loss 4.8895e-01 (1.6141e-01) 
2023-05-27 07:41:39.328847: val Epoch: [13][63/72]	Time  0.361 ( 2.541)	Data  0.250 ( 2.422)	Loss 6.5022e-02 (1.5991e-01) 
2023-05-27 07:41:44.291655: val Epoch: [13][64/72]	Time  4.963 ( 2.578)	Data  4.854 ( 2.460)	Loss 3.9119e-01 (1.6347e-01) 
2023-05-27 07:41:44.755022: val Epoch: [13][65/72]	Time  0.463 ( 2.546)	Data  0.355 ( 2.428)	Loss 1.8189e-01 (1.6375e-01) 
2023-05-27 07:41:49.179498: val Epoch: [13][66/72]	Time  4.424 ( 2.574)	Data  4.313 ( 2.456)	Loss 5.5561e-02 (1.6213e-01) 
2023-05-27 07:41:49.860460: val Epoch: [13][67/72]	Time  0.681 ( 2.546)	Data  0.574 ( 2.428)	Loss 1.5440e-01 (1.6202e-01) 
2023-05-27 07:41:53.982431: val Epoch: [13][68/72]	Time  4.122 ( 2.569)	Data  4.015 ( 2.451)	Loss 8.4812e-02 (1.6090e-01) 
2023-05-27 07:41:54.636928: val Epoch: [13][69/72]	Time  0.654 ( 2.542)	Data  0.547 ( 2.424)	Loss 8.0149e-02 (1.5975e-01) 
2023-05-27 07:41:58.998886: val Epoch: [13][70/72]	Time  4.362 ( 2.567)	Data  4.255 ( 2.450)	Loss 6.3258e-02 (1.5839e-01) 
2023-05-27 07:41:59.610510: val Epoch: [13][71/72]	Time  0.612 ( 2.540)	Data  0.504 ( 2.423)	Loss 6.1421e-02 (1.5704e-01) 
2023-05-27 07:41:59.893678: Epoch 13 :Val : ['ET : 0.6981923580169678', 'TC : 0.7417876720428467', 'WT : 0.8352106809616089'] 
2023-05-27 07:41:59.894434: Epoch 13 :Val : ['ET : 0.6981923580169678', 'TC : 0.7417876720428467', 'WT : 0.8352106809616089'] 
2023-05-27 07:41:59.897990: Saving the model with DSC 0.7587957382202148 
2023-05-27 07:42:00.602917: Val epoch done in 184.64028141100425 s 
2023-05-27 07:42:00.608656: Batches per epoch:  193 
2023-05-27 07:42:11.932446: train Epoch: [14][  0/193]	Time 11.323 (11.323)	Data 10.686 (10.686)	Loss 1.0435e-01 (1.0435e-01) 
2023-05-27 07:42:12.499177: train Epoch: [14][  1/193]	Time  0.567 ( 5.945)	Data  0.001 ( 5.343)	Loss 1.2635e-01 (1.1535e-01) 
2023-05-27 07:42:22.191592: train Epoch: [14][  2/193]	Time  9.692 ( 7.194)	Data  9.118 ( 6.602)	Loss 1.0259e-01 (1.1109e-01) 
2023-05-27 07:42:22.825110: train Epoch: [14][  3/193]	Time  0.634 ( 5.554)	Data  0.001 ( 4.951)	Loss 1.7903e-01 (1.2808e-01) 
2023-05-27 07:42:31.953099: train Epoch: [14][  4/193]	Time  9.128 ( 6.269)	Data  8.517 ( 5.665)	Loss 1.0880e-01 (1.2422e-01) 
2023-05-27 07:42:32.526583: train Epoch: [14][  5/193]	Time  0.573 ( 5.320)	Data  0.001 ( 4.721)	Loss 9.3702e-02 (1.1913e-01) 
2023-05-27 07:42:41.727477: train Epoch: [14][  6/193]	Time  9.201 ( 5.874)	Data  8.628 ( 5.279)	Loss 1.0632e-01 (1.1730e-01) 
2023-05-27 07:42:42.321062: train Epoch: [14][  7/193]	Time  0.594 ( 5.214)	Data  0.001 ( 4.619)	Loss 1.1970e-01 (1.1760e-01) 
2023-05-27 07:42:52.140901: train Epoch: [14][  8/193]	Time  9.820 ( 5.726)	Data  9.217 ( 5.130)	Loss 7.8665e-02 (1.1328e-01) 
2023-05-27 07:42:52.715403: train Epoch: [14][  9/193]	Time  0.575 ( 5.211)	Data  0.001 ( 4.617)	Loss 7.1154e-02 (1.0907e-01) 
2023-05-27 07:43:02.663775: train Epoch: [14][ 10/193]	Time  9.948 ( 5.641)	Data  9.328 ( 5.045)	Loss 1.0459e-01 (1.0866e-01) 
2023-05-27 07:43:03.232027: train Epoch: [14][ 11/193]	Time  0.568 ( 5.219)	Data  0.001 ( 4.625)	Loss 8.0500e-02 (1.0631e-01) 
2023-05-27 07:43:12.678030: train Epoch: [14][ 12/193]	Time  9.446 ( 5.544)	Data  8.863 ( 4.951)	Loss 1.1369e-01 (1.0688e-01) 
2023-05-27 07:43:13.246653: train Epoch: [14][ 13/193]	Time  0.569 ( 5.188)	Data  0.001 ( 4.597)	Loss 9.0230e-02 (1.0569e-01) 
2023-05-27 07:43:22.850625: train Epoch: [14][ 14/193]	Time  9.604 ( 5.483)	Data  9.033 ( 4.893)	Loss 1.8667e-01 (1.1109e-01) 
2023-05-27 07:43:23.420718: train Epoch: [14][ 15/193]	Time  0.570 ( 5.176)	Data  0.001 ( 4.587)	Loss 1.4571e-01 (1.1325e-01) 
2023-05-27 07:43:32.883784: train Epoch: [14][ 16/193]	Time  9.463 ( 5.428)	Data  8.888 ( 4.840)	Loss 8.4540e-02 (1.1156e-01) 
2023-05-27 07:43:33.457546: train Epoch: [14][ 17/193]	Time  0.574 ( 5.158)	Data  0.001 ( 4.571)	Loss 8.8798e-02 (1.1030e-01) 
2023-05-27 07:43:42.642619: train Epoch: [14][ 18/193]	Time  9.185 ( 5.370)	Data  8.607 ( 4.784)	Loss 7.7443e-02 (1.0857e-01) 
2023-05-27 07:43:43.211760: train Epoch: [14][ 19/193]	Time  0.569 ( 5.130)	Data  0.001 ( 4.545)	Loss 8.9251e-02 (1.0760e-01) 
2023-05-27 07:43:52.918375: train Epoch: [14][ 20/193]	Time  9.707 ( 5.348)	Data  9.143 ( 4.764)	Loss 1.5255e-01 (1.0974e-01) 
2023-05-27 07:43:53.480974: train Epoch: [14][ 21/193]	Time  0.563 ( 5.131)	Data  0.001 ( 4.547)	Loss 1.0302e-01 (1.0944e-01) 
2023-05-27 07:44:02.645547: train Epoch: [14][ 22/193]	Time  9.165 ( 5.306)	Data  8.588 ( 4.723)	Loss 1.2238e-01 (1.1000e-01) 
2023-05-27 07:44:03.209383: train Epoch: [14][ 23/193]	Time  0.564 ( 5.108)	Data  0.001 ( 4.526)	Loss 9.6246e-02 (1.0943e-01) 
2023-05-27 07:44:11.506939: train Epoch: [14][ 24/193]	Time  8.298 ( 5.236)	Data  7.735 ( 4.654)	Loss 1.0752e-01 (1.0935e-01) 
2023-05-27 07:44:12.071517: train Epoch: [14][ 25/193]	Time  0.565 ( 5.056)	Data  0.001 ( 4.475)	Loss 8.5942e-02 (1.0845e-01) 
2023-05-27 07:44:21.157802: train Epoch: [14][ 26/193]	Time  9.086 ( 5.206)	Data  8.515 ( 4.625)	Loss 1.5962e-01 (1.1035e-01) 
2023-05-27 07:44:21.727932: train Epoch: [14][ 27/193]	Time  0.570 ( 5.040)	Data  0.001 ( 4.460)	Loss 1.7103e-01 (1.1251e-01) 
2023-05-27 07:44:30.912530: train Epoch: [14][ 28/193]	Time  9.185 ( 5.183)	Data  8.606 ( 4.603)	Loss 7.4577e-02 (1.1121e-01) 
2023-05-27 07:44:31.475092: train Epoch: [14][ 29/193]	Time  0.563 ( 5.029)	Data  0.001 ( 4.449)	Loss 1.1180e-01 (1.1123e-01) 
2023-05-27 07:44:40.588674: train Epoch: [14][ 30/193]	Time  9.114 ( 5.161)	Data  8.548 ( 4.582)	Loss 1.8877e-01 (1.1373e-01) 
2023-05-27 07:44:41.151919: train Epoch: [14][ 31/193]	Time  0.563 ( 5.017)	Data  0.001 ( 4.439)	Loss 7.4659e-02 (1.1251e-01) 
2023-05-27 07:44:50.744792: train Epoch: [14][ 32/193]	Time  9.593 ( 5.156)	Data  9.022 ( 4.577)	Loss 9.6858e-02 (1.1203e-01) 
2023-05-27 07:44:51.308364: train Epoch: [14][ 33/193]	Time  0.564 ( 5.021)	Data  0.001 ( 4.443)	Loss 1.7427e-01 (1.1386e-01) 
2023-05-27 07:45:00.591255: train Epoch: [14][ 34/193]	Time  9.283 ( 5.142)	Data  8.701 ( 4.564)	Loss 1.5146e-01 (1.1494e-01) 
2023-05-27 07:45:01.156161: train Epoch: [14][ 35/193]	Time  0.565 ( 5.015)	Data  0.001 ( 4.438)	Loss 9.3834e-02 (1.1435e-01) 
2023-05-27 07:45:10.729427: train Epoch: [14][ 36/193]	Time  9.573 ( 5.138)	Data  9.008 ( 4.561)	Loss 1.1032e-01 (1.1424e-01) 
2023-05-27 07:45:11.301578: train Epoch: [14][ 37/193]	Time  0.572 ( 5.018)	Data  0.001 ( 4.441)	Loss 1.3387e-01 (1.1476e-01) 
2023-05-27 07:45:20.756643: train Epoch: [14][ 38/193]	Time  9.455 ( 5.132)	Data  8.886 ( 4.555)	Loss 9.4513e-02 (1.1424e-01) 
2023-05-27 07:45:21.322114: train Epoch: [14][ 39/193]	Time  0.565 ( 5.018)	Data  0.001 ( 4.441)	Loss 1.1088e-01 (1.1415e-01) 
2023-05-27 07:45:30.591711: train Epoch: [14][ 40/193]	Time  9.270 ( 5.122)	Data  8.702 ( 4.545)	Loss 9.8122e-02 (1.1376e-01) 
2023-05-27 07:45:31.154959: train Epoch: [14][ 41/193]	Time  0.563 ( 5.013)	Data  0.001 ( 4.437)	Loss 1.2242e-01 (1.1397e-01) 
2023-05-27 07:45:40.568076: train Epoch: [14][ 42/193]	Time  9.413 ( 5.115)	Data  8.850 ( 4.540)	Loss 1.0152e-01 (1.1368e-01) 
2023-05-27 07:45:41.131683: train Epoch: [14][ 43/193]	Time  0.564 ( 5.012)	Data  0.001 ( 4.437)	Loss 8.6159e-02 (1.1305e-01) 
2023-05-27 07:45:49.771817: train Epoch: [14][ 44/193]	Time  8.640 ( 5.093)	Data  8.077 ( 4.517)	Loss 9.0069e-02 (1.1254e-01) 
2023-05-27 07:45:50.337749: train Epoch: [14][ 45/193]	Time  0.566 ( 4.994)	Data  0.001 ( 4.419)	Loss 8.0326e-02 (1.1184e-01) 
2023-05-27 07:45:58.871503: train Epoch: [14][ 46/193]	Time  8.534 ( 5.069)	Data  7.971 ( 4.495)	Loss 7.4719e-02 (1.1105e-01) 
2023-05-27 07:45:59.439028: train Epoch: [14][ 47/193]	Time  0.568 ( 4.976)	Data  0.001 ( 4.401)	Loss 1.2062e-01 (1.1125e-01) 
2023-05-27 07:46:08.660259: train Epoch: [14][ 48/193]	Time  9.221 ( 5.062)	Data  8.658 ( 4.488)	Loss 1.2711e-01 (1.1158e-01) 
2023-05-27 07:46:09.226344: train Epoch: [14][ 49/193]	Time  0.566 ( 4.972)	Data  0.001 ( 4.398)	Loss 8.7831e-02 (1.1110e-01) 
2023-05-27 07:46:18.420794: train Epoch: [14][ 50/193]	Time  9.194 ( 5.055)	Data  8.623 ( 4.481)	Loss 7.6045e-02 (1.1041e-01) 
2023-05-27 07:46:18.984168: train Epoch: [14][ 51/193]	Time  0.563 ( 4.969)	Data  0.001 ( 4.395)	Loss 8.5286e-02 (1.0993e-01) 
2023-05-27 07:46:28.217686: train Epoch: [14][ 52/193]	Time  9.234 ( 5.049)	Data  8.671 ( 4.476)	Loss 1.7740e-01 (1.1120e-01) 
2023-05-27 07:46:28.793815: train Epoch: [14][ 53/193]	Time  0.576 ( 4.966)	Data  0.001 ( 4.393)	Loss 1.3484e-01 (1.1164e-01) 
2023-05-27 07:46:38.030453: train Epoch: [14][ 54/193]	Time  9.237 ( 5.044)	Data  8.674 ( 4.471)	Loss 1.0726e-01 (1.1156e-01) 
2023-05-27 07:46:38.595423: train Epoch: [14][ 55/193]	Time  0.565 ( 4.964)	Data  0.001 ( 4.391)	Loss 1.9181e-01 (1.1300e-01) 
2023-05-27 07:46:48.114942: train Epoch: [14][ 56/193]	Time  9.520 ( 5.044)	Data  8.956 ( 4.471)	Loss 1.3377e-01 (1.1336e-01) 
2023-05-27 07:46:48.678077: train Epoch: [14][ 57/193]	Time  0.563 ( 4.967)	Data  0.001 ( 4.394)	Loss 1.5032e-01 (1.1400e-01) 
2023-05-27 07:46:57.768194: train Epoch: [14][ 58/193]	Time  9.090 ( 5.037)	Data  8.528 ( 4.464)	Loss 8.5847e-02 (1.1352e-01) 
2023-05-27 07:46:58.336086: train Epoch: [14][ 59/193]	Time  0.568 ( 4.962)	Data  0.001 ( 4.390)	Loss 1.2826e-01 (1.1377e-01) 
2023-05-27 07:47:07.482039: train Epoch: [14][ 60/193]	Time  9.146 ( 5.031)	Data  8.572 ( 4.458)	Loss 1.4011e-01 (1.1420e-01) 
2023-05-27 07:47:08.047086: train Epoch: [14][ 61/193]	Time  0.565 ( 4.959)	Data  0.001 ( 4.386)	Loss 1.1720e-01 (1.1425e-01) 
2023-05-27 07:47:17.134811: train Epoch: [14][ 62/193]	Time  9.088 ( 5.024)	Data  8.521 ( 4.452)	Loss 8.6965e-02 (1.1381e-01) 
2023-05-27 07:47:17.708002: train Epoch: [14][ 63/193]	Time  0.573 ( 4.955)	Data  0.001 ( 4.382)	Loss 9.6770e-02 (1.1355e-01) 
2023-05-27 07:47:27.385555: train Epoch: [14][ 64/193]	Time  9.678 ( 5.027)	Data  9.107 ( 4.455)	Loss 8.9386e-02 (1.1317e-01) 
2023-05-27 07:47:27.956328: train Epoch: [14][ 65/193]	Time  0.571 ( 4.960)	Data  0.001 ( 4.388)	Loss 6.8996e-02 (1.1251e-01) 
2023-05-27 07:47:36.952278: train Epoch: [14][ 66/193]	Time  8.996 ( 5.020)	Data  8.427 ( 4.448)	Loss 9.3174e-02 (1.1222e-01) 
2023-05-27 07:47:37.523184: train Epoch: [14][ 67/193]	Time  0.571 ( 4.955)	Data  0.001 ( 4.382)	Loss 8.3965e-02 (1.1180e-01) 
2023-05-27 07:47:46.841515: train Epoch: [14][ 68/193]	Time  9.318 ( 5.018)	Data  8.740 ( 4.446)	Loss 6.5322e-02 (1.1113e-01) 
2023-05-27 07:47:47.412113: train Epoch: [14][ 69/193]	Time  0.571 ( 4.954)	Data  0.001 ( 4.382)	Loss 9.8774e-02 (1.1095e-01) 
2023-05-27 07:47:56.632886: train Epoch: [14][ 70/193]	Time  9.221 ( 5.014)	Data  8.658 ( 4.442)	Loss 1.3498e-01 (1.1129e-01) 
2023-05-27 07:47:57.197293: train Epoch: [14][ 71/193]	Time  0.564 ( 4.953)	Data  0.001 ( 4.381)	Loss 1.2315e-01 (1.1145e-01) 
2023-05-27 07:48:06.439064: train Epoch: [14][ 72/193]	Time  9.242 ( 5.011)	Data  8.679 ( 4.439)	Loss 1.2985e-01 (1.1171e-01) 
2023-05-27 07:48:07.004012: train Epoch: [14][ 73/193]	Time  0.565 ( 4.951)	Data  0.001 ( 4.379)	Loss 1.1789e-01 (1.1179e-01) 
2023-05-27 07:48:16.452417: train Epoch: [14][ 74/193]	Time  9.448 ( 5.011)	Data  8.884 ( 4.440)	Loss 1.1668e-01 (1.1186e-01) 
2023-05-27 07:48:17.016574: train Epoch: [14][ 75/193]	Time  0.564 ( 4.953)	Data  0.001 ( 4.381)	Loss 1.0385e-01 (1.1175e-01) 
2023-05-27 07:48:26.585876: train Epoch: [14][ 76/193]	Time  9.569 ( 5.013)	Data  9.007 ( 4.441)	Loss 6.7924e-02 (1.1118e-01) 
2023-05-27 07:48:27.150702: train Epoch: [14][ 77/193]	Time  0.565 ( 4.956)	Data  0.001 ( 4.384)	Loss 1.0676e-01 (1.1112e-01) 
2023-05-27 07:48:36.336984: train Epoch: [14][ 78/193]	Time  9.186 ( 5.009)	Data  8.618 ( 4.438)	Loss 9.0355e-02 (1.1086e-01) 
2023-05-27 07:48:36.901378: train Epoch: [14][ 79/193]	Time  0.564 ( 4.954)	Data  0.001 ( 4.382)	Loss 7.6531e-02 (1.1043e-01) 
2023-05-27 07:48:45.951628: train Epoch: [14][ 80/193]	Time  9.050 ( 5.004)	Data  8.487 ( 4.433)	Loss 1.1956e-01 (1.1054e-01) 
2023-05-27 07:48:46.514440: train Epoch: [14][ 81/193]	Time  0.563 ( 4.950)	Data  0.001 ( 4.379)	Loss 1.2847e-01 (1.1076e-01) 
2023-05-27 07:48:55.461679: train Epoch: [14][ 82/193]	Time  8.947 ( 4.998)	Data  8.371 ( 4.427)	Loss 1.1524e-01 (1.1082e-01) 
2023-05-27 07:48:56.030117: train Epoch: [14][ 83/193]	Time  0.568 ( 4.945)	Data  0.001 ( 4.374)	Loss 8.0968e-02 (1.1046e-01) 
2023-05-27 07:49:05.226183: train Epoch: [14][ 84/193]	Time  9.196 ( 4.995)	Data  8.626 ( 4.424)	Loss 1.0293e-01 (1.1037e-01) 
2023-05-27 07:49:05.803866: train Epoch: [14][ 85/193]	Time  0.578 ( 4.944)	Data  0.001 ( 4.373)	Loss 1.3382e-01 (1.1065e-01) 
2023-05-27 07:49:15.592717: train Epoch: [14][ 86/193]	Time  9.789 ( 5.000)	Data  9.216 ( 4.429)	Loss 1.2178e-01 (1.1077e-01) 
2023-05-27 07:49:16.161144: train Epoch: [14][ 87/193]	Time  0.568 ( 4.949)	Data  0.001 ( 4.378)	Loss 8.6104e-02 (1.1049e-01) 
2023-05-27 07:49:25.846900: train Epoch: [14][ 88/193]	Time  9.686 ( 5.003)	Data  9.107 ( 4.432)	Loss 1.1345e-01 (1.1053e-01) 
2023-05-27 07:49:26.414845: train Epoch: [14][ 89/193]	Time  0.568 ( 4.953)	Data  0.001 ( 4.382)	Loss 1.0464e-01 (1.1046e-01) 
2023-05-27 07:49:35.811361: train Epoch: [14][ 90/193]	Time  9.396 ( 5.002)	Data  8.820 ( 4.431)	Loss 7.7686e-02 (1.1010e-01) 
2023-05-27 07:49:36.380539: train Epoch: [14][ 91/193]	Time  0.569 ( 4.954)	Data  0.001 ( 4.383)	Loss 1.0544e-01 (1.1005e-01) 
2023-05-27 07:49:44.338295: train Epoch: [14][ 92/193]	Time  7.958 ( 4.986)	Data  7.391 ( 4.415)	Loss 7.9741e-02 (1.0972e-01) 
2023-05-27 07:49:44.912727: train Epoch: [14][ 93/193]	Time  0.574 ( 4.939)	Data  0.001 ( 4.368)	Loss 6.9469e-02 (1.0930e-01) 
2023-05-27 07:49:52.820505: train Epoch: [14][ 94/193]	Time  7.908 ( 4.971)	Data  7.336 ( 4.400)	Loss 1.2890e-01 (1.0950e-01) 
2023-05-27 07:49:53.393105: train Epoch: [14][ 95/193]	Time  0.573 ( 4.925)	Data  0.001 ( 4.354)	Loss 9.5035e-02 (1.0935e-01) 
2023-05-27 07:50:02.833489: train Epoch: [14][ 96/193]	Time  9.440 ( 4.971)	Data  8.867 ( 4.400)	Loss 7.6850e-02 (1.0902e-01) 
2023-05-27 07:50:03.399435: train Epoch: [14][ 97/193]	Time  0.566 ( 4.926)	Data  0.001 ( 4.355)	Loss 1.4574e-01 (1.0939e-01) 
2023-05-27 07:50:12.657429: train Epoch: [14][ 98/193]	Time  9.258 ( 4.970)	Data  8.670 ( 4.399)	Loss 9.8554e-02 (1.0928e-01) 
2023-05-27 07:50:13.231012: train Epoch: [14][ 99/193]	Time  0.574 ( 4.926)	Data  0.001 ( 4.355)	Loss 8.1709e-02 (1.0901e-01) 
2023-05-27 07:50:23.130973: train Epoch: [14][100/193]	Time  9.900 ( 4.975)	Data  9.329 ( 4.404)	Loss 9.0249e-02 (1.0882e-01) 
2023-05-27 07:50:23.698076: train Epoch: [14][101/193]	Time  0.567 ( 4.932)	Data  0.001 ( 4.361)	Loss 1.6279e-01 (1.0935e-01) 
2023-05-27 07:50:33.137052: train Epoch: [14][102/193]	Time  9.439 ( 4.976)	Data  8.877 ( 4.405)	Loss 7.5208e-02 (1.0902e-01) 
2023-05-27 07:50:33.701635: train Epoch: [14][103/193]	Time  0.565 ( 4.934)	Data  0.001 ( 4.363)	Loss 1.7352e-01 (1.0964e-01) 
2023-05-27 07:50:43.101893: train Epoch: [14][104/193]	Time  9.400 ( 4.976)	Data  8.831 ( 4.405)	Loss 1.7960e-01 (1.1030e-01) 
2023-05-27 07:50:43.669409: train Epoch: [14][105/193]	Time  0.568 ( 4.935)	Data  0.001 ( 4.364)	Loss 1.0944e-01 (1.1030e-01) 
2023-05-27 07:50:53.017540: train Epoch: [14][106/193]	Time  9.348 ( 4.976)	Data  8.774 ( 4.405)	Loss 2.3353e-01 (1.1145e-01) 
2023-05-27 07:50:53.581674: train Epoch: [14][107/193]	Time  0.564 ( 4.935)	Data  0.001 ( 4.364)	Loss 9.7721e-02 (1.1132e-01) 
2023-05-27 07:51:03.068596: train Epoch: [14][108/193]	Time  9.487 ( 4.977)	Data  8.915 ( 4.406)	Loss 9.5668e-02 (1.1118e-01) 
2023-05-27 07:51:03.631590: train Epoch: [14][109/193]	Time  0.563 ( 4.937)	Data  0.001 ( 4.366)	Loss 9.0263e-02 (1.1099e-01) 
2023-05-27 07:51:13.251708: train Epoch: [14][110/193]	Time  9.620 ( 4.979)	Data  9.052 ( 4.408)	Loss 6.4244e-02 (1.1057e-01) 
2023-05-27 07:51:13.815763: train Epoch: [14][111/193]	Time  0.564 ( 4.939)	Data  0.001 ( 4.369)	Loss 1.0389e-01 (1.1051e-01) 
2023-05-27 07:51:23.208477: train Epoch: [14][112/193]	Time  9.393 ( 4.979)	Data  8.815 ( 4.408)	Loss 8.9515e-02 (1.1032e-01) 
2023-05-27 07:51:23.776325: train Epoch: [14][113/193]	Time  0.568 ( 4.940)	Data  0.001 ( 4.369)	Loss 6.4196e-02 (1.0992e-01) 
2023-05-27 07:51:32.951359: train Epoch: [14][114/193]	Time  9.175 ( 4.977)	Data  8.604 ( 4.406)	Loss 7.8880e-02 (1.0965e-01) 
2023-05-27 07:51:33.519323: train Epoch: [14][115/193]	Time  0.568 ( 4.939)	Data  0.001 ( 4.368)	Loss 1.2856e-01 (1.0981e-01) 
2023-05-27 07:51:42.856615: train Epoch: [14][116/193]	Time  9.337 ( 4.976)	Data  8.765 ( 4.406)	Loss 1.4703e-01 (1.1013e-01) 
2023-05-27 07:51:43.420105: train Epoch: [14][117/193]	Time  0.563 ( 4.939)	Data  0.001 ( 4.368)	Loss 7.4943e-02 (1.0983e-01) 
2023-05-27 07:51:52.891048: train Epoch: [14][118/193]	Time  9.471 ( 4.977)	Data  8.859 ( 4.406)	Loss 1.0198e-01 (1.0976e-01) 
2023-05-27 07:51:53.467561: train Epoch: [14][119/193]	Time  0.577 ( 4.940)	Data  0.001 ( 4.369)	Loss 2.1091e-01 (1.1061e-01) 
2023-05-27 07:52:02.513753: train Epoch: [14][120/193]	Time  9.046 ( 4.974)	Data  8.474 ( 4.403)	Loss 1.2843e-01 (1.1075e-01) 
2023-05-27 07:52:03.086711: train Epoch: [14][121/193]	Time  0.573 ( 4.938)	Data  0.001 ( 4.367)	Loss 5.9128e-02 (1.1033e-01) 
2023-05-27 07:52:12.448660: train Epoch: [14][122/193]	Time  9.362 ( 4.974)	Data  8.781 ( 4.403)	Loss 5.8117e-02 (1.0991e-01) 
2023-05-27 07:52:13.026084: train Epoch: [14][123/193]	Time  0.577 ( 4.939)	Data  0.001 ( 4.368)	Loss 1.3262e-01 (1.1009e-01) 
2023-05-27 07:52:22.331140: train Epoch: [14][124/193]	Time  9.305 ( 4.974)	Data  8.728 ( 4.402)	Loss 9.6823e-02 (1.0998e-01) 
2023-05-27 07:52:22.909429: train Epoch: [14][125/193]	Time  0.578 ( 4.939)	Data  0.001 ( 4.368)	Loss 6.0670e-02 (1.0959e-01) 
2023-05-27 07:52:32.703296: train Epoch: [14][126/193]	Time  9.794 ( 4.977)	Data  9.219 ( 4.406)	Loss 9.6294e-02 (1.0949e-01) 
2023-05-27 07:52:33.265177: train Epoch: [14][127/193]	Time  0.562 ( 4.943)	Data  0.001 ( 4.371)	Loss 2.4126e-01 (1.1052e-01) 
2023-05-27 07:52:42.844832: train Epoch: [14][128/193]	Time  9.580 ( 4.979)	Data  9.009 ( 4.407)	Loss 1.3846e-01 (1.1073e-01) 
2023-05-27 07:52:43.407888: train Epoch: [14][129/193]	Time  0.563 ( 4.945)	Data  0.001 ( 4.373)	Loss 1.5529e-01 (1.1108e-01) 
2023-05-27 07:52:52.505529: train Epoch: [14][130/193]	Time  9.098 ( 4.976)	Data  8.536 ( 4.405)	Loss 1.0981e-01 (1.1107e-01) 
2023-05-27 07:52:53.066162: train Epoch: [14][131/193]	Time  0.561 ( 4.943)	Data  0.001 ( 4.372)	Loss 8.3307e-02 (1.1086e-01) 
2023-05-27 07:53:02.290583: train Epoch: [14][132/193]	Time  9.224 ( 4.975)	Data  8.657 ( 4.404)	Loss 8.8945e-02 (1.1069e-01) 
2023-05-27 07:53:02.853559: train Epoch: [14][133/193]	Time  0.563 ( 4.942)	Data  0.001 ( 4.371)	Loss 1.2458e-01 (1.1079e-01) 
2023-05-27 07:53:12.510876: train Epoch: [14][134/193]	Time  9.657 ( 4.977)	Data  9.087 ( 4.406)	Loss 1.2846e-01 (1.1093e-01) 
2023-05-27 07:53:13.073755: train Epoch: [14][135/193]	Time  0.563 ( 4.945)	Data  0.001 ( 4.374)	Loss 2.0637e-01 (1.1163e-01) 
2023-05-27 07:53:22.511579: train Epoch: [14][136/193]	Time  9.438 ( 4.977)	Data  8.841 ( 4.406)	Loss 1.0409e-01 (1.1157e-01) 
2023-05-27 07:53:23.080127: train Epoch: [14][137/193]	Time  0.569 ( 4.945)	Data  0.001 ( 4.374)	Loss 8.8410e-02 (1.1140e-01) 
2023-05-27 07:53:32.765900: train Epoch: [14][138/193]	Time  9.686 ( 4.980)	Data  9.123 ( 4.409)	Loss 1.1467e-01 (1.1143e-01) 
2023-05-27 07:53:33.329728: train Epoch: [14][139/193]	Time  0.564 ( 4.948)	Data  0.001 ( 4.377)	Loss 1.2623e-01 (1.1153e-01) 
2023-05-27 07:53:42.669043: train Epoch: [14][140/193]	Time  9.339 ( 4.979)	Data  8.776 ( 4.408)	Loss 7.6285e-02 (1.1128e-01) 
2023-05-27 07:53:43.233355: train Epoch: [14][141/193]	Time  0.564 ( 4.948)	Data  0.001 ( 4.377)	Loss 1.6044e-01 (1.1163e-01) 
2023-05-27 07:53:52.611330: train Epoch: [14][142/193]	Time  9.378 ( 4.979)	Data  8.815 ( 4.408)	Loss 2.2798e-01 (1.1244e-01) 
2023-05-27 07:53:53.173491: train Epoch: [14][143/193]	Time  0.562 ( 4.948)	Data  0.001 ( 4.378)	Loss 9.7949e-02 (1.1234e-01) 
2023-05-27 07:54:02.413811: train Epoch: [14][144/193]	Time  9.240 ( 4.978)	Data  8.673 ( 4.407)	Loss 1.2141e-01 (1.1241e-01) 
2023-05-27 07:54:02.976552: train Epoch: [14][145/193]	Time  0.563 ( 4.948)	Data  0.001 ( 4.377)	Loss 9.6492e-02 (1.1230e-01) 
2023-05-27 07:54:12.188904: train Epoch: [14][146/193]	Time  9.212 ( 4.977)	Data  8.642 ( 4.406)	Loss 1.6450e-01 (1.1265e-01) 
2023-05-27 07:54:12.753757: train Epoch: [14][147/193]	Time  0.565 ( 4.947)	Data  0.001 ( 4.376)	Loss 1.4926e-01 (1.1290e-01) 
2023-05-27 07:54:22.201488: train Epoch: [14][148/193]	Time  9.448 ( 4.977)	Data  8.882 ( 4.407)	Loss 1.0790e-01 (1.1287e-01) 
2023-05-27 07:54:22.776052: train Epoch: [14][149/193]	Time  0.575 ( 4.948)	Data  0.001 ( 4.377)	Loss 1.6580e-01 (1.1322e-01) 
2023-05-27 07:54:32.207078: train Epoch: [14][150/193]	Time  9.431 ( 4.977)	Data  8.868 ( 4.407)	Loss 1.0577e-01 (1.1317e-01) 
2023-05-27 07:54:32.771940: train Epoch: [14][151/193]	Time  0.565 ( 4.948)	Data  0.001 ( 4.378)	Loss 2.1456e-01 (1.1384e-01) 
2023-05-27 07:54:42.136179: train Epoch: [14][152/193]	Time  9.364 ( 4.977)	Data  8.798 ( 4.407)	Loss 1.1671e-01 (1.1385e-01) 
2023-05-27 07:54:42.712360: train Epoch: [14][153/193]	Time  0.576 ( 4.949)	Data  0.001 ( 4.378)	Loss 8.4037e-02 (1.1366e-01) 
2023-05-27 07:54:52.009798: train Epoch: [14][154/193]	Time  9.297 ( 4.977)	Data  8.728 ( 4.406)	Loss 1.3374e-01 (1.1379e-01) 
2023-05-27 07:54:52.622390: train Epoch: [14][155/193]	Time  0.613 ( 4.949)	Data  0.001 ( 4.378)	Loss 9.8057e-02 (1.1369e-01) 
2023-05-27 07:55:02.041721: train Epoch: [14][156/193]	Time  9.419 ( 4.977)	Data  8.854 ( 4.407)	Loss 8.6365e-02 (1.1352e-01) 
2023-05-27 07:55:02.636878: train Epoch: [14][157/193]	Time  0.595 ( 4.950)	Data  0.001 ( 4.379)	Loss 1.2376e-01 (1.1358e-01) 
2023-05-27 07:55:12.282239: train Epoch: [14][158/193]	Time  9.645 ( 4.979)	Data  9.066 ( 4.408)	Loss 1.3217e-01 (1.1370e-01) 
2023-05-27 07:55:12.844751: train Epoch: [14][159/193]	Time  0.563 ( 4.951)	Data  0.001 ( 4.381)	Loss 1.3082e-01 (1.1380e-01) 
2023-05-27 07:55:22.150212: train Epoch: [14][160/193]	Time  9.305 ( 4.979)	Data  8.740 ( 4.408)	Loss 1.6634e-01 (1.1413e-01) 
2023-05-27 07:55:22.722841: train Epoch: [14][161/193]	Time  0.573 ( 4.951)	Data  0.001 ( 4.380)	Loss 9.1767e-02 (1.1399e-01) 
2023-05-27 07:55:31.913960: train Epoch: [14][162/193]	Time  9.191 ( 4.977)	Data  8.618 ( 4.406)	Loss 7.1802e-02 (1.1373e-01) 
2023-05-27 07:55:32.485054: train Epoch: [14][163/193]	Time  0.571 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.4107e-01 (1.1390e-01) 
2023-05-27 07:55:41.819391: train Epoch: [14][164/193]	Time  9.334 ( 4.977)	Data  8.771 ( 4.406)	Loss 1.4326e-01 (1.1408e-01) 
2023-05-27 07:55:42.391805: train Epoch: [14][165/193]	Time  0.572 ( 4.950)	Data  0.001 ( 4.380)	Loss 6.6076e-02 (1.1379e-01) 
2023-05-27 07:55:51.795629: train Epoch: [14][166/193]	Time  9.404 ( 4.977)	Data  8.841 ( 4.406)	Loss 1.9729e-01 (1.1429e-01) 
2023-05-27 07:55:52.370799: train Epoch: [14][167/193]	Time  0.575 ( 4.951)	Data  0.001 ( 4.380)	Loss 1.2678e-01 (1.1436e-01) 
2023-05-27 07:56:01.464345: train Epoch: [14][168/193]	Time  9.094 ( 4.975)	Data  8.530 ( 4.405)	Loss 1.3447e-01 (1.1448e-01) 
2023-05-27 07:56:02.029608: train Epoch: [14][169/193]	Time  0.565 ( 4.950)	Data  0.001 ( 4.379)	Loss 1.2743e-01 (1.1456e-01) 
2023-05-27 07:56:11.519434: train Epoch: [14][170/193]	Time  9.490 ( 4.976)	Data  8.921 ( 4.405)	Loss 8.9208e-02 (1.1441e-01) 
2023-05-27 07:56:12.087828: train Epoch: [14][171/193]	Time  0.568 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.6127e-01 (1.1468e-01) 
2023-05-27 07:56:21.418389: train Epoch: [14][172/193]	Time  9.331 ( 4.976)	Data  8.757 ( 4.405)	Loss 7.2495e-02 (1.1444e-01) 
2023-05-27 07:56:21.995637: train Epoch: [14][173/193]	Time  0.577 ( 4.950)	Data  0.001 ( 4.380)	Loss 8.4908e-02 (1.1427e-01) 
2023-05-27 07:56:32.133247: train Epoch: [14][174/193]	Time 10.138 ( 4.980)	Data  9.561 ( 4.409)	Loss 1.2947e-01 (1.1436e-01) 
2023-05-27 07:56:32.735019: train Epoch: [14][175/193]	Time  0.602 ( 4.955)	Data  0.001 ( 4.384)	Loss 1.1103e-01 (1.1434e-01) 
2023-05-27 07:56:42.730295: train Epoch: [14][176/193]	Time  9.995 ( 4.984)	Data  9.428 ( 4.413)	Loss 1.1320e-01 (1.1433e-01) 
2023-05-27 07:56:43.307185: train Epoch: [14][177/193]	Time  0.577 ( 4.959)	Data  0.001 ( 4.388)	Loss 1.1879e-01 (1.1436e-01) 
2023-05-27 07:56:53.037310: train Epoch: [14][178/193]	Time  9.730 ( 4.986)	Data  9.162 ( 4.415)	Loss 6.6902e-02 (1.1409e-01) 
2023-05-27 07:56:53.620479: train Epoch: [14][179/193]	Time  0.583 ( 4.961)	Data  0.001 ( 4.390)	Loss 1.2598e-01 (1.1416e-01) 
2023-05-27 07:57:03.602449: train Epoch: [14][180/193]	Time  9.982 ( 4.989)	Data  9.416 ( 4.418)	Loss 8.6663e-02 (1.1401e-01) 
2023-05-27 07:57:04.180146: train Epoch: [14][181/193]	Time  0.578 ( 4.965)	Data  0.001 ( 4.394)	Loss 1.3306e-01 (1.1411e-01) 
2023-05-27 07:57:13.924090: train Epoch: [14][182/193]	Time  9.744 ( 4.991)	Data  9.142 ( 4.420)	Loss 1.1120e-01 (1.1409e-01) 
2023-05-27 07:57:14.486762: train Epoch: [14][183/193]	Time  0.563 ( 4.967)	Data  0.001 ( 4.396)	Loss 1.2883e-01 (1.1417e-01) 
2023-05-27 07:57:23.871730: train Epoch: [14][184/193]	Time  9.385 ( 4.991)	Data  8.809 ( 4.419)	Loss 1.1583e-01 (1.1418e-01) 
2023-05-27 07:57:24.435436: train Epoch: [14][185/193]	Time  0.564 ( 4.967)	Data  0.001 ( 4.396)	Loss 8.6853e-02 (1.1404e-01) 
2023-05-27 07:57:33.869616: train Epoch: [14][186/193]	Time  9.434 ( 4.991)	Data  8.840 ( 4.419)	Loss 1.7068e-01 (1.1434e-01) 
2023-05-27 07:57:34.458384: train Epoch: [14][187/193]	Time  0.589 ( 4.967)	Data  0.001 ( 4.396)	Loss 1.4489e-01 (1.1450e-01) 
2023-05-27 07:57:43.599136: train Epoch: [14][188/193]	Time  9.141 ( 4.989)	Data  8.573 ( 4.418)	Loss 6.7907e-02 (1.1426e-01) 
2023-05-27 07:57:44.163958: train Epoch: [14][189/193]	Time  0.565 ( 4.966)	Data  0.001 ( 4.395)	Loss 1.8817e-01 (1.1464e-01) 
2023-05-27 07:57:52.865706: train Epoch: [14][190/193]	Time  8.702 ( 4.986)	Data  8.124 ( 4.414)	Loss 1.1737e-01 (1.1466e-01) 
2023-05-27 07:57:53.434060: train Epoch: [14][191/193]	Time  0.568 ( 4.963)	Data  0.001 ( 4.391)	Loss 1.4974e-01 (1.1484e-01) 
2023-05-27 07:58:01.574957: train Epoch: [14][192/193]	Time  8.141 ( 4.979)	Data  7.561 ( 4.408)	Loss 1.0846e-01 (1.1481e-01) 
2023-05-27 07:58:01.715341: Train Epoch done in 961.106732870976 s 
2023-05-27 07:58:08.626017: val Epoch: [14][ 0/72]	Time  5.646 ( 5.646)	Data  5.464 ( 5.464)	Loss 1.4872e-01 (1.4872e-01) 
2023-05-27 07:58:08.739141: val Epoch: [14][ 1/72]	Time  0.113 ( 2.880)	Data  0.002 ( 2.733)	Loss 3.2603e-01 (2.3737e-01) 
2023-05-27 07:58:13.651863: val Epoch: [14][ 2/72]	Time  4.913 ( 3.557)	Data  4.799 ( 3.422)	Loss 1.1598e-01 (1.9691e-01) 
2023-05-27 07:58:13.763910: val Epoch: [14][ 3/72]	Time  0.112 ( 2.696)	Data  0.001 ( 2.566)	Loss 1.2641e-01 (1.7928e-01) 
2023-05-27 07:58:18.624445: val Epoch: [14][ 4/72]	Time  4.861 ( 3.129)	Data  4.745 ( 3.002)	Loss 1.1392e-01 (1.6621e-01) 
2023-05-27 07:58:18.747979: val Epoch: [14][ 5/72]	Time  0.124 ( 2.628)	Data  0.011 ( 2.504)	Loss 1.6417e-01 (1.6587e-01) 
2023-05-27 07:58:23.886018: val Epoch: [14][ 6/72]	Time  5.138 ( 2.987)	Data  5.026 ( 2.864)	Loss 1.8420e-01 (1.6849e-01) 
2023-05-27 07:58:23.998427: val Epoch: [14][ 7/72]	Time  0.112 ( 2.627)	Data  0.001 ( 2.506)	Loss 8.4087e-02 (1.5794e-01) 
2023-05-27 07:58:28.910088: val Epoch: [14][ 8/72]	Time  4.912 ( 2.881)	Data  4.800 ( 2.761)	Loss 9.8484e-02 (1.5133e-01) 
2023-05-27 07:58:29.022263: val Epoch: [14][ 9/72]	Time  0.112 ( 2.604)	Data  0.001 ( 2.485)	Loss 8.3130e-02 (1.4451e-01) 
2023-05-27 07:58:34.061250: val Epoch: [14][10/72]	Time  5.039 ( 2.826)	Data  4.927 ( 2.707)	Loss 8.2577e-02 (1.3888e-01) 
2023-05-27 07:58:34.173686: val Epoch: [14][11/72]	Time  0.112 ( 2.600)	Data  0.001 ( 2.481)	Loss 1.5349e-01 (1.4010e-01) 
2023-05-27 07:58:38.822592: val Epoch: [14][12/72]	Time  4.649 ( 2.757)	Data  4.537 ( 2.639)	Loss 9.3590e-02 (1.3652e-01) 
2023-05-27 07:58:38.935048: val Epoch: [14][13/72]	Time  0.112 ( 2.568)	Data  0.001 ( 2.451)	Loss 1.7322e-01 (1.3914e-01) 
2023-05-27 07:58:44.257520: val Epoch: [14][14/72]	Time  5.322 ( 2.752)	Data  5.207 ( 2.635)	Loss 1.9661e-01 (1.4297e-01) 
2023-05-27 07:58:44.374957: val Epoch: [14][15/72]	Time  0.117 ( 2.587)	Data  0.001 ( 2.470)	Loss 9.4712e-02 (1.3996e-01) 
2023-05-27 07:58:49.100415: val Epoch: [14][16/72]	Time  4.725 ( 2.713)	Data  4.612 ( 2.596)	Loss 2.2982e-01 (1.4524e-01) 
2023-05-27 07:58:49.214035: val Epoch: [14][17/72]	Time  0.114 ( 2.569)	Data  0.001 ( 2.452)	Loss 6.9368e-02 (1.4103e-01) 
2023-05-27 07:58:54.419098: val Epoch: [14][18/72]	Time  5.205 ( 2.707)	Data  5.093 ( 2.591)	Loss 1.1669e-01 (1.3975e-01) 
2023-05-27 07:58:54.529952: val Epoch: [14][19/72]	Time  0.111 ( 2.578)	Data  0.001 ( 2.461)	Loss 9.3215e-02 (1.3742e-01) 
2023-05-27 07:58:59.452641: val Epoch: [14][20/72]	Time  4.923 ( 2.689)	Data  4.815 ( 2.573)	Loss 7.0021e-02 (1.3421e-01) 
2023-05-27 07:58:59.560862: val Epoch: [14][21/72]	Time  0.108 ( 2.572)	Data  0.001 ( 2.457)	Loss 1.7455e-01 (1.3605e-01) 
2023-05-27 07:59:04.674719: val Epoch: [14][22/72]	Time  5.114 ( 2.682)	Data  5.006 ( 2.567)	Loss 6.3070e-02 (1.3287e-01) 
2023-05-27 07:59:04.782721: val Epoch: [14][23/72]	Time  0.108 ( 2.575)	Data  0.000 ( 2.460)	Loss 1.4581e-01 (1.3341e-01) 
2023-05-27 07:59:09.594059: val Epoch: [14][24/72]	Time  4.811 ( 2.665)	Data  4.703 ( 2.550)	Loss 1.0088e-01 (1.3211e-01) 
2023-05-27 07:59:09.701892: val Epoch: [14][25/72]	Time  0.108 ( 2.566)	Data  0.001 ( 2.452)	Loss 7.7191e-02 (1.3000e-01) 
2023-05-27 07:59:14.454685: val Epoch: [14][26/72]	Time  4.753 ( 2.647)	Data  4.645 ( 2.533)	Loss 1.5353e-01 (1.3087e-01) 
2023-05-27 07:59:14.562526: val Epoch: [14][27/72]	Time  0.108 ( 2.557)	Data  0.000 ( 2.443)	Loss 7.0026e-02 (1.2870e-01) 
2023-05-27 07:59:19.981971: val Epoch: [14][28/72]	Time  5.419 ( 2.655)	Data  5.303 ( 2.541)	Loss 7.8470e-02 (1.2696e-01) 
2023-05-27 07:59:20.096091: val Epoch: [14][29/72]	Time  0.114 ( 2.571)	Data  0.001 ( 2.457)	Loss 2.7208e-01 (1.3180e-01) 
2023-05-27 07:59:25.197512: val Epoch: [14][30/72]	Time  5.101 ( 2.652)	Data  4.973 ( 2.538)	Loss 1.9403e-01 (1.3381e-01) 
2023-05-27 07:59:25.312398: val Epoch: [14][31/72]	Time  0.115 ( 2.573)	Data  0.001 ( 2.459)	Loss 1.3830e-01 (1.3395e-01) 
2023-05-27 07:59:30.143552: val Epoch: [14][32/72]	Time  4.831 ( 2.641)	Data  4.719 ( 2.527)	Loss 1.0136e-01 (1.3296e-01) 
2023-05-27 07:59:30.255747: val Epoch: [14][33/72]	Time  0.112 ( 2.567)	Data  0.000 ( 2.453)	Loss 1.0011e-01 (1.3200e-01) 
2023-05-27 07:59:35.205151: val Epoch: [14][34/72]	Time  4.949 ( 2.635)	Data  4.834 ( 2.521)	Loss 6.1053e-02 (1.2997e-01) 
2023-05-27 07:59:35.330176: val Epoch: [14][35/72]	Time  0.125 ( 2.565)	Data  0.001 ( 2.451)	Loss 1.8999e-01 (1.3164e-01) 
2023-05-27 07:59:40.247574: val Epoch: [14][36/72]	Time  4.917 ( 2.629)	Data  4.805 ( 2.514)	Loss 1.2338e-01 (1.3141e-01) 
2023-05-27 07:59:40.359739: val Epoch: [14][37/72]	Time  0.112 ( 2.563)	Data  0.001 ( 2.448)	Loss 1.2056e-01 (1.3113e-01) 
2023-05-27 07:59:45.187082: val Epoch: [14][38/72]	Time  4.827 ( 2.621)	Data  4.720 ( 2.507)	Loss 6.6606e-02 (1.2947e-01) 
2023-05-27 07:59:45.294289: val Epoch: [14][39/72]	Time  0.107 ( 2.558)	Data  0.000 ( 2.444)	Loss 6.7744e-02 (1.2793e-01) 
2023-05-27 07:59:50.172390: val Epoch: [14][40/72]	Time  4.878 ( 2.614)	Data  4.771 ( 2.501)	Loss 4.4033e-01 (1.3555e-01) 
2023-05-27 07:59:50.280619: val Epoch: [14][41/72]	Time  0.108 ( 2.555)	Data  0.000 ( 2.441)	Loss 5.2896e-01 (1.4492e-01) 
2023-05-27 07:59:55.316288: val Epoch: [14][42/72]	Time  5.036 ( 2.612)	Data  4.914 ( 2.499)	Loss 7.7878e-02 (1.4336e-01) 
2023-05-27 07:59:55.442548: val Epoch: [14][43/72]	Time  0.126 ( 2.556)	Data  0.001 ( 2.442)	Loss 8.0383e-02 (1.4193e-01) 
2023-05-27 08:00:00.314270: val Epoch: [14][44/72]	Time  4.872 ( 2.607)	Data  4.763 ( 2.493)	Loss 1.5873e-01 (1.4230e-01) 
2023-05-27 08:00:00.427722: val Epoch: [14][45/72]	Time  0.113 ( 2.553)	Data  0.001 ( 2.439)	Loss 1.6933e-01 (1.4289e-01) 
2023-05-27 08:00:05.439827: val Epoch: [14][46/72]	Time  5.012 ( 2.606)	Data  4.903 ( 2.492)	Loss 1.0899e-01 (1.4217e-01) 
2023-05-27 08:00:05.554194: val Epoch: [14][47/72]	Time  0.114 ( 2.554)	Data  0.001 ( 2.440)	Loss 1.6878e-01 (1.4272e-01) 
2023-05-27 08:00:10.568378: val Epoch: [14][48/72]	Time  5.014 ( 2.604)	Data  4.899 ( 2.490)	Loss 4.7691e-01 (1.4954e-01) 
2023-05-27 08:00:10.705401: val Epoch: [14][49/72]	Time  0.137 ( 2.555)	Data  0.001 ( 2.440)	Loss 3.8100e-01 (1.5417e-01) 
2023-05-27 08:00:15.588455: val Epoch: [14][50/72]	Time  4.883 ( 2.600)	Data  4.763 ( 2.486)	Loss 5.1899e-02 (1.5216e-01) 
2023-05-27 08:00:15.730329: val Epoch: [14][51/72]	Time  0.142 ( 2.553)	Data  0.001 ( 2.438)	Loss 8.7909e-02 (1.5093e-01) 
2023-05-27 08:00:20.966872: val Epoch: [14][52/72]	Time  5.237 ( 2.604)	Data  5.110 ( 2.488)	Loss 1.5168e-01 (1.5094e-01) 
2023-05-27 08:00:21.099658: val Epoch: [14][53/72]	Time  0.133 ( 2.558)	Data  0.001 ( 2.442)	Loss 3.2934e-01 (1.5425e-01) 
2023-05-27 08:00:25.694318: val Epoch: [14][54/72]	Time  4.595 ( 2.595)	Data  4.486 ( 2.479)	Loss 1.1832e-01 (1.5359e-01) 
2023-05-27 08:00:25.807763: val Epoch: [14][55/72]	Time  0.113 ( 2.551)	Data  0.001 ( 2.435)	Loss 9.5386e-02 (1.5255e-01) 
2023-05-27 08:00:30.675698: val Epoch: [14][56/72]	Time  4.868 ( 2.591)	Data  4.759 ( 2.476)	Loss 3.5302e-01 (1.5607e-01) 
2023-05-27 08:00:30.791614: val Epoch: [14][57/72]	Time  0.116 ( 2.548)	Data  0.001 ( 2.433)	Loss 6.5949e-02 (1.5452e-01) 
2023-05-27 08:00:35.758398: val Epoch: [14][58/72]	Time  4.967 ( 2.589)	Data  4.855 ( 2.474)	Loss 7.7811e-02 (1.5322e-01) 
2023-05-27 08:00:35.873775: val Epoch: [14][59/72]	Time  0.115 ( 2.548)	Data  0.001 ( 2.433)	Loss 8.8294e-02 (1.5213e-01) 
2023-05-27 08:00:40.789870: val Epoch: [14][60/72]	Time  4.916 ( 2.587)	Data  4.808 ( 2.472)	Loss 7.3165e-02 (1.5084e-01) 
2023-05-27 08:00:40.898025: val Epoch: [14][61/72]	Time  0.108 ( 2.547)	Data  0.001 ( 2.432)	Loss 5.0216e-02 (1.4922e-01) 
2023-05-27 08:00:46.035283: val Epoch: [14][62/72]	Time  5.137 ( 2.588)	Data  5.019 ( 2.473)	Loss 4.5723e-01 (1.5411e-01) 
2023-05-27 08:00:46.146415: val Epoch: [14][63/72]	Time  0.111 ( 2.549)	Data  0.001 ( 2.435)	Loss 1.0333e-01 (1.5331e-01) 
2023-05-27 08:00:51.050809: val Epoch: [14][64/72]	Time  4.904 ( 2.586)	Data  4.785 ( 2.471)	Loss 9.8305e-02 (1.5247e-01) 
2023-05-27 08:00:51.162962: val Epoch: [14][65/72]	Time  0.112 ( 2.548)	Data  0.001 ( 2.433)	Loss 1.3208e-01 (1.5216e-01) 
2023-05-27 08:00:56.389536: val Epoch: [14][66/72]	Time  5.227 ( 2.588)	Data  5.115 ( 2.473)	Loss 2.3361e-01 (1.5337e-01) 
2023-05-27 08:00:56.503011: val Epoch: [14][67/72]	Time  0.113 ( 2.552)	Data  0.001 ( 2.437)	Loss 2.0808e-01 (1.5418e-01) 
2023-05-27 08:01:01.462937: val Epoch: [14][68/72]	Time  4.960 ( 2.587)	Data  4.835 ( 2.472)	Loss 3.8976e-01 (1.5759e-01) 
2023-05-27 08:01:01.579286: val Epoch: [14][69/72]	Time  0.116 ( 2.551)	Data  0.001 ( 2.436)	Loss 9.5230e-02 (1.5670e-01) 
2023-05-27 08:01:06.155244: val Epoch: [14][70/72]	Time  4.576 ( 2.580)	Data  4.443 ( 2.465)	Loss 1.4642e-01 (1.5656e-01) 
2023-05-27 08:01:06.278315: val Epoch: [14][71/72]	Time  0.123 ( 2.546)	Data  0.000 ( 2.430)	Loss 5.6202e-02 (1.5516e-01) 
2023-05-27 08:01:06.581609: Epoch 14 :Val : ['ET : 0.6877636909484863', 'TC : 0.7467579245567322', 'WT : 0.8349509239196777'] 
2023-05-27 08:01:06.584409: Epoch 14 :Val : ['ET : 0.6877636909484863', 'TC : 0.7467579245567322', 'WT : 0.8349509239196777'] 
2023-05-27 08:01:06.586428: Saving the model with DSC 0.7619556784629822 
2023-05-27 08:01:07.467935: Val epoch done in 185.75259020601516 s 
2023-05-27 08:01:07.596155: Batches per epoch:  193 
2023-05-27 08:01:18.412374: train Epoch: [15][  0/193]	Time 10.816 (10.816)	Data  9.978 ( 9.978)	Loss 1.7942e-01 (1.7942e-01) 
2023-05-27 08:01:18.982854: train Epoch: [15][  1/193]	Time  0.571 ( 5.693)	Data  0.001 ( 4.990)	Loss 9.9706e-02 (1.3956e-01) 
2023-05-27 08:01:28.245734: train Epoch: [15][  2/193]	Time  9.263 ( 6.883)	Data  8.699 ( 6.226)	Loss 2.1902e-01 (1.6605e-01) 
2023-05-27 08:01:28.812364: train Epoch: [15][  3/193]	Time  0.567 ( 5.304)	Data  0.001 ( 4.670)	Loss 1.4641e-01 (1.6114e-01) 
2023-05-27 08:01:37.919565: train Epoch: [15][  4/193]	Time  9.107 ( 6.065)	Data  8.543 ( 5.444)	Loss 8.2645e-02 (1.4544e-01) 
2023-05-27 08:01:38.491519: train Epoch: [15][  5/193]	Time  0.572 ( 5.149)	Data  0.001 ( 4.537)	Loss 1.8267e-01 (1.5164e-01) 
2023-05-27 08:01:48.139299: train Epoch: [15][  6/193]	Time  9.648 ( 5.792)	Data  9.074 ( 5.185)	Loss 1.4323e-01 (1.5044e-01) 
2023-05-27 08:01:48.703552: train Epoch: [15][  7/193]	Time  0.564 ( 5.138)	Data  0.001 ( 4.537)	Loss 8.4301e-02 (1.4218e-01) 
2023-05-27 08:01:58.156165: train Epoch: [15][  8/193]	Time  9.453 ( 5.618)	Data  8.889 ( 5.021)	Loss 8.8399e-02 (1.3620e-01) 
2023-05-27 08:01:58.720674: train Epoch: [15][  9/193]	Time  0.565 ( 5.112)	Data  0.001 ( 4.519)	Loss 1.1971e-01 (1.3455e-01) 
2023-05-27 08:02:07.968881: train Epoch: [15][ 10/193]	Time  9.248 ( 5.488)	Data  8.684 ( 4.897)	Loss 8.3789e-02 (1.2994e-01) 
2023-05-27 08:02:08.532136: train Epoch: [15][ 11/193]	Time  0.563 ( 5.078)	Data  0.001 ( 4.489)	Loss 1.4865e-01 (1.3150e-01) 
2023-05-27 08:02:17.793587: train Epoch: [15][ 12/193]	Time  9.261 ( 5.400)	Data  8.696 ( 4.813)	Loss 1.2047e-01 (1.3065e-01) 
2023-05-27 08:02:18.401994: train Epoch: [15][ 13/193]	Time  0.608 ( 5.058)	Data  0.045 ( 4.472)	Loss 6.5507e-02 (1.2599e-01) 
2023-05-27 08:02:27.946109: train Epoch: [15][ 14/193]	Time  9.544 ( 5.357)	Data  8.973 ( 4.772)	Loss 1.1823e-01 (1.2548e-01) 
2023-05-27 08:02:28.736018: train Epoch: [15][ 15/193]	Time  0.790 ( 5.071)	Data  0.186 ( 4.486)	Loss 1.4087e-01 (1.2644e-01) 
2023-05-27 08:02:37.878416: train Epoch: [15][ 16/193]	Time  9.142 ( 5.311)	Data  8.567 ( 4.726)	Loss 7.5818e-02 (1.2346e-01) 
2023-05-27 08:02:38.924195: train Epoch: [15][ 17/193]	Time  1.046 ( 5.074)	Data  0.456 ( 4.489)	Loss 8.7729e-02 (1.2148e-01) 
2023-05-27 08:02:47.625057: train Epoch: [15][ 18/193]	Time  8.701 ( 5.265)	Data  8.135 ( 4.681)	Loss 2.7074e-01 (1.2933e-01) 
2023-05-27 08:02:48.391423: train Epoch: [15][ 19/193]	Time  0.766 ( 5.040)	Data  0.200 ( 4.457)	Loss 1.1050e-01 (1.2839e-01) 
2023-05-27 08:02:57.955991: train Epoch: [15][ 20/193]	Time  9.565 ( 5.255)	Data  8.993 ( 4.673)	Loss 6.4916e-02 (1.2537e-01) 
2023-05-27 08:02:58.524939: train Epoch: [15][ 21/193]	Time  0.569 ( 5.042)	Data  0.001 ( 4.460)	Loss 1.1285e-01 (1.2480e-01) 
2023-05-27 08:03:06.173030: train Epoch: [15][ 22/193]	Time  7.648 ( 5.156)	Data  7.075 ( 4.574)	Loss 2.5912e-01 (1.3064e-01) 
2023-05-27 08:03:06.739817: train Epoch: [15][ 23/193]	Time  0.567 ( 4.964)	Data  0.001 ( 4.383)	Loss 9.2769e-02 (1.2906e-01) 
2023-05-27 08:03:16.601716: train Epoch: [15][ 24/193]	Time  9.862 ( 5.160)	Data  9.296 ( 4.580)	Loss 1.3777e-01 (1.2941e-01) 
2023-05-27 08:03:17.174596: train Epoch: [15][ 25/193]	Time  0.573 ( 4.984)	Data  0.001 ( 4.404)	Loss 1.4361e-01 (1.2996e-01) 
2023-05-27 08:03:26.913331: train Epoch: [15][ 26/193]	Time  9.739 ( 5.160)	Data  9.159 ( 4.580)	Loss 1.0178e-01 (1.2891e-01) 
2023-05-27 08:03:27.477290: train Epoch: [15][ 27/193]	Time  0.564 ( 4.996)	Data  0.001 ( 4.416)	Loss 1.5095e-01 (1.2970e-01) 
2023-05-27 08:03:36.589462: train Epoch: [15][ 28/193]	Time  9.112 ( 5.138)	Data  8.545 ( 4.559)	Loss 1.3870e-01 (1.3001e-01) 
2023-05-27 08:03:37.155285: train Epoch: [15][ 29/193]	Time  0.566 ( 4.985)	Data  0.001 ( 4.407)	Loss 1.0888e-01 (1.2931e-01) 
2023-05-27 08:03:46.727010: train Epoch: [15][ 30/193]	Time  9.572 ( 5.133)	Data  9.007 ( 4.555)	Loss 8.2397e-02 (1.2779e-01) 
2023-05-27 08:03:47.291740: train Epoch: [15][ 31/193]	Time  0.565 ( 4.990)	Data  0.001 ( 4.413)	Loss 1.4112e-01 (1.2821e-01) 
2023-05-27 08:03:56.816354: train Epoch: [15][ 32/193]	Time  9.525 ( 5.128)	Data  8.948 ( 4.550)	Loss 8.1576e-02 (1.2680e-01) 
2023-05-27 08:03:57.381155: train Epoch: [15][ 33/193]	Time  0.565 ( 4.994)	Data  0.001 ( 4.417)	Loss 9.7764e-02 (1.2594e-01) 
2023-05-27 08:04:06.782208: train Epoch: [15][ 34/193]	Time  9.401 ( 5.120)	Data  8.825 ( 4.542)	Loss 1.2311e-01 (1.2586e-01) 
2023-05-27 08:04:07.346308: train Epoch: [15][ 35/193]	Time  0.564 ( 4.993)	Data  0.001 ( 4.416)	Loss 1.0507e-01 (1.2528e-01) 
2023-05-27 08:04:16.709506: train Epoch: [15][ 36/193]	Time  9.363 ( 5.111)	Data  8.795 ( 4.535)	Loss 1.6328e-01 (1.2631e-01) 
2023-05-27 08:04:17.277068: train Epoch: [15][ 37/193]	Time  0.568 ( 4.992)	Data  0.001 ( 4.415)	Loss 1.9692e-01 (1.2817e-01) 
2023-05-27 08:04:26.760519: train Epoch: [15][ 38/193]	Time  9.483 ( 5.107)	Data  8.915 ( 4.531)	Loss 3.0920e-01 (1.3281e-01) 
2023-05-27 08:04:27.329833: train Epoch: [15][ 39/193]	Time  0.569 ( 4.993)	Data  0.001 ( 4.417)	Loss 1.8947e-01 (1.3423e-01) 
2023-05-27 08:04:36.739261: train Epoch: [15][ 40/193]	Time  9.409 ( 5.101)	Data  8.847 ( 4.526)	Loss 2.0647e-01 (1.3599e-01) 
2023-05-27 08:04:37.303027: train Epoch: [15][ 41/193]	Time  0.564 ( 4.993)	Data  0.001 ( 4.418)	Loss 1.0338e-01 (1.3521e-01) 
2023-05-27 08:04:45.411727: train Epoch: [15][ 42/193]	Time  8.109 ( 5.065)	Data  7.546 ( 4.491)	Loss 1.4547e-01 (1.3545e-01) 
2023-05-27 08:04:45.976250: train Epoch: [15][ 43/193]	Time  0.565 ( 4.963)	Data  0.001 ( 4.389)	Loss 8.6927e-02 (1.3435e-01) 
2023-05-27 08:04:53.489626: train Epoch: [15][ 44/193]	Time  7.513 ( 5.020)	Data  6.933 ( 4.445)	Loss 1.0607e-01 (1.3372e-01) 
2023-05-27 08:04:54.053778: train Epoch: [15][ 45/193]	Time  0.564 ( 4.923)	Data  0.001 ( 4.348)	Loss 8.2569e-02 (1.3261e-01) 
2023-05-27 08:05:03.300693: train Epoch: [15][ 46/193]	Time  9.247 ( 5.015)	Data  8.676 ( 4.441)	Loss 5.8153e-02 (1.3102e-01) 
2023-05-27 08:05:03.868674: train Epoch: [15][ 47/193]	Time  0.568 ( 4.922)	Data  0.001 ( 4.348)	Loss 8.1192e-02 (1.2999e-01) 
2023-05-27 08:05:13.583441: train Epoch: [15][ 48/193]	Time  9.715 ( 5.020)	Data  9.146 ( 4.446)	Loss 1.9289e-01 (1.3127e-01) 
2023-05-27 08:05:14.153405: train Epoch: [15][ 49/193]	Time  0.570 ( 4.931)	Data  0.001 ( 4.357)	Loss 9.4903e-02 (1.3054e-01) 
2023-05-27 08:05:23.380117: train Epoch: [15][ 50/193]	Time  9.227 ( 5.015)	Data  8.662 ( 4.441)	Loss 1.1183e-01 (1.3017e-01) 
2023-05-27 08:05:23.947617: train Epoch: [15][ 51/193]	Time  0.568 ( 4.930)	Data  0.001 ( 4.356)	Loss 9.8043e-02 (1.2956e-01) 
2023-05-27 08:05:33.173518: train Epoch: [15][ 52/193]	Time  9.226 ( 5.011)	Data  8.663 ( 4.437)	Loss 1.1039e-01 (1.2920e-01) 
2023-05-27 08:05:33.738075: train Epoch: [15][ 53/193]	Time  0.565 ( 4.929)	Data  0.001 ( 4.355)	Loss 1.7034e-01 (1.2996e-01) 
2023-05-27 08:05:43.286248: train Epoch: [15][ 54/193]	Time  9.548 ( 5.013)	Data  8.974 ( 4.439)	Loss 1.0540e-01 (1.2951e-01) 
2023-05-27 08:05:43.849893: train Epoch: [15][ 55/193]	Time  0.564 ( 4.933)	Data  0.001 ( 4.360)	Loss 1.2116e-01 (1.2936e-01) 
2023-05-27 08:05:52.969517: train Epoch: [15][ 56/193]	Time  9.120 ( 5.007)	Data  8.555 ( 4.433)	Loss 1.0038e-01 (1.2885e-01) 
2023-05-27 08:05:53.542947: train Epoch: [15][ 57/193]	Time  0.573 ( 4.930)	Data  0.001 ( 4.357)	Loss 1.1829e-01 (1.2867e-01) 
2023-05-27 08:06:02.372101: train Epoch: [15][ 58/193]	Time  8.829 ( 4.996)	Data  8.265 ( 4.423)	Loss 1.1094e-01 (1.2837e-01) 
2023-05-27 08:06:02.935063: train Epoch: [15][ 59/193]	Time  0.563 ( 4.922)	Data  0.001 ( 4.350)	Loss 9.2619e-02 (1.2777e-01) 
2023-05-27 08:06:12.522067: train Epoch: [15][ 60/193]	Time  9.587 ( 4.999)	Data  9.023 ( 4.426)	Loss 9.7072e-02 (1.2727e-01) 
2023-05-27 08:06:13.095428: train Epoch: [15][ 61/193]	Time  0.573 ( 4.927)	Data  0.001 ( 4.355)	Loss 1.2159e-01 (1.2718e-01) 
2023-05-27 08:06:22.456264: train Epoch: [15][ 62/193]	Time  9.361 ( 4.998)	Data  8.787 ( 4.425)	Loss 6.8392e-02 (1.2625e-01) 
2023-05-27 08:06:23.075088: train Epoch: [15][ 63/193]	Time  0.619 ( 4.929)	Data  0.001 ( 4.356)	Loss 1.0076e-01 (1.2585e-01) 
2023-05-27 08:06:32.300945: train Epoch: [15][ 64/193]	Time  9.226 ( 4.995)	Data  8.663 ( 4.422)	Loss 8.7816e-02 (1.2526e-01) 
2023-05-27 08:06:32.873597: train Epoch: [15][ 65/193]	Time  0.573 ( 4.928)	Data  0.001 ( 4.355)	Loss 1.7933e-01 (1.2608e-01) 
2023-05-27 08:06:42.441640: train Epoch: [15][ 66/193]	Time  9.568 ( 4.998)	Data  9.004 ( 4.425)	Loss 7.1619e-02 (1.2527e-01) 
2023-05-27 08:06:43.039008: train Epoch: [15][ 67/193]	Time  0.597 ( 4.933)	Data  0.001 ( 4.360)	Loss 1.8747e-01 (1.2618e-01) 
2023-05-27 08:06:52.938489: train Epoch: [15][ 68/193]	Time  9.899 ( 5.005)	Data  9.299 ( 4.431)	Loss 4.1682e-02 (1.2496e-01) 
2023-05-27 08:06:53.502780: train Epoch: [15][ 69/193]	Time  0.564 ( 4.942)	Data  0.001 ( 4.368)	Loss 6.7271e-02 (1.2414e-01) 
2023-05-27 08:07:03.045516: train Epoch: [15][ 70/193]	Time  9.543 ( 5.006)	Data  8.971 ( 4.433)	Loss 1.4443e-01 (1.2442e-01) 
2023-05-27 08:07:03.677830: train Epoch: [15][ 71/193]	Time  0.632 ( 4.946)	Data  0.001 ( 4.371)	Loss 8.7198e-02 (1.2390e-01) 
2023-05-27 08:07:12.806012: train Epoch: [15][ 72/193]	Time  9.128 ( 5.003)	Data  8.561 ( 4.429)	Loss 5.9555e-02 (1.2302e-01) 
2023-05-27 08:07:13.371659: train Epoch: [15][ 73/193]	Time  0.566 ( 4.943)	Data  0.001 ( 4.369)	Loss 7.6621e-02 (1.2240e-01) 
2023-05-27 08:07:22.510335: train Epoch: [15][ 74/193]	Time  9.139 ( 4.999)	Data  8.569 ( 4.425)	Loss 1.3364e-01 (1.2255e-01) 
2023-05-27 08:07:23.082454: train Epoch: [15][ 75/193]	Time  0.572 ( 4.941)	Data  0.001 ( 4.367)	Loss 1.5439e-01 (1.2296e-01) 
2023-05-27 08:07:32.333708: train Epoch: [15][ 76/193]	Time  9.251 ( 4.997)	Data  8.682 ( 4.423)	Loss 1.2858e-01 (1.2304e-01) 
2023-05-27 08:07:32.911114: train Epoch: [15][ 77/193]	Time  0.577 ( 4.940)	Data  0.001 ( 4.366)	Loss 1.2067e-01 (1.2301e-01) 
2023-05-27 08:07:42.335653: train Epoch: [15][ 78/193]	Time  9.425 ( 4.997)	Data  8.860 ( 4.423)	Loss 1.0883e-01 (1.2283e-01) 
2023-05-27 08:07:42.901371: train Epoch: [15][ 79/193]	Time  0.566 ( 4.941)	Data  0.001 ( 4.368)	Loss 5.4436e-02 (1.2197e-01) 
2023-05-27 08:07:52.044629: train Epoch: [15][ 80/193]	Time  9.143 ( 4.993)	Data  8.567 ( 4.419)	Loss 1.6608e-01 (1.2252e-01) 
2023-05-27 08:07:52.630032: train Epoch: [15][ 81/193]	Time  0.585 ( 4.939)	Data  0.001 ( 4.365)	Loss 5.8349e-02 (1.2173e-01) 
2023-05-27 08:08:01.710747: train Epoch: [15][ 82/193]	Time  9.081 ( 4.989)	Data  8.502 ( 4.415)	Loss 1.1682e-01 (1.2168e-01) 
2023-05-27 08:08:02.313701: train Epoch: [15][ 83/193]	Time  0.603 ( 4.937)	Data  0.001 ( 4.363)	Loss 1.2458e-01 (1.2171e-01) 
2023-05-27 08:08:11.765642: train Epoch: [15][ 84/193]	Time  9.452 ( 4.990)	Data  8.881 ( 4.416)	Loss 1.2876e-01 (1.2179e-01) 
2023-05-27 08:08:12.362708: train Epoch: [15][ 85/193]	Time  0.597 ( 4.939)	Data  0.001 ( 4.365)	Loss 1.1172e-01 (1.2168e-01) 
2023-05-27 08:08:22.117640: train Epoch: [15][ 86/193]	Time  9.755 ( 4.994)	Data  9.147 ( 4.420)	Loss 1.9790e-01 (1.2255e-01) 
2023-05-27 08:08:22.712298: train Epoch: [15][ 87/193]	Time  0.595 ( 4.944)	Data  0.001 ( 4.369)	Loss 9.3449e-02 (1.2222e-01) 
2023-05-27 08:08:32.093122: train Epoch: [15][ 88/193]	Time  9.381 ( 4.994)	Data  8.806 ( 4.419)	Loss 7.1530e-02 (1.2165e-01) 
2023-05-27 08:08:32.690950: train Epoch: [15][ 89/193]	Time  0.598 ( 4.945)	Data  0.001 ( 4.370)	Loss 1.2993e-01 (1.2174e-01) 
2023-05-27 08:08:41.157130: train Epoch: [15][ 90/193]	Time  8.466 ( 4.984)	Data  7.868 ( 4.409)	Loss 1.1417e-01 (1.2166e-01) 
2023-05-27 08:08:41.720198: train Epoch: [15][ 91/193]	Time  0.563 ( 4.936)	Data  0.001 ( 4.361)	Loss 1.8094e-01 (1.2231e-01) 
2023-05-27 08:08:50.223940: train Epoch: [15][ 92/193]	Time  8.504 ( 4.974)	Data  7.907 ( 4.399)	Loss 1.0689e-01 (1.2214e-01) 
2023-05-27 08:08:50.788294: train Epoch: [15][ 93/193]	Time  0.564 ( 4.928)	Data  0.001 ( 4.352)	Loss 1.2664e-01 (1.2219e-01) 
2023-05-27 08:08:59.533466: train Epoch: [15][ 94/193]	Time  8.745 ( 4.968)	Data  8.141 ( 4.392)	Loss 1.2560e-01 (1.2222e-01) 
2023-05-27 08:09:00.097909: train Epoch: [15][ 95/193]	Time  0.564 ( 4.922)	Data  0.001 ( 4.346)	Loss 1.2696e-01 (1.2227e-01) 
2023-05-27 08:09:09.624074: train Epoch: [15][ 96/193]	Time  9.526 ( 4.969)	Data  8.952 ( 4.394)	Loss 4.1680e-01 (1.2531e-01) 
2023-05-27 08:09:10.194824: train Epoch: [15][ 97/193]	Time  0.571 ( 4.924)	Data  0.001 ( 4.349)	Loss 1.0082e-01 (1.2506e-01) 
2023-05-27 08:09:19.466339: train Epoch: [15][ 98/193]	Time  9.272 ( 4.968)	Data  8.702 ( 4.393)	Loss 1.1953e-01 (1.2500e-01) 
2023-05-27 08:09:20.035130: train Epoch: [15][ 99/193]	Time  0.569 ( 4.924)	Data  0.001 ( 4.349)	Loss 1.9064e-01 (1.2566e-01) 
2023-05-27 08:09:29.559948: train Epoch: [15][100/193]	Time  9.525 ( 4.970)	Data  8.956 ( 4.394)	Loss 1.2590e-01 (1.2566e-01) 
2023-05-27 08:09:30.130143: train Epoch: [15][101/193]	Time  0.570 ( 4.927)	Data  0.001 ( 4.351)	Loss 1.2555e-01 (1.2566e-01) 
2023-05-27 08:09:39.616346: train Epoch: [15][102/193]	Time  9.486 ( 4.971)	Data  8.910 ( 4.396)	Loss 1.8766e-01 (1.2626e-01) 
2023-05-27 08:09:40.187199: train Epoch: [15][103/193]	Time  0.571 ( 4.929)	Data  0.001 ( 4.353)	Loss 3.0826e-01 (1.2801e-01) 
2023-05-27 08:09:49.411424: train Epoch: [15][104/193]	Time  9.224 ( 4.970)	Data  8.660 ( 4.394)	Loss 7.5694e-02 (1.2751e-01) 
2023-05-27 08:09:49.988840: train Epoch: [15][105/193]	Time  0.577 ( 4.928)	Data  0.001 ( 4.353)	Loss 1.1597e-01 (1.2741e-01) 
2023-05-27 08:09:59.106076: train Epoch: [15][106/193]	Time  9.117 ( 4.967)	Data  8.540 ( 4.392)	Loss 6.7604e-02 (1.2685e-01) 
2023-05-27 08:09:59.687013: train Epoch: [15][107/193]	Time  0.581 ( 4.927)	Data  0.001 ( 4.351)	Loss 1.0397e-01 (1.2663e-01) 
2023-05-27 08:10:08.939664: train Epoch: [15][108/193]	Time  9.253 ( 4.966)	Data  8.682 ( 4.391)	Loss 9.2555e-02 (1.2632e-01) 
2023-05-27 08:10:09.504926: train Epoch: [15][109/193]	Time  0.565 ( 4.926)	Data  0.001 ( 4.351)	Loss 1.9836e-01 (1.2698e-01) 
2023-05-27 08:10:18.911383: train Epoch: [15][110/193]	Time  9.406 ( 4.967)	Data  8.816 ( 4.391)	Loss 1.1578e-01 (1.2688e-01) 
2023-05-27 08:10:19.483201: train Epoch: [15][111/193]	Time  0.572 ( 4.928)	Data  0.001 ( 4.352)	Loss 1.7597e-01 (1.2731e-01) 
2023-05-27 08:10:28.884011: train Epoch: [15][112/193]	Time  9.401 ( 4.967)	Data  8.785 ( 4.391)	Loss 1.1121e-01 (1.2717e-01) 
2023-05-27 08:10:29.454907: train Epoch: [15][113/193]	Time  0.571 ( 4.929)	Data  0.001 ( 4.353)	Loss 8.7510e-02 (1.2682e-01) 
2023-05-27 08:10:38.697534: train Epoch: [15][114/193]	Time  9.243 ( 4.966)	Data  8.629 ( 4.390)	Loss 7.7033e-02 (1.2639e-01) 
2023-05-27 08:10:39.269585: train Epoch: [15][115/193]	Time  0.572 ( 4.928)	Data  0.001 ( 4.352)	Loss 2.1213e-01 (1.2713e-01) 
2023-05-27 08:10:49.220804: train Epoch: [15][116/193]	Time  9.951 ( 4.971)	Data  9.382 ( 4.395)	Loss 1.1531e-01 (1.2703e-01) 
2023-05-27 08:10:49.790596: train Epoch: [15][117/193]	Time  0.570 ( 4.934)	Data  0.001 ( 4.358)	Loss 8.1663e-02 (1.2664e-01) 
2023-05-27 08:10:59.034132: train Epoch: [15][118/193]	Time  9.244 ( 4.970)	Data  8.682 ( 4.394)	Loss 1.0455e-01 (1.2646e-01) 
2023-05-27 08:10:59.596786: train Epoch: [15][119/193]	Time  0.563 ( 4.933)	Data  0.001 ( 4.358)	Loss 2.9255e-01 (1.2784e-01) 
2023-05-27 08:11:09.225592: train Epoch: [15][120/193]	Time  9.629 ( 4.972)	Data  9.050 ( 4.397)	Loss 1.0704e-01 (1.2767e-01) 
2023-05-27 08:11:09.793557: train Epoch: [15][121/193]	Time  0.568 ( 4.936)	Data  0.001 ( 4.361)	Loss 6.9125e-02 (1.2719e-01) 
2023-05-27 08:11:19.637186: train Epoch: [15][122/193]	Time  9.844 ( 4.976)	Data  9.280 ( 4.401)	Loss 1.0740e-01 (1.2703e-01) 
2023-05-27 08:11:20.199907: train Epoch: [15][123/193]	Time  0.563 ( 4.940)	Data  0.001 ( 4.365)	Loss 1.0297e-01 (1.2684e-01) 
2023-05-27 08:11:29.674679: train Epoch: [15][124/193]	Time  9.475 ( 4.977)	Data  8.906 ( 4.401)	Loss 1.9241e-01 (1.2736e-01) 
2023-05-27 08:11:30.239416: train Epoch: [15][125/193]	Time  0.565 ( 4.942)	Data  0.001 ( 4.366)	Loss 1.0074e-01 (1.2715e-01) 
2023-05-27 08:11:39.418404: train Epoch: [15][126/193]	Time  9.179 ( 4.975)	Data  8.606 ( 4.400)	Loss 1.2968e-01 (1.2717e-01) 
2023-05-27 08:11:39.982056: train Epoch: [15][127/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.365)	Loss 8.4454e-02 (1.2684e-01) 
2023-05-27 08:11:49.215474: train Epoch: [15][128/193]	Time  9.233 ( 4.974)	Data  8.656 ( 4.399)	Loss 8.2287e-02 (1.2649e-01) 
2023-05-27 08:11:49.779500: train Epoch: [15][129/193]	Time  0.564 ( 4.940)	Data  0.001 ( 4.365)	Loss 9.6135e-02 (1.2626e-01) 
2023-05-27 08:11:58.991618: train Epoch: [15][130/193]	Time  9.212 ( 4.972)	Data  8.629 ( 4.397)	Loss 1.8627e-01 (1.2672e-01) 
2023-05-27 08:11:59.553711: train Epoch: [15][131/193]	Time  0.562 ( 4.939)	Data  0.001 ( 4.364)	Loss 9.0231e-02 (1.2644e-01) 
2023-05-27 08:12:08.900036: train Epoch: [15][132/193]	Time  9.346 ( 4.972)	Data  8.783 ( 4.397)	Loss 1.3934e-01 (1.2654e-01) 
2023-05-27 08:12:09.462155: train Epoch: [15][133/193]	Time  0.562 ( 4.939)	Data  0.001 ( 4.365)	Loss 1.3444e-01 (1.2659e-01) 
2023-05-27 08:12:18.720834: train Epoch: [15][134/193]	Time  9.259 ( 4.971)	Data  8.696 ( 4.397)	Loss 6.6359e-02 (1.2615e-01) 
2023-05-27 08:12:19.295542: train Epoch: [15][135/193]	Time  0.575 ( 4.939)	Data  0.001 ( 4.364)	Loss 1.1239e-01 (1.2605e-01) 
2023-05-27 08:12:29.233859: train Epoch: [15][136/193]	Time  9.938 ( 4.975)	Data  9.370 ( 4.401)	Loss 9.4220e-02 (1.2582e-01) 
2023-05-27 08:12:29.803420: train Epoch: [15][137/193]	Time  0.570 ( 4.944)	Data  0.001 ( 4.369)	Loss 3.3084e-01 (1.2730e-01) 
2023-05-27 08:12:39.213852: train Epoch: [15][138/193]	Time  9.410 ( 4.976)	Data  8.837 ( 4.401)	Loss 1.1112e-01 (1.2718e-01) 
2023-05-27 08:12:39.781810: train Epoch: [15][139/193]	Time  0.568 ( 4.944)	Data  0.001 ( 4.370)	Loss 6.0085e-02 (1.2671e-01) 
2023-05-27 08:12:48.849180: train Epoch: [15][140/193]	Time  9.067 ( 4.973)	Data  8.462 ( 4.399)	Loss 1.6246e-01 (1.2696e-01) 
2023-05-27 08:12:49.420865: train Epoch: [15][141/193]	Time  0.572 ( 4.942)	Data  0.001 ( 4.368)	Loss 8.9994e-02 (1.2670e-01) 
2023-05-27 08:12:58.740456: train Epoch: [15][142/193]	Time  9.320 ( 4.973)	Data  8.741 ( 4.398)	Loss 8.9062e-02 (1.2644e-01) 
2023-05-27 08:12:59.335656: train Epoch: [15][143/193]	Time  0.595 ( 4.943)	Data  0.001 ( 4.368)	Loss 2.6905e-01 (1.2743e-01) 
2023-05-27 08:13:09.009806: train Epoch: [15][144/193]	Time  9.674 ( 4.975)	Data  9.082 ( 4.400)	Loss 9.3553e-02 (1.2719e-01) 
2023-05-27 08:13:09.571598: train Epoch: [15][145/193]	Time  0.562 ( 4.945)	Data  0.001 ( 4.370)	Loss 1.1641e-01 (1.2712e-01) 
2023-05-27 08:13:19.015275: train Epoch: [15][146/193]	Time  9.444 ( 4.976)	Data  8.839 ( 4.401)	Loss 9.5470e-02 (1.2690e-01) 
2023-05-27 08:13:19.577594: train Epoch: [15][147/193]	Time  0.562 ( 4.946)	Data  0.001 ( 4.371)	Loss 8.6282e-02 (1.2663e-01) 
2023-05-27 08:13:29.004594: train Epoch: [15][148/193]	Time  9.427 ( 4.976)	Data  8.825 ( 4.401)	Loss 8.5851e-02 (1.2635e-01) 
2023-05-27 08:13:29.566842: train Epoch: [15][149/193]	Time  0.562 ( 4.946)	Data  0.001 ( 4.371)	Loss 1.0204e-01 (1.2619e-01) 
2023-05-27 08:13:38.829258: train Epoch: [15][150/193]	Time  9.262 ( 4.975)	Data  8.694 ( 4.400)	Loss 8.3258e-02 (1.2591e-01) 
2023-05-27 08:13:39.399709: train Epoch: [15][151/193]	Time  0.570 ( 4.946)	Data  0.001 ( 4.371)	Loss 1.4846e-01 (1.2606e-01) 
2023-05-27 08:13:48.906694: train Epoch: [15][152/193]	Time  9.507 ( 4.976)	Data  8.922 ( 4.401)	Loss 1.0035e-01 (1.2589e-01) 
2023-05-27 08:13:49.484529: train Epoch: [15][153/193]	Time  0.578 ( 4.947)	Data  0.001 ( 4.372)	Loss 1.1347e-01 (1.2581e-01) 
2023-05-27 08:13:58.821586: train Epoch: [15][154/193]	Time  9.337 ( 4.976)	Data  8.769 ( 4.401)	Loss 1.2131e-01 (1.2578e-01) 
2023-05-27 08:13:59.384362: train Epoch: [15][155/193]	Time  0.563 ( 4.947)	Data  0.001 ( 4.372)	Loss 1.7461e-01 (1.2609e-01) 
2023-05-27 08:14:08.562512: train Epoch: [15][156/193]	Time  9.178 ( 4.974)	Data  8.602 ( 4.399)	Loss 7.2754e-02 (1.2575e-01) 
2023-05-27 08:14:09.126711: train Epoch: [15][157/193]	Time  0.564 ( 4.946)	Data  0.001 ( 4.372)	Loss 1.1747e-01 (1.2570e-01) 
2023-05-27 08:14:18.654346: train Epoch: [15][158/193]	Time  9.528 ( 4.975)	Data  8.936 ( 4.400)	Loss 1.5187e-01 (1.2586e-01) 
2023-05-27 08:14:19.233622: train Epoch: [15][159/193]	Time  0.579 ( 4.948)	Data  0.001 ( 4.373)	Loss 6.6085e-02 (1.2549e-01) 
2023-05-27 08:14:28.903182: train Epoch: [15][160/193]	Time  9.670 ( 4.977)	Data  9.105 ( 4.402)	Loss 9.2381e-02 (1.2529e-01) 
2023-05-27 08:14:29.467072: train Epoch: [15][161/193]	Time  0.564 ( 4.950)	Data  0.001 ( 4.375)	Loss 1.4190e-01 (1.2539e-01) 
2023-05-27 08:14:38.753568: train Epoch: [15][162/193]	Time  9.286 ( 4.976)	Data  8.674 ( 4.401)	Loss 8.2891e-02 (1.2513e-01) 
2023-05-27 08:14:39.315276: train Epoch: [15][163/193]	Time  0.562 ( 4.950)	Data  0.001 ( 4.374)	Loss 1.7895e-01 (1.2546e-01) 
2023-05-27 08:14:49.011361: train Epoch: [15][164/193]	Time  9.696 ( 4.978)	Data  9.118 ( 4.403)	Loss 1.7340e-01 (1.2575e-01) 
2023-05-27 08:14:49.582963: train Epoch: [15][165/193]	Time  0.572 ( 4.952)	Data  0.001 ( 4.377)	Loss 8.6265e-02 (1.2551e-01) 
2023-05-27 08:14:58.975789: train Epoch: [15][166/193]	Time  9.393 ( 4.978)	Data  8.811 ( 4.403)	Loss 8.5076e-02 (1.2527e-01) 
2023-05-27 08:14:59.543730: train Epoch: [15][167/193]	Time  0.568 ( 4.952)	Data  0.001 ( 4.377)	Loss 1.6787e-01 (1.2552e-01) 
2023-05-27 08:15:08.718472: train Epoch: [15][168/193]	Time  9.175 ( 4.977)	Data  8.573 ( 4.402)	Loss 7.1533e-02 (1.2520e-01) 
2023-05-27 08:15:09.285712: train Epoch: [15][169/193]	Time  0.567 ( 4.951)	Data  0.001 ( 4.376)	Loss 1.2072e-01 (1.2517e-01) 
2023-05-27 08:15:18.506054: train Epoch: [15][170/193]	Time  9.220 ( 4.976)	Data  8.647 ( 4.401)	Loss 1.6828e-01 (1.2543e-01) 
2023-05-27 08:15:19.117360: train Epoch: [15][171/193]	Time  0.611 ( 4.951)	Data  0.047 ( 4.376)	Loss 1.7992e-01 (1.2574e-01) 
2023-05-27 08:15:28.444093: train Epoch: [15][172/193]	Time  9.327 ( 4.976)	Data  8.759 ( 4.401)	Loss 1.1961e-01 (1.2571e-01) 
2023-05-27 08:15:29.053513: train Epoch: [15][173/193]	Time  0.609 ( 4.951)	Data  0.042 ( 4.376)	Loss 1.3530e-01 (1.2576e-01) 
2023-05-27 08:15:38.437114: train Epoch: [15][174/193]	Time  9.384 ( 4.976)	Data  8.816 ( 4.401)	Loss 1.1723e-01 (1.2571e-01) 
2023-05-27 08:15:39.008371: train Epoch: [15][175/193]	Time  0.571 ( 4.951)	Data  0.001 ( 4.376)	Loss 1.2541e-01 (1.2571e-01) 
2023-05-27 08:15:48.245498: train Epoch: [15][176/193]	Time  9.237 ( 4.975)	Data  8.657 ( 4.401)	Loss 1.3757e-01 (1.2578e-01) 
2023-05-27 08:15:49.405617: train Epoch: [15][177/193]	Time  1.160 ( 4.954)	Data  0.595 ( 4.379)	Loss 7.6046e-02 (1.2550e-01) 
2023-05-27 08:15:58.073219: train Epoch: [15][178/193]	Time  8.668 ( 4.975)	Data  8.085 ( 4.400)	Loss 1.3079e-01 (1.2553e-01) 
2023-05-27 08:15:59.038442: train Epoch: [15][179/193]	Time  0.965 ( 4.952)	Data  0.397 ( 4.378)	Loss 1.0016e-01 (1.2539e-01) 
2023-05-27 08:16:07.931809: train Epoch: [15][180/193]	Time  8.893 ( 4.974)	Data  8.324 ( 4.399)	Loss 8.9199e-02 (1.2519e-01) 
2023-05-27 08:16:09.154126: train Epoch: [15][181/193]	Time  1.222 ( 4.954)	Data  0.654 ( 4.379)	Loss 1.5856e-01 (1.2537e-01) 
2023-05-27 08:16:17.921420: train Epoch: [15][182/193]	Time  8.767 ( 4.974)	Data  8.185 ( 4.400)	Loss 9.1442e-02 (1.2519e-01) 
2023-05-27 08:16:19.092357: train Epoch: [15][183/193]	Time  1.171 ( 4.954)	Data  0.608 ( 4.379)	Loss 1.3881e-01 (1.2526e-01) 
2023-05-27 08:16:27.710275: train Epoch: [15][184/193]	Time  8.618 ( 4.974)	Data  8.035 ( 4.399)	Loss 3.0543e-01 (1.2623e-01) 
2023-05-27 08:16:28.794416: train Epoch: [15][185/193]	Time  1.084 ( 4.953)	Data  0.507 ( 4.378)	Loss 1.3393e-01 (1.2628e-01) 
2023-05-27 08:16:37.755727: train Epoch: [15][186/193]	Time  8.961 ( 4.974)	Data  8.374 ( 4.399)	Loss 1.3940e-01 (1.2635e-01) 
2023-05-27 08:16:38.656131: train Epoch: [15][187/193]	Time  0.900 ( 4.952)	Data  0.310 ( 4.377)	Loss 5.5391e-02 (1.2597e-01) 
2023-05-27 08:16:48.170847: train Epoch: [15][188/193]	Time  9.515 ( 4.977)	Data  8.925 ( 4.402)	Loss 1.5404e-01 (1.2612e-01) 
2023-05-27 08:16:48.752214: train Epoch: [15][189/193]	Time  0.581 ( 4.953)	Data  0.001 ( 4.378)	Loss 9.1817e-02 (1.2594e-01) 
2023-05-27 08:16:58.047750: train Epoch: [15][190/193]	Time  9.296 ( 4.976)	Data  8.708 ( 4.401)	Loss 9.5091e-02 (1.2577e-01) 
2023-05-27 08:16:58.861362: train Epoch: [15][191/193]	Time  0.814 ( 4.955)	Data  0.211 ( 4.379)	Loss 1.2740e-01 (1.2578e-01) 
2023-05-27 08:17:07.042534: train Epoch: [15][192/193]	Time  8.181 ( 4.971)	Data  7.613 ( 4.396)	Loss 8.9738e-02 (1.2560e-01) 
2023-05-27 08:17:07.167141: Train Epoch done in 959.5710384470003 s 
2023-05-27 08:17:13.179208: val Epoch: [15][ 0/72]	Time  5.305 ( 5.305)	Data  5.126 ( 5.126)	Loss 1.0541e-01 (1.0541e-01) 
2023-05-27 08:17:13.292161: val Epoch: [15][ 1/72]	Time  0.113 ( 2.709)	Data  0.002 ( 2.564)	Loss 7.7097e-02 (9.1251e-02) 
2023-05-27 08:17:18.095448: val Epoch: [15][ 2/72]	Time  4.803 ( 3.407)	Data  4.692 ( 3.273)	Loss 1.7891e-01 (1.2047e-01) 
2023-05-27 08:17:18.207266: val Epoch: [15][ 3/72]	Time  0.112 ( 2.583)	Data  0.000 ( 2.455)	Loss 1.0821e-01 (1.1741e-01) 
2023-05-27 08:17:23.072629: val Epoch: [15][ 4/72]	Time  4.865 ( 3.040)	Data  4.749 ( 2.914)	Loss 6.2909e-02 (1.0651e-01) 
2023-05-27 08:17:23.188426: val Epoch: [15][ 5/72]	Time  0.116 ( 2.552)	Data  0.001 ( 2.428)	Loss 1.0177e-01 (1.0572e-01) 
2023-05-27 08:17:27.794520: val Epoch: [15][ 6/72]	Time  4.606 ( 2.846)	Data  4.492 ( 2.723)	Loss 5.3440e-02 (9.8249e-02) 
2023-05-27 08:17:27.914401: val Epoch: [15][ 7/72]	Time  0.120 ( 2.505)	Data  0.008 ( 2.384)	Loss 6.3996e-02 (9.3968e-02) 
2023-05-27 08:17:32.571570: val Epoch: [15][ 8/72]	Time  4.657 ( 2.744)	Data  4.546 ( 2.624)	Loss 2.2216e-01 (1.0821e-01) 
2023-05-27 08:17:32.755863: val Epoch: [15][ 9/72]	Time  0.184 ( 2.488)	Data  0.073 ( 2.369)	Loss 6.1539e-02 (1.0354e-01) 
2023-05-27 08:17:37.500766: val Epoch: [15][10/72]	Time  4.745 ( 2.693)	Data  4.634 ( 2.575)	Loss 1.6310e-01 (1.0896e-01) 
2023-05-27 08:17:37.807113: val Epoch: [15][11/72]	Time  0.306 ( 2.494)	Data  0.195 ( 2.377)	Loss 3.7537e-01 (1.3116e-01) 
2023-05-27 08:17:42.641051: val Epoch: [15][12/72]	Time  4.834 ( 2.674)	Data  4.723 ( 2.557)	Loss 1.2484e-01 (1.3067e-01) 
2023-05-27 08:17:42.752437: val Epoch: [15][13/72]	Time  0.111 ( 2.491)	Data  0.001 ( 2.374)	Loss 1.2414e-01 (1.3021e-01) 
2023-05-27 08:17:47.689416: val Epoch: [15][14/72]	Time  4.937 ( 2.654)	Data  4.826 ( 2.538)	Loss 1.1886e-01 (1.2945e-01) 
2023-05-27 08:17:47.800116: val Epoch: [15][15/72]	Time  0.111 ( 2.495)	Data  0.000 ( 2.379)	Loss 5.8065e-02 (1.2499e-01) 
2023-05-27 08:17:52.641309: val Epoch: [15][16/72]	Time  4.841 ( 2.633)	Data  4.733 ( 2.518)	Loss 7.6379e-02 (1.2213e-01) 
2023-05-27 08:17:52.749118: val Epoch: [15][17/72]	Time  0.108 ( 2.493)	Data  0.001 ( 2.378)	Loss 1.3046e-01 (1.2259e-01) 
2023-05-27 08:17:57.791639: val Epoch: [15][18/72]	Time  5.043 ( 2.627)	Data  4.930 ( 2.512)	Loss 9.3270e-02 (1.2105e-01) 
2023-05-27 08:17:57.903667: val Epoch: [15][19/72]	Time  0.112 ( 2.501)	Data  0.001 ( 2.387)	Loss 2.0525e-01 (1.2526e-01) 
2023-05-27 08:18:02.663471: val Epoch: [15][20/72]	Time  4.760 ( 2.609)	Data  4.652 ( 2.494)	Loss 6.7501e-01 (1.5144e-01) 
2023-05-27 08:18:02.898180: val Epoch: [15][21/72]	Time  0.235 ( 2.501)	Data  0.128 ( 2.387)	Loss 3.2568e-01 (1.5936e-01) 
2023-05-27 08:18:07.424695: val Epoch: [15][22/72]	Time  4.527 ( 2.589)	Data  4.418 ( 2.475)	Loss 1.7898e-01 (1.6021e-01) 
2023-05-27 08:18:07.654425: val Epoch: [15][23/72]	Time  0.230 ( 2.491)	Data  0.123 ( 2.377)	Loss 8.0088e-02 (1.5687e-01) 
2023-05-27 08:18:12.279265: val Epoch: [15][24/72]	Time  4.625 ( 2.576)	Data  4.510 ( 2.462)	Loss 6.3867e-02 (1.5315e-01) 
2023-05-27 08:18:12.469431: val Epoch: [15][25/72]	Time  0.190 ( 2.484)	Data  0.078 ( 2.371)	Loss 8.0068e-02 (1.5034e-01) 
2023-05-27 08:18:17.317444: val Epoch: [15][26/72]	Time  4.848 ( 2.572)	Data  4.722 ( 2.458)	Loss 1.1453e-01 (1.4902e-01) 
2023-05-27 08:18:17.646711: val Epoch: [15][27/72]	Time  0.329 ( 2.492)	Data  0.219 ( 2.378)	Loss 7.8713e-02 (1.4650e-01) 
2023-05-27 08:18:22.285791: val Epoch: [15][28/72]	Time  4.639 ( 2.566)	Data  4.503 ( 2.451)	Loss 5.8076e-02 (1.4346e-01) 
2023-05-27 08:18:22.579218: val Epoch: [15][29/72]	Time  0.293 ( 2.490)	Data  0.185 ( 2.376)	Loss 3.7614e-01 (1.5121e-01) 
2023-05-27 08:18:27.079640: val Epoch: [15][30/72]	Time  4.500 ( 2.555)	Data  4.383 ( 2.440)	Loss 2.4276e-01 (1.5416e-01) 
2023-05-27 08:18:27.380946: val Epoch: [15][31/72]	Time  0.301 ( 2.485)	Data  0.110 ( 2.368)	Loss 6.1913e-01 (1.6869e-01) 
2023-05-27 08:18:32.203234: val Epoch: [15][32/72]	Time  4.822 ( 2.555)	Data  4.704 ( 2.438)	Loss 1.7611e-01 (1.6892e-01) 
2023-05-27 08:18:32.499069: val Epoch: [15][33/72]	Time  0.296 ( 2.489)	Data  0.189 ( 2.372)	Loss 1.2235e-01 (1.6755e-01) 
2023-05-27 08:18:37.141584: val Epoch: [15][34/72]	Time  4.643 ( 2.551)	Data  4.514 ( 2.433)	Loss 5.3828e-01 (1.7814e-01) 
2023-05-27 08:18:37.431417: val Epoch: [15][35/72]	Time  0.290 ( 2.488)	Data  0.173 ( 2.371)	Loss 6.9524e-02 (1.7512e-01) 
2023-05-27 08:18:42.131181: val Epoch: [15][36/72]	Time  4.700 ( 2.547)	Data  4.575 ( 2.430)	Loss 2.2438e-01 (1.7646e-01) 
2023-05-27 08:18:42.603390: val Epoch: [15][37/72]	Time  0.472 ( 2.493)	Data  0.354 ( 2.376)	Loss 1.1370e-01 (1.7480e-01) 
2023-05-27 08:18:46.827388: val Epoch: [15][38/72]	Time  4.224 ( 2.537)	Data  4.102 ( 2.420)	Loss 6.7234e-02 (1.7205e-01) 
2023-05-27 08:18:47.543936: val Epoch: [15][39/72]	Time  0.717 ( 2.492)	Data  0.609 ( 2.375)	Loss 1.4075e-01 (1.7126e-01) 
2023-05-27 08:18:51.639300: val Epoch: [15][40/72]	Time  4.095 ( 2.531)	Data  3.988 ( 2.414)	Loss 5.6509e-02 (1.6846e-01) 
2023-05-27 08:18:52.715901: val Epoch: [15][41/72]	Time  1.077 ( 2.496)	Data  0.969 ( 2.380)	Loss 8.3652e-02 (1.6645e-01) 
2023-05-27 08:18:56.365324: val Epoch: [15][42/72]	Time  3.649 ( 2.523)	Data  3.518 ( 2.406)	Loss 8.8062e-02 (1.6462e-01) 
2023-05-27 08:18:57.875624: val Epoch: [15][43/72]	Time  1.510 ( 2.500)	Data  1.398 ( 2.383)	Loss 6.9783e-01 (1.7674e-01) 
2023-05-27 08:19:01.403993: val Epoch: [15][44/72]	Time  3.528 ( 2.523)	Data  3.417 ( 2.406)	Loss 3.8121e-01 (1.8128e-01) 
2023-05-27 08:19:02.946171: val Epoch: [15][45/72]	Time  1.542 ( 2.502)	Data  1.431 ( 2.385)	Loss 1.7465e-01 (1.8114e-01) 
2023-05-27 08:19:06.488091: val Epoch: [15][46/72]	Time  3.542 ( 2.524)	Data  3.430 ( 2.407)	Loss 5.1532e-01 (1.8825e-01) 
2023-05-27 08:19:07.697289: val Epoch: [15][47/72]	Time  1.209 ( 2.496)	Data  1.099 ( 2.380)	Loss 8.2978e-02 (1.8606e-01) 
2023-05-27 08:19:11.668881: val Epoch: [15][48/72]	Time  3.972 ( 2.526)	Data  3.861 ( 2.410)	Loss 6.0650e-02 (1.8350e-01) 
2023-05-27 08:19:12.899205: val Epoch: [15][49/72]	Time  1.230 ( 2.501)	Data  1.123 ( 2.384)	Loss 1.3046e-01 (1.8244e-01) 
2023-05-27 08:19:16.621423: val Epoch: [15][50/72]	Time  3.722 ( 2.524)	Data  3.614 ( 2.408)	Loss 1.4185e-01 (1.8164e-01) 
2023-05-27 08:19:17.922314: val Epoch: [15][51/72]	Time  1.301 ( 2.501)	Data  1.192 ( 2.385)	Loss 3.8961e-01 (1.8564e-01) 
2023-05-27 08:19:21.797878: val Epoch: [15][52/72]	Time  3.876 ( 2.527)	Data  3.745 ( 2.411)	Loss 2.0869e-01 (1.8608e-01) 
2023-05-27 08:19:22.906418: val Epoch: [15][53/72]	Time  1.109 ( 2.501)	Data  1.001 ( 2.385)	Loss 8.3006e-02 (1.8417e-01) 
2023-05-27 08:19:26.961349: val Epoch: [15][54/72]	Time  4.055 ( 2.529)	Data  3.947 ( 2.413)	Loss 4.0595e-01 (1.8820e-01) 
2023-05-27 08:19:27.792309: val Epoch: [15][55/72]	Time  0.831 ( 2.499)	Data  0.720 ( 2.383)	Loss 7.2553e-02 (1.8613e-01) 
2023-05-27 08:19:32.055043: val Epoch: [15][56/72]	Time  4.263 ( 2.529)	Data  4.155 ( 2.414)	Loss 7.4308e-02 (1.8417e-01) 
2023-05-27 08:19:32.946233: val Epoch: [15][57/72]	Time  0.891 ( 2.501)	Data  0.784 ( 2.386)	Loss 1.5692e-01 (1.8370e-01) 
2023-05-27 08:19:36.706051: val Epoch: [15][58/72]	Time  3.760 ( 2.523)	Data  3.652 ( 2.407)	Loss 1.7618e-01 (1.8358e-01) 
2023-05-27 08:19:37.852713: val Epoch: [15][59/72]	Time  1.147 ( 2.500)	Data  1.038 ( 2.384)	Loss 1.0629e-01 (1.8229e-01) 
2023-05-27 08:19:41.663749: val Epoch: [15][60/72]	Time  3.811 ( 2.521)	Data  3.699 ( 2.406)	Loss 7.7415e-02 (1.8057e-01) 
2023-05-27 08:19:42.803958: val Epoch: [15][61/72]	Time  1.140 ( 2.499)	Data  1.030 ( 2.384)	Loss 7.6151e-02 (1.7888e-01) 
2023-05-27 08:19:46.548616: val Epoch: [15][62/72]	Time  3.745 ( 2.519)	Data  3.637 ( 2.404)	Loss 8.9537e-02 (1.7747e-01) 
2023-05-27 08:19:47.848285: val Epoch: [15][63/72]	Time  1.300 ( 2.500)	Data  1.187 ( 2.385)	Loss 1.5400e-01 (1.7710e-01) 
2023-05-27 08:19:51.384877: val Epoch: [15][64/72]	Time  3.537 ( 2.516)	Data  3.429 ( 2.401)	Loss 1.1973e-01 (1.7622e-01) 
2023-05-27 08:19:52.939899: val Epoch: [15][65/72]	Time  1.555 ( 2.501)	Data  1.447 ( 2.386)	Loss 1.1656e-01 (1.7531e-01) 
2023-05-27 08:19:56.278969: val Epoch: [15][66/72]	Time  3.339 ( 2.514)	Data  3.231 ( 2.399)	Loss 1.7271e-01 (1.7527e-01) 
2023-05-27 08:19:57.972966: val Epoch: [15][67/72]	Time  1.694 ( 2.501)	Data  1.558 ( 2.387)	Loss 2.4575e-01 (1.7631e-01) 
2023-05-27 08:20:01.213808: val Epoch: [15][68/72]	Time  3.241 ( 2.512)	Data  3.123 ( 2.397)	Loss 8.4599e-02 (1.7498e-01) 
2023-05-27 08:20:03.035929: val Epoch: [15][69/72]	Time  1.822 ( 2.502)	Data  1.714 ( 2.387)	Loss 6.6217e-02 (1.7343e-01) 
2023-05-27 08:20:06.378379: val Epoch: [15][70/72]	Time  3.342 ( 2.514)	Data  3.224 ( 2.399)	Loss 1.2753e-01 (1.7278e-01) 
2023-05-27 08:20:07.952520: val Epoch: [15][71/72]	Time  1.574 ( 2.501)	Data  1.456 ( 2.386)	Loss 1.2084e-01 (1.7206e-01) 
2023-05-27 08:20:08.295151: Epoch 15 :Val : ['ET : 0.7160350680351257', 'TC : 0.7285249829292297', 'WT : 0.7911127805709839'] 
2023-05-27 08:20:08.302511: Epoch 15 :Val : ['ET : 0.7160350680351257', 'TC : 0.7285249829292297', 'WT : 0.7911127805709839'] 
2023-05-27 08:20:08.304614: Val epoch done in 181.13748195799417 s 
2023-05-27 08:20:08.312942: Batches per epoch:  193 
2023-05-27 08:20:19.519892: train Epoch: [16][  0/193]	Time 11.207 (11.207)	Data 10.479 (10.479)	Loss 1.2216e-01 (1.2216e-01) 
2023-05-27 08:20:20.126458: train Epoch: [16][  1/193]	Time  0.607 ( 5.907)	Data  0.001 ( 5.240)	Loss 2.8966e-01 (2.0591e-01) 
2023-05-27 08:20:29.754126: train Epoch: [16][  2/193]	Time  9.628 ( 7.147)	Data  9.022 ( 6.501)	Loss 8.4569e-02 (1.6546e-01) 
2023-05-27 08:20:30.324313: train Epoch: [16][  3/193]	Time  0.570 ( 5.503)	Data  0.001 ( 4.876)	Loss 9.0330e-02 (1.4668e-01) 
2023-05-27 08:20:39.753336: train Epoch: [16][  4/193]	Time  9.429 ( 6.288)	Data  8.823 ( 5.665)	Loss 1.2335e-01 (1.4201e-01) 
2023-05-27 08:20:40.321101: train Epoch: [16][  5/193]	Time  0.568 ( 5.335)	Data  0.001 ( 4.721)	Loss 6.9519e-02 (1.2993e-01) 
2023-05-27 08:20:49.880086: train Epoch: [16][  6/193]	Time  9.559 ( 5.938)	Data  8.978 ( 5.329)	Loss 8.7398e-02 (1.2385e-01) 
2023-05-27 08:20:50.485376: train Epoch: [16][  7/193]	Time  0.605 ( 5.272)	Data  0.001 ( 4.663)	Loss 8.6472e-02 (1.1918e-01) 
2023-05-27 08:21:00.016905: train Epoch: [16][  8/193]	Time  9.532 ( 5.745)	Data  8.965 ( 5.141)	Loss 1.1634e-01 (1.1887e-01) 
2023-05-27 08:21:00.603876: train Epoch: [16][  9/193]	Time  0.587 ( 5.229)	Data  0.001 ( 4.627)	Loss 7.9210e-02 (1.1490e-01) 
2023-05-27 08:21:10.428734: train Epoch: [16][ 10/193]	Time  9.825 ( 5.647)	Data  9.254 ( 5.048)	Loss 1.1238e-01 (1.1467e-01) 
2023-05-27 08:21:11.043610: train Epoch: [16][ 11/193]	Time  0.615 ( 5.228)	Data  0.001 ( 4.627)	Loss 1.3629e-01 (1.1647e-01) 
2023-05-27 08:21:21.101323: train Epoch: [16][ 12/193]	Time 10.058 ( 5.599)	Data  9.481 ( 5.001)	Loss 1.6853e-01 (1.2048e-01) 
2023-05-27 08:21:21.665003: train Epoch: [16][ 13/193]	Time  0.564 ( 5.239)	Data  0.001 ( 4.643)	Loss 1.4845e-01 (1.2248e-01) 
2023-05-27 08:21:31.128715: train Epoch: [16][ 14/193]	Time  9.464 ( 5.521)	Data  8.857 ( 4.924)	Loss 1.9218e-01 (1.2712e-01) 
2023-05-27 08:21:31.691940: train Epoch: [16][ 15/193]	Time  0.563 ( 5.211)	Data  0.001 ( 4.617)	Loss 2.0015e-01 (1.3169e-01) 
2023-05-27 08:21:40.967030: train Epoch: [16][ 16/193]	Time  9.275 ( 5.450)	Data  8.671 ( 4.855)	Loss 1.6937e-01 (1.3390e-01) 
2023-05-27 08:21:41.530223: train Epoch: [16][ 17/193]	Time  0.563 ( 5.179)	Data  0.001 ( 4.585)	Loss 1.6252e-01 (1.3549e-01) 
2023-05-27 08:21:51.015970: train Epoch: [16][ 18/193]	Time  9.486 ( 5.405)	Data  8.923 ( 4.814)	Loss 9.7759e-02 (1.3351e-01) 
2023-05-27 08:21:51.579626: train Epoch: [16][ 19/193]	Time  0.564 ( 5.163)	Data  0.001 ( 4.573)	Loss 7.8781e-02 (1.3077e-01) 
2023-05-27 08:22:00.440522: train Epoch: [16][ 20/193]	Time  8.861 ( 5.339)	Data  8.292 ( 4.750)	Loss 6.9650e-02 (1.2786e-01) 
2023-05-27 08:22:01.005483: train Epoch: [16][ 21/193]	Time  0.565 ( 5.122)	Data  0.001 ( 4.534)	Loss 1.6845e-01 (1.2971e-01) 
2023-05-27 08:22:09.876015: train Epoch: [16][ 22/193]	Time  8.871 ( 5.285)	Data  8.301 ( 4.698)	Loss 1.6549e-01 (1.3126e-01) 
2023-05-27 08:22:10.444956: train Epoch: [16][ 23/193]	Time  0.569 ( 5.089)	Data  0.001 ( 4.502)	Loss 1.1643e-01 (1.3064e-01) 
2023-05-27 08:22:20.151031: train Epoch: [16][ 24/193]	Time  9.706 ( 5.274)	Data  9.120 ( 4.687)	Loss 9.3219e-02 (1.2915e-01) 
2023-05-27 08:22:20.722265: train Epoch: [16][ 25/193]	Time  0.571 ( 5.093)	Data  0.001 ( 4.507)	Loss 8.4199e-02 (1.2742e-01) 
2023-05-27 08:22:29.795909: train Epoch: [16][ 26/193]	Time  9.074 ( 5.240)	Data  8.509 ( 4.655)	Loss 1.8090e-01 (1.2940e-01) 
2023-05-27 08:22:30.360461: train Epoch: [16][ 27/193]	Time  0.565 ( 5.073)	Data  0.001 ( 4.489)	Loss 4.9103e-02 (1.2653e-01) 
2023-05-27 08:22:39.939484: train Epoch: [16][ 28/193]	Time  9.579 ( 5.228)	Data  9.016 ( 4.645)	Loss 6.3291e-02 (1.2435e-01) 
2023-05-27 08:22:40.505140: train Epoch: [16][ 29/193]	Time  0.566 ( 5.073)	Data  0.001 ( 4.490)	Loss 7.8325e-02 (1.2282e-01) 
2023-05-27 08:22:49.760376: train Epoch: [16][ 30/193]	Time  9.255 ( 5.208)	Data  8.682 ( 4.625)	Loss 2.9728e-01 (1.2844e-01) 
2023-05-27 08:22:50.324485: train Epoch: [16][ 31/193]	Time  0.564 ( 5.063)	Data  0.001 ( 4.481)	Loss 1.3104e-01 (1.2852e-01) 
2023-05-27 08:22:59.203241: train Epoch: [16][ 32/193]	Time  8.879 ( 5.178)	Data  8.305 ( 4.597)	Loss 1.1167e-01 (1.2801e-01) 
2023-05-27 08:22:59.767761: train Epoch: [16][ 33/193]	Time  0.565 ( 5.043)	Data  0.001 ( 4.462)	Loss 1.3707e-01 (1.2828e-01) 
2023-05-27 08:23:09.717447: train Epoch: [16][ 34/193]	Time  9.950 ( 5.183)	Data  9.386 ( 4.602)	Loss 7.7538e-02 (1.2683e-01) 
2023-05-27 08:23:10.282054: train Epoch: [16][ 35/193]	Time  0.565 ( 5.055)	Data  0.001 ( 4.474)	Loss 9.8382e-02 (1.2604e-01) 
2023-05-27 08:23:20.053635: train Epoch: [16][ 36/193]	Time  9.772 ( 5.182)	Data  9.210 ( 4.602)	Loss 1.1092e-01 (1.2563e-01) 
2023-05-27 08:23:20.629560: train Epoch: [16][ 37/193]	Time  0.576 ( 5.061)	Data  0.001 ( 4.481)	Loss 9.2322e-02 (1.2476e-01) 
2023-05-27 08:23:29.779716: train Epoch: [16][ 38/193]	Time  9.150 ( 5.166)	Data  8.585 ( 4.587)	Loss 1.0759e-01 (1.2432e-01) 
2023-05-27 08:23:30.342842: train Epoch: [16][ 39/193]	Time  0.563 ( 5.051)	Data  0.001 ( 4.472)	Loss 1.5728e-01 (1.2514e-01) 
2023-05-27 08:23:38.820908: train Epoch: [16][ 40/193]	Time  8.478 ( 5.134)	Data  7.899 ( 4.555)	Loss 2.0001e-01 (1.2697e-01) 
2023-05-27 08:23:39.386216: train Epoch: [16][ 41/193]	Time  0.565 ( 5.026)	Data  0.001 ( 4.447)	Loss 7.8345e-02 (1.2581e-01) 
2023-05-27 08:23:47.421425: train Epoch: [16][ 42/193]	Time  8.035 ( 5.096)	Data  7.465 ( 4.517)	Loss 1.5956e-01 (1.2659e-01) 
2023-05-27 08:23:47.985911: train Epoch: [16][ 43/193]	Time  0.564 ( 4.993)	Data  0.001 ( 4.415)	Loss 1.2507e-01 (1.2656e-01) 
2023-05-27 08:23:57.235221: train Epoch: [16][ 44/193]	Time  9.249 ( 5.087)	Data  8.685 ( 4.509)	Loss 1.0781e-01 (1.2614e-01) 
2023-05-27 08:23:57.801041: train Epoch: [16][ 45/193]	Time  0.566 ( 4.989)	Data  0.001 ( 4.411)	Loss 1.0852e-01 (1.2576e-01) 
2023-05-27 08:24:06.976224: train Epoch: [16][ 46/193]	Time  9.175 ( 5.078)	Data  8.610 ( 4.501)	Loss 1.3243e-01 (1.2590e-01) 
2023-05-27 08:24:07.543483: train Epoch: [16][ 47/193]	Time  0.567 ( 4.984)	Data  0.001 ( 4.407)	Loss 1.6550e-01 (1.2673e-01) 
2023-05-27 08:24:16.863366: train Epoch: [16][ 48/193]	Time  9.320 ( 5.072)	Data  8.756 ( 4.496)	Loss 1.5212e-01 (1.2724e-01) 
2023-05-27 08:24:17.431545: train Epoch: [16][ 49/193]	Time  0.568 ( 4.982)	Data  0.001 ( 4.406)	Loss 1.1826e-01 (1.2706e-01) 
2023-05-27 08:24:26.625775: train Epoch: [16][ 50/193]	Time  9.194 ( 5.065)	Data  8.628 ( 4.489)	Loss 3.8598e-01 (1.3214e-01) 
2023-05-27 08:24:27.192248: train Epoch: [16][ 51/193]	Time  0.566 ( 4.978)	Data  0.001 ( 4.402)	Loss 1.1474e-01 (1.3181e-01) 
2023-05-27 08:24:36.963099: train Epoch: [16][ 52/193]	Time  9.771 ( 5.069)	Data  9.205 ( 4.493)	Loss 1.3696e-01 (1.3190e-01) 
2023-05-27 08:24:37.536038: train Epoch: [16][ 53/193]	Time  0.573 ( 4.986)	Data  0.001 ( 4.410)	Loss 9.1204e-02 (1.3115e-01) 
2023-05-27 08:24:46.646711: train Epoch: [16][ 54/193]	Time  9.111 ( 5.061)	Data  8.547 ( 4.485)	Loss 2.3894e-01 (1.3311e-01) 
2023-05-27 08:24:47.211030: train Epoch: [16][ 55/193]	Time  0.564 ( 4.980)	Data  0.001 ( 4.405)	Loss 8.0132e-02 (1.3216e-01) 
2023-05-27 08:24:56.262218: train Epoch: [16][ 56/193]	Time  9.051 ( 5.052)	Data  8.480 ( 4.476)	Loss 6.6003e-02 (1.3100e-01) 
2023-05-27 08:24:56.827500: train Epoch: [16][ 57/193]	Time  0.565 ( 4.974)	Data  0.001 ( 4.399)	Loss 9.7707e-02 (1.3043e-01) 
2023-05-27 08:25:05.605332: train Epoch: [16][ 58/193]	Time  8.778 ( 5.039)	Data  8.215 ( 4.464)	Loss 7.2356e-02 (1.2944e-01) 
2023-05-27 08:25:06.170865: train Epoch: [16][ 59/193]	Time  0.566 ( 4.964)	Data  0.001 ( 4.390)	Loss 7.8494e-02 (1.2860e-01) 
2023-05-27 08:25:15.377253: train Epoch: [16][ 60/193]	Time  9.206 ( 5.034)	Data  8.598 ( 4.459)	Loss 1.2376e-01 (1.2852e-01) 
2023-05-27 08:25:15.940392: train Epoch: [16][ 61/193]	Time  0.563 ( 4.962)	Data  0.001 ( 4.387)	Loss 5.9359e-02 (1.2740e-01) 
2023-05-27 08:25:25.657786: train Epoch: [16][ 62/193]	Time  9.717 ( 5.037)	Data  9.147 ( 4.462)	Loss 1.0016e-01 (1.2697e-01) 
2023-05-27 08:25:26.220832: train Epoch: [16][ 63/193]	Time  0.563 ( 4.967)	Data  0.001 ( 4.392)	Loss 1.2050e-01 (1.2687e-01) 
2023-05-27 08:25:36.042143: train Epoch: [16][ 64/193]	Time  9.821 ( 5.042)	Data  9.257 ( 4.467)	Loss 3.1021e-01 (1.2969e-01) 
2023-05-27 08:25:36.608830: train Epoch: [16][ 65/193]	Time  0.567 ( 4.974)	Data  0.001 ( 4.400)	Loss 8.4329e-02 (1.2900e-01) 
2023-05-27 08:25:46.059993: train Epoch: [16][ 66/193]	Time  9.451 ( 5.041)	Data  8.888 ( 4.467)	Loss 8.3664e-02 (1.2832e-01) 
2023-05-27 08:25:46.628587: train Epoch: [16][ 67/193]	Time  0.569 ( 4.975)	Data  0.001 ( 4.401)	Loss 1.0675e-01 (1.2801e-01) 
2023-05-27 08:25:55.593607: train Epoch: [16][ 68/193]	Time  8.965 ( 5.033)	Data  8.395 ( 4.459)	Loss 6.1066e-02 (1.2704e-01) 
2023-05-27 08:25:56.161178: train Epoch: [16][ 69/193]	Time  0.568 ( 4.969)	Data  0.001 ( 4.395)	Loss 9.0346e-02 (1.2651e-01) 
2023-05-27 08:26:05.629808: train Epoch: [16][ 70/193]	Time  9.469 ( 5.033)	Data  8.903 ( 4.459)	Loss 1.2715e-01 (1.2652e-01) 
2023-05-27 08:26:06.195560: train Epoch: [16][ 71/193]	Time  0.566 ( 4.971)	Data  0.001 ( 4.397)	Loss 1.0026e-01 (1.2616e-01) 
2023-05-27 08:26:15.918860: train Epoch: [16][ 72/193]	Time  9.723 ( 5.036)	Data  9.150 ( 4.462)	Loss 1.2206e-01 (1.2610e-01) 
2023-05-27 08:26:16.511264: train Epoch: [16][ 73/193]	Time  0.592 ( 4.976)	Data  0.001 ( 4.402)	Loss 7.5349e-02 (1.2541e-01) 
2023-05-27 08:26:25.986668: train Epoch: [16][ 74/193]	Time  9.475 ( 5.036)	Data  8.901 ( 4.462)	Loss 1.0543e-01 (1.2515e-01) 
2023-05-27 08:26:26.555279: train Epoch: [16][ 75/193]	Time  0.569 ( 4.977)	Data  0.001 ( 4.403)	Loss 6.9180e-02 (1.2441e-01) 
2023-05-27 08:26:35.811590: train Epoch: [16][ 76/193]	Time  9.256 ( 5.032)	Data  8.691 ( 4.459)	Loss 7.3328e-02 (1.2375e-01) 
2023-05-27 08:26:36.376159: train Epoch: [16][ 77/193]	Time  0.565 ( 4.975)	Data  0.001 ( 4.401)	Loss 1.5394e-01 (1.2414e-01) 
2023-05-27 08:26:45.255244: train Epoch: [16][ 78/193]	Time  8.879 ( 5.025)	Data  8.308 ( 4.451)	Loss 1.6689e-01 (1.2468e-01) 
2023-05-27 08:26:45.819638: train Epoch: [16][ 79/193]	Time  0.564 ( 4.969)	Data  0.001 ( 4.395)	Loss 1.0469e-01 (1.2443e-01) 
2023-05-27 08:26:55.133831: train Epoch: [16][ 80/193]	Time  9.314 ( 5.022)	Data  8.750 ( 4.449)	Loss 5.3487e-02 (1.2355e-01) 
2023-05-27 08:26:55.699826: train Epoch: [16][ 81/193]	Time  0.566 ( 4.968)	Data  0.001 ( 4.395)	Loss 6.6808e-02 (1.2286e-01) 
2023-05-27 08:27:04.954994: train Epoch: [16][ 82/193]	Time  9.255 ( 5.020)	Data  8.690 ( 4.447)	Loss 8.5958e-02 (1.2241e-01) 
2023-05-27 08:27:05.520474: train Epoch: [16][ 83/193]	Time  0.565 ( 4.967)	Data  0.001 ( 4.394)	Loss 1.2866e-01 (1.2249e-01) 
2023-05-27 08:27:15.226717: train Epoch: [16][ 84/193]	Time  9.706 ( 5.023)	Data  9.138 ( 4.449)	Loss 9.2033e-02 (1.2213e-01) 
2023-05-27 08:27:15.803851: train Epoch: [16][ 85/193]	Time  0.577 ( 4.971)	Data  0.001 ( 4.398)	Loss 9.5116e-02 (1.2182e-01) 
2023-05-27 08:27:25.432416: train Epoch: [16][ 86/193]	Time  9.629 ( 5.024)	Data  9.062 ( 4.451)	Loss 8.3773e-02 (1.2138e-01) 
2023-05-27 08:27:26.029525: train Epoch: [16][ 87/193]	Time  0.597 ( 4.974)	Data  0.001 ( 4.401)	Loss 6.0741e-02 (1.2069e-01) 
2023-05-27 08:27:34.986003: train Epoch: [16][ 88/193]	Time  8.956 ( 5.019)	Data  8.380 ( 4.445)	Loss 1.0150e-01 (1.2047e-01) 
2023-05-27 08:27:35.559327: train Epoch: [16][ 89/193]	Time  0.573 ( 4.969)	Data  0.001 ( 4.396)	Loss 8.4790e-02 (1.2008e-01) 
2023-05-27 08:27:43.306728: train Epoch: [16][ 90/193]	Time  7.747 ( 5.000)	Data  7.181 ( 4.427)	Loss 9.5752e-02 (1.1981e-01) 
2023-05-27 08:27:43.879771: train Epoch: [16][ 91/193]	Time  0.573 ( 4.952)	Data  0.001 ( 4.379)	Loss 7.0264e-02 (1.1927e-01) 
2023-05-27 08:27:52.124577: train Epoch: [16][ 92/193]	Time  8.245 ( 4.987)	Data  7.679 ( 4.414)	Loss 7.8377e-02 (1.1883e-01) 
2023-05-27 08:27:52.691593: train Epoch: [16][ 93/193]	Time  0.567 ( 4.940)	Data  0.001 ( 4.367)	Loss 8.7839e-02 (1.1850e-01) 
2023-05-27 08:28:02.192668: train Epoch: [16][ 94/193]	Time  9.501 ( 4.988)	Data  8.935 ( 4.415)	Loss 7.1009e-02 (1.1800e-01) 
2023-05-27 08:28:02.776792: train Epoch: [16][ 95/193]	Time  0.584 ( 4.942)	Data  0.001 ( 4.369)	Loss 7.3490e-02 (1.1754e-01) 
2023-05-27 08:28:11.872788: train Epoch: [16][ 96/193]	Time  9.096 ( 4.985)	Data  8.519 ( 4.412)	Loss 7.0623e-02 (1.1706e-01) 
2023-05-27 08:28:12.442517: train Epoch: [16][ 97/193]	Time  0.570 ( 4.940)	Data  0.001 ( 4.367)	Loss 7.3736e-02 (1.1661e-01) 
2023-05-27 08:28:22.051055: train Epoch: [16][ 98/193]	Time  9.609 ( 4.987)	Data  9.037 ( 4.414)	Loss 8.4931e-02 (1.1629e-01) 
2023-05-27 08:28:22.632897: train Epoch: [16][ 99/193]	Time  0.582 ( 4.943)	Data  0.001 ( 4.370)	Loss 9.2692e-02 (1.1606e-01) 
2023-05-27 08:28:31.953528: train Epoch: [16][100/193]	Time  9.321 ( 4.987)	Data  8.749 ( 4.413)	Loss 2.3751e-01 (1.1726e-01) 
2023-05-27 08:28:32.529819: train Epoch: [16][101/193]	Time  0.576 ( 4.943)	Data  0.001 ( 4.370)	Loss 1.1925e-01 (1.1728e-01) 
2023-05-27 08:28:41.891918: train Epoch: [16][102/193]	Time  9.362 ( 4.986)	Data  8.792 ( 4.413)	Loss 6.6264e-02 (1.1678e-01) 
2023-05-27 08:28:42.467403: train Epoch: [16][103/193]	Time  0.575 ( 4.944)	Data  0.001 ( 4.371)	Loss 7.2007e-02 (1.1635e-01) 
2023-05-27 08:28:51.538459: train Epoch: [16][104/193]	Time  9.071 ( 4.983)	Data  8.508 ( 4.410)	Loss 1.4217e-01 (1.1660e-01) 
2023-05-27 08:28:52.102947: train Epoch: [16][105/193]	Time  0.564 ( 4.941)	Data  0.001 ( 4.368)	Loss 8.8444e-02 (1.1633e-01) 
2023-05-27 08:29:01.316540: train Epoch: [16][106/193]	Time  9.214 ( 4.981)	Data  8.639 ( 4.408)	Loss 9.8864e-02 (1.1617e-01) 
2023-05-27 08:29:01.882117: train Epoch: [16][107/193]	Time  0.566 ( 4.940)	Data  0.001 ( 4.368)	Loss 4.4840e-01 (1.1925e-01) 
2023-05-27 08:29:11.525683: train Epoch: [16][108/193]	Time  9.644 ( 4.984)	Data  9.075 ( 4.411)	Loss 9.8861e-02 (1.1906e-01) 
2023-05-27 08:29:12.105633: train Epoch: [16][109/193]	Time  0.580 ( 4.944)	Data  0.001 ( 4.371)	Loss 7.8478e-02 (1.1869e-01) 
2023-05-27 08:29:21.768102: train Epoch: [16][110/193]	Time  9.662 ( 4.986)	Data  9.089 ( 4.413)	Loss 2.3758e-01 (1.1976e-01) 
2023-05-27 08:29:22.355599: train Epoch: [16][111/193]	Time  0.588 ( 4.947)	Data  0.001 ( 4.374)	Loss 1.2900e-01 (1.1984e-01) 
2023-05-27 08:29:31.773624: train Epoch: [16][112/193]	Time  9.418 ( 4.986)	Data  8.850 ( 4.413)	Loss 1.2652e-01 (1.1990e-01) 
2023-05-27 08:29:32.343397: train Epoch: [16][113/193]	Time  0.570 ( 4.948)	Data  0.001 ( 4.375)	Loss 6.8587e-02 (1.1945e-01) 
2023-05-27 08:29:41.745555: train Epoch: [16][114/193]	Time  9.402 ( 4.986)	Data  8.831 ( 4.413)	Loss 1.7370e-01 (1.1992e-01) 
2023-05-27 08:29:42.332689: train Epoch: [16][115/193]	Time  0.587 ( 4.948)	Data  0.001 ( 4.375)	Loss 1.2167e-01 (1.1994e-01) 
2023-05-27 08:29:51.335011: train Epoch: [16][116/193]	Time  9.002 ( 4.983)	Data  8.435 ( 4.410)	Loss 5.3111e-02 (1.1937e-01) 
2023-05-27 08:29:51.900310: train Epoch: [16][117/193]	Time  0.565 ( 4.946)	Data  0.001 ( 4.373)	Loss 7.9572e-02 (1.1903e-01) 
2023-05-27 08:30:01.556260: train Epoch: [16][118/193]	Time  9.656 ( 4.985)	Data  9.080 ( 4.412)	Loss 1.1459e-01 (1.1899e-01) 
2023-05-27 08:30:02.131379: train Epoch: [16][119/193]	Time  0.575 ( 4.948)	Data  0.001 ( 4.375)	Loss 1.0908e-01 (1.1891e-01) 
2023-05-27 08:30:11.680353: train Epoch: [16][120/193]	Time  9.549 ( 4.987)	Data  8.973 ( 4.413)	Loss 8.5361e-02 (1.1863e-01) 
2023-05-27 08:30:12.316020: train Epoch: [16][121/193]	Time  0.636 ( 4.951)	Data  0.001 ( 4.377)	Loss 2.1733e-01 (1.1944e-01) 
2023-05-27 08:30:22.330879: train Epoch: [16][122/193]	Time 10.015 ( 4.992)	Data  9.438 ( 4.418)	Loss 9.6302e-02 (1.1925e-01) 
2023-05-27 08:30:22.904183: train Epoch: [16][123/193]	Time  0.573 ( 4.956)	Data  0.001 ( 4.383)	Loss 1.0144e-01 (1.1911e-01) 
2023-05-27 08:30:32.302814: train Epoch: [16][124/193]	Time  9.399 ( 4.992)	Data  8.829 ( 4.418)	Loss 8.9819e-02 (1.1888e-01) 
2023-05-27 08:30:32.878655: train Epoch: [16][125/193]	Time  0.576 ( 4.957)	Data  0.001 ( 4.383)	Loss 1.2406e-01 (1.1892e-01) 
2023-05-27 08:30:42.329487: train Epoch: [16][126/193]	Time  9.451 ( 4.992)	Data  8.869 ( 4.419)	Loss 9.5709e-02 (1.1874e-01) 
2023-05-27 08:30:42.904092: train Epoch: [16][127/193]	Time  0.575 ( 4.958)	Data  0.001 ( 4.384)	Loss 9.3626e-02 (1.1854e-01) 
2023-05-27 08:30:51.723005: train Epoch: [16][128/193]	Time  8.819 ( 4.988)	Data  8.241 ( 4.414)	Loss 9.0192e-02 (1.1832e-01) 
2023-05-27 08:30:52.320406: train Epoch: [16][129/193]	Time  0.597 ( 4.954)	Data  0.001 ( 4.380)	Loss 1.0875e-01 (1.1825e-01) 
2023-05-27 08:31:01.387418: train Epoch: [16][130/193]	Time  9.067 ( 4.985)	Data  8.486 ( 4.411)	Loss 1.2948e-01 (1.1833e-01) 
2023-05-27 08:31:01.985317: train Epoch: [16][131/193]	Time  0.598 ( 4.952)	Data  0.001 ( 4.378)	Loss 1.2730e-01 (1.1840e-01) 
2023-05-27 08:31:11.641480: train Epoch: [16][132/193]	Time  9.656 ( 4.987)	Data  9.084 ( 4.413)	Loss 1.5796e-01 (1.1870e-01) 
2023-05-27 08:31:12.246201: train Epoch: [16][133/193]	Time  0.605 ( 4.955)	Data  0.001 ( 4.380)	Loss 1.3427e-01 (1.1881e-01) 
2023-05-27 08:31:21.721803: train Epoch: [16][134/193]	Time  9.476 ( 4.988)	Data  8.910 ( 4.414)	Loss 1.0704e-01 (1.1873e-01) 
2023-05-27 08:31:22.323109: train Epoch: [16][135/193]	Time  0.601 ( 4.956)	Data  0.001 ( 4.382)	Loss 1.0282e-01 (1.1861e-01) 
2023-05-27 08:31:31.638441: train Epoch: [16][136/193]	Time  9.315 ( 4.988)	Data  8.738 ( 4.413)	Loss 1.1781e-01 (1.1860e-01) 
2023-05-27 08:31:32.218538: train Epoch: [16][137/193]	Time  0.580 ( 4.956)	Data  0.001 ( 4.381)	Loss 8.2461e-02 (1.1834e-01) 
2023-05-27 08:31:41.274011: train Epoch: [16][138/193]	Time  9.055 ( 4.985)	Data  8.482 ( 4.411)	Loss 1.0685e-01 (1.1826e-01) 
2023-05-27 08:31:41.839727: train Epoch: [16][139/193]	Time  0.566 ( 4.954)	Data  0.001 ( 4.379)	Loss 7.6668e-02 (1.1796e-01) 
2023-05-27 08:31:51.057667: train Epoch: [16][140/193]	Time  9.218 ( 4.984)	Data  8.652 ( 4.410)	Loss 1.0513e-01 (1.1787e-01) 
2023-05-27 08:31:51.631587: train Epoch: [16][141/193]	Time  0.574 ( 4.953)	Data  0.001 ( 4.379)	Loss 7.1080e-02 (1.1754e-01) 
2023-05-27 08:32:00.818253: train Epoch: [16][142/193]	Time  9.187 ( 4.983)	Data  8.620 ( 4.408)	Loss 1.2869e-01 (1.1762e-01) 
2023-05-27 08:32:01.408645: train Epoch: [16][143/193]	Time  0.590 ( 4.952)	Data  0.001 ( 4.378)	Loss 1.5939e-01 (1.1791e-01) 
2023-05-27 08:32:10.875811: train Epoch: [16][144/193]	Time  9.467 ( 4.983)	Data  8.891 ( 4.409)	Loss 1.3426e-01 (1.1802e-01) 
2023-05-27 08:32:11.444535: train Epoch: [16][145/193]	Time  0.569 ( 4.953)	Data  0.001 ( 4.379)	Loss 8.2650e-02 (1.1778e-01) 
2023-05-27 08:32:20.536948: train Epoch: [16][146/193]	Time  9.092 ( 4.981)	Data  8.515 ( 4.407)	Loss 7.5846e-02 (1.1749e-01) 
2023-05-27 08:32:21.110889: train Epoch: [16][147/193]	Time  0.574 ( 4.951)	Data  0.001 ( 4.377)	Loss 1.1989e-01 (1.1751e-01) 
2023-05-27 08:32:30.031562: train Epoch: [16][148/193]	Time  8.921 ( 4.978)	Data  8.358 ( 4.404)	Loss 1.3991e-01 (1.1766e-01) 
2023-05-27 08:32:30.594559: train Epoch: [16][149/193]	Time  0.563 ( 4.949)	Data  0.001 ( 4.374)	Loss 7.9123e-02 (1.1740e-01) 
2023-05-27 08:32:39.655983: train Epoch: [16][150/193]	Time  9.061 ( 4.976)	Data  8.499 ( 4.402)	Loss 8.2948e-02 (1.1718e-01) 
2023-05-27 08:32:40.220442: train Epoch: [16][151/193]	Time  0.564 ( 4.947)	Data  0.001 ( 4.373)	Loss 1.2188e-01 (1.1721e-01) 
2023-05-27 08:32:49.995988: train Epoch: [16][152/193]	Time  9.776 ( 4.978)	Data  9.213 ( 4.404)	Loss 8.5822e-02 (1.1700e-01) 
2023-05-27 08:32:50.559827: train Epoch: [16][153/193]	Time  0.564 ( 4.950)	Data  0.001 ( 4.376)	Loss 9.6361e-02 (1.1687e-01) 
2023-05-27 08:33:00.501587: train Epoch: [16][154/193]	Time  9.942 ( 4.982)	Data  9.372 ( 4.408)	Loss 5.8286e-02 (1.1649e-01) 
2023-05-27 08:33:01.081763: train Epoch: [16][155/193]	Time  0.580 ( 4.954)	Data  0.001 ( 4.380)	Loss 9.2456e-02 (1.1634e-01) 
2023-05-27 08:33:10.568418: train Epoch: [16][156/193]	Time  9.487 ( 4.983)	Data  8.899 ( 4.409)	Loss 1.2643e-01 (1.1640e-01) 
2023-05-27 08:33:11.160079: train Epoch: [16][157/193]	Time  0.592 ( 4.955)	Data  0.001 ( 4.381)	Loss 6.7112e-02 (1.1609e-01) 
2023-05-27 08:33:21.176489: train Epoch: [16][158/193]	Time 10.016 ( 4.987)	Data  9.434 ( 4.412)	Loss 8.6092e-02 (1.1590e-01) 
2023-05-27 08:33:21.780922: train Epoch: [16][159/193]	Time  0.604 ( 4.959)	Data  0.001 ( 4.385)	Loss 7.3085e-02 (1.1563e-01) 
2023-05-27 08:33:31.198266: train Epoch: [16][160/193]	Time  9.417 ( 4.987)	Data  8.844 ( 4.413)	Loss 5.8180e-02 (1.1527e-01) 
2023-05-27 08:33:31.795274: train Epoch: [16][161/193]	Time  0.597 ( 4.960)	Data  0.001 ( 4.385)	Loss 2.6276e-01 (1.1618e-01) 
2023-05-27 08:33:41.367011: train Epoch: [16][162/193]	Time  9.572 ( 4.988)	Data  8.998 ( 4.414)	Loss 9.3878e-02 (1.1605e-01) 
2023-05-27 08:33:41.968486: train Epoch: [16][163/193]	Time  0.601 ( 4.961)	Data  0.001 ( 4.387)	Loss 7.1174e-02 (1.1577e-01) 
2023-05-27 08:33:51.073663: train Epoch: [16][164/193]	Time  9.105 ( 4.986)	Data  8.493 ( 4.412)	Loss 8.9681e-02 (1.1562e-01) 
2023-05-27 08:33:51.646552: train Epoch: [16][165/193]	Time  0.573 ( 4.960)	Data  0.001 ( 4.385)	Loss 1.7849e-01 (1.1600e-01) 
2023-05-27 08:34:00.903201: train Epoch: [16][166/193]	Time  9.257 ( 4.986)	Data  8.678 ( 4.411)	Loss 5.6094e-02 (1.1564e-01) 
2023-05-27 08:34:01.480235: train Epoch: [16][167/193]	Time  0.577 ( 4.959)	Data  0.001 ( 4.384)	Loss 4.7953e-02 (1.1523e-01) 
2023-05-27 08:34:10.709522: train Epoch: [16][168/193]	Time  9.229 ( 4.985)	Data  8.629 ( 4.410)	Loss 2.7586e-01 (1.1618e-01) 
2023-05-27 08:34:11.277302: train Epoch: [16][169/193]	Time  0.568 ( 4.959)	Data  0.001 ( 4.384)	Loss 9.9156e-02 (1.1608e-01) 
2023-05-27 08:34:20.682789: train Epoch: [16][170/193]	Time  9.405 ( 4.985)	Data  8.826 ( 4.410)	Loss 1.6267e-01 (1.1636e-01) 
2023-05-27 08:34:21.250515: train Epoch: [16][171/193]	Time  0.568 ( 4.959)	Data  0.001 ( 4.384)	Loss 1.4680e-01 (1.1653e-01) 
2023-05-27 08:34:30.235905: train Epoch: [16][172/193]	Time  8.985 ( 4.982)	Data  8.411 ( 4.407)	Loss 7.5446e-02 (1.1630e-01) 
2023-05-27 08:34:30.807451: train Epoch: [16][173/193]	Time  0.572 ( 4.957)	Data  0.001 ( 4.382)	Loss 9.2898e-02 (1.1616e-01) 
2023-05-27 08:34:40.156240: train Epoch: [16][174/193]	Time  9.349 ( 4.982)	Data  8.764 ( 4.407)	Loss 1.4182e-01 (1.1631e-01) 
2023-05-27 08:34:40.726840: train Epoch: [16][175/193]	Time  0.571 ( 4.957)	Data  0.001 ( 4.382)	Loss 8.3610e-02 (1.1612e-01) 
2023-05-27 08:34:50.036647: train Epoch: [16][176/193]	Time  9.310 ( 4.981)	Data  8.735 ( 4.407)	Loss 1.4025e-01 (1.1626e-01) 
2023-05-27 08:34:50.620644: train Epoch: [16][177/193]	Time  0.584 ( 4.957)	Data  0.001 ( 4.382)	Loss 9.0566e-02 (1.1611e-01) 
2023-05-27 08:35:00.233822: train Epoch: [16][178/193]	Time  9.613 ( 4.983)	Data  9.030 ( 4.408)	Loss 1.6998e-01 (1.1642e-01) 
2023-05-27 08:35:00.824096: train Epoch: [16][179/193]	Time  0.590 ( 4.958)	Data  0.001 ( 4.383)	Loss 1.0595e-01 (1.1636e-01) 
2023-05-27 08:35:10.083810: train Epoch: [16][180/193]	Time  9.260 ( 4.982)	Data  8.687 ( 4.407)	Loss 1.0887e-01 (1.1632e-01) 
2023-05-27 08:35:10.648133: train Epoch: [16][181/193]	Time  0.564 ( 4.958)	Data  0.001 ( 4.383)	Loss 1.4785e-01 (1.1649e-01) 
2023-05-27 08:35:20.304622: train Epoch: [16][182/193]	Time  9.656 ( 4.984)	Data  9.093 ( 4.409)	Loss 9.4028e-02 (1.1637e-01) 
2023-05-27 08:35:20.877614: train Epoch: [16][183/193]	Time  0.573 ( 4.960)	Data  0.001 ( 4.385)	Loss 1.3054e-01 (1.1644e-01) 
2023-05-27 08:35:30.294305: train Epoch: [16][184/193]	Time  9.417 ( 4.984)	Data  8.848 ( 4.409)	Loss 7.6055e-02 (1.1622e-01) 
2023-05-27 08:35:30.859885: train Epoch: [16][185/193]	Time  0.566 ( 4.960)	Data  0.001 ( 4.385)	Loss 1.2706e-01 (1.1628e-01) 
2023-05-27 08:35:40.447417: train Epoch: [16][186/193]	Time  9.588 ( 4.985)	Data  9.014 ( 4.410)	Loss 6.7489e-02 (1.1602e-01) 
2023-05-27 08:35:41.040674: train Epoch: [16][187/193]	Time  0.593 ( 4.961)	Data  0.001 ( 4.386)	Loss 2.2048e-01 (1.1658e-01) 
2023-05-27 08:35:50.575044: train Epoch: [16][188/193]	Time  9.534 ( 4.986)	Data  8.968 ( 4.411)	Loss 1.3389e-01 (1.1667e-01) 
2023-05-27 08:35:51.152987: train Epoch: [16][189/193]	Time  0.578 ( 4.962)	Data  0.001 ( 4.387)	Loss 1.4174e-01 (1.1680e-01) 
2023-05-27 08:35:59.850793: train Epoch: [16][190/193]	Time  8.698 ( 4.982)	Data  8.129 ( 4.407)	Loss 1.2284e-01 (1.1683e-01) 
2023-05-27 08:36:00.424990: train Epoch: [16][191/193]	Time  0.574 ( 4.959)	Data  0.001 ( 4.384)	Loss 1.4374e-01 (1.1697e-01) 
2023-05-27 08:36:08.334421: train Epoch: [16][192/193]	Time  7.909 ( 4.974)	Data  7.336 ( 4.399)	Loss 7.1196e-02 (1.1674e-01) 
2023-05-27 08:36:08.499896: Train Epoch done in 960.1869890649978 s 
2023-05-27 08:36:15.089446: val Epoch: [16][ 0/72]	Time  5.797 ( 5.797)	Data  5.642 ( 5.642)	Loss 3.8393e-01 (3.8393e-01) 
2023-05-27 08:36:15.199824: val Epoch: [16][ 1/72]	Time  0.111 ( 2.954)	Data  0.001 ( 2.821)	Loss 1.2811e-01 (2.5602e-01) 
2023-05-27 08:36:19.913520: val Epoch: [16][ 2/72]	Time  4.714 ( 3.541)	Data  4.588 ( 3.410)	Loss 7.4183e-02 (1.9541e-01) 
2023-05-27 08:36:20.197884: val Epoch: [16][ 3/72]	Time  0.284 ( 2.726)	Data  0.177 ( 2.602)	Loss 1.3404e-01 (1.8007e-01) 
2023-05-27 08:36:25.176641: val Epoch: [16][ 4/72]	Time  4.979 ( 3.177)	Data  4.871 ( 3.056)	Loss 1.2318e-01 (1.6869e-01) 
2023-05-27 08:36:25.285247: val Epoch: [16][ 5/72]	Time  0.109 ( 2.666)	Data  0.000 ( 2.546)	Loss 6.0385e-02 (1.5064e-01) 
2023-05-27 08:36:30.110816: val Epoch: [16][ 6/72]	Time  4.826 ( 2.974)	Data  4.694 ( 2.853)	Loss 5.1077e-02 (1.3642e-01) 
2023-05-27 08:36:30.219879: val Epoch: [16][ 7/72]	Time  0.109 ( 2.616)	Data  0.001 ( 2.497)	Loss 2.1647e-01 (1.4642e-01) 
2023-05-27 08:36:35.071782: val Epoch: [16][ 8/72]	Time  4.852 ( 2.864)	Data  4.747 ( 2.747)	Loss 7.9947e-02 (1.3904e-01) 
2023-05-27 08:36:35.226529: val Epoch: [16][ 9/72]	Time  0.155 ( 2.593)	Data  0.048 ( 2.477)	Loss 1.2527e-01 (1.3766e-01) 
2023-05-27 08:36:40.033914: val Epoch: [16][10/72]	Time  4.807 ( 2.795)	Data  4.702 ( 2.679)	Loss 5.0791e-02 (1.2976e-01) 
2023-05-27 08:36:40.426369: val Epoch: [16][11/72]	Time  0.392 ( 2.595)	Data  0.286 ( 2.480)	Loss 1.5662e-01 (1.3200e-01) 
2023-05-27 08:36:45.285314: val Epoch: [16][12/72]	Time  4.859 ( 2.769)	Data  4.754 ( 2.655)	Loss 6.4833e-01 (1.7172e-01) 
2023-05-27 08:36:45.574516: val Epoch: [16][13/72]	Time  0.289 ( 2.592)	Data  0.143 ( 2.475)	Loss 4.6213e-02 (1.6275e-01) 
2023-05-27 08:36:50.272684: val Epoch: [16][14/72]	Time  4.698 ( 2.732)	Data  4.593 ( 2.616)	Loss 9.1412e-02 (1.5800e-01) 
2023-05-27 08:36:50.544762: val Epoch: [16][15/72]	Time  0.272 ( 2.578)	Data  0.163 ( 2.463)	Loss 1.9647e-01 (1.6040e-01) 
2023-05-27 08:36:55.519152: val Epoch: [16][16/72]	Time  4.974 ( 2.719)	Data  4.865 ( 2.604)	Loss 8.9574e-02 (1.5624e-01) 
2023-05-27 08:36:55.626580: val Epoch: [16][17/72]	Time  0.107 ( 2.574)	Data  0.001 ( 2.460)	Loss 1.2877e-01 (1.5471e-01) 
2023-05-27 08:37:00.261185: val Epoch: [16][18/72]	Time  4.635 ( 2.683)	Data  4.509 ( 2.568)	Loss 1.0645e-01 (1.5217e-01) 
2023-05-27 08:37:00.668997: val Epoch: [16][19/72]	Time  0.408 ( 2.569)	Data  0.298 ( 2.454)	Loss 6.9268e-02 (1.4803e-01) 
2023-05-27 08:37:05.356282: val Epoch: [16][20/72]	Time  4.687 ( 2.670)	Data  4.577 ( 2.555)	Loss 4.8681e-02 (1.4329e-01) 
2023-05-27 08:37:05.543105: val Epoch: [16][21/72]	Time  0.187 ( 2.557)	Data  0.083 ( 2.443)	Loss 8.5279e-02 (1.4066e-01) 
2023-05-27 08:37:10.372910: val Epoch: [16][22/72]	Time  4.830 ( 2.656)	Data  4.725 ( 2.542)	Loss 4.3953e-01 (1.5365e-01) 
2023-05-27 08:37:10.700863: val Epoch: [16][23/72]	Time  0.328 ( 2.559)	Data  0.223 ( 2.445)	Loss 1.0086e-01 (1.5145e-01) 
2023-05-27 08:37:15.511208: val Epoch: [16][24/72]	Time  4.810 ( 2.649)	Data  4.705 ( 2.536)	Loss 5.2106e-01 (1.6624e-01) 
2023-05-27 08:37:15.885303: val Epoch: [16][25/72]	Time  0.374 ( 2.561)	Data  0.269 ( 2.449)	Loss 1.5758e-01 (1.6590e-01) 
2023-05-27 08:37:20.432060: val Epoch: [16][26/72]	Time  4.547 ( 2.635)	Data  4.441 ( 2.522)	Loss 2.1499e-01 (1.6772e-01) 
2023-05-27 08:37:20.878395: val Epoch: [16][27/72]	Time  0.446 ( 2.557)	Data  0.339 ( 2.444)	Loss 2.5556e-01 (1.7086e-01) 
2023-05-27 08:37:25.271772: val Epoch: [16][28/72]	Time  4.393 ( 2.620)	Data  4.286 ( 2.508)	Loss 4.7092e-02 (1.6659e-01) 
2023-05-27 08:37:25.686937: val Epoch: [16][29/72]	Time  0.415 ( 2.546)	Data  0.310 ( 2.435)	Loss 7.2534e-02 (1.6346e-01) 
2023-05-27 08:37:30.480367: val Epoch: [16][30/72]	Time  4.793 ( 2.619)	Data  4.688 ( 2.507)	Loss 1.1394e-01 (1.6186e-01) 
2023-05-27 08:37:30.996698: val Epoch: [16][31/72]	Time  0.516 ( 2.553)	Data  0.409 ( 2.442)	Loss 6.2912e-02 (1.5877e-01) 
2023-05-27 08:37:35.571254: val Epoch: [16][32/72]	Time  4.575 ( 2.615)	Data  4.470 ( 2.503)	Loss 4.4337e-01 (1.6739e-01) 
2023-05-27 08:37:36.077851: val Epoch: [16][33/72]	Time  0.507 ( 2.553)	Data  0.401 ( 2.441)	Loss 8.2873e-02 (1.6491e-01) 
2023-05-27 08:37:40.729931: val Epoch: [16][34/72]	Time  4.652 ( 2.613)	Data  4.547 ( 2.502)	Loss 6.5867e-02 (1.6208e-01) 
2023-05-27 08:37:41.072491: val Epoch: [16][35/72]	Time  0.343 ( 2.549)	Data  0.237 ( 2.439)	Loss 8.6107e-02 (1.5997e-01) 
2023-05-27 08:37:45.695594: val Epoch: [16][36/72]	Time  4.623 ( 2.606)	Data  4.514 ( 2.495)	Loss 9.6919e-02 (1.5826e-01) 
2023-05-27 08:37:46.456813: val Epoch: [16][37/72]	Time  0.761 ( 2.557)	Data  0.655 ( 2.446)	Loss 1.9028e-01 (1.5910e-01) 
2023-05-27 08:37:50.550964: val Epoch: [16][38/72]	Time  4.094 ( 2.596)	Data  3.988 ( 2.486)	Loss 1.6433e-01 (1.5924e-01) 
2023-05-27 08:37:51.421688: val Epoch: [16][39/72]	Time  0.871 ( 2.553)	Data  0.732 ( 2.442)	Loss 7.2897e-02 (1.5708e-01) 
2023-05-27 08:37:55.901567: val Epoch: [16][40/72]	Time  4.480 ( 2.600)	Data  4.372 ( 2.489)	Loss 3.4962e-01 (1.6178e-01) 
2023-05-27 08:37:56.588109: val Epoch: [16][41/72]	Time  0.687 ( 2.555)	Data  0.579 ( 2.444)	Loss 6.2680e-02 (1.5942e-01) 
2023-05-27 08:38:00.978998: val Epoch: [16][42/72]	Time  4.391 ( 2.597)	Data  4.280 ( 2.486)	Loss 8.2945e-02 (1.5764e-01) 
2023-05-27 08:38:01.848109: val Epoch: [16][43/72]	Time  0.869 ( 2.558)	Data  0.762 ( 2.447)	Loss 1.8031e-01 (1.5815e-01) 
2023-05-27 08:38:05.878957: val Epoch: [16][44/72]	Time  4.031 ( 2.591)	Data  3.923 ( 2.480)	Loss 9.6766e-02 (1.5679e-01) 
2023-05-27 08:38:06.801098: val Epoch: [16][45/72]	Time  0.922 ( 2.555)	Data  0.815 ( 2.444)	Loss 1.0275e-01 (1.5561e-01) 
2023-05-27 08:38:10.836924: val Epoch: [16][46/72]	Time  4.036 ( 2.586)	Data  3.928 ( 2.475)	Loss 1.3636e-01 (1.5520e-01) 
2023-05-27 08:38:11.925700: val Epoch: [16][47/72]	Time  1.089 ( 2.555)	Data  0.927 ( 2.443)	Loss 4.9023e-02 (1.5299e-01) 
2023-05-27 08:38:15.723798: val Epoch: [16][48/72]	Time  3.798 ( 2.580)	Data  3.690 ( 2.468)	Loss 5.6836e-02 (1.5103e-01) 
2023-05-27 08:38:17.081651: val Epoch: [16][49/72]	Time  1.358 ( 2.556)	Data  1.226 ( 2.444)	Loss 3.0966e-01 (1.5420e-01) 
2023-05-27 08:38:20.829700: val Epoch: [16][50/72]	Time  3.748 ( 2.579)	Data  3.632 ( 2.467)	Loss 9.0196e-02 (1.5295e-01) 
2023-05-27 08:38:21.883308: val Epoch: [16][51/72]	Time  1.054 ( 2.550)	Data  0.936 ( 2.437)	Loss 1.0543e-01 (1.5203e-01) 
2023-05-27 08:38:25.812984: val Epoch: [16][52/72]	Time  3.930 ( 2.576)	Data  3.822 ( 2.464)	Loss 1.2447e-01 (1.5151e-01) 
2023-05-27 08:38:26.742705: val Epoch: [16][53/72]	Time  0.930 ( 2.545)	Data  0.802 ( 2.433)	Loss 6.3601e-02 (1.4989e-01) 
2023-05-27 08:38:30.783477: val Epoch: [16][54/72]	Time  4.041 ( 2.573)	Data  3.928 ( 2.460)	Loss 1.5543e-01 (1.4999e-01) 
2023-05-27 08:38:31.581094: val Epoch: [16][55/72]	Time  0.798 ( 2.541)	Data  0.689 ( 2.428)	Loss 9.9854e-02 (1.4909e-01) 
2023-05-27 08:38:35.962826: val Epoch: [16][56/72]	Time  4.382 ( 2.573)	Data  4.277 ( 2.461)	Loss 1.2386e-01 (1.4865e-01) 
2023-05-27 08:38:36.602264: val Epoch: [16][57/72]	Time  0.639 ( 2.540)	Data  0.525 ( 2.427)	Loss 4.2436e-01 (1.5340e-01) 
2023-05-27 08:38:40.817718: val Epoch: [16][58/72]	Time  4.215 ( 2.568)	Data  4.110 ( 2.456)	Loss 7.2851e-02 (1.5204e-01) 
2023-05-27 08:38:41.541257: val Epoch: [16][59/72]	Time  0.724 ( 2.537)	Data  0.608 ( 2.425)	Loss 1.0379e-01 (1.5123e-01) 
2023-05-27 08:38:45.770158: val Epoch: [16][60/72]	Time  4.229 ( 2.565)	Data  4.123 ( 2.453)	Loss 3.2053e-01 (1.5401e-01) 
2023-05-27 08:38:46.854589: val Epoch: [16][61/72]	Time  1.084 ( 2.541)	Data  0.969 ( 2.429)	Loss 1.7611e-01 (1.5436e-01) 
2023-05-27 08:38:50.625059: val Epoch: [16][62/72]	Time  3.770 ( 2.561)	Data  3.663 ( 2.449)	Loss 6.2674e-02 (1.5291e-01) 
2023-05-27 08:38:52.014470: val Epoch: [16][63/72]	Time  1.389 ( 2.543)	Data  1.236 ( 2.430)	Loss 7.0954e-02 (1.5163e-01) 
2023-05-27 08:38:55.932543: val Epoch: [16][64/72]	Time  3.918 ( 2.564)	Data  3.807 ( 2.451)	Loss 1.2507e-01 (1.5122e-01) 
2023-05-27 08:38:57.179271: val Epoch: [16][65/72]	Time  1.247 ( 2.544)	Data  1.107 ( 2.431)	Loss 1.3124e-01 (1.5092e-01) 
2023-05-27 08:39:01.038246: val Epoch: [16][66/72]	Time  3.859 ( 2.563)	Data  3.746 ( 2.450)	Loss 7.3024e-02 (1.4975e-01) 
2023-05-27 08:39:02.243082: val Epoch: [16][67/72]	Time  1.205 ( 2.543)	Data  1.090 ( 2.430)	Loss 8.3937e-02 (1.4879e-01) 
2023-05-27 08:39:05.870815: val Epoch: [16][68/72]	Time  3.628 ( 2.559)	Data  3.519 ( 2.446)	Loss 7.6814e-02 (1.4774e-01) 
2023-05-27 08:39:07.030983: val Epoch: [16][69/72]	Time  1.160 ( 2.539)	Data  1.047 ( 2.426)	Loss 6.1347e-02 (1.4651e-01) 
2023-05-27 08:39:10.589369: val Epoch: [16][70/72]	Time  3.558 ( 2.553)	Data  3.450 ( 2.440)	Loss 6.5403e-02 (1.4537e-01) 
2023-05-27 08:39:11.857080: val Epoch: [16][71/72]	Time  1.268 ( 2.536)	Data  1.156 ( 2.423)	Loss 3.6887e-01 (1.4847e-01) 
2023-05-27 08:39:12.191534: Epoch 16 :Val : ['ET : 0.6951099038124084', 'TC : 0.7535468935966492', 'WT : 0.835079550743103'] 
2023-05-27 08:39:12.192083: Epoch 16 :Val : ['ET : 0.6951099038124084', 'TC : 0.7535468935966492', 'WT : 0.835079550743103'] 
2023-05-27 08:39:12.195097: Saving the model with DSC 0.7702686786651611 
2023-05-27 08:39:13.069823: Val epoch done in 184.56991940899752 s 
2023-05-27 08:39:13.111407: Batches per epoch:  193 
2023-05-27 08:39:24.098480: train Epoch: [17][  0/193]	Time 10.987 (10.987)	Data 10.318 (10.318)	Loss 1.1195e-01 (1.1195e-01) 
2023-05-27 08:39:24.663871: train Epoch: [17][  1/193]	Time  0.565 ( 5.776)	Data  0.001 ( 5.160)	Loss 1.0964e-01 (1.1080e-01) 
2023-05-27 08:39:33.989275: train Epoch: [17][  2/193]	Time  9.325 ( 6.959)	Data  8.759 ( 6.359)	Loss 9.0353e-02 (1.0398e-01) 
2023-05-27 08:39:34.611444: train Epoch: [17][  3/193]	Time  0.622 ( 5.375)	Data  0.001 ( 4.770)	Loss 6.1336e-02 (9.3320e-02) 
2023-05-27 08:39:43.935863: train Epoch: [17][  4/193]	Time  9.324 ( 6.165)	Data  8.746 ( 5.565)	Loss 5.8635e-02 (8.6383e-02) 
2023-05-27 08:39:44.533309: train Epoch: [17][  5/193]	Time  0.597 ( 5.237)	Data  0.001 ( 4.638)	Loss 9.3688e-02 (8.7601e-02) 
2023-05-27 08:39:53.875337: train Epoch: [17][  6/193]	Time  9.342 ( 5.823)	Data  8.770 ( 5.228)	Loss 2.2992e-01 (1.0793e-01) 
2023-05-27 08:39:54.448640: train Epoch: [17][  7/193]	Time  0.573 ( 5.167)	Data  0.001 ( 4.575)	Loss 5.9389e-02 (1.0186e-01) 
2023-05-27 08:40:03.832960: train Epoch: [17][  8/193]	Time  9.384 ( 5.636)	Data  8.807 ( 5.045)	Loss 1.1335e-01 (1.0314e-01) 
2023-05-27 08:40:04.407910: train Epoch: [17][  9/193]	Time  0.575 ( 5.130)	Data  0.001 ( 4.541)	Loss 1.4680e-01 (1.0751e-01) 
2023-05-27 08:40:13.613642: train Epoch: [17][ 10/193]	Time  9.206 ( 5.500)	Data  8.637 ( 4.913)	Loss 9.7545e-02 (1.0660e-01) 
2023-05-27 08:40:14.256741: train Epoch: [17][ 11/193]	Time  0.643 ( 5.095)	Data  0.063 ( 4.509)	Loss 7.4226e-02 (1.0390e-01) 
2023-05-27 08:40:23.726172: train Epoch: [17][ 12/193]	Time  9.469 ( 5.432)	Data  8.900 ( 4.847)	Loss 1.2887e-01 (1.0582e-01) 
2023-05-27 08:40:24.299840: train Epoch: [17][ 13/193]	Time  0.574 ( 5.085)	Data  0.001 ( 4.500)	Loss 5.0045e-02 (1.0184e-01) 
2023-05-27 08:40:33.802887: train Epoch: [17][ 14/193]	Time  9.503 ( 5.379)	Data  8.933 ( 4.796)	Loss 1.0862e-01 (1.0229e-01) 
2023-05-27 08:40:34.373427: train Epoch: [17][ 15/193]	Time  0.571 ( 5.079)	Data  0.001 ( 4.496)	Loss 9.1737e-02 (1.0163e-01) 
2023-05-27 08:40:43.694200: train Epoch: [17][ 16/193]	Time  9.321 ( 5.328)	Data  8.751 ( 4.746)	Loss 8.9465e-02 (1.0092e-01) 
2023-05-27 08:40:44.641989: train Epoch: [17][ 17/193]	Time  0.948 ( 5.085)	Data  0.377 ( 4.504)	Loss 1.0252e-01 (1.0100e-01) 
2023-05-27 08:40:53.338625: train Epoch: [17][ 18/193]	Time  8.697 ( 5.275)	Data  8.118 ( 4.694)	Loss 8.0849e-02 (9.9944e-02) 
2023-05-27 08:40:54.497199: train Epoch: [17][ 19/193]	Time  1.159 ( 5.069)	Data  0.588 ( 4.489)	Loss 9.4720e-02 (9.9683e-02) 
2023-05-27 08:41:02.006038: train Epoch: [17][ 20/193]	Time  7.509 ( 5.185)	Data  6.938 ( 4.605)	Loss 5.7644e-02 (9.7681e-02) 
2023-05-27 08:41:03.207073: train Epoch: [17][ 21/193]	Time  1.201 ( 5.004)	Data  0.629 ( 4.425)	Loss 5.9450e-02 (9.5943e-02) 
2023-05-27 08:41:11.518238: train Epoch: [17][ 22/193]	Time  8.311 ( 5.148)	Data  7.740 ( 4.569)	Loss 1.1876e-01 (9.6935e-02) 
2023-05-27 08:41:13.638638: train Epoch: [17][ 23/193]	Time  2.120 ( 5.022)	Data  1.551 ( 4.443)	Loss 6.9362e-02 (9.5786e-02) 
2023-05-27 08:41:21.775185: train Epoch: [17][ 24/193]	Time  8.137 ( 5.147)	Data  7.563 ( 4.568)	Loss 1.0511e-01 (9.6159e-02) 
2023-05-27 08:41:23.603980: train Epoch: [17][ 25/193]	Time  1.829 ( 5.019)	Data  1.259 ( 4.441)	Loss 8.3742e-02 (9.5681e-02) 
2023-05-27 08:41:31.234179: train Epoch: [17][ 26/193]	Time  7.630 ( 5.116)	Data  7.060 ( 4.538)	Loss 7.0477e-02 (9.4748e-02) 
2023-05-27 08:41:34.148182: train Epoch: [17][ 27/193]	Time  2.914 ( 5.037)	Data  2.347 ( 4.459)	Loss 8.8736e-02 (9.4533e-02) 
2023-05-27 08:41:41.225792: train Epoch: [17][ 28/193]	Time  7.078 ( 5.107)	Data  6.504 ( 4.530)	Loss 7.6759e-02 (9.3920e-02) 
2023-05-27 08:41:44.103806: train Epoch: [17][ 29/193]	Time  2.878 ( 5.033)	Data  2.316 ( 4.456)	Loss 8.7604e-02 (9.3710e-02) 
2023-05-27 08:41:51.135923: train Epoch: [17][ 30/193]	Time  7.032 ( 5.098)	Data  6.466 ( 4.521)	Loss 1.0982e-01 (9.4229e-02) 
2023-05-27 08:41:53.937160: train Epoch: [17][ 31/193]	Time  2.801 ( 5.026)	Data  2.236 ( 4.449)	Loss 1.6227e-01 (9.6356e-02) 
2023-05-27 08:42:00.515350: train Epoch: [17][ 32/193]	Time  6.578 ( 5.073)	Data  6.011 ( 4.497)	Loss 4.7462e-02 (9.4874e-02) 
2023-05-27 08:42:03.786859: train Epoch: [17][ 33/193]	Time  3.272 ( 5.020)	Data  2.708 ( 4.444)	Loss 1.1016e-01 (9.5324e-02) 
2023-05-27 08:42:10.162751: train Epoch: [17][ 34/193]	Time  6.376 ( 5.059)	Data  5.813 ( 4.483)	Loss 8.7629e-02 (9.5104e-02) 
2023-05-27 08:42:13.711862: train Epoch: [17][ 35/193]	Time  3.549 ( 5.017)	Data  2.984 ( 4.442)	Loss 2.7717e-01 (1.0016e-01) 
2023-05-27 08:42:19.806206: train Epoch: [17][ 36/193]	Time  6.094 ( 5.046)	Data  5.532 ( 4.471)	Loss 1.2697e-01 (1.0089e-01) 
2023-05-27 08:42:23.830956: train Epoch: [17][ 37/193]	Time  4.025 ( 5.019)	Data  3.451 ( 4.444)	Loss 1.2942e-01 (1.0164e-01) 
2023-05-27 08:42:29.087465: train Epoch: [17][ 38/193]	Time  5.257 ( 5.025)	Data  4.693 ( 4.451)	Loss 9.7747e-02 (1.0154e-01) 
2023-05-27 08:42:32.292163: train Epoch: [17][ 39/193]	Time  3.205 ( 4.980)	Data  2.641 ( 4.405)	Loss 1.2645e-01 (1.0216e-01) 
2023-05-27 08:42:37.683197: train Epoch: [17][ 40/193]	Time  5.391 ( 4.990)	Data  4.828 ( 4.416)	Loss 5.6177e-02 (1.0104e-01) 
2023-05-27 08:42:41.460345: train Epoch: [17][ 41/193]	Time  3.777 ( 4.961)	Data  3.214 ( 4.387)	Loss 1.0877e-01 (1.0122e-01) 
2023-05-27 08:42:47.661798: train Epoch: [17][ 42/193]	Time  6.201 ( 4.990)	Data  5.625 ( 4.416)	Loss 7.1756e-02 (1.0054e-01) 
2023-05-27 08:42:51.255229: train Epoch: [17][ 43/193]	Time  3.593 ( 4.958)	Data  3.030 ( 4.384)	Loss 9.3516e-02 (1.0038e-01) 
2023-05-27 08:42:57.702485: train Epoch: [17][ 44/193]	Time  6.447 ( 4.991)	Data  5.875 ( 4.417)	Loss 8.4450e-02 (1.0002e-01) 
2023-05-27 08:43:00.944826: train Epoch: [17][ 45/193]	Time  3.242 ( 4.953)	Data  2.672 ( 4.380)	Loss 1.2416e-01 (1.0055e-01) 
2023-05-27 08:43:07.651841: train Epoch: [17][ 46/193]	Time  6.707 ( 4.990)	Data  6.136 ( 4.417)	Loss 9.7879e-02 (1.0049e-01) 
2023-05-27 08:43:10.542684: train Epoch: [17][ 47/193]	Time  2.891 ( 4.946)	Data  2.322 ( 4.373)	Loss 8.9535e-02 (1.0026e-01) 
2023-05-27 08:43:17.828646: train Epoch: [17][ 48/193]	Time  7.286 ( 4.994)	Data  6.712 ( 4.421)	Loss 9.4213e-02 (1.0014e-01) 
2023-05-27 08:43:20.090314: train Epoch: [17][ 49/193]	Time  2.262 ( 4.940)	Data  1.696 ( 4.366)	Loss 8.1757e-02 (9.9772e-02) 
2023-05-27 08:43:27.406860: train Epoch: [17][ 50/193]	Time  7.317 ( 4.986)	Data  6.738 ( 4.413)	Loss 3.6497e-02 (9.8532e-02) 
2023-05-27 08:43:29.851475: train Epoch: [17][ 51/193]	Time  2.445 ( 4.937)	Data  1.882 ( 4.364)	Loss 1.3516e-01 (9.9236e-02) 
2023-05-27 08:43:37.047360: train Epoch: [17][ 52/193]	Time  7.196 ( 4.980)	Data  6.632 ( 4.407)	Loss 8.2377e-02 (9.8918e-02) 
2023-05-27 08:43:39.752214: train Epoch: [17][ 53/193]	Time  2.705 ( 4.938)	Data  2.141 ( 4.365)	Loss 9.8961e-02 (9.8919e-02) 
2023-05-27 08:43:47.056042: train Epoch: [17][ 54/193]	Time  7.304 ( 4.981)	Data  6.737 ( 4.408)	Loss 1.0748e-01 (9.9074e-02) 
2023-05-27 08:43:49.928648: train Epoch: [17][ 55/193]	Time  2.873 ( 4.943)	Data  2.284 ( 4.370)	Loss 5.8454e-02 (9.8349e-02) 
2023-05-27 08:43:57.222982: train Epoch: [17][ 56/193]	Time  7.294 ( 4.984)	Data  6.729 ( 4.412)	Loss 1.1197e-01 (9.8588e-02) 
2023-05-27 08:43:59.607334: train Epoch: [17][ 57/193]	Time  2.384 ( 4.940)	Data  1.822 ( 4.367)	Loss 9.5414e-02 (9.8533e-02) 
2023-05-27 08:44:06.957711: train Epoch: [17][ 58/193]	Time  7.350 ( 4.980)	Data  6.781 ( 4.408)	Loss 1.0109e-01 (9.8577e-02) 
2023-05-27 08:44:09.655276: train Epoch: [17][ 59/193]	Time  2.698 ( 4.942)	Data  2.118 ( 4.370)	Loss 6.6857e-02 (9.8048e-02) 
2023-05-27 08:44:16.633184: train Epoch: [17][ 60/193]	Time  6.978 ( 4.976)	Data  6.409 ( 4.403)	Loss 1.3283e-01 (9.8618e-02) 
2023-05-27 08:44:19.841067: train Epoch: [17][ 61/193]	Time  3.208 ( 4.947)	Data  2.643 ( 4.375)	Loss 9.6608e-02 (9.8586e-02) 
2023-05-27 08:44:26.593376: train Epoch: [17][ 62/193]	Time  6.752 ( 4.976)	Data  6.189 ( 4.404)	Loss 9.5508e-02 (9.8537e-02) 
2023-05-27 08:44:30.443607: train Epoch: [17][ 63/193]	Time  3.850 ( 4.958)	Data  3.275 ( 4.386)	Loss 1.4260e-01 (9.9225e-02) 
2023-05-27 08:44:36.409697: train Epoch: [17][ 64/193]	Time  5.966 ( 4.974)	Data  5.394 ( 4.402)	Loss 1.1253e-01 (9.9430e-02) 
2023-05-27 08:44:40.410942: train Epoch: [17][ 65/193]	Time  4.001 ( 4.959)	Data  3.423 ( 4.387)	Loss 8.6731e-02 (9.9238e-02) 
2023-05-27 08:44:46.190694: train Epoch: [17][ 66/193]	Time  5.780 ( 4.971)	Data  5.206 ( 4.399)	Loss 5.6933e-02 (9.8606e-02) 
2023-05-27 08:44:50.346057: train Epoch: [17][ 67/193]	Time  4.155 ( 4.959)	Data  3.565 ( 4.387)	Loss 1.4301e-01 (9.9259e-02) 
2023-05-27 08:44:56.105259: train Epoch: [17][ 68/193]	Time  5.759 ( 4.971)	Data  5.196 ( 4.398)	Loss 7.3801e-02 (9.8890e-02) 
2023-05-27 08:44:59.932517: train Epoch: [17][ 69/193]	Time  3.827 ( 4.955)	Data  3.221 ( 4.382)	Loss 1.1360e-01 (9.9101e-02) 
2023-05-27 08:45:06.028422: train Epoch: [17][ 70/193]	Time  6.096 ( 4.971)	Data  5.531 ( 4.398)	Loss 2.7525e-01 (1.0158e-01) 
2023-05-27 08:45:09.996952: train Epoch: [17][ 71/193]	Time  3.969 ( 4.957)	Data  3.368 ( 4.383)	Loss 1.1906e-01 (1.0182e-01) 
2023-05-27 08:45:16.005414: train Epoch: [17][ 72/193]	Time  6.008 ( 4.971)	Data  5.434 ( 4.398)	Loss 7.7067e-02 (1.0149e-01) 
2023-05-27 08:45:19.997985: train Epoch: [17][ 73/193]	Time  3.993 ( 4.958)	Data  3.420 ( 4.385)	Loss 9.2556e-02 (1.0136e-01) 
2023-05-27 08:45:25.409963: train Epoch: [17][ 74/193]	Time  5.412 ( 4.964)	Data  4.843 ( 4.391)	Loss 1.2795e-01 (1.0172e-01) 
2023-05-27 08:45:29.931808: train Epoch: [17][ 75/193]	Time  4.522 ( 4.958)	Data  3.958 ( 4.385)	Loss 6.1374e-02 (1.0119e-01) 
2023-05-27 08:45:34.785680: train Epoch: [17][ 76/193]	Time  4.854 ( 4.957)	Data  4.271 ( 4.384)	Loss 1.4074e-01 (1.0170e-01) 
2023-05-27 08:45:39.651415: train Epoch: [17][ 77/193]	Time  4.866 ( 4.956)	Data  4.283 ( 4.382)	Loss 9.6784e-02 (1.0164e-01) 
2023-05-27 08:45:44.795803: train Epoch: [17][ 78/193]	Time  5.144 ( 4.958)	Data  4.579 ( 4.385)	Loss 8.5260e-02 (1.0143e-01) 
2023-05-27 08:45:49.590435: train Epoch: [17][ 79/193]	Time  4.795 ( 4.956)	Data  4.224 ( 4.383)	Loss 8.4291e-02 (1.0122e-01) 
2023-05-27 08:45:54.594678: train Epoch: [17][ 80/193]	Time  5.004 ( 4.957)	Data  4.432 ( 4.383)	Loss 1.7992e-01 (1.0219e-01) 
2023-05-27 08:46:00.088578: train Epoch: [17][ 81/193]	Time  5.494 ( 4.963)	Data  4.930 ( 4.390)	Loss 6.4585e-02 (1.0173e-01) 
2023-05-27 08:46:04.361289: train Epoch: [17][ 82/193]	Time  4.273 ( 4.955)	Data  3.709 ( 4.382)	Loss 8.6039e-02 (1.0154e-01) 
2023-05-27 08:46:10.333190: train Epoch: [17][ 83/193]	Time  5.972 ( 4.967)	Data  5.408 ( 4.394)	Loss 6.1654e-02 (1.0107e-01) 
2023-05-27 08:46:15.082255: train Epoch: [17][ 84/193]	Time  4.749 ( 4.964)	Data  4.182 ( 4.392)	Loss 7.9141e-02 (1.0081e-01) 
2023-05-27 08:46:20.389220: train Epoch: [17][ 85/193]	Time  5.307 ( 4.968)	Data  4.744 ( 4.396)	Loss 1.3847e-01 (1.0125e-01) 
2023-05-27 08:46:25.258885: train Epoch: [17][ 86/193]	Time  4.870 ( 4.967)	Data  4.293 ( 4.394)	Loss 9.1196e-02 (1.0113e-01) 
2023-05-27 08:46:30.306383: train Epoch: [17][ 87/193]	Time  5.047 ( 4.968)	Data  4.483 ( 4.395)	Loss 8.7080e-02 (1.0097e-01) 
2023-05-27 08:46:34.713440: train Epoch: [17][ 88/193]	Time  4.407 ( 4.962)	Data  3.835 ( 4.389)	Loss 1.3309e-01 (1.0133e-01) 
2023-05-27 08:46:39.350456: train Epoch: [17][ 89/193]	Time  4.637 ( 4.958)	Data  4.074 ( 4.386)	Loss 8.5455e-02 (1.0116e-01) 
2023-05-27 08:46:43.397589: train Epoch: [17][ 90/193]	Time  4.047 ( 4.948)	Data  3.471 ( 4.376)	Loss 9.3375e-02 (1.0107e-01) 
2023-05-27 08:46:47.989195: train Epoch: [17][ 91/193]	Time  4.592 ( 4.944)	Data  4.030 ( 4.372)	Loss 5.5070e-02 (1.0057e-01) 
2023-05-27 08:46:52.519158: train Epoch: [17][ 92/193]	Time  4.530 ( 4.940)	Data  3.951 ( 4.367)	Loss 6.7010e-02 (1.0021e-01) 
2023-05-27 08:46:58.096813: train Epoch: [17][ 93/193]	Time  5.578 ( 4.947)	Data  5.008 ( 4.374)	Loss 9.3074e-02 (1.0013e-01) 
2023-05-27 08:47:02.612121: train Epoch: [17][ 94/193]	Time  4.515 ( 4.942)	Data  3.943 ( 4.370)	Loss 5.3809e-02 (9.9646e-02) 
2023-05-27 08:47:08.009614: train Epoch: [17][ 95/193]	Time  5.397 ( 4.947)	Data  4.831 ( 4.374)	Loss 1.0884e-01 (9.9741e-02) 
2023-05-27 08:47:12.616668: train Epoch: [17][ 96/193]	Time  4.607 ( 4.943)	Data  4.032 ( 4.371)	Loss 1.1218e-01 (9.9870e-02) 
2023-05-27 08:47:18.333560: train Epoch: [17][ 97/193]	Time  5.717 ( 4.951)	Data  5.139 ( 4.379)	Loss 6.4393e-02 (9.9508e-02) 
2023-05-27 08:47:22.715119: train Epoch: [17][ 98/193]	Time  4.382 ( 4.945)	Data  3.818 ( 4.373)	Loss 7.4578e-02 (9.9256e-02) 
2023-05-27 08:47:28.300818: train Epoch: [17][ 99/193]	Time  5.586 ( 4.952)	Data  5.014 ( 4.379)	Loss 8.6864e-02 (9.9132e-02) 
2023-05-27 08:47:32.440822: train Epoch: [17][100/193]	Time  4.140 ( 4.944)	Data  3.568 ( 4.371)	Loss 1.1539e-01 (9.9293e-02) 
2023-05-27 08:47:38.206352: train Epoch: [17][101/193]	Time  5.766 ( 4.952)	Data  5.195 ( 4.380)	Loss 1.0337e-01 (9.9333e-02) 
2023-05-27 08:47:42.413340: train Epoch: [17][102/193]	Time  4.207 ( 4.945)	Data  3.626 ( 4.372)	Loss 1.7931e-01 (1.0011e-01) 
2023-05-27 08:47:48.082765: train Epoch: [17][103/193]	Time  5.669 ( 4.952)	Data  5.104 ( 4.379)	Loss 1.3008e-01 (1.0040e-01) 
2023-05-27 08:47:52.091125: train Epoch: [17][104/193]	Time  4.008 ( 4.943)	Data  3.443 ( 4.370)	Loss 6.9969e-02 (1.0011e-01) 
2023-05-27 08:47:57.845529: train Epoch: [17][105/193]	Time  5.754 ( 4.950)	Data  5.188 ( 4.378)	Loss 1.1132e-01 (1.0021e-01) 
2023-05-27 08:48:02.261361: train Epoch: [17][106/193]	Time  4.416 ( 4.945)	Data  3.843 ( 4.373)	Loss 1.0721e-01 (1.0028e-01) 
2023-05-27 08:48:07.584840: train Epoch: [17][107/193]	Time  5.323 ( 4.949)	Data  4.760 ( 4.377)	Loss 1.0551e-01 (1.0033e-01) 
2023-05-27 08:48:12.232536: train Epoch: [17][108/193]	Time  4.648 ( 4.946)	Data  4.084 ( 4.374)	Loss 1.2687e-01 (1.0057e-01) 
2023-05-27 08:48:17.326827: train Epoch: [17][109/193]	Time  5.094 ( 4.947)	Data  4.532 ( 4.375)	Loss 8.8508e-02 (1.0046e-01) 
2023-05-27 08:48:21.944789: train Epoch: [17][110/193]	Time  4.618 ( 4.944)	Data  4.055 ( 4.372)	Loss 1.5300e-01 (1.0093e-01) 
2023-05-27 08:48:27.735296: train Epoch: [17][111/193]	Time  5.791 ( 4.952)	Data  5.227 ( 4.380)	Loss 9.8516e-02 (1.0091e-01) 
2023-05-27 08:48:32.196971: train Epoch: [17][112/193]	Time  4.462 ( 4.948)	Data  3.898 ( 4.376)	Loss 9.3378e-02 (1.0085e-01) 
2023-05-27 08:48:37.769997: train Epoch: [17][113/193]	Time  5.573 ( 4.953)	Data  5.002 ( 4.381)	Loss 1.6186e-01 (1.0138e-01) 
2023-05-27 08:48:42.224538: train Epoch: [17][114/193]	Time  4.455 ( 4.949)	Data  3.884 ( 4.377)	Loss 9.3344e-02 (1.0131e-01) 
2023-05-27 08:48:47.802409: train Epoch: [17][115/193]	Time  5.578 ( 4.954)	Data  5.003 ( 4.382)	Loss 9.5526e-02 (1.0126e-01) 
2023-05-27 08:48:52.413556: train Epoch: [17][116/193]	Time  4.611 ( 4.951)	Data  4.035 ( 4.379)	Loss 3.1835e-01 (1.0312e-01) 
2023-05-27 08:48:57.954595: train Epoch: [17][117/193]	Time  5.541 ( 4.956)	Data  4.967 ( 4.384)	Loss 1.5080e-01 (1.0352e-01) 
2023-05-27 08:49:02.569291: train Epoch: [17][118/193]	Time  4.615 ( 4.953)	Data  4.049 ( 4.382)	Loss 2.6375e-01 (1.0487e-01) 
2023-05-27 08:49:08.096095: train Epoch: [17][119/193]	Time  5.527 ( 4.958)	Data  4.960 ( 4.386)	Loss 9.1470e-02 (1.0476e-01) 
2023-05-27 08:49:12.269334: train Epoch: [17][120/193]	Time  4.173 ( 4.952)	Data  3.600 ( 4.380)	Loss 1.7288e-01 (1.0532e-01) 
2023-05-27 08:49:17.909280: train Epoch: [17][121/193]	Time  5.640 ( 4.957)	Data  5.072 ( 4.386)	Loss 1.1687e-01 (1.0541e-01) 
2023-05-27 08:49:22.081861: train Epoch: [17][122/193]	Time  4.173 ( 4.951)	Data  3.601 ( 4.379)	Loss 1.4092e-01 (1.0570e-01) 
2023-05-27 08:49:27.750860: train Epoch: [17][123/193]	Time  5.669 ( 4.957)	Data  5.101 ( 4.385)	Loss 8.8149e-02 (1.0556e-01) 
2023-05-27 08:49:31.784408: train Epoch: [17][124/193]	Time  4.034 ( 4.949)	Data  3.462 ( 4.378)	Loss 1.7865e-01 (1.0615e-01) 
2023-05-27 08:49:37.775504: train Epoch: [17][125/193]	Time  5.991 ( 4.958)	Data  5.416 ( 4.386)	Loss 1.1280e-01 (1.0620e-01) 
2023-05-27 08:49:42.047879: train Epoch: [17][126/193]	Time  4.272 ( 4.952)	Data  3.700 ( 4.380)	Loss 2.0517e-01 (1.0698e-01) 
2023-05-27 08:49:47.154145: train Epoch: [17][127/193]	Time  5.106 ( 4.953)	Data  4.538 ( 4.382)	Loss 1.2970e-01 (1.0716e-01) 
2023-05-27 08:49:52.013925: train Epoch: [17][128/193]	Time  4.860 ( 4.953)	Data  4.289 ( 4.381)	Loss 1.4290e-01 (1.0743e-01) 
2023-05-27 08:49:57.233637: train Epoch: [17][129/193]	Time  5.220 ( 4.955)	Data  4.648 ( 4.383)	Loss 1.0303e-01 (1.0740e-01) 
2023-05-27 08:50:02.074940: train Epoch: [17][130/193]	Time  4.841 ( 4.954)	Data  4.268 ( 4.382)	Loss 2.6206e-01 (1.0858e-01) 
2023-05-27 08:50:07.134503: train Epoch: [17][131/193]	Time  5.060 ( 4.955)	Data  4.488 ( 4.383)	Loss 8.4867e-02 (1.0840e-01) 
2023-05-27 08:50:12.101324: train Epoch: [17][132/193]	Time  4.967 ( 4.955)	Data  4.387 ( 4.383)	Loss 6.3337e-02 (1.0806e-01) 
2023-05-27 08:50:16.847911: train Epoch: [17][133/193]	Time  4.747 ( 4.953)	Data  4.156 ( 4.381)	Loss 6.9527e-02 (1.0777e-01) 
2023-05-27 08:50:22.365952: train Epoch: [17][134/193]	Time  5.518 ( 4.957)	Data  4.937 ( 4.385)	Loss 1.3008e-01 (1.0794e-01) 
2023-05-27 08:50:27.092270: train Epoch: [17][135/193]	Time  4.726 ( 4.956)	Data  4.112 ( 4.383)	Loss 1.7462e-01 (1.0843e-01) 
2023-05-27 08:50:32.398035: train Epoch: [17][136/193]	Time  5.306 ( 4.958)	Data  4.737 ( 4.386)	Loss 2.5846e-01 (1.0952e-01) 
2023-05-27 08:50:37.039653: train Epoch: [17][137/193]	Time  4.642 ( 4.956)	Data  4.044 ( 4.384)	Loss 3.5334e-01 (1.1129e-01) 
2023-05-27 08:50:42.590284: train Epoch: [17][138/193]	Time  5.551 ( 4.960)	Data  4.980 ( 4.388)	Loss 7.9984e-02 (1.1107e-01) 
2023-05-27 08:50:46.999564: train Epoch: [17][139/193]	Time  4.409 ( 4.956)	Data  3.823 ( 4.384)	Loss 8.0934e-02 (1.1085e-01) 
2023-05-27 08:50:53.108045: train Epoch: [17][140/193]	Time  6.108 ( 4.965)	Data  5.539 ( 4.392)	Loss 6.9718e-02 (1.1056e-01) 
2023-05-27 08:50:56.905939: train Epoch: [17][141/193]	Time  3.798 ( 4.956)	Data  3.228 ( 4.384)	Loss 7.5521e-02 (1.1031e-01) 
2023-05-27 08:51:02.876541: train Epoch: [17][142/193]	Time  5.971 ( 4.963)	Data  5.407 ( 4.391)	Loss 8.1355e-02 (1.1011e-01) 
2023-05-27 08:51:06.651778: train Epoch: [17][143/193]	Time  3.775 ( 4.955)	Data  3.175 ( 4.382)	Loss 9.3754e-02 (1.1000e-01) 
2023-05-27 08:51:12.798587: train Epoch: [17][144/193]	Time  6.147 ( 4.963)	Data  5.545 ( 4.391)	Loss 8.8595e-02 (1.0985e-01) 
2023-05-27 08:51:16.576457: train Epoch: [17][145/193]	Time  3.778 ( 4.955)	Data  3.184 ( 4.382)	Loss 1.0225e-01 (1.0980e-01) 
2023-05-27 08:51:22.911813: train Epoch: [17][146/193]	Time  6.335 ( 4.965)	Data  5.734 ( 4.391)	Loss 9.3345e-02 (1.0968e-01) 
2023-05-27 08:51:27.018895: train Epoch: [17][147/193]	Time  4.107 ( 4.959)	Data  3.532 ( 4.386)	Loss 1.2380e-01 (1.0978e-01) 
2023-05-27 08:51:33.023588: train Epoch: [17][148/193]	Time  6.005 ( 4.966)	Data  5.441 ( 4.393)	Loss 9.2332e-02 (1.0966e-01) 
2023-05-27 08:51:37.479240: train Epoch: [17][149/193]	Time  4.456 ( 4.962)	Data  3.887 ( 4.389)	Loss 1.3052e-01 (1.0980e-01) 
2023-05-27 08:51:42.772628: train Epoch: [17][150/193]	Time  5.293 ( 4.965)	Data  4.703 ( 4.391)	Loss 1.0259e-01 (1.0975e-01) 
2023-05-27 08:51:47.182101: train Epoch: [17][151/193]	Time  4.409 ( 4.961)	Data  3.836 ( 4.388)	Loss 1.1209e-01 (1.0977e-01) 
2023-05-27 08:51:52.830146: train Epoch: [17][152/193]	Time  5.648 ( 4.965)	Data  5.040 ( 4.392)	Loss 7.8707e-02 (1.0957e-01) 
2023-05-27 08:51:56.538820: train Epoch: [17][153/193]	Time  3.709 ( 4.957)	Data  3.138 ( 4.384)	Loss 6.5248e-02 (1.0928e-01) 
2023-05-27 08:52:02.906236: train Epoch: [17][154/193]	Time  6.367 ( 4.966)	Data  5.779 ( 4.393)	Loss 2.2536e-01 (1.1003e-01) 
2023-05-27 08:52:06.474934: train Epoch: [17][155/193]	Time  3.569 ( 4.957)	Data  2.992 ( 4.384)	Loss 8.3774e-02 (1.0986e-01) 
2023-05-27 08:52:13.003549: train Epoch: [17][156/193]	Time  6.529 ( 4.967)	Data  5.955 ( 4.394)	Loss 5.6302e-02 (1.0952e-01) 
2023-05-27 08:52:17.095565: train Epoch: [17][157/193]	Time  4.092 ( 4.962)	Data  3.473 ( 4.388)	Loss 1.7112e-01 (1.0991e-01) 
2023-05-27 08:52:22.864236: train Epoch: [17][158/193]	Time  5.769 ( 4.967)	Data  5.191 ( 4.393)	Loss 1.0418e-01 (1.0987e-01) 
2023-05-27 08:52:27.034692: train Epoch: [17][159/193]	Time  4.170 ( 4.962)	Data  3.586 ( 4.388)	Loss 1.6090e-01 (1.1019e-01) 
2023-05-27 08:52:32.918238: train Epoch: [17][160/193]	Time  5.884 ( 4.968)	Data  5.312 ( 4.394)	Loss 1.1662e-01 (1.1023e-01) 
2023-05-27 08:52:36.998364: train Epoch: [17][161/193]	Time  4.080 ( 4.962)	Data  3.511 ( 4.388)	Loss 7.0485e-02 (1.0999e-01) 
2023-05-27 08:52:42.964447: train Epoch: [17][162/193]	Time  5.966 ( 4.968)	Data  5.366 ( 4.394)	Loss 1.2322e-01 (1.1007e-01) 
2023-05-27 08:52:47.128755: train Epoch: [17][163/193]	Time  4.164 ( 4.964)	Data  3.590 ( 4.389)	Loss 8.1874e-02 (1.0989e-01) 
2023-05-27 08:52:53.274476: train Epoch: [17][164/193]	Time  6.146 ( 4.971)	Data  5.585 ( 4.397)	Loss 9.9895e-02 (1.0983e-01) 
2023-05-27 08:52:57.246072: train Epoch: [17][165/193]	Time  3.972 ( 4.965)	Data  3.371 ( 4.391)	Loss 6.8222e-02 (1.0958e-01) 
2023-05-27 08:53:03.530722: train Epoch: [17][166/193]	Time  6.285 ( 4.973)	Data  5.722 ( 4.399)	Loss 5.6857e-02 (1.0927e-01) 
2023-05-27 08:53:07.100766: train Epoch: [17][167/193]	Time  3.570 ( 4.964)	Data  2.990 ( 4.390)	Loss 1.3372e-01 (1.0941e-01) 
2023-05-27 08:53:13.434013: train Epoch: [17][168/193]	Time  6.333 ( 4.972)	Data  5.764 ( 4.398)	Loss 8.7040e-02 (1.0928e-01) 
2023-05-27 08:53:17.187586: train Epoch: [17][169/193]	Time  3.754 ( 4.965)	Data  3.182 ( 4.391)	Loss 1.0437e-01 (1.0925e-01) 
2023-05-27 08:53:23.486423: train Epoch: [17][170/193]	Time  6.299 ( 4.973)	Data  5.736 ( 4.399)	Loss 7.3236e-02 (1.0904e-01) 
2023-05-27 08:53:27.207648: train Epoch: [17][171/193]	Time  3.721 ( 4.966)	Data  3.156 ( 4.392)	Loss 1.2151e-01 (1.0911e-01) 
2023-05-27 08:53:33.215984: train Epoch: [17][172/193]	Time  6.008 ( 4.972)	Data  5.441 ( 4.398)	Loss 5.9266e-02 (1.0883e-01) 
2023-05-27 08:53:37.443198: train Epoch: [17][173/193]	Time  4.227 ( 4.967)	Data  3.661 ( 4.394)	Loss 3.3125e-01 (1.1010e-01) 
2023-05-27 08:53:43.045625: train Epoch: [17][174/193]	Time  5.602 ( 4.971)	Data  5.040 ( 4.397)	Loss 7.5936e-02 (1.0991e-01) 
2023-05-27 08:53:47.456967: train Epoch: [17][175/193]	Time  4.411 ( 4.968)	Data  3.845 ( 4.394)	Loss 8.2044e-02 (1.0975e-01) 
2023-05-27 08:53:52.869156: train Epoch: [17][176/193]	Time  5.412 ( 4.970)	Data  4.849 ( 4.397)	Loss 1.1619e-01 (1.0979e-01) 
2023-05-27 08:53:57.080006: train Epoch: [17][177/193]	Time  4.211 ( 4.966)	Data  3.646 ( 4.392)	Loss 1.1944e-01 (1.0984e-01) 
2023-05-27 08:54:03.400061: train Epoch: [17][178/193]	Time  6.320 ( 4.974)	Data  5.757 ( 4.400)	Loss 1.2960e-01 (1.0995e-01) 
2023-05-27 08:54:07.145231: train Epoch: [17][179/193]	Time  3.745 ( 4.967)	Data  3.180 ( 4.393)	Loss 9.0487e-02 (1.0984e-01) 
2023-05-27 08:54:13.425726: train Epoch: [17][180/193]	Time  6.281 ( 4.974)	Data  5.709 ( 4.401)	Loss 9.1839e-02 (1.0974e-01) 
2023-05-27 08:54:17.099471: train Epoch: [17][181/193]	Time  3.674 ( 4.967)	Data  3.108 ( 4.393)	Loss 1.2870e-01 (1.0985e-01) 
2023-05-27 08:54:23.829490: train Epoch: [17][182/193]	Time  6.730 ( 4.977)	Data  6.154 ( 4.403)	Loss 1.3860e-01 (1.1000e-01) 
2023-05-27 08:54:27.096356: train Epoch: [17][183/193]	Time  3.267 ( 4.967)	Data  2.703 ( 4.394)	Loss 1.6712e-01 (1.1032e-01) 
2023-05-27 08:54:34.002357: train Epoch: [17][184/193]	Time  6.906 ( 4.978)	Data  6.336 ( 4.404)	Loss 7.8093e-02 (1.1014e-01) 
2023-05-27 08:54:36.837969: train Epoch: [17][185/193]	Time  2.836 ( 4.966)	Data  2.271 ( 4.393)	Loss 1.1947e-01 (1.1019e-01) 
2023-05-27 08:54:43.814845: train Epoch: [17][186/193]	Time  6.977 ( 4.977)	Data  6.401 ( 4.404)	Loss 9.8143e-02 (1.1013e-01) 
2023-05-27 08:54:46.601732: train Epoch: [17][187/193]	Time  2.787 ( 4.965)	Data  2.223 ( 4.392)	Loss 1.1335e-01 (1.1014e-01) 
2023-05-27 08:54:53.538228: train Epoch: [17][188/193]	Time  6.936 ( 4.976)	Data  6.373 ( 4.403)	Loss 1.1547e-01 (1.1017e-01) 
2023-05-27 08:54:57.072613: train Epoch: [17][189/193]	Time  3.534 ( 4.968)	Data  2.963 ( 4.395)	Loss 7.2495e-02 (1.0997e-01) 
2023-05-27 08:55:03.413546: train Epoch: [17][190/193]	Time  6.341 ( 4.975)	Data  5.776 ( 4.402)	Loss 1.6785e-01 (1.1028e-01) 
2023-05-27 08:55:07.326303: train Epoch: [17][191/193]	Time  3.913 ( 4.970)	Data  3.333 ( 4.397)	Loss 9.5709e-02 (1.1020e-01) 
2023-05-27 08:55:12.606495: train Epoch: [17][192/193]	Time  5.280 ( 4.971)	Data  4.705 ( 4.398)	Loss 1.1829e-01 (1.1024e-01) 
2023-05-27 08:55:12.761465: Train Epoch done in 959.6500884630077 s 
2023-05-27 08:55:19.370689: val Epoch: [17][ 0/72]	Time  5.807 ( 5.807)	Data  5.606 ( 5.606)	Loss 6.5379e-02 (6.5379e-02) 
2023-05-27 08:55:19.587975: val Epoch: [17][ 1/72]	Time  0.217 ( 3.012)	Data  0.111 ( 2.858)	Loss 1.8913e-01 (1.2725e-01) 
2023-05-27 08:55:24.199350: val Epoch: [17][ 2/72]	Time  4.611 ( 3.545)	Data  4.496 ( 3.404)	Loss 1.0752e-01 (1.2068e-01) 
2023-05-27 08:55:24.755814: val Epoch: [17][ 3/72]	Time  0.556 ( 2.798)	Data  0.448 ( 2.665)	Loss 3.6165e-01 (1.8092e-01) 
2023-05-27 08:55:29.282985: val Epoch: [17][ 4/72]	Time  4.527 ( 3.144)	Data  4.404 ( 3.013)	Loss 1.3339e-01 (1.7141e-01) 
2023-05-27 08:55:29.808702: val Epoch: [17][ 5/72]	Time  0.526 ( 2.708)	Data  0.420 ( 2.581)	Loss 4.5357e-01 (2.1844e-01) 
2023-05-27 08:55:34.306569: val Epoch: [17][ 6/72]	Time  4.498 ( 2.963)	Data  4.387 ( 2.839)	Loss 4.4649e-01 (2.5102e-01) 
2023-05-27 08:55:34.794963: val Epoch: [17][ 7/72]	Time  0.488 ( 2.654)	Data  0.379 ( 2.531)	Loss 3.2214e-01 (2.5991e-01) 
2023-05-27 08:55:39.355155: val Epoch: [17][ 8/72]	Time  4.560 ( 2.866)	Data  4.452 ( 2.745)	Loss 1.0189e-01 (2.4235e-01) 
2023-05-27 08:55:39.890183: val Epoch: [17][ 9/72]	Time  0.535 ( 2.633)	Data  0.430 ( 2.513)	Loss 8.2358e-02 (2.2635e-01) 
2023-05-27 08:55:44.397758: val Epoch: [17][10/72]	Time  4.508 ( 2.803)	Data  4.402 ( 2.685)	Loss 1.0553e-01 (2.1537e-01) 
2023-05-27 08:55:44.878567: val Epoch: [17][11/72]	Time  0.481 ( 2.610)	Data  0.371 ( 2.492)	Loss 4.8949e-02 (2.0150e-01) 
2023-05-27 08:55:49.353967: val Epoch: [17][12/72]	Time  4.475 ( 2.753)	Data  4.370 ( 2.637)	Loss 9.3035e-02 (1.9316e-01) 
2023-05-27 08:55:49.837173: val Epoch: [17][13/72]	Time  0.483 ( 2.591)	Data  0.378 ( 2.475)	Loss 3.4458e-01 (2.0397e-01) 
2023-05-27 08:55:54.723513: val Epoch: [17][14/72]	Time  4.886 ( 2.744)	Data  4.777 ( 2.629)	Loss 1.6612e-01 (2.0145e-01) 
2023-05-27 08:55:54.834345: val Epoch: [17][15/72]	Time  0.111 ( 2.579)	Data  0.000 ( 2.464)	Loss 5.5855e-02 (1.9235e-01) 
2023-05-27 08:55:59.806886: val Epoch: [17][16/72]	Time  4.973 ( 2.720)	Data  4.866 ( 2.606)	Loss 1.2814e-01 (1.8857e-01) 
2023-05-27 08:55:59.912903: val Epoch: [17][17/72]	Time  0.106 ( 2.575)	Data  0.000 ( 2.461)	Loss 2.0037e-01 (1.8923e-01) 
2023-05-27 08:56:04.929690: val Epoch: [17][18/72]	Time  5.017 ( 2.703)	Data  4.899 ( 2.589)	Loss 3.7817e-01 (1.9917e-01) 
2023-05-27 08:56:05.043806: val Epoch: [17][19/72]	Time  0.114 ( 2.574)	Data  0.001 ( 2.460)	Loss 1.1643e-01 (1.9503e-01) 
2023-05-27 08:56:09.631608: val Epoch: [17][20/72]	Time  4.588 ( 2.670)	Data  4.483 ( 2.556)	Loss 6.0630e-02 (1.8863e-01) 
2023-05-27 08:56:09.875197: val Epoch: [17][21/72]	Time  0.244 ( 2.560)	Data  0.139 ( 2.446)	Loss 9.9096e-02 (1.8456e-01) 
2023-05-27 08:56:14.541333: val Epoch: [17][22/72]	Time  4.666 ( 2.651)	Data  4.561 ( 2.538)	Loss 4.9795e-02 (1.7870e-01) 
2023-05-27 08:56:14.645793: val Epoch: [17][23/72]	Time  0.104 ( 2.545)	Data  0.000 ( 2.433)	Loss 1.0085e-01 (1.7546e-01) 
2023-05-27 08:56:19.724721: val Epoch: [17][24/72]	Time  5.079 ( 2.646)	Data  4.974 ( 2.534)	Loss 9.9612e-02 (1.7243e-01) 
2023-05-27 08:56:19.829505: val Epoch: [17][25/72]	Time  0.105 ( 2.549)	Data  0.000 ( 2.437)	Loss 7.2883e-02 (1.6860e-01) 
2023-05-27 08:56:25.068489: val Epoch: [17][26/72]	Time  5.239 ( 2.648)	Data  5.108 ( 2.536)	Loss 1.1086e-01 (1.6646e-01) 
2023-05-27 08:56:25.187315: val Epoch: [17][27/72]	Time  0.119 ( 2.558)	Data  0.001 ( 2.445)	Loss 5.1525e-02 (1.6235e-01) 
2023-05-27 08:56:30.156271: val Epoch: [17][28/72]	Time  4.969 ( 2.641)	Data  4.861 ( 2.528)	Loss 8.8917e-02 (1.5982e-01) 
2023-05-27 08:56:30.263525: val Epoch: [17][29/72]	Time  0.107 ( 2.557)	Data  0.000 ( 2.444)	Loss 8.6857e-02 (1.5739e-01) 
2023-05-27 08:56:35.124400: val Epoch: [17][30/72]	Time  4.861 ( 2.631)	Data  4.746 ( 2.518)	Loss 1.0054e-01 (1.5556e-01) 
2023-05-27 08:56:35.258213: val Epoch: [17][31/72]	Time  0.134 ( 2.553)	Data  0.001 ( 2.440)	Loss 2.2697e-01 (1.5779e-01) 
2023-05-27 08:56:40.168768: val Epoch: [17][32/72]	Time  4.911 ( 2.624)	Data  4.798 ( 2.511)	Loss 1.1897e-01 (1.5661e-01) 
2023-05-27 08:56:40.278836: val Epoch: [17][33/72]	Time  0.110 ( 2.550)	Data  0.001 ( 2.437)	Loss 5.0025e-02 (1.5348e-01) 
2023-05-27 08:56:45.391550: val Epoch: [17][34/72]	Time  5.113 ( 2.624)	Data  5.007 ( 2.511)	Loss 1.8422e-01 (1.5436e-01) 
2023-05-27 08:56:45.497882: val Epoch: [17][35/72]	Time  0.106 ( 2.554)	Data  0.000 ( 2.441)	Loss 5.5837e-02 (1.5162e-01) 
2023-05-27 08:56:50.307466: val Epoch: [17][36/72]	Time  4.810 ( 2.615)	Data  4.703 ( 2.502)	Loss 6.4803e-02 (1.4927e-01) 
2023-05-27 08:56:50.413397: val Epoch: [17][37/72]	Time  0.106 ( 2.549)	Data  0.001 ( 2.436)	Loss 7.6984e-02 (1.4737e-01) 
2023-05-27 08:56:55.114837: val Epoch: [17][38/72]	Time  4.701 ( 2.604)	Data  4.593 ( 2.492)	Loss 1.3178e-01 (1.4697e-01) 
2023-05-27 08:56:55.222584: val Epoch: [17][39/72]	Time  0.108 ( 2.541)	Data  0.000 ( 2.429)	Loss 7.0068e-02 (1.4505e-01) 
2023-05-27 08:57:00.375607: val Epoch: [17][40/72]	Time  5.153 ( 2.605)	Data  5.045 ( 2.493)	Loss 4.9123e-01 (1.5349e-01) 
2023-05-27 08:57:00.482789: val Epoch: [17][41/72]	Time  0.107 ( 2.546)	Data  0.000 ( 2.434)	Loss 4.2746e-01 (1.6001e-01) 
2023-05-27 08:57:05.587801: val Epoch: [17][42/72]	Time  5.105 ( 2.605)	Data  4.996 ( 2.493)	Loss 1.1254e-01 (1.5891e-01) 
2023-05-27 08:57:05.695785: val Epoch: [17][43/72]	Time  0.108 ( 2.548)	Data  0.001 ( 2.437)	Loss 5.5574e-02 (1.5656e-01) 
2023-05-27 08:57:10.991031: val Epoch: [17][44/72]	Time  5.295 ( 2.609)	Data  5.188 ( 2.498)	Loss 6.4048e-02 (1.5451e-01) 
2023-05-27 08:57:11.099449: val Epoch: [17][45/72]	Time  0.108 ( 2.555)	Data  0.000 ( 2.444)	Loss 1.7431e-01 (1.5494e-01) 
2023-05-27 08:57:16.003110: val Epoch: [17][46/72]	Time  4.904 ( 2.605)	Data  4.796 ( 2.494)	Loss 6.2278e-02 (1.5296e-01) 
2023-05-27 08:57:16.113675: val Epoch: [17][47/72]	Time  0.111 ( 2.553)	Data  0.001 ( 2.442)	Loss 1.7647e-01 (1.5345e-01) 
2023-05-27 08:57:20.924321: val Epoch: [17][48/72]	Time  4.811 ( 2.599)	Data  4.699 ( 2.488)	Loss 1.0039e-01 (1.5237e-01) 
2023-05-27 08:57:21.057709: val Epoch: [17][49/72]	Time  0.133 ( 2.550)	Data  0.001 ( 2.438)	Loss 8.2449e-02 (1.5097e-01) 
2023-05-27 08:57:26.005649: val Epoch: [17][50/72]	Time  4.948 ( 2.597)	Data  4.837 ( 2.485)	Loss 4.9892e-02 (1.4899e-01) 
2023-05-27 08:57:26.119270: val Epoch: [17][51/72]	Time  0.114 ( 2.549)	Data  0.001 ( 2.437)	Loss 7.4978e-02 (1.4757e-01) 
2023-05-27 08:57:31.032028: val Epoch: [17][52/72]	Time  4.913 ( 2.594)	Data  4.788 ( 2.482)	Loss 7.5314e-02 (1.4620e-01) 
2023-05-27 08:57:31.149325: val Epoch: [17][53/72]	Time  0.117 ( 2.548)	Data  0.001 ( 2.436)	Loss 1.4246e-01 (1.4614e-01) 
2023-05-27 08:57:35.838784: val Epoch: [17][54/72]	Time  4.689 ( 2.587)	Data  4.576 ( 2.475)	Loss 5.7347e-02 (1.4452e-01) 
2023-05-27 08:57:35.954178: val Epoch: [17][55/72]	Time  0.115 ( 2.543)	Data  0.001 ( 2.430)	Loss 1.6094e-01 (1.4481e-01) 
2023-05-27 08:57:40.665976: val Epoch: [17][56/72]	Time  4.712 ( 2.581)	Data  4.607 ( 2.469)	Loss 1.9360e-01 (1.4567e-01) 
2023-05-27 08:57:40.771821: val Epoch: [17][57/72]	Time  0.106 ( 2.538)	Data  0.001 ( 2.426)	Loss 7.3891e-02 (1.4443e-01) 
2023-05-27 08:57:45.662777: val Epoch: [17][58/72]	Time  4.891 ( 2.578)	Data  4.783 ( 2.466)	Loss 5.2007e-02 (1.4287e-01) 
2023-05-27 08:57:45.767410: val Epoch: [17][59/72]	Time  0.105 ( 2.537)	Data  0.001 ( 2.425)	Loss 9.0312e-02 (1.4199e-01) 
2023-05-27 08:57:50.434390: val Epoch: [17][60/72]	Time  4.667 ( 2.572)	Data  4.562 ( 2.460)	Loss 8.3535e-02 (1.4103e-01) 
2023-05-27 08:57:50.538829: val Epoch: [17][61/72]	Time  0.104 ( 2.532)	Data  0.001 ( 2.420)	Loss 6.8962e-02 (1.3987e-01) 
2023-05-27 08:57:55.399657: val Epoch: [17][62/72]	Time  4.861 ( 2.569)	Data  4.702 ( 2.457)	Loss 4.7088e-02 (1.3840e-01) 
2023-05-27 08:57:55.564332: val Epoch: [17][63/72]	Time  0.165 ( 2.531)	Data  0.001 ( 2.418)	Loss 4.0373e-01 (1.4254e-01) 
2023-05-27 08:58:00.522177: val Epoch: [17][64/72]	Time  4.958 ( 2.569)	Data  4.841 ( 2.455)	Loss 1.8779e-01 (1.4324e-01) 
2023-05-27 08:58:00.634359: val Epoch: [17][65/72]	Time  0.112 ( 2.531)	Data  0.001 ( 2.418)	Loss 1.5464e-01 (1.4341e-01) 
2023-05-27 08:58:05.431320: val Epoch: [17][66/72]	Time  4.797 ( 2.565)	Data  4.646 ( 2.451)	Loss 8.2846e-02 (1.4251e-01) 
2023-05-27 08:58:05.561109: val Epoch: [17][67/72]	Time  0.130 ( 2.529)	Data  0.003 ( 2.415)	Loss 5.7920e-02 (1.4126e-01) 
2023-05-27 08:58:10.490999: val Epoch: [17][68/72]	Time  4.930 ( 2.564)	Data  4.822 ( 2.450)	Loss 2.6407e-01 (1.4304e-01) 
2023-05-27 08:58:10.599071: val Epoch: [17][69/72]	Time  0.108 ( 2.529)	Data  0.000 ( 2.415)	Loss 1.0889e-01 (1.4256e-01) 
2023-05-27 08:58:15.252011: val Epoch: [17][70/72]	Time  4.653 ( 2.559)	Data  4.541 ( 2.445)	Loss 1.2686e-01 (1.4233e-01) 
2023-05-27 08:58:15.364163: val Epoch: [17][71/72]	Time  0.112 ( 2.525)	Data  0.000 ( 2.411)	Loss 3.5318e-01 (1.4526e-01) 
2023-05-27 08:58:15.663570: Epoch 17 :Val : ['ET : 0.6968510746955872', 'TC : 0.7659690380096436', 'WT : 0.8454594016075134'] 
2023-05-27 08:58:15.666766: Epoch 17 :Val : ['ET : 0.6968510746955872', 'TC : 0.7659690380096436', 'WT : 0.8454594016075134'] 
2023-05-27 08:58:15.669279: Saving the model with DSC 0.77564537525177 
2023-05-27 08:58:16.314670: Val epoch done in 183.55322627798887 s 
2023-05-27 08:58:16.320358: Batches per epoch:  193 
2023-05-27 08:58:27.205403: train Epoch: [18][  0/193]	Time 10.885 (10.885)	Data 10.287 (10.287)	Loss 9.0782e-02 (9.0782e-02) 
2023-05-27 08:58:27.771143: train Epoch: [18][  1/193]	Time  0.566 ( 5.725)	Data  0.001 ( 5.144)	Loss 7.5814e-02 (8.3298e-02) 
2023-05-27 08:58:36.893022: train Epoch: [18][  2/193]	Time  9.122 ( 6.857)	Data  8.562 ( 6.283)	Loss 9.0908e-02 (8.5835e-02) 
2023-05-27 08:58:37.600893: train Epoch: [18][  3/193]	Time  0.708 ( 5.320)	Data  0.148 ( 4.749)	Loss 7.0967e-02 (8.2118e-02) 
2023-05-27 08:58:46.728981: train Epoch: [18][  4/193]	Time  9.128 ( 6.082)	Data  8.567 ( 5.513)	Loss 1.2054e-01 (8.9803e-02) 
2023-05-27 08:58:47.546363: train Epoch: [18][  5/193]	Time  0.817 ( 5.204)	Data  0.257 ( 4.637)	Loss 1.6182e-01 (1.0181e-01) 
2023-05-27 08:58:57.387355: train Epoch: [18][  6/193]	Time  9.841 ( 5.867)	Data  9.281 ( 5.300)	Loss 1.5865e-01 (1.0993e-01) 
2023-05-27 08:58:57.946804: train Epoch: [18][  7/193]	Time  0.559 ( 5.203)	Data  0.001 ( 4.638)	Loss 1.0084e-01 (1.0879e-01) 
2023-05-27 08:59:07.251230: train Epoch: [18][  8/193]	Time  9.304 ( 5.659)	Data  8.736 ( 5.093)	Loss 9.9092e-02 (1.0771e-01) 
2023-05-27 08:59:07.812284: train Epoch: [18][  9/193]	Time  0.561 ( 5.149)	Data  0.001 ( 4.584)	Loss 7.0937e-02 (1.0404e-01) 
2023-05-27 08:59:17.146353: train Epoch: [18][ 10/193]	Time  9.334 ( 5.530)	Data  8.774 ( 4.965)	Loss 1.1115e-01 (1.0468e-01) 
2023-05-27 08:59:17.705997: train Epoch: [18][ 11/193]	Time  0.560 ( 5.115)	Data  0.001 ( 4.551)	Loss 1.6421e-01 (1.0964e-01) 
2023-05-27 08:59:27.190662: train Epoch: [18][ 12/193]	Time  9.485 ( 5.452)	Data  8.925 ( 4.888)	Loss 7.3591e-02 (1.0687e-01) 
2023-05-27 08:59:27.958052: train Epoch: [18][ 13/193]	Time  0.767 ( 5.117)	Data  0.208 ( 4.553)	Loss 7.9412e-02 (1.0491e-01) 
2023-05-27 08:59:36.842572: train Epoch: [18][ 14/193]	Time  8.885 ( 5.368)	Data  8.322 ( 4.805)	Loss 2.5531e-01 (1.1494e-01) 
2023-05-27 08:59:37.402960: train Epoch: [18][ 15/193]	Time  0.560 ( 5.068)	Data  0.001 ( 4.505)	Loss 6.5790e-02 (1.1186e-01) 
2023-05-27 08:59:46.744772: train Epoch: [18][ 16/193]	Time  9.342 ( 5.319)	Data  8.782 ( 4.756)	Loss 1.0859e-01 (1.1167e-01) 
2023-05-27 08:59:47.304551: train Epoch: [18][ 17/193]	Time  0.560 ( 5.055)	Data  0.001 ( 4.492)	Loss 7.9237e-02 (1.0987e-01) 
2023-05-27 08:59:54.973666: train Epoch: [18][ 18/193]	Time  7.669 ( 5.192)	Data  7.090 ( 4.629)	Loss 8.4212e-02 (1.0852e-01) 
2023-05-27 08:59:55.540896: train Epoch: [18][ 19/193]	Time  0.567 ( 4.961)	Data  0.001 ( 4.397)	Loss 1.1334e-01 (1.0876e-01) 
2023-05-27 09:00:03.987474: train Epoch: [18][ 20/193]	Time  8.447 ( 5.127)	Data  7.881 ( 4.563)	Loss 9.7881e-02 (1.0824e-01) 
2023-05-27 09:00:05.131163: train Epoch: [18][ 21/193]	Time  1.144 ( 4.946)	Data  0.578 ( 4.382)	Loss 8.7030e-02 (1.0728e-01) 
2023-05-27 09:00:13.746764: train Epoch: [18][ 22/193]	Time  8.616 ( 5.105)	Data  8.050 ( 4.542)	Loss 6.6323e-02 (1.0550e-01) 
2023-05-27 09:00:14.696192: train Epoch: [18][ 23/193]	Time  0.949 ( 4.932)	Data  0.384 ( 4.368)	Loss 1.3549e-01 (1.0675e-01) 
2023-05-27 09:00:23.665102: train Epoch: [18][ 24/193]	Time  8.969 ( 5.094)	Data  8.401 ( 4.530)	Loss 1.3559e-01 (1.0790e-01) 
2023-05-27 09:00:24.516143: train Epoch: [18][ 25/193]	Time  0.851 ( 4.931)	Data  0.282 ( 4.366)	Loss 8.3802e-02 (1.0697e-01) 
2023-05-27 09:00:33.575767: train Epoch: [18][ 26/193]	Time  9.060 ( 5.084)	Data  8.492 ( 4.519)	Loss 1.2624e-01 (1.0769e-01) 
2023-05-27 09:00:34.438138: train Epoch: [18][ 27/193]	Time  0.862 ( 4.933)	Data  0.302 ( 4.368)	Loss 2.3115e-01 (1.1210e-01) 
2023-05-27 09:00:43.402414: train Epoch: [18][ 28/193]	Time  8.964 ( 5.072)	Data  8.394 ( 4.507)	Loss 9.5606e-02 (1.1153e-01) 
2023-05-27 09:00:44.710209: train Epoch: [18][ 29/193]	Time  1.308 ( 4.946)	Data  0.745 ( 4.382)	Loss 9.0042e-02 (1.1081e-01) 
2023-05-27 09:00:53.142838: train Epoch: [18][ 30/193]	Time  8.433 ( 5.059)	Data  7.872 ( 4.494)	Loss 7.4063e-02 (1.0963e-01) 
2023-05-27 09:00:54.482812: train Epoch: [18][ 31/193]	Time  1.340 ( 4.943)	Data  0.778 ( 4.378)	Loss 6.6970e-02 (1.0829e-01) 
2023-05-27 09:01:02.759031: train Epoch: [18][ 32/193]	Time  8.276 ( 5.044)	Data  7.713 ( 4.479)	Loss 7.8448e-02 (1.0739e-01) 
2023-05-27 09:01:04.250109: train Epoch: [18][ 33/193]	Time  1.491 ( 4.939)	Data  0.926 ( 4.375)	Loss 1.1448e-01 (1.0760e-01) 
2023-05-27 09:01:12.450483: train Epoch: [18][ 34/193]	Time  8.200 ( 5.032)	Data  7.635 ( 4.468)	Loss 6.0697e-02 (1.0626e-01) 
2023-05-27 09:01:14.107725: train Epoch: [18][ 35/193]	Time  1.657 ( 4.939)	Data  1.090 ( 4.374)	Loss 1.8521e-01 (1.0845e-01) 
2023-05-27 09:01:21.318283: train Epoch: [18][ 36/193]	Time  7.211 ( 5.000)	Data  6.651 ( 4.436)	Loss 1.2348e-01 (1.0886e-01) 
2023-05-27 09:01:23.192695: train Epoch: [18][ 37/193]	Time  1.874 ( 4.918)	Data  1.315 ( 4.354)	Loss 5.9506e-02 (1.0756e-01) 
2023-05-27 09:01:29.982654: train Epoch: [18][ 38/193]	Time  6.790 ( 4.966)	Data  6.221 ( 4.401)	Loss 2.4305e-01 (1.1103e-01) 
2023-05-27 09:01:31.790739: train Epoch: [18][ 39/193]	Time  1.808 ( 4.887)	Data  1.249 ( 4.323)	Loss 2.3140e-01 (1.1404e-01) 
2023-05-27 09:01:39.776164: train Epoch: [18][ 40/193]	Time  7.985 ( 4.962)	Data  7.426 ( 4.398)	Loss 7.6429e-02 (1.1312e-01) 
2023-05-27 09:01:41.465479: train Epoch: [18][ 41/193]	Time  1.689 ( 4.884)	Data  1.130 ( 4.320)	Loss 1.1173e-01 (1.1309e-01) 
2023-05-27 09:01:49.929814: train Epoch: [18][ 42/193]	Time  8.464 ( 4.968)	Data  7.904 ( 4.404)	Loss 6.4803e-02 (1.1197e-01) 
2023-05-27 09:01:51.432191: train Epoch: [18][ 43/193]	Time  1.502 ( 4.889)	Data  0.942 ( 4.325)	Loss 6.6617e-02 (1.1094e-01) 
2023-05-27 09:01:59.973063: train Epoch: [18][ 44/193]	Time  8.541 ( 4.970)	Data  7.982 ( 4.406)	Loss 9.8449e-02 (1.1066e-01) 
2023-05-27 09:02:01.516831: train Epoch: [18][ 45/193]	Time  1.544 ( 4.896)	Data  0.982 ( 4.332)	Loss 6.4846e-02 (1.0966e-01) 
2023-05-27 09:02:09.684046: train Epoch: [18][ 46/193]	Time  8.167 ( 4.965)	Data  7.608 ( 4.402)	Loss 1.0305e-01 (1.0952e-01) 
2023-05-27 09:02:12.415971: train Epoch: [18][ 47/193]	Time  2.732 ( 4.919)	Data  2.166 ( 4.355)	Loss 1.0620e-01 (1.0945e-01) 
2023-05-27 09:02:19.269094: train Epoch: [18][ 48/193]	Time  6.853 ( 4.958)	Data  6.280 ( 4.394)	Loss 1.5083e-01 (1.1030e-01) 
2023-05-27 09:02:21.826490: train Epoch: [18][ 49/193]	Time  2.557 ( 4.910)	Data  1.996 ( 4.346)	Loss 7.1412e-02 (1.0952e-01) 
2023-05-27 09:02:28.813227: train Epoch: [18][ 50/193]	Time  6.987 ( 4.951)	Data  6.426 ( 4.387)	Loss 5.5380e-02 (1.0846e-01) 
2023-05-27 09:02:31.821442: train Epoch: [18][ 51/193]	Time  3.008 ( 4.913)	Data  2.446 ( 4.350)	Loss 2.0703e-01 (1.1035e-01) 
2023-05-27 09:02:38.407706: train Epoch: [18][ 52/193]	Time  6.586 ( 4.945)	Data  6.023 ( 4.381)	Loss 1.3160e-01 (1.1076e-01) 
2023-05-27 09:02:41.134263: train Epoch: [18][ 53/193]	Time  2.727 ( 4.904)	Data  2.160 ( 4.340)	Loss 7.8069e-02 (1.1015e-01) 
2023-05-27 09:02:48.155856: train Epoch: [18][ 54/193]	Time  7.022 ( 4.942)	Data  6.456 ( 4.379)	Loss 7.5763e-02 (1.0953e-01) 
2023-05-27 09:02:50.761175: train Epoch: [18][ 55/193]	Time  2.605 ( 4.901)	Data  2.040 ( 4.337)	Loss 1.2530e-01 (1.0981e-01) 
2023-05-27 09:02:58.067651: train Epoch: [18][ 56/193]	Time  7.306 ( 4.943)	Data  6.699 ( 4.378)	Loss 1.7360e-01 (1.1093e-01) 
2023-05-27 09:03:00.396555: train Epoch: [18][ 57/193]	Time  2.329 ( 4.898)	Data  1.764 ( 4.333)	Loss 6.8696e-02 (1.1020e-01) 
2023-05-27 09:03:08.064391: train Epoch: [18][ 58/193]	Time  7.668 ( 4.945)	Data  7.087 ( 4.380)	Loss 1.8665e-01 (1.1149e-01) 
2023-05-27 09:03:10.546245: train Epoch: [18][ 59/193]	Time  2.482 ( 4.904)	Data  1.921 ( 4.339)	Loss 6.8538e-02 (1.1078e-01) 
2023-05-27 09:03:18.382104: train Epoch: [18][ 60/193]	Time  7.836 ( 4.952)	Data  7.277 ( 4.387)	Loss 1.1726e-01 (1.1088e-01) 
2023-05-27 09:03:21.031227: train Epoch: [18][ 61/193]	Time  2.649 ( 4.915)	Data  2.089 ( 4.350)	Loss 1.6385e-01 (1.1174e-01) 
2023-05-27 09:03:28.097568: train Epoch: [18][ 62/193]	Time  7.066 ( 4.949)	Data  6.502 ( 4.384)	Loss 8.0054e-02 (1.1124e-01) 
2023-05-27 09:03:31.091833: train Epoch: [18][ 63/193]	Time  2.994 ( 4.918)	Data  2.433 ( 4.354)	Loss 4.1562e-02 (1.1015e-01) 
2023-05-27 09:03:37.987934: train Epoch: [18][ 64/193]	Time  6.896 ( 4.949)	Data  6.288 ( 4.384)	Loss 1.7709e-01 (1.1118e-01) 
2023-05-27 09:03:41.203293: train Epoch: [18][ 65/193]	Time  3.215 ( 4.922)	Data  2.654 ( 4.357)	Loss 9.0969e-02 (1.1087e-01) 
2023-05-27 09:03:47.601460: train Epoch: [18][ 66/193]	Time  6.398 ( 4.944)	Data  5.836 ( 4.379)	Loss 1.0241e-01 (1.1074e-01) 
2023-05-27 09:03:51.099093: train Epoch: [18][ 67/193]	Time  3.498 ( 4.923)	Data  2.925 ( 4.358)	Loss 1.1983e-01 (1.1088e-01) 
2023-05-27 09:03:57.889429: train Epoch: [18][ 68/193]	Time  6.790 ( 4.950)	Data  6.224 ( 4.385)	Loss 5.2378e-02 (1.1003e-01) 
2023-05-27 09:04:01.054108: train Epoch: [18][ 69/193]	Time  3.165 ( 4.925)	Data  2.600 ( 4.360)	Loss 1.0965e-01 (1.1002e-01) 
2023-05-27 09:04:07.913837: train Epoch: [18][ 70/193]	Time  6.860 ( 4.952)	Data  6.291 ( 4.387)	Loss 1.0372e-01 (1.0994e-01) 
2023-05-27 09:04:11.350914: train Epoch: [18][ 71/193]	Time  3.437 ( 4.931)	Data  2.870 ( 4.366)	Loss 1.6873e-01 (1.1075e-01) 
2023-05-27 09:04:17.843224: train Epoch: [18][ 72/193]	Time  6.492 ( 4.952)	Data  5.921 ( 4.387)	Loss 6.8914e-02 (1.1018e-01) 
2023-05-27 09:04:21.171583: train Epoch: [18][ 73/193]	Time  3.328 ( 4.930)	Data  2.766 ( 4.365)	Loss 7.9696e-02 (1.0977e-01) 
2023-05-27 09:04:27.254288: train Epoch: [18][ 74/193]	Time  6.083 ( 4.946)	Data  5.500 ( 4.380)	Loss 1.1980e-01 (1.0990e-01) 
2023-05-27 09:04:30.679624: train Epoch: [18][ 75/193]	Time  3.425 ( 4.926)	Data  2.857 ( 4.360)	Loss 9.2575e-02 (1.0967e-01) 
2023-05-27 09:04:36.935400: train Epoch: [18][ 76/193]	Time  6.256 ( 4.943)	Data  5.682 ( 4.377)	Loss 6.4224e-02 (1.0908e-01) 
2023-05-27 09:04:40.393505: train Epoch: [18][ 77/193]	Time  3.458 ( 4.924)	Data  2.897 ( 4.358)	Loss 1.1009e-01 (1.0910e-01) 
2023-05-27 09:04:47.365318: train Epoch: [18][ 78/193]	Time  6.972 ( 4.950)	Data  6.382 ( 4.384)	Loss 8.1725e-02 (1.0875e-01) 
2023-05-27 09:04:50.079485: train Epoch: [18][ 79/193]	Time  2.714 ( 4.922)	Data  2.154 ( 4.356)	Loss 7.2675e-02 (1.0830e-01) 
2023-05-27 09:04:57.045280: train Epoch: [18][ 80/193]	Time  6.966 ( 4.947)	Data  6.395 ( 4.381)	Loss 1.1347e-01 (1.0836e-01) 
2023-05-27 09:04:59.760193: train Epoch: [18][ 81/193]	Time  2.715 ( 4.920)	Data  2.149 ( 4.354)	Loss 8.9614e-02 (1.0813e-01) 
2023-05-27 09:05:06.924423: train Epoch: [18][ 82/193]	Time  7.164 ( 4.947)	Data  6.586 ( 4.381)	Loss 1.1319e-01 (1.0819e-01) 
2023-05-27 09:05:09.183483: train Epoch: [18][ 83/193]	Time  2.259 ( 4.915)	Data  1.693 ( 4.349)	Loss 1.0362e-01 (1.0814e-01) 
2023-05-27 09:05:17.083743: train Epoch: [18][ 84/193]	Time  7.900 ( 4.950)	Data  7.336 ( 4.384)	Loss 6.4588e-02 (1.0763e-01) 
2023-05-27 09:05:19.375976: train Epoch: [18][ 85/193]	Time  2.292 ( 4.919)	Data  1.731 ( 4.353)	Loss 1.9170e-01 (1.0861e-01) 
2023-05-27 09:05:26.865496: train Epoch: [18][ 86/193]	Time  7.490 ( 4.949)	Data  6.919 ( 4.383)	Loss 1.3357e-01 (1.0889e-01) 
2023-05-27 09:05:28.994450: train Epoch: [18][ 87/193]	Time  2.129 ( 4.917)	Data  1.568 ( 4.351)	Loss 1.0490e-01 (1.0885e-01) 
2023-05-27 09:05:35.535410: train Epoch: [18][ 88/193]	Time  6.541 ( 4.935)	Data  5.965 ( 4.369)	Loss 9.8315e-02 (1.0873e-01) 
2023-05-27 09:05:37.496612: train Epoch: [18][ 89/193]	Time  1.961 ( 4.902)	Data  1.395 ( 4.336)	Loss 1.0150e-01 (1.0865e-01) 
2023-05-27 09:05:43.905789: train Epoch: [18][ 90/193]	Time  6.409 ( 4.919)	Data  5.841 ( 4.352)	Loss 1.0648e-01 (1.0862e-01) 
2023-05-27 09:05:45.943892: train Epoch: [18][ 91/193]	Time  2.038 ( 4.887)	Data  1.477 ( 4.321)	Loss 9.8784e-02 (1.0852e-01) 
2023-05-27 09:05:53.691845: train Epoch: [18][ 92/193]	Time  7.748 ( 4.918)	Data  7.171 ( 4.352)	Loss 2.0616e-01 (1.0957e-01) 
2023-05-27 09:05:55.544810: train Epoch: [18][ 93/193]	Time  1.853 ( 4.885)	Data  1.288 ( 4.319)	Loss 1.2077e-01 (1.0969e-01) 
2023-05-27 09:06:03.401927: train Epoch: [18][ 94/193]	Time  7.857 ( 4.917)	Data  7.289 ( 4.350)	Loss 1.1908e-01 (1.0979e-01) 
2023-05-27 09:06:05.681035: train Epoch: [18][ 95/193]	Time  2.279 ( 4.889)	Data  1.712 ( 4.323)	Loss 8.9979e-02 (1.0958e-01) 
2023-05-27 09:06:13.535498: train Epoch: [18][ 96/193]	Time  7.854 ( 4.920)	Data  7.283 ( 4.353)	Loss 9.6729e-02 (1.0945e-01) 
2023-05-27 09:06:15.609069: train Epoch: [18][ 97/193]	Time  2.074 ( 4.891)	Data  1.514 ( 4.324)	Loss 1.0602e-01 (1.0941e-01) 
2023-05-27 09:06:23.642294: train Epoch: [18][ 98/193]	Time  8.033 ( 4.922)	Data  7.472 ( 4.356)	Loss 7.7388e-02 (1.0909e-01) 
2023-05-27 09:06:25.637577: train Epoch: [18][ 99/193]	Time  1.995 ( 4.893)	Data  1.436 ( 4.327)	Loss 8.4042e-02 (1.0884e-01) 
2023-05-27 09:06:33.591263: train Epoch: [18][100/193]	Time  7.954 ( 4.923)	Data  7.394 ( 4.357)	Loss 1.3340e-01 (1.0908e-01) 
2023-05-27 09:06:35.674714: train Epoch: [18][101/193]	Time  2.083 ( 4.896)	Data  1.525 ( 4.330)	Loss 9.9970e-02 (1.0899e-01) 
2023-05-27 09:06:43.845294: train Epoch: [18][102/193]	Time  8.171 ( 4.927)	Data  7.609 ( 4.362)	Loss 1.5732e-01 (1.0946e-01) 
2023-05-27 09:06:45.830795: train Epoch: [18][103/193]	Time  1.986 ( 4.899)	Data  1.419 ( 4.333)	Loss 1.6590e-01 (1.1000e-01) 
2023-05-27 09:06:53.563277: train Epoch: [18][104/193]	Time  7.732 ( 4.926)	Data  7.172 ( 4.360)	Loss 1.0957e-01 (1.1000e-01) 
2023-05-27 09:06:55.914564: train Epoch: [18][105/193]	Time  2.351 ( 4.902)	Data  1.772 ( 4.336)	Loss 1.9250e-01 (1.1078e-01) 
2023-05-27 09:07:03.122907: train Epoch: [18][106/193]	Time  7.208 ( 4.923)	Data  6.642 ( 4.357)	Loss 5.2356e-02 (1.1023e-01) 
2023-05-27 09:07:05.908614: train Epoch: [18][107/193]	Time  2.786 ( 4.904)	Data  2.217 ( 4.338)	Loss 2.0943e-01 (1.1115e-01) 
2023-05-27 09:07:12.832758: train Epoch: [18][108/193]	Time  6.924 ( 4.922)	Data  6.358 ( 4.356)	Loss 1.3822e-01 (1.1140e-01) 
2023-05-27 09:07:16.257003: train Epoch: [18][109/193]	Time  3.424 ( 4.909)	Data  2.859 ( 4.343)	Loss 1.4722e-01 (1.1172e-01) 
2023-05-27 09:07:22.813323: train Epoch: [18][110/193]	Time  6.556 ( 4.923)	Data  5.994 ( 4.357)	Loss 6.9425e-02 (1.1134e-01) 
2023-05-27 09:07:26.246246: train Epoch: [18][111/193]	Time  3.433 ( 4.910)	Data  2.869 ( 4.344)	Loss 1.3666e-01 (1.1157e-01) 
2023-05-27 09:07:32.575465: train Epoch: [18][112/193]	Time  6.329 ( 4.923)	Data  5.768 ( 4.357)	Loss 6.0659e-02 (1.1112e-01) 
2023-05-27 09:07:36.107589: train Epoch: [18][113/193]	Time  3.532 ( 4.910)	Data  2.972 ( 4.345)	Loss 9.5974e-02 (1.1099e-01) 
2023-05-27 09:07:43.052660: train Epoch: [18][114/193]	Time  6.945 ( 4.928)	Data  6.372 ( 4.362)	Loss 1.3934e-01 (1.1123e-01) 
2023-05-27 09:07:46.333997: train Epoch: [18][115/193]	Time  3.281 ( 4.914)	Data  2.707 ( 4.348)	Loss 1.0157e-01 (1.1115e-01) 
2023-05-27 09:07:53.350738: train Epoch: [18][116/193]	Time  7.017 ( 4.932)	Data  6.456 ( 4.366)	Loss 9.1000e-02 (1.1098e-01) 
2023-05-27 09:07:56.397479: train Epoch: [18][117/193]	Time  3.047 ( 4.916)	Data  2.485 ( 4.350)	Loss 1.2488e-01 (1.1109e-01) 
2023-05-27 09:08:02.905356: train Epoch: [18][118/193]	Time  6.508 ( 4.929)	Data  5.944 ( 4.363)	Loss 9.1117e-02 (1.1093e-01) 
2023-05-27 09:08:06.287261: train Epoch: [18][119/193]	Time  3.382 ( 4.916)	Data  2.806 ( 4.350)	Loss 6.0166e-02 (1.1050e-01) 
2023-05-27 09:08:13.453983: train Epoch: [18][120/193]	Time  7.167 ( 4.935)	Data  6.593 ( 4.369)	Loss 1.8873e-01 (1.1115e-01) 
2023-05-27 09:08:15.808652: train Epoch: [18][121/193]	Time  2.355 ( 4.914)	Data  1.788 ( 4.348)	Loss 1.2493e-01 (1.1126e-01) 
2023-05-27 09:08:23.142182: train Epoch: [18][122/193]	Time  7.334 ( 4.934)	Data  6.765 ( 4.367)	Loss 4.9783e-02 (1.1076e-01) 
2023-05-27 09:08:25.570998: train Epoch: [18][123/193]	Time  2.429 ( 4.913)	Data  1.868 ( 4.347)	Loss 1.6882e-01 (1.1123e-01) 
2023-05-27 09:08:33.512444: train Epoch: [18][124/193]	Time  7.941 ( 4.938)	Data  7.373 ( 4.371)	Loss 6.8955e-02 (1.1089e-01) 
2023-05-27 09:08:35.698139: train Epoch: [18][125/193]	Time  2.186 ( 4.916)	Data  1.626 ( 4.350)	Loss 2.1105e-01 (1.1169e-01) 
2023-05-27 09:08:43.012080: train Epoch: [18][126/193]	Time  7.314 ( 4.935)	Data  6.749 ( 4.369)	Loss 1.0136e-01 (1.1161e-01) 
2023-05-27 09:08:45.295217: train Epoch: [18][127/193]	Time  2.283 ( 4.914)	Data  1.713 ( 4.348)	Loss 1.0152e-01 (1.1153e-01) 
2023-05-27 09:08:52.953303: train Epoch: [18][128/193]	Time  7.658 ( 4.935)	Data  7.085 ( 4.369)	Loss 3.9798e-01 (1.1375e-01) 
2023-05-27 09:08:55.139106: train Epoch: [18][129/193]	Time  2.186 ( 4.914)	Data  1.612 ( 4.348)	Loss 7.9161e-02 (1.1348e-01) 
2023-05-27 09:09:03.553874: train Epoch: [18][130/193]	Time  8.415 ( 4.941)	Data  7.822 ( 4.374)	Loss 7.6873e-02 (1.1320e-01) 
2023-05-27 09:09:05.172358: train Epoch: [18][131/193]	Time  1.618 ( 4.916)	Data  1.053 ( 4.349)	Loss 2.1697e-01 (1.1399e-01) 
2023-05-27 09:09:13.889072: train Epoch: [18][132/193]	Time  8.717 ( 4.944)	Data  8.151 ( 4.378)	Loss 2.7972e-01 (1.1524e-01) 
2023-05-27 09:09:15.288722: train Epoch: [18][133/193]	Time  1.400 ( 4.918)	Data  0.827 ( 4.351)	Loss 1.7501e-01 (1.1568e-01) 
2023-05-27 09:09:24.200258: train Epoch: [18][134/193]	Time  8.912 ( 4.947)	Data  8.339 ( 4.381)	Loss 1.3533e-01 (1.1583e-01) 
2023-05-27 09:09:25.043890: train Epoch: [18][135/193]	Time  0.844 ( 4.917)	Data  0.277 ( 4.351)	Loss 2.3242e-01 (1.1668e-01) 
2023-05-27 09:09:33.997679: train Epoch: [18][136/193]	Time  8.954 ( 4.947)	Data  8.394 ( 4.380)	Loss 6.1263e-02 (1.1628e-01) 
2023-05-27 09:09:34.889503: train Epoch: [18][137/193]	Time  0.892 ( 4.917)	Data  0.331 ( 4.351)	Loss 1.6477e-01 (1.1663e-01) 
2023-05-27 09:09:44.127939: train Epoch: [18][138/193]	Time  9.238 ( 4.948)	Data  8.672 ( 4.382)	Loss 1.2071e-01 (1.1666e-01) 
2023-05-27 09:09:44.700215: train Epoch: [18][139/193]	Time  0.572 ( 4.917)	Data  0.001 ( 4.351)	Loss 8.6753e-02 (1.1645e-01) 
2023-05-27 09:09:53.855432: train Epoch: [18][140/193]	Time  9.155 ( 4.947)	Data  8.590 ( 4.381)	Loss 1.4082e-01 (1.1662e-01) 
2023-05-27 09:09:54.483752: train Epoch: [18][141/193]	Time  0.628 ( 4.917)	Data  0.062 ( 4.350)	Loss 1.3893e-01 (1.1678e-01) 
2023-05-27 09:10:03.755160: train Epoch: [18][142/193]	Time  9.271 ( 4.947)	Data  8.708 ( 4.381)	Loss 1.3933e-01 (1.1693e-01) 
2023-05-27 09:10:04.319857: train Epoch: [18][143/193]	Time  0.565 ( 4.917)	Data  0.001 ( 4.350)	Loss 8.2134e-02 (1.1669e-01) 
2023-05-27 09:10:13.834925: train Epoch: [18][144/193]	Time  9.515 ( 4.948)	Data  8.941 ( 4.382)	Loss 1.4718e-01 (1.1690e-01) 
2023-05-27 09:10:14.399317: train Epoch: [18][145/193]	Time  0.564 ( 4.918)	Data  0.001 ( 4.352)	Loss 2.5074e-01 (1.1782e-01) 
2023-05-27 09:10:23.421343: train Epoch: [18][146/193]	Time  9.022 ( 4.946)	Data  8.462 ( 4.380)	Loss 1.9896e-01 (1.1837e-01) 
2023-05-27 09:10:24.036367: train Epoch: [18][147/193]	Time  0.615 ( 4.917)	Data  0.047 ( 4.351)	Loss 9.3384e-02 (1.1820e-01) 
2023-05-27 09:10:33.130938: train Epoch: [18][148/193]	Time  9.095 ( 4.945)	Data  8.528 ( 4.379)	Loss 1.7591e-01 (1.1859e-01) 
2023-05-27 09:10:34.458178: train Epoch: [18][149/193]	Time  1.327 ( 4.921)	Data  0.759 ( 4.355)	Loss 2.3394e-01 (1.1936e-01) 
2023-05-27 09:10:43.019851: train Epoch: [18][150/193]	Time  8.562 ( 4.945)	Data  7.993 ( 4.379)	Loss 1.4327e-01 (1.1952e-01) 
2023-05-27 09:10:44.354201: train Epoch: [18][151/193]	Time  1.334 ( 4.921)	Data  0.769 ( 4.355)	Loss 9.4043e-02 (1.1935e-01) 
2023-05-27 09:10:52.862562: train Epoch: [18][152/193]	Time  8.508 ( 4.945)	Data  7.944 ( 4.378)	Loss 9.6867e-02 (1.1920e-01) 
2023-05-27 09:10:54.411673: train Epoch: [18][153/193]	Time  1.549 ( 4.923)	Data  0.961 ( 4.356)	Loss 8.8340e-02 (1.1900e-01) 
2023-05-27 09:11:02.876258: train Epoch: [18][154/193]	Time  8.465 ( 4.946)	Data  7.897 ( 4.379)	Loss 9.2736e-02 (1.1883e-01) 
2023-05-27 09:11:03.995171: train Epoch: [18][155/193]	Time  1.119 ( 4.921)	Data  0.561 ( 4.355)	Loss 1.0047e-01 (1.1872e-01) 
2023-05-27 09:11:12.437509: train Epoch: [18][156/193]	Time  8.442 ( 4.943)	Data  7.840 ( 4.377)	Loss 1.9708e-01 (1.1921e-01) 
2023-05-27 09:11:13.850804: train Epoch: [18][157/193]	Time  1.413 ( 4.921)	Data  0.849 ( 4.354)	Loss 1.0390e-01 (1.1912e-01) 
2023-05-27 09:11:22.547247: train Epoch: [18][158/193]	Time  8.696 ( 4.945)	Data  8.110 ( 4.378)	Loss 1.5579e-01 (1.1935e-01) 
2023-05-27 09:11:23.277795: train Epoch: [18][159/193]	Time  0.731 ( 4.918)	Data  0.171 ( 4.352)	Loss 7.7421e-02 (1.1909e-01) 
2023-05-27 09:11:32.635546: train Epoch: [18][160/193]	Time  9.358 ( 4.946)	Data  8.791 ( 4.379)	Loss 1.3282e-01 (1.1917e-01) 
2023-05-27 09:11:33.251024: train Epoch: [18][161/193]	Time  0.615 ( 4.919)	Data  0.057 ( 4.353)	Loss 8.8046e-02 (1.1898e-01) 
2023-05-27 09:11:42.577487: train Epoch: [18][162/193]	Time  9.326 ( 4.946)	Data  8.723 ( 4.379)	Loss 1.2964e-01 (1.1904e-01) 
2023-05-27 09:11:43.218133: train Epoch: [18][163/193]	Time  0.641 ( 4.920)	Data  0.078 ( 4.353)	Loss 6.9200e-02 (1.1874e-01) 
2023-05-27 09:11:52.198206: train Epoch: [18][164/193]	Time  8.980 ( 4.945)	Data  8.414 ( 4.378)	Loss 1.1533e-01 (1.1872e-01) 
2023-05-27 09:11:53.179557: train Epoch: [18][165/193]	Time  0.981 ( 4.921)	Data  0.423 ( 4.354)	Loss 2.6237e-01 (1.1959e-01) 
2023-05-27 09:12:02.654682: train Epoch: [18][166/193]	Time  9.475 ( 4.948)	Data  8.916 ( 4.381)	Loss 1.9103e-01 (1.2001e-01) 
2023-05-27 09:12:03.214091: train Epoch: [18][167/193]	Time  0.559 ( 4.922)	Data  0.001 ( 4.355)	Loss 1.2588e-01 (1.2005e-01) 
2023-05-27 09:12:13.306288: train Epoch: [18][168/193]	Time 10.092 ( 4.953)	Data  9.534 ( 4.386)	Loss 6.8812e-02 (1.1974e-01) 
2023-05-27 09:12:13.873203: train Epoch: [18][169/193]	Time  0.567 ( 4.927)	Data  0.001 ( 4.360)	Loss 1.1638e-01 (1.1973e-01) 
2023-05-27 09:12:23.262526: train Epoch: [18][170/193]	Time  9.389 ( 4.953)	Data  8.830 ( 4.386)	Loss 8.3509e-02 (1.1951e-01) 
2023-05-27 09:12:23.825146: train Epoch: [18][171/193]	Time  0.563 ( 4.927)	Data  0.001 ( 4.361)	Loss 1.0998e-01 (1.1946e-01) 
2023-05-27 09:12:32.976881: train Epoch: [18][172/193]	Time  9.152 ( 4.952)	Data  8.583 ( 4.385)	Loss 1.4806e-01 (1.1962e-01) 
2023-05-27 09:12:33.536422: train Epoch: [18][173/193]	Time  0.560 ( 4.927)	Data  0.001 ( 4.360)	Loss 1.1379e-01 (1.1959e-01) 
2023-05-27 09:12:42.886279: train Epoch: [18][174/193]	Time  9.350 ( 4.952)	Data  8.790 ( 4.385)	Loss 7.5308e-02 (1.1934e-01) 
2023-05-27 09:12:43.445851: train Epoch: [18][175/193]	Time  0.560 ( 4.927)	Data  0.001 ( 4.360)	Loss 5.8848e-02 (1.1899e-01) 
2023-05-27 09:12:52.661423: train Epoch: [18][176/193]	Time  9.216 ( 4.951)	Data  8.657 ( 4.385)	Loss 2.0090e-01 (1.1946e-01) 
2023-05-27 09:12:53.221526: train Epoch: [18][177/193]	Time  0.560 ( 4.926)	Data  0.001 ( 4.360)	Loss 2.5234e-01 (1.2020e-01) 
2023-05-27 09:13:02.732244: train Epoch: [18][178/193]	Time  9.511 ( 4.952)	Data  8.951 ( 4.386)	Loss 1.2826e-01 (1.2025e-01) 
2023-05-27 09:13:03.294485: train Epoch: [18][179/193]	Time  0.562 ( 4.928)	Data  0.001 ( 4.361)	Loss 9.5197e-02 (1.2011e-01) 
2023-05-27 09:13:12.728526: train Epoch: [18][180/193]	Time  9.434 ( 4.953)	Data  8.869 ( 4.386)	Loss 9.8333e-02 (1.1999e-01) 
2023-05-27 09:13:13.297262: train Epoch: [18][181/193]	Time  0.569 ( 4.928)	Data  0.001 ( 4.362)	Loss 1.6841e-01 (1.2025e-01) 
2023-05-27 09:13:22.383429: train Epoch: [18][182/193]	Time  9.086 ( 4.951)	Data  8.515 ( 4.385)	Loss 1.7403e-01 (1.2055e-01) 
2023-05-27 09:13:22.957661: train Epoch: [18][183/193]	Time  0.574 ( 4.927)	Data  0.001 ( 4.361)	Loss 1.2768e-01 (1.2059e-01) 
2023-05-27 09:13:32.217816: train Epoch: [18][184/193]	Time  9.260 ( 4.951)	Data  8.698 ( 4.384)	Loss 8.8117e-02 (1.2041e-01) 
2023-05-27 09:13:32.781554: train Epoch: [18][185/193]	Time  0.564 ( 4.927)	Data  0.001 ( 4.361)	Loss 8.0601e-02 (1.2020e-01) 
2023-05-27 09:13:41.765765: train Epoch: [18][186/193]	Time  8.984 ( 4.949)	Data  8.410 ( 4.383)	Loss 9.9079e-02 (1.2008e-01) 
2023-05-27 09:13:42.509755: train Epoch: [18][187/193]	Time  0.744 ( 4.927)	Data  0.185 ( 4.360)	Loss 2.2987e-01 (1.2067e-01) 
2023-05-27 09:13:51.458815: train Epoch: [18][188/193]	Time  8.949 ( 4.948)	Data  8.380 ( 4.381)	Loss 1.4766e-01 (1.2081e-01) 
2023-05-27 09:13:52.068326: train Epoch: [18][189/193]	Time  0.610 ( 4.925)	Data  0.050 ( 4.359)	Loss 9.2930e-02 (1.2066e-01) 
2023-05-27 09:14:01.109453: train Epoch: [18][190/193]	Time  9.041 ( 4.947)	Data  8.474 ( 4.380)	Loss 8.4326e-02 (1.2047e-01) 
2023-05-27 09:14:01.935803: train Epoch: [18][191/193]	Time  0.826 ( 4.925)	Data  0.266 ( 4.359)	Loss 1.2920e-01 (1.2052e-01) 
2023-05-27 09:14:09.515393: train Epoch: [18][192/193]	Time  7.580 ( 4.939)	Data  7.005 ( 4.372)	Loss 8.3763e-02 (1.2033e-01) 
2023-05-27 09:14:09.644113: Train Epoch done in 953.3238011439971 s 
2023-05-27 09:14:16.437651: val Epoch: [18][ 0/72]	Time  6.032 ( 6.032)	Data  5.833 ( 5.833)	Loss 3.2275e-01 (3.2275e-01) 
2023-05-27 09:14:16.546688: val Epoch: [18][ 1/72]	Time  0.109 ( 3.070)	Data  0.002 ( 2.918)	Loss 1.4705e-01 (2.3490e-01) 
2023-05-27 09:14:21.486507: val Epoch: [18][ 2/72]	Time  4.940 ( 3.694)	Data  4.779 ( 3.538)	Loss 6.5547e-02 (1.7845e-01) 
2023-05-27 09:14:21.659077: val Epoch: [18][ 3/72]	Time  0.173 ( 2.813)	Data  0.001 ( 2.654)	Loss 5.2330e-01 (2.6466e-01) 
2023-05-27 09:14:26.695147: val Epoch: [18][ 4/72]	Time  5.036 ( 3.258)	Data  4.920 ( 3.107)	Loss 1.2971e-01 (2.3767e-01) 
2023-05-27 09:14:26.806815: val Epoch: [18][ 5/72]	Time  0.112 ( 2.734)	Data  0.001 ( 2.589)	Loss 1.2540e-01 (2.1896e-01) 
2023-05-27 09:14:31.674555: val Epoch: [18][ 6/72]	Time  4.868 ( 3.038)	Data  4.739 ( 2.896)	Loss 1.5413e-01 (2.0970e-01) 
2023-05-27 09:14:31.793990: val Epoch: [18][ 7/72]	Time  0.119 ( 2.674)	Data  0.001 ( 2.534)	Loss 2.3130e-01 (2.1240e-01) 
2023-05-27 09:14:36.681607: val Epoch: [18][ 8/72]	Time  4.888 ( 2.920)	Data  4.779 ( 2.784)	Loss 9.5601e-02 (1.9942e-01) 
2023-05-27 09:14:36.792675: val Epoch: [18][ 9/72]	Time  0.111 ( 2.639)	Data  0.001 ( 2.505)	Loss 1.8977e-01 (1.9846e-01) 
2023-05-27 09:14:41.734890: val Epoch: [18][10/72]	Time  4.942 ( 2.848)	Data  4.796 ( 2.714)	Loss 4.9832e-02 (1.8494e-01) 
2023-05-27 09:14:41.849702: val Epoch: [18][11/72]	Time  0.115 ( 2.620)	Data  0.001 ( 2.488)	Loss 4.9268e-01 (2.1059e-01) 
2023-05-27 09:14:46.527007: val Epoch: [18][12/72]	Time  4.677 ( 2.779)	Data  4.567 ( 2.648)	Loss 9.4483e-02 (2.0166e-01) 
2023-05-27 09:14:46.645081: val Epoch: [18][13/72]	Time  0.118 ( 2.589)	Data  0.001 ( 2.458)	Loss 4.6706e-01 (2.2061e-01) 
2023-05-27 09:14:51.689662: val Epoch: [18][14/72]	Time  5.045 ( 2.752)	Data  4.929 ( 2.623)	Loss 1.9160e-01 (2.1868e-01) 
2023-05-27 09:14:51.802282: val Epoch: [18][15/72]	Time  0.113 ( 2.587)	Data  0.001 ( 2.459)	Loss 1.7776e-01 (2.1612e-01) 
2023-05-27 09:14:56.872015: val Epoch: [18][16/72]	Time  5.070 ( 2.733)	Data  4.947 ( 2.606)	Loss 3.1413e-01 (2.2189e-01) 
2023-05-27 09:14:56.982116: val Epoch: [18][17/72]	Time  0.110 ( 2.588)	Data  0.001 ( 2.461)	Loss 1.6455e-01 (2.1870e-01) 
2023-05-27 09:15:01.867911: val Epoch: [18][18/72]	Time  4.886 ( 2.709)	Data  4.779 ( 2.583)	Loss 3.1513e-01 (2.2378e-01) 
2023-05-27 09:15:01.973193: val Epoch: [18][19/72]	Time  0.105 ( 2.578)	Data  0.000 ( 2.454)	Loss 9.0169e-02 (2.1710e-01) 
2023-05-27 09:15:06.934537: val Epoch: [18][20/72]	Time  4.961 ( 2.692)	Data  4.856 ( 2.568)	Loss 1.6370e-01 (2.1455e-01) 
2023-05-27 09:15:07.043471: val Epoch: [18][21/72]	Time  0.109 ( 2.574)	Data  0.001 ( 2.451)	Loss 2.3600e-01 (2.1553e-01) 
2023-05-27 09:15:12.117117: val Epoch: [18][22/72]	Time  5.074 ( 2.683)	Data  4.953 ( 2.560)	Loss 1.4325e-01 (2.1239e-01) 
2023-05-27 09:15:12.362259: val Epoch: [18][23/72]	Time  0.245 ( 2.582)	Data  0.108 ( 2.458)	Loss 8.9434e-02 (2.0726e-01) 
2023-05-27 09:15:17.532667: val Epoch: [18][24/72]	Time  5.170 ( 2.685)	Data  5.063 ( 2.562)	Loss 1.6282e-01 (2.0549e-01) 
2023-05-27 09:15:17.640542: val Epoch: [18][25/72]	Time  0.108 ( 2.586)	Data  0.001 ( 2.464)	Loss 7.6378e-02 (2.0052e-01) 
2023-05-27 09:15:22.902189: val Epoch: [18][26/72]	Time  5.262 ( 2.685)	Data  5.043 ( 2.559)	Loss 1.3209e-01 (1.9799e-01) 
2023-05-27 09:15:23.053812: val Epoch: [18][27/72]	Time  0.152 ( 2.595)	Data  0.001 ( 2.468)	Loss 7.2114e-02 (1.9349e-01) 
2023-05-27 09:15:27.843577: val Epoch: [18][28/72]	Time  4.790 ( 2.670)	Data  4.650 ( 2.543)	Loss 7.9756e-02 (1.8957e-01) 
2023-05-27 09:15:27.967610: val Epoch: [18][29/72]	Time  0.124 ( 2.585)	Data  0.001 ( 2.458)	Loss 3.0080e-01 (1.9328e-01) 
2023-05-27 09:15:32.983952: val Epoch: [18][30/72]	Time  5.016 ( 2.664)	Data  4.865 ( 2.536)	Loss 2.4279e-01 (1.9487e-01) 
2023-05-27 09:15:33.092437: val Epoch: [18][31/72]	Time  0.108 ( 2.584)	Data  0.001 ( 2.457)	Loss 1.6755e-01 (1.9402e-01) 
2023-05-27 09:15:37.695291: val Epoch: [18][32/72]	Time  4.603 ( 2.645)	Data  4.491 ( 2.518)	Loss 2.2276e-01 (1.9489e-01) 
2023-05-27 09:15:38.105101: val Epoch: [18][33/72]	Time  0.410 ( 2.579)	Data  0.251 ( 2.452)	Loss 6.2661e-02 (1.9100e-01) 
2023-05-27 09:15:42.933335: val Epoch: [18][34/72]	Time  4.828 ( 2.644)	Data  4.628 ( 2.514)	Loss 8.6271e-02 (1.8801e-01) 
2023-05-27 09:15:43.115930: val Epoch: [18][35/72]	Time  0.183 ( 2.575)	Data  0.066 ( 2.446)	Loss 2.2881e-01 (1.8914e-01) 
2023-05-27 09:15:47.680544: val Epoch: [18][36/72]	Time  4.565 ( 2.629)	Data  4.458 ( 2.500)	Loss 2.3561e-01 (1.9040e-01) 
2023-05-27 09:15:48.247746: val Epoch: [18][37/72]	Time  0.567 ( 2.575)	Data  0.452 ( 2.446)	Loss 7.4464e-02 (1.8735e-01) 
2023-05-27 09:15:52.450017: val Epoch: [18][38/72]	Time  4.202 ( 2.617)	Data  4.083 ( 2.488)	Loss 6.7646e-02 (1.8428e-01) 
2023-05-27 09:15:53.457002: val Epoch: [18][39/72]	Time  1.007 ( 2.576)	Data  0.863 ( 2.448)	Loss 2.1892e-01 (1.8514e-01) 
2023-05-27 09:15:57.397020: val Epoch: [18][40/72]	Time  3.940 ( 2.610)	Data  3.825 ( 2.481)	Loss 1.1148e-01 (1.8335e-01) 
2023-05-27 09:15:58.515393: val Epoch: [18][41/72]	Time  1.118 ( 2.574)	Data  1.008 ( 2.446)	Loss 1.5799e-01 (1.8274e-01) 
2023-05-27 09:16:02.234325: val Epoch: [18][42/72]	Time  3.719 ( 2.601)	Data  3.600 ( 2.473)	Loss 9.5029e-02 (1.8070e-01) 
2023-05-27 09:16:03.482100: val Epoch: [18][43/72]	Time  1.248 ( 2.570)	Data  1.141 ( 2.443)	Loss 9.5873e-02 (1.7878e-01) 
2023-05-27 09:16:07.430601: val Epoch: [18][44/72]	Time  3.949 ( 2.601)	Data  3.834 ( 2.474)	Loss 1.9490e-01 (1.7913e-01) 
2023-05-27 09:16:08.385436: val Epoch: [18][45/72]	Time  0.955 ( 2.565)	Data  0.845 ( 2.438)	Loss 9.9930e-02 (1.7741e-01) 
2023-05-27 09:16:12.611143: val Epoch: [18][46/72]	Time  4.226 ( 2.600)	Data  4.111 ( 2.474)	Loss 1.4331e-01 (1.7669e-01) 
2023-05-27 09:16:13.593096: val Epoch: [18][47/72]	Time  0.982 ( 2.566)	Data  0.875 ( 2.441)	Loss 9.4324e-02 (1.7497e-01) 
2023-05-27 09:16:17.790016: val Epoch: [18][48/72]	Time  4.197 ( 2.600)	Data  4.090 ( 2.474)	Loss 1.9919e-01 (1.7546e-01) 
2023-05-27 09:16:18.463848: val Epoch: [18][49/72]	Time  0.674 ( 2.561)	Data  0.552 ( 2.436)	Loss 6.0967e-02 (1.7317e-01) 
2023-05-27 09:16:22.939346: val Epoch: [18][50/72]	Time  4.475 ( 2.599)	Data  4.351 ( 2.473)	Loss 9.6366e-02 (1.7167e-01) 
2023-05-27 09:16:23.399734: val Epoch: [18][51/72]	Time  0.460 ( 2.558)	Data  0.327 ( 2.432)	Loss 5.3004e-02 (1.6939e-01) 
2023-05-27 09:16:28.026971: val Epoch: [18][52/72]	Time  4.627 ( 2.597)	Data  4.522 ( 2.471)	Loss 3.5000e-01 (1.7279e-01) 
2023-05-27 09:16:28.234593: val Epoch: [18][53/72]	Time  0.208 ( 2.552)	Data  0.100 ( 2.428)	Loss 6.8924e-02 (1.7087e-01) 
2023-05-27 09:16:33.305240: val Epoch: [18][54/72]	Time  5.071 ( 2.598)	Data  4.951 ( 2.473)	Loss 1.2644e-01 (1.7006e-01) 
2023-05-27 09:16:33.416820: val Epoch: [18][55/72]	Time  0.112 ( 2.554)	Data  0.001 ( 2.429)	Loss 1.7292e-01 (1.7011e-01) 
2023-05-27 09:16:38.041750: val Epoch: [18][56/72]	Time  4.625 ( 2.590)	Data  4.518 ( 2.466)	Loss 3.5379e-01 (1.7334e-01) 
2023-05-27 09:16:38.151183: val Epoch: [18][57/72]	Time  0.109 ( 2.547)	Data  0.001 ( 2.423)	Loss 1.5124e-01 (1.7296e-01) 
2023-05-27 09:16:43.191838: val Epoch: [18][58/72]	Time  5.041 ( 2.590)	Data  4.924 ( 2.466)	Loss 7.3157e-02 (1.7126e-01) 
2023-05-27 09:16:43.304178: val Epoch: [18][59/72]	Time  0.112 ( 2.548)	Data  0.001 ( 2.425)	Loss 6.7808e-02 (1.6954e-01) 
2023-05-27 09:16:48.644913: val Epoch: [18][60/72]	Time  5.341 ( 2.594)	Data  5.236 ( 2.471)	Loss 2.1681e-01 (1.7031e-01) 
2023-05-27 09:16:48.749631: val Epoch: [18][61/72]	Time  0.105 ( 2.554)	Data  0.000 ( 2.431)	Loss 1.6867e-01 (1.7029e-01) 
2023-05-27 09:16:53.579259: val Epoch: [18][62/72]	Time  4.830 ( 2.590)	Data  4.695 ( 2.467)	Loss 1.2655e-01 (1.6959e-01) 
2023-05-27 09:16:53.683928: val Epoch: [18][63/72]	Time  0.105 ( 2.551)	Data  0.001 ( 2.428)	Loss 5.0994e-01 (1.7491e-01) 
2023-05-27 09:16:58.849475: val Epoch: [18][64/72]	Time  5.166 ( 2.591)	Data  5.050 ( 2.469)	Loss 1.2256e-01 (1.7411e-01) 
2023-05-27 09:16:58.966447: val Epoch: [18][65/72]	Time  0.117 ( 2.554)	Data  0.001 ( 2.431)	Loss 6.7990e-02 (1.7250e-01) 
2023-05-27 09:17:03.991469: val Epoch: [18][66/72]	Time  5.025 ( 2.591)	Data  4.918 ( 2.468)	Loss 3.9201e-01 (1.7578e-01) 
2023-05-27 09:17:04.098943: val Epoch: [18][67/72]	Time  0.107 ( 2.554)	Data  0.001 ( 2.432)	Loss 7.1272e-02 (1.7424e-01) 
2023-05-27 09:17:09.118044: val Epoch: [18][68/72]	Time  5.019 ( 2.590)	Data  4.908 ( 2.468)	Loss 2.2273e-01 (1.7494e-01) 
2023-05-27 09:17:09.227163: val Epoch: [18][69/72]	Time  0.109 ( 2.555)	Data  0.000 ( 2.433)	Loss 3.5579e-01 (1.7752e-01) 
2023-05-27 09:17:14.067148: val Epoch: [18][70/72]	Time  4.840 ( 2.587)	Data  4.732 ( 2.465)	Loss 1.5769e-01 (1.7725e-01) 
2023-05-27 09:17:14.174712: val Epoch: [18][71/72]	Time  0.108 ( 2.552)	Data  0.000 ( 2.431)	Loss 6.6032e-01 (1.8395e-01) 
2023-05-27 09:17:14.454581: Epoch 18 :Val : ['ET : 0.6744002103805542', 'TC : 0.7020744681358337', 'WT : 0.7671559453010559'] 
2023-05-27 09:17:14.457281: Epoch 18 :Val : ['ET : 0.6744002103805542', 'TC : 0.7020744681358337', 'WT : 0.7671559453010559'] 
2023-05-27 09:17:14.459368: Val epoch done in 184.81525757501367 s 
2023-05-27 09:17:14.465898: Batches per epoch:  193 
2023-05-27 09:17:25.224005: train Epoch: [19][  0/193]	Time 10.758 (10.758)	Data 10.147 (10.147)	Loss 9.9270e-02 (9.9270e-02) 
2023-05-27 09:17:25.795682: train Epoch: [19][  1/193]	Time  0.572 ( 5.665)	Data  0.001 ( 5.074)	Loss 5.7877e-02 (7.8573e-02) 
2023-05-27 09:17:35.265643: train Epoch: [19][  2/193]	Time  9.470 ( 6.933)	Data  8.898 ( 6.349)	Loss 1.0414e-01 (8.7097e-02) 
2023-05-27 09:17:35.836351: train Epoch: [19][  3/193]	Time  0.571 ( 5.343)	Data  0.001 ( 4.762)	Loss 2.9076e-01 (1.3801e-01) 
2023-05-27 09:17:45.460247: train Epoch: [19][  4/193]	Time  9.624 ( 6.199)	Data  9.053 ( 5.620)	Loss 1.0051e-01 (1.3051e-01) 
2023-05-27 09:17:46.032182: train Epoch: [19][  5/193]	Time  0.572 ( 5.261)	Data  0.001 ( 4.683)	Loss 9.2172e-02 (1.2412e-01) 
2023-05-27 09:17:55.700770: train Epoch: [19][  6/193]	Time  9.669 ( 5.891)	Data  9.092 ( 5.313)	Loss 1.4337e-01 (1.2687e-01) 
2023-05-27 09:17:56.265395: train Epoch: [19][  7/193]	Time  0.565 ( 5.225)	Data  0.001 ( 4.649)	Loss 9.9066e-02 (1.2340e-01) 
2023-05-27 09:18:05.437726: train Epoch: [19][  8/193]	Time  9.172 ( 5.664)	Data  8.601 ( 5.088)	Loss 1.4658e-01 (1.2597e-01) 
2023-05-27 09:18:06.010520: train Epoch: [19][  9/193]	Time  0.573 ( 5.154)	Data  0.001 ( 4.579)	Loss 1.1038e-01 (1.2441e-01) 
2023-05-27 09:18:15.124458: train Epoch: [19][ 10/193]	Time  9.114 ( 5.514)	Data  8.543 ( 4.940)	Loss 1.3381e-01 (1.2527e-01) 
2023-05-27 09:18:15.694209: train Epoch: [19][ 11/193]	Time  0.570 ( 5.102)	Data  0.001 ( 4.528)	Loss 9.7109e-02 (1.2292e-01) 
2023-05-27 09:18:25.562182: train Epoch: [19][ 12/193]	Time  9.868 ( 5.469)	Data  9.295 ( 4.895)	Loss 9.1863e-02 (1.2053e-01) 
2023-05-27 09:18:26.189101: train Epoch: [19][ 13/193]	Time  0.627 ( 5.123)	Data  0.001 ( 4.545)	Loss 2.9035e-01 (1.3266e-01) 
2023-05-27 09:18:35.474366: train Epoch: [19][ 14/193]	Time  9.285 ( 5.401)	Data  8.710 ( 4.823)	Loss 1.6686e-01 (1.3494e-01) 
2023-05-27 09:18:36.080455: train Epoch: [19][ 15/193]	Time  0.606 ( 5.101)	Data  0.001 ( 4.522)	Loss 2.8125e-01 (1.4409e-01) 
2023-05-27 09:18:45.008814: train Epoch: [19][ 16/193]	Time  8.928 ( 5.326)	Data  8.354 ( 4.747)	Loss 1.0175e-01 (1.4160e-01) 
2023-05-27 09:18:45.580414: train Epoch: [19][ 17/193]	Time  0.572 ( 5.062)	Data  0.001 ( 4.483)	Loss 9.5142e-02 (1.3901e-01) 
2023-05-27 09:18:53.721434: train Epoch: [19][ 18/193]	Time  8.141 ( 5.224)	Data  7.569 ( 4.646)	Loss 9.4583e-02 (1.3668e-01) 
2023-05-27 09:18:54.290841: train Epoch: [19][ 19/193]	Time  0.569 ( 4.991)	Data  0.001 ( 4.414)	Loss 1.1931e-01 (1.3581e-01) 
2023-05-27 09:19:03.426754: train Epoch: [19][ 20/193]	Time  9.136 ( 5.189)	Data  8.572 ( 4.612)	Loss 1.6730e-01 (1.3731e-01) 
2023-05-27 09:19:03.991559: train Epoch: [19][ 21/193]	Time  0.565 ( 4.978)	Data  0.001 ( 4.402)	Loss 1.2209e-01 (1.3662e-01) 
2023-05-27 09:19:13.385609: train Epoch: [19][ 22/193]	Time  9.394 ( 5.170)	Data  8.830 ( 4.594)	Loss 2.7464e-01 (1.4262e-01) 
2023-05-27 09:19:13.950198: train Epoch: [19][ 23/193]	Time  0.565 ( 4.978)	Data  0.001 ( 4.403)	Loss 7.5886e-02 (1.3984e-01) 
2023-05-27 09:19:23.088177: train Epoch: [19][ 24/193]	Time  9.138 ( 5.145)	Data  8.572 ( 4.570)	Loss 1.4522e-01 (1.4005e-01) 
2023-05-27 09:19:23.653805: train Epoch: [19][ 25/193]	Time  0.566 ( 4.969)	Data  0.001 ( 4.394)	Loss 6.5238e-02 (1.3717e-01) 
2023-05-27 09:19:33.033858: train Epoch: [19][ 26/193]	Time  9.380 ( 5.132)	Data  8.810 ( 4.558)	Loss 9.5164e-02 (1.3562e-01) 
2023-05-27 09:19:33.600621: train Epoch: [19][ 27/193]	Time  0.567 ( 4.969)	Data  0.001 ( 4.395)	Loss 1.0597e-01 (1.3456e-01) 
2023-05-27 09:19:42.795590: train Epoch: [19][ 28/193]	Time  9.195 ( 5.115)	Data  8.632 ( 4.541)	Loss 1.4398e-01 (1.3488e-01) 
2023-05-27 09:19:43.360445: train Epoch: [19][ 29/193]	Time  0.565 ( 4.963)	Data  0.001 ( 4.390)	Loss 6.1535e-02 (1.3244e-01) 
2023-05-27 09:19:52.550285: train Epoch: [19][ 30/193]	Time  9.190 ( 5.099)	Data  8.626 ( 4.526)	Loss 8.7795e-02 (1.3100e-01) 
2023-05-27 09:19:53.116358: train Epoch: [19][ 31/193]	Time  0.566 ( 4.958)	Data  0.001 ( 4.385)	Loss 1.4334e-01 (1.3138e-01) 
2023-05-27 09:20:02.487428: train Epoch: [19][ 32/193]	Time  9.371 ( 5.092)	Data  8.806 ( 4.519)	Loss 2.2397e-01 (1.3419e-01) 
2023-05-27 09:20:03.052969: train Epoch: [19][ 33/193]	Time  0.566 ( 4.958)	Data  0.001 ( 4.386)	Loss 1.2378e-01 (1.3388e-01) 
2023-05-27 09:20:11.978064: train Epoch: [19][ 34/193]	Time  8.925 ( 5.072)	Data  8.360 ( 4.500)	Loss 1.4024e-01 (1.3407e-01) 
2023-05-27 09:20:12.542168: train Epoch: [19][ 35/193]	Time  0.564 ( 4.947)	Data  0.001 ( 4.375)	Loss 8.1409e-02 (1.3260e-01) 
2023-05-27 09:20:21.145441: train Epoch: [19][ 36/193]	Time  8.603 ( 5.045)	Data  8.019 ( 4.473)	Loss 8.0903e-02 (1.3121e-01) 
2023-05-27 09:20:21.709725: train Epoch: [19][ 37/193]	Time  0.564 ( 4.927)	Data  0.001 ( 4.355)	Loss 1.4945e-01 (1.3169e-01) 
2023-05-27 09:20:30.801430: train Epoch: [19][ 38/193]	Time  9.092 ( 5.034)	Data  8.526 ( 4.462)	Loss 1.8644e-01 (1.3309e-01) 
2023-05-27 09:20:31.368520: train Epoch: [19][ 39/193]	Time  0.567 ( 4.923)	Data  0.001 ( 4.351)	Loss 1.1978e-01 (1.3276e-01) 
2023-05-27 09:20:40.470684: train Epoch: [19][ 40/193]	Time  9.102 ( 5.024)	Data  8.534 ( 4.453)	Loss 2.0550e-01 (1.3453e-01) 
2023-05-27 09:20:41.042849: train Epoch: [19][ 41/193]	Time  0.572 ( 4.918)	Data  0.001 ( 4.347)	Loss 1.6270e-01 (1.3520e-01) 
2023-05-27 09:20:50.699101: train Epoch: [19][ 42/193]	Time  9.656 ( 5.029)	Data  9.084 ( 4.457)	Loss 1.0695e-01 (1.3454e-01) 
2023-05-27 09:20:51.265176: train Epoch: [19][ 43/193]	Time  0.566 ( 4.927)	Data  0.001 ( 4.356)	Loss 9.5308e-02 (1.3365e-01) 
2023-05-27 09:21:00.856747: train Epoch: [19][ 44/193]	Time  9.592 ( 5.031)	Data  9.025 ( 4.459)	Loss 7.5523e-02 (1.3236e-01) 
2023-05-27 09:21:01.445820: train Epoch: [19][ 45/193]	Time  0.589 ( 4.934)	Data  0.001 ( 4.363)	Loss 2.3890e-01 (1.3468e-01) 
2023-05-27 09:21:10.765611: train Epoch: [19][ 46/193]	Time  9.320 ( 5.028)	Data  8.748 ( 4.456)	Loss 1.4458e-01 (1.3489e-01) 
2023-05-27 09:21:11.328510: train Epoch: [19][ 47/193]	Time  0.563 ( 4.935)	Data  0.001 ( 4.363)	Loss 1.0138e-01 (1.3419e-01) 
2023-05-27 09:21:20.680552: train Epoch: [19][ 48/193]	Time  9.352 ( 5.025)	Data  8.789 ( 4.453)	Loss 1.8639e-01 (1.3526e-01) 
2023-05-27 09:21:21.244147: train Epoch: [19][ 49/193]	Time  0.564 ( 4.936)	Data  0.001 ( 4.364)	Loss 8.1302e-02 (1.3418e-01) 
2023-05-27 09:21:30.541739: train Epoch: [19][ 50/193]	Time  9.298 ( 5.021)	Data  8.731 ( 4.450)	Loss 1.5363e-01 (1.3456e-01) 
2023-05-27 09:21:31.115059: train Epoch: [19][ 51/193]	Time  0.573 ( 4.936)	Data  0.001 ( 4.364)	Loss 1.5459e-01 (1.3494e-01) 
2023-05-27 09:21:40.091488: train Epoch: [19][ 52/193]	Time  8.976 ( 5.012)	Data  8.413 ( 4.441)	Loss 1.8614e-01 (1.3591e-01) 
2023-05-27 09:21:40.654610: train Epoch: [19][ 53/193]	Time  0.563 ( 4.929)	Data  0.001 ( 4.359)	Loss 1.0934e-01 (1.3542e-01) 
2023-05-27 09:21:49.610977: train Epoch: [19][ 54/193]	Time  8.956 ( 5.003)	Data  8.375 ( 4.432)	Loss 5.7076e-02 (1.3399e-01) 
2023-05-27 09:21:50.179216: train Epoch: [19][ 55/193]	Time  0.568 ( 4.923)	Data  0.001 ( 4.352)	Loss 1.3436e-01 (1.3400e-01) 
2023-05-27 09:21:59.349262: train Epoch: [19][ 56/193]	Time  9.170 ( 4.998)	Data  8.590 ( 4.427)	Loss 1.6661e-01 (1.3457e-01) 
2023-05-27 09:21:59.916137: train Epoch: [19][ 57/193]	Time  0.567 ( 4.922)	Data  0.001 ( 4.350)	Loss 1.5438e-01 (1.3491e-01) 
2023-05-27 09:22:09.043259: train Epoch: [19][ 58/193]	Time  9.127 ( 4.993)	Data  8.566 ( 4.422)	Loss 1.4394e-01 (1.3507e-01) 
2023-05-27 09:22:09.607456: train Epoch: [19][ 59/193]	Time  0.564 ( 4.919)	Data  0.001 ( 4.348)	Loss 6.9641e-02 (1.3398e-01) 
2023-05-27 09:22:19.137226: train Epoch: [19][ 60/193]	Time  9.530 ( 4.995)	Data  8.966 ( 4.424)	Loss 8.8517e-02 (1.3323e-01) 
2023-05-27 09:22:19.698923: train Epoch: [19][ 61/193]	Time  0.562 ( 4.923)	Data  0.001 ( 4.353)	Loss 1.4000e-01 (1.3334e-01) 
2023-05-27 09:22:29.154274: train Epoch: [19][ 62/193]	Time  9.455 ( 4.995)	Data  8.885 ( 4.425)	Loss 7.8338e-02 (1.3247e-01) 
2023-05-27 09:22:29.719342: train Epoch: [19][ 63/193]	Time  0.565 ( 4.926)	Data  0.001 ( 4.355)	Loss 1.4735e-01 (1.3270e-01) 
2023-05-27 09:22:39.073572: train Epoch: [19][ 64/193]	Time  9.354 ( 4.994)	Data  8.777 ( 4.423)	Loss 1.0653e-01 (1.3230e-01) 
2023-05-27 09:22:39.641347: train Epoch: [19][ 65/193]	Time  0.568 ( 4.927)	Data  0.001 ( 4.356)	Loss 8.5149e-02 (1.3158e-01) 
2023-05-27 09:22:48.936824: train Epoch: [19][ 66/193]	Time  9.295 ( 4.992)	Data  8.732 ( 4.422)	Loss 8.8610e-02 (1.3094e-01) 
2023-05-27 09:22:49.499166: train Epoch: [19][ 67/193]	Time  0.562 ( 4.927)	Data  0.001 ( 4.357)	Loss 6.0654e-02 (1.2991e-01) 
2023-05-27 09:22:58.950343: train Epoch: [19][ 68/193]	Time  9.451 ( 4.993)	Data  8.880 ( 4.422)	Loss 9.3885e-02 (1.2938e-01) 
2023-05-27 09:22:59.517916: train Epoch: [19][ 69/193]	Time  0.568 ( 4.929)	Data  0.001 ( 4.359)	Loss 1.2520e-01 (1.2933e-01) 
2023-05-27 09:23:08.642074: train Epoch: [19][ 70/193]	Time  9.124 ( 4.988)	Data  8.554 ( 4.418)	Loss 2.8184e-01 (1.3147e-01) 
2023-05-27 09:23:09.204983: train Epoch: [19][ 71/193]	Time  0.563 ( 4.927)	Data  0.001 ( 4.357)	Loss 9.0884e-02 (1.3091e-01) 
2023-05-27 09:23:18.603668: train Epoch: [19][ 72/193]	Time  9.399 ( 4.988)	Data  8.835 ( 4.418)	Loss 1.4052e-01 (1.3104e-01) 
2023-05-27 09:23:19.167501: train Epoch: [19][ 73/193]	Time  0.564 ( 4.928)	Data  0.001 ( 4.359)	Loss 9.2579e-02 (1.3052e-01) 
2023-05-27 09:23:28.508997: train Epoch: [19][ 74/193]	Time  9.341 ( 4.987)	Data  8.774 ( 4.417)	Loss 1.0547e-01 (1.3019e-01) 
2023-05-27 09:23:29.091462: train Epoch: [19][ 75/193]	Time  0.582 ( 4.929)	Data  0.001 ( 4.359)	Loss 8.1665e-02 (1.2955e-01) 
2023-05-27 09:23:38.396852: train Epoch: [19][ 76/193]	Time  9.305 ( 4.986)	Data  8.738 ( 4.416)	Loss 1.6264e-01 (1.2998e-01) 
2023-05-27 09:23:38.966247: train Epoch: [19][ 77/193]	Time  0.569 ( 4.929)	Data  0.001 ( 4.360)	Loss 1.5434e-01 (1.3029e-01) 
2023-05-27 09:23:47.891413: train Epoch: [19][ 78/193]	Time  8.925 ( 4.980)	Data  8.361 ( 4.410)	Loss 1.1281e-01 (1.3007e-01) 
2023-05-27 09:23:48.455396: train Epoch: [19][ 79/193]	Time  0.564 ( 4.925)	Data  0.001 ( 4.355)	Loss 1.2877e-01 (1.3005e-01) 
2023-05-27 09:23:57.982732: train Epoch: [19][ 80/193]	Time  9.527 ( 4.982)	Data  8.959 ( 4.412)	Loss 4.9337e-02 (1.2906e-01) 
2023-05-27 09:23:58.554817: train Epoch: [19][ 81/193]	Time  0.572 ( 4.928)	Data  0.001 ( 4.358)	Loss 1.3512e-01 (1.2913e-01) 
2023-05-27 09:24:08.100704: train Epoch: [19][ 82/193]	Time  9.546 ( 4.984)	Data  8.962 ( 4.414)	Loss 1.5179e-01 (1.2940e-01) 
2023-05-27 09:24:08.671216: train Epoch: [19][ 83/193]	Time  0.571 ( 4.931)	Data  0.001 ( 4.361)	Loss 3.1844e-02 (1.2824e-01) 
2023-05-27 09:24:18.022461: train Epoch: [19][ 84/193]	Time  9.351 ( 4.983)	Data  8.783 ( 4.413)	Loss 1.2637e-01 (1.2822e-01) 
2023-05-27 09:24:18.591788: train Epoch: [19][ 85/193]	Time  0.569 ( 4.932)	Data  0.001 ( 4.362)	Loss 5.7513e-02 (1.2740e-01) 
2023-05-27 09:24:27.886727: train Epoch: [19][ 86/193]	Time  9.295 ( 4.982)	Data  8.721 ( 4.412)	Loss 7.9795e-02 (1.2685e-01) 
2023-05-27 09:24:28.452746: train Epoch: [19][ 87/193]	Time  0.566 ( 4.932)	Data  0.001 ( 4.362)	Loss 2.9566e-01 (1.2877e-01) 
2023-05-27 09:24:37.077671: train Epoch: [19][ 88/193]	Time  8.625 ( 4.973)	Data  8.061 ( 4.403)	Loss 1.2376e-01 (1.2871e-01) 
2023-05-27 09:24:37.640733: train Epoch: [19][ 89/193]	Time  0.563 ( 4.924)	Data  0.001 ( 4.354)	Loss 7.8387e-02 (1.2815e-01) 
2023-05-27 09:24:45.919738: train Epoch: [19][ 90/193]	Time  8.279 ( 4.961)	Data  7.714 ( 4.391)	Loss 1.0795e-01 (1.2793e-01) 
2023-05-27 09:24:46.484757: train Epoch: [19][ 91/193]	Time  0.565 ( 4.913)	Data  0.001 ( 4.344)	Loss 1.4928e-01 (1.2816e-01) 
2023-05-27 09:24:55.851423: train Epoch: [19][ 92/193]	Time  9.367 ( 4.961)	Data  8.790 ( 4.391)	Loss 9.4096e-02 (1.2780e-01) 
2023-05-27 09:24:56.415864: train Epoch: [19][ 93/193]	Time  0.564 ( 4.914)	Data  0.001 ( 4.345)	Loss 2.1054e-01 (1.2868e-01) 
2023-05-27 09:25:05.718203: train Epoch: [19][ 94/193]	Time  9.302 ( 4.961)	Data  8.738 ( 4.391)	Loss 1.5986e-01 (1.2901e-01) 
2023-05-27 09:25:06.501219: train Epoch: [19][ 95/193]	Time  0.783 ( 4.917)	Data  0.219 ( 4.347)	Loss 6.2833e-02 (1.2832e-01) 
2023-05-27 09:25:15.709449: train Epoch: [19][ 96/193]	Time  9.208 ( 4.961)	Data  8.641 ( 4.392)	Loss 1.4535e-01 (1.2849e-01) 
2023-05-27 09:25:16.273191: train Epoch: [19][ 97/193]	Time  0.564 ( 4.916)	Data  0.001 ( 4.347)	Loss 1.6420e-01 (1.2886e-01) 
2023-05-27 09:25:25.502370: train Epoch: [19][ 98/193]	Time  9.229 ( 4.960)	Data  8.665 ( 4.391)	Loss 8.8651e-02 (1.2845e-01) 
2023-05-27 09:25:26.479183: train Epoch: [19][ 99/193]	Time  0.977 ( 4.920)	Data  0.413 ( 4.351)	Loss 1.4045e-01 (1.2857e-01) 
2023-05-27 09:25:35.616746: train Epoch: [19][100/193]	Time  9.138 ( 4.962)	Data  8.573 ( 4.393)	Loss 7.3070e-02 (1.2802e-01) 
2023-05-27 09:25:36.565551: train Epoch: [19][101/193]	Time  0.949 ( 4.923)	Data  0.384 ( 4.353)	Loss 5.7867e-02 (1.2733e-01) 
2023-05-27 09:25:46.016834: train Epoch: [19][102/193]	Time  9.451 ( 4.967)	Data  8.882 ( 4.397)	Loss 7.9508e-02 (1.2687e-01) 
2023-05-27 09:25:46.581289: train Epoch: [19][103/193]	Time  0.564 ( 4.924)	Data  0.001 ( 4.355)	Loss 1.3458e-01 (1.2694e-01) 
2023-05-27 09:25:55.845087: train Epoch: [19][104/193]	Time  9.264 ( 4.966)	Data  8.699 ( 4.396)	Loss 7.9331e-02 (1.2649e-01) 
2023-05-27 09:25:56.409445: train Epoch: [19][105/193]	Time  0.564 ( 4.924)	Data  0.001 ( 4.355)	Loss 1.2656e-01 (1.2649e-01) 
2023-05-27 09:26:06.127343: train Epoch: [19][106/193]	Time  9.718 ( 4.969)	Data  9.148 ( 4.400)	Loss 9.1275e-02 (1.2616e-01) 
2023-05-27 09:26:06.698841: train Epoch: [19][107/193]	Time  0.571 ( 4.928)	Data  0.001 ( 4.359)	Loss 9.8222e-02 (1.2590e-01) 
2023-05-27 09:26:15.389256: train Epoch: [19][108/193]	Time  8.690 ( 4.963)	Data  8.119 ( 4.393)	Loss 8.5791e-02 (1.2553e-01) 
2023-05-27 09:26:16.407718: train Epoch: [19][109/193]	Time  1.018 ( 4.927)	Data  0.440 ( 4.358)	Loss 1.8536e-01 (1.2608e-01) 
2023-05-27 09:26:25.437492: train Epoch: [19][110/193]	Time  9.030 ( 4.964)	Data  8.448 ( 4.394)	Loss 9.1268e-02 (1.2576e-01) 
2023-05-27 09:26:26.766050: train Epoch: [19][111/193]	Time  1.329 ( 4.931)	Data  0.744 ( 4.362)	Loss 2.3887e-01 (1.2677e-01) 
2023-05-27 09:26:35.537876: train Epoch: [19][112/193]	Time  8.772 ( 4.965)	Data  8.200 ( 4.396)	Loss 1.3049e-01 (1.2681e-01) 
2023-05-27 09:26:36.598808: train Epoch: [19][113/193]	Time  1.061 ( 4.931)	Data  0.486 ( 4.361)	Loss 1.3724e-01 (1.2690e-01) 
2023-05-27 09:26:45.091561: train Epoch: [19][114/193]	Time  8.493 ( 4.962)	Data  7.922 ( 4.392)	Loss 1.2595e-01 (1.2689e-01) 
2023-05-27 09:26:46.598720: train Epoch: [19][115/193]	Time  1.507 ( 4.932)	Data  0.925 ( 4.362)	Loss 8.2827e-02 (1.2651e-01) 
2023-05-27 09:26:54.834396: train Epoch: [19][116/193]	Time  8.236 ( 4.960)	Data  7.666 ( 4.391)	Loss 8.7302e-02 (1.2618e-01) 
2023-05-27 09:26:56.516807: train Epoch: [19][117/193]	Time  1.682 ( 4.933)	Data  1.112 ( 4.363)	Loss 8.8301e-02 (1.2585e-01) 
2023-05-27 09:27:04.241069: train Epoch: [19][118/193]	Time  7.724 ( 4.956)	Data  7.161 ( 4.386)	Loss 1.1459e-01 (1.2576e-01) 
2023-05-27 09:27:06.824505: train Epoch: [19][119/193]	Time  2.583 ( 4.936)	Data  1.930 ( 4.366)	Loss 6.0501e-02 (1.2522e-01) 
2023-05-27 09:27:14.073968: train Epoch: [19][120/193]	Time  7.249 ( 4.955)	Data  6.677 ( 4.385)	Loss 7.9899e-02 (1.2484e-01) 
2023-05-27 09:27:16.720303: train Epoch: [19][121/193]	Time  2.646 ( 4.937)	Data  2.036 ( 4.366)	Loss 5.7073e-02 (1.2429e-01) 
2023-05-27 09:27:24.009463: train Epoch: [19][122/193]	Time  7.289 ( 4.956)	Data  6.726 ( 4.385)	Loss 6.9504e-02 (1.2384e-01) 
2023-05-27 09:27:26.646746: train Epoch: [19][123/193]	Time  2.637 ( 4.937)	Data  2.050 ( 4.366)	Loss 9.8084e-02 (1.2363e-01) 
2023-05-27 09:27:33.751393: train Epoch: [19][124/193]	Time  7.105 ( 4.954)	Data  6.536 ( 4.384)	Loss 8.5214e-02 (1.2333e-01) 
2023-05-27 09:27:36.356665: train Epoch: [19][125/193]	Time  2.605 ( 4.936)	Data  2.021 ( 4.365)	Loss 8.6774e-02 (1.2304e-01) 
2023-05-27 09:27:43.231221: train Epoch: [19][126/193]	Time  6.875 ( 4.951)	Data  6.307 ( 4.380)	Loss 1.4528e-01 (1.2321e-01) 
2023-05-27 09:27:45.635386: train Epoch: [19][127/193]	Time  2.404 ( 4.931)	Data  1.835 ( 4.360)	Loss 1.3409e-01 (1.2330e-01) 
2023-05-27 09:27:52.987527: train Epoch: [19][128/193]	Time  7.352 ( 4.950)	Data  6.785 ( 4.379)	Loss 1.0714e-01 (1.2317e-01) 
2023-05-27 09:27:55.262975: train Epoch: [19][129/193]	Time  2.275 ( 4.929)	Data  1.706 ( 4.358)	Loss 6.3121e-02 (1.2271e-01) 
2023-05-27 09:28:02.942876: train Epoch: [19][130/193]	Time  7.680 ( 4.950)	Data  7.101 ( 4.379)	Loss 1.0616e-01 (1.2258e-01) 
2023-05-27 09:28:05.351903: train Epoch: [19][131/193]	Time  2.409 ( 4.931)	Data  1.840 ( 4.360)	Loss 1.0678e-01 (1.2246e-01) 
2023-05-27 09:28:12.956812: train Epoch: [19][132/193]	Time  7.605 ( 4.951)	Data  7.033 ( 4.380)	Loss 1.0294e-01 (1.2232e-01) 
2023-05-27 09:28:14.946837: train Epoch: [19][133/193]	Time  1.990 ( 4.929)	Data  1.419 ( 4.358)	Loss 1.4717e-01 (1.2250e-01) 
2023-05-27 09:28:22.911735: train Epoch: [19][134/193]	Time  7.965 ( 4.951)	Data  7.397 ( 4.381)	Loss 7.3058e-02 (1.2214e-01) 
2023-05-27 09:28:25.249567: train Epoch: [19][135/193]	Time  2.338 ( 4.932)	Data  1.767 ( 4.361)	Loss 1.3605e-01 (1.2224e-01) 
2023-05-27 09:28:32.926324: train Epoch: [19][136/193]	Time  7.677 ( 4.952)	Data  7.103 ( 4.381)	Loss 5.7342e-02 (1.2176e-01) 
2023-05-27 09:28:35.656650: train Epoch: [19][137/193]	Time  2.730 ( 4.936)	Data  2.165 ( 4.365)	Loss 1.3221e-01 (1.2184e-01) 
2023-05-27 09:28:43.036705: train Epoch: [19][138/193]	Time  7.380 ( 4.954)	Data  6.793 ( 4.383)	Loss 1.6340e-01 (1.2214e-01) 
2023-05-27 09:28:45.098043: train Epoch: [19][139/193]	Time  2.061 ( 4.933)	Data  1.498 ( 4.362)	Loss 1.0155e-01 (1.2199e-01) 
2023-05-27 09:28:53.046905: train Epoch: [19][140/193]	Time  7.949 ( 4.954)	Data  7.378 ( 4.384)	Loss 8.5483e-02 (1.2173e-01) 
2023-05-27 09:28:55.110587: train Epoch: [19][141/193]	Time  2.064 ( 4.934)	Data  1.500 ( 4.363)	Loss 7.7834e-02 (1.2142e-01) 
2023-05-27 09:29:02.938448: train Epoch: [19][142/193]	Time  7.828 ( 4.954)	Data  7.265 ( 4.384)	Loss 9.5262e-02 (1.2124e-01) 
2023-05-27 09:29:05.657495: train Epoch: [19][143/193]	Time  2.719 ( 4.939)	Data  2.155 ( 4.368)	Loss 6.8348e-02 (1.2087e-01) 
2023-05-27 09:29:12.753575: train Epoch: [19][144/193]	Time  7.096 ( 4.954)	Data  6.521 ( 4.383)	Loss 3.0828e-01 (1.2217e-01) 
2023-05-27 09:29:15.829412: train Epoch: [19][145/193]	Time  3.076 ( 4.941)	Data  2.512 ( 4.370)	Loss 1.8505e-01 (1.2260e-01) 
2023-05-27 09:29:22.764960: train Epoch: [19][146/193]	Time  6.936 ( 4.954)	Data  6.369 ( 4.384)	Loss 6.1829e-02 (1.2218e-01) 
2023-05-27 09:29:25.356221: train Epoch: [19][147/193]	Time  2.591 ( 4.938)	Data  2.027 ( 4.368)	Loss 6.5035e-02 (1.2180e-01) 
2023-05-27 09:29:32.579606: train Epoch: [19][148/193]	Time  7.223 ( 4.954)	Data  6.661 ( 4.383)	Loss 7.9231e-02 (1.2151e-01) 
2023-05-27 09:29:35.059292: train Epoch: [19][149/193]	Time  2.480 ( 4.937)	Data  1.915 ( 4.367)	Loss 6.0505e-02 (1.2110e-01) 
2023-05-27 09:29:42.605173: train Epoch: [19][150/193]	Time  7.546 ( 4.955)	Data  6.966 ( 4.384)	Loss 1.1110e-01 (1.2104e-01) 
2023-05-27 09:29:45.430900: train Epoch: [19][151/193]	Time  2.826 ( 4.941)	Data  2.263 ( 4.370)	Loss 1.1180e-01 (1.2098e-01) 
2023-05-27 09:29:52.199372: train Epoch: [19][152/193]	Time  6.768 ( 4.952)	Data  6.169 ( 4.382)	Loss 1.2832e-01 (1.2103e-01) 
2023-05-27 09:29:56.049509: train Epoch: [19][153/193]	Time  3.850 ( 4.945)	Data  3.266 ( 4.375)	Loss 9.9870e-02 (1.2089e-01) 
2023-05-27 09:30:02.417590: train Epoch: [19][154/193]	Time  6.368 ( 4.955)	Data  5.793 ( 4.384)	Loss 9.0216e-02 (1.2069e-01) 
2023-05-27 09:30:05.902274: train Epoch: [19][155/193]	Time  3.485 ( 4.945)	Data  2.904 ( 4.374)	Loss 2.0617e-01 (1.2124e-01) 
2023-05-27 09:30:12.798450: train Epoch: [19][156/193]	Time  6.896 ( 4.958)	Data  6.321 ( 4.387)	Loss 7.9011e-02 (1.2097e-01) 
2023-05-27 09:30:16.216874: train Epoch: [19][157/193]	Time  3.418 ( 4.948)	Data  2.817 ( 4.377)	Loss 1.1180e-01 (1.2091e-01) 
2023-05-27 09:30:23.154660: train Epoch: [19][158/193]	Time  6.938 ( 4.960)	Data  6.376 ( 4.389)	Loss 9.2210e-02 (1.2073e-01) 
2023-05-27 09:30:26.126984: train Epoch: [19][159/193]	Time  2.972 ( 4.948)	Data  2.395 ( 4.377)	Loss 1.1464e-01 (1.2069e-01) 
2023-05-27 09:30:33.290629: train Epoch: [19][160/193]	Time  7.164 ( 4.962)	Data  6.590 ( 4.391)	Loss 7.8927e-02 (1.2043e-01) 
2023-05-27 09:30:35.790547: train Epoch: [19][161/193]	Time  2.500 ( 4.946)	Data  1.925 ( 4.375)	Loss 1.1666e-01 (1.2041e-01) 
2023-05-27 09:30:42.967792: train Epoch: [19][162/193]	Time  7.177 ( 4.960)	Data  6.606 ( 4.389)	Loss 1.2772e-01 (1.2045e-01) 
2023-05-27 09:30:45.544023: train Epoch: [19][163/193]	Time  2.576 ( 4.946)	Data  1.997 ( 4.374)	Loss 1.0392e-01 (1.2035e-01) 
2023-05-27 09:30:53.494113: train Epoch: [19][164/193]	Time  7.950 ( 4.964)	Data  7.389 ( 4.393)	Loss 9.8011e-02 (1.2022e-01) 
2023-05-27 09:30:55.913966: train Epoch: [19][165/193]	Time  2.420 ( 4.948)	Data  1.815 ( 4.377)	Loss 1.0081e-01 (1.2010e-01) 
2023-05-27 09:31:03.240331: train Epoch: [19][166/193]	Time  7.326 ( 4.963)	Data  6.764 ( 4.391)	Loss 9.1225e-02 (1.1993e-01) 
2023-05-27 09:31:05.907104: train Epoch: [19][167/193]	Time  2.667 ( 4.949)	Data  2.101 ( 4.378)	Loss 7.3451e-02 (1.1965e-01) 
2023-05-27 09:31:12.964105: train Epoch: [19][168/193]	Time  7.057 ( 4.962)	Data  6.494 ( 4.390)	Loss 1.4865e-01 (1.1982e-01) 
2023-05-27 09:31:15.680854: train Epoch: [19][169/193]	Time  2.717 ( 4.948)	Data  2.151 ( 4.377)	Loss 5.4024e-02 (1.1944e-01) 
2023-05-27 09:31:22.922160: train Epoch: [19][170/193]	Time  7.241 ( 4.962)	Data  6.669 ( 4.391)	Loss 8.4386e-02 (1.1923e-01) 
2023-05-27 09:31:25.692812: train Epoch: [19][171/193]	Time  2.771 ( 4.949)	Data  2.166 ( 4.378)	Loss 6.7360e-02 (1.1893e-01) 
2023-05-27 09:31:33.509528: train Epoch: [19][172/193]	Time  7.817 ( 4.966)	Data  7.253 ( 4.394)	Loss 6.4914e-02 (1.1862e-01) 
2023-05-27 09:31:35.588598: train Epoch: [19][173/193]	Time  2.079 ( 4.949)	Data  1.510 ( 4.378)	Loss 1.5885e-01 (1.1885e-01) 
2023-05-27 09:31:43.323095: train Epoch: [19][174/193]	Time  7.735 ( 4.965)	Data  7.171 ( 4.394)	Loss 1.0780e-01 (1.1879e-01) 
2023-05-27 09:31:45.884771: train Epoch: [19][175/193]	Time  2.562 ( 4.951)	Data  1.979 ( 4.380)	Loss 7.2498e-02 (1.1852e-01) 
2023-05-27 09:31:52.986966: train Epoch: [19][176/193]	Time  7.102 ( 4.963)	Data  6.539 ( 4.392)	Loss 4.9825e-02 (1.1813e-01) 
2023-05-27 09:31:56.314283: train Epoch: [19][177/193]	Time  3.327 ( 4.954)	Data  2.725 ( 4.383)	Loss 1.6238e-01 (1.1838e-01) 
2023-05-27 09:32:02.639675: train Epoch: [19][178/193]	Time  6.325 ( 4.962)	Data  5.761 ( 4.390)	Loss 7.7034e-02 (1.1815e-01) 
2023-05-27 09:32:05.943125: train Epoch: [19][179/193]	Time  3.303 ( 4.953)	Data  2.720 ( 4.381)	Loss 2.3427e-01 (1.1880e-01) 
2023-05-27 09:32:12.625829: train Epoch: [19][180/193]	Time  6.683 ( 4.962)	Data  6.112 ( 4.391)	Loss 9.2390e-02 (1.1865e-01) 
2023-05-27 09:32:15.954752: train Epoch: [19][181/193]	Time  3.329 ( 4.953)	Data  2.756 ( 4.382)	Loss 1.1968e-01 (1.1866e-01) 
2023-05-27 09:32:22.200133: train Epoch: [19][182/193]	Time  6.245 ( 4.960)	Data  5.681 ( 4.389)	Loss 6.0940e-02 (1.1834e-01) 
2023-05-27 09:32:25.604010: train Epoch: [19][183/193]	Time  3.404 ( 4.952)	Data  2.830 ( 4.380)	Loss 1.3000e-01 (1.1841e-01) 
2023-05-27 09:32:32.170263: train Epoch: [19][184/193]	Time  6.566 ( 4.961)	Data  6.004 ( 4.389)	Loss 1.4417e-01 (1.1854e-01) 
2023-05-27 09:32:36.431328: train Epoch: [19][185/193]	Time  4.261 ( 4.957)	Data  3.694 ( 4.385)	Loss 2.2633e-01 (1.1912e-01) 
2023-05-27 09:32:42.383375: train Epoch: [19][186/193]	Time  5.952 ( 4.962)	Data  5.378 ( 4.391)	Loss 6.4364e-02 (1.1883e-01) 
2023-05-27 09:32:46.294380: train Epoch: [19][187/193]	Time  3.911 ( 4.957)	Data  3.338 ( 4.385)	Loss 6.8667e-02 (1.1856e-01) 
2023-05-27 09:32:52.116865: train Epoch: [19][188/193]	Time  5.822 ( 4.961)	Data  5.258 ( 4.390)	Loss 1.4154e-01 (1.1869e-01) 
2023-05-27 09:32:56.421915: train Epoch: [19][189/193]	Time  4.305 ( 4.958)	Data  3.733 ( 4.386)	Loss 5.0729e-02 (1.1833e-01) 
2023-05-27 09:33:02.074784: train Epoch: [19][190/193]	Time  5.653 ( 4.961)	Data  5.087 ( 4.390)	Loss 8.9246e-02 (1.1818e-01) 
2023-05-27 09:33:06.386135: train Epoch: [19][191/193]	Time  4.311 ( 4.958)	Data  3.748 ( 4.387)	Loss 5.9812e-02 (1.1787e-01) 
2023-05-27 09:33:11.691244: train Epoch: [19][192/193]	Time  5.305 ( 4.960)	Data  4.701 ( 4.388)	Loss 7.4372e-02 (1.1765e-01) 
2023-05-27 09:33:11.818471: Train Epoch done in 957.3526034740207 s 
2023-05-27 09:33:18.117103: val Epoch: [19][ 0/72]	Time  5.491 ( 5.491)	Data  5.311 ( 5.311)	Loss 2.2969e-01 (2.2969e-01) 
2023-05-27 09:33:18.525794: val Epoch: [19][ 1/72]	Time  0.409 ( 2.950)	Data  0.277 ( 2.794)	Loss 8.0894e-02 (1.5529e-01) 
2023-05-27 09:33:23.255256: val Epoch: [19][ 2/72]	Time  4.729 ( 3.543)	Data  4.619 ( 3.403)	Loss 1.4226e-01 (1.5095e-01) 
2023-05-27 09:33:23.364717: val Epoch: [19][ 3/72]	Time  0.109 ( 2.685)	Data  0.001 ( 2.552)	Loss 1.0346e-01 (1.3907e-01) 
2023-05-27 09:33:28.379300: val Epoch: [19][ 4/72]	Time  5.015 ( 3.151)	Data  4.901 ( 3.022)	Loss 7.0982e-02 (1.2546e-01) 
2023-05-27 09:33:28.498059: val Epoch: [19][ 5/72]	Time  0.119 ( 2.645)	Data  0.001 ( 2.518)	Loss 6.2225e-02 (1.1492e-01) 
2023-05-27 09:33:33.630063: val Epoch: [19][ 6/72]	Time  5.132 ( 3.001)	Data  5.025 ( 2.876)	Loss 8.9589e-02 (1.1130e-01) 
2023-05-27 09:33:33.734379: val Epoch: [19][ 7/72]	Time  0.104 ( 2.639)	Data  0.000 ( 2.517)	Loss 3.4376e-01 (1.4036e-01) 
2023-05-27 09:33:38.392828: val Epoch: [19][ 8/72]	Time  4.658 ( 2.863)	Data  4.554 ( 2.743)	Loss 6.6643e-02 (1.3217e-01) 
2023-05-27 09:33:38.639743: val Epoch: [19][ 9/72]	Time  0.247 ( 2.601)	Data  0.096 ( 2.478)	Loss 6.9733e-02 (1.2592e-01) 
2023-05-27 09:33:43.613752: val Epoch: [19][10/72]	Time  4.974 ( 2.817)	Data  4.863 ( 2.695)	Loss 6.4736e-02 (1.2036e-01) 
2023-05-27 09:33:43.724299: val Epoch: [19][11/72]	Time  0.111 ( 2.592)	Data  0.001 ( 2.471)	Loss 1.3329e-01 (1.2144e-01) 
2023-05-27 09:33:48.764017: val Epoch: [19][12/72]	Time  5.040 ( 2.780)	Data  4.910 ( 2.658)	Loss 3.7431e-01 (1.4089e-01) 
2023-05-27 09:33:48.872204: val Epoch: [19][13/72]	Time  0.108 ( 2.589)	Data  0.001 ( 2.468)	Loss 4.7813e-02 (1.3424e-01) 
2023-05-27 09:33:53.816726: val Epoch: [19][14/72]	Time  4.945 ( 2.746)	Data  4.838 ( 2.626)	Loss 4.5249e-01 (1.5546e-01) 
2023-05-27 09:33:53.931450: val Epoch: [19][15/72]	Time  0.115 ( 2.582)	Data  0.001 ( 2.462)	Loss 1.2582e-01 (1.5360e-01) 
2023-05-27 09:33:58.915803: val Epoch: [19][16/72]	Time  4.984 ( 2.723)	Data  4.880 ( 2.604)	Loss 1.0343e-01 (1.5065e-01) 
2023-05-27 09:33:59.020669: val Epoch: [19][17/72]	Time  0.105 ( 2.577)	Data  0.001 ( 2.460)	Loss 3.0859e-01 (1.5943e-01) 
2023-05-27 09:34:03.844965: val Epoch: [19][18/72]	Time  4.824 ( 2.696)	Data  4.719 ( 2.579)	Loss 8.7815e-02 (1.5566e-01) 
2023-05-27 09:34:03.950029: val Epoch: [19][19/72]	Time  0.105 ( 2.566)	Data  0.000 ( 2.450)	Loss 6.0196e-02 (1.5089e-01) 
2023-05-27 09:34:08.723931: val Epoch: [19][20/72]	Time  4.774 ( 2.671)	Data  4.668 ( 2.555)	Loss 4.1517e-02 (1.4568e-01) 
2023-05-27 09:34:08.828609: val Epoch: [19][21/72]	Time  0.105 ( 2.555)	Data  0.000 ( 2.439)	Loss 2.2375e-01 (1.4923e-01) 
2023-05-27 09:34:13.653430: val Epoch: [19][22/72]	Time  4.825 ( 2.653)	Data  4.720 ( 2.538)	Loss 2.5887e-01 (1.5399e-01) 
2023-05-27 09:34:13.757641: val Epoch: [19][23/72]	Time  0.104 ( 2.547)	Data  0.000 ( 2.433)	Loss 1.5300e-01 (1.5395e-01) 
2023-05-27 09:34:18.343737: val Epoch: [19][24/72]	Time  4.586 ( 2.629)	Data  4.481 ( 2.515)	Loss 7.0424e-02 (1.5061e-01) 
2023-05-27 09:34:18.592288: val Epoch: [19][25/72]	Time  0.249 ( 2.537)	Data  0.143 ( 2.423)	Loss 5.2333e-02 (1.4683e-01) 
2023-05-27 09:34:23.499660: val Epoch: [19][26/72]	Time  4.907 ( 2.625)	Data  4.799 ( 2.511)	Loss 1.1654e-01 (1.4571e-01) 
2023-05-27 09:34:23.606877: val Epoch: [19][27/72]	Time  0.107 ( 2.535)	Data  0.001 ( 2.422)	Loss 9.1389e-02 (1.4377e-01) 
2023-05-27 09:34:28.865106: val Epoch: [19][28/72]	Time  5.258 ( 2.629)	Data  5.138 ( 2.515)	Loss 1.3091e-01 (1.4333e-01) 
2023-05-27 09:34:28.977793: val Epoch: [19][29/72]	Time  0.113 ( 2.545)	Data  0.001 ( 2.432)	Loss 4.2873e-01 (1.5284e-01) 
2023-05-27 09:34:33.632665: val Epoch: [19][30/72]	Time  4.655 ( 2.613)	Data  4.546 ( 2.500)	Loss 5.1152e-02 (1.4956e-01) 
2023-05-27 09:34:33.986095: val Epoch: [19][31/72]	Time  0.353 ( 2.542)	Data  0.245 ( 2.429)	Loss 1.1346e-01 (1.4843e-01) 
2023-05-27 09:34:38.541936: val Epoch: [19][32/72]	Time  4.556 ( 2.604)	Data  4.448 ( 2.491)	Loss 7.5040e-02 (1.4621e-01) 
2023-05-27 09:34:39.079363: val Epoch: [19][33/72]	Time  0.537 ( 2.543)	Data  0.429 ( 2.430)	Loss 6.9487e-02 (1.4395e-01) 
2023-05-27 09:34:43.465022: val Epoch: [19][34/72]	Time  4.386 ( 2.595)	Data  4.278 ( 2.483)	Loss 6.5760e-02 (1.4172e-01) 
2023-05-27 09:34:44.041423: val Epoch: [19][35/72]	Time  0.576 ( 2.539)	Data  0.468 ( 2.427)	Loss 1.0274e-01 (1.4063e-01) 
2023-05-27 09:34:48.501862: val Epoch: [19][36/72]	Time  4.460 ( 2.591)	Data  4.353 ( 2.479)	Loss 1.1114e-01 (1.3984e-01) 
2023-05-27 09:34:48.968368: val Epoch: [19][37/72]	Time  0.467 ( 2.535)	Data  0.361 ( 2.423)	Loss 6.1864e-01 (1.5244e-01) 
2023-05-27 09:34:53.403736: val Epoch: [19][38/72]	Time  4.435 ( 2.584)	Data  4.330 ( 2.472)	Loss 2.0222e-01 (1.5371e-01) 
2023-05-27 09:34:53.893776: val Epoch: [19][39/72]	Time  0.490 ( 2.532)	Data  0.381 ( 2.420)	Loss 6.3496e-02 (1.5146e-01) 
2023-05-27 09:34:58.466828: val Epoch: [19][40/72]	Time  4.573 ( 2.581)	Data  4.465 ( 2.470)	Loss 3.5363e-01 (1.5639e-01) 
2023-05-27 09:34:58.888264: val Epoch: [19][41/72]	Time  0.421 ( 2.530)	Data  0.313 ( 2.418)	Loss 7.1853e-02 (1.5438e-01) 
2023-05-27 09:35:03.280259: val Epoch: [19][42/72]	Time  4.392 ( 2.573)	Data  4.281 ( 2.462)	Loss 8.8500e-02 (1.5284e-01) 
2023-05-27 09:35:03.856745: val Epoch: [19][43/72]	Time  0.576 ( 2.528)	Data  0.471 ( 2.416)	Loss 1.1865e-01 (1.5207e-01) 
2023-05-27 09:35:08.335948: val Epoch: [19][44/72]	Time  4.479 ( 2.571)	Data  4.360 ( 2.460)	Loss 3.5641e-01 (1.5661e-01) 
2023-05-27 09:35:09.062103: val Epoch: [19][45/72]	Time  0.726 ( 2.531)	Data  0.619 ( 2.420)	Loss 1.8448e-01 (1.5721e-01) 
2023-05-27 09:35:13.350669: val Epoch: [19][46/72]	Time  4.289 ( 2.569)	Data  4.168 ( 2.457)	Loss 9.0152e-02 (1.5579e-01) 
2023-05-27 09:35:14.165837: val Epoch: [19][47/72]	Time  0.815 ( 2.532)	Data  0.709 ( 2.420)	Loss 5.8385e-02 (1.5376e-01) 
2023-05-27 09:35:18.342037: val Epoch: [19][48/72]	Time  4.176 ( 2.566)	Data  4.060 ( 2.454)	Loss 4.5493e-02 (1.5155e-01) 
2023-05-27 09:35:19.075111: val Epoch: [19][49/72]	Time  0.733 ( 2.529)	Data  0.628 ( 2.417)	Loss 9.7112e-02 (1.5046e-01) 
2023-05-27 09:35:23.450193: val Epoch: [19][50/72]	Time  4.375 ( 2.565)	Data  4.267 ( 2.454)	Loss 1.1049e-01 (1.4968e-01) 
2023-05-27 09:35:24.241655: val Epoch: [19][51/72]	Time  0.791 ( 2.531)	Data  0.686 ( 2.420)	Loss 9.8063e-02 (1.4868e-01) 
2023-05-27 09:35:28.468947: val Epoch: [19][52/72]	Time  4.227 ( 2.563)	Data  4.122 ( 2.452)	Loss 1.7437e-01 (1.4917e-01) 
2023-05-27 09:35:29.468641: val Epoch: [19][53/72]	Time  1.000 ( 2.534)	Data  0.893 ( 2.423)	Loss 6.1874e-02 (1.4755e-01) 
2023-05-27 09:35:33.410107: val Epoch: [19][54/72]	Time  3.941 ( 2.560)	Data  3.826 ( 2.448)	Loss 1.6479e-01 (1.4786e-01) 
2023-05-27 09:35:34.540411: val Epoch: [19][55/72]	Time  1.130 ( 2.534)	Data  1.023 ( 2.423)	Loss 5.9687e-02 (1.4629e-01) 
2023-05-27 09:35:38.275331: val Epoch: [19][56/72]	Time  3.735 ( 2.555)	Data  3.619 ( 2.444)	Loss 7.1984e-02 (1.4499e-01) 
2023-05-27 09:35:39.515534: val Epoch: [19][57/72]	Time  1.240 ( 2.533)	Data  1.135 ( 2.421)	Loss 1.6631e-01 (1.4535e-01) 
2023-05-27 09:35:43.278399: val Epoch: [19][58/72]	Time  3.763 ( 2.553)	Data  3.647 ( 2.442)	Loss 5.0632e-02 (1.4375e-01) 
2023-05-27 09:35:44.396393: val Epoch: [19][59/72]	Time  1.118 ( 2.530)	Data  1.011 ( 2.418)	Loss 7.8936e-02 (1.4267e-01) 
2023-05-27 09:35:48.070572: val Epoch: [19][60/72]	Time  3.674 ( 2.548)	Data  3.567 ( 2.437)	Loss 5.2972e-02 (1.4120e-01) 
2023-05-27 09:35:49.324040: val Epoch: [19][61/72]	Time  1.253 ( 2.527)	Data  1.146 ( 2.416)	Loss 4.5875e-01 (1.4632e-01) 
2023-05-27 09:35:52.880299: val Epoch: [19][62/72]	Time  3.556 ( 2.544)	Data  3.448 ( 2.433)	Loss 1.7220e-01 (1.4673e-01) 
2023-05-27 09:35:54.291830: val Epoch: [19][63/72]	Time  1.412 ( 2.526)	Data  1.303 ( 2.415)	Loss 9.2085e-02 (1.4588e-01) 
2023-05-27 09:35:58.168767: val Epoch: [19][64/72]	Time  3.877 ( 2.547)	Data  3.765 ( 2.436)	Loss 9.9624e-02 (1.4517e-01) 
2023-05-27 09:35:59.135926: val Epoch: [19][65/72]	Time  0.967 ( 2.523)	Data  0.858 ( 2.412)	Loss 7.1182e-02 (1.4404e-01) 
2023-05-27 09:36:03.272820: val Epoch: [19][66/72]	Time  4.137 ( 2.547)	Data  4.028 ( 2.436)	Loss 2.9602e-01 (1.4631e-01) 
2023-05-27 09:36:04.086307: val Epoch: [19][67/72]	Time  0.813 ( 2.521)	Data  0.706 ( 2.410)	Loss 7.8739e-02 (1.4532e-01) 
2023-05-27 09:36:08.194710: val Epoch: [19][68/72]	Time  4.108 ( 2.544)	Data  4.002 ( 2.434)	Loss 1.2682e-01 (1.4505e-01) 
2023-05-27 09:36:09.142646: val Epoch: [19][69/72]	Time  0.948 ( 2.522)	Data  0.833 ( 2.411)	Loss 4.8450e-02 (1.4367e-01) 
2023-05-27 09:36:13.081711: val Epoch: [19][70/72]	Time  3.939 ( 2.542)	Data  3.825 ( 2.431)	Loss 5.7706e-02 (1.4246e-01) 
2023-05-27 09:36:13.936319: val Epoch: [19][71/72]	Time  0.855 ( 2.518)	Data  0.750 ( 2.407)	Loss 9.4206e-02 (1.4179e-01) 
2023-05-27 09:36:14.222036: Epoch 19 :Val : ['ET : 0.7322661280632019', 'TC : 0.7700817584991455', 'WT : 0.8415762186050415'] 
2023-05-27 09:36:14.222725: Epoch 19 :Val : ['ET : 0.7322661280632019', 'TC : 0.7700817584991455', 'WT : 0.8415762186050415'] 
2023-05-27 09:36:14.226671: Saving the model with DSC 0.782481849193573 
2023-05-27 09:36:14.900351: Val epoch done in 183.08187133498723 s 
2023-05-27 09:36:14.906020: Batches per epoch:  193 
2023-05-27 09:36:25.911946: train Epoch: [20][  0/193]	Time 11.005 (11.005)	Data 10.387 (10.387)	Loss 6.2082e-02 (6.2082e-02) 
2023-05-27 09:36:26.491035: train Epoch: [20][  1/193]	Time  0.579 ( 5.792)	Data  0.001 ( 5.194)	Loss 1.0074e-01 (8.1412e-02) 
2023-05-27 09:36:36.454761: train Epoch: [20][  2/193]	Time  9.964 ( 7.183)	Data  9.395 ( 6.594)	Loss 1.4021e-01 (1.0101e-01) 
2023-05-27 09:36:37.028711: train Epoch: [20][  3/193]	Time  0.574 ( 5.531)	Data  0.001 ( 4.946)	Loss 8.7390e-02 (9.7607e-02) 
2023-05-27 09:36:46.237151: train Epoch: [20][  4/193]	Time  9.208 ( 6.266)	Data  8.638 ( 5.684)	Loss 7.7907e-02 (9.3667e-02) 
2023-05-27 09:36:46.806454: train Epoch: [20][  5/193]	Time  0.569 ( 5.317)	Data  0.001 ( 4.737)	Loss 1.0836e-01 (9.6116e-02) 
2023-05-27 09:36:55.808947: train Epoch: [20][  6/193]	Time  9.003 ( 5.843)	Data  8.432 ( 5.265)	Loss 6.6233e-02 (9.1847e-02) 
2023-05-27 09:36:56.379979: train Epoch: [20][  7/193]	Time  0.571 ( 5.184)	Data  0.001 ( 4.607)	Loss 1.2849e-01 (9.6427e-02) 
2023-05-27 09:37:05.688125: train Epoch: [20][  8/193]	Time  9.308 ( 5.642)	Data  8.745 ( 5.067)	Loss 5.5390e-02 (9.1867e-02) 
2023-05-27 09:37:06.251030: train Epoch: [20][  9/193]	Time  0.563 ( 5.134)	Data  0.001 ( 4.560)	Loss 1.2435e-01 (9.5116e-02) 
2023-05-27 09:37:15.560485: train Epoch: [20][ 10/193]	Time  9.309 ( 5.514)	Data  8.734 ( 4.940)	Loss 6.4110e-02 (9.2297e-02) 
2023-05-27 09:37:16.132014: train Epoch: [20][ 11/193]	Time  0.572 ( 5.102)	Data  0.001 ( 4.528)	Loss 6.3578e-02 (8.9904e-02) 
2023-05-27 09:37:25.755395: train Epoch: [20][ 12/193]	Time  9.623 ( 5.450)	Data  9.061 ( 4.877)	Loss 1.0364e-01 (9.0960e-02) 
2023-05-27 09:37:26.321068: train Epoch: [20][ 13/193]	Time  0.566 ( 5.101)	Data  0.001 ( 4.528)	Loss 9.7699e-02 (9.1442e-02) 
2023-05-27 09:37:35.951491: train Epoch: [20][ 14/193]	Time  9.630 ( 5.403)	Data  9.061 ( 4.831)	Loss 2.0115e-01 (9.8755e-02) 
2023-05-27 09:37:36.531045: train Epoch: [20][ 15/193]	Time  0.580 ( 5.102)	Data  0.001 ( 4.529)	Loss 9.2479e-02 (9.8363e-02) 
2023-05-27 09:37:44.702235: train Epoch: [20][ 16/193]	Time  8.171 ( 5.282)	Data  7.609 ( 4.710)	Loss 1.2259e-01 (9.9788e-02) 
2023-05-27 09:37:45.266107: train Epoch: [20][ 17/193]	Time  0.564 ( 5.020)	Data  0.001 ( 4.448)	Loss 2.6005e-01 (1.0869e-01) 
2023-05-27 09:37:53.585977: train Epoch: [20][ 18/193]	Time  8.320 ( 5.194)	Data  7.749 ( 4.622)	Loss 9.4758e-02 (1.0796e-01) 
2023-05-27 09:37:54.155353: train Epoch: [20][ 19/193]	Time  0.569 ( 4.962)	Data  0.001 ( 4.391)	Loss 1.3277e-01 (1.0920e-01) 
2023-05-27 09:38:03.531266: train Epoch: [20][ 20/193]	Time  9.376 ( 5.173)	Data  8.812 ( 4.602)	Loss 1.1771e-01 (1.0960e-01) 
2023-05-27 09:38:04.109905: train Epoch: [20][ 21/193]	Time  0.579 ( 4.964)	Data  0.001 ( 4.392)	Loss 1.1086e-01 (1.0966e-01) 
2023-05-27 09:38:13.678540: train Epoch: [20][ 22/193]	Time  9.569 ( 5.164)	Data  9.000 ( 4.593)	Loss 9.8828e-02 (1.0919e-01) 
2023-05-27 09:38:14.243009: train Epoch: [20][ 23/193]	Time  0.564 ( 4.972)	Data  0.001 ( 4.401)	Loss 1.7099e-01 (1.1176e-01) 
2023-05-27 09:38:23.274954: train Epoch: [20][ 24/193]	Time  9.032 ( 5.135)	Data  8.447 ( 4.563)	Loss 6.3514e-02 (1.0983e-01) 
2023-05-27 09:38:23.837336: train Epoch: [20][ 25/193]	Time  0.562 ( 4.959)	Data  0.001 ( 4.388)	Loss 8.6337e-02 (1.0893e-01) 
2023-05-27 09:38:33.064886: train Epoch: [20][ 26/193]	Time  9.228 ( 5.117)	Data  8.651 ( 4.546)	Loss 1.8874e-01 (1.1189e-01) 
2023-05-27 09:38:33.628143: train Epoch: [20][ 27/193]	Time  0.563 ( 4.954)	Data  0.001 ( 4.383)	Loss 7.8672e-02 (1.1070e-01) 
2023-05-27 09:38:42.934587: train Epoch: [20][ 28/193]	Time  9.306 ( 5.104)	Data  8.733 ( 4.533)	Loss 4.6639e-02 (1.0849e-01) 
2023-05-27 09:38:43.514408: train Epoch: [20][ 29/193]	Time  0.580 ( 4.954)	Data  0.001 ( 4.382)	Loss 1.3619e-01 (1.0941e-01) 
2023-05-27 09:38:53.082850: train Epoch: [20][ 30/193]	Time  9.568 ( 5.102)	Data  8.999 ( 4.531)	Loss 9.0657e-02 (1.0881e-01) 
2023-05-27 09:38:53.650548: train Epoch: [20][ 31/193]	Time  0.568 ( 4.961)	Data  0.001 ( 4.390)	Loss 8.4502e-02 (1.0805e-01) 
2023-05-27 09:39:01.790791: train Epoch: [20][ 32/193]	Time  8.140 ( 5.057)	Data  7.577 ( 4.486)	Loss 6.9164e-02 (1.0687e-01) 
2023-05-27 09:39:02.363547: train Epoch: [20][ 33/193]	Time  0.573 ( 4.925)	Data  0.001 ( 4.354)	Loss 1.1407e-01 (1.0708e-01) 
2023-05-27 09:39:11.373135: train Epoch: [20][ 34/193]	Time  9.010 ( 5.042)	Data  8.432 ( 4.471)	Loss 8.5623e-02 (1.0647e-01) 
2023-05-27 09:39:11.946496: train Epoch: [20][ 35/193]	Time  0.573 ( 4.918)	Data  0.001 ( 4.347)	Loss 7.1591e-02 (1.0550e-01) 
2023-05-27 09:39:21.022046: train Epoch: [20][ 36/193]	Time  9.076 ( 5.030)	Data  8.512 ( 4.459)	Loss 6.2588e-02 (1.0434e-01) 
2023-05-27 09:39:21.592197: train Epoch: [20][ 37/193]	Time  0.570 ( 4.913)	Data  0.001 ( 4.342)	Loss 9.8296e-02 (1.0418e-01) 
2023-05-27 09:39:30.915187: train Epoch: [20][ 38/193]	Time  9.323 ( 5.026)	Data  8.760 ( 4.455)	Loss 1.1209e-01 (1.0439e-01) 
2023-05-27 09:39:31.492059: train Epoch: [20][ 39/193]	Time  0.577 ( 4.915)	Data  0.001 ( 4.344)	Loss 1.5383e-01 (1.0562e-01) 
2023-05-27 09:39:40.573793: train Epoch: [20][ 40/193]	Time  9.082 ( 5.016)	Data  8.513 ( 4.445)	Loss 1.6014e-01 (1.0695e-01) 
2023-05-27 09:39:41.143392: train Epoch: [20][ 41/193]	Time  0.570 ( 4.910)	Data  0.001 ( 4.340)	Loss 1.3344e-01 (1.0758e-01) 
2023-05-27 09:39:50.396239: train Epoch: [20][ 42/193]	Time  9.253 ( 5.011)	Data  8.684 ( 4.441)	Loss 1.2577e-01 (1.0800e-01) 
2023-05-27 09:39:50.963117: train Epoch: [20][ 43/193]	Time  0.567 ( 4.910)	Data  0.001 ( 4.340)	Loss 1.0759e-01 (1.0800e-01) 
2023-05-27 09:40:00.586490: train Epoch: [20][ 44/193]	Time  9.623 ( 5.015)	Data  9.046 ( 4.444)	Loss 1.0197e-01 (1.0786e-01) 
2023-05-27 09:40:01.154251: train Epoch: [20][ 45/193]	Time  0.568 ( 4.918)	Data  0.001 ( 4.348)	Loss 1.9533e-01 (1.0976e-01) 
2023-05-27 09:40:10.418026: train Epoch: [20][ 46/193]	Time  9.264 ( 5.011)	Data  8.693 ( 4.440)	Loss 8.7789e-02 (1.0930e-01) 
2023-05-27 09:40:10.985053: train Epoch: [20][ 47/193]	Time  0.567 ( 4.918)	Data  0.001 ( 4.348)	Loss 5.4357e-02 (1.0815e-01) 
2023-05-27 09:40:20.229793: train Epoch: [20][ 48/193]	Time  9.245 ( 5.007)	Data  8.673 ( 4.436)	Loss 1.4653e-01 (1.0893e-01) 
2023-05-27 09:40:20.801019: train Epoch: [20][ 49/193]	Time  0.571 ( 4.918)	Data  0.001 ( 4.347)	Loss 6.0112e-02 (1.0796e-01) 
2023-05-27 09:40:30.241510: train Epoch: [20][ 50/193]	Time  9.440 ( 5.007)	Data  8.877 ( 4.436)	Loss 1.4259e-01 (1.0864e-01) 
2023-05-27 09:40:30.847159: train Epoch: [20][ 51/193]	Time  0.606 ( 4.922)	Data  0.001 ( 4.351)	Loss 2.0212e-01 (1.1043e-01) 
2023-05-27 09:40:39.982625: train Epoch: [20][ 52/193]	Time  9.135 ( 5.001)	Data  8.555 ( 4.430)	Loss 1.1020e-01 (1.1043e-01) 
2023-05-27 09:40:40.551768: train Epoch: [20][ 53/193]	Time  0.569 ( 4.919)	Data  0.001 ( 4.348)	Loss 1.0147e-01 (1.1026e-01) 
2023-05-27 09:40:49.751014: train Epoch: [20][ 54/193]	Time  9.199 ( 4.997)	Data  8.636 ( 4.426)	Loss 1.6313e-01 (1.1123e-01) 
2023-05-27 09:40:50.313763: train Epoch: [20][ 55/193]	Time  0.563 ( 4.918)	Data  0.001 ( 4.347)	Loss 8.0135e-02 (1.1067e-01) 
2023-05-27 09:40:59.360731: train Epoch: [20][ 56/193]	Time  9.047 ( 4.990)	Data  8.484 ( 4.420)	Loss 1.0090e-01 (1.1050e-01) 
2023-05-27 09:40:59.938744: train Epoch: [20][ 57/193]	Time  0.578 ( 4.914)	Data  0.001 ( 4.343)	Loss 8.8417e-02 (1.1012e-01) 
2023-05-27 09:41:09.564820: train Epoch: [20][ 58/193]	Time  9.626 ( 4.994)	Data  9.056 ( 4.423)	Loss 1.5469e-01 (1.1087e-01) 
2023-05-27 09:41:10.126158: train Epoch: [20][ 59/193]	Time  0.561 ( 4.920)	Data  0.001 ( 4.350)	Loss 1.8215e-01 (1.1206e-01) 
2023-05-27 09:41:19.364267: train Epoch: [20][ 60/193]	Time  9.238 ( 4.991)	Data  8.672 ( 4.421)	Loss 5.5839e-02 (1.1114e-01) 
2023-05-27 09:41:19.927120: train Epoch: [20][ 61/193]	Time  0.563 ( 4.920)	Data  0.001 ( 4.349)	Loss 9.3369e-02 (1.1085e-01) 
2023-05-27 09:41:29.431815: train Epoch: [20][ 62/193]	Time  9.505 ( 4.992)	Data  8.922 ( 4.422)	Loss 1.0824e-01 (1.1081e-01) 
2023-05-27 09:41:30.003499: train Epoch: [20][ 63/193]	Time  0.572 ( 4.923)	Data  0.001 ( 4.353)	Loss 8.0865e-02 (1.1034e-01) 
2023-05-27 09:41:39.404124: train Epoch: [20][ 64/193]	Time  9.401 ( 4.992)	Data  8.837 ( 4.422)	Loss 7.8384e-02 (1.0985e-01) 
2023-05-27 09:41:39.966221: train Epoch: [20][ 65/193]	Time  0.562 ( 4.925)	Data  0.001 ( 4.355)	Loss 9.3692e-02 (1.0961e-01) 
2023-05-27 09:41:49.275625: train Epoch: [20][ 66/193]	Time  9.309 ( 4.991)	Data  8.746 ( 4.420)	Loss 1.2100e-01 (1.0978e-01) 
2023-05-27 09:41:49.838725: train Epoch: [20][ 67/193]	Time  0.563 ( 4.925)	Data  0.001 ( 4.355)	Loss 8.7031e-02 (1.0944e-01) 
2023-05-27 09:41:58.442104: train Epoch: [20][ 68/193]	Time  8.603 ( 4.979)	Data  8.030 ( 4.409)	Loss 1.7809e-01 (1.1044e-01) 
2023-05-27 09:41:59.005131: train Epoch: [20][ 69/193]	Time  0.563 ( 4.916)	Data  0.001 ( 4.346)	Loss 5.4788e-02 (1.0964e-01) 
2023-05-27 09:42:08.426573: train Epoch: [20][ 70/193]	Time  9.421 ( 4.979)	Data  8.850 ( 4.409)	Loss 1.3315e-01 (1.0997e-01) 
2023-05-27 09:42:09.002983: train Epoch: [20][ 71/193]	Time  0.576 ( 4.918)	Data  0.001 ( 4.348)	Loss 7.6385e-02 (1.0951e-01) 
2023-05-27 09:42:18.459399: train Epoch: [20][ 72/193]	Time  9.456 ( 4.980)	Data  8.888 ( 4.410)	Loss 7.9554e-02 (1.0910e-01) 
2023-05-27 09:42:19.024326: train Epoch: [20][ 73/193]	Time  0.565 ( 4.921)	Data  0.001 ( 4.350)	Loss 1.2925e-01 (1.0937e-01) 
2023-05-27 09:42:28.296450: train Epoch: [20][ 74/193]	Time  9.272 ( 4.979)	Data  8.707 ( 4.408)	Loss 4.9010e-02 (1.0856e-01) 
2023-05-27 09:42:28.867395: train Epoch: [20][ 75/193]	Time  0.571 ( 4.921)	Data  0.001 ( 4.350)	Loss 3.5786e-02 (1.0761e-01) 
2023-05-27 09:42:38.936115: train Epoch: [20][ 76/193]	Time 10.069 ( 4.987)	Data  9.504 ( 4.417)	Loss 8.2424e-02 (1.0728e-01) 
2023-05-27 09:42:39.520778: train Epoch: [20][ 77/193]	Time  0.585 ( 4.931)	Data  0.001 ( 4.361)	Loss 9.9070e-02 (1.0717e-01) 
2023-05-27 09:42:48.717306: train Epoch: [20][ 78/193]	Time  9.197 ( 4.985)	Data  8.631 ( 4.415)	Loss 1.7446e-01 (1.0803e-01) 
2023-05-27 09:42:49.289146: train Epoch: [20][ 79/193]	Time  0.572 ( 4.930)	Data  0.001 ( 4.360)	Loss 1.3194e-01 (1.0833e-01) 
2023-05-27 09:42:58.684534: train Epoch: [20][ 80/193]	Time  9.395 ( 4.985)	Data  8.817 ( 4.415)	Loss 8.9027e-02 (1.0809e-01) 
2023-05-27 09:42:59.257201: train Epoch: [20][ 81/193]	Time  0.573 ( 4.931)	Data  0.001 ( 4.361)	Loss 1.0505e-01 (1.0805e-01) 
2023-05-27 09:43:08.618692: train Epoch: [20][ 82/193]	Time  9.361 ( 4.984)	Data  8.797 ( 4.414)	Loss 9.2222e-02 (1.0786e-01) 
2023-05-27 09:43:09.198521: train Epoch: [20][ 83/193]	Time  0.580 ( 4.932)	Data  0.001 ( 4.362)	Loss 8.7828e-02 (1.0762e-01) 
2023-05-27 09:43:18.647377: train Epoch: [20][ 84/193]	Time  9.449 ( 4.985)	Data  8.888 ( 4.415)	Loss 8.9707e-02 (1.0741e-01) 
2023-05-27 09:43:19.225460: train Epoch: [20][ 85/193]	Time  0.578 ( 4.934)	Data  0.001 ( 4.364)	Loss 1.3794e-01 (1.0776e-01) 
2023-05-27 09:43:28.582428: train Epoch: [20][ 86/193]	Time  9.357 ( 4.985)	Data  8.757 ( 4.414)	Loss 8.6299e-02 (1.0752e-01) 
2023-05-27 09:43:29.167091: train Epoch: [20][ 87/193]	Time  0.585 ( 4.935)	Data  0.001 ( 4.364)	Loss 1.5181e-01 (1.0802e-01) 
2023-05-27 09:43:37.411885: train Epoch: [20][ 88/193]	Time  8.245 ( 4.972)	Data  7.672 ( 4.401)	Loss 7.9360e-02 (1.0770e-01) 
2023-05-27 09:43:37.984858: train Epoch: [20][ 89/193]	Time  0.573 ( 4.923)	Data  0.001 ( 4.352)	Loss 6.8515e-02 (1.0726e-01) 
2023-05-27 09:43:46.250851: train Epoch: [20][ 90/193]	Time  8.266 ( 4.960)	Data  7.687 ( 4.389)	Loss 5.0461e-02 (1.0664e-01) 
2023-05-27 09:43:46.813823: train Epoch: [20][ 91/193]	Time  0.563 ( 4.912)	Data  0.001 ( 4.341)	Loss 1.5612e-01 (1.0718e-01) 
2023-05-27 09:43:56.111960: train Epoch: [20][ 92/193]	Time  9.298 ( 4.959)	Data  8.672 ( 4.388)	Loss 9.9450e-02 (1.0709e-01) 
2023-05-27 09:43:56.683768: train Epoch: [20][ 93/193]	Time  0.572 ( 4.913)	Data  0.001 ( 4.341)	Loss 8.6863e-02 (1.0688e-01) 
2023-05-27 09:44:06.303561: train Epoch: [20][ 94/193]	Time  9.620 ( 4.962)	Data  9.048 ( 4.391)	Loss 7.1182e-02 (1.0650e-01) 
2023-05-27 09:44:06.869105: train Epoch: [20][ 95/193]	Time  0.566 ( 4.916)	Data  0.001 ( 4.345)	Loss 1.0071e-01 (1.0644e-01) 
2023-05-27 09:44:16.035977: train Epoch: [20][ 96/193]	Time  9.167 ( 4.960)	Data  8.573 ( 4.389)	Loss 9.5625e-02 (1.0633e-01) 
2023-05-27 09:44:16.603304: train Epoch: [20][ 97/193]	Time  0.567 ( 4.915)	Data  0.001 ( 4.344)	Loss 7.6261e-02 (1.0602e-01) 
2023-05-27 09:44:26.114973: train Epoch: [20][ 98/193]	Time  9.512 ( 4.962)	Data  8.944 ( 4.390)	Loss 6.6455e-02 (1.0563e-01) 
2023-05-27 09:44:26.677991: train Epoch: [20][ 99/193]	Time  0.563 ( 4.918)	Data  0.001 ( 4.346)	Loss 7.7605e-02 (1.0534e-01) 
2023-05-27 09:44:36.595098: train Epoch: [20][100/193]	Time  9.917 ( 4.967)	Data  9.346 ( 4.396)	Loss 1.3051e-01 (1.0559e-01) 
2023-05-27 09:44:37.159536: train Epoch: [20][101/193]	Time  0.564 ( 4.924)	Data  0.001 ( 4.353)	Loss 1.7610e-01 (1.0629e-01) 
2023-05-27 09:44:46.608327: train Epoch: [20][102/193]	Time  9.449 ( 4.968)	Data  8.885 ( 4.397)	Loss 8.9677e-02 (1.0612e-01) 
2023-05-27 09:44:47.173741: train Epoch: [20][103/193]	Time  0.565 ( 4.926)	Data  0.001 ( 4.355)	Loss 7.7236e-02 (1.0585e-01) 
2023-05-27 09:44:56.648794: train Epoch: [20][104/193]	Time  9.475 ( 4.969)	Data  8.907 ( 4.398)	Loss 1.0498e-01 (1.0584e-01) 
2023-05-27 09:44:57.218991: train Epoch: [20][105/193]	Time  0.570 ( 4.927)	Data  0.001 ( 4.356)	Loss 4.1767e-02 (1.0523e-01) 
2023-05-27 09:45:06.422696: train Epoch: [20][106/193]	Time  9.204 ( 4.967)	Data  8.634 ( 4.396)	Loss 7.0039e-02 (1.0490e-01) 
2023-05-27 09:45:06.993401: train Epoch: [20][107/193]	Time  0.571 ( 4.927)	Data  0.001 ( 4.356)	Loss 1.1117e-01 (1.0496e-01) 
2023-05-27 09:45:16.340187: train Epoch: [20][108/193]	Time  9.347 ( 4.967)	Data  8.772 ( 4.396)	Loss 1.1376e-01 (1.0504e-01) 
2023-05-27 09:45:16.911097: train Epoch: [20][109/193]	Time  0.571 ( 4.927)	Data  0.001 ( 4.356)	Loss 3.2954e-01 (1.0708e-01) 
2023-05-27 09:45:26.271237: train Epoch: [20][110/193]	Time  9.360 ( 4.967)	Data  8.798 ( 4.396)	Loss 1.0429e-01 (1.0706e-01) 
2023-05-27 09:45:26.835802: train Epoch: [20][111/193]	Time  0.565 ( 4.928)	Data  0.001 ( 4.357)	Loss 5.4040e-02 (1.0659e-01) 
2023-05-27 09:45:36.423820: train Epoch: [20][112/193]	Time  9.588 ( 4.969)	Data  9.024 ( 4.398)	Loss 1.0870e-01 (1.0660e-01) 
2023-05-27 09:45:36.988120: train Epoch: [20][113/193]	Time  0.564 ( 4.931)	Data  0.001 ( 4.360)	Loss 2.3921e-01 (1.0777e-01) 
2023-05-27 09:45:46.487897: train Epoch: [20][114/193]	Time  9.500 ( 4.970)	Data  8.936 ( 4.400)	Loss 1.2511e-01 (1.0792e-01) 
2023-05-27 09:45:47.051905: train Epoch: [20][115/193]	Time  0.564 ( 4.932)	Data  0.001 ( 4.362)	Loss 1.0030e-01 (1.0785e-01) 
2023-05-27 09:45:56.674342: train Epoch: [20][116/193]	Time  9.622 ( 4.972)	Data  9.060 ( 4.402)	Loss 1.0593e-01 (1.0784e-01) 
2023-05-27 09:45:57.239324: train Epoch: [20][117/193]	Time  0.565 ( 4.935)	Data  0.001 ( 4.364)	Loss 5.3018e-02 (1.0737e-01) 
2023-05-27 09:46:06.580087: train Epoch: [20][118/193]	Time  9.341 ( 4.972)	Data  8.770 ( 4.401)	Loss 7.2625e-02 (1.0708e-01) 
2023-05-27 09:46:07.147639: train Epoch: [20][119/193]	Time  0.568 ( 4.935)	Data  0.001 ( 4.365)	Loss 1.0433e-01 (1.0706e-01) 
2023-05-27 09:46:16.488513: train Epoch: [20][120/193]	Time  9.341 ( 4.972)	Data  8.777 ( 4.401)	Loss 1.0030e-01 (1.0700e-01) 
2023-05-27 09:46:17.051935: train Epoch: [20][121/193]	Time  0.563 ( 4.936)	Data  0.001 ( 4.365)	Loss 8.0570e-02 (1.0678e-01) 
2023-05-27 09:46:26.391609: train Epoch: [20][122/193]	Time  9.340 ( 4.971)	Data  8.777 ( 4.401)	Loss 7.5556e-02 (1.0653e-01) 
2023-05-27 09:46:26.956721: train Epoch: [20][123/193]	Time  0.565 ( 4.936)	Data  0.001 ( 4.366)	Loss 7.2158e-02 (1.0625e-01) 
2023-05-27 09:46:36.186671: train Epoch: [20][124/193]	Time  9.230 ( 4.970)	Data  8.667 ( 4.400)	Loss 6.1999e-02 (1.0590e-01) 
2023-05-27 09:46:36.753362: train Epoch: [20][125/193]	Time  0.567 ( 4.935)	Data  0.001 ( 4.365)	Loss 9.0773e-02 (1.0578e-01) 
2023-05-27 09:46:45.724698: train Epoch: [20][126/193]	Time  8.971 ( 4.967)	Data  8.400 ( 4.397)	Loss 1.3122e-01 (1.0598e-01) 
2023-05-27 09:46:46.288266: train Epoch: [20][127/193]	Time  0.564 ( 4.933)	Data  0.001 ( 4.363)	Loss 9.0221e-02 (1.0586e-01) 
2023-05-27 09:46:55.581913: train Epoch: [20][128/193]	Time  9.294 ( 4.966)	Data  8.730 ( 4.396)	Loss 6.3453e-02 (1.0553e-01) 
2023-05-27 09:46:56.146411: train Epoch: [20][129/193]	Time  0.564 ( 4.933)	Data  0.001 ( 4.363)	Loss 9.0221e-02 (1.0541e-01) 
2023-05-27 09:47:05.118468: train Epoch: [20][130/193]	Time  8.972 ( 4.963)	Data  8.408 ( 4.393)	Loss 9.4567e-02 (1.0533e-01) 
2023-05-27 09:47:05.683269: train Epoch: [20][131/193]	Time  0.565 ( 4.930)	Data  0.001 ( 4.360)	Loss 1.0984e-01 (1.0536e-01) 
2023-05-27 09:47:14.825748: train Epoch: [20][132/193]	Time  9.142 ( 4.962)	Data  8.577 ( 4.392)	Loss 1.4564e-01 (1.0566e-01) 
2023-05-27 09:47:15.391076: train Epoch: [20][133/193]	Time  0.565 ( 4.929)	Data  0.001 ( 4.359)	Loss 6.5420e-02 (1.0536e-01) 
2023-05-27 09:47:24.572124: train Epoch: [20][134/193]	Time  9.181 ( 4.960)	Data  8.614 ( 4.391)	Loss 5.2152e-02 (1.0497e-01) 
2023-05-27 09:47:25.139450: train Epoch: [20][135/193]	Time  0.567 ( 4.928)	Data  0.001 ( 4.358)	Loss 9.8274e-02 (1.0492e-01) 
2023-05-27 09:47:34.682917: train Epoch: [20][136/193]	Time  9.543 ( 4.962)	Data  8.956 ( 4.392)	Loss 6.1643e-02 (1.0460e-01) 
2023-05-27 09:47:35.247857: train Epoch: [20][137/193]	Time  0.565 ( 4.930)	Data  0.001 ( 4.360)	Loss 9.2137e-02 (1.0451e-01) 
2023-05-27 09:47:44.560324: train Epoch: [20][138/193]	Time  9.312 ( 4.962)	Data  8.750 ( 4.392)	Loss 5.8630e-02 (1.0418e-01) 
2023-05-27 09:47:45.128201: train Epoch: [20][139/193]	Time  0.568 ( 4.930)	Data  0.001 ( 4.360)	Loss 6.4932e-02 (1.0390e-01) 
2023-05-27 09:47:55.032191: train Epoch: [20][140/193]	Time  9.904 ( 4.965)	Data  9.338 ( 4.396)	Loss 9.2745e-02 (1.0382e-01) 
2023-05-27 09:47:55.597398: train Epoch: [20][141/193]	Time  0.565 ( 4.934)	Data  0.001 ( 4.365)	Loss 6.1708e-02 (1.0353e-01) 
2023-05-27 09:48:04.759345: train Epoch: [20][142/193]	Time  9.162 ( 4.964)	Data  8.597 ( 4.394)	Loss 2.2738e-01 (1.0439e-01) 
2023-05-27 09:48:05.322969: train Epoch: [20][143/193]	Time  0.564 ( 4.933)	Data  0.001 ( 4.364)	Loss 5.9297e-02 (1.0408e-01) 
2023-05-27 09:48:14.357701: train Epoch: [20][144/193]	Time  9.035 ( 4.962)	Data  8.466 ( 4.392)	Loss 5.0336e-02 (1.0371e-01) 
2023-05-27 09:48:14.926614: train Epoch: [20][145/193]	Time  0.569 ( 4.932)	Data  0.001 ( 4.362)	Loss 8.3632e-02 (1.0357e-01) 
2023-05-27 09:48:24.275269: train Epoch: [20][146/193]	Time  9.349 ( 4.962)	Data  8.770 ( 4.392)	Loss 1.2568e-01 (1.0372e-01) 
2023-05-27 09:48:24.838017: train Epoch: [20][147/193]	Time  0.563 ( 4.932)	Data  0.001 ( 4.362)	Loss 2.4979e-01 (1.0471e-01) 
2023-05-27 09:48:34.462617: train Epoch: [20][148/193]	Time  9.625 ( 4.963)	Data  9.063 ( 4.394)	Loss 6.1189e-02 (1.0442e-01) 
2023-05-27 09:48:35.026433: train Epoch: [20][149/193]	Time  0.564 ( 4.934)	Data  0.001 ( 4.365)	Loss 1.2504e-01 (1.0456e-01) 
2023-05-27 09:48:44.653751: train Epoch: [20][150/193]	Time  9.627 ( 4.965)	Data  9.062 ( 4.396)	Loss 1.2329e-01 (1.0468e-01) 
2023-05-27 09:48:45.217957: train Epoch: [20][151/193]	Time  0.564 ( 4.936)	Data  0.001 ( 4.367)	Loss 1.4192e-01 (1.0492e-01) 
2023-05-27 09:48:54.457695: train Epoch: [20][152/193]	Time  9.240 ( 4.964)	Data  8.675 ( 4.395)	Loss 9.3888e-02 (1.0485e-01) 
2023-05-27 09:48:55.021945: train Epoch: [20][153/193]	Time  0.564 ( 4.936)	Data  0.001 ( 4.366)	Loss 7.2207e-02 (1.0464e-01) 
2023-05-27 09:49:04.809160: train Epoch: [20][154/193]	Time  9.787 ( 4.967)	Data  9.218 ( 4.398)	Loss 7.8011e-02 (1.0447e-01) 
2023-05-27 09:49:05.372239: train Epoch: [20][155/193]	Time  0.563 ( 4.939)	Data  0.001 ( 4.369)	Loss 9.9792e-02 (1.0444e-01) 
2023-05-27 09:49:14.462000: train Epoch: [20][156/193]	Time  9.090 ( 4.965)	Data  8.521 ( 4.396)	Loss 9.3635e-02 (1.0437e-01) 
2023-05-27 09:49:15.030839: train Epoch: [20][157/193]	Time  0.569 ( 4.937)	Data  0.001 ( 4.368)	Loss 9.2671e-02 (1.0430e-01) 
2023-05-27 09:49:24.514512: train Epoch: [20][158/193]	Time  9.484 ( 4.966)	Data  8.917 ( 4.397)	Loss 7.2197e-02 (1.0409e-01) 
2023-05-27 09:49:25.081975: train Epoch: [20][159/193]	Time  0.567 ( 4.939)	Data  0.001 ( 4.369)	Loss 8.8078e-02 (1.0399e-01) 
2023-05-27 09:49:34.386403: train Epoch: [20][160/193]	Time  9.304 ( 4.966)	Data  8.739 ( 4.396)	Loss 1.1327e-01 (1.0405e-01) 
2023-05-27 09:49:34.953433: train Epoch: [20][161/193]	Time  0.567 ( 4.939)	Data  0.001 ( 4.369)	Loss 9.8338e-02 (1.0402e-01) 
2023-05-27 09:49:44.836350: train Epoch: [20][162/193]	Time  9.883 ( 4.969)	Data  9.314 ( 4.400)	Loss 5.0564e-02 (1.0369e-01) 
2023-05-27 09:49:45.403034: train Epoch: [20][163/193]	Time  0.567 ( 4.942)	Data  0.001 ( 4.373)	Loss 1.0303e-01 (1.0368e-01) 
2023-05-27 09:49:54.612024: train Epoch: [20][164/193]	Time  9.209 ( 4.968)	Data  8.633 ( 4.399)	Loss 7.9512e-02 (1.0354e-01) 
2023-05-27 09:49:55.190975: train Epoch: [20][165/193]	Time  0.579 ( 4.941)	Data  0.001 ( 4.372)	Loss 1.0474e-01 (1.0354e-01) 
2023-05-27 09:50:05.035444: train Epoch: [20][166/193]	Time  9.844 ( 4.971)	Data  9.275 ( 4.401)	Loss 1.1044e-01 (1.0359e-01) 
2023-05-27 09:50:05.611105: train Epoch: [20][167/193]	Time  0.576 ( 4.945)	Data  0.001 ( 4.375)	Loss 5.1332e-02 (1.0328e-01) 
2023-05-27 09:50:14.954266: train Epoch: [20][168/193]	Time  9.343 ( 4.971)	Data  8.773 ( 4.401)	Loss 1.2745e-01 (1.0342e-01) 
2023-05-27 09:50:15.521781: train Epoch: [20][169/193]	Time  0.567 ( 4.945)	Data  0.001 ( 4.375)	Loss 1.9113e-01 (1.0393e-01) 
2023-05-27 09:50:24.574096: train Epoch: [20][170/193]	Time  9.052 ( 4.969)	Data  8.475 ( 4.399)	Loss 7.3932e-02 (1.0376e-01) 
2023-05-27 09:50:25.142946: train Epoch: [20][171/193]	Time  0.569 ( 4.943)	Data  0.001 ( 4.374)	Loss 8.7921e-02 (1.0367e-01) 
2023-05-27 09:50:34.479170: train Epoch: [20][172/193]	Time  9.336 ( 4.969)	Data  8.757 ( 4.399)	Loss 7.7646e-02 (1.0352e-01) 
2023-05-27 09:50:35.055298: train Epoch: [20][173/193]	Time  0.576 ( 4.943)	Data  0.001 ( 4.374)	Loss 5.2736e-02 (1.0322e-01) 
2023-05-27 09:50:44.629266: train Epoch: [20][174/193]	Time  9.574 ( 4.970)	Data  9.006 ( 4.400)	Loss 1.2058e-01 (1.0332e-01) 
2023-05-27 09:50:45.207580: train Epoch: [20][175/193]	Time  0.578 ( 4.945)	Data  0.001 ( 4.375)	Loss 8.7422e-02 (1.0323e-01) 
2023-05-27 09:50:54.954654: train Epoch: [20][176/193]	Time  9.747 ( 4.972)	Data  9.175 ( 4.402)	Loss 1.1418e-01 (1.0330e-01) 
2023-05-27 09:50:55.548248: train Epoch: [20][177/193]	Time  0.594 ( 4.947)	Data  0.001 ( 4.378)	Loss 1.0657e-01 (1.0331e-01) 
2023-05-27 09:51:04.852618: train Epoch: [20][178/193]	Time  9.304 ( 4.972)	Data  8.733 ( 4.402)	Loss 7.2298e-02 (1.0314e-01) 
2023-05-27 09:51:05.433745: train Epoch: [20][179/193]	Time  0.581 ( 4.947)	Data  0.001 ( 4.378)	Loss 7.1146e-02 (1.0296e-01) 
2023-05-27 09:51:14.933852: train Epoch: [20][180/193]	Time  9.500 ( 4.973)	Data  8.929 ( 4.403)	Loss 1.5757e-01 (1.0326e-01) 
2023-05-27 09:51:15.515660: train Epoch: [20][181/193]	Time  0.582 ( 4.948)	Data  0.001 ( 4.379)	Loss 5.8749e-02 (1.0302e-01) 
2023-05-27 09:51:25.039786: train Epoch: [20][182/193]	Time  9.524 ( 4.973)	Data  8.938 ( 4.403)	Loss 1.9998e-01 (1.0355e-01) 
2023-05-27 09:51:25.633916: train Epoch: [20][183/193]	Time  0.594 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.7827e-01 (1.0396e-01) 
2023-05-27 09:51:34.963911: train Epoch: [20][184/193]	Time  9.330 ( 4.973)	Data  8.764 ( 4.403)	Loss 9.0808e-02 (1.0388e-01) 
2023-05-27 09:51:35.544962: train Epoch: [20][185/193]	Time  0.581 ( 4.950)	Data  0.001 ( 4.380)	Loss 8.1207e-02 (1.0376e-01) 
2023-05-27 09:51:44.926728: train Epoch: [20][186/193]	Time  9.382 ( 4.973)	Data  8.780 ( 4.403)	Loss 6.4443e-02 (1.0355e-01) 
2023-05-27 09:51:45.492535: train Epoch: [20][187/193]	Time  0.566 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.3418e-01 (1.0372e-01) 
2023-05-27 09:51:54.577553: train Epoch: [20][188/193]	Time  9.085 ( 4.972)	Data  8.518 ( 4.402)	Loss 1.3373e-01 (1.0387e-01) 
2023-05-27 09:51:55.152637: train Epoch: [20][189/193]	Time  0.575 ( 4.949)	Data  0.001 ( 4.378)	Loss 1.8501e-01 (1.0430e-01) 
2023-05-27 09:52:04.321577: train Epoch: [20][190/193]	Time  9.169 ( 4.971)	Data  8.597 ( 4.401)	Loss 5.2737e-02 (1.0403e-01) 
2023-05-27 09:52:04.908798: train Epoch: [20][191/193]	Time  0.587 ( 4.948)	Data  0.001 ( 4.378)	Loss 1.2259e-01 (1.0413e-01) 
2023-05-27 09:52:13.079904: train Epoch: [20][192/193]	Time  8.171 ( 4.965)	Data  7.578 ( 4.394)	Loss 1.0936e-01 (1.0415e-01) 
2023-05-27 09:52:13.215075: Train Epoch done in 958.3090994030063 s 
2023-05-27 09:52:19.817830: val Epoch: [20][ 0/72]	Time  5.819 ( 5.819)	Data  5.633 ( 5.633)	Loss 1.7753e-01 (1.7753e-01) 
2023-05-27 09:52:19.928838: val Epoch: [20][ 1/72]	Time  0.111 ( 2.965)	Data  0.002 ( 2.817)	Loss 4.3546e-02 (1.1054e-01) 
2023-05-27 09:52:24.803898: val Epoch: [20][ 2/72]	Time  4.875 ( 3.602)	Data  4.766 ( 3.467)	Loss 3.4903e-01 (1.9004e-01) 
2023-05-27 09:52:24.911839: val Epoch: [20][ 3/72]	Time  0.108 ( 2.728)	Data  0.001 ( 2.600)	Loss 1.1541e-01 (1.7138e-01) 
2023-05-27 09:52:30.233775: val Epoch: [20][ 4/72]	Time  5.322 ( 3.247)	Data  5.215 ( 3.123)	Loss 1.0001e-01 (1.5711e-01) 
2023-05-27 09:52:30.341122: val Epoch: [20][ 5/72]	Time  0.107 ( 2.724)	Data  0.000 ( 2.603)	Loss 7.6998e-02 (1.4375e-01) 
2023-05-27 09:52:35.337531: val Epoch: [20][ 6/72]	Time  4.996 ( 3.048)	Data  4.881 ( 2.928)	Loss 1.3327e-01 (1.4226e-01) 
2023-05-27 09:52:35.445600: val Epoch: [20][ 7/72]	Time  0.108 ( 2.681)	Data  0.001 ( 2.562)	Loss 8.2858e-02 (1.3483e-01) 
2023-05-27 09:52:40.165182: val Epoch: [20][ 8/72]	Time  4.720 ( 2.907)	Data  4.614 ( 2.790)	Loss 4.6707e-02 (1.2504e-01) 
2023-05-27 09:52:40.269581: val Epoch: [20][ 9/72]	Time  0.104 ( 2.627)	Data  0.000 ( 2.511)	Loss 1.0332e-01 (1.2287e-01) 
2023-05-27 09:52:45.025063: val Epoch: [20][10/72]	Time  4.755 ( 2.821)	Data  4.648 ( 2.706)	Loss 7.2297e-02 (1.1827e-01) 
2023-05-27 09:52:45.132690: val Epoch: [20][11/72]	Time  0.108 ( 2.594)	Data  0.001 ( 2.480)	Loss 5.5445e-02 (1.1304e-01) 
2023-05-27 09:52:50.106940: val Epoch: [20][12/72]	Time  4.974 ( 2.778)	Data  4.864 ( 2.664)	Loss 3.9074e-02 (1.0735e-01) 
2023-05-27 09:52:50.215296: val Epoch: [20][13/72]	Time  0.108 ( 2.587)	Data  0.001 ( 2.473)	Loss 7.9975e-02 (1.0539e-01) 
2023-05-27 09:52:55.325096: val Epoch: [20][14/72]	Time  5.110 ( 2.755)	Data  4.997 ( 2.642)	Loss 6.5165e-02 (1.0271e-01) 
2023-05-27 09:52:55.435209: val Epoch: [20][15/72]	Time  0.110 ( 2.590)	Data  0.001 ( 2.477)	Loss 3.4236e-01 (1.1769e-01) 
2023-05-27 09:53:00.490767: val Epoch: [20][16/72]	Time  5.056 ( 2.735)	Data  4.951 ( 2.622)	Loss 5.7322e-02 (1.1414e-01) 
2023-05-27 09:53:00.595799: val Epoch: [20][17/72]	Time  0.105 ( 2.589)	Data  0.000 ( 2.476)	Loss 8.9101e-02 (1.1275e-01) 
2023-05-27 09:53:05.792404: val Epoch: [20][18/72]	Time  5.197 ( 2.726)	Data  5.088 ( 2.614)	Loss 4.0148e-01 (1.2794e-01) 
2023-05-27 09:53:05.926487: val Epoch: [20][19/72]	Time  0.134 ( 2.596)	Data  0.001 ( 2.483)	Loss 6.0708e-02 (1.2458e-01) 
2023-05-27 09:53:10.833386: val Epoch: [20][20/72]	Time  4.907 ( 2.706)	Data  4.794 ( 2.593)	Loss 2.0503e-01 (1.2841e-01) 
2023-05-27 09:53:10.943753: val Epoch: [20][21/72]	Time  0.110 ( 2.588)	Data  0.001 ( 2.475)	Loss 7.9620e-02 (1.2619e-01) 
2023-05-27 09:53:15.692290: val Epoch: [20][22/72]	Time  4.749 ( 2.682)	Data  4.642 ( 2.570)	Loss 1.2910e-01 (1.2632e-01) 
2023-05-27 09:53:15.802508: val Epoch: [20][23/72]	Time  0.110 ( 2.575)	Data  0.001 ( 2.463)	Loss 1.8102e-01 (1.2860e-01) 
2023-05-27 09:53:20.702628: val Epoch: [20][24/72]	Time  4.900 ( 2.668)	Data  4.794 ( 2.556)	Loss 6.4817e-02 (1.2605e-01) 
2023-05-27 09:53:20.814000: val Epoch: [20][25/72]	Time  0.111 ( 2.570)	Data  0.000 ( 2.458)	Loss 7.0914e-02 (1.2393e-01) 
2023-05-27 09:53:25.553501: val Epoch: [20][26/72]	Time  4.739 ( 2.650)	Data  4.632 ( 2.538)	Loss 1.5797e-01 (1.2519e-01) 
2023-05-27 09:53:25.661202: val Epoch: [20][27/72]	Time  0.108 ( 2.559)	Data  0.000 ( 2.447)	Loss 1.4348e-01 (1.2584e-01) 
2023-05-27 09:53:30.494860: val Epoch: [20][28/72]	Time  4.834 ( 2.638)	Data  4.726 ( 2.526)	Loss 7.0037e-02 (1.2392e-01) 
2023-05-27 09:53:30.601731: val Epoch: [20][29/72]	Time  0.107 ( 2.553)	Data  0.000 ( 2.442)	Loss 7.6962e-02 (1.2235e-01) 
2023-05-27 09:53:35.786217: val Epoch: [20][30/72]	Time  5.184 ( 2.638)	Data  5.066 ( 2.526)	Loss 8.3596e-02 (1.2110e-01) 
2023-05-27 09:53:35.903332: val Epoch: [20][31/72]	Time  0.117 ( 2.560)	Data  0.001 ( 2.448)	Loss 3.0943e-01 (1.2699e-01) 
2023-05-27 09:53:41.001875: val Epoch: [20][32/72]	Time  5.099 ( 2.636)	Data  4.985 ( 2.524)	Loss 1.1973e-01 (1.2677e-01) 
2023-05-27 09:53:41.112137: val Epoch: [20][33/72]	Time  0.110 ( 2.562)	Data  0.001 ( 2.450)	Loss 9.8748e-02 (1.2594e-01) 
2023-05-27 09:53:45.953028: val Epoch: [20][34/72]	Time  4.841 ( 2.627)	Data  4.733 ( 2.515)	Loss 5.6959e-02 (1.2397e-01) 
2023-05-27 09:53:46.065987: val Epoch: [20][35/72]	Time  0.113 ( 2.557)	Data  0.001 ( 2.446)	Loss 1.1705e-01 (1.2378e-01) 
2023-05-27 09:53:51.033460: val Epoch: [20][36/72]	Time  4.967 ( 2.623)	Data  4.816 ( 2.510)	Loss 9.2354e-02 (1.2293e-01) 
2023-05-27 09:53:51.167661: val Epoch: [20][37/72]	Time  0.134 ( 2.557)	Data  0.003 ( 2.444)	Loss 5.0179e-02 (1.2102e-01) 
2023-05-27 09:53:56.192299: val Epoch: [20][38/72]	Time  5.025 ( 2.620)	Data  4.917 ( 2.507)	Loss 4.5458e-01 (1.2957e-01) 
2023-05-27 09:53:56.300762: val Epoch: [20][39/72]	Time  0.108 ( 2.558)	Data  0.001 ( 2.444)	Loss 3.9177e-01 (1.3612e-01) 
2023-05-27 09:54:01.175994: val Epoch: [20][40/72]	Time  4.875 ( 2.614)	Data  4.767 ( 2.501)	Loss 8.4623e-02 (1.3487e-01) 
2023-05-27 09:54:01.284412: val Epoch: [20][41/72]	Time  0.108 ( 2.554)	Data  0.001 ( 2.442)	Loss 2.2664e-01 (1.3705e-01) 
2023-05-27 09:54:06.411517: val Epoch: [20][42/72]	Time  5.127 ( 2.614)	Data  5.020 ( 2.502)	Loss 3.5567e-01 (1.4214e-01) 
2023-05-27 09:54:06.519248: val Epoch: [20][43/72]	Time  0.108 ( 2.557)	Data  0.001 ( 2.445)	Loss 5.5866e-02 (1.4018e-01) 
2023-05-27 09:54:11.075532: val Epoch: [20][44/72]	Time  4.556 ( 2.602)	Data  4.449 ( 2.489)	Loss 9.2453e-02 (1.3912e-01) 
2023-05-27 09:54:11.183380: val Epoch: [20][45/72]	Time  0.108 ( 2.547)	Data  0.001 ( 2.435)	Loss 1.8921e-01 (1.4020e-01) 
2023-05-27 09:54:15.973879: val Epoch: [20][46/72]	Time  4.790 ( 2.595)	Data  4.683 ( 2.483)	Loss 8.3625e-02 (1.3900e-01) 
2023-05-27 09:54:16.082035: val Epoch: [20][47/72]	Time  0.108 ( 2.543)	Data  0.001 ( 2.431)	Loss 1.3760e-01 (1.3897e-01) 
2023-05-27 09:54:20.972944: val Epoch: [20][48/72]	Time  4.891 ( 2.591)	Data  4.783 ( 2.479)	Loss 4.5753e-02 (1.3707e-01) 
2023-05-27 09:54:21.079606: val Epoch: [20][49/72]	Time  0.107 ( 2.542)	Data  0.001 ( 2.430)	Loss 9.9530e-02 (1.3632e-01) 
2023-05-27 09:54:26.006177: val Epoch: [20][50/72]	Time  4.927 ( 2.588)	Data  4.817 ( 2.476)	Loss 1.5215e-01 (1.3663e-01) 
2023-05-27 09:54:26.114793: val Epoch: [20][51/72]	Time  0.109 ( 2.541)	Data  0.000 ( 2.429)	Loss 5.6067e-02 (1.3508e-01) 
2023-05-27 09:54:31.105216: val Epoch: [20][52/72]	Time  4.990 ( 2.587)	Data  4.870 ( 2.475)	Loss 2.9306e-01 (1.3806e-01) 
2023-05-27 09:54:31.222584: val Epoch: [20][53/72]	Time  0.117 ( 2.541)	Data  0.001 ( 2.429)	Loss 5.0026e-02 (1.3643e-01) 
2023-05-27 09:54:36.245067: val Epoch: [20][54/72]	Time  5.022 ( 2.586)	Data  4.906 ( 2.474)	Loss 6.1482e-02 (1.3507e-01) 
2023-05-27 09:54:36.358731: val Epoch: [20][55/72]	Time  0.114 ( 2.542)	Data  0.001 ( 2.430)	Loss 1.3325e-01 (1.3504e-01) 
2023-05-27 09:54:41.584386: val Epoch: [20][56/72]	Time  5.226 ( 2.589)	Data  5.105 ( 2.477)	Loss 1.1484e-01 (1.3468e-01) 
2023-05-27 09:54:41.696432: val Epoch: [20][57/72]	Time  0.112 ( 2.547)	Data  0.001 ( 2.434)	Loss 6.3291e-02 (1.3345e-01) 
2023-05-27 09:54:46.828976: val Epoch: [20][58/72]	Time  5.133 ( 2.590)	Data  5.025 ( 2.478)	Loss 2.5235e-01 (1.3547e-01) 
2023-05-27 09:54:46.935781: val Epoch: [20][59/72]	Time  0.107 ( 2.549)	Data  0.001 ( 2.437)	Loss 5.5936e-01 (1.4253e-01) 
2023-05-27 09:54:51.610740: val Epoch: [20][60/72]	Time  4.675 ( 2.584)	Data  4.570 ( 2.472)	Loss 5.8046e-02 (1.4115e-01) 
2023-05-27 09:54:51.718364: val Epoch: [20][61/72]	Time  0.108 ( 2.544)	Data  0.000 ( 2.432)	Loss 1.9510e-01 (1.4202e-01) 
2023-05-27 09:54:56.563498: val Epoch: [20][62/72]	Time  4.845 ( 2.580)	Data  4.729 ( 2.468)	Loss 9.9428e-02 (1.4134e-01) 
2023-05-27 09:54:56.676921: val Epoch: [20][63/72]	Time  0.113 ( 2.542)	Data  0.001 ( 2.430)	Loss 1.2260e-01 (1.4105e-01) 
2023-05-27 09:55:01.524545: val Epoch: [20][64/72]	Time  4.848 ( 2.577)	Data  4.727 ( 2.465)	Loss 6.4111e-02 (1.3986e-01) 
2023-05-27 09:55:01.636660: val Epoch: [20][65/72]	Time  0.112 ( 2.540)	Data  0.001 ( 2.428)	Loss 1.7817e-01 (1.4044e-01) 
2023-05-27 09:55:06.724530: val Epoch: [20][66/72]	Time  5.088 ( 2.578)	Data  4.978 ( 2.466)	Loss 9.4430e-02 (1.3976e-01) 
2023-05-27 09:55:06.829656: val Epoch: [20][67/72]	Time  0.105 ( 2.542)	Data  0.001 ( 2.430)	Loss 8.9758e-02 (1.3902e-01) 
2023-05-27 09:55:11.934448: val Epoch: [20][68/72]	Time  5.105 ( 2.579)	Data  4.992 ( 2.467)	Loss 1.4981e-01 (1.3918e-01) 
2023-05-27 09:55:12.046355: val Epoch: [20][69/72]	Time  0.112 ( 2.544)	Data  0.000 ( 2.432)	Loss 3.4740e-01 (1.4215e-01) 
2023-05-27 09:55:16.391908: val Epoch: [20][70/72]	Time  4.346 ( 2.569)	Data  4.224 ( 2.457)	Loss 5.2762e-02 (1.4089e-01) 
2023-05-27 09:55:16.510342: val Epoch: [20][71/72]	Time  0.118 ( 2.535)	Data  0.001 ( 2.423)	Loss 7.3229e-02 (1.3995e-01) 
2023-05-27 09:55:16.842499: Epoch 20 :Val : ['ET : 0.7172300815582275', 'TC : 0.7776538133621216', 'WT : 0.8456411361694336'] 
2023-05-27 09:55:16.847852: Epoch 20 :Val : ['ET : 0.7172300815582275', 'TC : 0.7776538133621216', 'WT : 0.8456411361694336'] 
2023-05-27 09:55:16.849973: Saving the model with DSC 0.786614716053009 
2023-05-27 09:55:17.520830: Val epoch done in 184.30573966901284 s 
2023-05-27 09:55:17.527666: Batches per epoch:  193 
2023-05-27 09:55:29.064989: train Epoch: [21][  0/193]	Time 11.537 (11.537)	Data 10.911 (10.911)	Loss 5.5880e-02 (5.5880e-02) 
2023-05-27 09:55:29.637032: train Epoch: [21][  1/193]	Time  0.572 ( 6.055)	Data  0.001 ( 5.456)	Loss 9.3095e-02 (7.4488e-02) 
2023-05-27 09:55:39.113132: train Epoch: [21][  2/193]	Time  9.476 ( 7.195)	Data  8.905 ( 6.606)	Loss 8.8911e-02 (7.9295e-02) 
2023-05-27 09:55:39.692695: train Epoch: [21][  3/193]	Time  0.580 ( 5.541)	Data  0.001 ( 4.954)	Loss 2.4267e-01 (1.2014e-01) 
2023-05-27 09:55:49.676046: train Epoch: [21][  4/193]	Time  9.983 ( 6.430)	Data  9.390 ( 5.841)	Loss 1.2536e-01 (1.2118e-01) 
2023-05-27 09:55:50.266865: train Epoch: [21][  5/193]	Time  0.591 ( 5.456)	Data  0.001 ( 4.868)	Loss 7.7085e-02 (1.1383e-01) 
2023-05-27 09:55:59.777522: train Epoch: [21][  6/193]	Time  9.511 ( 6.036)	Data  8.932 ( 5.449)	Loss 6.4041e-02 (1.0672e-01) 
2023-05-27 09:56:00.342586: train Epoch: [21][  7/193]	Time  0.565 ( 5.352)	Data  0.001 ( 4.768)	Loss 1.4655e-01 (1.1170e-01) 
2023-05-27 09:56:10.195451: train Epoch: [21][  8/193]	Time  9.853 ( 5.852)	Data  9.276 ( 5.269)	Loss 1.1649e-01 (1.1223e-01) 
2023-05-27 09:56:10.761600: train Epoch: [21][  9/193]	Time  0.566 ( 5.323)	Data  0.001 ( 4.742)	Loss 2.1608e-01 (1.2262e-01) 
2023-05-27 09:56:20.449068: train Epoch: [21][ 10/193]	Time  9.687 ( 5.720)	Data  9.083 ( 5.136)	Loss 8.5322e-02 (1.1923e-01) 
2023-05-27 09:56:21.034907: train Epoch: [21][ 11/193]	Time  0.586 ( 5.292)	Data  0.001 ( 4.708)	Loss 7.5449e-02 (1.1558e-01) 
2023-05-27 09:56:30.537196: train Epoch: [21][ 12/193]	Time  9.502 ( 5.616)	Data  8.896 ( 5.031)	Loss 1.0115e-01 (1.1447e-01) 
2023-05-27 09:56:31.110271: train Epoch: [21][ 13/193]	Time  0.573 ( 5.256)	Data  0.001 ( 4.671)	Loss 1.1927e-01 (1.1481e-01) 
2023-05-27 09:56:40.486643: train Epoch: [21][ 14/193]	Time  9.376 ( 5.531)	Data  8.813 ( 4.947)	Loss 8.6718e-02 (1.1294e-01) 
2023-05-27 09:56:41.067635: train Epoch: [21][ 15/193]	Time  0.581 ( 5.221)	Data  0.001 ( 4.638)	Loss 8.0101e-02 (1.1089e-01) 
2023-05-27 09:56:49.714559: train Epoch: [21][ 16/193]	Time  8.647 ( 5.423)	Data  8.075 ( 4.840)	Loss 8.5971e-02 (1.0942e-01) 
2023-05-27 09:56:50.277827: train Epoch: [21][ 17/193]	Time  0.563 ( 5.153)	Data  0.001 ( 4.572)	Loss 1.0475e-01 (1.0916e-01) 
2023-05-27 09:56:59.629771: train Epoch: [21][ 18/193]	Time  9.352 ( 5.374)	Data  8.776 ( 4.793)	Loss 7.0329e-02 (1.0712e-01) 
2023-05-27 09:57:00.199336: train Epoch: [21][ 19/193]	Time  0.570 ( 5.134)	Data  0.001 ( 4.553)	Loss 6.6328e-02 (1.0508e-01) 
2023-05-27 09:57:09.392461: train Epoch: [21][ 20/193]	Time  9.193 ( 5.327)	Data  8.618 ( 4.747)	Loss 7.9009e-02 (1.0384e-01) 
2023-05-27 09:57:09.954927: train Epoch: [21][ 21/193]	Time  0.562 ( 5.110)	Data  0.001 ( 4.531)	Loss 8.2987e-02 (1.0289e-01) 
2023-05-27 09:57:19.431024: train Epoch: [21][ 22/193]	Time  9.476 ( 5.300)	Data  8.912 ( 4.722)	Loss 6.8061e-02 (1.0137e-01) 
2023-05-27 09:57:19.994944: train Epoch: [21][ 23/193]	Time  0.564 ( 5.103)	Data  0.001 ( 4.525)	Loss 1.7145e-01 (1.0429e-01) 
2023-05-27 09:57:29.194142: train Epoch: [21][ 24/193]	Time  9.199 ( 5.267)	Data  8.631 ( 4.689)	Loss 1.0082e-01 (1.0416e-01) 
2023-05-27 09:57:29.764559: train Epoch: [21][ 25/193]	Time  0.570 ( 5.086)	Data  0.001 ( 4.509)	Loss 4.7460e-02 (1.0197e-01) 
2023-05-27 09:57:38.679893: train Epoch: [21][ 26/193]	Time  8.915 ( 5.228)	Data  8.333 ( 4.650)	Loss 8.5674e-02 (1.0137e-01) 
2023-05-27 09:57:39.242246: train Epoch: [21][ 27/193]	Time  0.562 ( 5.061)	Data  0.001 ( 4.484)	Loss 7.7897e-02 (1.0053e-01) 
2023-05-27 09:57:47.080498: train Epoch: [21][ 28/193]	Time  7.838 ( 5.157)	Data  7.263 ( 4.580)	Loss 5.6700e-02 (9.9021e-02) 
2023-05-27 09:57:47.651663: train Epoch: [21][ 29/193]	Time  0.571 ( 5.004)	Data  0.001 ( 4.427)	Loss 1.4531e-01 (1.0056e-01) 
2023-05-27 09:57:56.551643: train Epoch: [21][ 30/193]	Time  8.900 ( 5.130)	Data  8.336 ( 4.554)	Loss 1.4246e-01 (1.0192e-01) 
2023-05-27 09:57:57.113766: train Epoch: [21][ 31/193]	Time  0.562 ( 4.987)	Data  0.001 ( 4.411)	Loss 9.5132e-02 (1.0170e-01) 
2023-05-27 09:58:06.578841: train Epoch: [21][ 32/193]	Time  9.465 ( 5.123)	Data  8.900 ( 4.547)	Loss 9.1458e-02 (1.0139e-01) 
2023-05-27 09:58:07.150023: train Epoch: [21][ 33/193]	Time  0.571 ( 4.989)	Data  0.001 ( 4.414)	Loss 6.3007e-02 (1.0026e-01) 
2023-05-27 09:58:16.547538: train Epoch: [21][ 34/193]	Time  9.397 ( 5.115)	Data  8.831 ( 4.540)	Loss 1.3516e-01 (1.0126e-01) 
2023-05-27 09:58:17.121508: train Epoch: [21][ 35/193]	Time  0.574 ( 4.989)	Data  0.001 ( 4.414)	Loss 1.5060e-01 (1.0263e-01) 
2023-05-27 09:58:26.805140: train Epoch: [21][ 36/193]	Time  9.684 ( 5.116)	Data  9.102 ( 4.540)	Loss 6.9672e-02 (1.0174e-01) 
2023-05-27 09:58:27.372163: train Epoch: [21][ 37/193]	Time  0.567 ( 4.996)	Data  0.001 ( 4.421)	Loss 1.4426e-01 (1.0286e-01) 
2023-05-27 09:58:36.619040: train Epoch: [21][ 38/193]	Time  9.247 ( 5.105)	Data  8.683 ( 4.530)	Loss 7.7164e-02 (1.0220e-01) 
2023-05-27 09:58:37.192613: train Epoch: [21][ 39/193]	Time  0.574 ( 4.992)	Data  0.001 ( 4.417)	Loss 8.8066e-02 (1.0185e-01) 
2023-05-27 09:58:46.364380: train Epoch: [21][ 40/193]	Time  9.172 ( 5.094)	Data  8.599 ( 4.519)	Loss 1.7695e-01 (1.0368e-01) 
2023-05-27 09:58:46.943857: train Epoch: [21][ 41/193]	Time  0.579 ( 4.986)	Data  0.001 ( 4.411)	Loss 1.1658e-01 (1.0399e-01) 
2023-05-27 09:58:55.937338: train Epoch: [21][ 42/193]	Time  8.993 ( 5.079)	Data  8.419 ( 4.505)	Loss 7.6742e-02 (1.0335e-01) 
2023-05-27 09:58:56.551063: train Epoch: [21][ 43/193]	Time  0.614 ( 4.978)	Data  0.001 ( 4.402)	Loss 9.0627e-02 (1.0306e-01) 
2023-05-27 09:59:05.792183: train Epoch: [21][ 44/193]	Time  9.241 ( 5.073)	Data  8.678 ( 4.497)	Loss 7.3879e-02 (1.0242e-01) 
2023-05-27 09:59:06.405041: train Epoch: [21][ 45/193]	Time  0.613 ( 4.976)	Data  0.001 ( 4.400)	Loss 1.0633e-01 (1.0250e-01) 
2023-05-27 09:59:15.923747: train Epoch: [21][ 46/193]	Time  9.519 ( 5.072)	Data  8.918 ( 4.496)	Loss 1.0609e-01 (1.0258e-01) 
2023-05-27 09:59:16.508484: train Epoch: [21][ 47/193]	Time  0.585 ( 4.979)	Data  0.001 ( 4.402)	Loss 8.9781e-02 (1.0231e-01) 
2023-05-27 09:59:26.236179: train Epoch: [21][ 48/193]	Time  9.728 ( 5.076)	Data  9.158 ( 4.499)	Loss 1.3592e-01 (1.0300e-01) 
2023-05-27 09:59:26.800707: train Epoch: [21][ 49/193]	Time  0.565 ( 4.985)	Data  0.001 ( 4.409)	Loss 6.4054e-02 (1.0222e-01) 
2023-05-27 09:59:36.321182: train Epoch: [21][ 50/193]	Time  9.520 ( 5.074)	Data  8.957 ( 4.498)	Loss 1.9095e-01 (1.0396e-01) 
2023-05-27 09:59:36.885569: train Epoch: [21][ 51/193]	Time  0.564 ( 4.988)	Data  0.001 ( 4.412)	Loss 1.1141e-01 (1.0410e-01) 
2023-05-27 09:59:46.398806: train Epoch: [21][ 52/193]	Time  9.513 ( 5.073)	Data  8.939 ( 4.497)	Loss 9.6621e-02 (1.0396e-01) 
2023-05-27 09:59:46.969220: train Epoch: [21][ 53/193]	Time  0.570 ( 4.990)	Data  0.001 ( 4.414)	Loss 6.5634e-02 (1.0325e-01) 
2023-05-27 09:59:56.441461: train Epoch: [21][ 54/193]	Time  9.472 ( 5.071)	Data  8.881 ( 4.495)	Loss 1.1890e-01 (1.0353e-01) 
2023-05-27 09:59:57.016162: train Epoch: [21][ 55/193]	Time  0.575 ( 4.991)	Data  0.001 ( 4.415)	Loss 1.0999e-01 (1.0365e-01) 
2023-05-27 10:00:06.595535: train Epoch: [21][ 56/193]	Time  9.579 ( 5.071)	Data  8.973 ( 4.495)	Loss 1.6829e-01 (1.0478e-01) 
2023-05-27 10:00:07.158226: train Epoch: [21][ 57/193]	Time  0.563 ( 4.994)	Data  0.001 ( 4.417)	Loss 1.5284e-01 (1.0561e-01) 
2023-05-27 10:00:16.684144: train Epoch: [21][ 58/193]	Time  9.526 ( 5.070)	Data  8.953 ( 4.494)	Loss 8.2061e-02 (1.0521e-01) 
2023-05-27 10:00:17.251376: train Epoch: [21][ 59/193]	Time  0.567 ( 4.995)	Data  0.001 ( 4.419)	Loss 9.9612e-02 (1.0512e-01) 
2023-05-27 10:00:26.623780: train Epoch: [21][ 60/193]	Time  9.372 ( 5.067)	Data  8.800 ( 4.491)	Loss 1.7368e-01 (1.0624e-01) 
2023-05-27 10:00:27.186605: train Epoch: [21][ 61/193]	Time  0.563 ( 4.994)	Data  0.001 ( 4.419)	Loss 9.2741e-02 (1.0603e-01) 
2023-05-27 10:00:36.658636: train Epoch: [21][ 62/193]	Time  9.472 ( 5.066)	Data  8.897 ( 4.490)	Loss 4.2402e-02 (1.0502e-01) 
2023-05-27 10:00:37.227214: train Epoch: [21][ 63/193]	Time  0.569 ( 4.995)	Data  0.001 ( 4.420)	Loss 7.6943e-02 (1.0458e-01) 
2023-05-27 10:00:46.758368: train Epoch: [21][ 64/193]	Time  9.531 ( 5.065)	Data  8.943 ( 4.489)	Loss 8.1722e-02 (1.0423e-01) 
2023-05-27 10:00:47.329309: train Epoch: [21][ 65/193]	Time  0.571 ( 4.997)	Data  0.001 ( 4.421)	Loss 1.3238e-01 (1.0465e-01) 
2023-05-27 10:00:56.709356: train Epoch: [21][ 66/193]	Time  9.380 ( 5.062)	Data  8.814 ( 4.487)	Loss 2.4614e-01 (1.0676e-01) 
2023-05-27 10:00:57.291022: train Epoch: [21][ 67/193]	Time  0.582 ( 4.997)	Data  0.001 ( 4.421)	Loss 8.7014e-02 (1.0647e-01) 
2023-05-27 10:01:06.445942: train Epoch: [21][ 68/193]	Time  9.155 ( 5.057)	Data  8.587 ( 4.481)	Loss 6.7122e-02 (1.0590e-01) 
2023-05-27 10:01:07.023805: train Epoch: [21][ 69/193]	Time  0.578 ( 4.993)	Data  0.001 ( 4.417)	Loss 1.9152e-01 (1.0713e-01) 
2023-05-27 10:01:16.683996: train Epoch: [21][ 70/193]	Time  9.660 ( 5.059)	Data  9.092 ( 4.483)	Loss 2.2618e-01 (1.0880e-01) 
2023-05-27 10:01:17.253005: train Epoch: [21][ 71/193]	Time  0.569 ( 4.996)	Data  0.001 ( 4.421)	Loss 7.5720e-02 (1.0834e-01) 
2023-05-27 10:01:26.852394: train Epoch: [21][ 72/193]	Time  9.599 ( 5.059)	Data  9.015 ( 4.484)	Loss 8.5339e-02 (1.0803e-01) 
2023-05-27 10:01:27.421039: train Epoch: [21][ 73/193]	Time  0.569 ( 4.999)	Data  0.001 ( 4.423)	Loss 1.0361e-01 (1.0797e-01) 
2023-05-27 10:01:37.013881: train Epoch: [21][ 74/193]	Time  9.593 ( 5.060)	Data  9.007 ( 4.484)	Loss 9.7690e-02 (1.0783e-01) 
2023-05-27 10:01:37.628257: train Epoch: [21][ 75/193]	Time  0.614 ( 5.001)	Data  0.001 ( 4.425)	Loss 9.0315e-02 (1.0760e-01) 
2023-05-27 10:01:46.986531: train Epoch: [21][ 76/193]	Time  9.358 ( 5.058)	Data  8.784 ( 4.482)	Loss 1.3349e-01 (1.0794e-01) 
2023-05-27 10:01:47.549820: train Epoch: [21][ 77/193]	Time  0.563 ( 5.000)	Data  0.001 ( 4.425)	Loss 1.2279e-01 (1.0813e-01) 
2023-05-27 10:01:57.656849: train Epoch: [21][ 78/193]	Time 10.107 ( 5.065)	Data  9.541 ( 4.489)	Loss 8.3929e-02 (1.0782e-01) 
2023-05-27 10:01:58.229415: train Epoch: [21][ 79/193]	Time  0.573 ( 5.009)	Data  0.001 ( 4.433)	Loss 8.1602e-02 (1.0749e-01) 
2023-05-27 10:02:07.152544: train Epoch: [21][ 80/193]	Time  8.923 ( 5.057)	Data  8.356 ( 4.482)	Loss 1.0476e-01 (1.0746e-01) 
2023-05-27 10:02:07.736173: train Epoch: [21][ 81/193]	Time  0.584 ( 5.003)	Data  0.001 ( 4.427)	Loss 9.5251e-02 (1.0731e-01) 
2023-05-27 10:02:16.957044: train Epoch: [21][ 82/193]	Time  9.221 ( 5.053)	Data  8.645 ( 4.478)	Loss 6.4988e-02 (1.0680e-01) 
2023-05-27 10:02:17.530488: train Epoch: [21][ 83/193]	Time  0.573 ( 5.000)	Data  0.001 ( 4.425)	Loss 1.0094e-01 (1.0673e-01) 
2023-05-27 10:02:27.088792: train Epoch: [21][ 84/193]	Time  9.558 ( 5.054)	Data  8.995 ( 4.478)	Loss 7.2019e-02 (1.0632e-01) 
2023-05-27 10:02:27.655507: train Epoch: [21][ 85/193]	Time  0.567 ( 5.001)	Data  0.001 ( 4.426)	Loss 8.4682e-02 (1.0607e-01) 
2023-05-27 10:02:36.172352: train Epoch: [21][ 86/193]	Time  8.517 ( 5.042)	Data  7.938 ( 4.467)	Loss 7.1010e-02 (1.0567e-01) 
2023-05-27 10:02:36.746573: train Epoch: [21][ 87/193]	Time  0.574 ( 4.991)	Data  0.001 ( 4.416)	Loss 6.9944e-02 (1.0526e-01) 
2023-05-27 10:02:45.755518: train Epoch: [21][ 88/193]	Time  9.009 ( 5.036)	Data  8.429 ( 4.461)	Loss 9.9369e-02 (1.0520e-01) 
2023-05-27 10:02:46.320609: train Epoch: [21][ 89/193]	Time  0.565 ( 4.987)	Data  0.001 ( 4.411)	Loss 8.6269e-02 (1.0499e-01) 
2023-05-27 10:02:55.415025: train Epoch: [21][ 90/193]	Time  9.094 ( 5.032)	Data  8.529 ( 4.457)	Loss 9.6935e-02 (1.0490e-01) 
2023-05-27 10:02:55.981179: train Epoch: [21][ 91/193]	Time  0.566 ( 4.983)	Data  0.001 ( 4.408)	Loss 8.5827e-02 (1.0469e-01) 
2023-05-27 10:03:05.349385: train Epoch: [21][ 92/193]	Time  9.368 ( 5.030)	Data  8.792 ( 4.455)	Loss 8.5271e-02 (1.0448e-01) 
2023-05-27 10:03:05.936350: train Epoch: [21][ 93/193]	Time  0.587 ( 4.983)	Data  0.001 ( 4.408)	Loss 1.5834e-01 (1.0505e-01) 
2023-05-27 10:03:15.226162: train Epoch: [21][ 94/193]	Time  9.290 ( 5.028)	Data  8.725 ( 4.453)	Loss 7.0181e-02 (1.0469e-01) 
2023-05-27 10:03:15.794374: train Epoch: [21][ 95/193]	Time  0.568 ( 4.982)	Data  0.001 ( 4.407)	Loss 9.1163e-02 (1.0455e-01) 
2023-05-27 10:03:25.009513: train Epoch: [21][ 96/193]	Time  9.215 ( 5.026)	Data  8.642 ( 4.451)	Loss 1.2441e-01 (1.0475e-01) 
2023-05-27 10:03:25.580980: train Epoch: [21][ 97/193]	Time  0.571 ( 4.980)	Data  0.001 ( 4.405)	Loss 1.2527e-01 (1.0496e-01) 
2023-05-27 10:03:34.879857: train Epoch: [21][ 98/193]	Time  9.299 ( 5.024)	Data  8.735 ( 4.449)	Loss 8.5969e-02 (1.0477e-01) 
2023-05-27 10:03:35.445272: train Epoch: [21][ 99/193]	Time  0.565 ( 4.979)	Data  0.001 ( 4.405)	Loss 1.1936e-01 (1.0491e-01) 
2023-05-27 10:03:44.589005: train Epoch: [21][100/193]	Time  9.144 ( 5.020)	Data  8.569 ( 4.446)	Loss 8.8818e-02 (1.0476e-01) 
2023-05-27 10:03:45.153638: train Epoch: [21][101/193]	Time  0.565 ( 4.977)	Data  0.001 ( 4.402)	Loss 1.0933e-01 (1.0480e-01) 
2023-05-27 10:03:54.474241: train Epoch: [21][102/193]	Time  9.321 ( 5.019)	Data  8.757 ( 4.444)	Loss 6.8315e-02 (1.0445e-01) 
2023-05-27 10:03:55.039930: train Epoch: [21][103/193]	Time  0.566 ( 4.976)	Data  0.001 ( 4.402)	Loss 5.5886e-02 (1.0398e-01) 
2023-05-27 10:04:04.338662: train Epoch: [21][104/193]	Time  9.299 ( 5.017)	Data  8.734 ( 4.443)	Loss 8.4737e-02 (1.0380e-01) 
2023-05-27 10:04:04.903134: train Epoch: [21][105/193]	Time  0.564 ( 4.975)	Data  0.001 ( 4.401)	Loss 6.3777e-02 (1.0342e-01) 
2023-05-27 10:04:14.320785: train Epoch: [21][106/193]	Time  9.418 ( 5.017)	Data  8.854 ( 4.443)	Loss 1.2096e-01 (1.0358e-01) 
2023-05-27 10:04:14.886227: train Epoch: [21][107/193]	Time  0.565 ( 4.976)	Data  0.001 ( 4.402)	Loss 8.6776e-02 (1.0343e-01) 
2023-05-27 10:04:24.202016: train Epoch: [21][108/193]	Time  9.316 ( 5.015)	Data  8.751 ( 4.441)	Loss 1.3089e-01 (1.0368e-01) 
2023-05-27 10:04:24.766704: train Epoch: [21][109/193]	Time  0.565 ( 4.975)	Data  0.001 ( 4.401)	Loss 7.6468e-02 (1.0343e-01) 
2023-05-27 10:04:33.713934: train Epoch: [21][110/193]	Time  8.947 ( 5.011)	Data  8.375 ( 4.437)	Loss 7.9555e-02 (1.0322e-01) 
2023-05-27 10:04:34.279384: train Epoch: [21][111/193]	Time  0.565 ( 4.971)	Data  0.001 ( 4.397)	Loss 5.0134e-02 (1.0274e-01) 
2023-05-27 10:04:43.598842: train Epoch: [21][112/193]	Time  9.319 ( 5.009)	Data  8.745 ( 4.436)	Loss 1.7040e-01 (1.0334e-01) 
2023-05-27 10:04:44.162807: train Epoch: [21][113/193]	Time  0.564 ( 4.970)	Data  0.001 ( 4.397)	Loss 9.3963e-02 (1.0326e-01) 
2023-05-27 10:04:53.512696: train Epoch: [21][114/193]	Time  9.350 ( 5.009)	Data  8.784 ( 4.435)	Loss 6.3993e-02 (1.0292e-01) 
2023-05-27 10:04:54.075042: train Epoch: [21][115/193]	Time  0.562 ( 4.970)	Data  0.001 ( 4.397)	Loss 1.3977e-01 (1.0323e-01) 
2023-05-27 10:05:03.664268: train Epoch: [21][116/193]	Time  9.589 ( 5.010)	Data  9.025 ( 4.436)	Loss 8.6625e-02 (1.0309e-01) 
2023-05-27 10:05:04.228489: train Epoch: [21][117/193]	Time  0.564 ( 4.972)	Data  0.001 ( 4.399)	Loss 1.2107e-01 (1.0324e-01) 
2023-05-27 10:05:13.576659: train Epoch: [21][118/193]	Time  9.348 ( 5.009)	Data  8.782 ( 4.436)	Loss 7.0272e-02 (1.0297e-01) 
2023-05-27 10:05:14.139990: train Epoch: [21][119/193]	Time  0.563 ( 4.972)	Data  0.001 ( 4.399)	Loss 8.2633e-02 (1.0280e-01) 
2023-05-27 10:05:23.598977: train Epoch: [21][120/193]	Time  9.459 ( 5.009)	Data  8.875 ( 4.436)	Loss 1.5970e-01 (1.0327e-01) 
2023-05-27 10:05:24.163453: train Epoch: [21][121/193]	Time  0.564 ( 4.972)	Data  0.001 ( 4.399)	Loss 7.4642e-02 (1.0303e-01) 
2023-05-27 10:05:33.393124: train Epoch: [21][122/193]	Time  9.230 ( 5.007)	Data  8.659 ( 4.434)	Loss 9.2814e-02 (1.0295e-01) 
2023-05-27 10:05:33.957754: train Epoch: [21][123/193]	Time  0.565 ( 4.971)	Data  0.001 ( 4.398)	Loss 1.0003e-01 (1.0293e-01) 
2023-05-27 10:05:43.527105: train Epoch: [21][124/193]	Time  9.569 ( 5.008)	Data  9.006 ( 4.435)	Loss 9.4409e-02 (1.0286e-01) 
2023-05-27 10:05:44.091389: train Epoch: [21][125/193]	Time  0.564 ( 4.973)	Data  0.001 ( 4.400)	Loss 3.5331e-01 (1.0485e-01) 
2023-05-27 10:05:53.347151: train Epoch: [21][126/193]	Time  9.256 ( 5.006)	Data  8.689 ( 4.434)	Loss 7.4137e-02 (1.0461e-01) 
2023-05-27 10:05:53.912339: train Epoch: [21][127/193]	Time  0.565 ( 4.972)	Data  0.001 ( 4.399)	Loss 4.7252e-02 (1.0416e-01) 
2023-05-27 10:06:03.434033: train Epoch: [21][128/193]	Time  9.522 ( 5.007)	Data  8.945 ( 4.434)	Loss 1.5061e-01 (1.0452e-01) 
2023-05-27 10:06:03.997515: train Epoch: [21][129/193]	Time  0.563 ( 4.973)	Data  0.001 ( 4.400)	Loss 8.3149e-02 (1.0435e-01) 
2023-05-27 10:06:12.931566: train Epoch: [21][130/193]	Time  8.934 ( 5.003)	Data  8.366 ( 4.430)	Loss 9.6924e-02 (1.0430e-01) 
2023-05-27 10:06:13.503816: train Epoch: [21][131/193]	Time  0.572 ( 4.970)	Data  0.001 ( 4.397)	Loss 7.0359e-02 (1.0404e-01) 
2023-05-27 10:06:22.926618: train Epoch: [21][132/193]	Time  9.423 ( 5.003)	Data  8.822 ( 4.430)	Loss 2.4632e-01 (1.0511e-01) 
2023-05-27 10:06:23.509155: train Epoch: [21][133/193]	Time  0.583 ( 4.970)	Data  0.001 ( 4.397)	Loss 1.1831e-01 (1.0521e-01) 
2023-05-27 10:06:32.789893: train Epoch: [21][134/193]	Time  9.281 ( 5.002)	Data  8.698 ( 4.429)	Loss 1.1914e-01 (1.0531e-01) 
2023-05-27 10:06:33.360439: train Epoch: [21][135/193]	Time  0.571 ( 4.969)	Data  0.001 ( 4.396)	Loss 1.3879e-01 (1.0556e-01) 
2023-05-27 10:06:42.822357: train Epoch: [21][136/193]	Time  9.462 ( 5.002)	Data  8.891 ( 4.429)	Loss 9.9151e-02 (1.0551e-01) 
2023-05-27 10:06:43.390713: train Epoch: [21][137/193]	Time  0.568 ( 4.970)	Data  0.001 ( 4.397)	Loss 1.0772e-01 (1.0553e-01) 
2023-05-27 10:06:52.947917: train Epoch: [21][138/193]	Time  9.557 ( 5.003)	Data  8.964 ( 4.430)	Loss 7.8479e-02 (1.0533e-01) 
2023-05-27 10:06:53.528799: train Epoch: [21][139/193]	Time  0.581 ( 4.971)	Data  0.001 ( 4.398)	Loss 7.5529e-02 (1.0512e-01) 
2023-05-27 10:07:02.899757: train Epoch: [21][140/193]	Time  9.371 ( 5.003)	Data  8.799 ( 4.429)	Loss 9.0005e-02 (1.0501e-01) 
2023-05-27 10:07:03.466780: train Epoch: [21][141/193]	Time  0.567 ( 4.971)	Data  0.001 ( 4.398)	Loss 1.3723e-01 (1.0524e-01) 
2023-05-27 10:07:12.947593: train Epoch: [21][142/193]	Time  9.481 ( 5.003)	Data  8.913 ( 4.430)	Loss 1.8805e-01 (1.0582e-01) 
2023-05-27 10:07:13.515938: train Epoch: [21][143/193]	Time  0.568 ( 4.972)	Data  0.001 ( 4.399)	Loss 1.0439e-01 (1.0581e-01) 
2023-05-27 10:07:22.999565: train Epoch: [21][144/193]	Time  9.484 ( 5.003)	Data  8.919 ( 4.430)	Loss 1.3879e-01 (1.0603e-01) 
2023-05-27 10:07:23.571885: train Epoch: [21][145/193]	Time  0.572 ( 4.973)	Data  0.001 ( 4.400)	Loss 6.1540e-02 (1.0573e-01) 
2023-05-27 10:07:32.866180: train Epoch: [21][146/193]	Time  9.294 ( 5.002)	Data  8.732 ( 4.429)	Loss 1.1005e-01 (1.0576e-01) 
2023-05-27 10:07:33.429294: train Epoch: [21][147/193]	Time  0.563 ( 4.972)	Data  0.001 ( 4.399)	Loss 2.2719e-01 (1.0658e-01) 
2023-05-27 10:07:42.836349: train Epoch: [21][148/193]	Time  9.407 ( 5.002)	Data  8.838 ( 4.429)	Loss 2.0275e-01 (1.0723e-01) 
2023-05-27 10:07:43.398714: train Epoch: [21][149/193]	Time  0.562 ( 4.972)	Data  0.001 ( 4.400)	Loss 6.4776e-02 (1.0694e-01) 
2023-05-27 10:07:52.548417: train Epoch: [21][150/193]	Time  9.150 ( 5.000)	Data  8.584 ( 4.427)	Loss 1.4749e-01 (1.0721e-01) 
2023-05-27 10:07:53.126278: train Epoch: [21][151/193]	Time  0.578 ( 4.971)	Data  0.001 ( 4.398)	Loss 1.5334e-01 (1.0751e-01) 
2023-05-27 10:08:02.225511: train Epoch: [21][152/193]	Time  9.099 ( 4.998)	Data  8.521 ( 4.425)	Loss 1.1490e-01 (1.0756e-01) 
2023-05-27 10:08:02.788296: train Epoch: [21][153/193]	Time  0.563 ( 4.969)	Data  0.001 ( 4.397)	Loss 1.0165e-01 (1.0752e-01) 
2023-05-27 10:08:12.213427: train Epoch: [21][154/193]	Time  9.425 ( 4.998)	Data  8.837 ( 4.425)	Loss 7.2257e-02 (1.0730e-01) 
2023-05-27 10:08:12.781716: train Epoch: [21][155/193]	Time  0.568 ( 4.970)	Data  0.001 ( 4.397)	Loss 1.1438e-01 (1.0734e-01) 
2023-05-27 10:08:22.125861: train Epoch: [21][156/193]	Time  9.344 ( 4.997)	Data  8.765 ( 4.425)	Loss 1.4045e-01 (1.0755e-01) 
2023-05-27 10:08:22.716254: train Epoch: [21][157/193]	Time  0.590 ( 4.970)	Data  0.001 ( 4.397)	Loss 6.1903e-02 (1.0726e-01) 
2023-05-27 10:08:32.452559: train Epoch: [21][158/193]	Time  9.736 ( 5.000)	Data  9.164 ( 4.427)	Loss 1.0797e-01 (1.0727e-01) 
2023-05-27 10:08:33.015592: train Epoch: [21][159/193]	Time  0.563 ( 4.972)	Data  0.001 ( 4.399)	Loss 8.8428e-02 (1.0715e-01) 
2023-05-27 10:08:42.172273: train Epoch: [21][160/193]	Time  9.157 ( 4.998)	Data  8.594 ( 4.425)	Loss 8.9610e-02 (1.0704e-01) 
2023-05-27 10:08:42.750824: train Epoch: [21][161/193]	Time  0.579 ( 4.971)	Data  0.001 ( 4.398)	Loss 5.5049e-02 (1.0672e-01) 
2023-05-27 10:08:52.330931: train Epoch: [21][162/193]	Time  9.580 ( 4.999)	Data  9.010 ( 4.426)	Loss 8.8111e-02 (1.0661e-01) 
2023-05-27 10:08:52.904875: train Epoch: [21][163/193]	Time  0.574 ( 4.972)	Data  0.001 ( 4.399)	Loss 1.8697e-01 (1.0710e-01) 
2023-05-27 10:09:02.251506: train Epoch: [21][164/193]	Time  9.347 ( 4.998)	Data  8.776 ( 4.426)	Loss 1.1147e-01 (1.0712e-01) 
2023-05-27 10:09:02.831014: train Epoch: [21][165/193]	Time  0.580 ( 4.972)	Data  0.001 ( 4.399)	Loss 9.8694e-02 (1.0707e-01) 
2023-05-27 10:09:12.104238: train Epoch: [21][166/193]	Time  9.273 ( 4.997)	Data  8.704 ( 4.425)	Loss 9.5587e-02 (1.0700e-01) 
2023-05-27 10:09:12.668035: train Epoch: [21][167/193]	Time  0.564 ( 4.971)	Data  0.001 ( 4.398)	Loss 2.3482e-01 (1.0776e-01) 
2023-05-27 10:09:22.026168: train Epoch: [21][168/193]	Time  9.358 ( 4.997)	Data  8.752 ( 4.424)	Loss 1.9962e-01 (1.0831e-01) 
2023-05-27 10:09:22.598776: train Epoch: [21][169/193]	Time  0.573 ( 4.971)	Data  0.001 ( 4.398)	Loss 1.1324e-01 (1.0834e-01) 
2023-05-27 10:09:31.747179: train Epoch: [21][170/193]	Time  9.148 ( 4.995)	Data  8.578 ( 4.423)	Loss 1.6895e-01 (1.0869e-01) 
2023-05-27 10:09:32.323926: train Epoch: [21][171/193]	Time  0.577 ( 4.970)	Data  0.001 ( 4.397)	Loss 9.7812e-02 (1.0863e-01) 
2023-05-27 10:09:42.016093: train Epoch: [21][172/193]	Time  9.692 ( 4.997)	Data  9.125 ( 4.424)	Loss 2.7873e-01 (1.0961e-01) 
2023-05-27 10:09:42.595073: train Epoch: [21][173/193]	Time  0.579 ( 4.972)	Data  0.001 ( 4.399)	Loss 8.9146e-02 (1.0949e-01) 
2023-05-27 10:09:52.403354: train Epoch: [21][174/193]	Time  9.808 ( 4.999)	Data  9.217 ( 4.426)	Loss 1.4297e-01 (1.0969e-01) 
2023-05-27 10:09:52.975758: train Epoch: [21][175/193]	Time  0.572 ( 4.974)	Data  0.001 ( 4.401)	Loss 1.5416e-01 (1.0994e-01) 
2023-05-27 10:10:01.882786: train Epoch: [21][176/193]	Time  8.907 ( 4.996)	Data  8.330 ( 4.423)	Loss 6.1620e-02 (1.0966e-01) 
2023-05-27 10:10:02.458917: train Epoch: [21][177/193]	Time  0.576 ( 4.972)	Data  0.001 ( 4.399)	Loss 5.9639e-02 (1.0938e-01) 
2023-05-27 10:10:12.011622: train Epoch: [21][178/193]	Time  9.553 ( 4.997)	Data  8.983 ( 4.424)	Loss 8.2044e-02 (1.0923e-01) 
2023-05-27 10:10:12.592435: train Epoch: [21][179/193]	Time  0.581 ( 4.973)	Data  0.001 ( 4.400)	Loss 1.7108e-01 (1.0957e-01) 
2023-05-27 10:10:21.883327: train Epoch: [21][180/193]	Time  9.291 ( 4.996)	Data  8.720 ( 4.423)	Loss 9.0297e-02 (1.0947e-01) 
2023-05-27 10:10:22.460088: train Epoch: [21][181/193]	Time  0.577 ( 4.972)	Data  0.001 ( 4.399)	Loss 8.5501e-02 (1.0934e-01) 
2023-05-27 10:10:32.147919: train Epoch: [21][182/193]	Time  9.688 ( 4.998)	Data  9.120 ( 4.425)	Loss 1.2145e-01 (1.0940e-01) 
2023-05-27 10:10:32.721475: train Epoch: [21][183/193]	Time  0.574 ( 4.974)	Data  0.001 ( 4.401)	Loss 7.4774e-02 (1.0921e-01) 
2023-05-27 10:10:42.500853: train Epoch: [21][184/193]	Time  9.779 ( 5.000)	Data  9.165 ( 4.427)	Loss 1.0605e-01 (1.0920e-01) 
2023-05-27 10:10:43.084180: train Epoch: [21][185/193]	Time  0.583 ( 4.976)	Data  0.001 ( 4.403)	Loss 9.5891e-02 (1.0913e-01) 
2023-05-27 10:10:52.244111: train Epoch: [21][186/193]	Time  9.160 ( 4.998)	Data  8.562 ( 4.425)	Loss 2.2266e-01 (1.0973e-01) 
2023-05-27 10:10:52.818413: train Epoch: [21][187/193]	Time  0.574 ( 4.975)	Data  0.001 ( 4.402)	Loss 2.1399e-01 (1.1029e-01) 
2023-05-27 10:11:02.186872: train Epoch: [21][188/193]	Time  9.368 ( 4.998)	Data  8.794 ( 4.425)	Loss 1.1742e-01 (1.1033e-01) 
2023-05-27 10:11:02.757907: train Epoch: [21][189/193]	Time  0.571 ( 4.975)	Data  0.001 ( 4.401)	Loss 7.2402e-02 (1.1013e-01) 
2023-05-27 10:11:11.675337: train Epoch: [21][190/193]	Time  8.917 ( 4.996)	Data  8.332 ( 4.422)	Loss 1.3472e-01 (1.1025e-01) 
2023-05-27 10:11:12.254910: train Epoch: [21][191/193]	Time  0.580 ( 4.973)	Data  0.001 ( 4.399)	Loss 8.6588e-02 (1.1013e-01) 
2023-05-27 10:11:20.644168: train Epoch: [21][192/193]	Time  8.389 ( 4.990)	Data  7.816 ( 4.417)	Loss 9.0948e-02 (1.1003e-01) 
2023-05-27 10:11:20.807916: Train Epoch done in 963.2803003379959 s 
2023-05-27 10:11:27.037958: val Epoch: [21][ 0/72]	Time  5.508 ( 5.508)	Data  5.354 ( 5.354)	Loss 1.1911e-01 (1.1911e-01) 
2023-05-27 10:11:27.325109: val Epoch: [21][ 1/72]	Time  0.287 ( 2.898)	Data  0.178 ( 2.766)	Loss 4.2662e-01 (2.7286e-01) 
2023-05-27 10:11:31.911324: val Epoch: [21][ 2/72]	Time  4.586 ( 3.461)	Data  4.474 ( 3.335)	Loss 6.7426e-02 (2.0438e-01) 
2023-05-27 10:11:32.191705: val Epoch: [21][ 3/72]	Time  0.280 ( 2.666)	Data  0.167 ( 2.543)	Loss 9.8548e-02 (1.7792e-01) 
2023-05-27 10:11:36.816606: val Epoch: [21][ 4/72]	Time  4.625 ( 3.057)	Data  4.511 ( 2.937)	Loss 1.1012e-01 (1.6436e-01) 
2023-05-27 10:11:37.443849: val Epoch: [21][ 5/72]	Time  0.627 ( 2.652)	Data  0.519 ( 2.534)	Loss 1.0587e-01 (1.5461e-01) 
2023-05-27 10:11:41.846415: val Epoch: [21][ 6/72]	Time  4.403 ( 2.902)	Data  4.297 ( 2.786)	Loss 9.5928e-02 (1.4623e-01) 
2023-05-27 10:11:42.577301: val Epoch: [21][ 7/72]	Time  0.731 ( 2.631)	Data  0.612 ( 2.514)	Loss 6.1472e-02 (1.3564e-01) 
2023-05-27 10:11:47.051157: val Epoch: [21][ 8/72]	Time  4.474 ( 2.836)	Data  4.368 ( 2.720)	Loss 3.0647e-01 (1.5462e-01) 
2023-05-27 10:11:47.526756: val Epoch: [21][ 9/72]	Time  0.476 ( 2.600)	Data  0.354 ( 2.483)	Loss 6.0180e-02 (1.4517e-01) 
2023-05-27 10:11:52.167193: val Epoch: [21][10/72]	Time  4.640 ( 2.785)	Data  4.534 ( 2.670)	Loss 3.5948e-01 (1.6466e-01) 
2023-05-27 10:11:52.564568: val Epoch: [21][11/72]	Time  0.397 ( 2.586)	Data  0.290 ( 2.472)	Loss 7.6665e-02 (1.5732e-01) 
2023-05-27 10:11:57.225404: val Epoch: [21][12/72]	Time  4.661 ( 2.746)	Data  4.555 ( 2.632)	Loss 8.2569e-02 (1.5157e-01) 
2023-05-27 10:11:57.532085: val Epoch: [21][13/72]	Time  0.307 ( 2.572)	Data  0.200 ( 2.458)	Loss 6.7800e-02 (1.4559e-01) 
2023-05-27 10:12:02.192651: val Epoch: [21][14/72]	Time  4.661 ( 2.711)	Data  4.554 ( 2.598)	Loss 5.0282e-02 (1.3924e-01) 
2023-05-27 10:12:02.402432: val Epoch: [21][15/72]	Time  0.210 ( 2.555)	Data  0.104 ( 2.442)	Loss 7.4404e-02 (1.3518e-01) 
2023-05-27 10:12:07.169083: val Epoch: [21][16/72]	Time  4.767 ( 2.685)	Data  4.662 ( 2.573)	Loss 5.9153e-02 (1.3071e-01) 
2023-05-27 10:12:07.473000: val Epoch: [21][17/72]	Time  0.304 ( 2.552)	Data  0.199 ( 2.441)	Loss 1.1208e-01 (1.2968e-01) 
2023-05-27 10:12:11.951452: val Epoch: [21][18/72]	Time  4.478 ( 2.654)	Data  4.373 ( 2.542)	Loss 6.1011e-02 (1.2606e-01) 
2023-05-27 10:12:12.867069: val Epoch: [21][19/72]	Time  0.916 ( 2.567)	Data  0.799 ( 2.455)	Loss 6.1666e-02 (1.2284e-01) 
2023-05-27 10:12:16.979450: val Epoch: [21][20/72]	Time  4.112 ( 2.640)	Data  3.999 ( 2.529)	Loss 1.1954e-01 (1.2268e-01) 
2023-05-27 10:12:18.132228: val Epoch: [21][21/72]	Time  1.153 ( 2.573)	Data  1.040 ( 2.461)	Loss 8.2143e-02 (1.2084e-01) 
2023-05-27 10:12:22.105831: val Epoch: [21][22/72]	Time  3.974 ( 2.634)	Data  3.863 ( 2.522)	Loss 4.0659e-01 (1.3327e-01) 
2023-05-27 10:12:23.061964: val Epoch: [21][23/72]	Time  0.956 ( 2.564)	Data  0.840 ( 2.452)	Loss 8.4310e-02 (1.3123e-01) 
2023-05-27 10:12:27.346081: val Epoch: [21][24/72]	Time  4.284 ( 2.633)	Data  4.175 ( 2.521)	Loss 3.0098e-01 (1.3802e-01) 
2023-05-27 10:12:27.947987: val Epoch: [21][25/72]	Time  0.602 ( 2.555)	Data  0.493 ( 2.443)	Loss 2.4628e-01 (1.4218e-01) 
2023-05-27 10:12:32.770292: val Epoch: [21][26/72]	Time  4.822 ( 2.639)	Data  4.679 ( 2.526)	Loss 9.7017e-02 (1.4051e-01) 
2023-05-27 10:12:32.883907: val Epoch: [21][27/72]	Time  0.114 ( 2.548)	Data  0.001 ( 2.436)	Loss 5.7225e-02 (1.3753e-01) 
2023-05-27 10:12:37.728305: val Epoch: [21][28/72]	Time  4.844 ( 2.628)	Data  4.734 ( 2.515)	Loss 7.2191e-02 (1.3528e-01) 
2023-05-27 10:12:38.177037: val Epoch: [21][29/72]	Time  0.449 ( 2.555)	Data  0.341 ( 2.442)	Loss 7.6617e-02 (1.3332e-01) 
2023-05-27 10:12:42.800833: val Epoch: [21][30/72]	Time  4.624 ( 2.622)	Data  4.516 ( 2.509)	Loss 4.4279e-02 (1.3045e-01) 
2023-05-27 10:12:43.114685: val Epoch: [21][31/72]	Time  0.314 ( 2.550)	Data  0.208 ( 2.437)	Loss 2.6960e-01 (1.3480e-01) 
2023-05-27 10:12:47.783089: val Epoch: [21][32/72]	Time  4.668 ( 2.614)	Data  4.553 ( 2.501)	Loss 5.5736e-02 (1.3240e-01) 
2023-05-27 10:12:48.307117: val Epoch: [21][33/72]	Time  0.524 ( 2.552)	Data  0.419 ( 2.440)	Loss 3.5808e-01 (1.3904e-01) 
2023-05-27 10:12:52.780728: val Epoch: [21][34/72]	Time  4.474 ( 2.607)	Data  4.362 ( 2.495)	Loss 8.9881e-02 (1.3764e-01) 
2023-05-27 10:12:53.558972: val Epoch: [21][35/72]	Time  0.778 ( 2.556)	Data  0.674 ( 2.444)	Loss 1.7623e-01 (1.3871e-01) 
2023-05-27 10:12:57.905820: val Epoch: [21][36/72]	Time  4.347 ( 2.605)	Data  4.242 ( 2.493)	Loss 8.3977e-02 (1.3723e-01) 
2023-05-27 10:12:58.539843: val Epoch: [21][37/72]	Time  0.634 ( 2.553)	Data  0.529 ( 2.441)	Loss 1.7572e-01 (1.3824e-01) 
2023-05-27 10:13:02.967703: val Epoch: [21][38/72]	Time  4.428 ( 2.601)	Data  4.316 ( 2.489)	Loss 1.6488e-01 (1.3893e-01) 
2023-05-27 10:13:03.773228: val Epoch: [21][39/72]	Time  0.806 ( 2.556)	Data  0.699 ( 2.445)	Loss 3.7772e-01 (1.4490e-01) 
2023-05-27 10:13:07.778838: val Epoch: [21][40/72]	Time  4.006 ( 2.591)	Data  3.886 ( 2.480)	Loss 9.2645e-02 (1.4362e-01) 
2023-05-27 10:13:09.148735: val Epoch: [21][41/72]	Time  1.370 ( 2.562)	Data  1.265 ( 2.451)	Loss 1.5692e-01 (1.4394e-01) 
2023-05-27 10:13:12.856580: val Epoch: [21][42/72]	Time  3.708 ( 2.589)	Data  3.602 ( 2.478)	Loss 1.4137e-01 (1.4388e-01) 
2023-05-27 10:13:14.098898: val Epoch: [21][43/72]	Time  1.242 ( 2.558)	Data  1.137 ( 2.447)	Loss 2.2653e-01 (1.4576e-01) 
2023-05-27 10:13:17.736514: val Epoch: [21][44/72]	Time  3.638 ( 2.582)	Data  3.503 ( 2.471)	Loss 6.9456e-02 (1.4406e-01) 
2023-05-27 10:13:19.251585: val Epoch: [21][45/72]	Time  1.515 ( 2.559)	Data  1.410 ( 2.448)	Loss 2.9822e-01 (1.4741e-01) 
2023-05-27 10:13:22.693266: val Epoch: [21][46/72]	Time  3.442 ( 2.578)	Data  3.335 ( 2.466)	Loss 5.8099e-02 (1.4551e-01) 
2023-05-27 10:13:24.462764: val Epoch: [21][47/72]	Time  1.769 ( 2.561)	Data  1.630 ( 2.449)	Loss 1.6018e-01 (1.4582e-01) 
2023-05-27 10:13:27.358147: val Epoch: [21][48/72]	Time  2.895 ( 2.568)	Data  2.778 ( 2.456)	Loss 5.3009e-02 (1.4392e-01) 
2023-05-27 10:13:29.323376: val Epoch: [21][49/72]	Time  1.965 ( 2.556)	Data  1.860 ( 2.444)	Loss 1.8035e-01 (1.4465e-01) 
2023-05-27 10:13:32.355034: val Epoch: [21][50/72]	Time  3.032 ( 2.565)	Data  2.926 ( 2.453)	Loss 1.0355e-01 (1.4385e-01) 
2023-05-27 10:13:34.614552: val Epoch: [21][51/72]	Time  2.260 ( 2.559)	Data  2.086 ( 2.446)	Loss 1.2500e-01 (1.4348e-01) 
2023-05-27 10:13:37.419012: val Epoch: [21][52/72]	Time  2.804 ( 2.564)	Data  2.697 ( 2.451)	Loss 1.8927e-01 (1.4435e-01) 
2023-05-27 10:13:39.817488: val Epoch: [21][53/72]	Time  2.398 ( 2.561)	Data  2.283 ( 2.448)	Loss 5.4734e-02 (1.4269e-01) 
2023-05-27 10:13:42.562011: val Epoch: [21][54/72]	Time  2.745 ( 2.564)	Data  2.639 ( 2.451)	Loss 9.7731e-02 (1.4187e-01) 
2023-05-27 10:13:44.654636: val Epoch: [21][55/72]	Time  2.093 ( 2.556)	Data  1.984 ( 2.443)	Loss 7.0225e-02 (1.4059e-01) 
2023-05-27 10:13:47.826811: val Epoch: [21][56/72]	Time  3.172 ( 2.567)	Data  3.062 ( 2.454)	Loss 9.6960e-02 (1.3983e-01) 
2023-05-27 10:13:49.681764: val Epoch: [21][57/72]	Time  1.855 ( 2.554)	Data  1.735 ( 2.441)	Loss 9.4456e-02 (1.3904e-01) 
2023-05-27 10:13:52.855793: val Epoch: [21][58/72]	Time  3.174 ( 2.565)	Data  3.069 ( 2.452)	Loss 1.4070e-01 (1.3907e-01) 
2023-05-27 10:13:54.755725: val Epoch: [21][59/72]	Time  1.900 ( 2.554)	Data  1.791 ( 2.441)	Loss 6.7227e-02 (1.3787e-01) 
2023-05-27 10:13:57.825535: val Epoch: [21][60/72]	Time  3.070 ( 2.562)	Data  2.964 ( 2.450)	Loss 1.6036e-01 (1.3824e-01) 
2023-05-27 10:13:59.991779: val Epoch: [21][61/72]	Time  2.166 ( 2.556)	Data  2.061 ( 2.443)	Loss 2.2977e-01 (1.3972e-01) 
2023-05-27 10:14:02.942106: val Epoch: [21][62/72]	Time  2.950 ( 2.562)	Data  2.842 ( 2.450)	Loss 1.1669e-01 (1.3935e-01) 
2023-05-27 10:14:04.841610: val Epoch: [21][63/72]	Time  1.900 ( 2.552)	Data  1.791 ( 2.439)	Loss 1.4668e-01 (1.3947e-01) 
2023-05-27 10:14:08.104337: val Epoch: [21][64/72]	Time  3.263 ( 2.563)	Data  3.156 ( 2.450)	Loss 3.2320e-01 (1.4229e-01) 
2023-05-27 10:14:09.713781: val Epoch: [21][65/72]	Time  1.609 ( 2.548)	Data  1.503 ( 2.436)	Loss 5.4061e-02 (1.4096e-01) 
2023-05-27 10:14:13.257223: val Epoch: [21][66/72]	Time  3.543 ( 2.563)	Data  3.435 ( 2.451)	Loss 4.5322e-01 (1.4562e-01) 
2023-05-27 10:14:14.752350: val Epoch: [21][67/72]	Time  1.495 ( 2.547)	Data  1.387 ( 2.435)	Loss 1.3741e-01 (1.4550e-01) 
2023-05-27 10:14:18.166485: val Epoch: [21][68/72]	Time  3.414 ( 2.560)	Data  3.306 ( 2.448)	Loss 4.3070e-02 (1.4401e-01) 
2023-05-27 10:14:19.849920: val Epoch: [21][69/72]	Time  1.683 ( 2.547)	Data  1.553 ( 2.435)	Loss 4.0903e-01 (1.4780e-01) 
2023-05-27 10:14:23.007192: val Epoch: [21][70/72]	Time  3.157 ( 2.556)	Data  3.051 ( 2.444)	Loss 1.0148e-01 (1.4715e-01) 
2023-05-27 10:14:24.537171: val Epoch: [21][71/72]	Time  1.530 ( 2.542)	Data  1.421 ( 2.430)	Loss 8.5014e-02 (1.4628e-01) 
2023-05-27 10:14:24.854916: Epoch 21 :Val : ['ET : 0.717277467250824', 'TC : 0.7559323906898499', 'WT : 0.8428308963775635'] 
2023-05-27 10:14:24.858919: Epoch 21 :Val : ['ET : 0.717277467250824', 'TC : 0.7559323906898499', 'WT : 0.8428308963775635'] 
2023-05-27 10:14:24.861022: Val epoch done in 184.05310889100656 s 
2023-05-27 10:14:24.870003: Batches per epoch:  193 
2023-05-27 10:14:36.202689: train Epoch: [22][  0/193]	Time 11.332 (11.332)	Data 10.627 (10.627)	Loss 8.1149e-02 (8.1149e-02) 
2023-05-27 10:14:36.773102: train Epoch: [22][  1/193]	Time  0.570 ( 5.951)	Data  0.001 ( 5.314)	Loss 1.6591e-01 (1.2353e-01) 
2023-05-27 10:14:46.281205: train Epoch: [22][  2/193]	Time  9.508 ( 7.137)	Data  8.915 ( 6.514)	Loss 2.2662e-01 (1.5789e-01) 
2023-05-27 10:14:46.845842: train Epoch: [22][  3/193]	Time  0.565 ( 5.494)	Data  0.001 ( 4.886)	Loss 9.1207e-02 (1.4122e-01) 
2023-05-27 10:14:55.903034: train Epoch: [22][  4/193]	Time  9.057 ( 6.207)	Data  8.488 ( 5.606)	Loss 2.5683e-01 (1.6434e-01) 
2023-05-27 10:14:56.467600: train Epoch: [22][  5/193]	Time  0.565 ( 5.266)	Data  0.001 ( 4.672)	Loss 7.3763e-02 (1.4925e-01) 
2023-05-27 10:15:06.325836: train Epoch: [22][  6/193]	Time  9.858 ( 5.922)	Data  9.294 ( 5.332)	Loss 2.0479e-01 (1.5718e-01) 
2023-05-27 10:15:06.889801: train Epoch: [22][  7/193]	Time  0.564 ( 5.252)	Data  0.001 ( 4.666)	Loss 9.2073e-02 (1.4904e-01) 
2023-05-27 10:15:16.309639: train Epoch: [22][  8/193]	Time  9.420 ( 5.715)	Data  8.856 ( 5.131)	Loss 1.4792e-01 (1.4892e-01) 
2023-05-27 10:15:16.874493: train Epoch: [22][  9/193]	Time  0.565 ( 5.200)	Data  0.001 ( 4.618)	Loss 9.5711e-02 (1.4360e-01) 
2023-05-27 10:15:25.759824: train Epoch: [22][ 10/193]	Time  8.885 ( 5.535)	Data  8.316 ( 4.955)	Loss 9.3252e-02 (1.3902e-01) 
2023-05-27 10:15:26.324811: train Epoch: [22][ 11/193]	Time  0.565 ( 5.121)	Data  0.001 ( 4.542)	Loss 1.3342e-01 (1.3855e-01) 
2023-05-27 10:15:35.687766: train Epoch: [22][ 12/193]	Time  9.363 ( 5.447)	Data  8.799 ( 4.869)	Loss 5.6388e-02 (1.3223e-01) 
2023-05-27 10:15:36.252969: train Epoch: [22][ 13/193]	Time  0.565 ( 5.099)	Data  0.001 ( 4.521)	Loss 1.3319e-01 (1.3230e-01) 
2023-05-27 10:15:44.444688: train Epoch: [22][ 14/193]	Time  8.192 ( 5.305)	Data  7.626 ( 4.728)	Loss 6.7098e-02 (1.2795e-01) 
2023-05-27 10:15:45.009685: train Epoch: [22][ 15/193]	Time  0.565 ( 5.009)	Data  0.001 ( 4.433)	Loss 2.0188e-01 (1.3257e-01) 
2023-05-27 10:15:54.162975: train Epoch: [22][ 16/193]	Time  9.153 ( 5.253)	Data  8.591 ( 4.678)	Loss 1.2005e-01 (1.3184e-01) 
2023-05-27 10:15:54.728266: train Epoch: [22][ 17/193]	Time  0.565 ( 4.992)	Data  0.001 ( 4.418)	Loss 1.0712e-01 (1.3046e-01) 
2023-05-27 10:16:04.400121: train Epoch: [22][ 18/193]	Time  9.672 ( 5.238)	Data  9.106 ( 4.665)	Loss 1.2803e-01 (1.3034e-01) 
2023-05-27 10:16:04.965026: train Epoch: [22][ 19/193]	Time  0.565 ( 5.005)	Data  0.001 ( 4.431)	Loss 1.0273e-01 (1.2896e-01) 
2023-05-27 10:16:14.346846: train Epoch: [22][ 20/193]	Time  9.382 ( 5.213)	Data  8.809 ( 4.640)	Loss 1.0409e-01 (1.2777e-01) 
2023-05-27 10:16:14.917901: train Epoch: [22][ 21/193]	Time  0.571 ( 5.002)	Data  0.001 ( 4.429)	Loss 5.1748e-02 (1.2432e-01) 
2023-05-27 10:16:24.854572: train Epoch: [22][ 22/193]	Time  9.937 ( 5.217)	Data  9.371 ( 4.644)	Loss 1.1803e-01 (1.2404e-01) 
2023-05-27 10:16:25.419238: train Epoch: [22][ 23/193]	Time  0.565 ( 5.023)	Data  0.001 ( 4.450)	Loss 1.0424e-01 (1.2322e-01) 
2023-05-27 10:16:33.995343: train Epoch: [22][ 24/193]	Time  8.576 ( 5.165)	Data  8.013 ( 4.593)	Loss 7.8559e-02 (1.2143e-01) 
2023-05-27 10:16:34.559684: train Epoch: [22][ 25/193]	Time  0.564 ( 4.988)	Data  0.001 ( 4.416)	Loss 1.4491e-01 (1.2233e-01) 
2023-05-27 10:16:43.053627: train Epoch: [22][ 26/193]	Time  8.494 ( 5.118)	Data  7.927 ( 4.546)	Loss 1.1541e-01 (1.2208e-01) 
2023-05-27 10:16:43.637813: train Epoch: [22][ 27/193]	Time  0.584 ( 4.956)	Data  0.001 ( 4.384)	Loss 1.1754e-01 (1.2192e-01) 
2023-05-27 10:16:53.145070: train Epoch: [22][ 28/193]	Time  9.507 ( 5.113)	Data  8.943 ( 4.541)	Loss 6.7279e-02 (1.2003e-01) 
2023-05-27 10:16:53.708565: train Epoch: [22][ 29/193]	Time  0.563 ( 4.961)	Data  0.001 ( 4.390)	Loss 9.1449e-02 (1.1908e-01) 
2023-05-27 10:17:02.910750: train Epoch: [22][ 30/193]	Time  9.202 ( 5.098)	Data  8.633 ( 4.527)	Loss 1.6985e-01 (1.2072e-01) 
2023-05-27 10:17:03.474647: train Epoch: [22][ 31/193]	Time  0.564 ( 4.956)	Data  0.001 ( 4.385)	Loss 5.0559e-02 (1.1852e-01) 
2023-05-27 10:17:13.308184: train Epoch: [22][ 32/193]	Time  9.834 ( 5.104)	Data  9.270 ( 4.533)	Loss 1.1323e-01 (1.1836e-01) 
2023-05-27 10:17:13.871462: train Epoch: [22][ 33/193]	Time  0.563 ( 4.971)	Data  0.001 ( 4.400)	Loss 1.0821e-01 (1.1807e-01) 
2023-05-27 10:17:22.522463: train Epoch: [22][ 34/193]	Time  8.651 ( 5.076)	Data  8.087 ( 4.505)	Loss 7.5598e-02 (1.1685e-01) 
2023-05-27 10:17:23.086222: train Epoch: [22][ 35/193]	Time  0.564 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.5289e-01 (1.1785e-01) 
2023-05-27 10:17:32.210155: train Epoch: [22][ 36/193]	Time  9.124 ( 5.063)	Data  8.560 ( 4.493)	Loss 7.1817e-02 (1.1661e-01) 
2023-05-27 10:17:32.776764: train Epoch: [22][ 37/193]	Time  0.567 ( 4.945)	Data  0.001 ( 4.375)	Loss 1.5242e-01 (1.1755e-01) 
2023-05-27 10:17:42.117508: train Epoch: [22][ 38/193]	Time  9.341 ( 5.058)	Data  8.770 ( 4.488)	Loss 9.9119e-02 (1.1708e-01) 
2023-05-27 10:17:42.689161: train Epoch: [22][ 39/193]	Time  0.572 ( 4.945)	Data  0.001 ( 4.375)	Loss 1.4389e-01 (1.1775e-01) 
2023-05-27 10:17:51.985406: train Epoch: [22][ 40/193]	Time  9.296 ( 5.052)	Data  8.728 ( 4.482)	Loss 9.2400e-02 (1.1713e-01) 
2023-05-27 10:17:52.550069: train Epoch: [22][ 41/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.375)	Loss 9.6697e-02 (1.1664e-01) 
2023-05-27 10:18:02.165793: train Epoch: [22][ 42/193]	Time  9.616 ( 5.053)	Data  9.051 ( 4.484)	Loss 1.1441e-01 (1.1659e-01) 
2023-05-27 10:18:02.731018: train Epoch: [22][ 43/193]	Time  0.565 ( 4.951)	Data  0.001 ( 4.382)	Loss 6.6117e-02 (1.1545e-01) 
2023-05-27 10:18:11.669555: train Epoch: [22][ 44/193]	Time  8.939 ( 5.040)	Data  8.365 ( 4.470)	Loss 6.5899e-02 (1.1434e-01) 
2023-05-27 10:18:12.251421: train Epoch: [22][ 45/193]	Time  0.582 ( 4.943)	Data  0.001 ( 4.373)	Loss 1.2195e-01 (1.1451e-01) 
2023-05-27 10:18:21.674762: train Epoch: [22][ 46/193]	Time  9.423 ( 5.038)	Data  8.859 ( 4.469)	Loss 7.4392e-02 (1.1366e-01) 
2023-05-27 10:18:22.239372: train Epoch: [22][ 47/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.376)	Loss 9.0917e-02 (1.1318e-01) 
2023-05-27 10:18:31.817584: train Epoch: [22][ 48/193]	Time  9.578 ( 5.040)	Data  9.014 ( 4.470)	Loss 1.4365e-01 (1.1380e-01) 
2023-05-27 10:18:32.383816: train Epoch: [22][ 49/193]	Time  0.566 ( 4.950)	Data  0.001 ( 4.381)	Loss 1.1154e-01 (1.1376e-01) 
2023-05-27 10:18:41.264955: train Epoch: [22][ 50/193]	Time  8.881 ( 5.027)	Data  8.306 ( 4.458)	Loss 9.9761e-02 (1.1348e-01) 
2023-05-27 10:18:41.835676: train Epoch: [22][ 51/193]	Time  0.571 ( 4.942)	Data  0.001 ( 4.372)	Loss 1.5000e-01 (1.1419e-01) 
2023-05-27 10:18:51.605415: train Epoch: [22][ 52/193]	Time  9.770 ( 5.033)	Data  9.199 ( 4.463)	Loss 5.6287e-02 (1.1309e-01) 
2023-05-27 10:18:52.176191: train Epoch: [22][ 53/193]	Time  0.571 ( 4.950)	Data  0.001 ( 4.380)	Loss 8.3969e-02 (1.1255e-01) 
2023-05-27 10:19:01.536558: train Epoch: [22][ 54/193]	Time  9.360 ( 5.030)	Data  8.797 ( 4.461)	Loss 1.1874e-01 (1.1267e-01) 
2023-05-27 10:19:02.100136: train Epoch: [22][ 55/193]	Time  0.564 ( 4.951)	Data  0.001 ( 4.381)	Loss 9.1048e-02 (1.1228e-01) 
2023-05-27 10:19:11.437555: train Epoch: [22][ 56/193]	Time  9.337 ( 5.027)	Data  8.748 ( 4.458)	Loss 7.0703e-02 (1.1155e-01) 
2023-05-27 10:19:12.005852: train Epoch: [22][ 57/193]	Time  0.568 ( 4.951)	Data  0.001 ( 4.381)	Loss 5.0548e-02 (1.1050e-01) 
2023-05-27 10:19:21.416348: train Epoch: [22][ 58/193]	Time  9.410 ( 5.026)	Data  8.835 ( 4.456)	Loss 8.1949e-02 (1.1002e-01) 
2023-05-27 10:19:21.979300: train Epoch: [22][ 59/193]	Time  0.563 ( 4.952)	Data  0.001 ( 4.382)	Loss 8.6942e-02 (1.0963e-01) 
2023-05-27 10:19:31.548603: train Epoch: [22][ 60/193]	Time  9.569 ( 5.028)	Data  9.008 ( 4.458)	Loss 6.3309e-02 (1.0887e-01) 
2023-05-27 10:19:32.112000: train Epoch: [22][ 61/193]	Time  0.563 ( 4.956)	Data  0.001 ( 4.386)	Loss 8.4684e-02 (1.0848e-01) 
2023-05-27 10:19:40.630749: train Epoch: [22][ 62/193]	Time  8.519 ( 5.012)	Data  7.949 ( 4.443)	Loss 3.1605e-01 (1.1178e-01) 
2023-05-27 10:19:41.200541: train Epoch: [22][ 63/193]	Time  0.570 ( 4.943)	Data  0.001 ( 4.373)	Loss 1.1050e-01 (1.1176e-01) 
2023-05-27 10:19:50.210137: train Epoch: [22][ 64/193]	Time  9.010 ( 5.005)	Data  8.434 ( 4.436)	Loss 5.9158e-02 (1.1095e-01) 
2023-05-27 10:19:50.794171: train Epoch: [22][ 65/193]	Time  0.584 ( 4.938)	Data  0.001 ( 4.369)	Loss 9.7948e-02 (1.1075e-01) 
2023-05-27 10:20:00.163821: train Epoch: [22][ 66/193]	Time  9.370 ( 5.004)	Data  8.791 ( 4.435)	Loss 1.2464e-01 (1.1096e-01) 
2023-05-27 10:20:00.741891: train Epoch: [22][ 67/193]	Time  0.578 ( 4.939)	Data  0.001 ( 4.369)	Loss 1.4668e-01 (1.1148e-01) 
2023-05-27 10:20:10.804287: train Epoch: [22][ 68/193]	Time 10.062 ( 5.014)	Data  9.485 ( 4.443)	Loss 7.4185e-02 (1.1094e-01) 
2023-05-27 10:20:11.368392: train Epoch: [22][ 69/193]	Time  0.564 ( 4.950)	Data  0.001 ( 4.380)	Loss 1.1834e-01 (1.1105e-01) 
2023-05-27 10:20:20.390082: train Epoch: [22][ 70/193]	Time  9.022 ( 5.007)	Data  8.451 ( 4.437)	Loss 3.8963e-01 (1.1497e-01) 
2023-05-27 10:20:20.971889: train Epoch: [22][ 71/193]	Time  0.582 ( 4.946)	Data  0.001 ( 4.376)	Loss 8.2682e-02 (1.1452e-01) 
2023-05-27 10:20:30.798485: train Epoch: [22][ 72/193]	Time  9.827 ( 5.013)	Data  9.254 ( 4.443)	Loss 9.0118e-02 (1.1419e-01) 
2023-05-27 10:20:31.361579: train Epoch: [22][ 73/193]	Time  0.563 ( 4.953)	Data  0.001 ( 4.383)	Loss 8.8042e-02 (1.1384e-01) 
2023-05-27 10:20:40.551467: train Epoch: [22][ 74/193]	Time  9.190 ( 5.009)	Data  8.584 ( 4.439)	Loss 7.7382e-02 (1.1335e-01) 
2023-05-27 10:20:41.122435: train Epoch: [22][ 75/193]	Time  0.571 ( 4.951)	Data  0.001 ( 4.380)	Loss 8.1837e-02 (1.1294e-01) 
2023-05-27 10:20:50.025467: train Epoch: [22][ 76/193]	Time  8.903 ( 5.002)	Data  8.334 ( 4.431)	Loss 6.8497e-02 (1.1236e-01) 
2023-05-27 10:20:50.598911: train Epoch: [22][ 77/193]	Time  0.573 ( 4.945)	Data  0.001 ( 4.375)	Loss 1.6224e-01 (1.1300e-01) 
2023-05-27 10:21:00.234970: train Epoch: [22][ 78/193]	Time  9.636 ( 5.005)	Data  9.059 ( 4.434)	Loss 1.1173e-01 (1.1298e-01) 
2023-05-27 10:21:00.820132: train Epoch: [22][ 79/193]	Time  0.585 ( 4.949)	Data  0.001 ( 4.379)	Loss 1.1865e-01 (1.1305e-01) 
2023-05-27 10:21:10.706981: train Epoch: [22][ 80/193]	Time  9.887 ( 5.010)	Data  9.310 ( 4.439)	Loss 1.1530e-01 (1.1308e-01) 
2023-05-27 10:21:11.282523: train Epoch: [22][ 81/193]	Time  0.576 ( 4.956)	Data  0.001 ( 4.385)	Loss 8.1059e-02 (1.1269e-01) 
2023-05-27 10:21:20.447183: train Epoch: [22][ 82/193]	Time  9.165 ( 5.007)	Data  8.575 ( 4.436)	Loss 1.0382e-01 (1.1258e-01) 
2023-05-27 10:21:21.010168: train Epoch: [22][ 83/193]	Time  0.563 ( 4.954)	Data  0.001 ( 4.383)	Loss 1.4335e-01 (1.1295e-01) 
2023-05-27 10:21:29.791754: train Epoch: [22][ 84/193]	Time  8.782 ( 4.999)	Data  8.220 ( 4.428)	Loss 6.1504e-02 (1.1234e-01) 
2023-05-27 10:21:30.365440: train Epoch: [22][ 85/193]	Time  0.574 ( 4.948)	Data  0.001 ( 4.377)	Loss 1.4369e-01 (1.1271e-01) 
2023-05-27 10:21:38.187149: train Epoch: [22][ 86/193]	Time  7.822 ( 4.981)	Data  7.254 ( 4.410)	Loss 2.5538e-01 (1.1435e-01) 
2023-05-27 10:21:38.774708: train Epoch: [22][ 87/193]	Time  0.588 ( 4.931)	Data  0.001 ( 4.360)	Loss 1.0978e-01 (1.1430e-01) 
2023-05-27 10:21:47.854497: train Epoch: [22][ 88/193]	Time  9.080 ( 4.977)	Data  8.480 ( 4.406)	Loss 1.1656e-01 (1.1432e-01) 
2023-05-27 10:21:48.415255: train Epoch: [22][ 89/193]	Time  0.561 ( 4.928)	Data  0.001 ( 4.357)	Loss 1.1539e-01 (1.1433e-01) 
2023-05-27 10:21:57.788110: train Epoch: [22][ 90/193]	Time  9.373 ( 4.977)	Data  8.803 ( 4.406)	Loss 6.7722e-02 (1.1382e-01) 
2023-05-27 10:21:58.366095: train Epoch: [22][ 91/193]	Time  0.578 ( 4.929)	Data  0.001 ( 4.358)	Loss 9.5022e-02 (1.1362e-01) 
2023-05-27 10:22:07.692519: train Epoch: [22][ 92/193]	Time  9.326 ( 4.977)	Data  8.754 ( 4.405)	Loss 6.8540e-02 (1.1313e-01) 
2023-05-27 10:22:08.260729: train Epoch: [22][ 93/193]	Time  0.568 ( 4.930)	Data  0.001 ( 4.358)	Loss 5.0924e-02 (1.1247e-01) 
2023-05-27 10:22:17.632244: train Epoch: [22][ 94/193]	Time  9.372 ( 4.976)	Data  8.782 ( 4.405)	Loss 1.7382e-01 (1.1312e-01) 
2023-05-27 10:22:18.195997: train Epoch: [22][ 95/193]	Time  0.564 ( 4.930)	Data  0.001 ( 4.359)	Loss 8.1309e-02 (1.1278e-01) 
2023-05-27 10:22:27.796818: train Epoch: [22][ 96/193]	Time  9.601 ( 4.979)	Data  9.031 ( 4.407)	Loss 1.3859e-01 (1.1305e-01) 
2023-05-27 10:22:28.380679: train Epoch: [22][ 97/193]	Time  0.584 ( 4.934)	Data  0.001 ( 4.362)	Loss 1.0223e-01 (1.1294e-01) 
2023-05-27 10:22:37.492429: train Epoch: [22][ 98/193]	Time  9.112 ( 4.976)	Data  8.526 ( 4.404)	Loss 1.1442e-01 (1.1296e-01) 
2023-05-27 10:22:38.134557: train Epoch: [22][ 99/193]	Time  0.642 ( 4.933)	Data  0.001 ( 4.360)	Loss 9.8517e-02 (1.1281e-01) 
2023-05-27 10:22:47.767619: train Epoch: [22][100/193]	Time  9.633 ( 4.979)	Data  9.069 ( 4.407)	Loss 2.4134e-01 (1.1408e-01) 
2023-05-27 10:22:48.340029: train Epoch: [22][101/193]	Time  0.572 ( 4.936)	Data  0.001 ( 4.364)	Loss 1.8469e-01 (1.1478e-01) 
2023-05-27 10:22:58.040717: train Epoch: [22][102/193]	Time  9.701 ( 4.982)	Data  9.112 ( 4.410)	Loss 7.3055e-02 (1.1437e-01) 
2023-05-27 10:22:58.613218: train Epoch: [22][103/193]	Time  0.573 ( 4.940)	Data  0.001 ( 4.367)	Loss 9.6908e-02 (1.1420e-01) 
2023-05-27 10:23:07.750012: train Epoch: [22][104/193]	Time  9.137 ( 4.980)	Data  8.573 ( 4.407)	Loss 1.1964e-01 (1.1425e-01) 
2023-05-27 10:23:08.320223: train Epoch: [22][105/193]	Time  0.570 ( 4.938)	Data  0.001 ( 4.366)	Loss 1.0399e-01 (1.1416e-01) 
2023-05-27 10:23:17.686874: train Epoch: [22][106/193]	Time  9.367 ( 4.980)	Data  8.791 ( 4.407)	Loss 6.8001e-02 (1.1373e-01) 
2023-05-27 10:23:18.282138: train Epoch: [22][107/193]	Time  0.595 ( 4.939)	Data  0.001 ( 4.366)	Loss 1.3652e-01 (1.1394e-01) 
2023-05-27 10:23:28.302237: train Epoch: [22][108/193]	Time 10.020 ( 4.986)	Data  9.448 ( 4.413)	Loss 1.4215e-01 (1.1420e-01) 
2023-05-27 10:23:28.866997: train Epoch: [22][109/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.373)	Loss 2.1587e-01 (1.1512e-01) 
2023-05-27 10:23:38.291174: train Epoch: [22][110/193]	Time  9.424 ( 4.986)	Data  8.857 ( 4.413)	Loss 9.1033e-02 (1.1490e-01) 
2023-05-27 10:23:38.850930: train Epoch: [22][111/193]	Time  0.560 ( 4.946)	Data  0.001 ( 4.374)	Loss 1.5986e-01 (1.1530e-01) 
2023-05-27 10:23:48.266028: train Epoch: [22][112/193]	Time  9.415 ( 4.986)	Data  8.835 ( 4.413)	Loss 1.5044e-01 (1.1562e-01) 
2023-05-27 10:23:48.838274: train Epoch: [22][113/193]	Time  0.572 ( 4.947)	Data  0.001 ( 4.375)	Loss 1.3872e-01 (1.1582e-01) 
2023-05-27 10:23:57.889234: train Epoch: [22][114/193]	Time  9.051 ( 4.983)	Data  8.481 ( 4.410)	Loss 1.1971e-01 (1.1585e-01) 
2023-05-27 10:23:58.454151: train Epoch: [22][115/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.372)	Loss 7.4391e-02 (1.1549e-01) 
2023-05-27 10:24:08.021668: train Epoch: [22][116/193]	Time  9.567 ( 4.984)	Data  8.976 ( 4.412)	Loss 7.7119e-02 (1.1517e-01) 
2023-05-27 10:24:08.589385: train Epoch: [22][117/193]	Time  0.568 ( 4.947)	Data  0.001 ( 4.374)	Loss 1.0177e-01 (1.1505e-01) 
2023-05-27 10:24:18.052386: train Epoch: [22][118/193]	Time  9.463 ( 4.985)	Data  8.892 ( 4.412)	Loss 1.2792e-01 (1.1516e-01) 
2023-05-27 10:24:18.619821: train Epoch: [22][119/193]	Time  0.567 ( 4.948)	Data  0.001 ( 4.376)	Loss 6.4912e-02 (1.1474e-01) 
2023-05-27 10:24:27.749374: train Epoch: [22][120/193]	Time  9.130 ( 4.982)	Data  8.567 ( 4.410)	Loss 2.0544e-01 (1.1549e-01) 
2023-05-27 10:24:28.374543: train Epoch: [22][121/193]	Time  0.625 ( 4.947)	Data  0.001 ( 4.374)	Loss 7.5983e-02 (1.1517e-01) 
2023-05-27 10:24:37.414828: train Epoch: [22][122/193]	Time  9.040 ( 4.980)	Data  8.469 ( 4.407)	Loss 8.1687e-02 (1.1490e-01) 
2023-05-27 10:24:38.007308: train Epoch: [22][123/193]	Time  0.592 ( 4.945)	Data  0.001 ( 4.372)	Loss 8.6227e-02 (1.1467e-01) 
2023-05-27 10:24:47.049842: train Epoch: [22][124/193]	Time  9.043 ( 4.977)	Data  8.470 ( 4.405)	Loss 4.2778e-02 (1.1409e-01) 
2023-05-27 10:24:47.622187: train Epoch: [22][125/193]	Time  0.572 ( 4.942)	Data  0.001 ( 4.370)	Loss 6.5138e-02 (1.1370e-01) 
2023-05-27 10:24:57.380257: train Epoch: [22][126/193]	Time  9.758 ( 4.980)	Data  9.191 ( 4.408)	Loss 7.9712e-02 (1.1343e-01) 
2023-05-27 10:24:57.946716: train Epoch: [22][127/193]	Time  0.566 ( 4.946)	Data  0.001 ( 4.373)	Loss 6.3325e-02 (1.1304e-01) 
2023-05-27 10:25:07.283773: train Epoch: [22][128/193]	Time  9.337 ( 4.980)	Data  8.767 ( 4.407)	Loss 1.3052e-01 (1.1318e-01) 
2023-05-27 10:25:07.845432: train Epoch: [22][129/193]	Time  0.562 ( 4.946)	Data  0.001 ( 4.373)	Loss 9.5942e-02 (1.1305e-01) 
2023-05-27 10:25:17.413833: train Epoch: [22][130/193]	Time  9.568 ( 4.981)	Data  9.006 ( 4.409)	Loss 7.3946e-02 (1.1275e-01) 
2023-05-27 10:25:17.975212: train Epoch: [22][131/193]	Time  0.561 ( 4.948)	Data  0.001 ( 4.375)	Loss 7.3404e-02 (1.1245e-01) 
2023-05-27 10:25:27.246422: train Epoch: [22][132/193]	Time  9.271 ( 4.980)	Data  8.710 ( 4.408)	Loss 8.7719e-02 (1.1226e-01) 
2023-05-27 10:25:27.807733: train Epoch: [22][133/193]	Time  0.561 ( 4.947)	Data  0.001 ( 4.375)	Loss 1.5161e-01 (1.1256e-01) 
2023-05-27 10:25:37.342019: train Epoch: [22][134/193]	Time  9.534 ( 4.981)	Data  8.962 ( 4.409)	Loss 7.2100e-02 (1.1226e-01) 
2023-05-27 10:25:37.903542: train Epoch: [22][135/193]	Time  0.562 ( 4.949)	Data  0.001 ( 4.377)	Loss 7.8667e-02 (1.1201e-01) 
2023-05-27 10:25:47.552135: train Epoch: [22][136/193]	Time  9.649 ( 4.983)	Data  9.088 ( 4.411)	Loss 7.7928e-02 (1.1176e-01) 
2023-05-27 10:25:48.115732: train Epoch: [22][137/193]	Time  0.564 ( 4.951)	Data  0.001 ( 4.379)	Loss 9.0444e-02 (1.1161e-01) 
2023-05-27 10:25:57.127564: train Epoch: [22][138/193]	Time  9.012 ( 4.980)	Data  8.451 ( 4.408)	Loss 8.7723e-02 (1.1143e-01) 
2023-05-27 10:25:57.689019: train Epoch: [22][139/193]	Time  0.561 ( 4.949)	Data  0.001 ( 4.377)	Loss 6.8521e-02 (1.1113e-01) 
2023-05-27 10:26:06.804386: train Epoch: [22][140/193]	Time  9.115 ( 4.978)	Data  8.554 ( 4.407)	Loss 1.2823e-01 (1.1125e-01) 
2023-05-27 10:26:07.366815: train Epoch: [22][141/193]	Time  0.562 ( 4.947)	Data  0.001 ( 4.375)	Loss 6.1804e-02 (1.1090e-01) 
2023-05-27 10:26:16.582115: train Epoch: [22][142/193]	Time  9.215 ( 4.977)	Data  8.655 ( 4.405)	Loss 8.2550e-02 (1.1070e-01) 
2023-05-27 10:26:17.143028: train Epoch: [22][143/193]	Time  0.561 ( 4.946)	Data  0.001 ( 4.375)	Loss 8.0791e-02 (1.1050e-01) 
2023-05-27 10:26:26.461750: train Epoch: [22][144/193]	Time  9.319 ( 4.976)	Data  8.745 ( 4.405)	Loss 9.5697e-02 (1.1039e-01) 
2023-05-27 10:26:27.028045: train Epoch: [22][145/193]	Time  0.566 ( 4.946)	Data  0.001 ( 4.375)	Loss 1.9341e-01 (1.1096e-01) 
2023-05-27 10:26:35.952783: train Epoch: [22][146/193]	Time  8.925 ( 4.973)	Data  8.358 ( 4.402)	Loss 1.4563e-01 (1.1120e-01) 
2023-05-27 10:26:36.514244: train Epoch: [22][147/193]	Time  0.561 ( 4.944)	Data  0.001 ( 4.372)	Loss 1.0802e-01 (1.1118e-01) 
2023-05-27 10:26:45.742151: train Epoch: [22][148/193]	Time  9.228 ( 4.972)	Data  8.662 ( 4.401)	Loss 5.8393e-02 (1.1082e-01) 
2023-05-27 10:26:46.307284: train Epoch: [22][149/193]	Time  0.565 ( 4.943)	Data  0.001 ( 4.372)	Loss 8.5066e-02 (1.1065e-01) 
2023-05-27 10:26:55.566896: train Epoch: [22][150/193]	Time  9.260 ( 4.971)	Data  8.699 ( 4.400)	Loss 1.4448e-01 (1.1087e-01) 
2023-05-27 10:26:56.130236: train Epoch: [22][151/193]	Time  0.563 ( 4.942)	Data  0.001 ( 4.371)	Loss 2.4593e-01 (1.1176e-01) 
2023-05-27 10:27:05.178757: train Epoch: [22][152/193]	Time  9.049 ( 4.969)	Data  8.479 ( 4.398)	Loss 5.7198e-02 (1.1141e-01) 
2023-05-27 10:27:05.739643: train Epoch: [22][153/193]	Time  0.561 ( 4.941)	Data  0.001 ( 4.370)	Loss 4.7073e-02 (1.1099e-01) 
2023-05-27 10:27:14.742743: train Epoch: [22][154/193]	Time  9.003 ( 4.967)	Data  8.434 ( 4.396)	Loss 9.1752e-02 (1.1086e-01) 
2023-05-27 10:27:15.312923: train Epoch: [22][155/193]	Time  0.570 ( 4.939)	Data  0.001 ( 4.368)	Loss 9.0589e-02 (1.1073e-01) 
2023-05-27 10:27:24.714079: train Epoch: [22][156/193]	Time  9.401 ( 4.967)	Data  8.795 ( 4.396)	Loss 8.0017e-02 (1.1054e-01) 
2023-05-27 10:27:25.280123: train Epoch: [22][157/193]	Time  0.566 ( 4.939)	Data  0.001 ( 4.368)	Loss 1.4320e-01 (1.1075e-01) 
2023-05-27 10:27:34.709554: train Epoch: [22][158/193]	Time  9.429 ( 4.968)	Data  8.840 ( 4.396)	Loss 9.0745e-02 (1.1062e-01) 
2023-05-27 10:27:35.271803: train Epoch: [22][159/193]	Time  0.562 ( 4.940)	Data  0.001 ( 4.369)	Loss 7.7704e-02 (1.1041e-01) 
2023-05-27 10:27:44.770037: train Epoch: [22][160/193]	Time  9.498 ( 4.968)	Data  8.934 ( 4.397)	Loss 1.0568e-01 (1.1038e-01) 
2023-05-27 10:27:45.353226: train Epoch: [22][161/193]	Time  0.583 ( 4.941)	Data  0.001 ( 4.370)	Loss 2.3258e-01 (1.1114e-01) 
2023-05-27 10:27:54.621987: train Epoch: [22][162/193]	Time  9.269 ( 4.968)	Data  8.701 ( 4.396)	Loss 5.4402e-02 (1.1079e-01) 
2023-05-27 10:27:55.193867: train Epoch: [22][163/193]	Time  0.572 ( 4.941)	Data  0.001 ( 4.370)	Loss 8.8734e-02 (1.1066e-01) 
2023-05-27 10:28:04.637599: train Epoch: [22][164/193]	Time  9.444 ( 4.968)	Data  8.868 ( 4.397)	Loss 7.4215e-02 (1.1044e-01) 
2023-05-27 10:28:05.209636: train Epoch: [22][165/193]	Time  0.572 ( 4.942)	Data  0.001 ( 4.370)	Loss 9.6687e-02 (1.1035e-01) 
2023-05-27 10:28:14.464278: train Epoch: [22][166/193]	Time  9.255 ( 4.968)	Data  8.689 ( 4.396)	Loss 1.0247e-01 (1.1031e-01) 
2023-05-27 10:28:15.030796: train Epoch: [22][167/193]	Time  0.567 ( 4.941)	Data  0.001 ( 4.370)	Loss 7.6018e-02 (1.1010e-01) 
2023-05-27 10:28:24.671084: train Epoch: [22][168/193]	Time  9.640 ( 4.969)	Data  9.067 ( 4.398)	Loss 7.0795e-02 (1.0987e-01) 
2023-05-27 10:28:25.241638: train Epoch: [22][169/193]	Time  0.571 ( 4.943)	Data  0.001 ( 4.372)	Loss 7.1108e-02 (1.0964e-01) 
2023-05-27 10:28:34.328886: train Epoch: [22][170/193]	Time  9.087 ( 4.968)	Data  8.521 ( 4.396)	Loss 6.4319e-02 (1.0938e-01) 
2023-05-27 10:28:34.892251: train Epoch: [22][171/193]	Time  0.563 ( 4.942)	Data  0.001 ( 4.371)	Loss 6.7272e-02 (1.0913e-01) 
2023-05-27 10:28:44.326589: train Epoch: [22][172/193]	Time  9.434 ( 4.968)	Data  8.869 ( 4.397)	Loss 2.0655e-01 (1.0969e-01) 
2023-05-27 10:28:44.894052: train Epoch: [22][173/193]	Time  0.567 ( 4.943)	Data  0.001 ( 4.372)	Loss 8.8893e-02 (1.0957e-01) 
2023-05-27 10:28:54.299323: train Epoch: [22][174/193]	Time  9.405 ( 4.968)	Data  8.844 ( 4.397)	Loss 2.6865e-01 (1.1048e-01) 
2023-05-27 10:28:54.859710: train Epoch: [22][175/193]	Time  0.560 ( 4.943)	Data  0.001 ( 4.372)	Loss 7.6467e-02 (1.1029e-01) 
2023-05-27 10:29:04.659247: train Epoch: [22][176/193]	Time  9.800 ( 4.971)	Data  9.233 ( 4.400)	Loss 7.7342e-02 (1.1010e-01) 
2023-05-27 10:29:05.226537: train Epoch: [22][177/193]	Time  0.567 ( 4.946)	Data  0.001 ( 4.375)	Loss 6.3901e-02 (1.0984e-01) 
2023-05-27 10:29:14.871589: train Epoch: [22][178/193]	Time  9.645 ( 4.972)	Data  9.080 ( 4.401)	Loss 9.3957e-02 (1.0976e-01) 
2023-05-27 10:29:15.432449: train Epoch: [22][179/193]	Time  0.561 ( 4.948)	Data  0.001 ( 4.377)	Loss 7.5295e-02 (1.0956e-01) 
2023-05-27 10:29:24.918020: train Epoch: [22][180/193]	Time  9.486 ( 4.973)	Data  8.925 ( 4.402)	Loss 1.0063e-01 (1.0951e-01) 
2023-05-27 10:29:25.479864: train Epoch: [22][181/193]	Time  0.562 ( 4.948)	Data  0.001 ( 4.378)	Loss 1.2030e-01 (1.0957e-01) 
2023-05-27 10:29:34.745841: train Epoch: [22][182/193]	Time  9.266 ( 4.972)	Data  8.694 ( 4.401)	Loss 8.6780e-02 (1.0945e-01) 
2023-05-27 10:29:35.311536: train Epoch: [22][183/193]	Time  0.566 ( 4.948)	Data  0.001 ( 4.377)	Loss 4.0507e-02 (1.0907e-01) 
2023-05-27 10:29:44.825393: train Epoch: [22][184/193]	Time  9.514 ( 4.973)	Data  8.928 ( 4.402)	Loss 6.7923e-02 (1.0885e-01) 
2023-05-27 10:29:45.397796: train Epoch: [22][185/193]	Time  0.572 ( 4.949)	Data  0.001 ( 4.378)	Loss 1.7113e-01 (1.0919e-01) 
2023-05-27 10:29:54.552497: train Epoch: [22][186/193]	Time  9.155 ( 4.972)	Data  8.584 ( 4.401)	Loss 1.6833e-01 (1.0950e-01) 
2023-05-27 10:29:55.117975: train Epoch: [22][187/193]	Time  0.565 ( 4.948)	Data  0.001 ( 4.377)	Loss 3.6371e-02 (1.0911e-01) 
2023-05-27 10:30:04.376518: train Epoch: [22][188/193]	Time  9.259 ( 4.971)	Data  8.692 ( 4.400)	Loss 9.5918e-02 (1.0904e-01) 
2023-05-27 10:30:04.941232: train Epoch: [22][189/193]	Time  0.565 ( 4.948)	Data  0.001 ( 4.377)	Loss 9.1855e-02 (1.0895e-01) 
2023-05-27 10:30:14.091059: train Epoch: [22][190/193]	Time  9.150 ( 4.970)	Data  8.556 ( 4.399)	Loss 1.7268e-01 (1.0929e-01) 
2023-05-27 10:30:14.652099: train Epoch: [22][191/193]	Time  0.561 ( 4.947)	Data  0.001 ( 4.376)	Loss 9.7323e-02 (1.0923e-01) 
2023-05-27 10:30:22.899974: train Epoch: [22][192/193]	Time  8.248 ( 4.964)	Data  7.612 ( 4.393)	Loss 4.6615e-02 (1.0890e-01) 
2023-05-27 10:30:23.026187: Train Epoch done in 958.1562176099978 s 
2023-05-27 10:30:29.272790: val Epoch: [22][ 0/72]	Time  5.609 ( 5.609)	Data  5.456 ( 5.456)	Loss 6.6372e-02 (6.6372e-02) 
2023-05-27 10:30:29.378454: val Epoch: [22][ 1/72]	Time  0.106 ( 2.857)	Data  0.001 ( 2.728)	Loss 5.0053e-02 (5.8213e-02) 
2023-05-27 10:30:34.381474: val Epoch: [22][ 2/72]	Time  5.003 ( 3.573)	Data  4.894 ( 3.450)	Loss 7.6925e-02 (6.4450e-02) 
2023-05-27 10:30:34.486734: val Epoch: [22][ 3/72]	Time  0.105 ( 2.706)	Data  0.000 ( 2.588)	Loss 6.0686e-02 (6.3509e-02) 
2023-05-27 10:30:39.529769: val Epoch: [22][ 4/72]	Time  5.043 ( 3.173)	Data  4.935 ( 3.057)	Loss 3.6415e-01 (1.2364e-01) 
2023-05-27 10:30:39.635284: val Epoch: [22][ 5/72]	Time  0.106 ( 2.662)	Data  0.000 ( 2.548)	Loss 4.9289e-02 (1.1125e-01) 
2023-05-27 10:30:44.467402: val Epoch: [22][ 6/72]	Time  4.832 ( 2.972)	Data  4.723 ( 2.859)	Loss 1.2969e-01 (1.1388e-01) 
2023-05-27 10:30:44.572418: val Epoch: [22][ 7/72]	Time  0.105 ( 2.614)	Data  0.001 ( 2.501)	Loss 1.1821e-01 (1.1442e-01) 
2023-05-27 10:30:49.287436: val Epoch: [22][ 8/72]	Time  4.715 ( 2.847)	Data  4.600 ( 2.734)	Loss 5.3230e-02 (1.0762e-01) 
2023-05-27 10:30:49.397218: val Epoch: [22][ 9/72]	Time  0.110 ( 2.573)	Data  0.001 ( 2.461)	Loss 9.8910e-02 (1.0675e-01) 
2023-05-27 10:30:54.254117: val Epoch: [22][10/72]	Time  4.857 ( 2.781)	Data  4.744 ( 2.669)	Loss 9.1070e-02 (1.0533e-01) 
2023-05-27 10:30:54.362498: val Epoch: [22][11/72]	Time  0.108 ( 2.558)	Data  0.001 ( 2.446)	Loss 9.4022e-02 (1.0438e-01) 
2023-05-27 10:30:59.316441: val Epoch: [22][12/72]	Time  4.954 ( 2.742)	Data  4.842 ( 2.631)	Loss 2.8774e-01 (1.1849e-01) 
2023-05-27 10:30:59.424969: val Epoch: [22][13/72]	Time  0.109 ( 2.554)	Data  0.001 ( 2.443)	Loss 6.5936e-02 (1.1473e-01) 
2023-05-27 10:31:04.566675: val Epoch: [22][14/72]	Time  5.142 ( 2.727)	Data  5.003 ( 2.613)	Loss 4.3805e-01 (1.3629e-01) 
2023-05-27 10:31:04.683143: val Epoch: [22][15/72]	Time  0.116 ( 2.564)	Data  0.001 ( 2.450)	Loss 5.9825e-02 (1.3151e-01) 
2023-05-27 10:31:09.316343: val Epoch: [22][16/72]	Time  4.633 ( 2.685)	Data  4.527 ( 2.572)	Loss 6.6672e-02 (1.2770e-01) 
2023-05-27 10:31:09.425467: val Epoch: [22][17/72]	Time  0.109 ( 2.542)	Data  0.001 ( 2.429)	Loss 3.8316e-01 (1.4189e-01) 
2023-05-27 10:31:14.409914: val Epoch: [22][18/72]	Time  4.984 ( 2.671)	Data  4.870 ( 2.558)	Loss 3.8977e-01 (1.5493e-01) 
2023-05-27 10:31:14.558264: val Epoch: [22][19/72]	Time  0.148 ( 2.545)	Data  0.002 ( 2.430)	Loss 1.2545e-01 (1.5346e-01) 
2023-05-27 10:31:19.347463: val Epoch: [22][20/72]	Time  4.789 ( 2.652)	Data  4.677 ( 2.537)	Loss 7.2463e-02 (1.4960e-01) 
2023-05-27 10:31:19.456412: val Epoch: [22][21/72]	Time  0.109 ( 2.536)	Data  0.001 ( 2.422)	Loss 1.9467e-01 (1.5165e-01) 
2023-05-27 10:31:24.299817: val Epoch: [22][22/72]	Time  4.843 ( 2.636)	Data  4.736 ( 2.522)	Loss 6.4547e-02 (1.4786e-01) 
2023-05-27 10:31:24.407469: val Epoch: [22][23/72]	Time  0.108 ( 2.531)	Data  0.001 ( 2.417)	Loss 3.8056e-02 (1.4329e-01) 
2023-05-27 10:31:29.272466: val Epoch: [22][24/72]	Time  4.865 ( 2.624)	Data  4.757 ( 2.511)	Loss 2.2954e-01 (1.4674e-01) 
2023-05-27 10:31:29.380650: val Epoch: [22][25/72]	Time  0.108 ( 2.528)	Data  0.000 ( 2.414)	Loss 1.3095e-01 (1.4613e-01) 
2023-05-27 10:31:34.178662: val Epoch: [22][26/72]	Time  4.798 ( 2.612)	Data  4.689 ( 2.499)	Loss 5.2318e-02 (1.4266e-01) 
2023-05-27 10:31:34.286709: val Epoch: [22][27/72]	Time  0.108 ( 2.522)	Data  0.001 ( 2.409)	Loss 1.4495e-01 (1.4274e-01) 
2023-05-27 10:31:39.047961: val Epoch: [22][28/72]	Time  4.761 ( 2.599)	Data  4.653 ( 2.487)	Loss 8.7984e-02 (1.4085e-01) 
2023-05-27 10:31:39.155642: val Epoch: [22][29/72]	Time  0.108 ( 2.516)	Data  0.001 ( 2.404)	Loss 4.0754e-02 (1.3751e-01) 
2023-05-27 10:31:44.101697: val Epoch: [22][30/72]	Time  4.946 ( 2.595)	Data  4.835 ( 2.482)	Loss 9.6987e-02 (1.3621e-01) 
2023-05-27 10:31:44.210338: val Epoch: [22][31/72]	Time  0.109 ( 2.517)	Data  0.001 ( 2.405)	Loss 9.3543e-02 (1.3487e-01) 
2023-05-27 10:31:49.259579: val Epoch: [22][32/72]	Time  5.049 ( 2.594)	Data  4.926 ( 2.481)	Loss 4.8505e-02 (1.3226e-01) 
2023-05-27 10:31:49.375284: val Epoch: [22][33/72]	Time  0.116 ( 2.521)	Data  0.001 ( 2.408)	Loss 1.8047e-01 (1.3367e-01) 
2023-05-27 10:31:54.507052: val Epoch: [22][34/72]	Time  5.132 ( 2.596)	Data  5.022 ( 2.483)	Loss 6.5542e-02 (1.3173e-01) 
2023-05-27 10:31:54.618625: val Epoch: [22][35/72]	Time  0.112 ( 2.527)	Data  0.001 ( 2.414)	Loss 4.4046e-02 (1.2929e-01) 
2023-05-27 10:31:59.786457: val Epoch: [22][36/72]	Time  5.168 ( 2.598)	Data  5.049 ( 2.485)	Loss 5.9731e-02 (1.2741e-01) 
2023-05-27 10:31:59.894781: val Epoch: [22][37/72]	Time  0.108 ( 2.532)	Data  0.001 ( 2.420)	Loss 7.3922e-02 (1.2600e-01) 
2023-05-27 10:32:04.720997: val Epoch: [22][38/72]	Time  4.826 ( 2.591)	Data  4.704 ( 2.478)	Loss 7.9387e-02 (1.2481e-01) 
2023-05-27 10:32:04.833850: val Epoch: [22][39/72]	Time  0.113 ( 2.529)	Data  0.001 ( 2.416)	Loss 1.2058e-01 (1.2470e-01) 
2023-05-27 10:32:10.012890: val Epoch: [22][40/72]	Time  5.179 ( 2.594)	Data  5.070 ( 2.481)	Loss 9.4674e-02 (1.2397e-01) 
2023-05-27 10:32:10.121592: val Epoch: [22][41/72]	Time  0.109 ( 2.535)	Data  0.001 ( 2.422)	Loss 6.0705e-02 (1.2246e-01) 
2023-05-27 10:32:15.126170: val Epoch: [22][42/72]	Time  5.005 ( 2.592)	Data  4.896 ( 2.480)	Loss 6.3626e-02 (1.2110e-01) 
2023-05-27 10:32:15.235430: val Epoch: [22][43/72]	Time  0.109 ( 2.536)	Data  0.001 ( 2.423)	Loss 8.4651e-02 (1.2027e-01) 
2023-05-27 10:32:20.329198: val Epoch: [22][44/72]	Time  5.094 ( 2.593)	Data  4.924 ( 2.479)	Loss 9.0272e-02 (1.1960e-01) 
2023-05-27 10:32:20.465085: val Epoch: [22][45/72]	Time  0.136 ( 2.539)	Data  0.001 ( 2.425)	Loss 1.0453e-01 (1.1927e-01) 
2023-05-27 10:32:25.420506: val Epoch: [22][46/72]	Time  4.955 ( 2.591)	Data  4.844 ( 2.476)	Loss 8.0539e-02 (1.1845e-01) 
2023-05-27 10:32:25.531304: val Epoch: [22][47/72]	Time  0.111 ( 2.539)	Data  0.001 ( 2.425)	Loss 4.3806e-01 (1.2511e-01) 
2023-05-27 10:32:30.267316: val Epoch: [22][48/72]	Time  4.736 ( 2.584)	Data  4.623 ( 2.470)	Loss 8.5378e-02 (1.2430e-01) 
2023-05-27 10:32:30.382401: val Epoch: [22][49/72]	Time  0.115 ( 2.534)	Data  0.001 ( 2.420)	Loss 6.3426e-02 (1.2308e-01) 
2023-05-27 10:32:35.578847: val Epoch: [22][50/72]	Time  5.196 ( 2.587)	Data  5.076 ( 2.472)	Loss 1.6416e-01 (1.2389e-01) 
2023-05-27 10:32:35.696651: val Epoch: [22][51/72]	Time  0.118 ( 2.539)	Data  0.001 ( 2.425)	Loss 1.4145e-01 (1.2422e-01) 
2023-05-27 10:32:40.809699: val Epoch: [22][52/72]	Time  5.113 ( 2.588)	Data  5.002 ( 2.473)	Loss 1.0417e-01 (1.2385e-01) 
2023-05-27 10:32:40.917807: val Epoch: [22][53/72]	Time  0.108 ( 2.542)	Data  0.000 ( 2.428)	Loss 1.8205e-01 (1.2492e-01) 
2023-05-27 10:32:45.997807: val Epoch: [22][54/72]	Time  5.080 ( 2.588)	Data  4.968 ( 2.474)	Loss 8.8938e-02 (1.2427e-01) 
2023-05-27 10:32:46.116189: val Epoch: [22][55/72]	Time  0.118 ( 2.544)	Data  0.001 ( 2.430)	Loss 5.2838e-02 (1.2299e-01) 
2023-05-27 10:32:51.092697: val Epoch: [22][56/72]	Time  4.977 ( 2.586)	Data  4.869 ( 2.472)	Loss 2.7003e-01 (1.2557e-01) 
2023-05-27 10:32:51.199785: val Epoch: [22][57/72]	Time  0.107 ( 2.544)	Data  0.000 ( 2.430)	Loss 3.7627e-01 (1.2990e-01) 
2023-05-27 10:32:56.308791: val Epoch: [22][58/72]	Time  5.109 ( 2.587)	Data  5.001 ( 2.473)	Loss 1.1367e-01 (1.2962e-01) 
2023-05-27 10:32:56.416678: val Epoch: [22][59/72]	Time  0.108 ( 2.546)	Data  0.000 ( 2.432)	Loss 2.5336e-01 (1.3168e-01) 
2023-05-27 10:33:01.205641: val Epoch: [22][60/72]	Time  4.789 ( 2.583)	Data  4.678 ( 2.469)	Loss 8.3622e-02 (1.3089e-01) 
2023-05-27 10:33:01.317504: val Epoch: [22][61/72]	Time  0.112 ( 2.543)	Data  0.000 ( 2.429)	Loss 6.7994e-02 (1.2988e-01) 
2023-05-27 10:33:06.197127: val Epoch: [22][62/72]	Time  4.880 ( 2.580)	Data  4.767 ( 2.466)	Loss 4.3840e-01 (1.3478e-01) 
2023-05-27 10:33:06.308513: val Epoch: [22][63/72]	Time  0.111 ( 2.541)	Data  0.001 ( 2.428)	Loss 1.3888e-01 (1.3484e-01) 
2023-05-27 10:33:11.278265: val Epoch: [22][64/72]	Time  4.970 ( 2.579)	Data  4.859 ( 2.465)	Loss 1.2859e-01 (1.3474e-01) 
2023-05-27 10:33:11.389903: val Epoch: [22][65/72]	Time  0.112 ( 2.541)	Data  0.000 ( 2.428)	Loss 5.0992e-01 (1.4043e-01) 
2023-05-27 10:33:16.277333: val Epoch: [22][66/72]	Time  4.887 ( 2.576)	Data  4.777 ( 2.463)	Loss 7.2088e-02 (1.3941e-01) 
2023-05-27 10:33:16.388127: val Epoch: [22][67/72]	Time  0.111 ( 2.540)	Data  0.001 ( 2.427)	Loss 1.9652e-01 (1.4025e-01) 
2023-05-27 10:33:21.313893: val Epoch: [22][68/72]	Time  4.926 ( 2.575)	Data  4.810 ( 2.461)	Loss 1.5527e-01 (1.4047e-01) 
2023-05-27 10:33:21.429189: val Epoch: [22][69/72]	Time  0.115 ( 2.539)	Data  0.000 ( 2.426)	Loss 5.4140e-02 (1.3923e-01) 
2023-05-27 10:33:26.244542: val Epoch: [22][70/72]	Time  4.815 ( 2.572)	Data  4.706 ( 2.458)	Loss 1.0771e-01 (1.3879e-01) 
2023-05-27 10:33:26.352485: val Epoch: [22][71/72]	Time  0.108 ( 2.537)	Data  0.000 ( 2.424)	Loss 4.5304e-02 (1.3749e-01) 
2023-05-27 10:33:26.644610: Epoch 22 :Val : ['ET : 0.7384291887283325', 'TC : 0.7688616514205933', 'WT : 0.8497987389564514'] 
2023-05-27 10:33:26.645252: Epoch 22 :Val : ['ET : 0.7384291887283325', 'TC : 0.7688616514205933', 'WT : 0.8497987389564514'] 
2023-05-27 10:33:26.648859: Saving the model with DSC 0.7872434258460999 
2023-05-27 10:33:27.361001: Val epoch done in 184.33479170899955 s 
2023-05-27 10:33:27.416107: Batches per epoch:  193 
2023-05-27 10:33:38.870116: train Epoch: [23][  0/193]	Time 11.454 (11.454)	Data 10.687 (10.687)	Loss 7.6130e-02 (7.6130e-02) 
2023-05-27 10:33:39.438332: train Epoch: [23][  1/193]	Time  0.568 ( 6.011)	Data  0.001 ( 5.344)	Loss 1.1182e-01 (9.3976e-02) 
2023-05-27 10:33:48.012139: train Epoch: [23][  2/193]	Time  8.574 ( 6.865)	Data  7.927 ( 6.205)	Loss 3.7385e-02 (7.5112e-02) 
2023-05-27 10:33:48.597138: train Epoch: [23][  3/193]	Time  0.585 ( 5.295)	Data  0.001 ( 4.654)	Loss 6.2817e-02 (7.2038e-02) 
2023-05-27 10:33:57.621978: train Epoch: [23][  4/193]	Time  9.025 ( 6.041)	Data  8.449 ( 5.413)	Loss 8.2099e-02 (7.4050e-02) 
2023-05-27 10:33:58.228091: train Epoch: [23][  5/193]	Time  0.606 ( 5.135)	Data  0.001 ( 4.511)	Loss 8.9558e-02 (7.6635e-02) 
2023-05-27 10:34:07.291910: train Epoch: [23][  6/193]	Time  9.064 ( 5.696)	Data  8.483 ( 5.078)	Loss 1.2160e-01 (8.3058e-02) 
2023-05-27 10:34:07.898591: train Epoch: [23][  7/193]	Time  0.607 ( 5.060)	Data  0.001 ( 4.444)	Loss 8.8335e-02 (8.3718e-02) 
2023-05-27 10:34:16.693655: train Epoch: [23][  8/193]	Time  8.795 ( 5.475)	Data  8.226 ( 4.864)	Loss 6.4997e-02 (8.1638e-02) 
2023-05-27 10:34:17.260250: train Epoch: [23][  9/193]	Time  0.567 ( 4.984)	Data  0.001 ( 4.378)	Loss 1.1184e-01 (8.4658e-02) 
2023-05-27 10:34:26.092041: train Epoch: [23][ 10/193]	Time  8.832 ( 5.334)	Data  8.272 ( 4.732)	Loss 1.1813e-01 (8.7701e-02) 
2023-05-27 10:34:26.910998: train Epoch: [23][ 11/193]	Time  0.819 ( 4.958)	Data  0.254 ( 4.359)	Loss 1.0157e-01 (8.8857e-02) 
2023-05-27 10:34:35.005004: train Epoch: [23][ 12/193]	Time  8.094 ( 5.199)	Data  7.533 ( 4.603)	Loss 5.8492e-02 (8.6521e-02) 
2023-05-27 10:34:36.465391: train Epoch: [23][ 13/193]	Time  1.460 ( 4.932)	Data  0.880 ( 4.337)	Loss 9.6553e-02 (8.7238e-02) 
2023-05-27 10:34:43.559963: train Epoch: [23][ 14/193]	Time  7.095 ( 5.076)	Data  6.532 ( 4.483)	Loss 6.0489e-02 (8.5454e-02) 
2023-05-27 10:34:45.726426: train Epoch: [23][ 15/193]	Time  2.166 ( 4.894)	Data  1.602 ( 4.303)	Loss 6.8714e-02 (8.4408e-02) 
2023-05-27 10:34:53.676032: train Epoch: [23][ 16/193]	Time  7.950 ( 5.074)	Data  7.376 ( 4.484)	Loss 5.0081e-02 (8.2389e-02) 
2023-05-27 10:34:55.596166: train Epoch: [23][ 17/193]	Time  1.920 ( 4.899)	Data  1.361 ( 4.310)	Loss 6.7335e-02 (8.1553e-02) 
2023-05-27 10:35:03.378501: train Epoch: [23][ 18/193]	Time  7.782 ( 5.051)	Data  7.218 ( 4.463)	Loss 5.8653e-02 (8.0347e-02) 
2023-05-27 10:35:05.553778: train Epoch: [23][ 19/193]	Time  2.175 ( 4.907)	Data  1.616 ( 4.321)	Loss 1.1608e-01 (8.2134e-02) 
2023-05-27 10:35:13.434764: train Epoch: [23][ 20/193]	Time  7.881 ( 5.048)	Data  7.303 ( 4.463)	Loss 5.5533e-02 (8.0867e-02) 
2023-05-27 10:35:15.077232: train Epoch: [23][ 21/193]	Time  1.642 ( 4.894)	Data  1.068 ( 4.309)	Loss 1.3256e-01 (8.3217e-02) 
2023-05-27 10:35:22.448373: train Epoch: [23][ 22/193]	Time  7.371 ( 5.001)	Data  6.804 ( 4.417)	Loss 1.1414e-01 (8.4562e-02) 
2023-05-27 10:35:24.126665: train Epoch: [23][ 23/193]	Time  1.678 ( 4.863)	Data  1.114 ( 4.280)	Loss 1.1435e-01 (8.5803e-02) 
2023-05-27 10:35:31.511602: train Epoch: [23][ 24/193]	Time  7.385 ( 4.964)	Data  6.819 ( 4.381)	Loss 1.0195e-01 (8.6449e-02) 
2023-05-27 10:35:33.672246: train Epoch: [23][ 25/193]	Time  2.161 ( 4.856)	Data  1.600 ( 4.274)	Loss 1.5411e-01 (8.9051e-02) 
2023-05-27 10:35:41.347236: train Epoch: [23][ 26/193]	Time  7.675 ( 4.960)	Data  7.103 ( 4.379)	Loss 1.1903e-01 (9.0161e-02) 
2023-05-27 10:35:42.741568: train Epoch: [23][ 27/193]	Time  1.394 ( 4.833)	Data  0.817 ( 4.252)	Loss 1.3055e-01 (9.1604e-02) 
2023-05-27 10:35:50.932738: train Epoch: [23][ 28/193]	Time  8.191 ( 4.949)	Data  7.626 ( 4.368)	Loss 3.2976e-01 (9.9816e-02) 
2023-05-27 10:35:52.343485: train Epoch: [23][ 29/193]	Time  1.411 ( 4.831)	Data  0.850 ( 4.251)	Loss 1.5918e-01 (1.0179e-01) 
2023-05-27 10:36:00.457138: train Epoch: [23][ 30/193]	Time  8.114 ( 4.937)	Data  7.550 ( 4.357)	Loss 7.5422e-02 (1.0094e-01) 
2023-05-27 10:36:01.807938: train Epoch: [23][ 31/193]	Time  1.351 ( 4.825)	Data  0.789 ( 4.246)	Loss 6.4298e-02 (9.9799e-02) 
2023-05-27 10:36:10.169428: train Epoch: [23][ 32/193]	Time  8.361 ( 4.932)	Data  7.797 ( 4.353)	Loss 1.0289e-01 (9.9893e-02) 
2023-05-27 10:36:11.849264: train Epoch: [23][ 33/193]	Time  1.680 ( 4.836)	Data  1.117 ( 4.258)	Loss 6.3652e-02 (9.8827e-02) 
2023-05-27 10:36:20.011827: train Epoch: [23][ 34/193]	Time  8.163 ( 4.931)	Data  7.592 ( 4.353)	Loss 6.7388e-02 (9.7928e-02) 
2023-05-27 10:36:21.475436: train Epoch: [23][ 35/193]	Time  1.464 ( 4.835)	Data  0.897 ( 4.257)	Loss 6.5477e-02 (9.7027e-02) 
2023-05-27 10:36:29.722731: train Epoch: [23][ 36/193]	Time  8.247 ( 4.927)	Data  7.672 ( 4.350)	Loss 8.9655e-02 (9.6828e-02) 
2023-05-27 10:36:31.109211: train Epoch: [23][ 37/193]	Time  1.386 ( 4.834)	Data  0.825 ( 4.257)	Loss 6.6428e-02 (9.6028e-02) 
2023-05-27 10:36:39.019796: train Epoch: [23][ 38/193]	Time  7.911 ( 4.913)	Data  7.333 ( 4.336)	Loss 9.6125e-02 (9.6030e-02) 
2023-05-27 10:36:41.201200: train Epoch: [23][ 39/193]	Time  2.181 ( 4.845)	Data  1.616 ( 4.268)	Loss 9.2263e-02 (9.5936e-02) 
2023-05-27 10:36:49.276037: train Epoch: [23][ 40/193]	Time  8.075 ( 4.923)	Data  7.511 ( 4.347)	Loss 8.7330e-02 (9.5726e-02) 
2023-05-27 10:36:50.960911: train Epoch: [23][ 41/193]	Time  1.685 ( 4.846)	Data  1.124 ( 4.270)	Loss 9.8415e-02 (9.5790e-02) 
2023-05-27 10:36:59.310099: train Epoch: [23][ 42/193]	Time  8.349 ( 4.928)	Data  7.784 ( 4.352)	Loss 1.0009e-01 (9.5890e-02) 
2023-05-27 10:37:00.725493: train Epoch: [23][ 43/193]	Time  1.415 ( 4.848)	Data  0.855 ( 4.273)	Loss 1.4843e-01 (9.7084e-02) 
2023-05-27 10:37:08.739327: train Epoch: [23][ 44/193]	Time  8.014 ( 4.918)	Data  7.450 ( 4.343)	Loss 9.0463e-02 (9.6937e-02) 
2023-05-27 10:37:10.611334: train Epoch: [23][ 45/193]	Time  1.872 ( 4.852)	Data  1.308 ( 4.277)	Loss 1.2879e-01 (9.7629e-02) 
2023-05-27 10:37:18.355437: train Epoch: [23][ 46/193]	Time  7.744 ( 4.914)	Data  7.176 ( 4.339)	Loss 8.8502e-02 (9.7435e-02) 
2023-05-27 10:37:20.427877: train Epoch: [23][ 47/193]	Time  2.072 ( 4.854)	Data  1.512 ( 4.280)	Loss 8.6626e-02 (9.7210e-02) 
2023-05-27 10:37:27.960156: train Epoch: [23][ 48/193]	Time  7.532 ( 4.909)	Data  6.969 ( 4.335)	Loss 5.5898e-02 (9.6367e-02) 
2023-05-27 10:37:29.802118: train Epoch: [23][ 49/193]	Time  1.842 ( 4.848)	Data  1.279 ( 4.274)	Loss 6.9321e-02 (9.5826e-02) 
2023-05-27 10:37:37.542218: train Epoch: [23][ 50/193]	Time  7.740 ( 4.904)	Data  7.176 ( 4.331)	Loss 2.4110e-01 (9.8674e-02) 
2023-05-27 10:37:39.322335: train Epoch: [23][ 51/193]	Time  1.780 ( 4.844)	Data  1.213 ( 4.271)	Loss 1.4468e-01 (9.9559e-02) 
2023-05-27 10:37:47.361028: train Epoch: [23][ 52/193]	Time  8.039 ( 4.905)	Data  7.475 ( 4.331)	Loss 7.9780e-02 (9.9186e-02) 
2023-05-27 10:37:49.070460: train Epoch: [23][ 53/193]	Time  1.709 ( 4.845)	Data  1.147 ( 4.272)	Loss 9.8666e-02 (9.9176e-02) 
2023-05-27 10:37:57.470455: train Epoch: [23][ 54/193]	Time  8.400 ( 4.910)	Data  7.838 ( 4.337)	Loss 6.7099e-02 (9.8593e-02) 
2023-05-27 10:37:58.910467: train Epoch: [23][ 55/193]	Time  1.440 ( 4.848)	Data  0.865 ( 4.275)	Loss 1.7366e-01 (9.9934e-02) 
2023-05-27 10:38:07.500722: train Epoch: [23][ 56/193]	Time  8.590 ( 4.914)	Data  8.019 ( 4.341)	Loss 8.5323e-02 (9.9677e-02) 
2023-05-27 10:38:08.863044: train Epoch: [23][ 57/193]	Time  1.362 ( 4.853)	Data  0.780 ( 4.279)	Loss 8.5701e-02 (9.9436e-02) 
2023-05-27 10:38:17.058736: train Epoch: [23][ 58/193]	Time  8.196 ( 4.909)	Data  7.632 ( 4.336)	Loss 5.4248e-02 (9.8670e-02) 
2023-05-27 10:38:18.769778: train Epoch: [23][ 59/193]	Time  1.711 ( 4.856)	Data  1.131 ( 4.283)	Loss 1.6657e-01 (9.9802e-02) 
2023-05-27 10:38:26.399398: train Epoch: [23][ 60/193]	Time  7.630 ( 4.901)	Data  7.065 ( 4.328)	Loss 4.0989e-02 (9.8838e-02) 
2023-05-27 10:38:28.327586: train Epoch: [23][ 61/193]	Time  1.928 ( 4.853)	Data  1.361 ( 4.280)	Loss 1.1774e-01 (9.9143e-02) 
2023-05-27 10:38:35.920845: train Epoch: [23][ 62/193]	Time  7.593 ( 4.897)	Data  7.029 ( 4.324)	Loss 8.9230e-02 (9.8985e-02) 
2023-05-27 10:38:38.161560: train Epoch: [23][ 63/193]	Time  2.241 ( 4.855)	Data  1.654 ( 4.282)	Loss 8.8546e-02 (9.8822e-02) 
2023-05-27 10:38:45.773751: train Epoch: [23][ 64/193]	Time  7.612 ( 4.898)	Data  7.046 ( 4.325)	Loss 5.3292e-02 (9.8122e-02) 
2023-05-27 10:38:48.038171: train Epoch: [23][ 65/193]	Time  2.264 ( 4.858)	Data  1.702 ( 4.285)	Loss 1.2833e-01 (9.8579e-02) 
2023-05-27 10:38:55.519188: train Epoch: [23][ 66/193]	Time  7.481 ( 4.897)	Data  6.903 ( 4.324)	Loss 6.2115e-02 (9.8035e-02) 
2023-05-27 10:38:57.973306: train Epoch: [23][ 67/193]	Time  2.454 ( 4.861)	Data  1.890 ( 4.288)	Loss 9.4401e-02 (9.7982e-02) 
2023-05-27 10:39:05.554992: train Epoch: [23][ 68/193]	Time  7.582 ( 4.901)	Data  7.017 ( 4.328)	Loss 1.0700e-01 (9.8112e-02) 
2023-05-27 10:39:07.865964: train Epoch: [23][ 69/193]	Time  2.311 ( 4.864)	Data  1.739 ( 4.291)	Loss 6.8416e-02 (9.7688e-02) 
2023-05-27 10:39:15.674388: train Epoch: [23][ 70/193]	Time  7.808 ( 4.905)	Data  7.247 ( 4.333)	Loss 8.8505e-02 (9.7559e-02) 
2023-05-27 10:39:17.907099: train Epoch: [23][ 71/193]	Time  2.233 ( 4.868)	Data  1.666 ( 4.296)	Loss 1.4826e-01 (9.8263e-02) 
2023-05-27 10:39:25.151495: train Epoch: [23][ 72/193]	Time  7.244 ( 4.900)	Data  6.675 ( 4.328)	Loss 4.9045e-02 (9.7589e-02) 
2023-05-27 10:39:27.761436: train Epoch: [23][ 73/193]	Time  2.610 ( 4.870)	Data  2.041 ( 4.297)	Loss 9.9947e-02 (9.7621e-02) 
2023-05-27 10:39:34.918660: train Epoch: [23][ 74/193]	Time  7.157 ( 4.900)	Data  6.592 ( 4.328)	Loss 1.2503e-01 (9.7986e-02) 
2023-05-27 10:39:37.915103: train Epoch: [23][ 75/193]	Time  2.996 ( 4.875)	Data  2.428 ( 4.303)	Loss 1.2727e-01 (9.8371e-02) 
2023-05-27 10:39:44.989539: train Epoch: [23][ 76/193]	Time  7.074 ( 4.904)	Data  6.500 ( 4.331)	Loss 1.1143e-01 (9.8541e-02) 
2023-05-27 10:39:47.554383: train Epoch: [23][ 77/193]	Time  2.565 ( 4.874)	Data  2.004 ( 4.302)	Loss 1.3327e-01 (9.8986e-02) 
2023-05-27 10:39:54.808879: train Epoch: [23][ 78/193]	Time  7.254 ( 4.904)	Data  6.680 ( 4.332)	Loss 1.1255e-01 (9.9158e-02) 
2023-05-27 10:39:57.141947: train Epoch: [23][ 79/193]	Time  2.333 ( 4.872)	Data  1.766 ( 4.300)	Loss 1.3539e-01 (9.9611e-02) 
2023-05-27 10:40:04.589278: train Epoch: [23][ 80/193]	Time  7.447 ( 4.903)	Data  6.874 ( 4.331)	Loss 1.1609e-01 (9.9814e-02) 
2023-05-27 10:40:07.395405: train Epoch: [23][ 81/193]	Time  2.806 ( 4.878)	Data  2.247 ( 4.306)	Loss 9.2908e-02 (9.9730e-02) 
2023-05-27 10:40:13.969824: train Epoch: [23][ 82/193]	Time  6.574 ( 4.898)	Data  6.003 ( 4.326)	Loss 1.0997e-01 (9.9853e-02) 
2023-05-27 10:40:16.935433: train Epoch: [23][ 83/193]	Time  2.966 ( 4.875)	Data  2.406 ( 4.304)	Loss 6.4663e-02 (9.9434e-02) 
2023-05-27 10:40:23.483629: train Epoch: [23][ 84/193]	Time  6.548 ( 4.895)	Data  5.983 ( 4.323)	Loss 7.4303e-02 (9.9139e-02) 
2023-05-27 10:40:26.163895: train Epoch: [23][ 85/193]	Time  2.680 ( 4.869)	Data  2.120 ( 4.298)	Loss 6.8838e-02 (9.8786e-02) 
2023-05-27 10:40:32.308245: train Epoch: [23][ 86/193]	Time  6.144 ( 4.884)	Data  5.556 ( 4.312)	Loss 1.4087e-01 (9.9270e-02) 
2023-05-27 10:40:34.939974: train Epoch: [23][ 87/193]	Time  2.632 ( 4.858)	Data  2.071 ( 4.287)	Loss 1.1433e-01 (9.9441e-02) 
2023-05-27 10:40:40.532902: train Epoch: [23][ 88/193]	Time  5.593 ( 4.866)	Data  5.026 ( 4.295)	Loss 9.7302e-02 (9.9417e-02) 
2023-05-27 10:40:44.402423: train Epoch: [23][ 89/193]	Time  3.870 ( 4.855)	Data  3.310 ( 4.284)	Loss 8.7851e-02 (9.9289e-02) 
2023-05-27 10:40:50.206606: train Epoch: [23][ 90/193]	Time  5.804 ( 4.866)	Data  5.232 ( 4.294)	Loss 7.7181e-02 (9.9046e-02) 
2023-05-27 10:40:54.470759: train Epoch: [23][ 91/193]	Time  4.264 ( 4.859)	Data  3.705 ( 4.288)	Loss 1.0661e-01 (9.9128e-02) 
2023-05-27 10:41:00.610273: train Epoch: [23][ 92/193]	Time  6.140 ( 4.873)	Data  5.528 ( 4.301)	Loss 1.3739e-01 (9.9539e-02) 
2023-05-27 10:41:04.232156: train Epoch: [23][ 93/193]	Time  3.622 ( 4.860)	Data  3.062 ( 4.288)	Loss 1.2983e-01 (9.9862e-02) 
2023-05-27 10:41:10.266564: train Epoch: [23][ 94/193]	Time  6.034 ( 4.872)	Data  5.432 ( 4.300)	Loss 7.7159e-02 (9.9623e-02) 
2023-05-27 10:41:13.587731: train Epoch: [23][ 95/193]	Time  3.321 ( 4.856)	Data  2.761 ( 4.284)	Loss 9.2106e-02 (9.9544e-02) 
2023-05-27 10:41:19.910964: train Epoch: [23][ 96/193]	Time  6.323 ( 4.871)	Data  5.746 ( 4.299)	Loss 1.3392e-01 (9.9899e-02) 
2023-05-27 10:41:23.207386: train Epoch: [23][ 97/193]	Time  3.296 ( 4.855)	Data  2.735 ( 4.283)	Loss 5.2054e-02 (9.9410e-02) 
2023-05-27 10:41:29.475772: train Epoch: [23][ 98/193]	Time  6.268 ( 4.869)	Data  5.701 ( 4.298)	Loss 8.3249e-02 (9.9247e-02) 
2023-05-27 10:41:32.938467: train Epoch: [23][ 99/193]	Time  3.463 ( 4.855)	Data  2.895 ( 4.284)	Loss 8.6665e-02 (9.9121e-02) 
2023-05-27 10:41:38.967968: train Epoch: [23][100/193]	Time  6.030 ( 4.867)	Data  5.457 ( 4.295)	Loss 9.5238e-02 (9.9083e-02) 
2023-05-27 10:41:42.859014: train Epoch: [23][101/193]	Time  3.891 ( 4.857)	Data  3.319 ( 4.286)	Loss 5.3929e-02 (9.8640e-02) 
2023-05-27 10:41:48.871517: train Epoch: [23][102/193]	Time  6.012 ( 4.868)	Data  5.442 ( 4.297)	Loss 1.1492e-01 (9.8798e-02) 
2023-05-27 10:41:52.557613: train Epoch: [23][103/193]	Time  3.686 ( 4.857)	Data  3.126 ( 4.286)	Loss 7.0160e-02 (9.8523e-02) 
2023-05-27 10:41:58.413162: train Epoch: [23][104/193]	Time  5.856 ( 4.867)	Data  5.292 ( 4.295)	Loss 7.5862e-02 (9.8307e-02) 
2023-05-27 10:42:02.441868: train Epoch: [23][105/193]	Time  4.029 ( 4.859)	Data  3.466 ( 4.287)	Loss 3.1551e-01 (1.0036e-01) 
2023-05-27 10:42:08.246951: train Epoch: [23][106/193]	Time  5.805 ( 4.868)	Data  5.229 ( 4.296)	Loss 7.3503e-02 (1.0011e-01) 
2023-05-27 10:42:11.925413: train Epoch: [23][107/193]	Time  3.678 ( 4.857)	Data  3.117 ( 4.285)	Loss 1.0098e-01 (1.0011e-01) 
2023-05-27 10:42:18.113400: train Epoch: [23][108/193]	Time  6.188 ( 4.869)	Data  5.602 ( 4.297)	Loss 1.9618e-01 (1.0099e-01) 
2023-05-27 10:42:22.230682: train Epoch: [23][109/193]	Time  4.117 ( 4.862)	Data  3.554 ( 4.291)	Loss 8.8322e-02 (1.0088e-01) 
2023-05-27 10:42:27.483685: train Epoch: [23][110/193]	Time  5.253 ( 4.865)	Data  4.683 ( 4.294)	Loss 1.1307e-01 (1.0099e-01) 
2023-05-27 10:42:32.080040: train Epoch: [23][111/193]	Time  4.596 ( 4.863)	Data  4.036 ( 4.292)	Loss 9.1159e-02 (1.0090e-01) 
2023-05-27 10:42:37.387828: train Epoch: [23][112/193]	Time  5.308 ( 4.867)	Data  4.741 ( 4.296)	Loss 6.0502e-02 (1.0054e-01) 
2023-05-27 10:42:41.837787: train Epoch: [23][113/193]	Time  4.450 ( 4.863)	Data  3.889 ( 4.292)	Loss 9.4081e-02 (1.0049e-01) 
2023-05-27 10:42:46.987177: train Epoch: [23][114/193]	Time  5.149 ( 4.866)	Data  4.582 ( 4.295)	Loss 7.9636e-02 (1.0031e-01) 
2023-05-27 10:42:51.225227: train Epoch: [23][115/193]	Time  4.238 ( 4.860)	Data  3.664 ( 4.289)	Loss 7.1115e-02 (1.0005e-01) 
2023-05-27 10:42:56.689001: train Epoch: [23][116/193]	Time  5.464 ( 4.866)	Data  4.884 ( 4.294)	Loss 9.8735e-02 (1.0004e-01) 
2023-05-27 10:43:01.234005: train Epoch: [23][117/193]	Time  4.545 ( 4.863)	Data  3.970 ( 4.292)	Loss 1.0333e-01 (1.0007e-01) 
2023-05-27 10:43:06.274984: train Epoch: [23][118/193]	Time  5.041 ( 4.864)	Data  4.477 ( 4.293)	Loss 6.9471e-02 (9.9814e-02) 
2023-05-27 10:43:11.097505: train Epoch: [23][119/193]	Time  4.823 ( 4.864)	Data  4.263 ( 4.293)	Loss 1.0342e-01 (9.9844e-02) 
2023-05-27 10:43:16.517378: train Epoch: [23][120/193]	Time  5.420 ( 4.869)	Data  4.857 ( 4.298)	Loss 1.2173e-01 (1.0002e-01) 
2023-05-27 10:43:21.276318: train Epoch: [23][121/193]	Time  4.759 ( 4.868)	Data  4.200 ( 4.297)	Loss 7.0583e-02 (9.9783e-02) 
2023-05-27 10:43:26.535539: train Epoch: [23][122/193]	Time  5.259 ( 4.871)	Data  4.692 ( 4.300)	Loss 7.1700e-02 (9.9555e-02) 
2023-05-27 10:43:31.460712: train Epoch: [23][123/193]	Time  4.925 ( 4.871)	Data  4.361 ( 4.301)	Loss 8.8609e-02 (9.9467e-02) 
2023-05-27 10:43:36.029226: train Epoch: [23][124/193]	Time  4.569 ( 4.869)	Data  3.982 ( 4.298)	Loss 8.0025e-02 (9.9311e-02) 
2023-05-27 10:43:40.937284: train Epoch: [23][125/193]	Time  4.908 ( 4.869)	Data  4.339 ( 4.298)	Loss 7.7692e-02 (9.9140e-02) 
2023-05-27 10:43:45.292334: train Epoch: [23][126/193]	Time  4.355 ( 4.865)	Data  3.791 ( 4.294)	Loss 1.2049e-01 (9.9308e-02) 
2023-05-27 10:43:50.763815: train Epoch: [23][127/193]	Time  5.471 ( 4.870)	Data  4.910 ( 4.299)	Loss 1.6478e-01 (9.9819e-02) 
2023-05-27 10:43:55.658276: train Epoch: [23][128/193]	Time  4.894 ( 4.870)	Data  4.331 ( 4.299)	Loss 6.8941e-02 (9.9580e-02) 
2023-05-27 10:44:00.446593: train Epoch: [23][129/193]	Time  4.788 ( 4.869)	Data  4.226 ( 4.299)	Loss 1.1351e-01 (9.9687e-02) 
2023-05-27 10:44:05.696459: train Epoch: [23][130/193]	Time  5.250 ( 4.872)	Data  4.684 ( 4.302)	Loss 1.5184e-01 (1.0009e-01) 
2023-05-27 10:44:10.403052: train Epoch: [23][131/193]	Time  4.707 ( 4.871)	Data  4.145 ( 4.301)	Loss 1.1604e-01 (1.0021e-01) 
2023-05-27 10:44:15.728614: train Epoch: [23][132/193]	Time  5.326 ( 4.875)	Data  4.763 ( 4.304)	Loss 1.1565e-01 (1.0032e-01) 
2023-05-27 10:44:20.532408: train Epoch: [23][133/193]	Time  4.804 ( 4.874)	Data  4.244 ( 4.304)	Loss 6.8199e-02 (1.0008e-01) 
2023-05-27 10:44:25.376878: train Epoch: [23][134/193]	Time  4.844 ( 4.874)	Data  4.275 ( 4.303)	Loss 1.2842e-01 (1.0029e-01) 
2023-05-27 10:44:30.202853: train Epoch: [23][135/193]	Time  4.826 ( 4.873)	Data  4.265 ( 4.303)	Loss 5.0067e-02 (9.9923e-02) 
2023-05-27 10:44:35.183006: train Epoch: [23][136/193]	Time  4.980 ( 4.874)	Data  4.413 ( 4.304)	Loss 6.5545e-02 (9.9672e-02) 
2023-05-27 10:44:40.137127: train Epoch: [23][137/193]	Time  4.954 ( 4.875)	Data  4.394 ( 4.305)	Loss 9.7055e-02 (9.9653e-02) 
2023-05-27 10:44:45.766944: train Epoch: [23][138/193]	Time  5.630 ( 4.880)	Data  5.067 ( 4.310)	Loss 1.5446e-01 (1.0005e-01) 
2023-05-27 10:44:50.344175: train Epoch: [23][139/193]	Time  4.577 ( 4.878)	Data  4.014 ( 4.308)	Loss 8.2127e-02 (9.9919e-02) 
2023-05-27 10:44:55.429747: train Epoch: [23][140/193]	Time  5.086 ( 4.880)	Data  4.522 ( 4.309)	Loss 6.5868e-02 (9.9678e-02) 
2023-05-27 10:45:00.100234: train Epoch: [23][141/193]	Time  4.670 ( 4.878)	Data  4.109 ( 4.308)	Loss 1.0294e-01 (9.9701e-02) 
2023-05-27 10:45:05.368644: train Epoch: [23][142/193]	Time  5.268 ( 4.881)	Data  4.693 ( 4.311)	Loss 9.3165e-02 (9.9655e-02) 
2023-05-27 10:45:09.794678: train Epoch: [23][143/193]	Time  4.426 ( 4.878)	Data  3.866 ( 4.308)	Loss 1.8136e-01 (1.0022e-01) 
2023-05-27 10:45:15.717728: train Epoch: [23][144/193]	Time  5.923 ( 4.885)	Data  5.347 ( 4.315)	Loss 7.9267e-02 (1.0008e-01) 
2023-05-27 10:45:19.793278: train Epoch: [23][145/193]	Time  4.076 ( 4.879)	Data  3.513 ( 4.309)	Loss 1.3593e-01 (1.0032e-01) 
2023-05-27 10:45:25.640313: train Epoch: [23][146/193]	Time  5.847 ( 4.886)	Data  5.285 ( 4.316)	Loss 5.6816e-02 (1.0003e-01) 
2023-05-27 10:45:29.744486: train Epoch: [23][147/193]	Time  4.104 ( 4.881)	Data  3.543 ( 4.311)	Loss 1.6629e-01 (1.0048e-01) 
2023-05-27 10:45:35.898429: train Epoch: [23][148/193]	Time  6.154 ( 4.889)	Data  5.582 ( 4.319)	Loss 6.6686e-02 (1.0025e-01) 
2023-05-27 10:45:39.629513: train Epoch: [23][149/193]	Time  3.731 ( 4.881)	Data  3.165 ( 4.312)	Loss 6.3874e-02 (1.0001e-01) 
2023-05-27 10:45:46.212216: train Epoch: [23][150/193]	Time  6.583 ( 4.893)	Data  6.012 ( 4.323)	Loss 1.0542e-01 (1.0004e-01) 
2023-05-27 10:45:49.426159: train Epoch: [23][151/193]	Time  3.214 ( 4.882)	Data  2.655 ( 4.312)	Loss 6.4337e-02 (9.9807e-02) 
2023-05-27 10:45:56.459114: train Epoch: [23][152/193]	Time  7.033 ( 4.896)	Data  6.465 ( 4.326)	Loss 1.3228e-01 (1.0002e-01) 
2023-05-27 10:45:58.958961: train Epoch: [23][153/193]	Time  2.500 ( 4.880)	Data  1.934 ( 4.310)	Loss 6.2284e-02 (9.9774e-02) 
2023-05-27 10:46:06.047197: train Epoch: [23][154/193]	Time  7.088 ( 4.894)	Data  6.510 ( 4.325)	Loss 1.2317e-01 (9.9925e-02) 
2023-05-27 10:46:09.125177: train Epoch: [23][155/193]	Time  3.078 ( 4.883)	Data  2.511 ( 4.313)	Loss 8.9794e-02 (9.9860e-02) 
2023-05-27 10:46:15.556560: train Epoch: [23][156/193]	Time  6.431 ( 4.893)	Data  5.869 ( 4.323)	Loss 5.1473e-02 (9.9552e-02) 
2023-05-27 10:46:18.958717: train Epoch: [23][157/193]	Time  3.402 ( 4.883)	Data  2.839 ( 4.313)	Loss 3.0416e-01 (1.0085e-01) 
2023-05-27 10:46:25.792013: train Epoch: [23][158/193]	Time  6.833 ( 4.895)	Data  6.269 ( 4.326)	Loss 8.6852e-02 (1.0076e-01) 
2023-05-27 10:46:28.692988: train Epoch: [23][159/193]	Time  2.901 ( 4.883)	Data  2.340 ( 4.313)	Loss 4.9830e-02 (1.0044e-01) 
2023-05-27 10:46:35.571750: train Epoch: [23][160/193]	Time  6.879 ( 4.895)	Data  6.301 ( 4.326)	Loss 1.0929e-01 (1.0050e-01) 
2023-05-27 10:46:38.603379: train Epoch: [23][161/193]	Time  3.032 ( 4.884)	Data  2.471 ( 4.314)	Loss 8.1581e-02 (1.0038e-01) 
2023-05-27 10:46:45.246576: train Epoch: [23][162/193]	Time  6.643 ( 4.895)	Data  6.080 ( 4.325)	Loss 1.1860e-01 (1.0049e-01) 
2023-05-27 10:46:48.656188: train Epoch: [23][163/193]	Time  3.410 ( 4.886)	Data  2.839 ( 4.316)	Loss 1.2751e-01 (1.0066e-01) 
2023-05-27 10:46:55.342654: train Epoch: [23][164/193]	Time  6.686 ( 4.897)	Data  6.122 ( 4.327)	Loss 1.1556e-01 (1.0075e-01) 
2023-05-27 10:46:58.357028: train Epoch: [23][165/193]	Time  3.014 ( 4.885)	Data  2.448 ( 4.316)	Loss 6.5915e-02 (1.0054e-01) 
2023-05-27 10:47:05.090842: train Epoch: [23][166/193]	Time  6.734 ( 4.896)	Data  6.161 ( 4.327)	Loss 9.0829e-02 (1.0048e-01) 
2023-05-27 10:47:08.706923: train Epoch: [23][167/193]	Time  3.616 ( 4.889)	Data  3.050 ( 4.319)	Loss 8.4575e-02 (1.0038e-01) 
2023-05-27 10:47:14.718102: train Epoch: [23][168/193]	Time  6.011 ( 4.895)	Data  5.441 ( 4.326)	Loss 5.1851e-02 (1.0010e-01) 
2023-05-27 10:47:18.382094: train Epoch: [23][169/193]	Time  3.664 ( 4.888)	Data  3.098 ( 4.319)	Loss 8.0808e-02 (9.9983e-02) 
2023-05-27 10:47:24.425849: train Epoch: [23][170/193]	Time  6.044 ( 4.895)	Data  5.476 ( 4.325)	Loss 9.2888e-02 (9.9941e-02) 
2023-05-27 10:47:28.329996: train Epoch: [23][171/193]	Time  3.904 ( 4.889)	Data  3.341 ( 4.320)	Loss 7.1766e-02 (9.9777e-02) 
2023-05-27 10:47:34.253752: train Epoch: [23][172/193]	Time  5.924 ( 4.895)	Data  5.330 ( 4.325)	Loss 7.7534e-02 (9.9649e-02) 
2023-05-27 10:47:38.121312: train Epoch: [23][173/193]	Time  3.868 ( 4.889)	Data  3.281 ( 4.319)	Loss 7.1007e-02 (9.9484e-02) 
2023-05-27 10:47:43.824441: train Epoch: [23][174/193]	Time  5.703 ( 4.894)	Data  5.139 ( 4.324)	Loss 6.8518e-02 (9.9307e-02) 
2023-05-27 10:47:47.844116: train Epoch: [23][175/193]	Time  4.020 ( 4.889)	Data  3.401 ( 4.319)	Loss 7.5819e-02 (9.9174e-02) 
2023-05-27 10:47:53.476409: train Epoch: [23][176/193]	Time  5.632 ( 4.893)	Data  5.070 ( 4.323)	Loss 5.4724e-02 (9.8923e-02) 
2023-05-27 10:47:57.287267: train Epoch: [23][177/193]	Time  3.811 ( 4.887)	Data  3.246 ( 4.317)	Loss 5.0283e-02 (9.8649e-02) 
2023-05-27 10:48:03.114877: train Epoch: [23][178/193]	Time  5.828 ( 4.892)	Data  5.246 ( 4.322)	Loss 4.1114e-02 (9.8328e-02) 
2023-05-27 10:48:07.614221: train Epoch: [23][179/193]	Time  4.499 ( 4.890)	Data  3.925 ( 4.320)	Loss 7.9598e-02 (9.8224e-02) 
2023-05-27 10:48:12.947974: train Epoch: [23][180/193]	Time  5.334 ( 4.892)	Data  4.760 ( 4.322)	Loss 1.4074e-01 (9.8459e-02) 
2023-05-27 10:48:17.563233: train Epoch: [23][181/193]	Time  4.615 ( 4.891)	Data  4.026 ( 4.321)	Loss 9.6596e-02 (9.8448e-02) 
2023-05-27 10:48:23.023225: train Epoch: [23][182/193]	Time  5.460 ( 4.894)	Data  4.888 ( 4.324)	Loss 6.0852e-02 (9.8243e-02) 
2023-05-27 10:48:27.624807: train Epoch: [23][183/193]	Time  4.602 ( 4.892)	Data  4.026 ( 4.322)	Loss 1.9967e-01 (9.8794e-02) 
2023-05-27 10:48:33.021353: train Epoch: [23][184/193]	Time  5.397 ( 4.895)	Data  4.821 ( 4.325)	Loss 9.4038e-02 (9.8769e-02) 
2023-05-27 10:48:37.596557: train Epoch: [23][185/193]	Time  4.575 ( 4.893)	Data  3.999 ( 4.323)	Loss 1.1905e-01 (9.8878e-02) 
2023-05-27 10:48:42.698738: train Epoch: [23][186/193]	Time  5.102 ( 4.895)	Data  4.536 ( 4.324)	Loss 8.8781e-02 (9.8824e-02) 
2023-05-27 10:48:47.108017: train Epoch: [23][187/193]	Time  4.409 ( 4.892)	Data  3.791 ( 4.322)	Loss 8.1305e-02 (9.8730e-02) 
2023-05-27 10:48:52.801628: train Epoch: [23][188/193]	Time  5.694 ( 4.896)	Data  5.121 ( 4.326)	Loss 9.9902e-02 (9.8737e-02) 
2023-05-27 10:48:56.676473: train Epoch: [23][189/193]	Time  3.875 ( 4.891)	Data  3.293 ( 4.320)	Loss 4.8016e-02 (9.8470e-02) 
2023-05-27 10:49:02.621836: train Epoch: [23][190/193]	Time  5.945 ( 4.896)	Data  5.346 ( 4.326)	Loss 1.0127e-01 (9.8484e-02) 
2023-05-27 10:49:06.626640: train Epoch: [23][191/193]	Time  4.005 ( 4.892)	Data  3.424 ( 4.321)	Loss 7.5483e-02 (9.8365e-02) 
2023-05-27 10:49:11.765816: train Epoch: [23][192/193]	Time  5.139 ( 4.893)	Data  4.571 ( 4.322)	Loss 9.6030e-02 (9.8352e-02) 
2023-05-27 10:49:11.900115: Train Epoch done in 944.4840729470016 s 
2023-05-27 10:49:18.563406: val Epoch: [23][ 0/72]	Time  5.913 ( 5.913)	Data  5.753 ( 5.753)	Loss 5.4695e-02 (5.4695e-02) 
2023-05-27 10:49:18.669771: val Epoch: [23][ 1/72]	Time  0.107 ( 3.010)	Data  0.001 ( 2.877)	Loss 8.7479e-02 (7.1087e-02) 
2023-05-27 10:49:23.270398: val Epoch: [23][ 2/72]	Time  4.601 ( 3.540)	Data  4.480 ( 3.411)	Loss 6.7272e-02 (6.9815e-02) 
2023-05-27 10:49:23.672081: val Epoch: [23][ 3/72]	Time  0.402 ( 2.756)	Data  0.296 ( 2.633)	Loss 1.0662e-01 (7.9017e-02) 
2023-05-27 10:49:28.391416: val Epoch: [23][ 4/72]	Time  4.719 ( 3.148)	Data  4.614 ( 3.029)	Loss 9.3631e-02 (8.1940e-02) 
2023-05-27 10:49:28.552935: val Epoch: [23][ 5/72]	Time  0.162 ( 2.651)	Data  0.056 ( 2.533)	Loss 4.9945e-02 (7.6608e-02) 
2023-05-27 10:49:33.616832: val Epoch: [23][ 6/72]	Time  5.064 ( 2.995)	Data  4.958 ( 2.880)	Loss 8.1482e-02 (7.7304e-02) 
2023-05-27 10:49:33.722266: val Epoch: [23][ 7/72]	Time  0.105 ( 2.634)	Data  0.000 ( 2.520)	Loss 5.9126e-01 (1.4155e-01) 
2023-05-27 10:49:38.502496: val Epoch: [23][ 8/72]	Time  4.780 ( 2.873)	Data  4.674 ( 2.759)	Loss 5.6582e-02 (1.3211e-01) 
2023-05-27 10:49:38.607473: val Epoch: [23][ 9/72]	Time  0.105 ( 2.596)	Data  0.000 ( 2.483)	Loss 1.2381e-01 (1.3128e-01) 
2023-05-27 10:49:43.470311: val Epoch: [23][10/72]	Time  4.863 ( 2.802)	Data  4.757 ( 2.690)	Loss 6.0170e-02 (1.2481e-01) 
2023-05-27 10:49:43.575163: val Epoch: [23][11/72]	Time  0.105 ( 2.577)	Data  0.000 ( 2.466)	Loss 8.3773e-02 (1.2139e-01) 
2023-05-27 10:49:48.310763: val Epoch: [23][12/72]	Time  4.736 ( 2.743)	Data  4.629 ( 2.632)	Loss 6.1322e-02 (1.1677e-01) 
2023-05-27 10:49:48.415795: val Epoch: [23][13/72]	Time  0.105 ( 2.555)	Data  0.000 ( 2.444)	Loss 1.3020e-01 (1.1773e-01) 
2023-05-27 10:49:53.587090: val Epoch: [23][14/72]	Time  5.171 ( 2.729)	Data  5.061 ( 2.619)	Loss 4.7199e-01 (1.4135e-01) 
2023-05-27 10:49:53.693582: val Epoch: [23][15/72]	Time  0.106 ( 2.565)	Data  0.001 ( 2.455)	Loss 6.0345e-02 (1.3629e-01) 
2023-05-27 10:49:58.611285: val Epoch: [23][16/72]	Time  4.918 ( 2.704)	Data  4.812 ( 2.594)	Loss 6.7207e-02 (1.3222e-01) 
2023-05-27 10:49:58.716042: val Epoch: [23][17/72]	Time  0.105 ( 2.559)	Data  0.001 ( 2.450)	Loss 1.5241e-01 (1.3334e-01) 
2023-05-27 10:50:03.493501: val Epoch: [23][18/72]	Time  4.777 ( 2.676)	Data  4.671 ( 2.567)	Loss 8.3119e-02 (1.3070e-01) 
2023-05-27 10:50:03.599445: val Epoch: [23][19/72]	Time  0.106 ( 2.547)	Data  0.000 ( 2.438)	Loss 3.9594e-02 (1.2615e-01) 
2023-05-27 10:50:08.545600: val Epoch: [23][20/72]	Time  4.946 ( 2.662)	Data  4.840 ( 2.553)	Loss 5.4419e-02 (1.2273e-01) 
2023-05-27 10:50:08.651574: val Epoch: [23][21/72]	Time  0.106 ( 2.546)	Data  0.000 ( 2.437)	Loss 2.9254e-01 (1.3045e-01) 
2023-05-27 10:50:13.219717: val Epoch: [23][22/72]	Time  4.568 ( 2.633)	Data  4.462 ( 2.525)	Loss 5.9462e-02 (1.2736e-01) 
2023-05-27 10:50:13.325543: val Epoch: [23][23/72]	Time  0.106 ( 2.528)	Data  0.000 ( 2.420)	Loss 8.8739e-02 (1.2575e-01) 
2023-05-27 10:50:18.011495: val Epoch: [23][24/72]	Time  4.686 ( 2.614)	Data  4.580 ( 2.506)	Loss 8.4197e-02 (1.2409e-01) 
2023-05-27 10:50:18.117163: val Epoch: [23][25/72]	Time  0.106 ( 2.518)	Data  0.001 ( 2.410)	Loss 1.5388e-01 (1.2524e-01) 
2023-05-27 10:50:22.500444: val Epoch: [23][26/72]	Time  4.383 ( 2.587)	Data  4.278 ( 2.479)	Loss 9.0825e-02 (1.2396e-01) 
2023-05-27 10:50:23.079034: val Epoch: [23][27/72]	Time  0.579 ( 2.515)	Data  0.473 ( 2.407)	Loss 1.0671e-01 (1.2335e-01) 
2023-05-27 10:50:27.457264: val Epoch: [23][28/72]	Time  4.378 ( 2.580)	Data  4.272 ( 2.472)	Loss 6.5509e-02 (1.2135e-01) 
2023-05-27 10:50:28.077682: val Epoch: [23][29/72]	Time  0.620 ( 2.514)	Data  0.515 ( 2.406)	Loss 3.3497e-01 (1.2847e-01) 
2023-05-27 10:50:32.402056: val Epoch: [23][30/72]	Time  4.324 ( 2.573)	Data  4.219 ( 2.465)	Loss 4.9458e-02 (1.2592e-01) 
2023-05-27 10:50:33.124597: val Epoch: [23][31/72]	Time  0.723 ( 2.515)	Data  0.617 ( 2.407)	Loss 7.3356e-02 (1.2428e-01) 
2023-05-27 10:50:37.528217: val Epoch: [23][32/72]	Time  4.404 ( 2.572)	Data  4.294 ( 2.464)	Loss 1.0543e-01 (1.2371e-01) 
2023-05-27 10:50:38.083824: val Epoch: [23][33/72]	Time  0.556 ( 2.513)	Data  0.449 ( 2.405)	Loss 1.5166e-01 (1.2453e-01) 
2023-05-27 10:50:42.572616: val Epoch: [23][34/72]	Time  4.489 ( 2.569)	Data  4.383 ( 2.461)	Loss 6.9105e-02 (1.2295e-01) 
2023-05-27 10:50:43.026117: val Epoch: [23][35/72]	Time  0.453 ( 2.510)	Data  0.348 ( 2.403)	Loss 1.6338e-01 (1.2407e-01) 
2023-05-27 10:50:47.641979: val Epoch: [23][36/72]	Time  4.616 ( 2.567)	Data  4.510 ( 2.460)	Loss 7.3775e-02 (1.2271e-01) 
2023-05-27 10:50:47.747012: val Epoch: [23][37/72]	Time  0.105 ( 2.503)	Data  0.000 ( 2.395)	Loss 9.2071e-02 (1.2191e-01) 
2023-05-27 10:50:52.459364: val Epoch: [23][38/72]	Time  4.712 ( 2.559)	Data  4.607 ( 2.452)	Loss 4.3969e-01 (1.3005e-01) 
2023-05-27 10:50:52.587904: val Epoch: [23][39/72]	Time  0.129 ( 2.498)	Data  0.023 ( 2.391)	Loss 3.7636e-02 (1.2774e-01) 
2023-05-27 10:50:57.288254: val Epoch: [23][40/72]	Time  4.700 ( 2.552)	Data  4.595 ( 2.445)	Loss 2.0847e-01 (1.2971e-01) 
2023-05-27 10:50:57.554273: val Epoch: [23][41/72]	Time  0.266 ( 2.498)	Data  0.160 ( 2.390)	Loss 4.4765e-02 (1.2769e-01) 
2023-05-27 10:51:01.755403: val Epoch: [23][42/72]	Time  4.201 ( 2.537)	Data  4.096 ( 2.430)	Loss 5.1440e-02 (1.2592e-01) 
2023-05-27 10:51:02.612223: val Epoch: [23][43/72]	Time  0.857 ( 2.499)	Data  0.751 ( 2.392)	Loss 3.3414e-01 (1.3065e-01) 
2023-05-27 10:51:06.378867: val Epoch: [23][44/72]	Time  3.767 ( 2.527)	Data  3.661 ( 2.420)	Loss 6.5024e-02 (1.2919e-01) 
2023-05-27 10:51:07.444172: val Epoch: [23][45/72]	Time  1.065 ( 2.496)	Data  0.959 ( 2.388)	Loss 1.4113e-01 (1.2945e-01) 
2023-05-27 10:51:11.318851: val Epoch: [23][46/72]	Time  3.875 ( 2.525)	Data  3.768 ( 2.418)	Loss 1.0813e-01 (1.2900e-01) 
2023-05-27 10:51:12.342523: val Epoch: [23][47/72]	Time  1.024 ( 2.494)	Data  0.917 ( 2.386)	Loss 5.9815e-02 (1.2755e-01) 
2023-05-27 10:51:16.155721: val Epoch: [23][48/72]	Time  3.813 ( 2.521)	Data  3.708 ( 2.413)	Loss 4.1141e-02 (1.2579e-01) 
2023-05-27 10:51:17.279422: val Epoch: [23][49/72]	Time  1.124 ( 2.493)	Data  1.018 ( 2.385)	Loss 1.8555e-01 (1.2699e-01) 
2023-05-27 10:51:20.778716: val Epoch: [23][50/72]	Time  3.499 ( 2.512)	Data  3.394 ( 2.405)	Loss 9.2369e-02 (1.2631e-01) 
2023-05-27 10:51:22.538291: val Epoch: [23][51/72]	Time  1.760 ( 2.498)	Data  1.651 ( 2.391)	Loss 2.3615e-01 (1.2842e-01) 
2023-05-27 10:51:25.571206: val Epoch: [23][52/72]	Time  3.033 ( 2.508)	Data  2.922 ( 2.401)	Loss 7.4033e-02 (1.2739e-01) 
2023-05-27 10:51:27.512517: val Epoch: [23][53/72]	Time  1.941 ( 2.497)	Data  1.822 ( 2.390)	Loss 8.8372e-02 (1.2667e-01) 
2023-05-27 10:51:30.657907: val Epoch: [23][54/72]	Time  3.145 ( 2.509)	Data  3.037 ( 2.402)	Loss 2.9283e-01 (1.2969e-01) 
2023-05-27 10:51:32.477010: val Epoch: [23][55/72]	Time  1.819 ( 2.497)	Data  1.711 ( 2.389)	Loss 1.1511e-01 (1.2943e-01) 
2023-05-27 10:51:35.316058: val Epoch: [23][56/72]	Time  2.839 ( 2.503)	Data  2.731 ( 2.395)	Loss 1.3279e-01 (1.2949e-01) 
2023-05-27 10:51:37.389202: val Epoch: [23][57/72]	Time  2.073 ( 2.496)	Data  1.965 ( 2.388)	Loss 5.9554e-01 (1.3753e-01) 
2023-05-27 10:51:40.127209: val Epoch: [23][58/72]	Time  2.738 ( 2.500)	Data  2.630 ( 2.392)	Loss 4.9137e-02 (1.3603e-01) 
2023-05-27 10:51:42.050475: val Epoch: [23][59/72]	Time  1.923 ( 2.490)	Data  1.814 ( 2.382)	Loss 6.0836e-02 (1.3477e-01) 
2023-05-27 10:51:44.759608: val Epoch: [23][60/72]	Time  2.709 ( 2.494)	Data  2.569 ( 2.386)	Loss 5.6054e-02 (1.3348e-01) 
2023-05-27 10:51:46.940089: val Epoch: [23][61/72]	Time  2.180 ( 2.489)	Data  2.072 ( 2.380)	Loss 1.3835e-01 (1.3356e-01) 
2023-05-27 10:51:49.487375: val Epoch: [23][62/72]	Time  2.547 ( 2.489)	Data  2.440 ( 2.381)	Loss 4.1283e-02 (1.3210e-01) 
2023-05-27 10:51:51.844762: val Epoch: [23][63/72]	Time  2.357 ( 2.487)	Data  2.250 ( 2.379)	Loss 6.8369e-02 (1.3110e-01) 
2023-05-27 10:51:54.620360: val Epoch: [23][64/72]	Time  2.776 ( 2.492)	Data  2.667 ( 2.384)	Loss 1.5965e-01 (1.3154e-01) 
2023-05-27 10:51:56.448818: val Epoch: [23][65/72]	Time  1.828 ( 2.482)	Data  1.721 ( 2.374)	Loss 2.1564e-01 (1.3282e-01) 
2023-05-27 10:51:59.310210: val Epoch: [23][66/72]	Time  2.861 ( 2.487)	Data  2.753 ( 2.379)	Loss 4.9575e-02 (1.3157e-01) 
2023-05-27 10:52:01.502445: val Epoch: [23][67/72]	Time  2.192 ( 2.483)	Data  2.084 ( 2.375)	Loss 7.2320e-02 (1.3070e-01) 
2023-05-27 10:52:04.374477: val Epoch: [23][68/72]	Time  2.872 ( 2.489)	Data  2.765 ( 2.381)	Loss 3.8031e-01 (1.3432e-01) 
2023-05-27 10:52:06.300013: val Epoch: [23][69/72]	Time  1.926 ( 2.481)	Data  1.818 ( 2.373)	Loss 4.0660e-01 (1.3821e-01) 
2023-05-27 10:52:09.473700: val Epoch: [23][70/72]	Time  3.174 ( 2.490)	Data  3.054 ( 2.382)	Loss 1.7635e-01 (1.3875e-01) 
2023-05-27 10:52:10.844478: val Epoch: [23][71/72]	Time  1.371 ( 2.475)	Data  1.263 ( 2.367)	Loss 1.6225e-01 (1.3907e-01) 
2023-05-27 10:52:11.159303: Epoch 23 :Val : ['ET : 0.7016969919204712', 'TC : 0.7749233245849609', 'WT : 0.8483965396881104'] 
2023-05-27 10:52:11.162063: Epoch 23 :Val : ['ET : 0.7016969919204712', 'TC : 0.7749233245849609', 'WT : 0.8483965396881104'] 
2023-05-27 10:52:11.164092: Val epoch done in 179.26397929602535 s 
2023-05-27 10:52:11.170035: Batches per epoch:  193 
2023-05-27 10:52:23.159699: train Epoch: [24][  0/193]	Time 11.989 (11.989)	Data 11.173 (11.173)	Loss 9.1469e-02 (9.1469e-02) 
2023-05-27 10:52:23.733918: train Epoch: [24][  1/193]	Time  0.574 ( 6.282)	Data  0.001 ( 5.587)	Loss 7.7617e-02 (8.4543e-02) 
2023-05-27 10:52:32.577008: train Epoch: [24][  2/193]	Time  8.843 ( 7.136)	Data  8.273 ( 6.482)	Loss 3.3798e-01 (1.6902e-01) 
2023-05-27 10:52:33.146927: train Epoch: [24][  3/193]	Time  0.570 ( 5.494)	Data  0.001 ( 4.862)	Loss 6.1589e-02 (1.4216e-01) 
2023-05-27 10:52:42.634196: train Epoch: [24][  4/193]	Time  9.487 ( 6.293)	Data  8.923 ( 5.674)	Loss 9.1003e-02 (1.3193e-01) 
2023-05-27 10:52:43.198286: train Epoch: [24][  5/193]	Time  0.564 ( 5.338)	Data  0.001 ( 4.729)	Loss 5.7633e-02 (1.1955e-01) 
2023-05-27 10:52:52.296153: train Epoch: [24][  6/193]	Time  9.098 ( 5.875)	Data  8.527 ( 5.271)	Loss 9.3921e-02 (1.1589e-01) 
2023-05-27 10:52:52.859357: train Epoch: [24][  7/193]	Time  0.563 ( 5.211)	Data  0.001 ( 4.612)	Loss 1.6836e-01 (1.2245e-01) 
2023-05-27 10:53:02.360833: train Epoch: [24][  8/193]	Time  9.501 ( 5.688)	Data  8.929 ( 5.092)	Loss 5.6744e-02 (1.1515e-01) 
2023-05-27 10:53:02.926012: train Epoch: [24][  9/193]	Time  0.565 ( 5.176)	Data  0.001 ( 4.583)	Loss 7.8666e-02 (1.1150e-01) 
2023-05-27 10:53:12.361647: train Epoch: [24][ 10/193]	Time  9.436 ( 5.563)	Data  8.863 ( 4.972)	Loss 5.5906e-02 (1.0644e-01) 
2023-05-27 10:53:12.977189: train Epoch: [24][ 11/193]	Time  0.616 ( 5.151)	Data  0.044 ( 4.561)	Loss 9.7273e-02 (1.0568e-01) 
2023-05-27 10:53:22.837776: train Epoch: [24][ 12/193]	Time  9.861 ( 5.513)	Data  9.295 ( 4.925)	Loss 5.0733e-02 (1.0145e-01) 
2023-05-27 10:53:23.402821: train Epoch: [24][ 13/193]	Time  0.565 ( 5.159)	Data  0.001 ( 4.574)	Loss 6.8499e-02 (9.9100e-02) 
2023-05-27 10:53:32.595509: train Epoch: [24][ 14/193]	Time  9.193 ( 5.428)	Data  8.623 ( 4.844)	Loss 9.3840e-02 (9.8749e-02) 
2023-05-27 10:53:33.173277: train Epoch: [24][ 15/193]	Time  0.578 ( 5.125)	Data  0.001 ( 4.541)	Loss 1.0059e-01 (9.8864e-02) 
2023-05-27 10:53:41.090416: train Epoch: [24][ 16/193]	Time  7.917 ( 5.289)	Data  7.343 ( 4.706)	Loss 7.4091e-02 (9.7407e-02) 
2023-05-27 10:53:41.659787: train Epoch: [24][ 17/193]	Time  0.569 ( 5.027)	Data  0.001 ( 4.444)	Loss 1.1604e-01 (9.8442e-02) 
2023-05-27 10:53:51.020935: train Epoch: [24][ 18/193]	Time  9.361 ( 5.255)	Data  8.778 ( 4.672)	Loss 9.6919e-02 (9.8362e-02) 
2023-05-27 10:53:51.599822: train Epoch: [24][ 19/193]	Time  0.579 ( 5.021)	Data  0.001 ( 4.439)	Loss 7.8118e-02 (9.7350e-02) 
2023-05-27 10:54:00.857608: train Epoch: [24][ 20/193]	Time  9.258 ( 5.223)	Data  8.692 ( 4.641)	Loss 6.6533e-02 (9.5882e-02) 
2023-05-27 10:54:01.422355: train Epoch: [24][ 21/193]	Time  0.565 ( 5.011)	Data  0.001 ( 4.430)	Loss 8.7881e-02 (9.5518e-02) 
2023-05-27 10:54:10.116867: train Epoch: [24][ 22/193]	Time  8.694 ( 5.172)	Data  8.130 ( 4.591)	Loss 7.0927e-02 (9.4449e-02) 
2023-05-27 10:54:10.692928: train Epoch: [24][ 23/193]	Time  0.576 ( 4.980)	Data  0.001 ( 4.400)	Loss 1.0102e-01 (9.4723e-02) 
2023-05-27 10:54:18.694161: train Epoch: [24][ 24/193]	Time  8.001 ( 5.101)	Data  7.436 ( 4.521)	Loss 5.5026e-02 (9.3135e-02) 
2023-05-27 10:54:19.260587: train Epoch: [24][ 25/193]	Time  0.566 ( 4.927)	Data  0.001 ( 4.348)	Loss 9.2149e-02 (9.3097e-02) 
2023-05-27 10:54:28.614054: train Epoch: [24][ 26/193]	Time  9.353 ( 5.091)	Data  8.789 ( 4.512)	Loss 1.2122e-01 (9.4139e-02) 
2023-05-27 10:54:29.179842: train Epoch: [24][ 27/193]	Time  0.566 ( 4.929)	Data  0.001 ( 4.351)	Loss 6.7321e-02 (9.3181e-02) 
2023-05-27 10:54:38.077464: train Epoch: [24][ 28/193]	Time  8.898 ( 5.066)	Data  8.321 ( 4.488)	Loss 1.1539e-01 (9.3947e-02) 
2023-05-27 10:54:38.641723: train Epoch: [24][ 29/193]	Time  0.564 ( 4.916)	Data  0.001 ( 4.338)	Loss 7.2102e-02 (9.3219e-02) 
2023-05-27 10:54:48.141620: train Epoch: [24][ 30/193]	Time  9.500 ( 5.064)	Data  8.928 ( 4.486)	Loss 9.5853e-02 (9.3304e-02) 
2023-05-27 10:54:48.714669: train Epoch: [24][ 31/193]	Time  0.573 ( 4.923)	Data  0.001 ( 4.346)	Loss 1.2207e-01 (9.4203e-02) 
2023-05-27 10:54:57.634201: train Epoch: [24][ 32/193]	Time  8.920 ( 5.044)	Data  8.354 ( 4.468)	Loss 5.4779e-02 (9.3008e-02) 
2023-05-27 10:54:58.200722: train Epoch: [24][ 33/193]	Time  0.567 ( 4.913)	Data  0.001 ( 4.336)	Loss 1.0177e-01 (9.3266e-02) 
2023-05-27 10:55:07.204621: train Epoch: [24][ 34/193]	Time  9.004 ( 5.030)	Data  8.438 ( 4.453)	Loss 8.2879e-02 (9.2969e-02) 
2023-05-27 10:55:07.798814: train Epoch: [24][ 35/193]	Time  0.594 ( 4.906)	Data  0.028 ( 4.331)	Loss 8.9163e-02 (9.2863e-02) 
2023-05-27 10:55:16.519976: train Epoch: [24][ 36/193]	Time  8.721 ( 5.009)	Data  8.157 ( 4.434)	Loss 6.6613e-02 (9.2154e-02) 
2023-05-27 10:55:17.816692: train Epoch: [24][ 37/193]	Time  1.297 ( 4.912)	Data  0.730 ( 4.336)	Loss 1.5076e-01 (9.3696e-02) 
2023-05-27 10:55:26.053485: train Epoch: [24][ 38/193]	Time  8.237 ( 4.997)	Data  7.664 ( 4.422)	Loss 8.5966e-02 (9.3498e-02) 
2023-05-27 10:55:28.026543: train Epoch: [24][ 39/193]	Time  1.973 ( 4.921)	Data  1.408 ( 4.346)	Loss 9.6145e-02 (9.3564e-02) 
2023-05-27 10:55:35.800694: train Epoch: [24][ 40/193]	Time  7.774 ( 4.991)	Data  7.211 ( 4.416)	Loss 4.4232e-02 (9.2361e-02) 
2023-05-27 10:55:37.230715: train Epoch: [24][ 41/193]	Time  1.430 ( 4.906)	Data  0.864 ( 4.332)	Loss 6.6289e-02 (9.1740e-02) 
2023-05-27 10:55:45.361566: train Epoch: [24][ 42/193]	Time  8.131 ( 4.981)	Data  7.567 ( 4.407)	Loss 9.0589e-02 (9.1713e-02) 
2023-05-27 10:55:47.122785: train Epoch: [24][ 43/193]	Time  1.761 ( 4.908)	Data  1.194 ( 4.334)	Loss 1.2439e-01 (9.2456e-02) 
2023-05-27 10:55:55.449975: train Epoch: [24][ 44/193]	Time  8.327 ( 4.984)	Data  7.763 ( 4.410)	Loss 1.2986e-01 (9.3287e-02) 
2023-05-27 10:55:56.616871: train Epoch: [24][ 45/193]	Time  1.167 ( 4.901)	Data  0.601 ( 4.327)	Loss 9.5439e-02 (9.3334e-02) 
2023-05-27 10:56:05.050218: train Epoch: [24][ 46/193]	Time  8.433 ( 4.976)	Data  7.862 ( 4.403)	Loss 1.2817e-01 (9.4075e-02) 
2023-05-27 10:56:06.637809: train Epoch: [24][ 47/193]	Time  1.588 ( 4.906)	Data  1.023 ( 4.332)	Loss 8.4946e-02 (9.3885e-02) 
2023-05-27 10:56:14.998265: train Epoch: [24][ 48/193]	Time  8.360 ( 4.976)	Data  7.781 ( 4.403)	Loss 1.8223e-01 (9.5688e-02) 
2023-05-27 10:56:16.070156: train Epoch: [24][ 49/193]	Time  1.072 ( 4.898)	Data  0.507 ( 4.325)	Loss 1.0112e-01 (9.5796e-02) 
2023-05-27 10:56:24.744568: train Epoch: [24][ 50/193]	Time  8.674 ( 4.972)	Data  8.104 ( 4.399)	Loss 6.7827e-02 (9.5248e-02) 
2023-05-27 10:56:25.832782: train Epoch: [24][ 51/193]	Time  1.088 ( 4.897)	Data  0.524 ( 4.324)	Loss 6.9034e-02 (9.4744e-02) 
2023-05-27 10:56:34.893562: train Epoch: [24][ 52/193]	Time  9.061 ( 4.976)	Data  8.496 ( 4.403)	Loss 1.3304e-01 (9.5466e-02) 
2023-05-27 10:56:35.760317: train Epoch: [24][ 53/193]	Time  0.867 ( 4.900)	Data  0.301 ( 4.327)	Loss 1.4212e-01 (9.6331e-02) 
2023-05-27 10:56:44.457351: train Epoch: [24][ 54/193]	Time  8.697 ( 4.969)	Data  8.107 ( 4.396)	Loss 1.0540e-01 (9.6495e-02) 
2023-05-27 10:56:45.707520: train Epoch: [24][ 55/193]	Time  1.250 ( 4.902)	Data  0.681 ( 4.329)	Loss 8.5053e-02 (9.6291e-02) 
2023-05-27 10:56:54.358839: train Epoch: [24][ 56/193]	Time  8.651 ( 4.968)	Data  8.068 ( 4.395)	Loss 1.0477e-01 (9.6440e-02) 
2023-05-27 10:56:55.522869: train Epoch: [24][ 57/193]	Time  1.164 ( 4.903)	Data  0.596 ( 4.329)	Loss 1.0771e-01 (9.6634e-02) 
2023-05-27 10:57:04.317460: train Epoch: [24][ 58/193]	Time  8.795 ( 4.969)	Data  8.221 ( 4.395)	Loss 5.1901e-02 (9.5876e-02) 
2023-05-27 10:57:05.578849: train Epoch: [24][ 59/193]	Time  1.261 ( 4.907)	Data  0.673 ( 4.333)	Loss 5.5571e-02 (9.5204e-02) 
2023-05-27 10:57:14.363286: train Epoch: [24][ 60/193]	Time  8.784 ( 4.970)	Data  8.211 ( 4.397)	Loss 5.8261e-02 (9.4599e-02) 
2023-05-27 10:57:15.371067: train Epoch: [24][ 61/193]	Time  1.008 ( 4.906)	Data  0.435 ( 4.333)	Loss 8.6900e-02 (9.4474e-02) 
2023-05-27 10:57:24.141982: train Epoch: [24][ 62/193]	Time  8.771 ( 4.968)	Data  8.204 ( 4.394)	Loss 5.8209e-02 (9.3899e-02) 
2023-05-27 10:57:25.398796: train Epoch: [24][ 63/193]	Time  1.257 ( 4.910)	Data  0.686 ( 4.337)	Loss 1.2085e-01 (9.4320e-02) 
2023-05-27 10:57:34.405184: train Epoch: [24][ 64/193]	Time  9.006 ( 4.973)	Data  8.427 ( 4.399)	Loss 2.5606e-01 (9.6808e-02) 
2023-05-27 10:57:35.311408: train Epoch: [24][ 65/193]	Time  0.906 ( 4.911)	Data  0.282 ( 4.337)	Loss 9.2526e-02 (9.6743e-02) 
2023-05-27 10:57:43.945475: train Epoch: [24][ 66/193]	Time  8.634 ( 4.967)	Data  8.054 ( 4.393)	Loss 9.5938e-02 (9.6731e-02) 
2023-05-27 10:57:45.469064: train Epoch: [24][ 67/193]	Time  1.524 ( 4.916)	Data  0.959 ( 4.342)	Loss 1.2397e-01 (9.7132e-02) 
2023-05-27 10:57:53.836982: train Epoch: [24][ 68/193]	Time  8.368 ( 4.966)	Data  7.802 ( 4.392)	Loss 6.4062e-02 (9.6653e-02) 
2023-05-27 10:57:55.531795: train Epoch: [24][ 69/193]	Time  1.695 ( 4.919)	Data  1.129 ( 4.346)	Loss 1.1072e-01 (9.6853e-02) 
2023-05-27 10:58:03.958310: train Epoch: [24][ 70/193]	Time  8.427 ( 4.969)	Data  7.847 ( 4.395)	Loss 5.9435e-02 (9.6326e-02) 
2023-05-27 10:58:05.163284: train Epoch: [24][ 71/193]	Time  1.205 ( 4.917)	Data  0.626 ( 4.343)	Loss 6.4159e-02 (9.5880e-02) 
2023-05-27 10:58:14.031060: train Epoch: [24][ 72/193]	Time  8.868 ( 4.971)	Data  8.289 ( 4.397)	Loss 1.3845e-01 (9.6463e-02) 
2023-05-27 10:58:15.036819: train Epoch: [24][ 73/193]	Time  1.006 ( 4.917)	Data  0.439 ( 4.343)	Loss 8.5374e-02 (9.6313e-02) 
2023-05-27 10:58:23.606800: train Epoch: [24][ 74/193]	Time  8.570 ( 4.966)	Data  7.999 ( 4.392)	Loss 9.8884e-02 (9.6347e-02) 
2023-05-27 10:58:24.997545: train Epoch: [24][ 75/193]	Time  1.391 ( 4.919)	Data  0.825 ( 4.345)	Loss 7.9536e-02 (9.6126e-02) 
2023-05-27 10:58:33.857757: train Epoch: [24][ 76/193]	Time  8.860 ( 4.970)	Data  8.286 ( 4.396)	Loss 1.1812e-01 (9.6412e-02) 
2023-05-27 10:58:34.919189: train Epoch: [24][ 77/193]	Time  1.061 ( 4.920)	Data  0.474 ( 4.346)	Loss 7.8239e-02 (9.6179e-02) 
2023-05-27 10:58:43.430302: train Epoch: [24][ 78/193]	Time  8.511 ( 4.965)	Data  7.899 ( 4.391)	Loss 5.0292e-02 (9.5598e-02) 
2023-05-27 10:58:45.092737: train Epoch: [24][ 79/193]	Time  1.662 ( 4.924)	Data  1.098 ( 4.350)	Loss 9.5878e-02 (9.5601e-02) 
2023-05-27 10:58:53.098606: train Epoch: [24][ 80/193]	Time  8.006 ( 4.962)	Data  7.427 ( 4.388)	Loss 5.9609e-02 (9.5157e-02) 
2023-05-27 10:58:55.268293: train Epoch: [24][ 81/193]	Time  2.170 ( 4.928)	Data  1.604 ( 4.354)	Loss 4.9663e-02 (9.4602e-02) 
2023-05-27 10:59:02.932536: train Epoch: [24][ 82/193]	Time  7.664 ( 4.961)	Data  7.097 ( 4.387)	Loss 8.5125e-02 (9.4488e-02) 
2023-05-27 10:59:04.940664: train Epoch: [24][ 83/193]	Time  2.008 ( 4.926)	Data  1.444 ( 4.352)	Loss 1.7392e-01 (9.5434e-02) 
2023-05-27 10:59:12.470104: train Epoch: [24][ 84/193]	Time  7.529 ( 4.956)	Data  6.957 ( 4.382)	Loss 9.3713e-02 (9.5414e-02) 
2023-05-27 10:59:15.041086: train Epoch: [24][ 85/193]	Time  2.571 ( 4.929)	Data  1.996 ( 4.355)	Loss 1.6396e-01 (9.6211e-02) 
2023-05-27 10:59:21.925470: train Epoch: [24][ 86/193]	Time  6.884 ( 4.951)	Data  6.310 ( 4.377)	Loss 2.1188e-01 (9.7540e-02) 
2023-05-27 10:59:24.696969: train Epoch: [24][ 87/193]	Time  2.771 ( 4.926)	Data  2.197 ( 4.352)	Loss 1.8446e-01 (9.8528e-02) 
2023-05-27 10:59:30.763040: train Epoch: [24][ 88/193]	Time  6.066 ( 4.939)	Data  5.491 ( 4.365)	Loss 7.8363e-02 (9.8301e-02) 
2023-05-27 10:59:33.316579: train Epoch: [24][ 89/193]	Time  2.554 ( 4.913)	Data  1.982 ( 4.339)	Loss 7.5459e-02 (9.8047e-02) 
2023-05-27 10:59:40.211416: train Epoch: [24][ 90/193]	Time  6.895 ( 4.935)	Data  6.329 ( 4.360)	Loss 8.6158e-02 (9.7917e-02) 
2023-05-27 10:59:43.304693: train Epoch: [24][ 91/193]	Time  3.093 ( 4.914)	Data  2.521 ( 4.341)	Loss 4.7434e-02 (9.7368e-02) 
2023-05-27 10:59:50.000659: train Epoch: [24][ 92/193]	Time  6.696 ( 4.934)	Data  6.129 ( 4.360)	Loss 1.2736e-01 (9.7691e-02) 
2023-05-27 10:59:53.199481: train Epoch: [24][ 93/193]	Time  3.199 ( 4.915)	Data  2.634 ( 4.341)	Loss 2.9552e-01 (9.9795e-02) 
2023-05-27 10:59:59.661205: train Epoch: [24][ 94/193]	Time  6.462 ( 4.931)	Data  5.894 ( 4.358)	Loss 1.0383e-01 (9.9838e-02) 
2023-05-27 11:00:02.854975: train Epoch: [24][ 95/193]	Time  3.194 ( 4.913)	Data  2.623 ( 4.340)	Loss 2.2885e-01 (1.0118e-01) 
2023-05-27 11:00:09.439549: train Epoch: [24][ 96/193]	Time  6.585 ( 4.931)	Data  5.969 ( 4.356)	Loss 1.7086e-01 (1.0190e-01) 
2023-05-27 11:00:12.896666: train Epoch: [24][ 97/193]	Time  3.457 ( 4.916)	Data  2.887 ( 4.341)	Loss 6.6807e-02 (1.0154e-01) 
2023-05-27 11:00:19.341807: train Epoch: [24][ 98/193]	Time  6.445 ( 4.931)	Data  5.875 ( 4.357)	Loss 1.4362e-01 (1.0197e-01) 
2023-05-27 11:00:22.939541: train Epoch: [24][ 99/193]	Time  3.598 ( 4.918)	Data  3.020 ( 4.344)	Loss 4.0669e-02 (1.0135e-01) 
2023-05-27 11:00:29.339709: train Epoch: [24][100/193]	Time  6.400 ( 4.932)	Data  5.835 ( 4.358)	Loss 9.4036e-02 (1.0128e-01) 
2023-05-27 11:00:33.191179: train Epoch: [24][101/193]	Time  3.851 ( 4.922)	Data  3.281 ( 4.348)	Loss 9.3777e-02 (1.0121e-01) 
2023-05-27 11:00:39.104295: train Epoch: [24][102/193]	Time  5.913 ( 4.931)	Data  5.352 ( 4.358)	Loss 1.5076e-01 (1.0169e-01) 
2023-05-27 11:00:42.987285: train Epoch: [24][103/193]	Time  3.883 ( 4.921)	Data  3.279 ( 4.347)	Loss 5.8595e-02 (1.0127e-01) 
2023-05-27 11:00:49.040386: train Epoch: [24][104/193]	Time  6.053 ( 4.932)	Data  5.485 ( 4.358)	Loss 7.3290e-02 (1.0101e-01) 
2023-05-27 11:00:52.578774: train Epoch: [24][105/193]	Time  3.538 ( 4.919)	Data  2.923 ( 4.344)	Loss 8.9973e-02 (1.0090e-01) 
2023-05-27 11:00:58.492225: train Epoch: [24][106/193]	Time  5.913 ( 4.928)	Data  5.338 ( 4.354)	Loss 8.8042e-02 (1.0078e-01) 
2023-05-27 11:01:02.237472: train Epoch: [24][107/193]	Time  3.745 ( 4.917)	Data  3.180 ( 4.343)	Loss 8.4081e-02 (1.0063e-01) 
2023-05-27 11:01:08.634167: train Epoch: [24][108/193]	Time  6.397 ( 4.931)	Data  5.813 ( 4.356)	Loss 8.0312e-02 (1.0044e-01) 
2023-05-27 11:01:12.141000: train Epoch: [24][109/193]	Time  3.507 ( 4.918)	Data  2.941 ( 4.343)	Loss 8.1112e-02 (1.0027e-01) 
2023-05-27 11:01:18.463975: train Epoch: [24][110/193]	Time  6.323 ( 4.931)	Data  5.719 ( 4.356)	Loss 7.2288e-02 (1.0001e-01) 
2023-05-27 11:01:21.697459: train Epoch: [24][111/193]	Time  3.233 ( 4.915)	Data  2.661 ( 4.341)	Loss 1.0847e-01 (1.0009e-01) 
2023-05-27 11:01:28.286093: train Epoch: [24][112/193]	Time  6.589 ( 4.930)	Data  6.026 ( 4.356)	Loss 1.7259e-01 (1.0073e-01) 
2023-05-27 11:01:31.824952: train Epoch: [24][113/193]	Time  3.539 ( 4.918)	Data  2.964 ( 4.343)	Loss 2.5187e-01 (1.0206e-01) 
2023-05-27 11:01:37.922906: train Epoch: [24][114/193]	Time  6.098 ( 4.928)	Data  5.519 ( 4.354)	Loss 5.5858e-02 (1.0166e-01) 
2023-05-27 11:01:41.440235: train Epoch: [24][115/193]	Time  3.517 ( 4.916)	Data  2.946 ( 4.342)	Loss 8.3979e-02 (1.0150e-01) 
2023-05-27 11:01:47.478257: train Epoch: [24][116/193]	Time  6.038 ( 4.926)	Data  5.467 ( 4.351)	Loss 1.3669e-01 (1.0180e-01) 
2023-05-27 11:01:51.298294: train Epoch: [24][117/193]	Time  3.820 ( 4.916)	Data  3.255 ( 4.342)	Loss 1.0719e-01 (1.0185e-01) 
2023-05-27 11:01:57.346385: train Epoch: [24][118/193]	Time  6.048 ( 4.926)	Data  5.468 ( 4.351)	Loss 6.1227e-02 (1.0151e-01) 
2023-05-27 11:02:00.972987: train Epoch: [24][119/193]	Time  3.627 ( 4.915)	Data  3.052 ( 4.341)	Loss 6.2883e-02 (1.0119e-01) 
2023-05-27 11:02:07.351381: train Epoch: [24][120/193]	Time  6.378 ( 4.927)	Data  5.803 ( 4.353)	Loss 5.1857e-02 (1.0078e-01) 
2023-05-27 11:02:11.280039: train Epoch: [24][121/193]	Time  3.929 ( 4.919)	Data  3.354 ( 4.344)	Loss 6.5078e-02 (1.0049e-01) 
2023-05-27 11:02:17.269477: train Epoch: [24][122/193]	Time  5.989 ( 4.928)	Data  5.426 ( 4.353)	Loss 6.8291e-02 (1.0022e-01) 
2023-05-27 11:02:20.949975: train Epoch: [24][123/193]	Time  3.680 ( 4.918)	Data  3.106 ( 4.343)	Loss 9.6140e-02 (1.0019e-01) 
2023-05-27 11:02:27.201675: train Epoch: [24][124/193]	Time  6.252 ( 4.928)	Data  5.672 ( 4.354)	Loss 6.5986e-02 (9.9918e-02) 
2023-05-27 11:02:30.733919: train Epoch: [24][125/193]	Time  3.532 ( 4.917)	Data  2.962 ( 4.343)	Loss 1.3492e-01 (1.0020e-01) 
2023-05-27 11:02:36.647344: train Epoch: [24][126/193]	Time  5.913 ( 4.925)	Data  5.353 ( 4.351)	Loss 1.2985e-01 (1.0043e-01) 
2023-05-27 11:02:40.661680: train Epoch: [24][127/193]	Time  4.014 ( 4.918)	Data  3.450 ( 4.344)	Loss 8.4513e-02 (1.0031e-01) 
2023-05-27 11:02:46.152141: train Epoch: [24][128/193]	Time  5.490 ( 4.922)	Data  4.930 ( 4.348)	Loss 1.0280e-01 (1.0032e-01) 
2023-05-27 11:02:50.117510: train Epoch: [24][129/193]	Time  3.965 ( 4.915)	Data  3.398 ( 4.341)	Loss 1.4856e-01 (1.0070e-01) 
2023-05-27 11:02:56.210238: train Epoch: [24][130/193]	Time  6.093 ( 4.924)	Data  5.532 ( 4.350)	Loss 1.3377e-01 (1.0095e-01) 
2023-05-27 11:02:59.480630: train Epoch: [24][131/193]	Time  3.270 ( 4.911)	Data  2.704 ( 4.338)	Loss 8.1525e-02 (1.0080e-01) 
2023-05-27 11:03:05.972086: train Epoch: [24][132/193]	Time  6.491 ( 4.923)	Data  5.931 ( 4.350)	Loss 6.9328e-02 (1.0056e-01) 
2023-05-27 11:03:09.186568: train Epoch: [24][133/193]	Time  3.214 ( 4.911)	Data  2.652 ( 4.337)	Loss 1.1402e-01 (1.0066e-01) 
2023-05-27 11:03:15.703736: train Epoch: [24][134/193]	Time  6.517 ( 4.922)	Data  5.951 ( 4.349)	Loss 6.9956e-02 (1.0044e-01) 
2023-05-27 11:03:19.392530: train Epoch: [24][135/193]	Time  3.689 ( 4.913)	Data  3.115 ( 4.340)	Loss 7.1779e-02 (1.0023e-01) 
2023-05-27 11:03:25.648062: train Epoch: [24][136/193]	Time  6.256 ( 4.923)	Data  5.691 ( 4.350)	Loss 8.8301e-02 (1.0014e-01) 
2023-05-27 11:03:28.857602: train Epoch: [24][137/193]	Time  3.210 ( 4.911)	Data  2.619 ( 4.337)	Loss 8.2106e-02 (1.0001e-01) 
2023-05-27 11:03:35.448159: train Epoch: [24][138/193]	Time  6.591 ( 4.923)	Data  6.031 ( 4.349)	Loss 5.8494e-02 (9.9710e-02) 
2023-05-27 11:03:39.167451: train Epoch: [24][139/193]	Time  3.719 ( 4.914)	Data  3.096 ( 4.340)	Loss 1.1154e-01 (9.9794e-02) 
2023-05-27 11:03:45.618923: train Epoch: [24][140/193]	Time  6.451 ( 4.925)	Data  5.890 ( 4.351)	Loss 1.0667e-01 (9.9843e-02) 
2023-05-27 11:03:49.349120: train Epoch: [24][141/193]	Time  3.730 ( 4.917)	Data  3.117 ( 4.343)	Loss 1.3549e-01 (1.0009e-01) 
2023-05-27 11:03:55.376238: train Epoch: [24][142/193]	Time  6.027 ( 4.925)	Data  5.461 ( 4.350)	Loss 9.4521e-02 (1.0006e-01) 
2023-05-27 11:03:59.113150: train Epoch: [24][143/193]	Time  3.737 ( 4.916)	Data  3.137 ( 4.342)	Loss 6.0567e-02 (9.9781e-02) 
2023-05-27 11:04:05.235262: train Epoch: [24][144/193]	Time  6.122 ( 4.925)	Data  5.556 ( 4.350)	Loss 6.6738e-02 (9.9553e-02) 
2023-05-27 11:04:08.895436: train Epoch: [24][145/193]	Time  3.660 ( 4.916)	Data  3.074 ( 4.342)	Loss 8.0550e-02 (9.9423e-02) 
2023-05-27 11:04:15.250982: train Epoch: [24][146/193]	Time  6.356 ( 4.926)	Data  5.768 ( 4.351)	Loss 1.0231e-01 (9.9443e-02) 
2023-05-27 11:04:18.830272: train Epoch: [24][147/193]	Time  3.579 ( 4.917)	Data  3.004 ( 4.342)	Loss 6.7751e-02 (9.9228e-02) 
2023-05-27 11:04:25.118787: train Epoch: [24][148/193]	Time  6.289 ( 4.926)	Data  5.714 ( 4.351)	Loss 8.5451e-02 (9.9136e-02) 
2023-05-27 11:04:29.030119: train Epoch: [24][149/193]	Time  3.911 ( 4.919)	Data  3.346 ( 4.345)	Loss 6.8725e-02 (9.8933e-02) 
2023-05-27 11:04:35.234812: train Epoch: [24][150/193]	Time  6.205 ( 4.928)	Data  5.638 ( 4.353)	Loss 2.0616e-01 (9.9643e-02) 
2023-05-27 11:04:38.723347: train Epoch: [24][151/193]	Time  3.489 ( 4.918)	Data  2.924 ( 4.344)	Loss 8.6134e-02 (9.9555e-02) 
2023-05-27 11:04:45.035655: train Epoch: [24][152/193]	Time  6.312 ( 4.927)	Data  5.717 ( 4.353)	Loss 6.6217e-02 (9.9337e-02) 
2023-05-27 11:04:48.388046: train Epoch: [24][153/193]	Time  3.352 ( 4.917)	Data  2.775 ( 4.343)	Loss 1.2380e-01 (9.9495e-02) 
2023-05-27 11:04:55.157935: train Epoch: [24][154/193]	Time  6.770 ( 4.929)	Data  6.197 ( 4.355)	Loss 1.7489e-01 (9.9982e-02) 
2023-05-27 11:04:58.077677: train Epoch: [24][155/193]	Time  2.920 ( 4.916)	Data  2.346 ( 4.342)	Loss 7.5833e-02 (9.9827e-02) 
2023-05-27 11:05:04.676076: train Epoch: [24][156/193]	Time  6.598 ( 4.927)	Data  6.033 ( 4.352)	Loss 6.0979e-02 (9.9580e-02) 
2023-05-27 11:05:08.290713: train Epoch: [24][157/193]	Time  3.615 ( 4.918)	Data  3.035 ( 4.344)	Loss 1.0508e-01 (9.9614e-02) 
2023-05-27 11:05:14.663561: train Epoch: [24][158/193]	Time  6.373 ( 4.928)	Data  5.809 ( 4.353)	Loss 1.3564e-01 (9.9841e-02) 
2023-05-27 11:05:17.713856: train Epoch: [24][159/193]	Time  3.050 ( 4.916)	Data  2.477 ( 4.342)	Loss 1.5301e-01 (1.0017e-01) 
2023-05-27 11:05:24.715869: train Epoch: [24][160/193]	Time  7.002 ( 4.929)	Data  6.428 ( 4.355)	Loss 2.0676e-01 (1.0084e-01) 
2023-05-27 11:05:27.592168: train Epoch: [24][161/193]	Time  2.876 ( 4.916)	Data  2.312 ( 4.342)	Loss 2.6042e-01 (1.0182e-01) 
2023-05-27 11:05:34.875447: train Epoch: [24][162/193]	Time  7.283 ( 4.931)	Data  6.709 ( 4.356)	Loss 1.0390e-01 (1.0183e-01) 
2023-05-27 11:05:37.408789: train Epoch: [24][163/193]	Time  2.533 ( 4.916)	Data  1.968 ( 4.342)	Loss 1.2770e-01 (1.0199e-01) 
2023-05-27 11:05:44.863519: train Epoch: [24][164/193]	Time  7.455 ( 4.931)	Data  6.870 ( 4.357)	Loss 7.7090e-02 (1.0184e-01) 
2023-05-27 11:05:47.226770: train Epoch: [24][165/193]	Time  2.363 ( 4.916)	Data  1.795 ( 4.342)	Loss 6.1366e-02 (1.0160e-01) 
2023-05-27 11:05:54.160708: train Epoch: [24][166/193]	Time  6.934 ( 4.928)	Data  6.366 ( 4.354)	Loss 1.1910e-01 (1.0170e-01) 
2023-05-27 11:05:57.372501: train Epoch: [24][167/193]	Time  3.212 ( 4.918)	Data  2.647 ( 4.344)	Loss 1.2100e-01 (1.0182e-01) 
2023-05-27 11:06:03.606112: train Epoch: [24][168/193]	Time  6.234 ( 4.926)	Data  5.665 ( 4.352)	Loss 1.3005e-01 (1.0198e-01) 
2023-05-27 11:06:07.297425: train Epoch: [24][169/193]	Time  3.691 ( 4.918)	Data  3.127 ( 4.344)	Loss 8.0408e-02 (1.0186e-01) 
2023-05-27 11:06:14.031040: train Epoch: [24][170/193]	Time  6.734 ( 4.929)	Data  6.168 ( 4.355)	Loss 7.6025e-02 (1.0170e-01) 
2023-05-27 11:06:16.807586: train Epoch: [24][171/193]	Time  2.777 ( 4.916)	Data  2.205 ( 4.343)	Loss 1.3787e-01 (1.0192e-01) 
2023-05-27 11:06:23.641836: train Epoch: [24][172/193]	Time  6.834 ( 4.928)	Data  6.239 ( 4.354)	Loss 8.9090e-02 (1.0184e-01) 
2023-05-27 11:06:26.805739: train Epoch: [24][173/193]	Time  3.164 ( 4.917)	Data  2.599 ( 4.343)	Loss 1.2306e-01 (1.0196e-01) 
2023-05-27 11:06:33.347123: train Epoch: [24][174/193]	Time  6.541 ( 4.927)	Data  5.970 ( 4.353)	Loss 6.1944e-02 (1.0173e-01) 
2023-05-27 11:06:36.733700: train Epoch: [24][175/193]	Time  3.387 ( 4.918)	Data  2.821 ( 4.344)	Loss 1.4848e-01 (1.0200e-01) 
2023-05-27 11:06:43.424877: train Epoch: [24][176/193]	Time  6.691 ( 4.928)	Data  6.129 ( 4.354)	Loss 6.2774e-02 (1.0178e-01) 
2023-05-27 11:06:47.029833: train Epoch: [24][177/193]	Time  3.605 ( 4.921)	Data  3.039 ( 4.347)	Loss 1.2085e-01 (1.0189e-01) 
2023-05-27 11:06:53.081079: train Epoch: [24][178/193]	Time  6.051 ( 4.927)	Data  5.484 ( 4.353)	Loss 1.1835e-01 (1.0198e-01) 
2023-05-27 11:06:56.390794: train Epoch: [24][179/193]	Time  3.310 ( 4.918)	Data  2.737 ( 4.344)	Loss 7.4962e-02 (1.0183e-01) 
2023-05-27 11:07:02.596104: train Epoch: [24][180/193]	Time  6.205 ( 4.925)	Data  5.636 ( 4.351)	Loss 5.5327e-02 (1.0157e-01) 
2023-05-27 11:07:06.560391: train Epoch: [24][181/193]	Time  3.964 ( 4.920)	Data  3.382 ( 4.346)	Loss 1.3146e-01 (1.0173e-01) 
2023-05-27 11:07:12.334294: train Epoch: [24][182/193]	Time  5.774 ( 4.924)	Data  5.209 ( 4.351)	Loss 7.3716e-02 (1.0158e-01) 
2023-05-27 11:07:15.719741: train Epoch: [24][183/193]	Time  3.385 ( 4.916)	Data  2.815 ( 4.342)	Loss 9.2654e-02 (1.0153e-01) 
2023-05-27 11:07:22.077481: train Epoch: [24][184/193]	Time  6.358 ( 4.924)	Data  5.791 ( 4.350)	Loss 9.0093e-02 (1.0147e-01) 
2023-05-27 11:07:25.097302: train Epoch: [24][185/193]	Time  3.020 ( 4.914)	Data  2.449 ( 4.340)	Loss 8.0789e-02 (1.0136e-01) 
2023-05-27 11:07:31.370847: train Epoch: [24][186/193]	Time  6.274 ( 4.921)	Data  5.708 ( 4.347)	Loss 9.2637e-02 (1.0131e-01) 
2023-05-27 11:07:34.731146: train Epoch: [24][187/193]	Time  3.360 ( 4.913)	Data  2.786 ( 4.339)	Loss 5.8752e-02 (1.0109e-01) 
2023-05-27 11:07:40.898434: train Epoch: [24][188/193]	Time  6.167 ( 4.919)	Data  5.608 ( 4.346)	Loss 1.2042e-01 (1.0119e-01) 
2023-05-27 11:07:44.609429: train Epoch: [24][189/193]	Time  3.711 ( 4.913)	Data  3.100 ( 4.339)	Loss 1.8450e-01 (1.0163e-01) 
2023-05-27 11:07:50.731479: train Epoch: [24][190/193]	Time  6.122 ( 4.919)	Data  5.560 ( 4.345)	Loss 1.2578e-01 (1.0175e-01) 
2023-05-27 11:07:54.686553: train Epoch: [24][191/193]	Time  3.955 ( 4.914)	Data  3.383 ( 4.340)	Loss 1.4462e-01 (1.0198e-01) 
2023-05-27 11:07:59.839445: train Epoch: [24][192/193]	Time  5.153 ( 4.915)	Data  4.592 ( 4.342)	Loss 1.0070e-01 (1.0197e-01) 
2023-05-27 11:08:00.002997: Train Epoch done in 948.8329975020024 s 
2023-05-27 11:08:06.754604: val Epoch: [24][ 0/72]	Time  5.856 ( 5.856)	Data  5.670 ( 5.670)	Loss 1.0106e-01 (1.0106e-01) 
2023-05-27 11:08:06.860378: val Epoch: [24][ 1/72]	Time  0.106 ( 2.981)	Data  0.001 ( 2.836)	Loss 1.0775e-01 (1.0440e-01) 
2023-05-27 11:08:11.630714: val Epoch: [24][ 2/72]	Time  4.770 ( 3.577)	Data  4.654 ( 3.442)	Loss 4.4626e-01 (2.1835e-01) 
2023-05-27 11:08:11.742643: val Epoch: [24][ 3/72]	Time  0.112 ( 2.711)	Data  0.001 ( 2.582)	Loss 7.6988e-02 (1.8301e-01) 
2023-05-27 11:08:16.573632: val Epoch: [24][ 4/72]	Time  4.831 ( 3.135)	Data  4.723 ( 3.010)	Loss 1.8093e-01 (1.8260e-01) 
2023-05-27 11:08:16.682539: val Epoch: [24][ 5/72]	Time  0.109 ( 2.631)	Data  0.001 ( 2.508)	Loss 5.1080e-02 (1.6068e-01) 
2023-05-27 11:08:21.469429: val Epoch: [24][ 6/72]	Time  4.787 ( 2.939)	Data  4.679 ( 2.818)	Loss 6.0410e-01 (2.2402e-01) 
2023-05-27 11:08:21.580798: val Epoch: [24][ 7/72]	Time  0.111 ( 2.585)	Data  0.000 ( 2.466)	Loss 3.5420e-01 (2.4030e-01) 
2023-05-27 11:08:26.679956: val Epoch: [24][ 8/72]	Time  5.099 ( 2.865)	Data  4.988 ( 2.746)	Loss 6.0602e-02 (2.2033e-01) 
2023-05-27 11:08:26.823231: val Epoch: [24][ 9/72]	Time  0.143 ( 2.592)	Data  0.001 ( 2.472)	Loss 4.5300e-02 (2.0283e-01) 
2023-05-27 11:08:31.684477: val Epoch: [24][10/72]	Time  4.861 ( 2.799)	Data  4.730 ( 2.677)	Loss 6.7745e-02 (1.9055e-01) 
2023-05-27 11:08:31.803337: val Epoch: [24][11/72]	Time  0.119 ( 2.575)	Data  0.001 ( 2.454)	Loss 1.5425e-01 (1.8752e-01) 
2023-05-27 11:08:36.431592: val Epoch: [24][12/72]	Time  4.628 ( 2.733)	Data  4.521 ( 2.613)	Loss 9.4791e-02 (1.8039e-01) 
2023-05-27 11:08:36.536395: val Epoch: [24][13/72]	Time  0.105 ( 2.546)	Data  0.001 ( 2.426)	Loss 1.6273e-01 (1.7913e-01) 
2023-05-27 11:08:41.278039: val Epoch: [24][14/72]	Time  4.742 ( 2.692)	Data  4.632 ( 2.574)	Loss 4.5107e-02 (1.7019e-01) 
2023-05-27 11:08:41.389626: val Epoch: [24][15/72]	Time  0.112 ( 2.531)	Data  0.000 ( 2.413)	Loss 5.1955e-02 (1.6280e-01) 
2023-05-27 11:08:46.046083: val Epoch: [24][16/72]	Time  4.656 ( 2.656)	Data  4.550 ( 2.538)	Loss 6.3885e-01 (1.9081e-01) 
2023-05-27 11:08:46.357991: val Epoch: [24][17/72]	Time  0.312 ( 2.526)	Data  0.204 ( 2.409)	Loss 6.8824e-02 (1.8403e-01) 
2023-05-27 11:08:50.825460: val Epoch: [24][18/72]	Time  4.467 ( 2.628)	Data  4.360 ( 2.511)	Loss 4.5923e-02 (1.7676e-01) 
2023-05-27 11:08:51.431000: val Epoch: [24][19/72]	Time  0.606 ( 2.527)	Data  0.500 ( 2.411)	Loss 9.2095e-02 (1.7253e-01) 
2023-05-27 11:08:55.805627: val Epoch: [24][20/72]	Time  4.375 ( 2.615)	Data  4.265 ( 2.499)	Loss 1.0566e-01 (1.6934e-01) 
2023-05-27 11:08:56.737650: val Epoch: [24][21/72]	Time  0.932 ( 2.538)	Data  0.824 ( 2.423)	Loss 1.4056e-01 (1.6803e-01) 
2023-05-27 11:09:00.533733: val Epoch: [24][22/72]	Time  3.796 ( 2.593)	Data  3.690 ( 2.478)	Loss 1.1051e-01 (1.6553e-01) 
2023-05-27 11:09:01.684007: val Epoch: [24][23/72]	Time  1.150 ( 2.533)	Data  1.045 ( 2.418)	Loss 2.3584e-01 (1.6846e-01) 
2023-05-27 11:09:05.450082: val Epoch: [24][24/72]	Time  3.766 ( 2.582)	Data  3.661 ( 2.468)	Loss 1.3327e-01 (1.6705e-01) 
2023-05-27 11:09:06.656484: val Epoch: [24][25/72]	Time  1.206 ( 2.529)	Data  1.098 ( 2.415)	Loss 4.7523e-01 (1.7891e-01) 
2023-05-27 11:09:10.192165: val Epoch: [24][26/72]	Time  3.536 ( 2.566)	Data  3.424 ( 2.453)	Loss 6.8671e-02 (1.7482e-01) 
2023-05-27 11:09:11.529706: val Epoch: [24][27/72]	Time  1.338 ( 2.523)	Data  1.232 ( 2.409)	Loss 1.7348e-01 (1.7478e-01) 
2023-05-27 11:09:15.192387: val Epoch: [24][28/72]	Time  3.663 ( 2.562)	Data  3.557 ( 2.449)	Loss 1.5407e-01 (1.7406e-01) 
2023-05-27 11:09:16.622181: val Epoch: [24][29/72]	Time  1.430 ( 2.524)	Data  1.322 ( 2.411)	Loss 8.7530e-02 (1.7118e-01) 
2023-05-27 11:09:20.029571: val Epoch: [24][30/72]	Time  3.407 ( 2.553)	Data  3.302 ( 2.440)	Loss 2.3845e-01 (1.7335e-01) 
2023-05-27 11:09:21.770063: val Epoch: [24][31/72]	Time  1.740 ( 2.527)	Data  1.631 ( 2.415)	Loss 9.9329e-02 (1.7104e-01) 
2023-05-27 11:09:24.937353: val Epoch: [24][32/72]	Time  3.167 ( 2.547)	Data  3.057 ( 2.434)	Loss 6.1829e-02 (1.6773e-01) 
2023-05-27 11:09:26.411578: val Epoch: [24][33/72]	Time  1.474 ( 2.515)	Data  1.369 ( 2.403)	Loss 7.1092e-02 (1.6488e-01) 
2023-05-27 11:09:29.848458: val Epoch: [24][34/72]	Time  3.437 ( 2.541)	Data  3.332 ( 2.429)	Loss 1.4795e-01 (1.6440e-01) 
2023-05-27 11:09:31.527997: val Epoch: [24][35/72]	Time  1.680 ( 2.517)	Data  1.561 ( 2.405)	Loss 1.2219e-01 (1.6323e-01) 
2023-05-27 11:09:34.813622: val Epoch: [24][36/72]	Time  3.286 ( 2.538)	Data  3.176 ( 2.426)	Loss 1.1861e-01 (1.6202e-01) 
2023-05-27 11:09:36.533684: val Epoch: [24][37/72]	Time  1.720 ( 2.517)	Data  1.611 ( 2.405)	Loss 5.3122e-02 (1.5916e-01) 
2023-05-27 11:09:39.668469: val Epoch: [24][38/72]	Time  3.135 ( 2.533)	Data  3.024 ( 2.420)	Loss 5.3700e-02 (1.5645e-01) 
2023-05-27 11:09:41.444267: val Epoch: [24][39/72]	Time  1.776 ( 2.514)	Data  1.668 ( 2.402)	Loss 3.1324e-01 (1.6037e-01) 
2023-05-27 11:09:44.545202: val Epoch: [24][40/72]	Time  3.101 ( 2.528)	Data  2.993 ( 2.416)	Loss 4.9922e-02 (1.5768e-01) 
2023-05-27 11:09:46.135593: val Epoch: [24][41/72]	Time  1.590 ( 2.506)	Data  1.482 ( 2.394)	Loss 6.9032e-02 (1.5557e-01) 
2023-05-27 11:09:49.649575: val Epoch: [24][42/72]	Time  3.514 ( 2.529)	Data  3.407 ( 2.417)	Loss 1.0389e-01 (1.5437e-01) 
2023-05-27 11:09:51.223664: val Epoch: [24][43/72]	Time  1.574 ( 2.507)	Data  1.463 ( 2.396)	Loss 3.1434e-01 (1.5800e-01) 
2023-05-27 11:09:54.497330: val Epoch: [24][44/72]	Time  3.274 ( 2.524)	Data  3.154 ( 2.413)	Loss 3.9763e-02 (1.5537e-01) 
2023-05-27 11:09:55.889628: val Epoch: [24][45/72]	Time  1.392 ( 2.500)	Data  1.285 ( 2.388)	Loss 7.2019e-02 (1.5356e-01) 
2023-05-27 11:09:59.407089: val Epoch: [24][46/72]	Time  3.517 ( 2.521)	Data  3.411 ( 2.410)	Loss 6.7635e-02 (1.5173e-01) 
2023-05-27 11:10:00.685667: val Epoch: [24][47/72]	Time  1.279 ( 2.496)	Data  1.170 ( 2.384)	Loss 1.1554e-01 (1.5098e-01) 
2023-05-27 11:10:04.518851: val Epoch: [24][48/72]	Time  3.833 ( 2.523)	Data  3.720 ( 2.411)	Loss 1.0927e-01 (1.5013e-01) 
2023-05-27 11:10:05.579722: val Epoch: [24][49/72]	Time  1.061 ( 2.494)	Data  0.949 ( 2.382)	Loss 3.9582e-01 (1.5504e-01) 
2023-05-27 11:10:09.417631: val Epoch: [24][50/72]	Time  3.838 ( 2.520)	Data  3.728 ( 2.408)	Loss 3.7774e-02 (1.5274e-01) 
2023-05-27 11:10:10.654039: val Epoch: [24][51/72]	Time  1.236 ( 2.495)	Data  1.125 ( 2.384)	Loss 1.9790e-01 (1.5361e-01) 
2023-05-27 11:10:14.488047: val Epoch: [24][52/72]	Time  3.834 ( 2.521)	Data  3.717 ( 2.409)	Loss 1.9016e-01 (1.5430e-01) 
2023-05-27 11:10:15.672554: val Epoch: [24][53/72]	Time  1.185 ( 2.496)	Data  1.075 ( 2.384)	Loss 3.8083e-01 (1.5850e-01) 
2023-05-27 11:10:19.281809: val Epoch: [24][54/72]	Time  3.609 ( 2.516)	Data  3.499 ( 2.404)	Loss 9.7524e-02 (1.5739e-01) 
2023-05-27 11:10:20.667697: val Epoch: [24][55/72]	Time  1.386 ( 2.496)	Data  1.279 ( 2.384)	Loss 9.2778e-02 (1.5623e-01) 
2023-05-27 11:10:24.206988: val Epoch: [24][56/72]	Time  3.539 ( 2.514)	Data  3.430 ( 2.403)	Loss 2.6295e-01 (1.5811e-01) 
2023-05-27 11:10:25.516267: val Epoch: [24][57/72]	Time  1.309 ( 2.493)	Data  1.200 ( 2.382)	Loss 3.5861e-01 (1.6156e-01) 
2023-05-27 11:10:29.321291: val Epoch: [24][58/72]	Time  3.805 ( 2.516)	Data  3.697 ( 2.404)	Loss 1.0646e-01 (1.6063e-01) 
2023-05-27 11:10:30.178524: val Epoch: [24][59/72]	Time  0.857 ( 2.488)	Data  0.750 ( 2.377)	Loss 1.4238e-01 (1.6032e-01) 
2023-05-27 11:10:34.158365: val Epoch: [24][60/72]	Time  3.980 ( 2.512)	Data  3.871 ( 2.401)	Loss 5.4302e-02 (1.5859e-01) 
2023-05-27 11:10:35.247321: val Epoch: [24][61/72]	Time  1.089 ( 2.489)	Data  0.984 ( 2.378)	Loss 7.7111e-02 (1.5727e-01) 
2023-05-27 11:10:39.151647: val Epoch: [24][62/72]	Time  3.904 ( 2.512)	Data  3.799 ( 2.401)	Loss 1.0114e-01 (1.5638e-01) 
2023-05-27 11:10:39.867918: val Epoch: [24][63/72]	Time  0.716 ( 2.484)	Data  0.611 ( 2.373)	Loss 4.7730e-02 (1.5468e-01) 
2023-05-27 11:10:43.898575: val Epoch: [24][64/72]	Time  4.031 ( 2.508)	Data  3.921 ( 2.397)	Loss 8.1703e-02 (1.5356e-01) 
2023-05-27 11:10:44.590612: val Epoch: [24][65/72]	Time  0.692 ( 2.480)	Data  0.587 ( 2.369)	Loss 4.8950e-02 (1.5198e-01) 
2023-05-27 11:10:48.835597: val Epoch: [24][66/72]	Time  4.245 ( 2.507)	Data  4.139 ( 2.396)	Loss 9.2494e-02 (1.5109e-01) 
2023-05-27 11:10:49.316220: val Epoch: [24][67/72]	Time  0.481 ( 2.477)	Data  0.375 ( 2.366)	Loss 1.0742e-01 (1.5045e-01) 
2023-05-27 11:10:53.934854: val Epoch: [24][68/72]	Time  4.619 ( 2.508)	Data  4.514 ( 2.397)	Loss 7.5285e-02 (1.4936e-01) 
2023-05-27 11:10:54.321515: val Epoch: [24][69/72]	Time  0.387 ( 2.477)	Data  0.281 ( 2.367)	Loss 7.3233e-02 (1.4827e-01) 
2023-05-27 11:10:58.994139: val Epoch: [24][70/72]	Time  4.673 ( 2.508)	Data  4.566 ( 2.398)	Loss 3.9103e-01 (1.5169e-01) 
2023-05-27 11:10:59.210208: val Epoch: [24][71/72]	Time  0.216 ( 2.477)	Data  0.111 ( 2.366)	Loss 6.2913e-02 (1.5046e-01) 
2023-05-27 11:10:59.654618: Epoch 24 :Val : ['ET : 0.6836164593696594', 'TC : 0.7512576580047607', 'WT : 0.8409653306007385'] 
2023-05-27 11:10:59.657373: Epoch 24 :Val : ['ET : 0.6836164593696594', 'TC : 0.7512576580047607', 'WT : 0.8409653306007385'] 
2023-05-27 11:10:59.659320: Val epoch done in 179.6563324960007 s 
2023-05-27 11:10:59.665200: Batches per epoch:  193 
2023-05-27 11:11:11.273229: train Epoch: [25][  0/193]	Time 11.608 (11.608)	Data 10.994 (10.994)	Loss 6.8254e-02 (6.8254e-02) 
2023-05-27 11:11:11.837578: train Epoch: [25][  1/193]	Time  0.564 ( 6.086)	Data  0.001 ( 5.497)	Loss 1.4329e-01 (1.0577e-01) 
2023-05-27 11:11:21.356826: train Epoch: [25][  2/193]	Time  9.519 ( 7.230)	Data  8.895 ( 6.630)	Loss 1.0650e-01 (1.0602e-01) 
2023-05-27 11:11:21.931203: train Epoch: [25][  3/193]	Time  0.574 ( 5.566)	Data  0.001 ( 4.973)	Loss 7.3938e-02 (9.7996e-02) 
2023-05-27 11:11:30.984920: train Epoch: [25][  4/193]	Time  9.054 ( 6.264)	Data  8.489 ( 5.676)	Loss 1.4258e-01 (1.0691e-01) 
2023-05-27 11:11:31.595812: train Epoch: [25][  5/193]	Time  0.611 ( 5.322)	Data  0.001 ( 4.730)	Loss 8.6520e-02 (1.0351e-01) 
2023-05-27 11:11:40.752794: train Epoch: [25][  6/193]	Time  9.157 ( 5.870)	Data  8.584 ( 5.281)	Loss 7.7155e-02 (9.9748e-02) 
2023-05-27 11:11:41.327553: train Epoch: [25][  7/193]	Time  0.575 ( 5.208)	Data  0.001 ( 4.621)	Loss 6.6301e-02 (9.5567e-02) 
2023-05-27 11:11:50.590101: train Epoch: [25][  8/193]	Time  9.263 ( 5.658)	Data  8.684 ( 5.072)	Loss 7.9273e-02 (9.3756e-02) 
2023-05-27 11:11:51.165574: train Epoch: [25][  9/193]	Time  0.575 ( 5.150)	Data  0.001 ( 4.565)	Loss 8.3416e-02 (9.2722e-02) 
2023-05-27 11:12:01.211695: train Epoch: [25][ 10/193]	Time 10.046 ( 5.595)	Data  9.477 ( 5.012)	Loss 7.2881e-02 (9.0919e-02) 
2023-05-27 11:12:01.778373: train Epoch: [25][ 11/193]	Time  0.567 ( 5.176)	Data  0.001 ( 4.594)	Loss 1.0145e-01 (9.1796e-02) 
2023-05-27 11:12:11.229895: train Epoch: [25][ 12/193]	Time  9.451 ( 5.505)	Data  8.882 ( 4.924)	Loss 1.0644e-01 (9.2922e-02) 
2023-05-27 11:12:11.810231: train Epoch: [25][ 13/193]	Time  0.580 ( 5.153)	Data  0.001 ( 4.572)	Loss 5.1377e-02 (8.9955e-02) 
2023-05-27 11:12:20.970080: train Epoch: [25][ 14/193]	Time  9.160 ( 5.420)	Data  8.564 ( 4.838)	Loss 9.9379e-02 (9.0583e-02) 
2023-05-27 11:12:21.584775: train Epoch: [25][ 15/193]	Time  0.615 ( 5.120)	Data  0.005 ( 4.536)	Loss 1.7731e-01 (9.6003e-02) 
2023-05-27 11:12:30.745900: train Epoch: [25][ 16/193]	Time  9.161 ( 5.358)	Data  8.594 ( 4.775)	Loss 1.3457e-01 (9.8272e-02) 
2023-05-27 11:12:31.321516: train Epoch: [25][ 17/193]	Time  0.576 ( 5.092)	Data  0.001 ( 4.510)	Loss 8.1321e-02 (9.7330e-02) 
2023-05-27 11:12:40.011997: train Epoch: [25][ 18/193]	Time  8.690 ( 5.281)	Data  8.114 ( 4.699)	Loss 1.2455e-01 (9.8763e-02) 
2023-05-27 11:12:40.590675: train Epoch: [25][ 19/193]	Time  0.579 ( 5.046)	Data  0.001 ( 4.464)	Loss 8.8879e-02 (9.8269e-02) 
2023-05-27 11:12:48.176518: train Epoch: [25][ 20/193]	Time  7.586 ( 5.167)	Data  7.011 ( 4.586)	Loss 7.2484e-02 (9.7041e-02) 
2023-05-27 11:12:48.745088: train Epoch: [25][ 21/193]	Time  0.569 ( 4.958)	Data  0.001 ( 4.377)	Loss 8.1047e-02 (9.6314e-02) 
2023-05-27 11:12:57.704819: train Epoch: [25][ 22/193]	Time  8.960 ( 5.132)	Data  8.390 ( 4.552)	Loss 1.5453e-01 (9.8845e-02) 
2023-05-27 11:12:58.274168: train Epoch: [25][ 23/193]	Time  0.569 ( 4.942)	Data  0.001 ( 4.362)	Loss 1.1378e-01 (9.9467e-02) 
2023-05-27 11:13:06.366790: train Epoch: [25][ 24/193]	Time  8.093 ( 5.068)	Data  7.528 ( 4.489)	Loss 1.2866e-01 (1.0063e-01) 
2023-05-27 11:13:06.966083: train Epoch: [25][ 25/193]	Time  0.599 ( 4.896)	Data  0.001 ( 4.316)	Loss 7.9459e-02 (9.9821e-02) 
2023-05-27 11:13:15.477800: train Epoch: [25][ 26/193]	Time  8.512 ( 5.030)	Data  7.951 ( 4.451)	Loss 8.3071e-02 (9.9200e-02) 
2023-05-27 11:13:16.038637: train Epoch: [25][ 27/193]	Time  0.561 ( 4.870)	Data  0.001 ( 4.292)	Loss 5.0755e-02 (9.7470e-02) 
2023-05-27 11:13:24.987752: train Epoch: [25][ 28/193]	Time  8.949 ( 5.011)	Data  8.384 ( 4.433)	Loss 7.8551e-02 (9.6818e-02) 
2023-05-27 11:13:25.550974: train Epoch: [25][ 29/193]	Time  0.563 ( 4.863)	Data  0.001 ( 4.285)	Loss 8.0597e-02 (9.6277e-02) 
2023-05-27 11:13:34.461446: train Epoch: [25][ 30/193]	Time  8.910 ( 4.993)	Data  8.350 ( 4.416)	Loss 6.1337e-02 (9.5150e-02) 
2023-05-27 11:13:35.022861: train Epoch: [25][ 31/193]	Time  0.561 ( 4.855)	Data  0.001 ( 4.278)	Loss 5.9214e-02 (9.4027e-02) 
2023-05-27 11:13:44.035089: train Epoch: [25][ 32/193]	Time  9.012 ( 4.981)	Data  8.444 ( 4.405)	Loss 6.4746e-02 (9.3140e-02) 
2023-05-27 11:13:44.599086: train Epoch: [25][ 33/193]	Time  0.564 ( 4.851)	Data  0.001 ( 4.275)	Loss 7.4059e-02 (9.2578e-02) 
2023-05-27 11:13:53.769198: train Epoch: [25][ 34/193]	Time  9.170 ( 4.974)	Data  8.611 ( 4.399)	Loss 6.2244e-02 (9.1712e-02) 
2023-05-27 11:13:54.330146: train Epoch: [25][ 35/193]	Time  0.561 ( 4.852)	Data  0.001 ( 4.277)	Loss 9.1606e-02 (9.1709e-02) 
2023-05-27 11:14:03.517914: train Epoch: [25][ 36/193]	Time  9.188 ( 4.969)	Data  8.622 ( 4.394)	Loss 9.6372e-02 (9.1835e-02) 
2023-05-27 11:14:04.077733: train Epoch: [25][ 37/193]	Time  0.560 ( 4.853)	Data  0.001 ( 4.279)	Loss 9.8789e-02 (9.2018e-02) 
2023-05-27 11:14:13.078066: train Epoch: [25][ 38/193]	Time  9.000 ( 4.959)	Data  8.428 ( 4.385)	Loss 1.7407e-01 (9.4122e-02) 
2023-05-27 11:14:13.642940: train Epoch: [25][ 39/193]	Time  0.565 ( 4.849)	Data  0.001 ( 4.275)	Loss 6.0613e-02 (9.3284e-02) 
2023-05-27 11:14:22.949299: train Epoch: [25][ 40/193]	Time  9.306 ( 4.958)	Data  8.732 ( 4.384)	Loss 5.8383e-02 (9.2433e-02) 
2023-05-27 11:14:23.510419: train Epoch: [25][ 41/193]	Time  0.561 ( 4.853)	Data  0.001 ( 4.280)	Loss 1.1693e-01 (9.3016e-02) 
2023-05-27 11:14:32.429299: train Epoch: [25][ 42/193]	Time  8.919 ( 4.948)	Data  8.359 ( 4.375)	Loss 4.5237e-02 (9.1905e-02) 
2023-05-27 11:14:32.990158: train Epoch: [25][ 43/193]	Time  0.561 ( 4.848)	Data  0.001 ( 4.275)	Loss 7.9750e-02 (9.1628e-02) 
2023-05-27 11:14:42.615557: train Epoch: [25][ 44/193]	Time  9.625 ( 4.954)	Data  9.063 ( 4.382)	Loss 1.2256e-01 (9.2316e-02) 
2023-05-27 11:14:43.188410: train Epoch: [25][ 45/193]	Time  0.573 ( 4.859)	Data  0.001 ( 4.286)	Loss 7.3593e-02 (9.1909e-02) 
2023-05-27 11:14:52.615885: train Epoch: [25][ 46/193]	Time  9.427 ( 4.956)	Data  8.851 ( 4.384)	Loss 1.5198e-01 (9.3187e-02) 
2023-05-27 11:14:53.182126: train Epoch: [25][ 47/193]	Time  0.566 ( 4.865)	Data  0.001 ( 4.292)	Loss 1.3829e-01 (9.4127e-02) 
2023-05-27 11:15:02.974692: train Epoch: [25][ 48/193]	Time  9.793 ( 4.965)	Data  9.226 ( 4.393)	Loss 6.4730e-02 (9.3527e-02) 
2023-05-27 11:15:03.539344: train Epoch: [25][ 49/193]	Time  0.565 ( 4.877)	Data  0.001 ( 4.305)	Loss 7.9328e-02 (9.3243e-02) 
2023-05-27 11:15:12.488084: train Epoch: [25][ 50/193]	Time  8.949 ( 4.957)	Data  8.382 ( 4.385)	Loss 9.3392e-02 (9.3246e-02) 
2023-05-27 11:15:13.052291: train Epoch: [25][ 51/193]	Time  0.564 ( 4.873)	Data  0.001 ( 4.301)	Loss 6.4530e-02 (9.2693e-02) 
2023-05-27 11:15:22.195773: train Epoch: [25][ 52/193]	Time  9.143 ( 4.953)	Data  8.583 ( 4.381)	Loss 1.6853e-01 (9.4124e-02) 
2023-05-27 11:15:22.763494: train Epoch: [25][ 53/193]	Time  0.568 ( 4.872)	Data  0.001 ( 4.300)	Loss 7.7830e-02 (9.3823e-02) 
2023-05-27 11:15:31.809427: train Epoch: [25][ 54/193]	Time  9.046 ( 4.948)	Data  8.485 ( 4.376)	Loss 8.9163e-02 (9.3738e-02) 
2023-05-27 11:15:32.370577: train Epoch: [25][ 55/193]	Time  0.561 ( 4.870)	Data  0.001 ( 4.298)	Loss 6.9695e-02 (9.3309e-02) 
2023-05-27 11:15:41.713095: train Epoch: [25][ 56/193]	Time  9.343 ( 4.948)	Data  8.764 ( 4.377)	Loss 6.3655e-02 (9.2788e-02) 
2023-05-27 11:15:42.275388: train Epoch: [25][ 57/193]	Time  0.562 ( 4.873)	Data  0.001 ( 4.301)	Loss 7.5982e-02 (9.2499e-02) 
2023-05-27 11:15:51.103532: train Epoch: [25][ 58/193]	Time  8.828 ( 4.940)	Data  8.268 ( 4.368)	Loss 1.4165e-01 (9.3332e-02) 
2023-05-27 11:15:51.663856: train Epoch: [25][ 59/193]	Time  0.560 ( 4.867)	Data  0.001 ( 4.296)	Loss 1.7964e-01 (9.4770e-02) 
2023-05-27 11:16:00.627536: train Epoch: [25][ 60/193]	Time  8.964 ( 4.934)	Data  8.403 ( 4.363)	Loss 1.3689e-01 (9.5461e-02) 
2023-05-27 11:16:01.188212: train Epoch: [25][ 61/193]	Time  0.561 ( 4.863)	Data  0.001 ( 4.293)	Loss 9.0237e-02 (9.5376e-02) 
2023-05-27 11:16:09.561448: train Epoch: [25][ 62/193]	Time  8.373 ( 4.919)	Data  7.809 ( 4.348)	Loss 7.0125e-02 (9.4976e-02) 
2023-05-27 11:16:10.121212: train Epoch: [25][ 63/193]	Time  0.560 ( 4.851)	Data  0.001 ( 4.281)	Loss 1.1459e-01 (9.5282e-02) 
2023-05-27 11:16:19.806051: train Epoch: [25][ 64/193]	Time  9.685 ( 4.925)	Data  9.119 ( 4.355)	Loss 6.1851e-02 (9.4768e-02) 
2023-05-27 11:16:20.366483: train Epoch: [25][ 65/193]	Time  0.560 ( 4.859)	Data  0.001 ( 4.289)	Loss 7.9348e-02 (9.4534e-02) 
2023-05-27 11:16:29.543543: train Epoch: [25][ 66/193]	Time  9.177 ( 4.924)	Data  8.611 ( 4.353)	Loss 3.9353e-02 (9.3710e-02) 
2023-05-27 11:16:30.104708: train Epoch: [25][ 67/193]	Time  0.561 ( 4.859)	Data  0.001 ( 4.289)	Loss 9.3505e-02 (9.3707e-02) 
2023-05-27 11:16:39.421735: train Epoch: [25][ 68/193]	Time  9.317 ( 4.924)	Data  8.751 ( 4.354)	Loss 1.1359e-01 (9.3996e-02) 
2023-05-27 11:16:39.987719: train Epoch: [25][ 69/193]	Time  0.566 ( 4.862)	Data  0.001 ( 4.292)	Loss 2.3293e-01 (9.5980e-02) 
2023-05-27 11:16:48.897466: train Epoch: [25][ 70/193]	Time  8.910 ( 4.919)	Data  8.349 ( 4.349)	Loss 1.4016e-01 (9.6603e-02) 
2023-05-27 11:16:49.466104: train Epoch: [25][ 71/193]	Time  0.569 ( 4.858)	Data  0.001 ( 4.289)	Loss 1.2225e-01 (9.6959e-02) 
2023-05-27 11:16:58.691889: train Epoch: [25][ 72/193]	Time  9.226 ( 4.918)	Data  8.660 ( 4.349)	Loss 5.2245e-02 (9.6346e-02) 
2023-05-27 11:16:59.256893: train Epoch: [25][ 73/193]	Time  0.565 ( 4.859)	Data  0.001 ( 4.290)	Loss 1.4182e-01 (9.6961e-02) 
2023-05-27 11:17:08.222887: train Epoch: [25][ 74/193]	Time  8.966 ( 4.914)	Data  8.395 ( 4.345)	Loss 8.3236e-02 (9.6778e-02) 
2023-05-27 11:17:09.243177: train Epoch: [25][ 75/193]	Time  1.020 ( 4.863)	Data  0.454 ( 4.293)	Loss 9.6004e-02 (9.6768e-02) 
2023-05-27 11:17:17.577225: train Epoch: [25][ 76/193]	Time  8.334 ( 4.908)	Data  7.759 ( 4.338)	Loss 7.3356e-02 (9.6463e-02) 
2023-05-27 11:17:19.291233: train Epoch: [25][ 77/193]	Time  1.714 ( 4.867)	Data  1.154 ( 4.298)	Loss 9.4611e-02 (9.6440e-02) 
2023-05-27 11:17:27.385016: train Epoch: [25][ 78/193]	Time  8.094 ( 4.908)	Data  7.491 ( 4.338)	Loss 2.4451e-01 (9.8314e-02) 
2023-05-27 11:17:29.152634: train Epoch: [25][ 79/193]	Time  1.768 ( 4.869)	Data  1.208 ( 4.299)	Loss 1.1258e-01 (9.8492e-02) 
2023-05-27 11:17:36.925988: train Epoch: [25][ 80/193]	Time  7.773 ( 4.904)	Data  7.194 ( 4.335)	Loss 1.1320e-01 (9.8674e-02) 
2023-05-27 11:17:39.082371: train Epoch: [25][ 81/193]	Time  2.156 ( 4.871)	Data  1.596 ( 4.301)	Loss 1.3507e-01 (9.9118e-02) 
2023-05-27 11:17:46.742518: train Epoch: [25][ 82/193]	Time  7.660 ( 4.905)	Data  7.087 ( 4.335)	Loss 7.8384e-02 (9.8868e-02) 
2023-05-27 11:17:48.810394: train Epoch: [25][ 83/193]	Time  2.068 ( 4.871)	Data  1.500 ( 4.301)	Loss 1.4223e-01 (9.9384e-02) 
2023-05-27 11:17:56.447927: train Epoch: [25][ 84/193]	Time  7.638 ( 4.903)	Data  7.066 ( 4.334)	Loss 9.9351e-02 (9.9384e-02) 
2023-05-27 11:17:58.655412: train Epoch: [25][ 85/193]	Time  2.207 ( 4.872)	Data  1.641 ( 4.302)	Loss 6.5382e-02 (9.8988e-02) 
2023-05-27 11:18:06.239656: train Epoch: [25][ 86/193]	Time  7.584 ( 4.903)	Data  6.996 ( 4.333)	Loss 8.4646e-02 (9.8824e-02) 
2023-05-27 11:18:08.421118: train Epoch: [25][ 87/193]	Time  2.181 ( 4.872)	Data  1.616 ( 4.302)	Loss 1.8832e-01 (9.9841e-02) 
2023-05-27 11:18:15.953178: train Epoch: [25][ 88/193]	Time  7.532 ( 4.902)	Data  6.961 ( 4.332)	Loss 1.5516e-01 (1.0046e-01) 
2023-05-27 11:18:18.192697: train Epoch: [25][ 89/193]	Time  2.240 ( 4.873)	Data  1.651 ( 4.302)	Loss 7.2897e-02 (1.0016e-01) 
2023-05-27 11:18:24.746417: train Epoch: [25][ 90/193]	Time  6.554 ( 4.891)	Data  5.985 ( 4.321)	Loss 3.9213e-02 (9.9486e-02) 
2023-05-27 11:18:26.690684: train Epoch: [25][ 91/193]	Time  1.944 ( 4.859)	Data  1.353 ( 4.289)	Loss 1.1610e-01 (9.9667e-02) 
2023-05-27 11:18:33.244086: train Epoch: [25][ 92/193]	Time  6.553 ( 4.877)	Data  5.990 ( 4.307)	Loss 9.1938e-02 (9.9584e-02) 
2023-05-27 11:18:34.961880: train Epoch: [25][ 93/193]	Time  1.718 ( 4.844)	Data  1.145 ( 4.273)	Loss 8.6127e-02 (9.9441e-02) 
2023-05-27 11:18:43.123853: train Epoch: [25][ 94/193]	Time  8.162 ( 4.879)	Data  7.595 ( 4.308)	Loss 1.2923e-01 (9.9754e-02) 
2023-05-27 11:18:45.220847: train Epoch: [25][ 95/193]	Time  2.097 ( 4.850)	Data  1.495 ( 4.279)	Loss 1.5792e-01 (1.0036e-01) 
2023-05-27 11:18:53.074642: train Epoch: [25][ 96/193]	Time  7.854 ( 4.881)	Data  7.281 ( 4.310)	Loss 5.5421e-02 (9.9897e-02) 
2023-05-27 11:18:54.894765: train Epoch: [25][ 97/193]	Time  1.820 ( 4.849)	Data  1.233 ( 4.278)	Loss 9.1372e-02 (9.9810e-02) 
2023-05-27 11:19:03.020402: train Epoch: [25][ 98/193]	Time  8.126 ( 4.882)	Data  7.546 ( 4.311)	Loss 5.2214e-02 (9.9329e-02) 
2023-05-27 11:19:04.792790: train Epoch: [25][ 99/193]	Time  1.772 ( 4.851)	Data  1.201 ( 4.280)	Loss 1.5282e-01 (9.9864e-02) 
2023-05-27 11:19:12.628254: train Epoch: [25][100/193]	Time  7.835 ( 4.881)	Data  7.271 ( 4.310)	Loss 1.3207e-01 (1.0018e-01) 
2023-05-27 11:19:14.198618: train Epoch: [25][101/193]	Time  1.570 ( 4.848)	Data  1.007 ( 4.278)	Loss 1.4572e-01 (1.0063e-01) 
2023-05-27 11:19:22.477858: train Epoch: [25][102/193]	Time  8.279 ( 4.882)	Data  7.717 ( 4.311)	Loss 1.0800e-01 (1.0070e-01) 
2023-05-27 11:19:24.182550: train Epoch: [25][103/193]	Time  1.705 ( 4.851)	Data  1.107 ( 4.280)	Loss 7.9766e-02 (1.0050e-01) 
2023-05-27 11:19:33.006825: train Epoch: [25][104/193]	Time  8.824 ( 4.889)	Data  8.226 ( 4.318)	Loss 7.5760e-02 (1.0026e-01) 
2023-05-27 11:19:33.881032: train Epoch: [25][105/193]	Time  0.874 ( 4.851)	Data  0.312 ( 4.280)	Loss 1.4036e-01 (1.0064e-01) 
2023-05-27 11:19:42.717469: train Epoch: [25][106/193]	Time  8.836 ( 4.888)	Data  8.258 ( 4.317)	Loss 9.0303e-02 (1.0055e-01) 
2023-05-27 11:19:43.427940: train Epoch: [25][107/193]	Time  0.710 ( 4.850)	Data  0.115 ( 4.278)	Loss 8.6867e-02 (1.0042e-01) 
2023-05-27 11:19:52.925703: train Epoch: [25][108/193]	Time  9.498 ( 4.892)	Data  8.927 ( 4.321)	Loss 6.9279e-02 (1.0013e-01) 
2023-05-27 11:19:53.555748: train Epoch: [25][109/193]	Time  0.630 ( 4.854)	Data  0.001 ( 4.282)	Loss 1.2773e-01 (1.0038e-01) 
2023-05-27 11:20:02.683832: train Epoch: [25][110/193]	Time  9.128 ( 4.892)	Data  8.558 ( 4.320)	Loss 9.2947e-02 (1.0032e-01) 
2023-05-27 11:20:03.538662: train Epoch: [25][111/193]	Time  0.855 ( 4.856)	Data  0.264 ( 4.284)	Loss 9.8940e-02 (1.0030e-01) 
2023-05-27 11:20:12.715324: train Epoch: [25][112/193]	Time  9.177 ( 4.894)	Data  8.613 ( 4.322)	Loss 5.0668e-02 (9.9866e-02) 
2023-05-27 11:20:13.747261: train Epoch: [25][113/193]	Time  1.032 ( 4.860)	Data  0.455 ( 4.288)	Loss 2.7683e-01 (1.0142e-01) 
2023-05-27 11:20:22.551008: train Epoch: [25][114/193]	Time  8.804 ( 4.895)	Data  8.224 ( 4.323)	Loss 4.4611e-02 (1.0092e-01) 
2023-05-27 11:20:23.488631: train Epoch: [25][115/193]	Time  0.938 ( 4.861)	Data  0.368 ( 4.288)	Loss 8.4609e-02 (1.0078e-01) 
2023-05-27 11:20:32.699941: train Epoch: [25][116/193]	Time  9.211 ( 4.898)	Data  8.644 ( 4.326)	Loss 1.4880e-01 (1.0119e-01) 
2023-05-27 11:20:33.283503: train Epoch: [25][117/193]	Time  0.584 ( 4.861)	Data  0.001 ( 4.289)	Loss 5.9252e-02 (1.0084e-01) 
2023-05-27 11:20:42.075173: train Epoch: [25][118/193]	Time  8.792 ( 4.894)	Data  8.232 ( 4.322)	Loss 6.6455e-02 (1.0055e-01) 
2023-05-27 11:20:42.779087: train Epoch: [25][119/193]	Time  0.704 ( 4.859)	Data  0.143 ( 4.287)	Loss 1.3139e-01 (1.0081e-01) 
2023-05-27 11:20:52.254682: train Epoch: [25][120/193]	Time  9.476 ( 4.897)	Data  8.908 ( 4.326)	Loss 1.0229e-01 (1.0082e-01) 
2023-05-27 11:20:52.819774: train Epoch: [25][121/193]	Time  0.565 ( 4.862)	Data  0.001 ( 4.290)	Loss 7.1079e-02 (1.0057e-01) 
2023-05-27 11:21:02.258025: train Epoch: [25][122/193]	Time  9.438 ( 4.899)	Data  8.866 ( 4.327)	Loss 6.0984e-02 (1.0025e-01) 
2023-05-27 11:21:02.848991: train Epoch: [25][123/193]	Time  0.591 ( 4.864)	Data  0.001 ( 4.292)	Loss 7.5514e-02 (1.0005e-01) 
2023-05-27 11:21:11.908215: train Epoch: [25][124/193]	Time  9.059 ( 4.898)	Data  8.487 ( 4.326)	Loss 5.0979e-02 (9.9661e-02) 
2023-05-27 11:21:12.475675: train Epoch: [25][125/193]	Time  0.567 ( 4.864)	Data  0.001 ( 4.292)	Loss 8.5209e-02 (9.9546e-02) 
2023-05-27 11:21:21.470548: train Epoch: [25][126/193]	Time  8.995 ( 4.896)	Data  8.426 ( 4.324)	Loss 9.3966e-02 (9.9502e-02) 
2023-05-27 11:21:22.198799: train Epoch: [25][127/193]	Time  0.728 ( 4.864)	Data  0.162 ( 4.292)	Loss 7.1673e-02 (9.9285e-02) 
2023-05-27 11:21:31.251976: train Epoch: [25][128/193]	Time  9.053 ( 4.896)	Data  8.492 ( 4.324)	Loss 7.8534e-02 (9.9124e-02) 
2023-05-27 11:21:31.910323: train Epoch: [25][129/193]	Time  0.658 ( 4.863)	Data  0.098 ( 4.292)	Loss 2.6202e-01 (1.0038e-01) 
2023-05-27 11:21:40.417469: train Epoch: [25][130/193]	Time  8.507 ( 4.891)	Data  7.940 ( 4.320)	Loss 1.1077e-01 (1.0046e-01) 
2023-05-27 11:21:41.606293: train Epoch: [25][131/193]	Time  1.189 ( 4.863)	Data  0.622 ( 4.292)	Loss 1.3411e-01 (1.0071e-01) 
2023-05-27 11:21:50.129140: train Epoch: [25][132/193]	Time  8.523 ( 4.891)	Data  7.949 ( 4.319)	Loss 5.7149e-02 (1.0038e-01) 
2023-05-27 11:21:51.506081: train Epoch: [25][133/193]	Time  1.377 ( 4.864)	Data  0.811 ( 4.293)	Loss 1.0026e-01 (1.0038e-01) 
2023-05-27 11:21:59.479752: train Epoch: [25][134/193]	Time  7.974 ( 4.888)	Data  7.395 ( 4.316)	Loss 1.4242e-01 (1.0069e-01) 
2023-05-27 11:22:01.994623: train Epoch: [25][135/193]	Time  2.515 ( 4.870)	Data  1.921 ( 4.298)	Loss 7.3695e-02 (1.0050e-01) 
2023-05-27 11:22:09.360629: train Epoch: [25][136/193]	Time  7.366 ( 4.888)	Data  6.797 ( 4.316)	Loss 8.7350e-02 (1.0040e-01) 
2023-05-27 11:22:12.022564: train Epoch: [25][137/193]	Time  2.662 ( 4.872)	Data  2.095 ( 4.300)	Loss 1.5402e-01 (1.0079e-01) 
2023-05-27 11:22:19.620119: train Epoch: [25][138/193]	Time  7.598 ( 4.892)	Data  7.026 ( 4.320)	Loss 1.2509e-01 (1.0096e-01) 
2023-05-27 11:22:21.782721: train Epoch: [25][139/193]	Time  2.163 ( 4.872)	Data  1.593 ( 4.301)	Loss 7.0965e-02 (1.0075e-01) 
2023-05-27 11:22:29.564040: train Epoch: [25][140/193]	Time  7.781 ( 4.893)	Data  7.220 ( 4.321)	Loss 1.1000e-01 (1.0081e-01) 
2023-05-27 11:22:31.268657: train Epoch: [25][141/193]	Time  1.705 ( 4.870)	Data  1.137 ( 4.299)	Loss 9.0929e-02 (1.0074e-01) 
2023-05-27 11:22:39.256625: train Epoch: [25][142/193]	Time  7.988 ( 4.892)	Data  7.420 ( 4.321)	Loss 1.2089e-01 (1.0089e-01) 
2023-05-27 11:22:40.695516: train Epoch: [25][143/193]	Time  1.439 ( 4.868)	Data  0.872 ( 4.297)	Loss 7.2328e-02 (1.0069e-01) 
2023-05-27 11:22:49.224815: train Epoch: [25][144/193]	Time  8.529 ( 4.894)	Data  7.958 ( 4.322)	Loss 1.4000e-01 (1.0096e-01) 
2023-05-27 11:22:50.207026: train Epoch: [25][145/193]	Time  0.982 ( 4.867)	Data  0.412 ( 4.295)	Loss 6.9448e-02 (1.0074e-01) 
2023-05-27 11:22:58.929718: train Epoch: [25][146/193]	Time  8.723 ( 4.893)	Data  8.160 ( 4.321)	Loss 1.0975e-01 (1.0080e-01) 
2023-05-27 11:22:59.705191: train Epoch: [25][147/193]	Time  0.775 ( 4.865)	Data  0.214 ( 4.294)	Loss 2.2531e-01 (1.0165e-01) 
2023-05-27 11:23:08.935641: train Epoch: [25][148/193]	Time  9.230 ( 4.894)	Data  8.672 ( 4.323)	Loss 7.8130e-02 (1.0149e-01) 
2023-05-27 11:23:09.735387: train Epoch: [25][149/193]	Time  0.800 ( 4.867)	Data  0.237 ( 4.296)	Loss 8.4321e-02 (1.0137e-01) 
2023-05-27 11:23:18.871831: train Epoch: [25][150/193]	Time  9.136 ( 4.895)	Data  8.538 ( 4.324)	Loss 7.0820e-02 (1.0117e-01) 
2023-05-27 11:23:19.993285: train Epoch: [25][151/193]	Time  1.121 ( 4.871)	Data  0.553 ( 4.299)	Loss 7.7230e-02 (1.0101e-01) 
2023-05-27 11:23:28.724827: train Epoch: [25][152/193]	Time  8.732 ( 4.896)	Data  8.167 ( 4.324)	Loss 8.1209e-02 (1.0088e-01) 
2023-05-27 11:23:29.321814: train Epoch: [25][153/193]	Time  0.597 ( 4.868)	Data  0.033 ( 4.297)	Loss 6.3786e-02 (1.0064e-01) 
2023-05-27 11:23:38.439953: train Epoch: [25][154/193]	Time  9.118 ( 4.895)	Data  8.543 ( 4.324)	Loss 4.7265e-02 (1.0030e-01) 
2023-05-27 11:23:39.116908: train Epoch: [25][155/193]	Time  0.677 ( 4.868)	Data  0.108 ( 4.297)	Loss 8.6764e-02 (1.0021e-01) 
2023-05-27 11:23:48.349417: train Epoch: [25][156/193]	Time  9.233 ( 4.896)	Data  8.651 ( 4.325)	Loss 7.5229e-02 (1.0005e-01) 
2023-05-27 11:23:48.929878: train Epoch: [25][157/193]	Time  0.580 ( 4.869)	Data  0.001 ( 4.297)	Loss 8.6216e-02 (9.9965e-02) 
2023-05-27 11:23:58.151943: train Epoch: [25][158/193]	Time  9.222 ( 4.896)	Data  8.659 ( 4.325)	Loss 6.3685e-02 (9.9737e-02) 
2023-05-27 11:23:58.950268: train Epoch: [25][159/193]	Time  0.798 ( 4.871)	Data  0.237 ( 4.299)	Loss 9.1412e-02 (9.9685e-02) 
2023-05-27 11:24:07.788242: train Epoch: [25][160/193]	Time  8.838 ( 4.895)	Data  8.279 ( 4.324)	Loss 6.0077e-02 (9.9439e-02) 
2023-05-27 11:24:09.371169: train Epoch: [25][161/193]	Time  1.583 ( 4.875)	Data  1.022 ( 4.304)	Loss 7.6510e-02 (9.9297e-02) 
2023-05-27 11:24:17.928156: train Epoch: [25][162/193]	Time  8.557 ( 4.897)	Data  7.984 ( 4.326)	Loss 9.9101e-02 (9.9296e-02) 
2023-05-27 11:24:19.221261: train Epoch: [25][163/193]	Time  1.293 ( 4.875)	Data  0.720 ( 4.304)	Loss 1.7479e-01 (9.9756e-02) 
2023-05-27 11:24:27.647501: train Epoch: [25][164/193]	Time  8.426 ( 4.897)	Data  7.868 ( 4.326)	Loss 8.1426e-02 (9.9645e-02) 
2023-05-27 11:24:28.954971: train Epoch: [25][165/193]	Time  1.307 ( 4.875)	Data  0.737 ( 4.304)	Loss 9.2935e-02 (9.9605e-02) 
2023-05-27 11:24:37.210994: train Epoch: [25][166/193]	Time  8.256 ( 4.895)	Data  7.696 ( 4.324)	Loss 5.8777e-02 (9.9360e-02) 
2023-05-27 11:24:38.569232: train Epoch: [25][167/193]	Time  1.358 ( 4.874)	Data  0.766 ( 4.303)	Loss 8.5488e-02 (9.9278e-02) 
2023-05-27 11:24:47.303648: train Epoch: [25][168/193]	Time  8.734 ( 4.897)	Data  8.169 ( 4.326)	Loss 7.6894e-02 (9.9145e-02) 
2023-05-27 11:24:48.436513: train Epoch: [25][169/193]	Time  1.133 ( 4.875)	Data  0.565 ( 4.304)	Loss 3.7587e-02 (9.8783e-02) 
2023-05-27 11:24:57.553216: train Epoch: [25][170/193]	Time  9.117 ( 4.900)	Data  8.550 ( 4.329)	Loss 1.9011e-01 (9.9317e-02) 
2023-05-27 11:24:58.256771: train Epoch: [25][171/193]	Time  0.704 ( 4.876)	Data  0.134 ( 4.304)	Loss 1.3377e-01 (9.9518e-02) 
2023-05-27 11:25:07.178083: train Epoch: [25][172/193]	Time  8.921 ( 4.899)	Data  8.348 ( 4.328)	Loss 7.3249e-02 (9.9366e-02) 
2023-05-27 11:25:08.329193: train Epoch: [25][173/193]	Time  1.151 ( 4.877)	Data  0.578 ( 4.306)	Loss 5.2749e-02 (9.9098e-02) 
2023-05-27 11:25:17.144715: train Epoch: [25][174/193]	Time  8.816 ( 4.900)	Data  8.242 ( 4.329)	Loss 1.1533e-01 (9.9191e-02) 
2023-05-27 11:25:18.324923: train Epoch: [25][175/193]	Time  1.180 ( 4.879)	Data  0.620 ( 4.308)	Loss 8.0070e-02 (9.9082e-02) 
2023-05-27 11:25:27.050545: train Epoch: [25][176/193]	Time  8.726 ( 4.900)	Data  8.166 ( 4.329)	Loss 1.0112e-01 (9.9093e-02) 
2023-05-27 11:25:28.027946: train Epoch: [25][177/193]	Time  0.977 ( 4.878)	Data  0.401 ( 4.307)	Loss 7.6172e-02 (9.8965e-02) 
2023-05-27 11:25:36.726679: train Epoch: [25][178/193]	Time  8.699 ( 4.900)	Data  8.137 ( 4.329)	Loss 6.1129e-02 (9.8753e-02) 
2023-05-27 11:25:37.704334: train Epoch: [25][179/193]	Time  0.978 ( 4.878)	Data  0.403 ( 4.307)	Loss 7.7049e-02 (9.8633e-02) 
2023-05-27 11:25:46.535477: train Epoch: [25][180/193]	Time  8.831 ( 4.900)	Data  8.263 ( 4.329)	Loss 8.2954e-02 (9.8546e-02) 
2023-05-27 11:25:47.593305: train Epoch: [25][181/193]	Time  1.058 ( 4.879)	Data  0.489 ( 4.308)	Loss 1.5269e-01 (9.8844e-02) 
2023-05-27 11:25:56.451503: train Epoch: [25][182/193]	Time  8.858 ( 4.900)	Data  8.292 ( 4.329)	Loss 6.2409e-02 (9.8644e-02) 
2023-05-27 11:25:57.051098: train Epoch: [25][183/193]	Time  0.600 ( 4.877)	Data  0.039 ( 4.306)	Loss 8.1806e-02 (9.8553e-02) 
2023-05-27 11:26:06.251688: train Epoch: [25][184/193]	Time  9.201 ( 4.900)	Data  8.640 ( 4.330)	Loss 1.1612e-01 (9.8648e-02) 
2023-05-27 11:26:07.126823: train Epoch: [25][185/193]	Time  0.875 ( 4.879)	Data  0.219 ( 4.308)	Loss 1.5978e-01 (9.8977e-02) 
2023-05-27 11:26:15.930889: train Epoch: [25][186/193]	Time  8.804 ( 4.900)	Data  8.237 ( 4.329)	Loss 7.2607e-02 (9.8836e-02) 
2023-05-27 11:26:17.108352: train Epoch: [25][187/193]	Time  1.177 ( 4.880)	Data  0.609 ( 4.309)	Loss 1.3985e-01 (9.9054e-02) 
2023-05-27 11:26:25.937235: train Epoch: [25][188/193]	Time  8.829 ( 4.901)	Data  8.266 ( 4.330)	Loss 2.6629e-01 (9.9939e-02) 
2023-05-27 11:26:27.094933: train Epoch: [25][189/193]	Time  1.158 ( 4.881)	Data  0.598 ( 4.310)	Loss 3.7048e-01 (1.0136e-01) 
2023-05-27 11:26:35.697179: train Epoch: [25][190/193]	Time  8.602 ( 4.901)	Data  8.022 ( 4.329)	Loss 8.3410e-02 (1.0127e-01) 
2023-05-27 11:26:37.303406: train Epoch: [25][191/193]	Time  1.606 ( 4.884)	Data  1.046 ( 4.312)	Loss 1.0756e-01 (1.0130e-01) 
2023-05-27 11:26:44.415080: train Epoch: [25][192/193]	Time  7.112 ( 4.895)	Data  6.524 ( 4.324)	Loss 9.2980e-02 (1.0126e-01) 
2023-05-27 11:26:44.622571: Train Epoch done in 944.957391873002 s 
2023-05-27 11:26:51.802293: val Epoch: [25][ 0/72]	Time  6.013 ( 6.013)	Data  5.860 ( 5.860)	Loss 6.3415e-02 (6.3415e-02) 
2023-05-27 11:26:51.908412: val Epoch: [25][ 1/72]	Time  0.106 ( 3.059)	Data  0.001 ( 2.931)	Loss 1.3114e-01 (9.7277e-02) 
2023-05-27 11:26:56.529839: val Epoch: [25][ 2/72]	Time  4.621 ( 3.580)	Data  4.515 ( 3.459)	Loss 1.4955e-01 (1.1470e-01) 
2023-05-27 11:26:56.635026: val Epoch: [25][ 3/72]	Time  0.105 ( 2.711)	Data  0.000 ( 2.594)	Loss 5.4983e-01 (2.2348e-01) 
2023-05-27 11:27:01.583615: val Epoch: [25][ 4/72]	Time  4.949 ( 3.159)	Data  4.843 ( 3.044)	Loss 1.4584e-01 (2.0795e-01) 
2023-05-27 11:27:01.689292: val Epoch: [25][ 5/72]	Time  0.106 ( 2.650)	Data  0.000 ( 2.537)	Loss 5.8696e-02 (1.8308e-01) 
2023-05-27 11:27:06.519245: val Epoch: [25][ 6/72]	Time  4.830 ( 2.961)	Data  4.724 ( 2.849)	Loss 2.4338e-01 (1.9169e-01) 
2023-05-27 11:27:06.624431: val Epoch: [25][ 7/72]	Time  0.105 ( 2.604)	Data  0.000 ( 2.493)	Loss 5.4679e-02 (1.7457e-01) 
2023-05-27 11:27:11.497057: val Epoch: [25][ 8/72]	Time  4.873 ( 2.856)	Data  4.767 ( 2.746)	Loss 1.1908e-01 (1.6840e-01) 
2023-05-27 11:27:11.602764: val Epoch: [25][ 9/72]	Time  0.106 ( 2.581)	Data  0.000 ( 2.471)	Loss 9.3917e-02 (1.6095e-01) 
2023-05-27 11:27:16.672867: val Epoch: [25][10/72]	Time  5.070 ( 2.808)	Data  4.965 ( 2.698)	Loss 3.1867e-01 (1.7529e-01) 
2023-05-27 11:27:16.778549: val Epoch: [25][11/72]	Time  0.106 ( 2.582)	Data  0.000 ( 2.473)	Loss 5.7164e-02 (1.6545e-01) 
2023-05-27 11:27:21.352482: val Epoch: [25][12/72]	Time  4.574 ( 2.736)	Data  4.468 ( 2.627)	Loss 9.0105e-02 (1.5965e-01) 
2023-05-27 11:27:21.457893: val Epoch: [25][13/72]	Time  0.105 ( 2.548)	Data  0.000 ( 2.439)	Loss 5.1543e-02 (1.5193e-01) 
2023-05-27 11:27:26.617429: val Epoch: [25][14/72]	Time  5.160 ( 2.722)	Data  5.047 ( 2.613)	Loss 3.7071e-01 (1.6651e-01) 
2023-05-27 11:27:26.731316: val Epoch: [25][15/72]	Time  0.114 ( 2.559)	Data  0.001 ( 2.450)	Loss 4.4119e-02 (1.5886e-01) 
2023-05-27 11:27:31.599274: val Epoch: [25][16/72]	Time  4.868 ( 2.695)	Data  4.762 ( 2.586)	Loss 6.0934e-02 (1.5310e-01) 
2023-05-27 11:27:31.704657: val Epoch: [25][17/72]	Time  0.105 ( 2.551)	Data  0.000 ( 2.442)	Loss 9.0370e-02 (1.4962e-01) 
2023-05-27 11:27:36.543074: val Epoch: [25][18/72]	Time  4.838 ( 2.671)	Data  4.733 ( 2.563)	Loss 1.0466e-01 (1.4725e-01) 
2023-05-27 11:27:36.647696: val Epoch: [25][19/72]	Time  0.105 ( 2.543)	Data  0.000 ( 2.434)	Loss 1.1946e-01 (1.4586e-01) 
2023-05-27 11:27:41.791349: val Epoch: [25][20/72]	Time  5.144 ( 2.667)	Data  5.037 ( 2.558)	Loss 1.1089e-01 (1.4420e-01) 
2023-05-27 11:27:41.901284: val Epoch: [25][21/72]	Time  0.110 ( 2.551)	Data  0.001 ( 2.442)	Loss 1.6760e-01 (1.4526e-01) 
2023-05-27 11:27:46.993119: val Epoch: [25][22/72]	Time  5.092 ( 2.661)	Data  4.983 ( 2.553)	Loss 7.4603e-02 (1.4219e-01) 
2023-05-27 11:27:47.101993: val Epoch: [25][23/72]	Time  0.109 ( 2.555)	Data  0.001 ( 2.446)	Loss 4.1483e-01 (1.5355e-01) 
2023-05-27 11:27:51.750543: val Epoch: [25][24/72]	Time  4.649 ( 2.638)	Data  4.538 ( 2.530)	Loss 4.1816e-02 (1.4908e-01) 
2023-05-27 11:27:51.861600: val Epoch: [25][25/72]	Time  0.111 ( 2.541)	Data  0.001 ( 2.433)	Loss 7.2092e-02 (1.4612e-01) 
2023-05-27 11:27:56.878536: val Epoch: [25][26/72]	Time  5.017 ( 2.633)	Data  4.909 ( 2.524)	Loss 1.1593e-01 (1.4500e-01) 
2023-05-27 11:27:56.986368: val Epoch: [25][27/72]	Time  0.108 ( 2.543)	Data  0.001 ( 2.434)	Loss 1.8239e-01 (1.4634e-01) 
2023-05-27 11:28:01.716919: val Epoch: [25][28/72]	Time  4.731 ( 2.618)	Data  4.609 ( 2.509)	Loss 4.3515e-02 (1.4279e-01) 
2023-05-27 11:28:01.871646: val Epoch: [25][29/72]	Time  0.155 ( 2.536)	Data  0.044 ( 2.427)	Loss 6.8527e-02 (1.4032e-01) 
2023-05-27 11:28:06.662566: val Epoch: [25][30/72]	Time  4.791 ( 2.609)	Data  4.684 ( 2.500)	Loss 6.1022e-02 (1.3776e-01) 
2023-05-27 11:28:06.888634: val Epoch: [25][31/72]	Time  0.226 ( 2.534)	Data  0.118 ( 2.425)	Loss 1.9570e-01 (1.3957e-01) 
2023-05-27 11:28:11.436934: val Epoch: [25][32/72]	Time  4.548 ( 2.595)	Data  4.436 ( 2.486)	Loss 5.9399e-02 (1.3714e-01) 
2023-05-27 11:28:11.947752: val Epoch: [25][33/72]	Time  0.511 ( 2.534)	Data  0.403 ( 2.425)	Loss 1.3321e-01 (1.3702e-01) 
2023-05-27 11:28:16.268038: val Epoch: [25][34/72]	Time  4.320 ( 2.585)	Data  4.212 ( 2.476)	Loss 4.7847e-01 (1.4678e-01) 
2023-05-27 11:28:16.642284: val Epoch: [25][35/72]	Time  0.374 ( 2.524)	Data  0.266 ( 2.415)	Loss 6.1609e-02 (1.4441e-01) 
2023-05-27 11:28:21.237696: val Epoch: [25][36/72]	Time  4.595 ( 2.580)	Data  4.487 ( 2.471)	Loss 8.3799e-02 (1.4278e-01) 
2023-05-27 11:28:21.424303: val Epoch: [25][37/72]	Time  0.187 ( 2.517)	Data  0.079 ( 2.408)	Loss 1.1670e-01 (1.4209e-01) 
2023-05-27 11:28:26.245712: val Epoch: [25][38/72]	Time  4.821 ( 2.576)	Data  4.714 ( 2.467)	Loss 6.0670e-02 (1.4000e-01) 
2023-05-27 11:28:26.353340: val Epoch: [25][39/72]	Time  0.108 ( 2.514)	Data  0.001 ( 2.405)	Loss 1.1685e-01 (1.3942e-01) 
2023-05-27 11:28:31.287236: val Epoch: [25][40/72]	Time  4.934 ( 2.573)	Data  4.826 ( 2.464)	Loss 4.7366e-01 (1.4757e-01) 
2023-05-27 11:28:31.395278: val Epoch: [25][41/72]	Time  0.108 ( 2.514)	Data  0.001 ( 2.406)	Loss 1.4009e-01 (1.4740e-01) 
2023-05-27 11:28:36.148698: val Epoch: [25][42/72]	Time  4.753 ( 2.566)	Data  4.648 ( 2.458)	Loss 1.0117e-01 (1.4632e-01) 
2023-05-27 11:28:36.253739: val Epoch: [25][43/72]	Time  0.105 ( 2.511)	Data  0.001 ( 2.402)	Loss 8.4614e-02 (1.4492e-01) 
2023-05-27 11:28:41.381573: val Epoch: [25][44/72]	Time  5.128 ( 2.569)	Data  5.019 ( 2.460)	Loss 6.6620e-02 (1.4318e-01) 
2023-05-27 11:28:41.488394: val Epoch: [25][45/72]	Time  0.107 ( 2.515)	Data  0.000 ( 2.407)	Loss 7.4947e-02 (1.4170e-01) 
2023-05-27 11:28:46.445903: val Epoch: [25][46/72]	Time  4.958 ( 2.567)	Data  4.852 ( 2.459)	Loss 4.9211e-02 (1.3973e-01) 
2023-05-27 11:28:46.551310: val Epoch: [25][47/72]	Time  0.105 ( 2.516)	Data  0.001 ( 2.407)	Loss 5.0867e-02 (1.3788e-01) 
2023-05-27 11:28:51.100830: val Epoch: [25][48/72]	Time  4.550 ( 2.557)	Data  4.443 ( 2.449)	Loss 4.1894e-02 (1.3592e-01) 
2023-05-27 11:28:51.208955: val Epoch: [25][49/72]	Time  0.108 ( 2.508)	Data  0.001 ( 2.400)	Loss 5.0745e-01 (1.4335e-01) 
2023-05-27 11:28:56.204643: val Epoch: [25][50/72]	Time  4.996 ( 2.557)	Data  4.890 ( 2.449)	Loss 8.1891e-02 (1.4214e-01) 
2023-05-27 11:28:56.309363: val Epoch: [25][51/72]	Time  0.105 ( 2.510)	Data  0.000 ( 2.402)	Loss 3.4833e-01 (1.4611e-01) 
2023-05-27 11:29:01.127779: val Epoch: [25][52/72]	Time  4.818 ( 2.554)	Data  4.705 ( 2.445)	Loss 5.4750e-02 (1.4438e-01) 
2023-05-27 11:29:01.235011: val Epoch: [25][53/72]	Time  0.107 ( 2.508)	Data  0.001 ( 2.400)	Loss 8.9905e-02 (1.4338e-01) 
2023-05-27 11:29:05.912268: val Epoch: [25][54/72]	Time  4.677 ( 2.548)	Data  4.572 ( 2.439)	Loss 5.4929e-02 (1.4177e-01) 
2023-05-27 11:29:06.037442: val Epoch: [25][55/72]	Time  0.125 ( 2.504)	Data  0.021 ( 2.396)	Loss 4.1637e-02 (1.3998e-01) 
2023-05-27 11:29:10.889604: val Epoch: [25][56/72]	Time  4.852 ( 2.546)	Data  4.746 ( 2.437)	Loss 1.6320e-01 (1.4039e-01) 
2023-05-27 11:29:11.002753: val Epoch: [25][57/72]	Time  0.113 ( 2.504)	Data  0.009 ( 2.396)	Loss 9.6542e-02 (1.3963e-01) 
2023-05-27 11:29:15.768507: val Epoch: [25][58/72]	Time  4.766 ( 2.542)	Data  4.660 ( 2.434)	Loss 6.8742e-02 (1.3843e-01) 
2023-05-27 11:29:15.987482: val Epoch: [25][59/72]	Time  0.219 ( 2.503)	Data  0.114 ( 2.395)	Loss 2.9554e-01 (1.4105e-01) 
2023-05-27 11:29:20.878994: val Epoch: [25][60/72]	Time  4.892 ( 2.542)	Data  4.786 ( 2.435)	Loss 3.4573e-01 (1.4440e-01) 
2023-05-27 11:29:20.984302: val Epoch: [25][61/72]	Time  0.105 ( 2.503)	Data  0.000 ( 2.395)	Loss 7.3680e-02 (1.4326e-01) 
2023-05-27 11:29:25.849180: val Epoch: [25][62/72]	Time  4.865 ( 2.541)	Data  4.760 ( 2.433)	Loss 1.0585e-01 (1.4267e-01) 
2023-05-27 11:29:25.954629: val Epoch: [25][63/72]	Time  0.105 ( 2.503)	Data  0.000 ( 2.395)	Loss 1.0874e-01 (1.4214e-01) 
2023-05-27 11:29:30.712733: val Epoch: [25][64/72]	Time  4.758 ( 2.537)	Data  4.653 ( 2.430)	Loss 2.0666e-01 (1.4313e-01) 
2023-05-27 11:29:30.817703: val Epoch: [25][65/72]	Time  0.105 ( 2.500)	Data  0.001 ( 2.393)	Loss 5.1536e-02 (1.4174e-01) 
2023-05-27 11:29:35.629431: val Epoch: [25][66/72]	Time  4.812 ( 2.535)	Data  4.706 ( 2.427)	Loss 4.1779e-02 (1.4025e-01) 
2023-05-27 11:29:35.741285: val Epoch: [25][67/72]	Time  0.112 ( 2.499)	Data  0.001 ( 2.392)	Loss 7.6147e-02 (1.3931e-01) 
2023-05-27 11:29:40.515247: val Epoch: [25][68/72]	Time  4.774 ( 2.532)	Data  4.668 ( 2.425)	Loss 2.0606e-01 (1.4028e-01) 
2023-05-27 11:29:40.620447: val Epoch: [25][69/72]	Time  0.105 ( 2.498)	Data  0.000 ( 2.390)	Loss 6.4586e-02 (1.3919e-01) 
2023-05-27 11:29:45.124061: val Epoch: [25][70/72]	Time  4.504 ( 2.526)	Data  4.393 ( 2.418)	Loss 4.5348e-02 (1.3787e-01) 
2023-05-27 11:29:45.232976: val Epoch: [25][71/72]	Time  0.109 ( 2.492)	Data  0.001 ( 2.385)	Loss 7.0776e-02 (1.3694e-01) 
2023-05-27 11:29:45.533161: Epoch 25 :Val : ['ET : 0.7486381530761719', 'TC : 0.7732759118080139', 'WT : 0.8457932472229004'] 
2023-05-27 11:29:45.533903: Epoch 25 :Val : ['ET : 0.7486381530761719', 'TC : 0.7732759118080139', 'WT : 0.8457932472229004'] 
2023-05-27 11:29:45.537514: Val epoch done in 180.91494849399896 s 
2023-05-27 11:29:45.543312: Batches per epoch:  193 
2023-05-27 11:29:56.956633: train Epoch: [26][  0/193]	Time 11.413 (11.413)	Data 10.819 (10.819)	Loss 7.0013e-02 (7.0013e-02) 
2023-05-27 11:29:57.531826: train Epoch: [26][  1/193]	Time  0.575 ( 5.994)	Data  0.001 ( 5.410)	Loss 1.2163e-01 (9.5820e-02) 
2023-05-27 11:30:06.859289: train Epoch: [26][  2/193]	Time  9.327 ( 7.105)	Data  8.740 ( 6.520)	Loss 6.7776e-02 (8.6472e-02) 
2023-05-27 11:30:07.758832: train Epoch: [26][  3/193]	Time  0.900 ( 5.554)	Data  0.317 ( 4.969)	Loss 1.0524e-01 (9.1164e-02) 
2023-05-27 11:30:16.633082: train Epoch: [26][  4/193]	Time  8.874 ( 6.218)	Data  8.306 ( 5.637)	Loss 6.8525e-02 (8.6636e-02) 
2023-05-27 11:30:17.361346: train Epoch: [26][  5/193]	Time  0.728 ( 5.303)	Data  0.155 ( 4.723)	Loss 8.2562e-02 (8.5957e-02) 
2023-05-27 11:30:26.085392: train Epoch: [26][  6/193]	Time  8.724 ( 5.792)	Data  8.162 ( 5.214)	Loss 1.0256e-01 (8.8329e-02) 
2023-05-27 11:30:27.268602: train Epoch: [26][  7/193]	Time  1.183 ( 5.216)	Data  0.587 ( 4.636)	Loss 1.4859e-01 (9.5861e-02) 
2023-05-27 11:30:36.000517: train Epoch: [26][  8/193]	Time  8.732 ( 5.606)	Data  8.160 ( 5.028)	Loss 2.4278e-01 (1.1219e-01) 
2023-05-27 11:30:37.507587: train Epoch: [26][  9/193]	Time  1.507 ( 5.196)	Data  0.922 ( 4.617)	Loss 1.5386e-01 (1.1635e-01) 
2023-05-27 11:30:45.576210: train Epoch: [26][ 10/193]	Time  8.069 ( 5.458)	Data  7.502 ( 4.879)	Loss 1.0703e-01 (1.1551e-01) 
2023-05-27 11:30:47.274298: train Epoch: [26][ 11/193]	Time  1.698 ( 5.144)	Data  1.128 ( 4.567)	Loss 1.2937e-01 (1.1666e-01) 
2023-05-27 11:30:55.570747: train Epoch: [26][ 12/193]	Time  8.296 ( 5.387)	Data  7.728 ( 4.810)	Loss 5.8057e-02 (1.1215e-01) 
2023-05-27 11:30:57.270034: train Epoch: [26][ 13/193]	Time  1.699 ( 5.123)	Data  1.122 ( 4.546)	Loss 7.4833e-02 (1.0949e-01) 
2023-05-27 11:31:05.549023: train Epoch: [26][ 14/193]	Time  8.279 ( 5.334)	Data  7.718 ( 4.758)	Loss 5.8679e-02 (1.0610e-01) 
2023-05-27 11:31:07.294337: train Epoch: [26][ 15/193]	Time  1.745 ( 5.109)	Data  1.118 ( 4.530)	Loss 6.6691e-02 (1.0364e-01) 
2023-05-27 11:31:15.631831: train Epoch: [26][ 16/193]	Time  8.337 ( 5.299)	Data  7.770 ( 4.721)	Loss 5.5236e-02 (1.0079e-01) 
2023-05-27 11:31:17.738654: train Epoch: [26][ 17/193]	Time  2.107 ( 5.122)	Data  1.485 ( 4.541)	Loss 1.6995e-01 (1.0463e-01) 
2023-05-27 11:31:25.265606: train Epoch: [26][ 18/193]	Time  7.527 ( 5.249)	Data  6.962 ( 4.669)	Loss 7.3935e-02 (1.0302e-01) 
2023-05-27 11:31:27.271457: train Epoch: [26][ 19/193]	Time  2.006 ( 5.086)	Data  1.437 ( 4.507)	Loss 1.0286e-01 (1.0301e-01) 
2023-05-27 11:31:35.222349: train Epoch: [26][ 20/193]	Time  7.951 ( 5.223)	Data  7.383 ( 4.644)	Loss 9.6683e-02 (1.0271e-01) 
2023-05-27 11:31:37.211944: train Epoch: [26][ 21/193]	Time  1.990 ( 5.076)	Data  1.429 ( 4.498)	Loss 1.2983e-01 (1.0394e-01) 
2023-05-27 11:31:45.022889: train Epoch: [26][ 22/193]	Time  7.811 ( 5.195)	Data  7.250 ( 4.617)	Loss 9.9228e-02 (1.0374e-01) 
2023-05-27 11:31:46.824494: train Epoch: [26][ 23/193]	Time  1.802 ( 5.053)	Data  1.240 ( 4.477)	Loss 8.7732e-02 (1.0307e-01) 
2023-05-27 11:31:52.800623: train Epoch: [26][ 24/193]	Time  5.976 ( 5.090)	Data  5.416 ( 4.514)	Loss 5.4158e-02 (1.0111e-01) 
2023-05-27 11:31:53.942179: train Epoch: [26][ 25/193]	Time  1.142 ( 4.938)	Data  0.580 ( 4.363)	Loss 1.1195e-01 (1.0153e-01) 
2023-05-27 11:32:01.000300: train Epoch: [26][ 26/193]	Time  7.058 ( 5.017)	Data  6.485 ( 4.442)	Loss 1.2013e-01 (1.0222e-01) 
2023-05-27 11:32:02.062428: train Epoch: [26][ 27/193]	Time  1.062 ( 4.876)	Data  0.499 ( 4.301)	Loss 6.7222e-02 (1.0097e-01) 
2023-05-27 11:32:11.038163: train Epoch: [26][ 28/193]	Time  8.976 ( 5.017)	Data  8.397 ( 4.442)	Loss 9.8327e-02 (1.0088e-01) 
2023-05-27 11:32:11.916726: train Epoch: [26][ 29/193]	Time  0.879 ( 4.879)	Data  0.315 ( 4.304)	Loss 5.3731e-02 (9.9306e-02) 
2023-05-27 11:32:20.832623: train Epoch: [26][ 30/193]	Time  8.916 ( 5.009)	Data  8.355 ( 4.435)	Loss 1.0585e-01 (9.9517e-02) 
2023-05-27 11:32:21.441886: train Epoch: [26][ 31/193]	Time  0.609 ( 4.872)	Data  0.047 ( 4.298)	Loss 1.1665e-01 (1.0005e-01) 
2023-05-27 11:32:30.714513: train Epoch: [26][ 32/193]	Time  9.273 ( 5.005)	Data  8.710 ( 4.432)	Loss 7.6961e-02 (9.9352e-02) 
2023-05-27 11:32:31.287815: train Epoch: [26][ 33/193]	Time  0.573 ( 4.875)	Data  0.001 ( 4.301)	Loss 9.8537e-02 (9.9328e-02) 
2023-05-27 11:32:40.712466: train Epoch: [26][ 34/193]	Time  9.425 ( 5.005)	Data  8.862 ( 4.432)	Loss 9.9441e-02 (9.9332e-02) 
2023-05-27 11:32:41.282159: train Epoch: [26][ 35/193]	Time  0.570 ( 4.882)	Data  0.002 ( 4.309)	Loss 1.1293e-01 (9.9709e-02) 
2023-05-27 11:32:50.708816: train Epoch: [26][ 36/193]	Time  9.427 ( 5.004)	Data  8.858 ( 4.432)	Loss 9.8073e-02 (9.9665e-02) 
2023-05-27 11:32:51.275269: train Epoch: [26][ 37/193]	Time  0.566 ( 4.888)	Data  0.001 ( 4.315)	Loss 7.6705e-02 (9.9061e-02) 
2023-05-27 11:33:00.890893: train Epoch: [26][ 38/193]	Time  9.616 ( 5.009)	Data  9.043 ( 4.436)	Loss 8.3266e-02 (9.8656e-02) 
2023-05-27 11:33:01.458910: train Epoch: [26][ 39/193]	Time  0.568 ( 4.898)	Data  0.001 ( 4.325)	Loss 4.2113e-02 (9.7242e-02) 
2023-05-27 11:33:10.432891: train Epoch: [26][ 40/193]	Time  8.974 ( 4.997)	Data  8.408 ( 4.425)	Loss 6.0210e-02 (9.6339e-02) 
2023-05-27 11:33:10.997387: train Epoch: [26][ 41/193]	Time  0.564 ( 4.892)	Data  0.001 ( 4.320)	Loss 5.0740e-02 (9.5253e-02) 
2023-05-27 11:33:20.266543: train Epoch: [26][ 42/193]	Time  9.269 ( 4.994)	Data  8.708 ( 4.422)	Loss 7.4212e-02 (9.4764e-02) 
2023-05-27 11:33:20.828044: train Epoch: [26][ 43/193]	Time  0.561 ( 4.893)	Data  0.001 ( 4.321)	Loss 6.8863e-02 (9.4175e-02) 
2023-05-27 11:33:30.529579: train Epoch: [26][ 44/193]	Time  9.702 ( 5.000)	Data  9.134 ( 4.428)	Loss 7.2977e-02 (9.3704e-02) 
2023-05-27 11:33:31.100024: train Epoch: [26][ 45/193]	Time  0.570 ( 4.903)	Data  0.001 ( 4.332)	Loss 6.5451e-02 (9.3090e-02) 
2023-05-27 11:33:40.351516: train Epoch: [26][ 46/193]	Time  9.251 ( 4.996)	Data  8.678 ( 4.424)	Loss 7.1401e-02 (9.2629e-02) 
2023-05-27 11:33:40.919523: train Epoch: [26][ 47/193]	Time  0.568 ( 4.904)	Data  0.001 ( 4.332)	Loss 6.3270e-02 (9.2017e-02) 
2023-05-27 11:33:49.824842: train Epoch: [26][ 48/193]	Time  8.905 ( 4.985)	Data  8.339 ( 4.414)	Loss 9.8698e-02 (9.2153e-02) 
2023-05-27 11:33:50.391106: train Epoch: [26][ 49/193]	Time  0.566 ( 4.897)	Data  0.001 ( 4.326)	Loss 1.1125e-01 (9.2535e-02) 
2023-05-27 11:33:59.689851: train Epoch: [26][ 50/193]	Time  9.299 ( 4.983)	Data  8.731 ( 4.412)	Loss 7.7441e-02 (9.2239e-02) 
2023-05-27 11:34:00.257807: train Epoch: [26][ 51/193]	Time  0.568 ( 4.898)	Data  0.001 ( 4.327)	Loss 7.5700e-02 (9.1921e-02) 
2023-05-27 11:34:09.279640: train Epoch: [26][ 52/193]	Time  9.022 ( 4.976)	Data  8.456 ( 4.405)	Loss 8.1355e-02 (9.1722e-02) 
2023-05-27 11:34:09.845623: train Epoch: [26][ 53/193]	Time  0.566 ( 4.894)	Data  0.001 ( 4.324)	Loss 6.1949e-02 (9.1171e-02) 
2023-05-27 11:34:19.158770: train Epoch: [26][ 54/193]	Time  9.313 ( 4.975)	Data  8.750 ( 4.404)	Loss 1.0489e-01 (9.1420e-02) 
2023-05-27 11:34:19.720792: train Epoch: [26][ 55/193]	Time  0.562 ( 4.896)	Data  0.001 ( 4.325)	Loss 9.1089e-02 (9.1414e-02) 
2023-05-27 11:34:28.938382: train Epoch: [26][ 56/193]	Time  9.218 ( 4.972)	Data  8.644 ( 4.401)	Loss 1.6890e-01 (9.2774e-02) 
2023-05-27 11:34:29.511904: train Epoch: [26][ 57/193]	Time  0.574 ( 4.896)	Data  0.001 ( 4.325)	Loss 1.1389e-01 (9.3138e-02) 
2023-05-27 11:34:38.704001: train Epoch: [26][ 58/193]	Time  9.192 ( 4.969)	Data  8.631 ( 4.398)	Loss 1.0841e-01 (9.3397e-02) 
2023-05-27 11:34:39.265519: train Epoch: [26][ 59/193]	Time  0.562 ( 4.895)	Data  0.001 ( 4.325)	Loss 8.0535e-02 (9.3182e-02) 
2023-05-27 11:34:48.107952: train Epoch: [26][ 60/193]	Time  8.842 ( 4.960)	Data  8.282 ( 4.390)	Loss 4.5737e-02 (9.2404e-02) 
2023-05-27 11:34:48.668827: train Epoch: [26][ 61/193]	Time  0.561 ( 4.889)	Data  0.001 ( 4.319)	Loss 6.8344e-02 (9.2016e-02) 
2023-05-27 11:34:57.887717: train Epoch: [26][ 62/193]	Time  9.219 ( 4.958)	Data  8.653 ( 4.388)	Loss 1.2822e-01 (9.2591e-02) 
2023-05-27 11:34:58.466115: train Epoch: [26][ 63/193]	Time  0.578 ( 4.889)	Data  0.001 ( 4.319)	Loss 1.1107e-01 (9.2880e-02) 
2023-05-27 11:35:07.138743: train Epoch: [26][ 64/193]	Time  8.673 ( 4.948)	Data  8.113 ( 4.378)	Loss 5.9791e-02 (9.2371e-02) 
2023-05-27 11:35:07.699648: train Epoch: [26][ 65/193]	Time  0.561 ( 4.881)	Data  0.001 ( 4.311)	Loss 5.2145e-02 (9.1761e-02) 
2023-05-27 11:35:16.633467: train Epoch: [26][ 66/193]	Time  8.934 ( 4.942)	Data  8.355 ( 4.372)	Loss 7.6162e-02 (9.1528e-02) 
2023-05-27 11:35:17.199959: train Epoch: [26][ 67/193]	Time  0.566 ( 4.877)	Data  0.001 ( 4.307)	Loss 8.8802e-02 (9.1488e-02) 
2023-05-27 11:35:26.602955: train Epoch: [26][ 68/193]	Time  9.403 ( 4.943)	Data  8.833 ( 4.373)	Loss 9.3887e-02 (9.1523e-02) 
2023-05-27 11:35:27.168137: train Epoch: [26][ 69/193]	Time  0.565 ( 4.880)	Data  0.001 ( 4.311)	Loss 1.2764e-01 (9.2039e-02) 
2023-05-27 11:35:36.270053: train Epoch: [26][ 70/193]	Time  9.102 ( 4.940)	Data  8.535 ( 4.370)	Loss 8.7756e-02 (9.1979e-02) 
2023-05-27 11:35:36.835247: train Epoch: [26][ 71/193]	Time  0.565 ( 4.879)	Data  0.001 ( 4.309)	Loss 8.4361e-02 (9.1873e-02) 
2023-05-27 11:35:46.309465: train Epoch: [26][ 72/193]	Time  9.474 ( 4.942)	Data  8.896 ( 4.372)	Loss 7.4861e-02 (9.1640e-02) 
2023-05-27 11:35:46.874023: train Epoch: [26][ 73/193]	Time  0.565 ( 4.883)	Data  0.001 ( 4.313)	Loss 1.2163e-01 (9.2045e-02) 
2023-05-27 11:35:56.330639: train Epoch: [26][ 74/193]	Time  9.457 ( 4.944)	Data  8.883 ( 4.374)	Loss 1.0960e-01 (9.2279e-02) 
2023-05-27 11:35:56.890913: train Epoch: [26][ 75/193]	Time  0.560 ( 4.886)	Data  0.001 ( 4.317)	Loss 8.2152e-02 (9.2146e-02) 
2023-05-27 11:36:05.713697: train Epoch: [26][ 76/193]	Time  8.823 ( 4.937)	Data  8.252 ( 4.368)	Loss 6.3848e-02 (9.1778e-02) 
2023-05-27 11:36:06.274436: train Epoch: [26][ 77/193]	Time  0.561 ( 4.881)	Data  0.001 ( 4.312)	Loss 3.8380e-02 (9.1094e-02) 
2023-05-27 11:36:16.020712: train Epoch: [26][ 78/193]	Time  9.746 ( 4.943)	Data  9.175 ( 4.373)	Loss 1.1996e-01 (9.1459e-02) 
2023-05-27 11:36:16.593894: train Epoch: [26][ 79/193]	Time  0.573 ( 4.888)	Data  0.001 ( 4.319)	Loss 7.5599e-02 (9.1261e-02) 
2023-05-27 11:36:25.849555: train Epoch: [26][ 80/193]	Time  9.256 ( 4.942)	Data  8.675 ( 4.372)	Loss 1.0358e-01 (9.1413e-02) 
2023-05-27 11:36:26.423729: train Epoch: [26][ 81/193]	Time  0.574 ( 4.889)	Data  0.001 ( 4.319)	Loss 6.6985e-02 (9.1115e-02) 
2023-05-27 11:36:35.486372: train Epoch: [26][ 82/193]	Time  9.063 ( 4.939)	Data  8.502 ( 4.369)	Loss 7.8509e-02 (9.0963e-02) 
2023-05-27 11:36:36.064954: train Epoch: [26][ 83/193]	Time  0.578 ( 4.887)	Data  0.001 ( 4.317)	Loss 7.7507e-02 (9.0803e-02) 
2023-05-27 11:36:45.542546: train Epoch: [26][ 84/193]	Time  9.478 ( 4.941)	Data  8.907 ( 4.371)	Loss 8.4109e-02 (9.0724e-02) 
2023-05-27 11:36:46.214711: train Epoch: [26][ 85/193]	Time  0.672 ( 4.892)	Data  0.111 ( 4.322)	Loss 6.0494e-02 (9.0373e-02) 
2023-05-27 11:36:55.365749: train Epoch: [26][ 86/193]	Time  9.151 ( 4.940)	Data  8.564 ( 4.371)	Loss 6.8142e-02 (9.0117e-02) 
2023-05-27 11:36:55.933046: train Epoch: [26][ 87/193]	Time  0.567 ( 4.891)	Data  0.001 ( 4.321)	Loss 1.1510e-01 (9.0401e-02) 
2023-05-27 11:37:05.064693: train Epoch: [26][ 88/193]	Time  9.132 ( 4.938)	Data  8.557 ( 4.369)	Loss 6.3005e-02 (9.0093e-02) 
2023-05-27 11:37:05.930263: train Epoch: [26][ 89/193]	Time  0.866 ( 4.893)	Data  0.303 ( 4.323)	Loss 5.3172e-02 (8.9683e-02) 
2023-05-27 11:37:14.205124: train Epoch: [26][ 90/193]	Time  8.275 ( 4.930)	Data  7.713 ( 4.361)	Loss 1.0982e-01 (8.9904e-02) 
2023-05-27 11:37:14.774522: train Epoch: [26][ 91/193]	Time  0.569 ( 4.883)	Data  0.001 ( 4.313)	Loss 8.7239e-02 (8.9875e-02) 
2023-05-27 11:37:22.761181: train Epoch: [26][ 92/193]	Time  7.987 ( 4.916)	Data  7.412 ( 4.347)	Loss 8.6800e-02 (8.9842e-02) 
2023-05-27 11:37:23.347368: train Epoch: [26][ 93/193]	Time  0.586 ( 4.870)	Data  0.001 ( 4.300)	Loss 1.3430e-01 (9.0315e-02) 
2023-05-27 11:37:32.136761: train Epoch: [26][ 94/193]	Time  8.789 ( 4.912)	Data  8.219 ( 4.342)	Loss 1.0726e-01 (9.0494e-02) 
2023-05-27 11:37:33.129453: train Epoch: [26][ 95/193]	Time  0.993 ( 4.871)	Data  0.425 ( 4.301)	Loss 6.0327e-02 (9.0179e-02) 
2023-05-27 11:37:42.085779: train Epoch: [26][ 96/193]	Time  8.956 ( 4.913)	Data  8.389 ( 4.343)	Loss 9.5313e-02 (9.0232e-02) 
2023-05-27 11:37:43.249239: train Epoch: [26][ 97/193]	Time  1.163 ( 4.875)	Data  0.598 ( 4.305)	Loss 1.8486e-01 (9.1198e-02) 
2023-05-27 11:37:52.037162: train Epoch: [26][ 98/193]	Time  8.788 ( 4.914)	Data  8.223 ( 4.344)	Loss 5.8051e-02 (9.0863e-02) 
2023-05-27 11:37:53.162361: train Epoch: [26][ 99/193]	Time  1.125 ( 4.876)	Data  0.560 ( 4.306)	Loss 1.0832e-01 (9.1038e-02) 
2023-05-27 11:38:02.208285: train Epoch: [26][100/193]	Time  9.046 ( 4.917)	Data  8.480 ( 4.348)	Loss 4.2958e-02 (9.0562e-02) 
2023-05-27 11:38:03.114909: train Epoch: [26][101/193]	Time  0.907 ( 4.878)	Data  0.346 ( 4.309)	Loss 5.7622e-02 (9.0239e-02) 
2023-05-27 11:38:11.930486: train Epoch: [26][102/193]	Time  8.816 ( 4.916)	Data  8.252 ( 4.347)	Loss 9.7395e-02 (9.0308e-02) 
2023-05-27 11:38:13.077450: train Epoch: [26][103/193]	Time  1.147 ( 4.880)	Data  0.586 ( 4.311)	Loss 6.4397e-02 (9.0059e-02) 
2023-05-27 11:38:21.840966: train Epoch: [26][104/193]	Time  8.763 ( 4.917)	Data  8.184 ( 4.348)	Loss 1.4516e-01 (9.0584e-02) 
2023-05-27 11:38:22.854295: train Epoch: [26][105/193]	Time  1.013 ( 4.880)	Data  0.453 ( 4.311)	Loss 3.4807e-02 (9.0058e-02) 
2023-05-27 11:38:31.641086: train Epoch: [26][106/193]	Time  8.787 ( 4.917)	Data  8.227 ( 4.347)	Loss 7.3397e-02 (8.9902e-02) 
2023-05-27 11:38:32.885532: train Epoch: [26][107/193]	Time  1.244 ( 4.883)	Data  0.655 ( 4.313)	Loss 1.4031e-01 (9.0369e-02) 
2023-05-27 11:38:41.525785: train Epoch: [26][108/193]	Time  8.640 ( 4.917)	Data  8.079 ( 4.348)	Loss 6.6080e-02 (9.0146e-02) 
2023-05-27 11:38:42.968359: train Epoch: [26][109/193]	Time  1.443 ( 4.886)	Data  0.883 ( 4.316)	Loss 8.9406e-02 (9.0139e-02) 
2023-05-27 11:38:51.737214: train Epoch: [26][110/193]	Time  8.769 ( 4.921)	Data  8.200 ( 4.351)	Loss 9.9688e-02 (9.0225e-02) 
2023-05-27 11:38:52.846447: train Epoch: [26][111/193]	Time  1.109 ( 4.887)	Data  0.550 ( 4.317)	Loss 9.7473e-02 (9.0290e-02) 
2023-05-27 11:39:01.547776: train Epoch: [26][112/193]	Time  8.701 ( 4.920)	Data  8.122 ( 4.351)	Loss 1.1851e-01 (9.0539e-02) 
2023-05-27 11:39:02.367322: train Epoch: [26][113/193]	Time  0.820 ( 4.884)	Data  0.259 ( 4.315)	Loss 1.7182e-01 (9.1252e-02) 
2023-05-27 11:39:11.853809: train Epoch: [26][114/193]	Time  9.486 ( 4.924)	Data  8.916 ( 4.355)	Loss 6.6528e-02 (9.1037e-02) 
2023-05-27 11:39:12.418988: train Epoch: [26][115/193]	Time  0.565 ( 4.887)	Data  0.001 ( 4.318)	Loss 1.8881e-01 (9.1880e-02) 
2023-05-27 11:39:21.923039: train Epoch: [26][116/193]	Time  9.504 ( 4.926)	Data  8.924 ( 4.357)	Loss 1.0868e-01 (9.2024e-02) 
2023-05-27 11:39:22.482792: train Epoch: [26][117/193]	Time  0.560 ( 4.889)	Data  0.001 ( 4.320)	Loss 5.7809e-02 (9.1734e-02) 
2023-05-27 11:39:31.688543: train Epoch: [26][118/193]	Time  9.206 ( 4.926)	Data  8.621 ( 4.356)	Loss 1.1837e-01 (9.1958e-02) 
2023-05-27 11:39:32.417496: train Epoch: [26][119/193]	Time  0.729 ( 4.891)	Data  0.170 ( 4.321)	Loss 8.3916e-02 (9.1891e-02) 
2023-05-27 11:39:41.334160: train Epoch: [26][120/193]	Time  8.917 ( 4.924)	Data  8.356 ( 4.355)	Loss 9.5972e-02 (9.1924e-02) 
2023-05-27 11:39:42.347575: train Epoch: [26][121/193]	Time  1.013 ( 4.892)	Data  0.449 ( 4.323)	Loss 9.1705e-02 (9.1923e-02) 
2023-05-27 11:39:51.676347: train Epoch: [26][122/193]	Time  9.329 ( 4.928)	Data  8.751 ( 4.359)	Loss 7.9733e-02 (9.1824e-02) 
2023-05-27 11:39:52.512945: train Epoch: [26][123/193]	Time  0.837 ( 4.895)	Data  0.277 ( 4.326)	Loss 4.7841e-02 (9.1469e-02) 
2023-05-27 11:40:01.974039: train Epoch: [26][124/193]	Time  9.461 ( 4.931)	Data  8.892 ( 4.362)	Loss 9.0658e-02 (9.1462e-02) 
2023-05-27 11:40:02.536105: train Epoch: [26][125/193]	Time  0.562 ( 4.897)	Data  0.001 ( 4.328)	Loss 1.1086e-01 (9.1616e-02) 
2023-05-27 11:40:11.943304: train Epoch: [26][126/193]	Time  9.407 ( 4.932)	Data  8.838 ( 4.363)	Loss 1.3139e-01 (9.1929e-02) 
2023-05-27 11:40:12.503045: train Epoch: [26][127/193]	Time  0.560 ( 4.898)	Data  0.001 ( 4.329)	Loss 5.0514e-02 (9.1606e-02) 
2023-05-27 11:40:21.587368: train Epoch: [26][128/193]	Time  9.084 ( 4.931)	Data  8.521 ( 4.362)	Loss 1.1750e-01 (9.1807e-02) 
2023-05-27 11:40:22.155716: train Epoch: [26][129/193]	Time  0.568 ( 4.897)	Data  0.001 ( 4.328)	Loss 4.6287e-02 (9.1456e-02) 
2023-05-27 11:40:31.008405: train Epoch: [26][130/193]	Time  8.853 ( 4.927)	Data  8.278 ( 4.358)	Loss 7.9094e-02 (9.1362e-02) 
2023-05-27 11:40:31.829862: train Epoch: [26][131/193]	Time  0.821 ( 4.896)	Data  0.251 ( 4.327)	Loss 1.2564e-01 (9.1622e-02) 
2023-05-27 11:40:41.137253: train Epoch: [26][132/193]	Time  9.307 ( 4.929)	Data  8.726 ( 4.360)	Loss 7.3327e-02 (9.1484e-02) 
2023-05-27 11:40:41.706083: train Epoch: [26][133/193]	Time  0.569 ( 4.897)	Data  0.001 ( 4.328)	Loss 1.7008e-01 (9.2071e-02) 
2023-05-27 11:40:51.321295: train Epoch: [26][134/193]	Time  9.615 ( 4.932)	Data  9.046 ( 4.363)	Loss 6.8644e-02 (9.1897e-02) 
2023-05-27 11:40:51.882639: train Epoch: [26][135/193]	Time  0.561 ( 4.900)	Data  0.001 ( 4.330)	Loss 5.3110e-02 (9.1612e-02) 
2023-05-27 11:41:01.435362: train Epoch: [26][136/193]	Time  9.553 ( 4.934)	Data  8.982 ( 4.364)	Loss 8.9049e-02 (9.1593e-02) 
2023-05-27 11:41:02.001174: train Epoch: [26][137/193]	Time  0.566 ( 4.902)	Data  0.001 ( 4.333)	Loss 4.5536e-02 (9.1260e-02) 
2023-05-27 11:41:11.044249: train Epoch: [26][138/193]	Time  9.043 ( 4.932)	Data  8.470 ( 4.363)	Loss 1.3682e-01 (9.1587e-02) 
2023-05-27 11:41:11.943237: train Epoch: [26][139/193]	Time  0.899 ( 4.903)	Data  0.335 ( 4.334)	Loss 8.6641e-02 (9.1552e-02) 
2023-05-27 11:41:20.854816: train Epoch: [26][140/193]	Time  8.912 ( 4.931)	Data  8.330 ( 4.362)	Loss 1.9573e-01 (9.2291e-02) 
2023-05-27 11:41:22.226766: train Epoch: [26][141/193]	Time  1.372 ( 4.906)	Data  0.811 ( 4.337)	Loss 1.2084e-01 (9.2492e-02) 
2023-05-27 11:41:30.877658: train Epoch: [26][142/193]	Time  8.651 ( 4.932)	Data  8.067 ( 4.363)	Loss 7.3644e-02 (9.2360e-02) 
2023-05-27 11:41:31.893840: train Epoch: [26][143/193]	Time  1.016 ( 4.905)	Data  0.456 ( 4.336)	Loss 1.1271e-01 (9.2501e-02) 
2023-05-27 11:41:40.173260: train Epoch: [26][144/193]	Time  8.279 ( 4.928)	Data  7.711 ( 4.359)	Loss 6.5764e-02 (9.2317e-02) 
2023-05-27 11:41:41.629600: train Epoch: [26][145/193]	Time  1.456 ( 4.905)	Data  0.891 ( 4.336)	Loss 9.9012e-02 (9.2363e-02) 
2023-05-27 11:41:50.357790: train Epoch: [26][146/193]	Time  8.728 ( 4.931)	Data  8.142 ( 4.361)	Loss 1.0553e-01 (9.2452e-02) 
2023-05-27 11:41:50.918235: train Epoch: [26][147/193]	Time  0.560 ( 4.901)	Data  0.001 ( 4.332)	Loss 8.5885e-02 (9.2408e-02) 
2023-05-27 11:42:00.189269: train Epoch: [26][148/193]	Time  9.271 ( 4.931)	Data  8.698 ( 4.361)	Loss 9.9936e-02 (9.2459e-02) 
2023-05-27 11:42:00.750478: train Epoch: [26][149/193]	Time  0.561 ( 4.901)	Data  0.001 ( 4.332)	Loss 5.0898e-02 (9.2182e-02) 
2023-05-27 11:42:09.868513: train Epoch: [26][150/193]	Time  9.118 ( 4.929)	Data  8.511 ( 4.360)	Loss 1.4637e-01 (9.2540e-02) 
2023-05-27 11:42:10.482472: train Epoch: [26][151/193]	Time  0.614 ( 4.901)	Data  0.053 ( 4.332)	Loss 7.1197e-02 (9.2400e-02) 
2023-05-27 11:42:19.437745: train Epoch: [26][152/193]	Time  8.955 ( 4.927)	Data  8.385 ( 4.358)	Loss 8.5998e-02 (9.2358e-02) 
2023-05-27 11:42:20.487472: train Epoch: [26][153/193]	Time  1.050 ( 4.902)	Data  0.490 ( 4.333)	Loss 6.2912e-02 (9.2167e-02) 
2023-05-27 11:42:28.949629: train Epoch: [26][154/193]	Time  8.462 ( 4.925)	Data  7.894 ( 4.356)	Loss 6.6149e-02 (9.1999e-02) 
2023-05-27 11:42:30.623384: train Epoch: [26][155/193]	Time  1.674 ( 4.904)	Data  1.108 ( 4.335)	Loss 5.8599e-02 (9.1785e-02) 
2023-05-27 11:42:39.203836: train Epoch: [26][156/193]	Time  8.580 ( 4.928)	Data  7.999 ( 4.358)	Loss 6.5614e-02 (9.1618e-02) 
2023-05-27 11:42:40.767656: train Epoch: [26][157/193]	Time  1.564 ( 4.906)	Data  1.005 ( 4.337)	Loss 1.8968e-01 (9.2239e-02) 
2023-05-27 11:42:49.104134: train Epoch: [26][158/193]	Time  8.336 ( 4.928)	Data  7.770 ( 4.359)	Loss 1.2327e-01 (9.2434e-02) 
2023-05-27 11:42:50.253479: train Epoch: [26][159/193]	Time  1.149 ( 4.904)	Data  0.564 ( 4.335)	Loss 1.0926e-01 (9.2539e-02) 
2023-05-27 11:42:59.142411: train Epoch: [26][160/193]	Time  8.889 ( 4.929)	Data  8.314 ( 4.360)	Loss 1.4975e-01 (9.2895e-02) 
2023-05-27 11:43:00.008166: train Epoch: [26][161/193]	Time  0.866 ( 4.904)	Data  0.301 ( 4.335)	Loss 1.6098e-01 (9.3315e-02) 
2023-05-27 11:43:08.730213: train Epoch: [26][162/193]	Time  8.722 ( 4.928)	Data  8.147 ( 4.358)	Loss 8.7787e-02 (9.3281e-02) 
2023-05-27 11:43:09.986634: train Epoch: [26][163/193]	Time  1.256 ( 4.905)	Data  0.691 ( 4.336)	Loss 1.7477e-01 (9.3778e-02) 
2023-05-27 11:43:18.693594: train Epoch: [26][164/193]	Time  8.707 ( 4.928)	Data  8.137 ( 4.359)	Loss 9.4236e-02 (9.3781e-02) 
2023-05-27 11:43:19.768502: train Epoch: [26][165/193]	Time  1.075 ( 4.905)	Data  0.511 ( 4.336)	Loss 8.7922e-02 (9.3745e-02) 
2023-05-27 11:43:28.111115: train Epoch: [26][166/193]	Time  8.343 ( 4.926)	Data  7.780 ( 4.356)	Loss 1.0760e-01 (9.3828e-02) 
2023-05-27 11:43:29.695257: train Epoch: [26][167/193]	Time  1.584 ( 4.906)	Data  1.018 ( 4.336)	Loss 9.4804e-02 (9.3834e-02) 
2023-05-27 11:43:38.500781: train Epoch: [26][168/193]	Time  8.806 ( 4.929)	Data  8.233 ( 4.359)	Loss 7.5563e-02 (9.3726e-02) 
2023-05-27 11:43:39.943889: train Epoch: [26][169/193]	Time  1.443 ( 4.908)	Data  0.853 ( 4.339)	Loss 8.5048e-02 (9.3675e-02) 
2023-05-27 11:43:48.717171: train Epoch: [26][170/193]	Time  8.773 ( 4.931)	Data  8.204 ( 4.361)	Loss 9.2320e-02 (9.3667e-02) 
2023-05-27 11:43:49.514095: train Epoch: [26][171/193]	Time  0.797 ( 4.907)	Data  0.226 ( 4.337)	Loss 4.5885e-02 (9.3389e-02) 
2023-05-27 11:43:58.187765: train Epoch: [26][172/193]	Time  8.674 ( 4.929)	Data  8.108 ( 4.359)	Loss 5.7505e-02 (9.3182e-02) 
2023-05-27 11:43:59.392104: train Epoch: [26][173/193]	Time  1.204 ( 4.907)	Data  0.631 ( 4.338)	Loss 6.5578e-02 (9.3023e-02) 
2023-05-27 11:44:08.248217: train Epoch: [26][174/193]	Time  8.856 ( 4.930)	Data  8.295 ( 4.360)	Loss 9.8201e-02 (9.3053e-02) 
2023-05-27 11:44:09.724882: train Epoch: [26][175/193]	Time  1.477 ( 4.910)	Data  0.913 ( 4.341)	Loss 2.5273e-01 (9.3960e-02) 
2023-05-27 11:44:18.478232: train Epoch: [26][176/193]	Time  8.753 ( 4.932)	Data  8.191 ( 4.363)	Loss 6.4249e-02 (9.3792e-02) 
2023-05-27 11:44:19.526147: train Epoch: [26][177/193]	Time  1.048 ( 4.910)	Data  0.486 ( 4.341)	Loss 5.8593e-02 (9.3594e-02) 
2023-05-27 11:44:28.326300: train Epoch: [26][178/193]	Time  8.800 ( 4.932)	Data  8.229 ( 4.362)	Loss 9.1493e-02 (9.3583e-02) 
2023-05-27 11:44:29.348806: train Epoch: [26][179/193]	Time  1.023 ( 4.910)	Data  0.462 ( 4.341)	Loss 6.7970e-02 (9.3440e-02) 
2023-05-27 11:44:38.200744: train Epoch: [26][180/193]	Time  8.852 ( 4.932)	Data  8.283 ( 4.363)	Loss 8.3124e-02 (9.3383e-02) 
2023-05-27 11:44:38.932829: train Epoch: [26][181/193]	Time  0.732 ( 4.909)	Data  0.170 ( 4.340)	Loss 6.3639e-02 (9.3220e-02) 
2023-05-27 11:44:47.626130: train Epoch: [26][182/193]	Time  8.693 ( 4.929)	Data  8.131 ( 4.360)	Loss 5.5852e-02 (9.3016e-02) 
2023-05-27 11:44:48.438468: train Epoch: [26][183/193]	Time  0.812 ( 4.907)	Data  0.248 ( 4.338)	Loss 8.4047e-02 (9.2967e-02) 
2023-05-27 11:44:57.541866: train Epoch: [26][184/193]	Time  9.103 ( 4.930)	Data  8.542 ( 4.361)	Loss 5.5522e-02 (9.2765e-02) 
2023-05-27 11:44:58.105144: train Epoch: [26][185/193]	Time  0.563 ( 4.906)	Data  0.001 ( 4.337)	Loss 7.3127e-02 (9.2659e-02) 
2023-05-27 11:45:07.381188: train Epoch: [26][186/193]	Time  9.276 ( 4.930)	Data  8.711 ( 4.361)	Loss 1.3041e-01 (9.2861e-02) 
2023-05-27 11:45:07.947069: train Epoch: [26][187/193]	Time  0.566 ( 4.906)	Data  0.001 ( 4.337)	Loss 9.2673e-02 (9.2860e-02) 
2023-05-27 11:45:16.768855: train Epoch: [26][188/193]	Time  8.822 ( 4.927)	Data  8.256 ( 4.358)	Loss 7.1977e-02 (9.2749e-02) 
2023-05-27 11:45:17.615003: train Epoch: [26][189/193]	Time  0.846 ( 4.906)	Data  0.284 ( 4.337)	Loss 9.5312e-02 (9.2763e-02) 
2023-05-27 11:45:26.570424: train Epoch: [26][190/193]	Time  8.955 ( 4.927)	Data  8.395 ( 4.358)	Loss 5.8463e-02 (9.2583e-02) 
2023-05-27 11:45:27.170352: train Epoch: [26][191/193]	Time  0.600 ( 4.904)	Data  0.039 ( 4.335)	Loss 9.6542e-02 (9.2604e-02) 
2023-05-27 11:45:35.139528: train Epoch: [26][192/193]	Time  7.969 ( 4.920)	Data  7.397 ( 4.351)	Loss 6.9681e-02 (9.2485e-02) 
2023-05-27 11:45:35.267727: Train Epoch done in 949.7244385259983 s 
2023-05-27 11:45:42.189984: val Epoch: [26][ 0/72]	Time  6.111 ( 6.111)	Data  5.835 ( 5.835)	Loss 7.5788e-02 (7.5788e-02) 
2023-05-27 11:45:42.295609: val Epoch: [26][ 1/72]	Time  0.106 ( 3.108)	Data  0.001 ( 2.918)	Loss 4.1369e-01 (2.4474e-01) 
2023-05-27 11:45:46.819373: val Epoch: [26][ 2/72]	Time  4.524 ( 3.580)	Data  4.404 ( 3.413)	Loss 6.3875e-02 (1.8445e-01) 
2023-05-27 11:45:46.929322: val Epoch: [26][ 3/72]	Time  0.110 ( 2.713)	Data  0.000 ( 2.560)	Loss 4.6893e-01 (2.5557e-01) 
2023-05-27 11:45:51.597484: val Epoch: [26][ 4/72]	Time  4.668 ( 3.104)	Data  4.559 ( 2.960)	Loss 9.8189e-02 (2.2409e-01) 
2023-05-27 11:45:51.853858: val Epoch: [26][ 5/72]	Time  0.256 ( 2.629)	Data  0.151 ( 2.492)	Loss 4.2824e-01 (2.5812e-01) 
2023-05-27 11:45:56.693400: val Epoch: [26][ 6/72]	Time  4.840 ( 2.945)	Data  4.734 ( 2.812)	Loss 1.2537e-01 (2.3915e-01) 
2023-05-27 11:45:56.798542: val Epoch: [26][ 7/72]	Time  0.105 ( 2.590)	Data  0.000 ( 2.461)	Loss 9.1415e-02 (2.2069e-01) 
2023-05-27 11:46:01.432024: val Epoch: [26][ 8/72]	Time  4.633 ( 2.817)	Data  4.524 ( 2.690)	Loss 4.7619e-02 (2.0146e-01) 
2023-05-27 11:46:01.641870: val Epoch: [26][ 9/72]	Time  0.210 ( 2.556)	Data  0.095 ( 2.430)	Loss 3.9610e-01 (2.2092e-01) 
2023-05-27 11:46:06.242354: val Epoch: [26][10/72]	Time  4.600 ( 2.742)	Data  4.495 ( 2.618)	Loss 5.4636e-02 (2.0580e-01) 
2023-05-27 11:46:06.587373: val Epoch: [26][11/72]	Time  0.345 ( 2.542)	Data  0.240 ( 2.420)	Loss 4.2736e-02 (1.9222e-01) 
2023-05-27 11:46:11.301087: val Epoch: [26][12/72]	Time  4.714 ( 2.709)	Data  4.599 ( 2.587)	Loss 1.0844e-01 (1.8577e-01) 
2023-05-27 11:46:11.424990: val Epoch: [26][13/72]	Time  0.124 ( 2.525)	Data  0.018 ( 2.404)	Loss 3.9659e-02 (1.7534e-01) 
2023-05-27 11:46:16.363808: val Epoch: [26][14/72]	Time  4.939 ( 2.686)	Data  4.831 ( 2.566)	Loss 2.9338e-01 (1.8320e-01) 
2023-05-27 11:46:16.471793: val Epoch: [26][15/72]	Time  0.108 ( 2.525)	Data  0.001 ( 2.405)	Loss 2.1903e-01 (1.8544e-01) 
2023-05-27 11:46:21.445610: val Epoch: [26][16/72]	Time  4.974 ( 2.669)	Data  4.855 ( 2.550)	Loss 4.8538e-02 (1.7739e-01) 
2023-05-27 11:46:21.576114: val Epoch: [26][17/72]	Time  0.130 ( 2.528)	Data  0.002 ( 2.408)	Loss 5.9120e-02 (1.7082e-01) 
2023-05-27 11:46:26.326446: val Epoch: [26][18/72]	Time  4.750 ( 2.645)	Data  4.645 ( 2.526)	Loss 5.3221e-02 (1.6463e-01) 
2023-05-27 11:46:26.431762: val Epoch: [26][19/72]	Time  0.105 ( 2.518)	Data  0.000 ( 2.399)	Loss 3.2384e-01 (1.7259e-01) 
2023-05-27 11:46:31.234225: val Epoch: [26][20/72]	Time  4.802 ( 2.626)	Data  4.692 ( 2.509)	Loss 7.2772e-02 (1.6784e-01) 
2023-05-27 11:46:31.342987: val Epoch: [26][21/72]	Time  0.109 ( 2.512)	Data  0.001 ( 2.395)	Loss 3.8499e-02 (1.6196e-01) 
2023-05-27 11:46:36.041471: val Epoch: [26][22/72]	Time  4.698 ( 2.607)	Data  4.590 ( 2.490)	Loss 9.0540e-02 (1.5885e-01) 
2023-05-27 11:46:36.149271: val Epoch: [26][23/72]	Time  0.108 ( 2.503)	Data  0.001 ( 2.386)	Loss 1.9261e-01 (1.6026e-01) 
2023-05-27 11:46:40.965276: val Epoch: [26][24/72]	Time  4.816 ( 2.595)	Data  4.701 ( 2.479)	Loss 6.6123e-02 (1.5649e-01) 
2023-05-27 11:46:41.075181: val Epoch: [26][25/72]	Time  0.110 ( 2.500)	Data  0.001 ( 2.384)	Loss 1.0647e-01 (1.5457e-01) 
2023-05-27 11:46:45.869678: val Epoch: [26][26/72]	Time  4.795 ( 2.585)	Data  4.689 ( 2.469)	Loss 6.1165e-02 (1.5111e-01) 
2023-05-27 11:46:45.974993: val Epoch: [26][27/72]	Time  0.105 ( 2.496)	Data  0.001 ( 2.381)	Loss 2.8948e-01 (1.5605e-01) 
2023-05-27 11:46:51.179897: val Epoch: [26][28/72]	Time  5.205 ( 2.590)	Data  5.092 ( 2.474)	Loss 6.4681e-02 (1.5290e-01) 
2023-05-27 11:46:51.289495: val Epoch: [26][29/72]	Time  0.110 ( 2.507)	Data  0.001 ( 2.392)	Loss 4.6404e-02 (1.4935e-01) 
2023-05-27 11:46:56.278495: val Epoch: [26][30/72]	Time  4.989 ( 2.587)	Data  4.880 ( 2.472)	Loss 3.6494e-01 (1.5631e-01) 
2023-05-27 11:46:56.402117: val Epoch: [26][31/72]	Time  0.124 ( 2.510)	Data  0.001 ( 2.395)	Loss 1.0427e-01 (1.5468e-01) 
2023-05-27 11:47:01.253164: val Epoch: [26][32/72]	Time  4.851 ( 2.581)	Data  4.742 ( 2.466)	Loss 5.9507e-02 (1.5180e-01) 
2023-05-27 11:47:01.363111: val Epoch: [26][33/72]	Time  0.110 ( 2.508)	Data  0.001 ( 2.394)	Loss 3.4701e-01 (1.5754e-01) 
2023-05-27 11:47:06.333092: val Epoch: [26][34/72]	Time  4.970 ( 2.579)	Data  4.862 ( 2.464)	Loss 8.0902e-02 (1.5535e-01) 
2023-05-27 11:47:06.442643: val Epoch: [26][35/72]	Time  0.110 ( 2.510)	Data  0.001 ( 2.396)	Loss 6.2331e-02 (1.5276e-01) 
2023-05-27 11:47:11.269423: val Epoch: [26][36/72]	Time  4.827 ( 2.573)	Data  4.673 ( 2.457)	Loss 1.4662e-01 (1.5260e-01) 
2023-05-27 11:47:11.412613: val Epoch: [26][37/72]	Time  0.143 ( 2.509)	Data  0.002 ( 2.393)	Loss 6.1979e-02 (1.5021e-01) 
2023-05-27 11:47:16.089684: val Epoch: [26][38/72]	Time  4.677 ( 2.564)	Data  4.568 ( 2.448)	Loss 7.5149e-02 (1.4829e-01) 
2023-05-27 11:47:16.197787: val Epoch: [26][39/72]	Time  0.108 ( 2.503)	Data  0.001 ( 2.387)	Loss 4.8769e-02 (1.4580e-01) 
2023-05-27 11:47:20.992345: val Epoch: [26][40/72]	Time  4.795 ( 2.559)	Data  4.687 ( 2.443)	Loss 2.2518e-01 (1.4774e-01) 
2023-05-27 11:47:21.114136: val Epoch: [26][41/72]	Time  0.122 ( 2.501)	Data  0.001 ( 2.385)	Loss 3.6177e-01 (1.5283e-01) 
2023-05-27 11:47:25.681401: val Epoch: [26][42/72]	Time  4.567 ( 2.549)	Data  4.459 ( 2.433)	Loss 5.4426e-02 (1.5054e-01) 
2023-05-27 11:47:25.789492: val Epoch: [26][43/72]	Time  0.108 ( 2.493)	Data  0.001 ( 2.378)	Loss 1.8336e-01 (1.5129e-01) 
2023-05-27 11:47:30.345958: val Epoch: [26][44/72]	Time  4.556 ( 2.539)	Data  4.448 ( 2.424)	Loss 7.9804e-02 (1.4970e-01) 
2023-05-27 11:47:30.453758: val Epoch: [26][45/72]	Time  0.108 ( 2.486)	Data  0.001 ( 2.371)	Loss 1.7908e-01 (1.5034e-01) 
2023-05-27 11:47:35.313563: val Epoch: [26][46/72]	Time  4.860 ( 2.537)	Data  4.751 ( 2.422)	Loss 5.7221e-02 (1.4836e-01) 
2023-05-27 11:47:35.422277: val Epoch: [26][47/72]	Time  0.109 ( 2.486)	Data  0.001 ( 2.372)	Loss 1.3999e-01 (1.4818e-01) 
2023-05-27 11:47:40.489843: val Epoch: [26][48/72]	Time  5.068 ( 2.539)	Data  4.954 ( 2.424)	Loss 5.4720e-01 (1.5633e-01) 
2023-05-27 11:47:40.602548: val Epoch: [26][49/72]	Time  0.113 ( 2.490)	Data  0.001 ( 2.376)	Loss 8.9967e-02 (1.5500e-01) 
2023-05-27 11:47:45.631344: val Epoch: [26][50/72]	Time  5.029 ( 2.540)	Data  4.920 ( 2.426)	Loss 8.4153e-02 (1.5361e-01) 
2023-05-27 11:47:45.741371: val Epoch: [26][51/72]	Time  0.110 ( 2.494)	Data  0.001 ( 2.379)	Loss 1.1116e-01 (1.5279e-01) 
2023-05-27 11:47:50.726569: val Epoch: [26][52/72]	Time  4.985 ( 2.541)	Data  4.878 ( 2.426)	Loss 2.8654e-01 (1.5532e-01) 
2023-05-27 11:47:50.834190: val Epoch: [26][53/72]	Time  0.108 ( 2.495)	Data  0.001 ( 2.381)	Loss 8.3675e-02 (1.5399e-01) 
2023-05-27 11:47:55.710473: val Epoch: [26][54/72]	Time  4.876 ( 2.539)	Data  4.768 ( 2.425)	Loss 1.0061e-01 (1.5302e-01) 
2023-05-27 11:47:55.819346: val Epoch: [26][55/72]	Time  0.109 ( 2.495)	Data  0.001 ( 2.381)	Loss 1.2671e-01 (1.5255e-01) 
2023-05-27 11:48:00.534431: val Epoch: [26][56/72]	Time  4.715 ( 2.534)	Data  4.608 ( 2.420)	Loss 5.8549e-02 (1.5090e-01) 
2023-05-27 11:48:00.642356: val Epoch: [26][57/72]	Time  0.108 ( 2.492)	Data  0.001 ( 2.379)	Loss 1.0695e-01 (1.5014e-01) 
2023-05-27 11:48:05.133325: val Epoch: [26][58/72]	Time  4.491 ( 2.526)	Data  4.383 ( 2.413)	Loss 4.8654e-02 (1.4842e-01) 
2023-05-27 11:48:05.241307: val Epoch: [26][59/72]	Time  0.108 ( 2.486)	Data  0.001 ( 2.372)	Loss 1.1198e-01 (1.4782e-01) 
2023-05-27 11:48:09.921876: val Epoch: [26][60/72]	Time  4.681 ( 2.522)	Data  4.572 ( 2.409)	Loss 4.4147e-02 (1.4612e-01) 
2023-05-27 11:48:10.143843: val Epoch: [26][61/72]	Time  0.222 ( 2.485)	Data  0.113 ( 2.372)	Loss 1.6055e-01 (1.4635e-01) 
2023-05-27 11:48:14.763262: val Epoch: [26][62/72]	Time  4.619 ( 2.519)	Data  4.511 ( 2.405)	Loss 1.0748e-01 (1.4573e-01) 
2023-05-27 11:48:15.160812: val Epoch: [26][63/72]	Time  0.398 ( 2.486)	Data  0.289 ( 2.372)	Loss 1.3379e-01 (1.4555e-01) 
2023-05-27 11:48:19.643686: val Epoch: [26][64/72]	Time  4.483 ( 2.516)	Data  4.374 ( 2.403)	Loss 1.3246e-01 (1.4535e-01) 
2023-05-27 11:48:20.593752: val Epoch: [26][65/72]	Time  0.950 ( 2.493)	Data  0.842 ( 2.380)	Loss 5.5797e-02 (1.4399e-01) 
2023-05-27 11:48:24.525030: val Epoch: [26][66/72]	Time  3.931 ( 2.514)	Data  3.826 ( 2.401)	Loss 1.4634e-01 (1.4402e-01) 
2023-05-27 11:48:25.338813: val Epoch: [26][67/72]	Time  0.814 ( 2.489)	Data  0.707 ( 2.376)	Loss 9.0016e-02 (1.4323e-01) 
2023-05-27 11:48:29.668162: val Epoch: [26][68/72]	Time  4.329 ( 2.516)	Data  4.220 ( 2.403)	Loss 7.0440e-02 (1.4217e-01) 
2023-05-27 11:48:30.339501: val Epoch: [26][69/72]	Time  0.671 ( 2.489)	Data  0.565 ( 2.377)	Loss 9.5092e-02 (1.4150e-01) 
2023-05-27 11:48:34.836168: val Epoch: [26][70/72]	Time  4.497 ( 2.518)	Data  4.392 ( 2.405)	Loss 7.4566e-02 (1.4056e-01) 
2023-05-27 11:48:35.209988: val Epoch: [26][71/72]	Time  0.374 ( 2.488)	Data  0.268 ( 2.375)	Loss 5.7381e-02 (1.3940e-01) 
2023-05-27 11:48:35.607552: Epoch 26 :Val : ['ET : 0.7115843892097473', 'TC : 0.7695308327674866', 'WT : 0.8510317802429199'] 
2023-05-27 11:48:35.613055: Epoch 26 :Val : ['ET : 0.7115843892097473', 'TC : 0.7695308327674866', 'WT : 0.8510317802429199'] 
2023-05-27 11:48:35.615208: Val epoch done in 180.34748936397955 s 
2023-05-27 11:48:35.620983: Batches per epoch:  193 
2023-05-27 11:48:46.802687: train Epoch: [27][  0/193]	Time 11.181 (11.181)	Data 10.576 (10.576)	Loss 7.4423e-02 (7.4423e-02) 
2023-05-27 11:48:47.378620: train Epoch: [27][  1/193]	Time  0.576 ( 5.879)	Data  0.001 ( 5.289)	Loss 7.6094e-02 (7.5258e-02) 
2023-05-27 11:48:56.921909: train Epoch: [27][  2/193]	Time  9.543 ( 7.100)	Data  8.978 ( 6.519)	Loss 5.9716e-02 (7.0078e-02) 
2023-05-27 11:48:57.490481: train Epoch: [27][  3/193]	Time  0.569 ( 5.467)	Data  0.001 ( 4.889)	Loss 8.3877e-02 (7.3527e-02) 
2023-05-27 11:49:06.754120: train Epoch: [27][  4/193]	Time  9.264 ( 6.227)	Data  8.674 ( 5.646)	Loss 6.3487e-02 (7.1519e-02) 
2023-05-27 11:49:07.333067: train Epoch: [27][  5/193]	Time  0.579 ( 5.285)	Data  0.001 ( 4.705)	Loss 1.0541e-01 (7.7167e-02) 
2023-05-27 11:49:16.731119: train Epoch: [27][  6/193]	Time  9.398 ( 5.873)	Data  8.817 ( 5.293)	Loss 4.3424e-02 (7.2347e-02) 
2023-05-27 11:49:17.304285: train Epoch: [27][  7/193]	Time  0.573 ( 5.210)	Data  0.001 ( 4.631)	Loss 8.5315e-02 (7.3968e-02) 
2023-05-27 11:49:26.827088: train Epoch: [27][  8/193]	Time  9.523 ( 5.690)	Data  8.947 ( 5.111)	Loss 7.7649e-02 (7.4377e-02) 
2023-05-27 11:49:27.401490: train Epoch: [27][  9/193]	Time  0.574 ( 5.178)	Data  0.001 ( 4.600)	Loss 9.6624e-02 (7.6601e-02) 
2023-05-27 11:49:36.592287: train Epoch: [27][ 10/193]	Time  9.191 ( 5.543)	Data  8.608 ( 4.964)	Loss 1.2069e-01 (8.0609e-02) 
2023-05-27 11:49:37.160712: train Epoch: [27][ 11/193]	Time  0.568 ( 5.128)	Data  0.001 ( 4.551)	Loss 3.2774e-01 (1.0120e-01) 
2023-05-27 11:49:46.306207: train Epoch: [27][ 12/193]	Time  9.145 ( 5.437)	Data  8.574 ( 4.860)	Loss 5.4576e-02 (9.7617e-02) 
2023-05-27 11:49:46.872342: train Epoch: [27][ 13/193]	Time  0.566 ( 5.089)	Data  0.001 ( 4.513)	Loss 1.6698e-01 (1.0257e-01) 
2023-05-27 11:49:55.832252: train Epoch: [27][ 14/193]	Time  8.960 ( 5.347)	Data  8.393 ( 4.772)	Loss 7.5088e-02 (1.0074e-01) 
2023-05-27 11:49:56.405944: train Epoch: [27][ 15/193]	Time  0.574 ( 5.049)	Data  0.001 ( 4.473)	Loss 9.4119e-02 (1.0033e-01) 
2023-05-27 11:50:05.901682: train Epoch: [27][ 16/193]	Time  9.496 ( 5.311)	Data  8.918 ( 4.735)	Loss 1.0333e-01 (1.0050e-01) 
2023-05-27 11:50:06.474015: train Epoch: [27][ 17/193]	Time  0.572 ( 5.047)	Data  0.001 ( 4.472)	Loss 7.7169e-02 (9.9206e-02) 
2023-05-27 11:50:15.989618: train Epoch: [27][ 18/193]	Time  9.516 ( 5.283)	Data  8.922 ( 4.706)	Loss 1.4345e-01 (1.0153e-01) 
2023-05-27 11:50:16.563152: train Epoch: [27][ 19/193]	Time  0.574 ( 5.047)	Data  0.001 ( 4.471)	Loss 9.9003e-02 (1.0141e-01) 
2023-05-27 11:50:25.881709: train Epoch: [27][ 20/193]	Time  9.319 ( 5.250)	Data  8.749 ( 4.675)	Loss 5.7956e-02 (9.9339e-02) 
2023-05-27 11:50:26.453489: train Epoch: [27][ 21/193]	Time  0.572 ( 5.038)	Data  0.001 ( 4.462)	Loss 7.7246e-02 (9.8335e-02) 
2023-05-27 11:50:36.269048: train Epoch: [27][ 22/193]	Time  9.816 ( 5.246)	Data  9.191 ( 4.668)	Loss 7.8276e-02 (9.7463e-02) 
2023-05-27 11:50:36.831576: train Epoch: [27][ 23/193]	Time  0.563 ( 5.050)	Data  0.001 ( 4.473)	Loss 1.1115e-01 (9.8033e-02) 
2023-05-27 11:50:46.167667: train Epoch: [27][ 24/193]	Time  9.336 ( 5.222)	Data  8.742 ( 4.644)	Loss 4.5653e-02 (9.5938e-02) 
2023-05-27 11:50:46.742830: train Epoch: [27][ 25/193]	Time  0.575 ( 5.043)	Data  0.001 ( 4.465)	Loss 7.0101e-02 (9.4944e-02) 
2023-05-27 11:50:52.992034: train Epoch: [27][ 26/193]	Time  6.249 ( 5.088)	Data  5.689 ( 4.511)	Loss 6.7780e-02 (9.3938e-02) 
2023-05-27 11:50:53.552415: train Epoch: [27][ 27/193]	Time  0.560 ( 4.926)	Data  0.001 ( 4.350)	Loss 6.2726e-02 (9.2823e-02) 
2023-05-27 11:51:01.459179: train Epoch: [27][ 28/193]	Time  7.907 ( 5.029)	Data  7.341 ( 4.453)	Loss 7.0647e-02 (9.2059e-02) 
2023-05-27 11:51:02.041594: train Epoch: [27][ 29/193]	Time  0.582 ( 4.881)	Data  0.001 ( 4.304)	Loss 9.2278e-02 (9.2066e-02) 
2023-05-27 11:51:11.124047: train Epoch: [27][ 30/193]	Time  9.082 ( 5.016)	Data  8.520 ( 4.440)	Loss 5.6906e-02 (9.0932e-02) 
2023-05-27 11:51:11.685705: train Epoch: [27][ 31/193]	Time  0.562 ( 4.877)	Data  0.001 ( 4.302)	Loss 1.6285e-01 (9.3179e-02) 
2023-05-27 11:51:21.027801: train Epoch: [27][ 32/193]	Time  9.342 ( 5.012)	Data  8.782 ( 4.437)	Loss 1.1369e-01 (9.3801e-02) 
2023-05-27 11:51:21.588534: train Epoch: [27][ 33/193]	Time  0.561 ( 4.881)	Data  0.001 ( 4.307)	Loss 9.9775e-02 (9.3976e-02) 
2023-05-27 11:51:30.890977: train Epoch: [27][ 34/193]	Time  9.302 ( 5.008)	Data  8.729 ( 4.433)	Loss 1.1783e-01 (9.4658e-02) 
2023-05-27 11:51:31.459366: train Epoch: [27][ 35/193]	Time  0.568 ( 4.884)	Data  0.001 ( 4.310)	Loss 9.3374e-02 (9.4622e-02) 
2023-05-27 11:51:40.893510: train Epoch: [27][ 36/193]	Time  9.434 ( 5.007)	Data  8.874 ( 4.434)	Loss 5.2062e-02 (9.3472e-02) 
2023-05-27 11:51:41.456438: train Epoch: [27][ 37/193]	Time  0.563 ( 4.890)	Data  0.001 ( 4.317)	Loss 1.3517e-01 (9.4569e-02) 
2023-05-27 11:51:50.823872: train Epoch: [27][ 38/193]	Time  9.367 ( 5.005)	Data  8.806 ( 4.432)	Loss 5.9659e-02 (9.3674e-02) 
2023-05-27 11:51:51.386497: train Epoch: [27][ 39/193]	Time  0.563 ( 4.894)	Data  0.001 ( 4.321)	Loss 7.0980e-02 (9.3107e-02) 
2023-05-27 11:52:00.162673: train Epoch: [27][ 40/193]	Time  8.776 ( 4.989)	Data  8.214 ( 4.416)	Loss 5.8512e-02 (9.2263e-02) 
2023-05-27 11:52:00.731989: train Epoch: [27][ 41/193]	Time  0.569 ( 4.884)	Data  0.001 ( 4.311)	Loss 8.8787e-02 (9.2180e-02) 
2023-05-27 11:52:10.388855: train Epoch: [27][ 42/193]	Time  9.657 ( 4.995)	Data  9.095 ( 4.422)	Loss 7.5972e-02 (9.1803e-02) 
2023-05-27 11:52:10.950162: train Epoch: [27][ 43/193]	Time  0.561 ( 4.894)	Data  0.001 ( 4.322)	Loss 8.6120e-02 (9.1674e-02) 
2023-05-27 11:52:19.824081: train Epoch: [27][ 44/193]	Time  8.874 ( 4.982)	Data  8.307 ( 4.410)	Loss 8.2762e-02 (9.1476e-02) 
2023-05-27 11:52:20.385153: train Epoch: [27][ 45/193]	Time  0.561 ( 4.886)	Data  0.001 ( 4.315)	Loss 1.2044e-01 (9.2106e-02) 
2023-05-27 11:52:29.564871: train Epoch: [27][ 46/193]	Time  9.180 ( 4.978)	Data  8.619 ( 4.406)	Loss 1.0651e-01 (9.2412e-02) 
2023-05-27 11:52:30.125830: train Epoch: [27][ 47/193]	Time  0.561 ( 4.886)	Data  0.001 ( 4.314)	Loss 1.6862e-01 (9.4000e-02) 
2023-05-27 11:52:39.277353: train Epoch: [27][ 48/193]	Time  9.152 ( 4.973)	Data  8.585 ( 4.402)	Loss 5.2917e-02 (9.3161e-02) 
2023-05-27 11:52:39.843660: train Epoch: [27][ 49/193]	Time  0.566 ( 4.884)	Data  0.001 ( 4.313)	Loss 9.9668e-02 (9.3292e-02) 
2023-05-27 11:52:49.863013: train Epoch: [27][ 50/193]	Time 10.019 ( 4.985)	Data  9.453 ( 4.414)	Loss 5.9140e-02 (9.2622e-02) 
2023-05-27 11:52:50.428818: train Epoch: [27][ 51/193]	Time  0.566 ( 4.900)	Data  0.001 ( 4.329)	Loss 7.3195e-02 (9.2248e-02) 
2023-05-27 11:52:59.789123: train Epoch: [27][ 52/193]	Time  9.360 ( 4.984)	Data  8.791 ( 4.414)	Loss 2.0986e-01 (9.4467e-02) 
2023-05-27 11:53:00.352016: train Epoch: [27][ 53/193]	Time  0.563 ( 4.902)	Data  0.001 ( 4.332)	Loss 7.5783e-02 (9.4121e-02) 
2023-05-27 11:53:09.705817: train Epoch: [27][ 54/193]	Time  9.354 ( 4.983)	Data  8.784 ( 4.413)	Loss 2.8941e-01 (9.7672e-02) 
2023-05-27 11:53:10.268004: train Epoch: [27][ 55/193]	Time  0.562 ( 4.904)	Data  0.001 ( 4.334)	Loss 1.1780e-01 (9.8031e-02) 
2023-05-27 11:53:19.162763: train Epoch: [27][ 56/193]	Time  8.895 ( 4.974)	Data  8.328 ( 4.404)	Loss 8.8950e-02 (9.7872e-02) 
2023-05-27 11:53:19.730735: train Epoch: [27][ 57/193]	Time  0.568 ( 4.898)	Data  0.001 ( 4.328)	Loss 4.8190e-02 (9.7016e-02) 
2023-05-27 11:53:29.205073: train Epoch: [27][ 58/193]	Time  9.474 ( 4.976)	Data  8.906 ( 4.406)	Loss 5.5881e-02 (9.6318e-02) 
2023-05-27 11:53:29.766170: train Epoch: [27][ 59/193]	Time  0.561 ( 4.902)	Data  0.001 ( 4.332)	Loss 2.2107e-01 (9.8398e-02) 
2023-05-27 11:53:39.471458: train Epoch: [27][ 60/193]	Time  9.705 ( 4.981)	Data  9.145 ( 4.411)	Loss 8.8518e-02 (9.8236e-02) 
2023-05-27 11:53:40.033995: train Epoch: [27][ 61/193]	Time  0.563 ( 4.910)	Data  0.001 ( 4.340)	Loss 9.9010e-02 (9.8248e-02) 
2023-05-27 11:53:49.491387: train Epoch: [27][ 62/193]	Time  9.457 ( 4.982)	Data  8.879 ( 4.412)	Loss 7.8403e-02 (9.7933e-02) 
2023-05-27 11:53:50.058163: train Epoch: [27][ 63/193]	Time  0.567 ( 4.913)	Data  0.001 ( 4.343)	Loss 5.5049e-02 (9.7263e-02) 
2023-05-27 11:53:58.741004: train Epoch: [27][ 64/193]	Time  8.683 ( 4.971)	Data  8.118 ( 4.401)	Loss 1.0625e-01 (9.7401e-02) 
2023-05-27 11:53:59.308428: train Epoch: [27][ 65/193]	Time  0.567 ( 4.904)	Data  0.001 ( 4.335)	Loss 5.4801e-02 (9.6756e-02) 
2023-05-27 11:54:08.372826: train Epoch: [27][ 66/193]	Time  9.064 ( 4.966)	Data  8.498 ( 4.397)	Loss 9.1254e-02 (9.6674e-02) 
2023-05-27 11:54:08.939954: train Epoch: [27][ 67/193]	Time  0.567 ( 4.902)	Data  0.001 ( 4.332)	Loss 7.2180e-02 (9.6314e-02) 
2023-05-27 11:54:18.267199: train Epoch: [27][ 68/193]	Time  9.327 ( 4.966)	Data  8.757 ( 4.396)	Loss 4.9723e-02 (9.5638e-02) 
2023-05-27 11:54:18.829038: train Epoch: [27][ 69/193]	Time  0.562 ( 4.903)	Data  0.001 ( 4.333)	Loss 9.4821e-02 (9.5627e-02) 
2023-05-27 11:54:27.616914: train Epoch: [27][ 70/193]	Time  8.788 ( 4.958)	Data  8.212 ( 4.388)	Loss 1.0673e-01 (9.5783e-02) 
2023-05-27 11:54:28.184000: train Epoch: [27][ 71/193]	Time  0.567 ( 4.897)	Data  0.001 ( 4.327)	Loss 1.5541e-01 (9.6611e-02) 
2023-05-27 11:54:37.682722: train Epoch: [27][ 72/193]	Time  9.499 ( 4.960)	Data  8.925 ( 4.390)	Loss 1.1565e-01 (9.6872e-02) 
2023-05-27 11:54:38.243167: train Epoch: [27][ 73/193]	Time  0.560 ( 4.900)	Data  0.001 ( 4.331)	Loss 1.6857e-01 (9.7841e-02) 
2023-05-27 11:54:47.687695: train Epoch: [27][ 74/193]	Time  9.445 ( 4.961)	Data  8.883 ( 4.392)	Loss 6.4437e-02 (9.7396e-02) 
2023-05-27 11:54:48.247937: train Epoch: [27][ 75/193]	Time  0.560 ( 4.903)	Data  0.001 ( 4.334)	Loss 7.5280e-02 (9.7105e-02) 
2023-05-27 11:54:57.507385: train Epoch: [27][ 76/193]	Time  9.259 ( 4.960)	Data  8.690 ( 4.390)	Loss 1.2593e-01 (9.7479e-02) 
2023-05-27 11:54:58.084457: train Epoch: [27][ 77/193]	Time  0.577 ( 4.903)	Data  0.001 ( 4.334)	Loss 1.1203e-01 (9.7665e-02) 
2023-05-27 11:55:07.614557: train Epoch: [27][ 78/193]	Time  9.530 ( 4.962)	Data  8.963 ( 4.393)	Loss 9.5484e-02 (9.7638e-02) 
2023-05-27 11:55:08.181065: train Epoch: [27][ 79/193]	Time  0.566 ( 4.907)	Data  0.001 ( 4.338)	Loss 7.5182e-02 (9.7357e-02) 
2023-05-27 11:55:17.665852: train Epoch: [27][ 80/193]	Time  9.485 ( 4.964)	Data  8.921 ( 4.394)	Loss 1.3545e-01 (9.7827e-02) 
2023-05-27 11:55:18.231019: train Epoch: [27][ 81/193]	Time  0.565 ( 4.910)	Data  0.001 ( 4.341)	Loss 8.8192e-02 (9.7710e-02) 
2023-05-27 11:55:27.286702: train Epoch: [27][ 82/193]	Time  9.056 ( 4.960)	Data  8.444 ( 4.390)	Loss 6.6517e-02 (9.7334e-02) 
2023-05-27 11:55:27.856134: train Epoch: [27][ 83/193]	Time  0.569 ( 4.908)	Data  0.001 ( 4.338)	Loss 4.7911e-02 (9.6746e-02) 
2023-05-27 11:55:37.015823: train Epoch: [27][ 84/193]	Time  9.160 ( 4.958)	Data  8.587 ( 4.388)	Loss 6.3240e-02 (9.6351e-02) 
2023-05-27 11:55:37.612428: train Epoch: [27][ 85/193]	Time  0.597 ( 4.907)	Data  0.001 ( 4.337)	Loss 1.2423e-01 (9.6676e-02) 
2023-05-27 11:55:46.932835: train Epoch: [27][ 86/193]	Time  9.320 ( 4.958)	Data  8.747 ( 4.388)	Loss 2.9439e-01 (9.8948e-02) 
2023-05-27 11:55:47.505224: train Epoch: [27][ 87/193]	Time  0.572 ( 4.908)	Data  0.001 ( 4.338)	Loss 1.6489e-01 (9.9698e-02) 
2023-05-27 11:55:56.443702: train Epoch: [27][ 88/193]	Time  8.938 ( 4.953)	Data  8.364 ( 4.383)	Loss 1.3201e-01 (1.0006e-01) 
2023-05-27 11:55:57.025054: train Epoch: [27][ 89/193]	Time  0.581 ( 4.904)	Data  0.001 ( 4.334)	Loss 9.5230e-02 (1.0001e-01) 
2023-05-27 11:56:05.443237: train Epoch: [27][ 90/193]	Time  8.418 ( 4.943)	Data  7.846 ( 4.373)	Loss 7.3878e-02 (9.9720e-02) 
2023-05-27 11:56:06.004231: train Epoch: [27][ 91/193]	Time  0.561 ( 4.895)	Data  0.001 ( 4.325)	Loss 1.5026e-01 (1.0027e-01) 
2023-05-27 11:56:14.597402: train Epoch: [27][ 92/193]	Time  8.593 ( 4.935)	Data  8.019 ( 4.365)	Loss 4.3139e-02 (9.9655e-02) 
2023-05-27 11:56:15.165196: train Epoch: [27][ 93/193]	Time  0.568 ( 4.889)	Data  0.001 ( 4.319)	Loss 1.5179e-01 (1.0021e-01) 
2023-05-27 11:56:24.381355: train Epoch: [27][ 94/193]	Time  9.216 ( 4.934)	Data  8.638 ( 4.364)	Loss 1.1022e-01 (1.0031e-01) 
2023-05-27 11:56:24.989356: train Epoch: [27][ 95/193]	Time  0.608 ( 4.889)	Data  0.001 ( 4.319)	Loss 1.0176e-01 (1.0033e-01) 
2023-05-27 11:56:34.127593: train Epoch: [27][ 96/193]	Time  9.138 ( 4.933)	Data  8.562 ( 4.362)	Loss 8.0499e-02 (1.0013e-01) 
2023-05-27 11:56:34.744811: train Epoch: [27][ 97/193]	Time  0.617 ( 4.889)	Data  0.005 ( 4.318)	Loss 1.8820e-01 (1.0102e-01) 
2023-05-27 11:56:44.272953: train Epoch: [27][ 98/193]	Time  9.528 ( 4.936)	Data  8.944 ( 4.365)	Loss 1.2267e-01 (1.0124e-01) 
2023-05-27 11:56:44.860794: train Epoch: [27][ 99/193]	Time  0.588 ( 4.892)	Data  0.012 ( 4.321)	Loss 9.1008e-02 (1.0114e-01) 
2023-05-27 11:56:54.527515: train Epoch: [27][100/193]	Time  9.667 ( 4.940)	Data  9.098 ( 4.368)	Loss 8.3275e-02 (1.0096e-01) 
2023-05-27 11:56:55.096687: train Epoch: [27][101/193]	Time  0.569 ( 4.897)	Data  0.001 ( 4.326)	Loss 7.6340e-02 (1.0072e-01) 
2023-05-27 11:57:04.499366: train Epoch: [27][102/193]	Time  9.403 ( 4.941)	Data  8.823 ( 4.369)	Loss 6.8198e-02 (1.0041e-01) 
2023-05-27 11:57:05.075852: train Epoch: [27][103/193]	Time  0.576 ( 4.899)	Data  0.001 ( 4.327)	Loss 6.7823e-02 (1.0009e-01) 
2023-05-27 11:57:14.553426: train Epoch: [27][104/193]	Time  9.478 ( 4.942)	Data  8.912 ( 4.371)	Loss 8.1841e-02 (9.9919e-02) 
2023-05-27 11:57:15.122435: train Epoch: [27][105/193]	Time  0.569 ( 4.901)	Data  0.001 ( 4.330)	Loss 1.2877e-01 (1.0019e-01) 
2023-05-27 11:57:24.429784: train Epoch: [27][106/193]	Time  9.307 ( 4.942)	Data  8.732 ( 4.371)	Loss 1.0738e-01 (1.0026e-01) 
2023-05-27 11:57:25.014312: train Epoch: [27][107/193]	Time  0.585 ( 4.902)	Data  0.001 ( 4.330)	Loss 2.0531e-01 (1.0123e-01) 
2023-05-27 11:57:34.301093: train Epoch: [27][108/193]	Time  9.287 ( 4.942)	Data  8.714 ( 4.371)	Loss 1.1449e-01 (1.0135e-01) 
2023-05-27 11:57:34.919775: train Epoch: [27][109/193]	Time  0.619 ( 4.903)	Data  0.003 ( 4.331)	Loss 1.2795e-01 (1.0159e-01) 
2023-05-27 11:57:44.820292: train Epoch: [27][110/193]	Time  9.900 ( 4.948)	Data  9.317 ( 4.376)	Loss 1.8487e-01 (1.0234e-01) 
2023-05-27 11:57:45.424728: train Epoch: [27][111/193]	Time  0.604 ( 4.909)	Data  0.001 ( 4.337)	Loss 7.0849e-02 (1.0206e-01) 
2023-05-27 11:57:54.684257: train Epoch: [27][112/193]	Time  9.260 ( 4.947)	Data  8.693 ( 4.375)	Loss 6.9918e-02 (1.0178e-01) 
2023-05-27 11:57:55.251633: train Epoch: [27][113/193]	Time  0.567 ( 4.909)	Data  0.001 ( 4.337)	Loss 8.9275e-02 (1.0167e-01) 
2023-05-27 11:58:04.675555: train Epoch: [27][114/193]	Time  9.424 ( 4.948)	Data  8.854 ( 4.376)	Loss 1.4655e-01 (1.0206e-01) 
2023-05-27 11:58:05.247777: train Epoch: [27][115/193]	Time  0.572 ( 4.911)	Data  0.001 ( 4.339)	Loss 4.2000e-02 (1.0154e-01) 
2023-05-27 11:58:14.461013: train Epoch: [27][116/193]	Time  9.213 ( 4.947)	Data  8.648 ( 4.375)	Loss 6.8231e-02 (1.0126e-01) 
2023-05-27 11:58:15.034588: train Epoch: [27][117/193]	Time  0.574 ( 4.910)	Data  0.001 ( 4.338)	Loss 8.5394e-02 (1.0112e-01) 
2023-05-27 11:58:24.667834: train Epoch: [27][118/193]	Time  9.633 ( 4.950)	Data  9.058 ( 4.378)	Loss 5.1912e-02 (1.0071e-01) 
2023-05-27 11:58:25.255496: train Epoch: [27][119/193]	Time  0.588 ( 4.914)	Data  0.001 ( 4.341)	Loss 6.5037e-02 (1.0041e-01) 
2023-05-27 11:58:34.863572: train Epoch: [27][120/193]	Time  9.608 ( 4.952)	Data  9.033 ( 4.380)	Loss 5.5079e-02 (1.0004e-01) 
2023-05-27 11:58:35.478594: train Epoch: [27][121/193]	Time  0.615 ( 4.917)	Data  0.001 ( 4.344)	Loss 2.5387e-01 (1.0130e-01) 
2023-05-27 11:58:44.903739: train Epoch: [27][122/193]	Time  9.425 ( 4.954)	Data  8.855 ( 4.381)	Loss 7.5168e-02 (1.0109e-01) 
2023-05-27 11:58:45.494192: train Epoch: [27][123/193]	Time  0.590 ( 4.918)	Data  0.001 ( 4.346)	Loss 1.8825e-01 (1.0179e-01) 
2023-05-27 11:58:54.774764: train Epoch: [27][124/193]	Time  9.281 ( 4.953)	Data  8.713 ( 4.381)	Loss 1.0186e-01 (1.0179e-01) 
2023-05-27 11:58:55.345311: train Epoch: [27][125/193]	Time  0.571 ( 4.918)	Data  0.001 ( 4.346)	Loss 7.1701e-02 (1.0155e-01) 
2023-05-27 11:59:04.474714: train Epoch: [27][126/193]	Time  9.129 ( 4.952)	Data  8.559 ( 4.379)	Loss 1.1801e-01 (1.0168e-01) 
2023-05-27 11:59:05.065894: train Epoch: [27][127/193]	Time  0.591 ( 4.918)	Data  0.001 ( 4.345)	Loss 6.5164e-02 (1.0139e-01) 
2023-05-27 11:59:13.621662: train Epoch: [27][128/193]	Time  8.556 ( 4.946)	Data  7.986 ( 4.373)	Loss 9.5679e-02 (1.0135e-01) 
2023-05-27 11:59:14.197865: train Epoch: [27][129/193]	Time  0.576 ( 4.912)	Data  0.001 ( 4.339)	Loss 9.2370e-02 (1.0128e-01) 
2023-05-27 11:59:24.028143: train Epoch: [27][130/193]	Time  9.830 ( 4.950)	Data  9.261 ( 4.377)	Loss 9.5149e-02 (1.0123e-01) 
2023-05-27 11:59:24.615922: train Epoch: [27][131/193]	Time  0.588 ( 4.917)	Data  0.001 ( 4.344)	Loss 8.1642e-02 (1.0109e-01) 
2023-05-27 11:59:33.959647: train Epoch: [27][132/193]	Time  9.344 ( 4.950)	Data  8.776 ( 4.377)	Loss 9.9896e-02 (1.0108e-01) 
2023-05-27 11:59:34.550146: train Epoch: [27][133/193]	Time  0.591 ( 4.917)	Data  0.001 ( 4.345)	Loss 6.8629e-02 (1.0084e-01) 
2023-05-27 11:59:43.908925: train Epoch: [27][134/193]	Time  9.359 ( 4.950)	Data  8.795 ( 4.377)	Loss 8.4673e-02 (1.0072e-01) 
2023-05-27 11:59:44.492833: train Epoch: [27][135/193]	Time  0.584 ( 4.918)	Data  0.001 ( 4.345)	Loss 1.4827e-01 (1.0107e-01) 
2023-05-27 11:59:53.806097: train Epoch: [27][136/193]	Time  9.313 ( 4.950)	Data  8.745 ( 4.377)	Loss 8.3242e-02 (1.0094e-01) 
2023-05-27 11:59:54.438766: train Epoch: [27][137/193]	Time  0.633 ( 4.919)	Data  0.001 ( 4.346)	Loss 1.6768e-01 (1.0142e-01) 
2023-05-27 12:00:03.665431: train Epoch: [27][138/193]	Time  9.227 ( 4.950)	Data  8.656 ( 4.377)	Loss 6.6999e-02 (1.0117e-01) 
2023-05-27 12:00:04.234080: train Epoch: [27][139/193]	Time  0.569 ( 4.919)	Data  0.001 ( 4.345)	Loss 1.4193e-01 (1.0146e-01) 
2023-05-27 12:00:13.501023: train Epoch: [27][140/193]	Time  9.267 ( 4.949)	Data  8.705 ( 4.376)	Loss 1.3654e-01 (1.0171e-01) 
2023-05-27 12:00:14.069794: train Epoch: [27][141/193]	Time  0.569 ( 4.919)	Data  0.001 ( 4.346)	Loss 9.9655e-02 (1.0170e-01) 
2023-05-27 12:00:23.703778: train Epoch: [27][142/193]	Time  9.634 ( 4.952)	Data  9.064 ( 4.379)	Loss 9.6485e-02 (1.0166e-01) 
2023-05-27 12:00:24.276039: train Epoch: [27][143/193]	Time  0.572 ( 4.921)	Data  0.001 ( 4.348)	Loss 1.0504e-01 (1.0168e-01) 
2023-05-27 12:00:33.574006: train Epoch: [27][144/193]	Time  9.298 ( 4.951)	Data  8.737 ( 4.378)	Loss 8.4226e-02 (1.0156e-01) 
2023-05-27 12:00:34.138469: train Epoch: [27][145/193]	Time  0.564 ( 4.921)	Data  0.001 ( 4.348)	Loss 6.7988e-02 (1.0133e-01) 
2023-05-27 12:00:43.714582: train Epoch: [27][146/193]	Time  9.576 ( 4.953)	Data  9.015 ( 4.380)	Loss 1.0959e-01 (1.0139e-01) 
2023-05-27 12:00:44.283479: train Epoch: [27][147/193]	Time  0.569 ( 4.923)	Data  0.001 ( 4.351)	Loss 7.4549e-02 (1.0121e-01) 
2023-05-27 12:00:53.224775: train Epoch: [27][148/193]	Time  8.941 ( 4.950)	Data  8.370 ( 4.378)	Loss 9.3717e-02 (1.0116e-01) 
2023-05-27 12:00:53.785737: train Epoch: [27][149/193]	Time  0.561 ( 4.921)	Data  0.001 ( 4.348)	Loss 5.7535e-02 (1.0087e-01) 
2023-05-27 12:01:02.925581: train Epoch: [27][150/193]	Time  9.140 ( 4.949)	Data  8.578 ( 4.376)	Loss 1.5611e-01 (1.0123e-01) 
2023-05-27 12:01:03.487849: train Epoch: [27][151/193]	Time  0.562 ( 4.920)	Data  0.001 ( 4.348)	Loss 8.6057e-02 (1.0113e-01) 
2023-05-27 12:01:12.288846: train Epoch: [27][152/193]	Time  8.801 ( 4.946)	Data  8.235 ( 4.373)	Loss 7.4460e-02 (1.0096e-01) 
2023-05-27 12:01:12.856431: train Epoch: [27][153/193]	Time  0.568 ( 4.917)	Data  0.001 ( 4.345)	Loss 5.7384e-02 (1.0068e-01) 
2023-05-27 12:01:21.950579: train Epoch: [27][154/193]	Time  9.094 ( 4.944)	Data  8.527 ( 4.372)	Loss 4.3821e-02 (1.0031e-01) 
2023-05-27 12:01:22.511657: train Epoch: [27][155/193]	Time  0.561 ( 4.916)	Data  0.001 ( 4.344)	Loss 7.6141e-02 (1.0015e-01) 
2023-05-27 12:01:31.271019: train Epoch: [27][156/193]	Time  8.759 ( 4.940)	Data  8.200 ( 4.368)	Loss 6.3096e-02 (9.9918e-02) 
2023-05-27 12:01:31.832030: train Epoch: [27][157/193]	Time  0.561 ( 4.913)	Data  0.001 ( 4.341)	Loss 7.7817e-02 (9.9778e-02) 
2023-05-27 12:01:41.013510: train Epoch: [27][158/193]	Time  9.181 ( 4.940)	Data  8.614 ( 4.367)	Loss 1.2559e-01 (9.9940e-02) 
2023-05-27 12:01:41.574155: train Epoch: [27][159/193]	Time  0.561 ( 4.912)	Data  0.001 ( 4.340)	Loss 8.0886e-02 (9.9821e-02) 
2023-05-27 12:01:50.898846: train Epoch: [27][160/193]	Time  9.325 ( 4.940)	Data  8.729 ( 4.367)	Loss 1.0455e-01 (9.9851e-02) 
2023-05-27 12:01:51.466982: train Epoch: [27][161/193]	Time  0.568 ( 4.913)	Data  0.001 ( 4.340)	Loss 8.6596e-02 (9.9769e-02) 
2023-05-27 12:02:00.505357: train Epoch: [27][162/193]	Time  9.038 ( 4.938)	Data  8.475 ( 4.366)	Loss 5.8084e-02 (9.9513e-02) 
2023-05-27 12:02:01.073227: train Epoch: [27][163/193]	Time  0.568 ( 4.911)	Data  0.001 ( 4.339)	Loss 7.4800e-02 (9.9362e-02) 
2023-05-27 12:02:10.560662: train Epoch: [27][164/193]	Time  9.487 ( 4.939)	Data  8.919 ( 4.367)	Loss 5.6760e-02 (9.9104e-02) 
2023-05-27 12:02:11.149209: train Epoch: [27][165/193]	Time  0.589 ( 4.913)	Data  0.001 ( 4.341)	Loss 1.3783e-01 (9.9337e-02) 
2023-05-27 12:02:20.328282: train Epoch: [27][166/193]	Time  9.179 ( 4.938)	Data  8.612 ( 4.366)	Loss 7.9931e-02 (9.9221e-02) 
2023-05-27 12:02:20.900301: train Epoch: [27][167/193]	Time  0.572 ( 4.912)	Data  0.001 ( 4.340)	Loss 7.5589e-02 (9.9081e-02) 
2023-05-27 12:02:30.034628: train Epoch: [27][168/193]	Time  9.134 ( 4.937)	Data  8.562 ( 4.365)	Loss 8.0921e-02 (9.8973e-02) 
2023-05-27 12:02:30.608042: train Epoch: [27][169/193]	Time  0.573 ( 4.912)	Data  0.001 ( 4.340)	Loss 8.2807e-02 (9.8878e-02) 
2023-05-27 12:02:39.765642: train Epoch: [27][170/193]	Time  9.158 ( 4.937)	Data  8.597 ( 4.364)	Loss 8.7477e-02 (9.8811e-02) 
2023-05-27 12:02:40.334509: train Epoch: [27][171/193]	Time  0.569 ( 4.911)	Data  0.001 ( 4.339)	Loss 1.0435e-01 (9.8844e-02) 
2023-05-27 12:02:49.336846: train Epoch: [27][172/193]	Time  9.002 ( 4.935)	Data  8.436 ( 4.363)	Loss 4.6233e-02 (9.8539e-02) 
2023-05-27 12:02:49.905215: train Epoch: [27][173/193]	Time  0.568 ( 4.910)	Data  0.001 ( 4.338)	Loss 1.2816e-01 (9.8710e-02) 
2023-05-27 12:02:58.794891: train Epoch: [27][174/193]	Time  8.890 ( 4.932)	Data  8.328 ( 4.360)	Loss 9.4788e-02 (9.8687e-02) 
2023-05-27 12:02:59.358131: train Epoch: [27][175/193]	Time  0.563 ( 4.908)	Data  0.001 ( 4.336)	Loss 9.7367e-02 (9.8680e-02) 
2023-05-27 12:03:08.875117: train Epoch: [27][176/193]	Time  9.517 ( 4.934)	Data  8.953 ( 4.362)	Loss 7.1814e-02 (9.8528e-02) 
2023-05-27 12:03:09.437157: train Epoch: [27][177/193]	Time  0.562 ( 4.909)	Data  0.001 ( 4.337)	Loss 8.9738e-02 (9.8479e-02) 
2023-05-27 12:03:18.853174: train Epoch: [27][178/193]	Time  9.416 ( 4.934)	Data  8.842 ( 4.362)	Loss 1.1239e-01 (9.8556e-02) 
2023-05-27 12:03:19.421722: train Epoch: [27][179/193]	Time  0.569 ( 4.910)	Data  0.001 ( 4.338)	Loss 1.1323e-01 (9.8638e-02) 
2023-05-27 12:03:28.292786: train Epoch: [27][180/193]	Time  8.871 ( 4.932)	Data  8.311 ( 4.360)	Loss 1.1330e-01 (9.8719e-02) 
2023-05-27 12:03:28.853559: train Epoch: [27][181/193]	Time  0.561 ( 4.908)	Data  0.001 ( 4.336)	Loss 6.7655e-02 (9.8548e-02) 
2023-05-27 12:03:38.027839: train Epoch: [27][182/193]	Time  9.174 ( 4.931)	Data  8.612 ( 4.360)	Loss 6.7286e-02 (9.8377e-02) 
2023-05-27 12:03:38.588698: train Epoch: [27][183/193]	Time  0.561 ( 4.907)	Data  0.001 ( 4.336)	Loss 5.0471e-02 (9.8117e-02) 
2023-05-27 12:03:47.647165: train Epoch: [27][184/193]	Time  9.058 ( 4.930)	Data  8.498 ( 4.358)	Loss 2.1066e-01 (9.8725e-02) 
2023-05-27 12:03:48.211976: train Epoch: [27][185/193]	Time  0.565 ( 4.906)	Data  0.001 ( 4.335)	Loss 9.0113e-02 (9.8679e-02) 
2023-05-27 12:03:57.365362: train Epoch: [27][186/193]	Time  9.153 ( 4.929)	Data  8.592 ( 4.358)	Loss 1.0114e-01 (9.8692e-02) 
2023-05-27 12:03:57.925668: train Epoch: [27][187/193]	Time  0.560 ( 4.906)	Data  0.001 ( 4.335)	Loss 1.4242e-01 (9.8925e-02) 
2023-05-27 12:04:06.958383: train Epoch: [27][188/193]	Time  9.033 ( 4.928)	Data  8.455 ( 4.356)	Loss 1.4179e-01 (9.9152e-02) 
2023-05-27 12:04:07.532271: train Epoch: [27][189/193]	Time  0.574 ( 4.905)	Data  0.001 ( 4.333)	Loss 8.6975e-02 (9.9088e-02) 
2023-05-27 12:04:16.733701: train Epoch: [27][190/193]	Time  9.201 ( 4.927)	Data  8.640 ( 4.356)	Loss 8.5177e-02 (9.9015e-02) 
2023-05-27 12:04:17.298841: train Epoch: [27][191/193]	Time  0.565 ( 4.905)	Data  0.001 ( 4.333)	Loss 6.6868e-02 (9.8847e-02) 
2023-05-27 12:04:26.011639: train Epoch: [27][192/193]	Time  8.713 ( 4.924)	Data  8.152 ( 4.353)	Loss 9.5747e-02 (9.8831e-02) 
2023-05-27 12:04:26.160678: Train Epoch done in 950.5397215530102 s 
2023-05-27 12:04:32.973315: val Epoch: [27][ 0/72]	Time  6.110 ( 6.110)	Data  5.903 ( 5.903)	Loss 9.0663e-02 (9.0663e-02) 
2023-05-27 12:04:33.083730: val Epoch: [27][ 1/72]	Time  0.111 ( 3.110)	Data  0.002 ( 2.952)	Loss 7.1385e-02 (8.1024e-02) 
2023-05-27 12:04:38.113419: val Epoch: [27][ 2/72]	Time  5.030 ( 3.750)	Data  4.920 ( 3.608)	Loss 1.8857e-01 (1.1687e-01) 
2023-05-27 12:04:38.379650: val Epoch: [27][ 3/72]	Time  0.266 ( 2.879)	Data  0.157 ( 2.745)	Loss 5.7791e-02 (1.0210e-01) 
2023-05-27 12:04:43.186728: val Epoch: [27][ 4/72]	Time  4.807 ( 3.265)	Data  4.692 ( 3.135)	Loss 3.2965e-01 (1.4761e-01) 
2023-05-27 12:04:43.384202: val Epoch: [27][ 5/72]	Time  0.197 ( 2.753)	Data  0.081 ( 2.626)	Loss 7.3747e-02 (1.3530e-01) 
2023-05-27 12:04:48.179881: val Epoch: [27][ 6/72]	Time  4.796 ( 3.045)	Data  4.674 ( 2.918)	Loss 1.6339e-01 (1.3931e-01) 
2023-05-27 12:04:48.287354: val Epoch: [27][ 7/72]	Time  0.107 ( 2.678)	Data  0.001 ( 2.554)	Loss 3.5583e-01 (1.6638e-01) 
2023-05-27 12:04:52.906348: val Epoch: [27][ 8/72]	Time  4.619 ( 2.894)	Data  4.512 ( 2.771)	Loss 7.7656e-02 (1.5652e-01) 
2023-05-27 12:04:53.249252: val Epoch: [27][ 9/72]	Time  0.343 ( 2.639)	Data  0.235 ( 2.518)	Loss 1.0496e-01 (1.5136e-01) 
2023-05-27 12:04:57.756456: val Epoch: [27][10/72]	Time  4.507 ( 2.808)	Data  4.399 ( 2.689)	Loss 9.9441e-02 (1.4664e-01) 
2023-05-27 12:04:58.222719: val Epoch: [27][11/72]	Time  0.466 ( 2.613)	Data  0.358 ( 2.494)	Loss 7.6598e-02 (1.4081e-01) 
2023-05-27 12:05:02.813383: val Epoch: [27][12/72]	Time  4.591 ( 2.765)	Data  4.483 ( 2.647)	Loss 1.1086e-01 (1.3850e-01) 
2023-05-27 12:05:03.083021: val Epoch: [27][13/72]	Time  0.270 ( 2.587)	Data  0.161 ( 2.470)	Loss 6.6449e-02 (1.3336e-01) 
2023-05-27 12:05:07.772102: val Epoch: [27][14/72]	Time  4.689 ( 2.727)	Data  4.570 ( 2.610)	Loss 1.3374e-01 (1.3338e-01) 
2023-05-27 12:05:08.157943: val Epoch: [27][15/72]	Time  0.386 ( 2.581)	Data  0.280 ( 2.464)	Loss 3.7483e-01 (1.4847e-01) 
2023-05-27 12:05:12.500507: val Epoch: [27][16/72]	Time  4.343 ( 2.685)	Data  4.236 ( 2.568)	Loss 1.3474e-01 (1.4766e-01) 
2023-05-27 12:05:13.174255: val Epoch: [27][17/72]	Time  0.674 ( 2.573)	Data  0.569 ( 2.457)	Loss 1.1970e-01 (1.4611e-01) 
2023-05-27 12:05:17.392741: val Epoch: [27][18/72]	Time  4.218 ( 2.659)	Data  4.112 ( 2.544)	Loss 4.5553e-02 (1.4082e-01) 
2023-05-27 12:05:18.122553: val Epoch: [27][19/72]	Time  0.730 ( 2.563)	Data  0.624 ( 2.448)	Loss 4.1407e-01 (1.5448e-01) 
2023-05-27 12:05:22.545503: val Epoch: [27][20/72]	Time  4.423 ( 2.652)	Data  4.311 ( 2.537)	Loss 2.9851e-01 (1.6134e-01) 
2023-05-27 12:05:23.019212: val Epoch: [27][21/72]	Time  0.474 ( 2.553)	Data  0.358 ( 2.438)	Loss 9.6535e-02 (1.5839e-01) 
2023-05-27 12:05:27.684193: val Epoch: [27][22/72]	Time  4.665 ( 2.644)	Data  4.546 ( 2.530)	Loss 4.6955e-02 (1.5355e-01) 
2023-05-27 12:05:28.470214: val Epoch: [27][23/72]	Time  0.786 ( 2.567)	Data  0.680 ( 2.453)	Loss 1.2785e-01 (1.5248e-01) 
2023-05-27 12:05:32.952914: val Epoch: [27][24/72]	Time  4.483 ( 2.644)	Data  4.372 ( 2.529)	Loss 6.9246e-02 (1.4915e-01) 
2023-05-27 12:05:33.355990: val Epoch: [27][25/72]	Time  0.403 ( 2.557)	Data  0.292 ( 2.443)	Loss 6.1394e-02 (1.4577e-01) 
2023-05-27 12:05:37.817807: val Epoch: [27][26/72]	Time  4.462 ( 2.628)	Data  4.356 ( 2.514)	Loss 4.7600e-02 (1.4214e-01) 
2023-05-27 12:05:38.510387: val Epoch: [27][27/72]	Time  0.693 ( 2.559)	Data  0.565 ( 2.445)	Loss 1.0080e-01 (1.4066e-01) 
2023-05-27 12:05:42.653276: val Epoch: [27][28/72]	Time  4.143 ( 2.613)	Data  4.027 ( 2.499)	Loss 6.1875e-02 (1.3794e-01) 
2023-05-27 12:05:43.656983: val Epoch: [27][29/72]	Time  1.004 ( 2.560)	Data  0.874 ( 2.445)	Loss 5.8285e-01 (1.5277e-01) 
2023-05-27 12:05:47.640167: val Epoch: [27][30/72]	Time  3.983 ( 2.606)	Data  3.876 ( 2.491)	Loss 2.4411e-01 (1.5572e-01) 
2023-05-27 12:05:48.674747: val Epoch: [27][31/72]	Time  1.035 ( 2.557)	Data  0.919 ( 2.442)	Loss 2.0418e-01 (1.5723e-01) 
2023-05-27 12:05:52.441397: val Epoch: [27][32/72]	Time  3.767 ( 2.593)	Data  3.649 ( 2.479)	Loss 3.0455e-01 (1.6170e-01) 
2023-05-27 12:05:53.688299: val Epoch: [27][33/72]	Time  1.247 ( 2.554)	Data  1.139 ( 2.439)	Loss 1.6862e-01 (1.6190e-01) 
2023-05-27 12:05:57.485850: val Epoch: [27][34/72]	Time  3.798 ( 2.589)	Data  3.690 ( 2.475)	Loss 3.4131e-01 (1.6703e-01) 
2023-05-27 12:05:58.892341: val Epoch: [27][35/72]	Time  1.406 ( 2.556)	Data  1.299 ( 2.442)	Loss 8.7428e-02 (1.6482e-01) 
2023-05-27 12:06:02.289801: val Epoch: [27][36/72]	Time  3.397 ( 2.579)	Data  3.286 ( 2.465)	Loss 1.1338e-01 (1.6343e-01) 
2023-05-27 12:06:03.776226: val Epoch: [27][37/72]	Time  1.486 ( 2.550)	Data  1.372 ( 2.436)	Loss 6.9411e-02 (1.6095e-01) 
2023-05-27 12:06:07.248780: val Epoch: [27][38/72]	Time  3.473 ( 2.574)	Data  3.366 ( 2.460)	Loss 5.9738e-02 (1.5836e-01) 
2023-05-27 12:06:08.442548: val Epoch: [27][39/72]	Time  1.194 ( 2.539)	Data  1.089 ( 2.426)	Loss 1.1273e-01 (1.5722e-01) 
2023-05-27 12:06:12.099789: val Epoch: [27][40/72]	Time  3.657 ( 2.567)	Data  3.546 ( 2.453)	Loss 7.8682e-02 (1.5530e-01) 
2023-05-27 12:06:13.433988: val Epoch: [27][41/72]	Time  1.334 ( 2.537)	Data  1.229 ( 2.424)	Loss 4.8965e-01 (1.6326e-01) 
2023-05-27 12:06:17.139919: val Epoch: [27][42/72]	Time  3.706 ( 2.565)	Data  3.596 ( 2.451)	Loss 7.9689e-02 (1.6132e-01) 
2023-05-27 12:06:18.687786: val Epoch: [27][43/72]	Time  1.548 ( 2.541)	Data  1.430 ( 2.428)	Loss 1.2350e-01 (1.6046e-01) 
2023-05-27 12:06:22.086585: val Epoch: [27][44/72]	Time  3.399 ( 2.561)	Data  3.292 ( 2.447)	Loss 6.9453e-02 (1.5844e-01) 
2023-05-27 12:06:23.613525: val Epoch: [27][45/72]	Time  1.527 ( 2.538)	Data  1.421 ( 2.425)	Loss 2.1533e-01 (1.5967e-01) 
2023-05-27 12:06:27.211336: val Epoch: [27][46/72]	Time  3.598 ( 2.561)	Data  3.490 ( 2.448)	Loss 1.6940e-01 (1.5988e-01) 
2023-05-27 12:06:28.673366: val Epoch: [27][47/72]	Time  1.462 ( 2.538)	Data  1.357 ( 2.425)	Loss 3.6725e-01 (1.6420e-01) 
2023-05-27 12:06:32.023433: val Epoch: [27][48/72]	Time  3.350 ( 2.554)	Data  3.245 ( 2.442)	Loss 5.7513e-02 (1.6202e-01) 
2023-05-27 12:06:33.690644: val Epoch: [27][49/72]	Time  1.667 ( 2.537)	Data  1.562 ( 2.424)	Loss 2.1353e-01 (1.6305e-01) 
2023-05-27 12:06:37.000090: val Epoch: [27][50/72]	Time  3.309 ( 2.552)	Data  3.191 ( 2.439)	Loss 4.5218e-02 (1.6074e-01) 
2023-05-27 12:06:38.505567: val Epoch: [27][51/72]	Time  1.505 ( 2.532)	Data  1.400 ( 2.419)	Loss 6.4118e-02 (1.5888e-01) 
2023-05-27 12:06:42.012268: val Epoch: [27][52/72]	Time  3.507 ( 2.550)	Data  3.398 ( 2.438)	Loss 1.1967e-01 (1.5814e-01) 
2023-05-27 12:06:43.478889: val Epoch: [27][53/72]	Time  1.467 ( 2.530)	Data  1.361 ( 2.418)	Loss 1.3494e-01 (1.5772e-01) 
2023-05-27 12:06:47.175166: val Epoch: [27][54/72]	Time  3.696 ( 2.551)	Data  3.576 ( 2.439)	Loss 1.2040e-01 (1.5704e-01) 
2023-05-27 12:06:48.244138: val Epoch: [27][55/72]	Time  1.069 ( 2.525)	Data  0.963 ( 2.412)	Loss 5.0614e-01 (1.6327e-01) 
2023-05-27 12:06:52.036422: val Epoch: [27][56/72]	Time  3.792 ( 2.547)	Data  3.685 ( 2.435)	Loss 5.3270e-01 (1.6975e-01) 
2023-05-27 12:06:53.049487: val Epoch: [27][57/72]	Time  1.013 ( 2.520)	Data  0.908 ( 2.408)	Loss 4.6856e-02 (1.6763e-01) 
2023-05-27 12:06:57.063751: val Epoch: [27][58/72]	Time  4.014 ( 2.546)	Data  3.891 ( 2.433)	Loss 6.0967e-02 (1.6583e-01) 
2023-05-27 12:06:57.900316: val Epoch: [27][59/72]	Time  0.837 ( 2.517)	Data  0.681 ( 2.404)	Loss 4.4247e-02 (1.6380e-01) 
2023-05-27 12:07:01.972537: val Epoch: [27][60/72]	Time  4.072 ( 2.543)	Data  3.956 ( 2.430)	Loss 5.6972e-02 (1.6205e-01) 
2023-05-27 12:07:02.708519: val Epoch: [27][61/72]	Time  0.736 ( 2.514)	Data  0.615 ( 2.400)	Loss 6.1496e-02 (1.6043e-01) 
2023-05-27 12:07:06.804945: val Epoch: [27][62/72]	Time  4.096 ( 2.539)	Data  3.988 ( 2.426)	Loss 5.9828e-02 (1.5883e-01) 
2023-05-27 12:07:07.723697: val Epoch: [27][63/72]	Time  0.919 ( 2.513)	Data  0.811 ( 2.400)	Loss 7.5061e-02 (1.5752e-01) 
2023-05-27 12:07:11.580548: val Epoch: [27][64/72]	Time  3.857 ( 2.534)	Data  3.749 ( 2.421)	Loss 4.7418e-02 (1.5583e-01) 
2023-05-27 12:07:12.525364: val Epoch: [27][65/72]	Time  0.945 ( 2.510)	Data  0.839 ( 2.397)	Loss 9.0478e-02 (1.5484e-01) 
2023-05-27 12:07:16.895926: val Epoch: [27][66/72]	Time  4.371 ( 2.538)	Data  4.245 ( 2.425)	Loss 1.2843e-01 (1.5444e-01) 
2023-05-27 12:07:17.384785: val Epoch: [27][67/72]	Time  0.489 ( 2.508)	Data  0.381 ( 2.395)	Loss 2.0449e-01 (1.5518e-01) 
2023-05-27 12:07:21.584178: val Epoch: [27][68/72]	Time  4.199 ( 2.532)	Data  4.092 ( 2.419)	Loss 5.7235e-02 (1.5376e-01) 
2023-05-27 12:07:22.171046: val Epoch: [27][69/72]	Time  0.587 ( 2.504)	Data  0.471 ( 2.391)	Loss 8.5921e-02 (1.5279e-01) 
2023-05-27 12:07:26.391603: val Epoch: [27][70/72]	Time  4.221 ( 2.529)	Data  4.115 ( 2.416)	Loss 6.1813e-02 (1.5151e-01) 
2023-05-27 12:07:26.747290: val Epoch: [27][71/72]	Time  0.356 ( 2.498)	Data  0.235 ( 2.385)	Loss 8.3671e-02 (1.5057e-01) 
2023-05-27 12:07:27.106393: Epoch 27 :Val : ['ET : 0.7433044910430908', 'TC : 0.7538902759552002', 'WT : 0.8171120882034302'] 
2023-05-27 12:07:27.113396: Epoch 27 :Val : ['ET : 0.7433044910430908', 'TC : 0.7538902759552002', 'WT : 0.8171120882034302'] 
2023-05-27 12:07:27.116489: Val epoch done in 180.95581423299154 s 
2023-05-27 12:07:27.124030: Batches per epoch:  193 
2023-05-27 12:07:38.649696: train Epoch: [28][  0/193]	Time 11.525 (11.525)	Data 10.911 (10.911)	Loss 8.4688e-02 (8.4688e-02) 
2023-05-27 12:07:39.217002: train Epoch: [28][  1/193]	Time  0.567 ( 6.046)	Data  0.001 ( 5.456)	Loss 1.1551e-01 (1.0010e-01) 
2023-05-27 12:07:48.302937: train Epoch: [28][  2/193]	Time  9.086 ( 7.059)	Data  8.503 ( 6.472)	Loss 1.0084e-01 (1.0035e-01) 
2023-05-27 12:07:48.867934: train Epoch: [28][  3/193]	Time  0.565 ( 5.436)	Data  0.001 ( 4.854)	Loss 1.1579e-01 (1.0421e-01) 
2023-05-27 12:07:58.171789: train Epoch: [28][  4/193]	Time  9.304 ( 6.209)	Data  8.742 ( 5.632)	Loss 1.0548e-01 (1.0446e-01) 
2023-05-27 12:07:58.744658: train Epoch: [28][  5/193]	Time  0.573 ( 5.270)	Data  0.001 ( 4.693)	Loss 7.9246e-02 (1.0026e-01) 
2023-05-27 12:08:08.152632: train Epoch: [28][  6/193]	Time  9.408 ( 5.861)	Data  8.845 ( 5.286)	Loss 1.0909e-01 (1.0152e-01) 
2023-05-27 12:08:08.738722: train Epoch: [28][  7/193]	Time  0.586 ( 5.202)	Data  0.001 ( 4.626)	Loss 1.3160e-01 (1.0528e-01) 
2023-05-27 12:08:18.695139: train Epoch: [28][  8/193]	Time  9.956 ( 5.730)	Data  9.377 ( 5.154)	Loss 9.4747e-02 (1.0411e-01) 
2023-05-27 12:08:19.264200: train Epoch: [28][  9/193]	Time  0.569 ( 5.214)	Data  0.001 ( 4.638)	Loss 9.7013e-02 (1.0340e-01) 
2023-05-27 12:08:29.245636: train Epoch: [28][ 10/193]	Time  9.981 ( 5.647)	Data  9.413 ( 5.072)	Loss 7.8977e-02 (1.0118e-01) 
2023-05-27 12:08:29.811404: train Epoch: [28][ 11/193]	Time  0.566 ( 5.224)	Data  0.001 ( 4.650)	Loss 7.6363e-02 (9.9112e-02) 
2023-05-27 12:08:39.209338: train Epoch: [28][ 12/193]	Time  9.398 ( 5.545)	Data  8.833 ( 4.972)	Loss 1.6729e-01 (1.0436e-01) 
2023-05-27 12:08:39.782934: train Epoch: [28][ 13/193]	Time  0.574 ( 5.190)	Data  0.001 ( 4.616)	Loss 1.2015e-01 (1.0548e-01) 
2023-05-27 12:08:49.119440: train Epoch: [28][ 14/193]	Time  9.337 ( 5.466)	Data  8.728 ( 4.891)	Loss 8.3217e-02 (1.0400e-01) 
2023-05-27 12:08:49.686622: train Epoch: [28][ 15/193]	Time  0.567 ( 5.160)	Data  0.001 ( 4.585)	Loss 2.1756e-01 (1.1110e-01) 
2023-05-27 12:08:58.674236: train Epoch: [28][ 16/193]	Time  8.988 ( 5.385)	Data  8.385 ( 4.808)	Loss 9.2737e-02 (1.1002e-01) 
2023-05-27 12:08:59.241132: train Epoch: [28][ 17/193]	Time  0.567 ( 5.118)	Data  0.001 ( 4.541)	Loss 7.8256e-02 (1.0825e-01) 
2023-05-27 12:09:08.161012: train Epoch: [28][ 18/193]	Time  8.920 ( 5.318)	Data  8.345 ( 4.742)	Loss 7.1382e-02 (1.0631e-01) 
2023-05-27 12:09:08.764789: train Epoch: [28][ 19/193]	Time  0.604 ( 5.082)	Data  0.001 ( 4.505)	Loss 9.9795e-02 (1.0599e-01) 
2023-05-27 12:09:18.160357: train Epoch: [28][ 20/193]	Time  9.396 ( 5.287)	Data  8.825 ( 4.710)	Loss 1.3686e-01 (1.0746e-01) 
2023-05-27 12:09:18.732480: train Epoch: [28][ 21/193]	Time  0.572 ( 5.073)	Data  0.001 ( 4.496)	Loss 6.9754e-02 (1.0574e-01) 
2023-05-27 12:09:28.227006: train Epoch: [28][ 22/193]	Time  9.495 ( 5.265)	Data  8.917 ( 4.688)	Loss 3.2261e-01 (1.1517e-01) 
2023-05-27 12:09:28.837880: train Epoch: [28][ 23/193]	Time  0.611 ( 5.071)	Data  0.001 ( 4.493)	Loss 8.8149e-02 (1.1405e-01) 
2023-05-27 12:09:37.991924: train Epoch: [28][ 24/193]	Time  9.154 ( 5.235)	Data  8.586 ( 4.657)	Loss 1.6286e-01 (1.1600e-01) 
2023-05-27 12:09:38.560477: train Epoch: [28][ 25/193]	Time  0.569 ( 5.055)	Data  0.001 ( 4.478)	Loss 7.2502e-02 (1.1433e-01) 
2023-05-27 12:09:47.885856: train Epoch: [28][ 26/193]	Time  9.325 ( 5.213)	Data  8.753 ( 4.636)	Loss 9.3093e-02 (1.1354e-01) 
2023-05-27 12:09:48.515302: train Epoch: [28][ 27/193]	Time  0.629 ( 5.050)	Data  0.059 ( 4.473)	Loss 1.8633e-01 (1.1614e-01) 
2023-05-27 12:09:55.167733: train Epoch: [28][ 28/193]	Time  6.652 ( 5.105)	Data  6.071 ( 4.528)	Loss 6.2385e-02 (1.1428e-01) 
2023-05-27 12:09:56.140406: train Epoch: [28][ 29/193]	Time  0.973 ( 4.967)	Data  0.410 ( 4.390)	Loss 8.7602e-02 (1.1340e-01) 
2023-05-27 12:10:02.906727: train Epoch: [28][ 30/193]	Time  6.766 ( 5.025)	Data  6.203 ( 4.449)	Loss 6.7954e-02 (1.1193e-01) 
2023-05-27 12:10:04.068880: train Epoch: [28][ 31/193]	Time  1.162 ( 4.905)	Data  0.603 ( 4.329)	Loss 8.4241e-02 (1.1106e-01) 
2023-05-27 12:10:12.897755: train Epoch: [28][ 32/193]	Time  8.829 ( 5.023)	Data  8.253 ( 4.448)	Loss 8.8388e-02 (1.1038e-01) 
2023-05-27 12:10:14.062270: train Epoch: [28][ 33/193]	Time  1.165 ( 4.910)	Data  0.605 ( 4.335)	Loss 1.0220e-01 (1.1014e-01) 
2023-05-27 12:10:22.731121: train Epoch: [28][ 34/193]	Time  8.669 ( 5.017)	Data  8.099 ( 4.442)	Loss 1.1282e-01 (1.1021e-01) 
2023-05-27 12:10:23.576267: train Epoch: [28][ 35/193]	Time  0.845 ( 4.901)	Data  0.279 ( 4.327)	Loss 7.6776e-02 (1.0928e-01) 
2023-05-27 12:10:33.054147: train Epoch: [28][ 36/193]	Time  9.478 ( 5.025)	Data  8.915 ( 4.451)	Loss 1.7315e-01 (1.1101e-01) 
2023-05-27 12:10:33.629909: train Epoch: [28][ 37/193]	Time  0.576 ( 4.908)	Data  0.001 ( 4.333)	Loss 7.2363e-02 (1.0999e-01) 
2023-05-27 12:10:42.791788: train Epoch: [28][ 38/193]	Time  9.162 ( 5.017)	Data  8.602 ( 4.443)	Loss 7.1871e-02 (1.0902e-01) 
2023-05-27 12:10:43.356749: train Epoch: [28][ 39/193]	Time  0.565 ( 4.906)	Data  0.001 ( 4.332)	Loss 1.0276e-01 (1.0886e-01) 
2023-05-27 12:10:52.407305: train Epoch: [28][ 40/193]	Time  9.051 ( 5.007)	Data  8.480 ( 4.433)	Loss 6.5190e-02 (1.0779e-01) 
2023-05-27 12:10:52.970838: train Epoch: [28][ 41/193]	Time  0.564 ( 4.901)	Data  0.001 ( 4.328)	Loss 5.2718e-02 (1.0648e-01) 
2023-05-27 12:11:02.551394: train Epoch: [28][ 42/193]	Time  9.581 ( 5.010)	Data  9.010 ( 4.436)	Loss 6.8985e-02 (1.0561e-01) 
2023-05-27 12:11:03.114227: train Epoch: [28][ 43/193]	Time  0.563 ( 4.909)	Data  0.001 ( 4.336)	Loss 6.2239e-02 (1.0463e-01) 
2023-05-27 12:11:12.379645: train Epoch: [28][ 44/193]	Time  9.265 ( 5.006)	Data  8.695 ( 4.432)	Loss 1.4768e-01 (1.0558e-01) 
2023-05-27 12:11:12.943098: train Epoch: [28][ 45/193]	Time  0.563 ( 4.909)	Data  0.001 ( 4.336)	Loss 6.7093e-02 (1.0475e-01) 
2023-05-27 12:11:22.173345: train Epoch: [28][ 46/193]	Time  9.230 ( 5.001)	Data  8.666 ( 4.428)	Loss 8.7275e-02 (1.0437e-01) 
2023-05-27 12:11:22.734890: train Epoch: [28][ 47/193]	Time  0.562 ( 4.909)	Data  0.001 ( 4.336)	Loss 6.4218e-02 (1.0354e-01) 
2023-05-27 12:11:32.070938: train Epoch: [28][ 48/193]	Time  9.336 ( 4.999)	Data  8.776 ( 4.427)	Loss 6.8604e-02 (1.0282e-01) 
2023-05-27 12:11:32.633482: train Epoch: [28][ 49/193]	Time  0.563 ( 4.910)	Data  0.001 ( 4.338)	Loss 6.6266e-02 (1.0209e-01) 
2023-05-27 12:11:41.972946: train Epoch: [28][ 50/193]	Time  9.339 ( 4.997)	Data  8.735 ( 4.424)	Loss 7.1602e-02 (1.0150e-01) 
2023-05-27 12:11:42.535028: train Epoch: [28][ 51/193]	Time  0.562 ( 4.912)	Data  0.001 ( 4.339)	Loss 6.1933e-02 (1.0073e-01) 
2023-05-27 12:11:51.685652: train Epoch: [28][ 52/193]	Time  9.151 ( 4.992)	Data  8.588 ( 4.419)	Loss 6.5095e-02 (1.0006e-01) 
2023-05-27 12:11:52.246263: train Epoch: [28][ 53/193]	Time  0.561 ( 4.910)	Data  0.001 ( 4.338)	Loss 6.8950e-02 (9.9486e-02) 
2023-05-27 12:12:01.396684: train Epoch: [28][ 54/193]	Time  9.150 ( 4.987)	Data  8.589 ( 4.415)	Loss 9.0852e-02 (9.9329e-02) 
2023-05-27 12:12:01.958593: train Epoch: [28][ 55/193]	Time  0.562 ( 4.908)	Data  0.001 ( 4.336)	Loss 8.0027e-02 (9.8984e-02) 
2023-05-27 12:12:11.139941: train Epoch: [28][ 56/193]	Time  9.181 ( 4.983)	Data  8.614 ( 4.411)	Loss 1.5459e-01 (9.9960e-02) 
2023-05-27 12:12:11.699889: train Epoch: [28][ 57/193]	Time  0.560 ( 4.906)	Data  0.001 ( 4.335)	Loss 5.6552e-02 (9.9211e-02) 
2023-05-27 12:12:20.994140: train Epoch: [28][ 58/193]	Time  9.294 ( 4.981)	Data  8.733 ( 4.410)	Loss 6.7593e-02 (9.8675e-02) 
2023-05-27 12:12:21.584224: train Epoch: [28][ 59/193]	Time  0.590 ( 4.908)	Data  0.030 ( 4.337)	Loss 1.4581e-01 (9.9461e-02) 
2023-05-27 12:12:30.903769: train Epoch: [28][ 60/193]	Time  9.320 ( 4.980)	Data  8.760 ( 4.409)	Loss 1.2299e-01 (9.9847e-02) 
2023-05-27 12:12:31.470758: train Epoch: [28][ 61/193]	Time  0.567 ( 4.909)	Data  0.001 ( 4.338)	Loss 6.5360e-02 (9.9291e-02) 
2023-05-27 12:12:40.681502: train Epoch: [28][ 62/193]	Time  9.211 ( 4.977)	Data  8.640 ( 4.406)	Loss 6.6485e-02 (9.8770e-02) 
2023-05-27 12:12:41.243603: train Epoch: [28][ 63/193]	Time  0.562 ( 4.908)	Data  0.001 ( 4.337)	Loss 1.2983e-01 (9.9255e-02) 
2023-05-27 12:12:50.448895: train Epoch: [28][ 64/193]	Time  9.205 ( 4.974)	Data  8.645 ( 4.404)	Loss 1.0453e-01 (9.9336e-02) 
2023-05-27 12:12:51.009466: train Epoch: [28][ 65/193]	Time  0.561 ( 4.907)	Data  0.001 ( 4.337)	Loss 4.9738e-02 (9.8585e-02) 
2023-05-27 12:12:59.689502: train Epoch: [28][ 66/193]	Time  8.680 ( 4.964)	Data  8.119 ( 4.394)	Loss 7.4509e-02 (9.8225e-02) 
2023-05-27 12:13:00.250467: train Epoch: [28][ 67/193]	Time  0.561 ( 4.899)	Data  0.001 ( 4.329)	Loss 1.6484e-01 (9.9205e-02) 
2023-05-27 12:13:09.737191: train Epoch: [28][ 68/193]	Time  9.487 ( 4.965)	Data  8.926 ( 4.396)	Loss 1.4792e-01 (9.9911e-02) 
2023-05-27 12:13:10.298332: train Epoch: [28][ 69/193]	Time  0.561 ( 4.902)	Data  0.001 ( 4.333)	Loss 4.4441e-02 (9.9119e-02) 
2023-05-27 12:13:19.542865: train Epoch: [28][ 70/193]	Time  9.245 ( 4.964)	Data  8.684 ( 4.394)	Loss 2.4130e-01 (1.0112e-01) 
2023-05-27 12:13:20.104212: train Epoch: [28][ 71/193]	Time  0.561 ( 4.902)	Data  0.001 ( 4.333)	Loss 7.7517e-02 (1.0079e-01) 
2023-05-27 12:13:29.377691: train Epoch: [28][ 72/193]	Time  9.273 ( 4.962)	Data  8.710 ( 4.393)	Loss 1.3223e-01 (1.0122e-01) 
2023-05-27 12:13:29.938953: train Epoch: [28][ 73/193]	Time  0.561 ( 4.903)	Data  0.001 ( 4.334)	Loss 1.2004e-01 (1.0148e-01) 
2023-05-27 12:13:39.132919: train Epoch: [28][ 74/193]	Time  9.194 ( 4.960)	Data  8.628 ( 4.391)	Loss 1.0473e-01 (1.0152e-01) 
2023-05-27 12:13:39.698669: train Epoch: [28][ 75/193]	Time  0.566 ( 4.902)	Data  0.001 ( 4.333)	Loss 9.4093e-02 (1.0142e-01) 
2023-05-27 12:13:49.134356: train Epoch: [28][ 76/193]	Time  9.436 ( 4.961)	Data  8.869 ( 4.392)	Loss 8.6955e-02 (1.0124e-01) 
2023-05-27 12:13:49.700021: train Epoch: [28][ 77/193]	Time  0.566 ( 4.905)	Data  0.001 ( 4.336)	Loss 1.1548e-01 (1.0142e-01) 
2023-05-27 12:13:58.801076: train Epoch: [28][ 78/193]	Time  9.101 ( 4.958)	Data  8.537 ( 4.389)	Loss 9.3912e-02 (1.0132e-01) 
2023-05-27 12:13:59.365548: train Epoch: [28][ 79/193]	Time  0.564 ( 4.903)	Data  0.001 ( 4.334)	Loss 5.7957e-02 (1.0078e-01) 
2023-05-27 12:14:08.416044: train Epoch: [28][ 80/193]	Time  9.050 ( 4.954)	Data  8.472 ( 4.385)	Loss 1.0081e-01 (1.0078e-01) 
2023-05-27 12:14:08.981375: train Epoch: [28][ 81/193]	Time  0.565 ( 4.901)	Data  0.001 ( 4.332)	Loss 6.5288e-02 (1.0035e-01) 
2023-05-27 12:14:18.127282: train Epoch: [28][ 82/193]	Time  9.146 ( 4.952)	Data  8.576 ( 4.383)	Loss 8.3038e-02 (1.0014e-01) 
2023-05-27 12:14:18.692125: train Epoch: [28][ 83/193]	Time  0.565 ( 4.900)	Data  0.001 ( 4.331)	Loss 5.8612e-02 (9.9646e-02) 
2023-05-27 12:14:28.009173: train Epoch: [28][ 84/193]	Time  9.317 ( 4.952)	Data  8.746 ( 4.383)	Loss 7.9431e-02 (9.9408e-02) 
2023-05-27 12:14:28.585054: train Epoch: [28][ 85/193]	Time  0.576 ( 4.901)	Data  0.001 ( 4.332)	Loss 8.0040e-02 (9.9183e-02) 
2023-05-27 12:14:38.168900: train Epoch: [28][ 86/193]	Time  9.584 ( 4.955)	Data  8.996 ( 4.385)	Loss 1.1119e-01 (9.9321e-02) 
2023-05-27 12:14:38.735228: train Epoch: [28][ 87/193]	Time  0.566 ( 4.905)	Data  0.001 ( 4.335)	Loss 7.3074e-02 (9.9023e-02) 
2023-05-27 12:14:48.077186: train Epoch: [28][ 88/193]	Time  9.342 ( 4.955)	Data  8.754 ( 4.385)	Loss 4.3428e-02 (9.8398e-02) 
2023-05-27 12:14:48.638291: train Epoch: [28][ 89/193]	Time  0.561 ( 4.906)	Data  0.001 ( 4.336)	Loss 5.8645e-02 (9.7956e-02) 
2023-05-27 12:14:57.354582: train Epoch: [28][ 90/193]	Time  8.716 ( 4.948)	Data  8.089 ( 4.378)	Loss 1.3890e-01 (9.8406e-02) 
2023-05-27 12:14:57.916633: train Epoch: [28][ 91/193]	Time  0.562 ( 4.900)	Data  0.001 ( 4.330)	Loss 8.8692e-02 (9.8301e-02) 
2023-05-27 12:15:06.653005: train Epoch: [28][ 92/193]	Time  8.736 ( 4.941)	Data  8.168 ( 4.371)	Loss 8.5901e-02 (9.8167e-02) 
2023-05-27 12:15:07.222960: train Epoch: [28][ 93/193]	Time  0.570 ( 4.895)	Data  0.001 ( 4.325)	Loss 5.3737e-02 (9.7695e-02) 
2023-05-27 12:15:16.197308: train Epoch: [28][ 94/193]	Time  8.974 ( 4.938)	Data  8.396 ( 4.368)	Loss 7.8577e-02 (9.7493e-02) 
2023-05-27 12:15:16.804716: train Epoch: [28][ 95/193]	Time  0.607 ( 4.892)	Data  0.005 ( 4.322)	Loss 8.9051e-02 (9.7405e-02) 
2023-05-27 12:15:25.878942: train Epoch: [28][ 96/193]	Time  9.074 ( 4.936)	Data  8.502 ( 4.365)	Loss 1.2869e-01 (9.7728e-02) 
2023-05-27 12:15:26.467051: train Epoch: [28][ 97/193]	Time  0.588 ( 4.891)	Data  0.001 ( 4.321)	Loss 1.4282e-01 (9.8188e-02) 
2023-05-27 12:15:35.578714: train Epoch: [28][ 98/193]	Time  9.112 ( 4.934)	Data  8.544 ( 4.363)	Loss 1.3982e-01 (9.8609e-02) 
2023-05-27 12:15:36.165746: train Epoch: [28][ 99/193]	Time  0.587 ( 4.890)	Data  0.001 ( 4.320)	Loss 9.3779e-02 (9.8560e-02) 
2023-05-27 12:15:45.129507: train Epoch: [28][100/193]	Time  8.964 ( 4.931)	Data  8.395 ( 4.360)	Loss 8.4121e-02 (9.8417e-02) 
2023-05-27 12:15:45.693201: train Epoch: [28][101/193]	Time  0.564 ( 4.888)	Data  0.001 ( 4.317)	Loss 1.0813e-01 (9.8513e-02) 
2023-05-27 12:15:54.604738: train Epoch: [28][102/193]	Time  8.912 ( 4.927)	Data  8.351 ( 4.357)	Loss 1.1773e-01 (9.8699e-02) 
2023-05-27 12:15:55.165861: train Epoch: [28][103/193]	Time  0.561 ( 4.885)	Data  0.001 ( 4.315)	Loss 1.6448e-01 (9.9332e-02) 
2023-05-27 12:16:04.324884: train Epoch: [28][104/193]	Time  9.159 ( 4.926)	Data  8.599 ( 4.355)	Loss 1.9698e-01 (1.0026e-01) 
2023-05-27 12:16:04.886337: train Epoch: [28][105/193]	Time  0.561 ( 4.885)	Data  0.001 ( 4.314)	Loss 1.9107e-01 (1.0112e-01) 
2023-05-27 12:16:14.031894: train Epoch: [28][106/193]	Time  9.146 ( 4.924)	Data  8.585 ( 4.354)	Loss 8.6545e-02 (1.0098e-01) 
2023-05-27 12:16:15.187882: train Epoch: [28][107/193]	Time  1.156 ( 4.889)	Data  0.594 ( 4.320)	Loss 8.6523e-02 (1.0085e-01) 
2023-05-27 12:16:23.490270: train Epoch: [28][108/193]	Time  8.302 ( 4.921)	Data  7.742 ( 4.351)	Loss 1.1379e-01 (1.0097e-01) 
2023-05-27 12:16:24.736951: train Epoch: [28][109/193]	Time  1.247 ( 4.887)	Data  0.686 ( 4.318)	Loss 3.1139e-01 (1.0288e-01) 
2023-05-27 12:16:32.963728: train Epoch: [28][110/193]	Time  8.227 ( 4.917)	Data  7.662 ( 4.348)	Loss 7.2706e-02 (1.0261e-01) 
2023-05-27 12:16:34.314082: train Epoch: [28][111/193]	Time  1.350 ( 4.886)	Data  0.788 ( 4.316)	Loss 2.6329e-01 (1.0404e-01) 
2023-05-27 12:16:42.549341: train Epoch: [28][112/193]	Time  8.235 ( 4.915)	Data  7.667 ( 4.346)	Loss 5.0722e-02 (1.0357e-01) 
2023-05-27 12:16:44.378217: train Epoch: [28][113/193]	Time  1.829 ( 4.888)	Data  1.267 ( 4.319)	Loss 7.1566e-02 (1.0329e-01) 
2023-05-27 12:16:52.292513: train Epoch: [28][114/193]	Time  7.914 ( 4.914)	Data  7.345 ( 4.345)	Loss 8.7078e-02 (1.0315e-01) 
2023-05-27 12:16:54.157570: train Epoch: [28][115/193]	Time  1.865 ( 4.888)	Data  1.304 ( 4.319)	Loss 5.4169e-02 (1.0273e-01) 
2023-05-27 12:17:02.202067: train Epoch: [28][116/193]	Time  8.044 ( 4.915)	Data  7.431 ( 4.345)	Loss 1.0646e-01 (1.0276e-01) 
2023-05-27 12:17:03.600420: train Epoch: [28][117/193]	Time  1.398 ( 4.885)	Data  0.832 ( 4.316)	Loss 1.6024e-01 (1.0325e-01) 
2023-05-27 12:17:12.262532: train Epoch: [28][118/193]	Time  8.662 ( 4.917)	Data  8.076 ( 4.347)	Loss 1.0762e-01 (1.0328e-01) 
2023-05-27 12:17:13.456537: train Epoch: [28][119/193]	Time  1.194 ( 4.886)	Data  0.627 ( 4.316)	Loss 9.0374e-02 (1.0318e-01) 
2023-05-27 12:17:22.233485: train Epoch: [28][120/193]	Time  8.777 ( 4.918)	Data  8.186 ( 4.348)	Loss 5.8521e-02 (1.0281e-01) 
2023-05-27 12:17:23.366956: train Epoch: [28][121/193]	Time  1.133 ( 4.887)	Data  0.570 ( 4.317)	Loss 7.9236e-02 (1.0261e-01) 
2023-05-27 12:17:31.983696: train Epoch: [28][122/193]	Time  8.617 ( 4.918)	Data  8.020 ( 4.347)	Loss 1.0317e-01 (1.0262e-01) 
2023-05-27 12:17:33.033370: train Epoch: [28][123/193]	Time  1.050 ( 4.886)	Data  0.490 ( 4.316)	Loss 6.4063e-02 (1.0231e-01) 
2023-05-27 12:17:42.042899: train Epoch: [28][124/193]	Time  9.010 ( 4.919)	Data  8.422 ( 4.349)	Loss 8.8453e-02 (1.0220e-01) 
2023-05-27 12:17:43.005720: train Epoch: [28][125/193]	Time  0.963 ( 4.888)	Data  0.401 ( 4.318)	Loss 2.6759e-01 (1.0351e-01) 
2023-05-27 12:17:52.225504: train Epoch: [28][126/193]	Time  9.220 ( 4.922)	Data  8.623 ( 4.352)	Loss 1.4952e-01 (1.0387e-01) 
2023-05-27 12:17:52.787164: train Epoch: [28][127/193]	Time  0.562 ( 4.888)	Data  0.001 ( 4.318)	Loss 8.4507e-02 (1.0372e-01) 
2023-05-27 12:18:01.627817: train Epoch: [28][128/193]	Time  8.841 ( 4.919)	Data  8.255 ( 4.348)	Loss 1.1380e-01 (1.0380e-01) 
2023-05-27 12:18:02.376938: train Epoch: [28][129/193]	Time  0.749 ( 4.887)	Data  0.159 ( 4.316)	Loss 1.0737e-01 (1.0382e-01) 
2023-05-27 12:18:11.514452: train Epoch: [28][130/193]	Time  9.137 ( 4.919)	Data  8.560 ( 4.348)	Loss 8.4522e-02 (1.0368e-01) 
2023-05-27 12:18:12.387879: train Epoch: [28][131/193]	Time  0.873 ( 4.888)	Data  0.254 ( 4.317)	Loss 8.6047e-02 (1.0354e-01) 
2023-05-27 12:18:21.463913: train Epoch: [28][132/193]	Time  9.076 ( 4.920)	Data  8.483 ( 4.349)	Loss 4.7267e-02 (1.0312e-01) 
2023-05-27 12:18:22.488168: train Epoch: [28][133/193]	Time  1.024 ( 4.891)	Data  0.455 ( 4.319)	Loss 6.6822e-02 (1.0285e-01) 
2023-05-27 12:18:31.446250: train Epoch: [28][134/193]	Time  8.958 ( 4.921)	Data  8.386 ( 4.350)	Loss 8.9898e-02 (1.0275e-01) 
2023-05-27 12:18:32.259666: train Epoch: [28][135/193]	Time  0.813 ( 4.891)	Data  0.223 ( 4.319)	Loss 8.0448e-02 (1.0259e-01) 
2023-05-27 12:18:41.498211: train Epoch: [28][136/193]	Time  9.239 ( 4.922)	Data  8.662 ( 4.351)	Loss 8.9628e-02 (1.0250e-01) 
2023-05-27 12:18:42.192585: train Epoch: [28][137/193]	Time  0.694 ( 4.892)	Data  0.131 ( 4.320)	Loss 9.4469e-02 (1.0244e-01) 
2023-05-27 12:18:51.412150: train Epoch: [28][138/193]	Time  9.220 ( 4.923)	Data  8.623 ( 4.351)	Loss 4.9345e-02 (1.0206e-01) 
2023-05-27 12:18:51.982777: train Epoch: [28][139/193]	Time  0.571 ( 4.892)	Data  0.001 ( 4.320)	Loss 9.3530e-02 (1.0199e-01) 
2023-05-27 12:19:00.777542: train Epoch: [28][140/193]	Time  8.795 ( 4.920)	Data  8.231 ( 4.348)	Loss 1.8250e-01 (1.0257e-01) 
2023-05-27 12:19:01.585490: train Epoch: [28][141/193]	Time  0.808 ( 4.891)	Data  0.224 ( 4.319)	Loss 1.1663e-01 (1.0266e-01) 
2023-05-27 12:19:11.106645: train Epoch: [28][142/193]	Time  9.521 ( 4.923)	Data  8.945 ( 4.351)	Loss 9.0701e-02 (1.0258e-01) 
2023-05-27 12:19:11.700868: train Epoch: [28][143/193]	Time  0.594 ( 4.893)	Data  0.001 ( 4.321)	Loss 1.1389e-01 (1.0266e-01) 
2023-05-27 12:19:20.867397: train Epoch: [28][144/193]	Time  9.167 ( 4.922)	Data  8.605 ( 4.351)	Loss 5.4292e-02 (1.0233e-01) 
2023-05-27 12:19:21.669907: train Epoch: [28][145/193]	Time  0.803 ( 4.894)	Data  0.216 ( 4.322)	Loss 7.3271e-02 (1.0213e-01) 
2023-05-27 12:19:30.689441: train Epoch: [28][146/193]	Time  9.020 ( 4.922)	Data  8.458 ( 4.350)	Loss 1.0638e-01 (1.0216e-01) 
2023-05-27 12:19:31.253710: train Epoch: [28][147/193]	Time  0.564 ( 4.893)	Data  0.001 ( 4.321)	Loss 1.1116e-01 (1.0222e-01) 
2023-05-27 12:19:40.438739: train Epoch: [28][148/193]	Time  9.185 ( 4.922)	Data  8.617 ( 4.350)	Loss 1.0008e-01 (1.0220e-01) 
2023-05-27 12:19:41.002143: train Epoch: [28][149/193]	Time  0.563 ( 4.893)	Data  0.001 ( 4.321)	Loss 9.6158e-02 (1.0216e-01) 
2023-05-27 12:19:50.166237: train Epoch: [28][150/193]	Time  9.164 ( 4.921)	Data  8.600 ( 4.349)	Loss 8.6907e-02 (1.0206e-01) 
2023-05-27 12:19:50.736299: train Epoch: [28][151/193]	Time  0.570 ( 4.892)	Data  0.001 ( 4.321)	Loss 1.0331e-01 (1.0207e-01) 
2023-05-27 12:19:59.968215: train Epoch: [28][152/193]	Time  9.232 ( 4.921)	Data  8.664 ( 4.349)	Loss 5.0799e-02 (1.0173e-01) 
2023-05-27 12:20:00.541219: train Epoch: [28][153/193]	Time  0.573 ( 4.892)	Data  0.001 ( 4.321)	Loss 8.2089e-02 (1.0161e-01) 
2023-05-27 12:20:09.730080: train Epoch: [28][154/193]	Time  9.189 ( 4.920)	Data  8.627 ( 4.349)	Loss 9.4795e-02 (1.0156e-01) 
2023-05-27 12:20:10.294124: train Epoch: [28][155/193]	Time  0.564 ( 4.892)	Data  0.001 ( 4.321)	Loss 1.2887e-01 (1.0174e-01) 
2023-05-27 12:20:19.550869: train Epoch: [28][156/193]	Time  9.257 ( 4.920)	Data  8.690 ( 4.349)	Loss 1.1311e-01 (1.0181e-01) 
2023-05-27 12:20:20.117131: train Epoch: [28][157/193]	Time  0.566 ( 4.892)	Data  0.001 ( 4.321)	Loss 9.0273e-02 (1.0174e-01) 
2023-05-27 12:20:28.748396: train Epoch: [28][158/193]	Time  8.631 ( 4.916)	Data  8.060 ( 4.345)	Loss 8.6281e-02 (1.0164e-01) 
2023-05-27 12:20:29.514167: train Epoch: [28][159/193]	Time  0.766 ( 4.890)	Data  0.194 ( 4.319)	Loss 5.5314e-02 (1.0135e-01) 
2023-05-27 12:20:38.579495: train Epoch: [28][160/193]	Time  9.065 ( 4.916)	Data  8.495 ( 4.345)	Loss 6.6937e-02 (1.0114e-01) 
2023-05-27 12:20:39.161258: train Epoch: [28][161/193]	Time  0.582 ( 4.889)	Data  0.001 ( 4.318)	Loss 2.4018e-01 (1.0199e-01) 
2023-05-27 12:20:48.391371: train Epoch: [28][162/193]	Time  9.230 ( 4.916)	Data  8.664 ( 4.344)	Loss 7.5776e-02 (1.0183e-01) 
2023-05-27 12:20:48.965084: train Epoch: [28][163/193]	Time  0.574 ( 4.889)	Data  0.001 ( 4.318)	Loss 4.5970e-02 (1.0149e-01) 
2023-05-27 12:20:58.071754: train Epoch: [28][164/193]	Time  9.107 ( 4.915)	Data  8.538 ( 4.343)	Loss 6.3809e-02 (1.0126e-01) 
2023-05-27 12:20:59.466351: train Epoch: [28][165/193]	Time  1.395 ( 4.894)	Data  0.830 ( 4.322)	Loss 9.8704e-02 (1.0125e-01) 
2023-05-27 12:21:07.871330: train Epoch: [28][166/193]	Time  8.405 ( 4.915)	Data  7.844 ( 4.343)	Loss 1.0923e-01 (1.0130e-01) 
2023-05-27 12:21:09.499572: train Epoch: [28][167/193]	Time  1.628 ( 4.895)	Data  1.065 ( 4.324)	Loss 7.7372e-02 (1.0115e-01) 
2023-05-27 12:21:18.041857: train Epoch: [28][168/193]	Time  8.542 ( 4.917)	Data  7.971 ( 4.345)	Loss 7.7054e-02 (1.0101e-01) 
2023-05-27 12:21:18.928598: train Epoch: [28][169/193]	Time  0.887 ( 4.893)	Data  0.323 ( 4.322)	Loss 1.1151e-01 (1.0107e-01) 
2023-05-27 12:21:28.125134: train Epoch: [28][170/193]	Time  9.197 ( 4.918)	Data  8.634 ( 4.347)	Loss 1.1334e-01 (1.0115e-01) 
2023-05-27 12:21:28.914939: train Epoch: [28][171/193]	Time  0.790 ( 4.894)	Data  0.214 ( 4.323)	Loss 6.5694e-02 (1.0094e-01) 
2023-05-27 12:21:37.952049: train Epoch: [28][172/193]	Time  9.037 ( 4.918)	Data  8.477 ( 4.347)	Loss 8.3026e-02 (1.0084e-01) 
2023-05-27 12:21:38.517010: train Epoch: [28][173/193]	Time  0.565 ( 4.893)	Data  0.001 ( 4.322)	Loss 1.5051e-01 (1.0112e-01) 
2023-05-27 12:21:47.674400: train Epoch: [28][174/193]	Time  9.157 ( 4.917)	Data  8.598 ( 4.346)	Loss 1.2077e-01 (1.0123e-01) 
2023-05-27 12:21:48.234915: train Epoch: [28][175/193]	Time  0.561 ( 4.893)	Data  0.001 ( 4.322)	Loss 6.0319e-02 (1.0100e-01) 
2023-05-27 12:21:57.489218: train Epoch: [28][176/193]	Time  9.254 ( 4.917)	Data  8.688 ( 4.346)	Loss 5.3543e-02 (1.0073e-01) 
2023-05-27 12:21:58.051038: train Epoch: [28][177/193]	Time  0.562 ( 4.893)	Data  0.001 ( 4.322)	Loss 7.0513e-02 (1.0056e-01) 
2023-05-27 12:22:07.078945: train Epoch: [28][178/193]	Time  9.028 ( 4.916)	Data  8.456 ( 4.345)	Loss 1.3536e-01 (1.0076e-01) 
2023-05-27 12:22:07.639009: train Epoch: [28][179/193]	Time  0.560 ( 4.892)	Data  0.001 ( 4.321)	Loss 1.6521e-01 (1.0112e-01) 
2023-05-27 12:22:16.883516: train Epoch: [28][180/193]	Time  9.245 ( 4.916)	Data  8.684 ( 4.345)	Loss 1.4129e-01 (1.0134e-01) 
2023-05-27 12:22:17.444098: train Epoch: [28][181/193]	Time  0.561 ( 4.892)	Data  0.001 ( 4.321)	Loss 7.8878e-02 (1.0121e-01) 
2023-05-27 12:22:26.884912: train Epoch: [28][182/193]	Time  9.441 ( 4.917)	Data  8.872 ( 4.346)	Loss 6.3858e-02 (1.0101e-01) 
2023-05-27 12:22:27.455610: train Epoch: [28][183/193]	Time  0.571 ( 4.893)	Data  0.010 ( 4.323)	Loss 9.2739e-02 (1.0097e-01) 
2023-05-27 12:22:36.945617: train Epoch: [28][184/193]	Time  9.490 ( 4.918)	Data  8.929 ( 4.347)	Loss 8.7757e-02 (1.0089e-01) 
2023-05-27 12:22:37.510226: train Epoch: [28][185/193]	Time  0.565 ( 4.895)	Data  0.001 ( 4.324)	Loss 5.7017e-02 (1.0066e-01) 
2023-05-27 12:22:46.480762: train Epoch: [28][186/193]	Time  8.971 ( 4.916)	Data  8.400 ( 4.346)	Loss 8.0328e-02 (1.0055e-01) 
2023-05-27 12:22:47.123729: train Epoch: [28][187/193]	Time  0.643 ( 4.894)	Data  0.083 ( 4.323)	Loss 1.2766e-01 (1.0069e-01) 
2023-05-27 12:22:56.543161: train Epoch: [28][188/193]	Time  9.419 ( 4.918)	Data  8.858 ( 4.347)	Loss 8.1529e-02 (1.0059e-01) 
2023-05-27 12:22:57.104492: train Epoch: [28][189/193]	Time  0.561 ( 4.895)	Data  0.001 ( 4.324)	Loss 1.2279e-01 (1.0071e-01) 
2023-05-27 12:23:06.604368: train Epoch: [28][190/193]	Time  9.500 ( 4.919)	Data  8.939 ( 4.348)	Loss 1.5003e-01 (1.0097e-01) 
2023-05-27 12:23:07.174905: train Epoch: [28][191/193]	Time  0.571 ( 4.896)	Data  0.001 ( 4.326)	Loss 1.2871e-01 (1.0111e-01) 
2023-05-27 12:23:15.381270: train Epoch: [28][192/193]	Time  8.206 ( 4.913)	Data  7.644 ( 4.343)	Loss 7.0946e-02 (1.0096e-01) 
2023-05-27 12:23:15.551907: Train Epoch done in 948.4279376929917 s 
2023-05-27 12:23:22.219708: val Epoch: [28][ 0/72]	Time  5.859 ( 5.859)	Data  5.678 ( 5.678)	Loss 5.1705e-01 (5.1705e-01) 
2023-05-27 12:23:22.480198: val Epoch: [28][ 1/72]	Time  0.261 ( 3.060)	Data  0.152 ( 2.915)	Loss 3.7078e-01 (4.4391e-01) 
2023-05-27 12:23:26.986183: val Epoch: [28][ 2/72]	Time  4.506 ( 3.542)	Data  4.390 ( 3.407)	Loss 4.3527e-02 (3.1045e-01) 
2023-05-27 12:23:27.323568: val Epoch: [28][ 3/72]	Time  0.337 ( 2.741)	Data  0.230 ( 2.612)	Loss 3.5695e-01 (3.2208e-01) 
2023-05-27 12:23:31.716428: val Epoch: [28][ 4/72]	Time  4.393 ( 3.071)	Data  4.284 ( 2.947)	Loss 4.2660e-02 (2.6619e-01) 
2023-05-27 12:23:32.212710: val Epoch: [28][ 5/72]	Time  0.496 ( 2.642)	Data  0.390 ( 2.521)	Loss 1.8089e-01 (2.5198e-01) 
2023-05-27 12:23:37.019273: val Epoch: [28][ 6/72]	Time  4.807 ( 2.951)	Data  4.643 ( 2.824)	Loss 6.7424e-02 (2.2561e-01) 
2023-05-27 12:23:37.359901: val Epoch: [28][ 7/72]	Time  0.341 ( 2.625)	Data  0.234 ( 2.500)	Loss 9.9770e-02 (2.0988e-01) 
2023-05-27 12:23:41.872570: val Epoch: [28][ 8/72]	Time  4.513 ( 2.835)	Data  4.404 ( 2.712)	Loss 1.2477e-01 (2.0042e-01) 
2023-05-27 12:23:42.258243: val Epoch: [28][ 9/72]	Time  0.386 ( 2.590)	Data  0.272 ( 2.468)	Loss 4.5239e-02 (1.8491e-01) 
2023-05-27 12:23:46.625760: val Epoch: [28][10/72]	Time  4.368 ( 2.751)	Data  4.262 ( 2.631)	Loss 5.3257e-02 (1.7294e-01) 
2023-05-27 12:23:47.009614: val Epoch: [28][11/72]	Time  0.384 ( 2.554)	Data  0.268 ( 2.434)	Loss 5.4660e-02 (1.6308e-01) 
2023-05-27 12:23:52.040827: val Epoch: [28][12/72]	Time  5.031 ( 2.745)	Data  4.906 ( 2.624)	Loss 5.2458e-02 (1.5457e-01) 
2023-05-27 12:23:52.154633: val Epoch: [28][13/72]	Time  0.114 ( 2.557)	Data  0.001 ( 2.437)	Loss 5.9061e-02 (1.4775e-01) 
2023-05-27 12:23:56.986712: val Epoch: [28][14/72]	Time  4.832 ( 2.708)	Data  4.719 ( 2.589)	Loss 5.7906e-02 (1.4176e-01) 
2023-05-27 12:23:57.096447: val Epoch: [28][15/72]	Time  0.110 ( 2.546)	Data  0.001 ( 2.427)	Loss 6.9503e-02 (1.3724e-01) 
2023-05-27 12:24:02.092562: val Epoch: [28][16/72]	Time  4.996 ( 2.690)	Data  4.890 ( 2.572)	Loss 1.4903e-01 (1.3794e-01) 
2023-05-27 12:24:02.198239: val Epoch: [28][17/72]	Time  0.106 ( 2.547)	Data  0.000 ( 2.429)	Loss 4.2673e-02 (1.3264e-01) 
2023-05-27 12:24:07.160292: val Epoch: [28][18/72]	Time  4.962 ( 2.674)	Data  4.855 ( 2.557)	Loss 6.8070e-01 (1.6149e-01) 
2023-05-27 12:24:07.270957: val Epoch: [28][19/72]	Time  0.111 ( 2.546)	Data  0.001 ( 2.429)	Loss 1.4795e-01 (1.6081e-01) 
2023-05-27 12:24:12.344406: val Epoch: [28][20/72]	Time  5.073 ( 2.666)	Data  4.957 ( 2.549)	Loss 2.9548e-01 (1.6723e-01) 
2023-05-27 12:24:12.458570: val Epoch: [28][21/72]	Time  0.114 ( 2.550)	Data  0.001 ( 2.433)	Loss 8.5229e-02 (1.6350e-01) 
2023-05-27 12:24:17.088518: val Epoch: [28][22/72]	Time  4.630 ( 2.640)	Data  4.523 ( 2.524)	Loss 4.1845e-02 (1.5821e-01) 
2023-05-27 12:24:17.196889: val Epoch: [28][23/72]	Time  0.108 ( 2.535)	Data  0.001 ( 2.419)	Loss 6.2995e-02 (1.5424e-01) 
2023-05-27 12:24:22.122834: val Epoch: [28][24/72]	Time  4.926 ( 2.630)	Data  4.814 ( 2.515)	Loss 1.4864e-01 (1.5402e-01) 
2023-05-27 12:24:22.233511: val Epoch: [28][25/72]	Time  0.111 ( 2.534)	Data  0.001 ( 2.418)	Loss 3.9077e-01 (1.6312e-01) 
2023-05-27 12:24:27.028412: val Epoch: [28][26/72]	Time  4.795 ( 2.617)	Data  4.687 ( 2.502)	Loss 4.1881e-02 (1.5863e-01) 
2023-05-27 12:24:27.136837: val Epoch: [28][27/72]	Time  0.108 ( 2.528)	Data  0.001 ( 2.413)	Loss 1.0048e-01 (1.5656e-01) 
2023-05-27 12:24:32.091326: val Epoch: [28][28/72]	Time  4.955 ( 2.611)	Data  4.850 ( 2.497)	Loss 1.0785e-01 (1.5488e-01) 
2023-05-27 12:24:32.195979: val Epoch: [28][29/72]	Time  0.105 ( 2.528)	Data  0.000 ( 2.414)	Loss 2.1328e-01 (1.5682e-01) 
2023-05-27 12:24:37.107119: val Epoch: [28][30/72]	Time  4.911 ( 2.605)	Data  4.805 ( 2.491)	Loss 2.0285e-01 (1.5831e-01) 
2023-05-27 12:24:37.218889: val Epoch: [28][31/72]	Time  0.112 ( 2.527)	Data  0.001 ( 2.413)	Loss 1.4259e-01 (1.5782e-01) 
2023-05-27 12:24:41.991390: val Epoch: [28][32/72]	Time  4.773 ( 2.595)	Data  4.668 ( 2.481)	Loss 5.2924e-02 (1.5464e-01) 
2023-05-27 12:24:42.095997: val Epoch: [28][33/72]	Time  0.105 ( 2.522)	Data  0.001 ( 2.408)	Loss 9.0871e-02 (1.5276e-01) 
2023-05-27 12:24:46.648634: val Epoch: [28][34/72]	Time  4.553 ( 2.580)	Data  4.436 ( 2.466)	Loss 5.7923e-02 (1.5005e-01) 
2023-05-27 12:24:46.757696: val Epoch: [28][35/72]	Time  0.109 ( 2.511)	Data  0.001 ( 2.398)	Loss 1.2950e-01 (1.4948e-01) 
2023-05-27 12:24:51.382502: val Epoch: [28][36/72]	Time  4.625 ( 2.568)	Data  4.515 ( 2.455)	Loss 5.7879e-02 (1.4701e-01) 
2023-05-27 12:24:51.490658: val Epoch: [28][37/72]	Time  0.108 ( 2.503)	Data  0.001 ( 2.391)	Loss 3.4098e-01 (1.5211e-01) 
2023-05-27 12:24:56.717264: val Epoch: [28][38/72]	Time  5.227 ( 2.573)	Data  5.108 ( 2.460)	Loss 7.3876e-02 (1.5010e-01) 
2023-05-27 12:24:56.846045: val Epoch: [28][39/72]	Time  0.129 ( 2.512)	Data  0.001 ( 2.399)	Loss 8.0240e-02 (1.4836e-01) 
2023-05-27 12:25:01.591084: val Epoch: [28][40/72]	Time  4.745 ( 2.567)	Data  4.639 ( 2.453)	Loss 9.2156e-02 (1.4699e-01) 
2023-05-27 12:25:01.697136: val Epoch: [28][41/72]	Time  0.106 ( 2.508)	Data  0.000 ( 2.395)	Loss 5.5186e-02 (1.4480e-01) 
2023-05-27 12:25:06.552490: val Epoch: [28][42/72]	Time  4.855 ( 2.563)	Data  4.750 ( 2.450)	Loss 6.5713e-02 (1.4296e-01) 
2023-05-27 12:25:06.658179: val Epoch: [28][43/72]	Time  0.106 ( 2.507)	Data  0.000 ( 2.394)	Loss 4.2874e-02 (1.4069e-01) 
2023-05-27 12:25:11.390841: val Epoch: [28][44/72]	Time  4.733 ( 2.556)	Data  4.623 ( 2.444)	Loss 7.6834e-02 (1.3927e-01) 
2023-05-27 12:25:11.504738: val Epoch: [28][45/72]	Time  0.114 ( 2.503)	Data  0.001 ( 2.391)	Loss 3.0573e-01 (1.4289e-01) 
2023-05-27 12:25:16.151407: val Epoch: [28][46/72]	Time  4.647 ( 2.549)	Data  4.536 ( 2.436)	Loss 9.3102e-02 (1.4183e-01) 
2023-05-27 12:25:16.260139: val Epoch: [28][47/72]	Time  0.109 ( 2.498)	Data  0.001 ( 2.385)	Loss 3.1847e-01 (1.4551e-01) 
2023-05-27 12:25:21.282670: val Epoch: [28][48/72]	Time  5.023 ( 2.549)	Data  4.914 ( 2.437)	Loss 5.0659e-02 (1.4357e-01) 
2023-05-27 12:25:21.390724: val Epoch: [28][49/72]	Time  0.108 ( 2.501)	Data  0.001 ( 2.388)	Loss 1.0702e-01 (1.4284e-01) 
2023-05-27 12:25:26.404630: val Epoch: [28][50/72]	Time  5.014 ( 2.550)	Data  4.906 ( 2.438)	Loss 1.0413e-01 (1.4208e-01) 
2023-05-27 12:25:26.512585: val Epoch: [28][51/72]	Time  0.108 ( 2.503)	Data  0.001 ( 2.391)	Loss 8.0776e-02 (1.4090e-01) 
2023-05-27 12:25:31.190242: val Epoch: [28][52/72]	Time  4.678 ( 2.544)	Data  4.570 ( 2.432)	Loss 4.4176e-02 (1.3908e-01) 
2023-05-27 12:25:31.650837: val Epoch: [28][53/72]	Time  0.461 ( 2.505)	Data  0.345 ( 2.393)	Loss 7.0493e-02 (1.3781e-01) 
2023-05-27 12:25:36.212815: val Epoch: [28][54/72]	Time  4.562 ( 2.543)	Data  4.457 ( 2.431)	Loss 1.4141e-01 (1.3787e-01) 
2023-05-27 12:25:36.795265: val Epoch: [28][55/72]	Time  0.582 ( 2.508)	Data  0.476 ( 2.396)	Loss 1.2891e-01 (1.3771e-01) 
2023-05-27 12:25:41.367223: val Epoch: [28][56/72]	Time  4.572 ( 2.544)	Data  4.467 ( 2.432)	Loss 1.6450e-01 (1.3818e-01) 
2023-05-27 12:25:41.903387: val Epoch: [28][57/72]	Time  0.536 ( 2.509)	Data  0.414 ( 2.397)	Loss 1.4453e-01 (1.3829e-01) 
2023-05-27 12:25:46.449431: val Epoch: [28][58/72]	Time  4.546 ( 2.544)	Data  4.441 ( 2.432)	Loss 9.9620e-02 (1.3764e-01) 
2023-05-27 12:25:46.811710: val Epoch: [28][59/72]	Time  0.362 ( 2.508)	Data  0.209 ( 2.395)	Loss 2.7569e-01 (1.3994e-01) 
2023-05-27 12:25:51.229722: val Epoch: [28][60/72]	Time  4.418 ( 2.539)	Data  4.311 ( 2.426)	Loss 1.1536e-01 (1.3954e-01) 
2023-05-27 12:25:51.631097: val Epoch: [28][61/72]	Time  0.401 ( 2.504)	Data  0.284 ( 2.392)	Loss 4.9916e-02 (1.3809e-01) 
2023-05-27 12:25:56.302364: val Epoch: [28][62/72]	Time  4.671 ( 2.539)	Data  4.561 ( 2.426)	Loss 6.6938e-02 (1.3696e-01) 
2023-05-27 12:25:56.802080: val Epoch: [28][63/72]	Time  0.500 ( 2.507)	Data  0.391 ( 2.395)	Loss 6.4491e-01 (1.4490e-01) 
2023-05-27 12:26:00.969676: val Epoch: [28][64/72]	Time  4.168 ( 2.532)	Data  4.059 ( 2.420)	Loss 6.4038e-02 (1.4365e-01) 
2023-05-27 12:26:01.958870: val Epoch: [28][65/72]	Time  0.989 ( 2.509)	Data  0.882 ( 2.397)	Loss 1.1108e-01 (1.4316e-01) 
2023-05-27 12:26:05.932538: val Epoch: [28][66/72]	Time  3.974 ( 2.531)	Data  3.866 ( 2.419)	Loss 6.3568e-02 (1.4197e-01) 
2023-05-27 12:26:06.711659: val Epoch: [28][67/72]	Time  0.779 ( 2.505)	Data  0.616 ( 2.392)	Loss 8.0320e-02 (1.4107e-01) 
2023-05-27 12:26:10.595355: val Epoch: [28][68/72]	Time  3.884 ( 2.525)	Data  3.775 ( 2.412)	Loss 9.1737e-02 (1.4035e-01) 
2023-05-27 12:26:11.656225: val Epoch: [28][69/72]	Time  1.061 ( 2.504)	Data  0.953 ( 2.391)	Loss 6.1562e-02 (1.3922e-01) 
2023-05-27 12:26:15.767777: val Epoch: [28][70/72]	Time  4.112 ( 2.527)	Data  4.003 ( 2.414)	Loss 6.7387e-01 (1.4676e-01) 
2023-05-27 12:26:16.569077: val Epoch: [28][71/72]	Time  0.801 ( 2.503)	Data  0.690 ( 2.390)	Loss 4.0876e-02 (1.4528e-01) 
2023-05-27 12:26:16.889473: Epoch 28 :Val : ['ET : 0.7440411448478699', 'TC : 0.7654869556427002', 'WT : 0.8309438824653625'] 
2023-05-27 12:26:16.890399: Epoch 28 :Val : ['ET : 0.7440411448478699', 'TC : 0.7654869556427002', 'WT : 0.8309438824653625'] 
2023-05-27 12:26:16.895109: Val epoch done in 181.3432022880006 s 
2023-05-27 12:26:16.903831: Batches per epoch:  193 
2023-05-27 12:26:28.064138: train Epoch: [29][  0/193]	Time 11.160 (11.160)	Data 10.527 (10.527)	Loss 8.1994e-02 (8.1994e-02) 
2023-05-27 12:26:28.625456: train Epoch: [29][  1/193]	Time  0.561 ( 5.861)	Data  0.001 ( 5.264)	Loss 7.1623e-02 (7.6808e-02) 
2023-05-27 12:26:37.777223: train Epoch: [29][  2/193]	Time  9.152 ( 6.958)	Data  8.585 ( 6.371)	Loss 7.0311e-02 (7.4643e-02) 
2023-05-27 12:26:38.339048: train Epoch: [29][  3/193]	Time  0.562 ( 5.359)	Data  0.001 ( 4.778)	Loss 6.1835e-02 (7.1441e-02) 
2023-05-27 12:26:47.345170: train Epoch: [29][  4/193]	Time  9.006 ( 6.088)	Data  8.430 ( 5.509)	Loss 6.9707e-02 (7.1094e-02) 
2023-05-27 12:26:47.905326: train Epoch: [29][  5/193]	Time  0.560 ( 5.167)	Data  0.001 ( 4.591)	Loss 6.7121e-02 (7.0432e-02) 
2023-05-27 12:26:56.845142: train Epoch: [29][  6/193]	Time  8.940 ( 5.706)	Data  8.369 ( 5.131)	Loss 6.0188e-02 (6.8968e-02) 
2023-05-27 12:26:57.437667: train Epoch: [29][  7/193]	Time  0.593 ( 5.067)	Data  0.001 ( 4.489)	Loss 1.0130e-01 (7.3009e-02) 
2023-05-27 12:27:06.710857: train Epoch: [29][  8/193]	Time  9.273 ( 5.534)	Data  8.683 ( 4.955)	Loss 1.2828e-01 (7.9151e-02) 
2023-05-27 12:27:07.281133: train Epoch: [29][  9/193]	Time  0.570 ( 5.038)	Data  0.001 ( 4.460)	Loss 6.6885e-02 (7.7924e-02) 
2023-05-27 12:27:16.422122: train Epoch: [29][ 10/193]	Time  9.141 ( 5.411)	Data  8.572 ( 4.834)	Loss 9.6322e-02 (7.9597e-02) 
2023-05-27 12:27:16.990657: train Epoch: [29][ 11/193]	Time  0.569 ( 5.007)	Data  0.001 ( 4.431)	Loss 1.1609e-01 (8.2638e-02) 
2023-05-27 12:27:26.224311: train Epoch: [29][ 12/193]	Time  9.234 ( 5.332)	Data  8.665 ( 4.757)	Loss 9.7692e-02 (8.3796e-02) 
2023-05-27 12:27:26.797654: train Epoch: [29][ 13/193]	Time  0.573 ( 4.992)	Data  0.001 ( 4.417)	Loss 7.7230e-02 (8.3327e-02) 
2023-05-27 12:27:36.003037: train Epoch: [29][ 14/193]	Time  9.205 ( 5.273)	Data  8.607 ( 4.696)	Loss 1.2357e-01 (8.6010e-02) 
2023-05-27 12:27:36.567113: train Epoch: [29][ 15/193]	Time  0.564 ( 4.979)	Data  0.001 ( 4.403)	Loss 1.4160e-01 (8.9484e-02) 
2023-05-27 12:27:45.889277: train Epoch: [29][ 16/193]	Time  9.322 ( 5.234)	Data  8.759 ( 4.659)	Loss 1.0925e-01 (9.0647e-02) 
2023-05-27 12:27:46.459496: train Epoch: [29][ 17/193]	Time  0.570 ( 4.975)	Data  0.001 ( 4.400)	Loss 1.1197e-01 (9.1831e-02) 
2023-05-27 12:27:55.833375: train Epoch: [29][ 18/193]	Time  9.374 ( 5.207)	Data  8.804 ( 4.632)	Loss 1.0036e-01 (9.2280e-02) 
2023-05-27 12:27:56.628937: train Epoch: [29][ 19/193]	Time  0.796 ( 4.986)	Data  0.222 ( 4.412)	Loss 5.8704e-02 (9.0601e-02) 
2023-05-27 12:28:05.533244: train Epoch: [29][ 20/193]	Time  8.904 ( 5.173)	Data  8.334 ( 4.598)	Loss 5.5033e-02 (8.8907e-02) 
2023-05-27 12:28:07.160594: train Epoch: [29][ 21/193]	Time  1.627 ( 5.012)	Data  1.055 ( 4.437)	Loss 6.8907e-02 (8.7998e-02) 
2023-05-27 12:28:15.038144: train Epoch: [29][ 22/193]	Time  7.878 ( 5.136)	Data  7.316 ( 4.562)	Loss 1.1629e-01 (8.9228e-02) 
2023-05-27 12:28:16.806761: train Epoch: [29][ 23/193]	Time  1.769 ( 4.996)	Data  1.187 ( 4.422)	Loss 8.7235e-02 (8.9145e-02) 
2023-05-27 12:28:25.328857: train Epoch: [29][ 24/193]	Time  8.522 ( 5.137)	Data  7.954 ( 4.563)	Loss 8.9962e-02 (8.9178e-02) 
2023-05-27 12:28:26.643169: train Epoch: [29][ 25/193]	Time  1.314 ( 4.990)	Data  0.723 ( 4.415)	Loss 1.0983e-01 (8.9972e-02) 
2023-05-27 12:28:34.830292: train Epoch: [29][ 26/193]	Time  8.187 ( 5.108)	Data  7.621 ( 4.534)	Loss 1.0106e-01 (9.0383e-02) 
2023-05-27 12:28:36.516126: train Epoch: [29][ 27/193]	Time  1.686 ( 4.986)	Data  1.120 ( 4.412)	Loss 5.6240e-02 (8.9164e-02) 
2023-05-27 12:28:43.879104: train Epoch: [29][ 28/193]	Time  7.363 ( 5.068)	Data  6.796 ( 4.494)	Loss 3.6534e-02 (8.7349e-02) 
2023-05-27 12:28:45.605276: train Epoch: [29][ 29/193]	Time  1.726 ( 4.957)	Data  1.149 ( 4.383)	Loss 7.6212e-02 (8.6978e-02) 
2023-05-27 12:28:51.542787: train Epoch: [29][ 30/193]	Time  5.938 ( 4.988)	Data  5.376 ( 4.415)	Loss 5.1968e-02 (8.5848e-02) 
2023-05-27 12:28:53.463149: train Epoch: [29][ 31/193]	Time  1.920 ( 4.892)	Data  1.355 ( 4.319)	Loss 1.0292e-01 (8.6382e-02) 
2023-05-27 12:28:59.642727: train Epoch: [29][ 32/193]	Time  6.180 ( 4.931)	Data  5.616 ( 4.359)	Loss 1.7569e-01 (8.9088e-02) 
2023-05-27 12:29:01.636559: train Epoch: [29][ 33/193]	Time  1.994 ( 4.845)	Data  1.433 ( 4.273)	Loss 6.5113e-02 (8.8383e-02) 
2023-05-27 12:29:08.515400: train Epoch: [29][ 34/193]	Time  6.879 ( 4.903)	Data  6.308 ( 4.331)	Loss 5.6502e-02 (8.7472e-02) 
2023-05-27 12:29:11.376165: train Epoch: [29][ 35/193]	Time  2.861 ( 4.846)	Data  2.299 ( 4.274)	Loss 1.1954e-01 (8.8363e-02) 
2023-05-27 12:29:18.343035: train Epoch: [29][ 36/193]	Time  6.967 ( 4.904)	Data  6.407 ( 4.332)	Loss 4.7356e-02 (8.7255e-02) 
2023-05-27 12:29:21.238194: train Epoch: [29][ 37/193]	Time  2.895 ( 4.851)	Data  2.334 ( 4.279)	Loss 5.6569e-02 (8.6447e-02) 
2023-05-27 12:29:28.019760: train Epoch: [29][ 38/193]	Time  6.782 ( 4.900)	Data  6.222 ( 4.329)	Loss 1.8742e-01 (8.9036e-02) 
2023-05-27 12:29:31.318272: train Epoch: [29][ 39/193]	Time  3.299 ( 4.860)	Data  2.737 ( 4.289)	Loss 1.0326e-01 (8.9392e-02) 
2023-05-27 12:29:37.888862: train Epoch: [29][ 40/193]	Time  6.571 ( 4.902)	Data  6.006 ( 4.331)	Loss 8.0642e-02 (8.9178e-02) 
2023-05-27 12:29:41.484332: train Epoch: [29][ 41/193]	Time  3.595 ( 4.871)	Data  3.027 ( 4.300)	Loss 1.2749e-01 (9.0090e-02) 
2023-05-27 12:29:47.886617: train Epoch: [29][ 42/193]	Time  6.402 ( 4.907)	Data  5.842 ( 4.336)	Loss 8.6981e-02 (9.0018e-02) 
2023-05-27 12:29:51.310775: train Epoch: [29][ 43/193]	Time  3.424 ( 4.873)	Data  2.855 ( 4.302)	Loss 2.5130e-01 (9.3684e-02) 
2023-05-27 12:29:57.878422: train Epoch: [29][ 44/193]	Time  6.568 ( 4.911)	Data  6.004 ( 4.340)	Loss 5.5563e-02 (9.2837e-02) 
2023-05-27 12:30:00.754605: train Epoch: [29][ 45/193]	Time  2.876 ( 4.866)	Data  2.315 ( 4.296)	Loss 7.2456e-02 (9.2393e-02) 
2023-05-27 12:30:07.381108: train Epoch: [29][ 46/193]	Time  6.626 ( 4.904)	Data  6.066 ( 4.334)	Loss 6.0229e-02 (9.1709e-02) 
2023-05-27 12:30:11.085607: train Epoch: [29][ 47/193]	Time  3.704 ( 4.879)	Data  3.141 ( 4.309)	Loss 1.6570e-01 (9.3251e-02) 
2023-05-27 12:30:17.098658: train Epoch: [29][ 48/193]	Time  6.013 ( 4.902)	Data  5.448 ( 4.332)	Loss 1.1156e-01 (9.3624e-02) 
2023-05-27 12:30:21.007963: train Epoch: [29][ 49/193]	Time  3.909 ( 4.882)	Data  3.338 ( 4.312)	Loss 1.2010e-01 (9.4154e-02) 
2023-05-27 12:30:26.869157: train Epoch: [29][ 50/193]	Time  5.861 ( 4.901)	Data  5.289 ( 4.331)	Loss 1.8927e-01 (9.6019e-02) 
2023-05-27 12:30:30.365543: train Epoch: [29][ 51/193]	Time  3.496 ( 4.874)	Data  2.936 ( 4.305)	Loss 8.9188e-02 (9.5887e-02) 
2023-05-27 12:30:36.900368: train Epoch: [29][ 52/193]	Time  6.535 ( 4.906)	Data  5.969 ( 4.336)	Loss 1.5444e-01 (9.6992e-02) 
2023-05-27 12:30:40.113146: train Epoch: [29][ 53/193]	Time  3.213 ( 4.874)	Data  2.641 ( 4.305)	Loss 1.3759e-01 (9.7744e-02) 
2023-05-27 12:30:46.864264: train Epoch: [29][ 54/193]	Time  6.751 ( 4.908)	Data  6.180 ( 4.339)	Loss 8.9925e-02 (9.7602e-02) 
2023-05-27 12:30:50.186469: train Epoch: [29][ 55/193]	Time  3.322 ( 4.880)	Data  2.748 ( 4.310)	Loss 1.0257e-01 (9.7691e-02) 
2023-05-27 12:30:56.692315: train Epoch: [29][ 56/193]	Time  6.506 ( 4.909)	Data  5.939 ( 4.339)	Loss 7.6788e-02 (9.7324e-02) 
2023-05-27 12:31:00.409425: train Epoch: [29][ 57/193]	Time  3.717 ( 4.888)	Data  3.152 ( 4.318)	Loss 6.4303e-02 (9.6754e-02) 
2023-05-27 12:31:06.188974: train Epoch: [29][ 58/193]	Time  5.780 ( 4.903)	Data  5.213 ( 4.334)	Loss 6.1232e-02 (9.6152e-02) 
2023-05-27 12:31:10.177021: train Epoch: [29][ 59/193]	Time  3.988 ( 4.888)	Data  3.412 ( 4.318)	Loss 7.2911e-02 (9.5765e-02) 
2023-05-27 12:31:15.923766: train Epoch: [29][ 60/193]	Time  5.747 ( 4.902)	Data  5.183 ( 4.332)	Loss 5.8555e-02 (9.5155e-02) 
2023-05-27 12:31:20.041827: train Epoch: [29][ 61/193]	Time  4.118 ( 4.889)	Data  3.557 ( 4.320)	Loss 1.3780e-01 (9.5843e-02) 
2023-05-27 12:31:25.596875: train Epoch: [29][ 62/193]	Time  5.555 ( 4.900)	Data  4.993 ( 4.331)	Loss 7.0714e-02 (9.5444e-02) 
2023-05-27 12:31:29.942005: train Epoch: [29][ 63/193]	Time  4.345 ( 4.891)	Data  3.779 ( 4.322)	Loss 9.8735e-02 (9.5495e-02) 
2023-05-27 12:31:35.272237: train Epoch: [29][ 64/193]	Time  5.330 ( 4.898)	Data  4.768 ( 4.329)	Loss 1.0608e-01 (9.5658e-02) 
2023-05-27 12:31:39.570319: train Epoch: [29][ 65/193]	Time  4.298 ( 4.889)	Data  3.731 ( 4.320)	Loss 8.1517e-02 (9.5444e-02) 
2023-05-27 12:31:44.662593: train Epoch: [29][ 66/193]	Time  5.092 ( 4.892)	Data  4.532 ( 4.323)	Loss 4.0472e-02 (9.4624e-02) 
2023-05-27 12:31:49.274623: train Epoch: [29][ 67/193]	Time  4.612 ( 4.888)	Data  4.052 ( 4.319)	Loss 8.1894e-02 (9.4436e-02) 
2023-05-27 12:31:54.677075: train Epoch: [29][ 68/193]	Time  5.402 ( 4.895)	Data  4.841 ( 4.327)	Loss 9.5714e-02 (9.4455e-02) 
2023-05-27 12:31:58.823883: train Epoch: [29][ 69/193]	Time  4.147 ( 4.885)	Data  3.586 ( 4.316)	Loss 1.2643e-01 (9.4912e-02) 
2023-05-27 12:32:04.261525: train Epoch: [29][ 70/193]	Time  5.438 ( 4.892)	Data  4.878 ( 4.324)	Loss 9.2362e-02 (9.4876e-02) 
2023-05-27 12:32:08.378668: train Epoch: [29][ 71/193]	Time  4.117 ( 4.882)	Data  3.557 ( 4.313)	Loss 3.6665e-02 (9.4067e-02) 
2023-05-27 12:32:13.964182: train Epoch: [29][ 72/193]	Time  5.586 ( 4.891)	Data  5.021 ( 4.323)	Loss 1.0494e-01 (9.4216e-02) 
2023-05-27 12:32:18.714254: train Epoch: [29][ 73/193]	Time  4.750 ( 4.889)	Data  4.175 ( 4.321)	Loss 9.1856e-02 (9.4184e-02) 
2023-05-27 12:32:23.755531: train Epoch: [29][ 74/193]	Time  5.041 ( 4.891)	Data  4.481 ( 4.323)	Loss 1.7042e-01 (9.5201e-02) 
2023-05-27 12:32:28.539555: train Epoch: [29][ 75/193]	Time  4.784 ( 4.890)	Data  4.222 ( 4.322)	Loss 7.5654e-02 (9.4944e-02) 
2023-05-27 12:32:33.309491: train Epoch: [29][ 76/193]	Time  4.770 ( 4.888)	Data  4.209 ( 4.320)	Loss 6.0125e-02 (9.4492e-02) 
2023-05-27 12:32:38.210773: train Epoch: [29][ 77/193]	Time  4.901 ( 4.889)	Data  4.338 ( 4.320)	Loss 7.9362e-02 (9.4298e-02) 
2023-05-27 12:32:43.397082: train Epoch: [29][ 78/193]	Time  5.186 ( 4.892)	Data  4.625 ( 4.324)	Loss 9.1057e-02 (9.4257e-02) 
2023-05-27 12:32:47.934927: train Epoch: [29][ 79/193]	Time  4.538 ( 4.888)	Data  3.977 ( 4.320)	Loss 7.1487e-02 (9.3972e-02) 
2023-05-27 12:32:53.158220: train Epoch: [29][ 80/193]	Time  5.223 ( 4.892)	Data  4.661 ( 4.324)	Loss 2.5861e-01 (9.6005e-02) 
2023-05-27 12:32:58.017693: train Epoch: [29][ 81/193]	Time  4.859 ( 4.892)	Data  4.277 ( 4.324)	Loss 5.8819e-02 (9.5551e-02) 
2023-05-27 12:33:02.872417: train Epoch: [29][ 82/193]	Time  4.855 ( 4.891)	Data  4.292 ( 4.323)	Loss 7.7390e-02 (9.5332e-02) 
2023-05-27 12:33:07.954128: train Epoch: [29][ 83/193]	Time  5.082 ( 4.893)	Data  4.481 ( 4.325)	Loss 4.6253e-02 (9.4748e-02) 
2023-05-27 12:33:13.004778: train Epoch: [29][ 84/193]	Time  5.051 ( 4.895)	Data  4.486 ( 4.327)	Loss 5.1086e-02 (9.4234e-02) 
2023-05-27 12:33:17.976625: train Epoch: [29][ 85/193]	Time  4.972 ( 4.896)	Data  4.406 ( 4.328)	Loss 1.0936e-01 (9.4410e-02) 
2023-05-27 12:33:23.400327: train Epoch: [29][ 86/193]	Time  5.424 ( 4.902)	Data  4.857 ( 4.334)	Loss 1.3105e-01 (9.4831e-02) 
2023-05-27 12:33:27.989899: train Epoch: [29][ 87/193]	Time  4.590 ( 4.899)	Data  4.025 ( 4.331)	Loss 2.4504e-01 (9.6538e-02) 
2023-05-27 12:33:33.033222: train Epoch: [29][ 88/193]	Time  5.043 ( 4.900)	Data  4.476 ( 4.332)	Loss 1.3104e-01 (9.6926e-02) 
2023-05-27 12:33:41.771756: train Epoch: [29][ 89/193]	Time  8.739 ( 4.943)	Data  8.175 ( 4.375)	Loss 5.0748e-02 (9.6413e-02) 
2023-05-27 12:33:47.046422: train Epoch: [29][ 90/193]	Time  5.275 ( 4.947)	Data  4.713 ( 4.379)	Loss 7.0240e-02 (9.6125e-02) 
2023-05-27 12:33:50.697312: train Epoch: [29][ 91/193]	Time  3.651 ( 4.933)	Data  3.075 ( 4.364)	Loss 6.0565e-02 (9.5739e-02) 
2023-05-27 12:33:56.249248: train Epoch: [29][ 92/193]	Time  5.552 ( 4.939)	Data  4.982 ( 4.371)	Loss 2.0667e-01 (9.6932e-02) 
2023-05-27 12:33:59.772504: train Epoch: [29][ 93/193]	Time  3.523 ( 4.924)	Data  2.962 ( 4.356)	Loss 2.3504e-01 (9.8401e-02) 
2023-05-27 12:34:06.302871: train Epoch: [29][ 94/193]	Time  6.530 ( 4.941)	Data  5.963 ( 4.373)	Loss 9.5333e-02 (9.8369e-02) 
2023-05-27 12:34:10.469681: train Epoch: [29][ 95/193]	Time  4.167 ( 4.933)	Data  3.598 ( 4.365)	Loss 9.4526e-02 (9.8328e-02) 
2023-05-27 12:34:16.742927: train Epoch: [29][ 96/193]	Time  6.273 ( 4.947)	Data  5.712 ( 4.379)	Loss 7.8944e-02 (9.8129e-02) 
2023-05-27 12:34:20.539073: train Epoch: [29][ 97/193]	Time  3.796 ( 4.935)	Data  3.235 ( 4.367)	Loss 9.7926e-02 (9.8127e-02) 
2023-05-27 12:34:27.126394: train Epoch: [29][ 98/193]	Time  6.587 ( 4.952)	Data  6.018 ( 4.384)	Loss 5.4356e-02 (9.7684e-02) 
2023-05-27 12:34:30.466262: train Epoch: [29][ 99/193]	Time  3.340 ( 4.936)	Data  2.774 ( 4.368)	Loss 6.7564e-02 (9.7383e-02) 
2023-05-27 12:34:37.618688: train Epoch: [29][100/193]	Time  7.152 ( 4.958)	Data  6.583 ( 4.390)	Loss 1.7346e-01 (9.8136e-02) 
2023-05-27 12:34:41.036361: train Epoch: [29][101/193]	Time  3.418 ( 4.942)	Data  2.850 ( 4.375)	Loss 1.0827e-01 (9.8236e-02) 
2023-05-27 12:34:47.502520: train Epoch: [29][102/193]	Time  6.466 ( 4.957)	Data  5.905 ( 4.389)	Loss 5.0632e-02 (9.7774e-02) 
2023-05-27 12:34:50.730055: train Epoch: [29][103/193]	Time  3.228 ( 4.941)	Data  2.666 ( 4.373)	Loss 5.2993e-02 (9.7343e-02) 
2023-05-27 12:34:57.736701: train Epoch: [29][104/193]	Time  7.007 ( 4.960)	Data  6.444 ( 4.393)	Loss 8.0890e-02 (9.7186e-02) 
2023-05-27 12:35:00.421065: train Epoch: [29][105/193]	Time  2.684 ( 4.939)	Data  2.123 ( 4.371)	Loss 8.8459e-02 (9.7104e-02) 
2023-05-27 12:35:08.104767: train Epoch: [29][106/193]	Time  7.684 ( 4.964)	Data  7.122 ( 4.397)	Loss 4.7721e-02 (9.6643e-02) 
2023-05-27 12:35:10.668650: train Epoch: [29][107/193]	Time  2.564 ( 4.942)	Data  2.003 ( 4.375)	Loss 1.4287e-01 (9.7071e-02) 
2023-05-27 12:35:18.019137: train Epoch: [29][108/193]	Time  7.350 ( 4.964)	Data  6.789 ( 4.397)	Loss 1.2054e-01 (9.7286e-02) 
2023-05-27 12:35:20.695679: train Epoch: [29][109/193]	Time  2.677 ( 4.944)	Data  2.116 ( 4.376)	Loss 7.0676e-02 (9.7044e-02) 
2023-05-27 12:35:28.195710: train Epoch: [29][110/193]	Time  7.500 ( 4.967)	Data  6.928 ( 4.399)	Loss 8.2890e-02 (9.6916e-02) 
2023-05-27 12:35:30.924385: train Epoch: [29][111/193]	Time  2.729 ( 4.947)	Data  2.161 ( 4.379)	Loss 7.1755e-02 (9.6692e-02) 
2023-05-27 12:35:38.283477: train Epoch: [29][112/193]	Time  7.359 ( 4.968)	Data  6.792 ( 4.400)	Loss 1.0329e-01 (9.6750e-02) 
2023-05-27 12:35:40.717195: train Epoch: [29][113/193]	Time  2.434 ( 4.946)	Data  1.865 ( 4.378)	Loss 7.9094e-02 (9.6595e-02) 
2023-05-27 12:35:49.007630: train Epoch: [29][114/193]	Time  8.290 ( 4.975)	Data  7.729 ( 4.407)	Loss 6.1463e-02 (9.6290e-02) 
2023-05-27 12:35:51.137325: train Epoch: [29][115/193]	Time  2.130 ( 4.950)	Data  1.554 ( 4.383)	Loss 8.1571e-02 (9.6163e-02) 
2023-05-27 12:35:59.566823: train Epoch: [29][116/193]	Time  8.429 ( 4.980)	Data  7.865 ( 4.412)	Loss 1.2930e-01 (9.6446e-02) 
2023-05-27 12:36:01.251871: train Epoch: [29][117/193]	Time  1.685 ( 4.952)	Data  1.092 ( 4.384)	Loss 7.2976e-02 (9.6247e-02) 
2023-05-27 12:36:09.842467: train Epoch: [29][118/193]	Time  8.591 ( 4.983)	Data  8.021 ( 4.415)	Loss 1.1478e-01 (9.6403e-02) 
2023-05-27 12:36:11.349205: train Epoch: [29][119/193]	Time  1.507 ( 4.954)	Data  0.890 ( 4.386)	Loss 8.4688e-02 (9.6305e-02) 
2023-05-27 12:36:29.477282: train Epoch: [29][120/193]	Time 18.128 ( 5.063)	Data 17.558 ( 4.494)	Loss 9.1913e-02 (9.6269e-02) 
2023-05-27 12:36:31.106853: train Epoch: [29][121/193]	Time  1.630 ( 5.034)	Data  1.052 ( 4.466)	Loss 8.9635e-02 (9.6215e-02) 
2023-05-27 12:36:39.554254: train Epoch: [29][122/193]	Time  8.447 ( 5.062)	Data  7.885 ( 4.494)	Loss 8.3551e-02 (9.6112e-02) 
2023-05-27 12:36:41.384372: train Epoch: [29][123/193]	Time  1.830 ( 5.036)	Data  1.184 ( 4.467)	Loss 6.4982e-02 (9.5861e-02) 
2023-05-27 12:36:49.859130: train Epoch: [29][124/193]	Time  8.475 ( 5.064)	Data  7.906 ( 4.495)	Loss 8.7973e-02 (9.5798e-02) 
2023-05-27 12:36:51.692182: train Epoch: [29][125/193]	Time  1.833 ( 5.038)	Data  1.263 ( 4.469)	Loss 6.6053e-02 (9.5561e-02) 
2023-05-27 12:36:59.923331: train Epoch: [29][126/193]	Time  8.231 ( 5.063)	Data  7.661 ( 4.494)	Loss 9.5139e-02 (9.5558e-02) 
2023-05-27 12:37:01.781925: train Epoch: [29][127/193]	Time  1.859 ( 5.038)	Data  1.283 ( 4.469)	Loss 6.7922e-02 (9.5342e-02) 
2023-05-27 12:37:09.358988: train Epoch: [29][128/193]	Time  7.577 ( 5.058)	Data  7.007 ( 4.489)	Loss 6.3325e-02 (9.5094e-02) 
2023-05-27 12:37:11.574794: train Epoch: [29][129/193]	Time  2.216 ( 5.036)	Data  1.642 ( 4.467)	Loss 5.7112e-02 (9.4802e-02) 
2023-05-27 12:37:19.944021: train Epoch: [29][130/193]	Time  8.369 ( 5.061)	Data  7.807 ( 4.492)	Loss 9.5711e-02 (9.4809e-02) 
2023-05-27 12:37:21.704014: train Epoch: [29][131/193]	Time  1.760 ( 5.036)	Data  1.196 ( 4.467)	Loss 1.7776e-01 (9.5437e-02) 
2023-05-27 12:37:30.183760: train Epoch: [29][132/193]	Time  8.480 ( 5.062)	Data  7.916 ( 4.493)	Loss 6.5039e-02 (9.5209e-02) 
2023-05-27 12:37:32.095678: train Epoch: [29][133/193]	Time  1.912 ( 5.039)	Data  1.345 ( 4.470)	Loss 6.6694e-02 (9.4996e-02) 
2023-05-27 12:37:40.048403: train Epoch: [29][134/193]	Time  7.953 ( 5.060)	Data  7.389 ( 4.492)	Loss 1.0212e-01 (9.5049e-02) 
2023-05-27 12:37:41.938736: train Epoch: [29][135/193]	Time  1.890 ( 5.037)	Data  1.277 ( 4.468)	Loss 3.5126e-02 (9.4608e-02) 
2023-05-27 12:37:50.312616: train Epoch: [29][136/193]	Time  8.374 ( 5.061)	Data  7.812 ( 4.492)	Loss 1.1567e-01 (9.4762e-02) 
2023-05-27 12:37:51.746253: train Epoch: [29][137/193]	Time  1.434 ( 5.035)	Data  0.863 ( 4.466)	Loss 8.4811e-02 (9.4690e-02) 
2023-05-27 12:38:00.394375: train Epoch: [29][138/193]	Time  8.648 ( 5.061)	Data  8.076 ( 4.492)	Loss 7.0965e-02 (9.4519e-02) 
2023-05-27 12:38:01.692587: train Epoch: [29][139/193]	Time  1.298 ( 5.034)	Data  0.735 ( 4.465)	Loss 8.1570e-02 (9.4426e-02) 
2023-05-27 12:38:10.454557: train Epoch: [29][140/193]	Time  8.762 ( 5.061)	Data  8.200 ( 4.492)	Loss 2.4145e-01 (9.5469e-02) 
2023-05-27 12:38:12.363230: train Epoch: [29][141/193]	Time  1.909 ( 5.038)	Data  1.330 ( 4.469)	Loss 7.2585e-02 (9.5308e-02) 
2023-05-27 12:38:20.470194: train Epoch: [29][142/193]	Time  8.107 ( 5.060)	Data  7.540 ( 4.491)	Loss 2.5477e-01 (9.6423e-02) 
2023-05-27 12:38:30.587557: train Epoch: [29][143/193]	Time 10.117 ( 5.095)	Data  9.531 ( 4.526)	Loss 1.2522e-01 (9.6623e-02) 
2023-05-27 12:38:37.047086: train Epoch: [29][144/193]	Time  6.460 ( 5.104)	Data  5.891 ( 4.535)	Loss 1.0596e-01 (9.6688e-02) 
2023-05-27 12:38:40.422097: train Epoch: [29][145/193]	Time  3.375 ( 5.093)	Data  2.787 ( 4.523)	Loss 7.8597e-02 (9.6564e-02) 
2023-05-27 12:38:48.016531: train Epoch: [29][146/193]	Time  7.594 ( 5.110)	Data  7.031 ( 4.540)	Loss 7.7599e-02 (9.6435e-02) 
2023-05-27 12:38:51.422313: train Epoch: [29][147/193]	Time  3.406 ( 5.098)	Data  2.844 ( 4.529)	Loss 5.7077e-02 (9.6169e-02) 
2023-05-27 12:38:58.965445: train Epoch: [29][148/193]	Time  7.543 ( 5.115)	Data  6.976 ( 4.545)	Loss 1.2143e-01 (9.6338e-02) 
2023-05-27 12:39:02.380773: train Epoch: [29][149/193]	Time  3.415 ( 5.103)	Data  2.848 ( 4.534)	Loss 1.0071e-01 (9.6367e-02) 
2023-05-27 12:39:09.044467: train Epoch: [29][150/193]	Time  6.664 ( 5.114)	Data  6.095 ( 4.544)	Loss 6.4267e-02 (9.6155e-02) 
2023-05-27 12:39:12.451834: train Epoch: [29][151/193]	Time  3.407 ( 5.102)	Data  2.846 ( 4.533)	Loss 6.7405e-02 (9.5966e-02) 
2023-05-27 12:39:19.383610: train Epoch: [29][152/193]	Time  6.932 ( 5.114)	Data  6.357 ( 4.545)	Loss 1.6577e-01 (9.6422e-02) 
2023-05-27 12:39:22.381631: train Epoch: [29][153/193]	Time  2.998 ( 5.100)	Data  2.437 ( 4.531)	Loss 3.9237e-02 (9.6051e-02) 
2023-05-27 12:39:29.331943: train Epoch: [29][154/193]	Time  6.950 ( 5.112)	Data  6.368 ( 4.543)	Loss 2.1060e-01 (9.6790e-02) 
2023-05-27 12:39:32.809252: train Epoch: [29][155/193]	Time  3.477 ( 5.102)	Data  2.910 ( 4.533)	Loss 7.1760e-02 (9.6629e-02) 
2023-05-27 12:39:39.160343: train Epoch: [29][156/193]	Time  6.351 ( 5.110)	Data  5.782 ( 4.541)	Loss 1.2147e-01 (9.6787e-02) 
2023-05-27 12:39:42.690790: train Epoch: [29][157/193]	Time  3.530 ( 5.100)	Data  2.969 ( 4.531)	Loss 7.4961e-02 (9.6649e-02) 
2023-05-27 12:39:49.316707: train Epoch: [29][158/193]	Time  6.626 ( 5.110)	Data  6.061 ( 4.540)	Loss 8.0366e-02 (9.6547e-02) 
2023-05-27 12:39:52.920751: train Epoch: [29][159/193]	Time  3.604 ( 5.100)	Data  3.042 ( 4.531)	Loss 7.1418e-02 (9.6390e-02) 
2023-05-27 12:39:58.932694: train Epoch: [29][160/193]	Time  6.012 ( 5.106)	Data  5.427 ( 4.537)	Loss 5.7436e-02 (9.6148e-02) 
2023-05-27 12:40:03.334038: train Epoch: [29][161/193]	Time  4.401 ( 5.101)	Data  3.831 ( 4.532)	Loss 2.0978e-01 (9.6849e-02) 
2023-05-27 12:40:08.935932: train Epoch: [29][162/193]	Time  5.602 ( 5.104)	Data  5.032 ( 4.535)	Loss 4.7813e-02 (9.6548e-02) 
2023-05-27 12:40:13.536886: train Epoch: [29][163/193]	Time  4.601 ( 5.101)	Data  4.025 ( 4.532)	Loss 1.0649e-01 (9.6609e-02) 
2023-05-27 12:40:18.987999: train Epoch: [29][164/193]	Time  5.451 ( 5.104)	Data  4.852 ( 4.534)	Loss 5.6448e-02 (9.6366e-02) 
2023-05-27 12:40:23.443456: train Epoch: [29][165/193]	Time  4.455 ( 5.100)	Data  3.891 ( 4.530)	Loss 6.6150e-02 (9.6184e-02) 
2023-05-27 12:40:29.369767: train Epoch: [29][166/193]	Time  5.926 ( 5.105)	Data  5.352 ( 4.535)	Loss 1.0174e-01 (9.6217e-02) 
2023-05-27 12:40:33.294140: train Epoch: [29][167/193]	Time  3.924 ( 5.098)	Data  3.362 ( 4.528)	Loss 1.0947e-01 (9.6296e-02) 
2023-05-27 12:40:39.432030: train Epoch: [29][168/193]	Time  6.138 ( 5.104)	Data  5.545 ( 4.534)	Loss 5.4734e-02 (9.6050e-02) 
2023-05-27 12:40:43.267349: train Epoch: [29][169/193]	Time  3.835 ( 5.096)	Data  3.274 ( 4.527)	Loss 7.8745e-02 (9.5948e-02) 
2023-05-27 12:40:49.682743: train Epoch: [29][170/193]	Time  6.415 ( 5.104)	Data  5.844 ( 4.535)	Loss 9.8955e-02 (9.5966e-02) 
2023-05-27 12:40:53.419411: train Epoch: [29][171/193]	Time  3.737 ( 5.096)	Data  3.175 ( 4.527)	Loss 1.5180e-01 (9.6290e-02) 
2023-05-27 12:40:59.559763: train Epoch: [29][172/193]	Time  6.140 ( 5.102)	Data  5.561 ( 4.533)	Loss 7.2866e-02 (9.6155e-02) 
2023-05-27 12:41:03.700882: train Epoch: [29][173/193]	Time  4.141 ( 5.097)	Data  3.577 ( 4.527)	Loss 1.7863e-01 (9.6629e-02) 
2023-05-27 12:41:09.529989: train Epoch: [29][174/193]	Time  5.829 ( 5.101)	Data  5.260 ( 4.531)	Loss 9.1506e-02 (9.6600e-02) 
2023-05-27 12:41:14.170696: train Epoch: [29][175/193]	Time  4.641 ( 5.098)	Data  4.070 ( 4.529)	Loss 5.3784e-02 (9.6356e-02) 
2023-05-27 12:41:19.428011: train Epoch: [29][176/193]	Time  5.257 ( 5.099)	Data  4.628 ( 4.529)	Loss 5.3253e-02 (9.6113e-02) 
2023-05-27 12:41:24.666487: train Epoch: [29][177/193]	Time  5.238 ( 5.100)	Data  4.671 ( 4.530)	Loss 9.7528e-02 (9.6121e-02) 
2023-05-27 12:41:29.539297: train Epoch: [29][178/193]	Time  4.873 ( 5.099)	Data  4.287 ( 4.529)	Loss 1.0089e-01 (9.6147e-02) 
2023-05-27 12:41:34.763434: train Epoch: [29][179/193]	Time  5.224 ( 5.099)	Data  4.603 ( 4.529)	Loss 1.3386e-01 (9.6357e-02) 
2023-05-27 12:41:39.658502: train Epoch: [29][180/193]	Time  4.895 ( 5.098)	Data  4.325 ( 4.528)	Loss 4.3310e-02 (9.6064e-02) 
2023-05-27 12:41:45.066978: train Epoch: [29][181/193]	Time  5.408 ( 5.100)	Data  4.842 ( 4.530)	Loss 8.1255e-02 (9.5982e-02) 
2023-05-27 12:41:49.727739: train Epoch: [29][182/193]	Time  4.661 ( 5.097)	Data  4.065 ( 4.527)	Loss 5.6764e-02 (9.5768e-02) 
2023-05-27 12:41:55.651351: train Epoch: [29][183/193]	Time  5.924 ( 5.102)	Data  5.353 ( 4.532)	Loss 8.9443e-02 (9.5734e-02) 
2023-05-27 12:41:59.616759: train Epoch: [29][184/193]	Time  3.965 ( 5.096)	Data  3.388 ( 4.525)	Loss 9.2743e-02 (9.5718e-02) 
2023-05-27 12:42:05.800860: train Epoch: [29][185/193]	Time  6.184 ( 5.102)	Data  5.615 ( 4.531)	Loss 5.9447e-02 (9.5523e-02) 
2023-05-27 12:42:10.090773: train Epoch: [29][186/193]	Time  4.290 ( 5.097)	Data  3.724 ( 4.527)	Loss 5.1130e-02 (9.5285e-02) 
2023-05-27 12:42:16.146735: train Epoch: [29][187/193]	Time  6.056 ( 5.102)	Data  5.480 ( 4.532)	Loss 9.8128e-02 (9.5300e-02) 
2023-05-27 12:42:20.771662: train Epoch: [29][188/193]	Time  4.625 ( 5.100)	Data  4.055 ( 4.530)	Loss 9.4197e-02 (9.5294e-02) 
2023-05-27 12:42:26.403399: train Epoch: [29][189/193]	Time  5.632 ( 5.103)	Data  5.063 ( 4.532)	Loss 9.9756e-02 (9.5318e-02) 
2023-05-27 12:42:31.233270: train Epoch: [29][190/193]	Time  4.830 ( 5.101)	Data  4.269 ( 4.531)	Loss 1.1622e-01 (9.5427e-02) 
2023-05-27 12:42:36.343421: train Epoch: [29][191/193]	Time  5.110 ( 5.101)	Data  4.546 ( 4.531)	Loss 7.4291e-02 (9.5317e-02) 
2023-05-27 12:42:41.009460: train Epoch: [29][192/193]	Time  4.666 ( 5.099)	Data  4.096 ( 4.529)	Loss 7.1371e-02 (9.5193e-02) 
2023-05-27 12:42:41.362565: Train Epoch done in 984.4587845770002 s 
2023-05-27 12:42:48.325755: val Epoch: [29][ 0/72]	Time  6.143 ( 6.143)	Data  5.961 ( 5.961)	Loss 7.1791e-02 (7.1791e-02) 
2023-05-27 12:42:48.435658: val Epoch: [29][ 1/72]	Time  0.110 ( 3.126)	Data  0.002 ( 2.981)	Loss 2.6996e-01 (1.7088e-01) 
2023-05-27 12:42:53.579139: val Epoch: [29][ 2/72]	Time  5.143 ( 3.799)	Data  5.022 ( 3.662)	Loss 1.1464e-01 (1.5213e-01) 
2023-05-27 12:42:53.688575: val Epoch: [29][ 3/72]	Time  0.109 ( 2.876)	Data  0.001 ( 2.746)	Loss 3.9008e-02 (1.2385e-01) 
2023-05-27 12:42:58.449438: val Epoch: [29][ 4/72]	Time  4.761 ( 3.253)	Data  4.653 ( 3.128)	Loss 8.8593e-02 (1.1680e-01) 
2023-05-27 12:42:58.612772: val Epoch: [29][ 5/72]	Time  0.163 ( 2.738)	Data  0.048 ( 2.614)	Loss 1.4403e-01 (1.2134e-01) 
2023-05-27 12:43:03.677182: val Epoch: [29][ 6/72]	Time  5.064 ( 3.071)	Data  4.955 ( 2.949)	Loss 2.0392e-01 (1.3314e-01) 
2023-05-27 12:43:03.994461: val Epoch: [29][ 7/72]	Time  0.317 ( 2.726)	Data  0.206 ( 2.606)	Loss 8.9665e-02 (1.2770e-01) 
2023-05-27 12:43:08.562214: val Epoch: [29][ 8/72]	Time  4.568 ( 2.931)	Data  4.459 ( 2.812)	Loss 8.4669e-02 (1.2292e-01) 
2023-05-27 12:43:09.015680: val Epoch: [29][ 9/72]	Time  0.453 ( 2.683)	Data  0.342 ( 2.565)	Loss 2.0065e-01 (1.3069e-01) 
2023-05-27 12:43:13.540468: val Epoch: [29][10/72]	Time  4.525 ( 2.851)	Data  4.419 ( 2.733)	Loss 4.9541e-02 (1.2332e-01) 
2023-05-27 12:43:14.550638: val Epoch: [29][11/72]	Time  1.010 ( 2.697)	Data  0.901 ( 2.581)	Loss 5.6907e-02 (1.1778e-01) 
2023-05-27 12:43:18.763587: val Epoch: [29][12/72]	Time  4.213 ( 2.814)	Data  4.107 ( 2.698)	Loss 6.9354e-01 (1.6207e-01) 
2023-05-27 12:43:19.580903: val Epoch: [29][13/72]	Time  0.817 ( 2.671)	Data  0.700 ( 2.555)	Loss 8.1642e-02 (1.5633e-01) 
2023-05-27 12:43:23.673927: val Epoch: [29][14/72]	Time  4.093 ( 2.766)	Data  3.982 ( 2.651)	Loss 2.0182e-01 (1.5936e-01) 
2023-05-27 12:43:24.740870: val Epoch: [29][15/72]	Time  1.067 ( 2.660)	Data  0.941 ( 2.544)	Loss 6.3403e-02 (1.5336e-01) 
2023-05-27 12:43:28.941378: val Epoch: [29][16/72]	Time  4.201 ( 2.751)	Data  4.094 ( 2.635)	Loss 6.2223e-02 (1.4800e-01) 
2023-05-27 12:43:29.866632: val Epoch: [29][17/72]	Time  0.925 ( 2.649)	Data  0.816 ( 2.534)	Loss 4.0166e-01 (1.6209e-01) 
2023-05-27 12:43:34.141198: val Epoch: [29][18/72]	Time  4.275 ( 2.735)	Data  4.170 ( 2.620)	Loss 1.0182e-01 (1.5892e-01) 
2023-05-27 12:43:34.990588: val Epoch: [29][19/72]	Time  0.849 ( 2.640)	Data  0.715 ( 2.525)	Loss 1.0185e-01 (1.5607e-01) 
2023-05-27 12:43:39.246753: val Epoch: [29][20/72]	Time  4.256 ( 2.717)	Data  4.151 ( 2.602)	Loss 1.3531e-01 (1.5508e-01) 
2023-05-27 12:43:39.890187: val Epoch: [29][21/72]	Time  0.643 ( 2.623)	Data  0.528 ( 2.508)	Loss 5.8226e-02 (1.5068e-01) 
2023-05-27 12:43:44.231393: val Epoch: [29][22/72]	Time  4.341 ( 2.698)	Data  4.225 ( 2.583)	Loss 4.1603e-02 (1.4593e-01) 
2023-05-27 12:43:44.898352: val Epoch: [29][23/72]	Time  0.667 ( 2.613)	Data  0.556 ( 2.498)	Loss 6.8132e-02 (1.4269e-01) 
2023-05-27 12:43:49.159558: val Epoch: [29][24/72]	Time  4.261 ( 2.679)	Data  4.156 ( 2.564)	Loss 1.5148e-01 (1.4304e-01) 
2023-05-27 12:43:50.348357: val Epoch: [29][25/72]	Time  1.189 ( 2.622)	Data  1.080 ( 2.507)	Loss 5.9789e-02 (1.3984e-01) 
2023-05-27 12:43:54.315434: val Epoch: [29][26/72]	Time  3.967 ( 2.672)	Data  3.859 ( 2.557)	Loss 3.9692e-02 (1.3613e-01) 
2023-05-27 12:43:55.581162: val Epoch: [29][27/72]	Time  1.266 ( 2.621)	Data  1.134 ( 2.507)	Loss 6.0856e-02 (1.3344e-01) 
2023-05-27 12:43:59.322510: val Epoch: [29][28/72]	Time  3.741 ( 2.660)	Data  3.633 ( 2.545)	Loss 1.0413e-01 (1.3243e-01) 
2023-05-27 12:44:00.600122: val Epoch: [29][29/72]	Time  1.278 ( 2.614)	Data  1.170 ( 2.500)	Loss 6.5168e-01 (1.4974e-01) 
2023-05-27 12:44:04.335036: val Epoch: [29][30/72]	Time  3.735 ( 2.650)	Data  3.629 ( 2.536)	Loss 1.0472e-01 (1.4829e-01) 
2023-05-27 12:44:05.650959: val Epoch: [29][31/72]	Time  1.316 ( 2.608)	Data  1.206 ( 2.494)	Loss 3.7355e-02 (1.4482e-01) 
2023-05-27 12:44:09.428288: val Epoch: [29][32/72]	Time  3.777 ( 2.644)	Data  3.667 ( 2.530)	Loss 5.3624e-02 (1.4206e-01) 
2023-05-27 12:44:10.626613: val Epoch: [29][33/72]	Time  1.198 ( 2.601)	Data  1.084 ( 2.487)	Loss 9.7155e-02 (1.4074e-01) 
2023-05-27 12:44:14.849328: val Epoch: [29][34/72]	Time  4.223 ( 2.648)	Data  4.117 ( 2.534)	Loss 3.9071e-02 (1.3783e-01) 
2023-05-27 12:44:15.889243: val Epoch: [29][35/72]	Time  1.040 ( 2.603)	Data  0.924 ( 2.489)	Loss 5.6405e-02 (1.3557e-01) 
2023-05-27 12:44:20.018184: val Epoch: [29][36/72]	Time  4.129 ( 2.644)	Data  4.020 ( 2.531)	Loss 9.6754e-02 (1.3452e-01) 
2023-05-27 12:44:20.888391: val Epoch: [29][37/72]	Time  0.870 ( 2.598)	Data  0.761 ( 2.484)	Loss 6.5394e-02 (1.3270e-01) 
2023-05-27 12:44:25.197333: val Epoch: [29][38/72]	Time  4.309 ( 2.641)	Data  4.200 ( 2.528)	Loss 7.4033e-02 (1.3120e-01) 
2023-05-27 12:44:25.780407: val Epoch: [29][39/72]	Time  0.583 ( 2.590)	Data  0.467 ( 2.477)	Loss 8.5738e-02 (1.3006e-01) 
2023-05-27 12:44:30.300548: val Epoch: [29][40/72]	Time  4.520 ( 2.637)	Data  4.412 ( 2.524)	Loss 5.5364e-02 (1.2824e-01) 
2023-05-27 12:44:30.956807: val Epoch: [29][41/72]	Time  0.656 ( 2.590)	Data  0.540 ( 2.477)	Loss 4.3038e-02 (1.2621e-01) 
2023-05-27 12:44:35.009191: val Epoch: [29][42/72]	Time  4.052 ( 2.624)	Data  3.943 ( 2.511)	Loss 6.5731e-02 (1.2480e-01) 
2023-05-27 12:44:36.054366: val Epoch: [29][43/72]	Time  1.045 ( 2.588)	Data  0.937 ( 2.475)	Loss 7.1393e-02 (1.2359e-01) 
2023-05-27 12:44:40.241231: val Epoch: [29][44/72]	Time  4.187 ( 2.624)	Data  4.078 ( 2.511)	Loss 6.7678e-02 (1.2235e-01) 
2023-05-27 12:44:41.486623: val Epoch: [29][45/72]	Time  1.245 ( 2.594)	Data  1.137 ( 2.481)	Loss 3.4867e-01 (1.2727e-01) 
2023-05-27 12:44:45.289455: val Epoch: [29][46/72]	Time  3.803 ( 2.619)	Data  3.694 ( 2.506)	Loss 3.4516e-02 (1.2530e-01) 
2023-05-27 12:44:46.663065: val Epoch: [29][47/72]	Time  1.374 ( 2.593)	Data  1.265 ( 2.481)	Loss 1.3371e-01 (1.2547e-01) 
2023-05-27 12:44:50.202852: val Epoch: [29][48/72]	Time  3.540 ( 2.613)	Data  3.431 ( 2.500)	Loss 1.2011e-01 (1.2536e-01) 
2023-05-27 12:44:51.992243: val Epoch: [29][49/72]	Time  1.789 ( 2.596)	Data  1.681 ( 2.484)	Loss 1.1472e-01 (1.2515e-01) 
2023-05-27 12:44:55.128549: val Epoch: [29][50/72]	Time  3.136 ( 2.607)	Data  3.026 ( 2.494)	Loss 1.4378e-01 (1.2551e-01) 
2023-05-27 12:44:57.124928: val Epoch: [29][51/72]	Time  1.996 ( 2.595)	Data  1.885 ( 2.483)	Loss 1.0127e-01 (1.2505e-01) 
2023-05-27 12:45:00.098487: val Epoch: [29][52/72]	Time  2.974 ( 2.602)	Data  2.869 ( 2.490)	Loss 5.1000e-02 (1.2365e-01) 
2023-05-27 12:45:02.385237: val Epoch: [29][53/72]	Time  2.287 ( 2.596)	Data  2.182 ( 2.484)	Loss 3.9274e-01 (1.2863e-01) 
2023-05-27 12:45:05.010321: val Epoch: [29][54/72]	Time  2.625 ( 2.597)	Data  2.520 ( 2.485)	Loss 8.7716e-02 (1.2789e-01) 
2023-05-27 12:45:07.555564: val Epoch: [29][55/72]	Time  2.545 ( 2.596)	Data  2.439 ( 2.484)	Loss 3.2003e-01 (1.3132e-01) 
2023-05-27 12:45:10.020879: val Epoch: [29][56/72]	Time  2.465 ( 2.594)	Data  2.360 ( 2.482)	Loss 6.0681e-02 (1.3008e-01) 
2023-05-27 12:45:12.819629: val Epoch: [29][57/72]	Time  2.799 ( 2.597)	Data  2.693 ( 2.485)	Loss 4.6879e-02 (1.2865e-01) 
2023-05-27 12:45:14.902424: val Epoch: [29][58/72]	Time  2.083 ( 2.588)	Data  1.978 ( 2.477)	Loss 2.7782e-01 (1.3117e-01) 
2023-05-27 12:45:18.139270: val Epoch: [29][59/72]	Time  3.237 ( 2.599)	Data  3.131 ( 2.488)	Loss 1.6644e-01 (1.3176e-01) 
2023-05-27 12:45:20.243200: val Epoch: [29][60/72]	Time  2.104 ( 2.591)	Data  1.998 ( 2.480)	Loss 2.9421e-01 (1.3443e-01) 
2023-05-27 12:45:23.138541: val Epoch: [29][61/72]	Time  2.895 ( 2.596)	Data  2.782 ( 2.485)	Loss 6.4914e-02 (1.3330e-01) 
2023-05-27 12:45:24.970119: val Epoch: [29][62/72]	Time  1.832 ( 2.584)	Data  1.713 ( 2.472)	Loss 4.7690e-02 (1.3195e-01) 
2023-05-27 12:45:28.119689: val Epoch: [29][63/72]	Time  3.150 ( 2.593)	Data  3.043 ( 2.481)	Loss 5.2118e-02 (1.3070e-01) 
2023-05-27 12:45:30.109716: val Epoch: [29][64/72]	Time  1.990 ( 2.583)	Data  1.870 ( 2.472)	Loss 5.9572e-02 (1.2960e-01) 
2023-05-27 12:45:33.147455: val Epoch: [29][65/72]	Time  3.038 ( 2.590)	Data  2.932 ( 2.479)	Loss 3.5884e-01 (1.3308e-01) 
2023-05-27 12:45:35.278628: val Epoch: [29][66/72]	Time  2.131 ( 2.584)	Data  2.024 ( 2.472)	Loss 1.7898e-01 (1.3376e-01) 
2023-05-27 12:45:37.987398: val Epoch: [29][67/72]	Time  2.709 ( 2.585)	Data  2.601 ( 2.474)	Loss 8.6429e-02 (1.3307e-01) 
2023-05-27 12:45:40.114551: val Epoch: [29][68/72]	Time  2.127 ( 2.579)	Data  2.018 ( 2.467)	Loss 4.3627e-02 (1.3177e-01) 
2023-05-27 12:45:42.848145: val Epoch: [29][69/72]	Time  2.734 ( 2.581)	Data  2.624 ( 2.470)	Loss 4.4650e-01 (1.3627e-01) 
2023-05-27 12:45:45.217667: val Epoch: [29][70/72]	Time  2.370 ( 2.578)	Data  2.260 ( 2.467)	Loss 1.4349e-01 (1.3637e-01) 
2023-05-27 12:45:47.732717: val Epoch: [29][71/72]	Time  2.515 ( 2.577)	Data  2.409 ( 2.466)	Loss 8.7185e-02 (1.3568e-01) 
2023-05-27 12:45:48.077764: Epoch 29 :Val : ['ET : 0.7402482628822327', 'TC : 0.7803555727005005', 'WT : 0.8506433367729187'] 
2023-05-27 12:45:48.078819: Epoch 29 :Val : ['ET : 0.7402482628822327', 'TC : 0.7803555727005005', 'WT : 0.8506433367729187'] 
2023-05-27 12:45:48.083292: Saving the model with DSC 0.7920721769332886 
2023-05-27 12:45:49.053620: Val epoch done in 187.69104556401726 s 
2023-05-27 12:45:49.062131: Batches per epoch:  193 
2023-05-27 12:46:00.986439: train Epoch: [30][  0/193]	Time 11.924 (11.924)	Data 11.238 (11.238)	Loss 5.1483e-02 (5.1483e-02) 
2023-05-27 12:46:01.560059: train Epoch: [30][  1/193]	Time  0.574 ( 6.249)	Data  0.001 ( 5.620)	Loss 6.3349e-02 (5.7416e-02) 
2023-05-27 12:46:11.015494: train Epoch: [30][  2/193]	Time  9.455 ( 7.318)	Data  8.883 ( 6.707)	Loss 9.2367e-02 (6.9066e-02) 
2023-05-27 12:46:11.588475: train Epoch: [30][  3/193]	Time  0.573 ( 5.632)	Data  0.001 ( 5.031)	Loss 6.7281e-02 (6.8620e-02) 
2023-05-27 12:46:21.087266: train Epoch: [30][  4/193]	Time  9.499 ( 6.405)	Data  8.926 ( 5.810)	Loss 4.9193e-02 (6.4735e-02) 
2023-05-27 12:46:21.663293: train Epoch: [30][  5/193]	Time  0.576 ( 5.433)	Data  0.001 ( 4.842)	Loss 6.1904e-02 (6.4263e-02) 
2023-05-27 12:46:31.402240: train Epoch: [30][  6/193]	Time  9.739 ( 6.049)	Data  9.160 ( 5.459)	Loss 8.4102e-02 (6.7097e-02) 
2023-05-27 12:46:31.978076: train Epoch: [30][  7/193]	Time  0.576 ( 5.364)	Data  0.001 ( 4.776)	Loss 5.5726e-02 (6.5676e-02) 
2023-05-27 12:46:41.873541: train Epoch: [30][  8/193]	Time  9.895 ( 5.868)	Data  9.324 ( 5.282)	Loss 8.1204e-02 (6.7401e-02) 
2023-05-27 12:46:42.446649: train Epoch: [30][  9/193]	Time  0.573 ( 5.338)	Data  0.001 ( 4.754)	Loss 1.3847e-01 (7.4508e-02) 
2023-05-27 12:46:51.932058: train Epoch: [30][ 10/193]	Time  9.485 ( 5.715)	Data  8.912 ( 5.132)	Loss 6.6470e-02 (7.3777e-02) 
2023-05-27 12:46:52.506246: train Epoch: [30][ 11/193]	Time  0.574 ( 5.287)	Data  0.001 ( 4.704)	Loss 6.8351e-02 (7.3325e-02) 
2023-05-27 12:47:02.182277: train Epoch: [30][ 12/193]	Time  9.676 ( 5.625)	Data  9.103 ( 5.042)	Loss 5.6533e-02 (7.2033e-02) 
2023-05-27 12:47:02.755572: train Epoch: [30][ 13/193]	Time  0.573 ( 5.264)	Data  0.001 ( 4.682)	Loss 8.0227e-02 (7.2618e-02) 
2023-05-27 12:47:12.472657: train Epoch: [30][ 14/193]	Time  9.717 ( 5.561)	Data  9.152 ( 4.980)	Loss 9.5073e-02 (7.4115e-02) 
2023-05-27 12:47:13.038349: train Epoch: [30][ 15/193]	Time  0.566 ( 5.248)	Data  0.001 ( 4.669)	Loss 9.0267e-02 (7.5125e-02) 
2023-05-27 12:47:22.488335: train Epoch: [30][ 16/193]	Time  9.450 ( 5.496)	Data  8.878 ( 4.917)	Loss 1.7543e-01 (8.1025e-02) 
2023-05-27 12:47:23.056150: train Epoch: [30][ 17/193]	Time  0.568 ( 5.222)	Data  0.001 ( 4.644)	Loss 9.1449e-02 (8.1604e-02) 
2023-05-27 12:47:32.317934: train Epoch: [30][ 18/193]	Time  9.262 ( 5.434)	Data  8.696 ( 4.857)	Loss 9.4637e-02 (8.2290e-02) 
2023-05-27 12:47:32.883760: train Epoch: [30][ 19/193]	Time  0.566 ( 5.191)	Data  0.001 ( 4.614)	Loss 4.8597e-02 (8.0605e-02) 
2023-05-27 12:47:42.728640: train Epoch: [30][ 20/193]	Time  9.845 ( 5.413)	Data  9.280 ( 4.836)	Loss 7.2374e-02 (8.0213e-02) 
2023-05-27 12:47:43.294467: train Epoch: [30][ 21/193]	Time  0.566 ( 5.192)	Data  0.001 ( 4.616)	Loss 1.3279e-01 (8.2603e-02) 
2023-05-27 12:47:53.330872: train Epoch: [30][ 22/193]	Time 10.036 ( 5.403)	Data  9.462 ( 4.827)	Loss 6.8857e-02 (8.2006e-02) 
2023-05-27 12:47:53.913402: train Epoch: [30][ 23/193]	Time  0.583 ( 5.202)	Data  0.001 ( 4.626)	Loss 1.1642e-01 (8.3440e-02) 
2023-05-27 12:48:02.801203: train Epoch: [30][ 24/193]	Time  8.888 ( 5.350)	Data  8.305 ( 4.773)	Loss 6.5163e-02 (8.2709e-02) 
2023-05-27 12:48:03.382288: train Epoch: [30][ 25/193]	Time  0.581 ( 5.166)	Data  0.001 ( 4.590)	Loss 3.9493e-02 (8.1047e-02) 
2023-05-27 12:48:12.346302: train Epoch: [30][ 26/193]	Time  8.964 ( 5.307)	Data  8.399 ( 4.731)	Loss 5.0099e-02 (7.9900e-02) 
2023-05-27 12:48:12.912184: train Epoch: [30][ 27/193]	Time  0.566 ( 5.137)	Data  0.001 ( 4.562)	Loss 1.5680e-01 (8.2647e-02) 
2023-05-27 12:48:21.049654: train Epoch: [30][ 28/193]	Time  8.137 ( 5.241)	Data  7.565 ( 4.665)	Loss 6.6671e-02 (8.2096e-02) 
2023-05-27 12:48:21.627661: train Epoch: [30][ 29/193]	Time  0.578 ( 5.086)	Data  0.001 ( 4.510)	Loss 6.6538e-02 (8.1577e-02) 
2023-05-27 12:48:30.305672: train Epoch: [30][ 30/193]	Time  8.678 ( 5.201)	Data  8.106 ( 4.626)	Loss 1.3794e-01 (8.3396e-02) 
2023-05-27 12:48:30.880380: train Epoch: [30][ 31/193]	Time  0.575 ( 5.057)	Data  0.001 ( 4.481)	Loss 4.9130e-02 (8.2325e-02) 
2023-05-27 12:48:40.274339: train Epoch: [30][ 32/193]	Time  9.394 ( 5.188)	Data  8.823 ( 4.613)	Loss 1.3010e-01 (8.3773e-02) 
2023-05-27 12:48:40.848693: train Epoch: [30][ 33/193]	Time  0.574 ( 5.053)	Data  0.001 ( 4.477)	Loss 1.3736e-01 (8.5349e-02) 
2023-05-27 12:48:49.133199: train Epoch: [30][ 34/193]	Time  8.284 ( 5.145)	Data  7.716 ( 4.570)	Loss 5.7564e-02 (8.4555e-02) 
2023-05-27 12:48:49.719902: train Epoch: [30][ 35/193]	Time  0.587 ( 5.018)	Data  0.001 ( 4.443)	Loss 8.3428e-02 (8.4523e-02) 
2023-05-27 12:48:59.096637: train Epoch: [30][ 36/193]	Time  9.377 ( 5.136)	Data  8.792 ( 4.560)	Loss 7.5385e-02 (8.4276e-02) 
2023-05-27 12:48:59.679077: train Epoch: [30][ 37/193]	Time  0.582 ( 5.016)	Data  0.001 ( 4.440)	Loss 1.0138e-01 (8.4727e-02) 
2023-05-27 12:49:09.037725: train Epoch: [30][ 38/193]	Time  9.359 ( 5.128)	Data  8.786 ( 4.552)	Loss 6.7587e-02 (8.4287e-02) 
2023-05-27 12:49:09.605593: train Epoch: [30][ 39/193]	Time  0.568 ( 5.014)	Data  0.001 ( 4.438)	Loss 1.2097e-01 (8.5204e-02) 
2023-05-27 12:49:19.010967: train Epoch: [30][ 40/193]	Time  9.405 ( 5.121)	Data  8.839 ( 4.545)	Loss 3.9112e-02 (8.4080e-02) 
2023-05-27 12:49:19.581016: train Epoch: [30][ 41/193]	Time  0.570 ( 5.012)	Data  0.001 ( 4.437)	Loss 8.7532e-02 (8.4162e-02) 
2023-05-27 12:49:29.035192: train Epoch: [30][ 42/193]	Time  9.454 ( 5.116)	Data  8.882 ( 4.541)	Loss 6.8870e-02 (8.3807e-02) 
2023-05-27 12:49:29.613362: train Epoch: [30][ 43/193]	Time  0.578 ( 5.013)	Data  0.001 ( 4.437)	Loss 7.8607e-02 (8.3688e-02) 
2023-05-27 12:49:39.196394: train Epoch: [30][ 44/193]	Time  9.583 ( 5.114)	Data  9.004 ( 4.539)	Loss 7.8338e-02 (8.3569e-02) 
2023-05-27 12:49:39.773779: train Epoch: [30][ 45/193]	Time  0.577 ( 5.015)	Data  0.001 ( 4.440)	Loss 9.7993e-02 (8.3883e-02) 
2023-05-27 12:49:49.283270: train Epoch: [30][ 46/193]	Time  9.509 ( 5.111)	Data  8.941 ( 4.536)	Loss 5.3686e-02 (8.3241e-02) 
2023-05-27 12:49:49.867493: train Epoch: [30][ 47/193]	Time  0.584 ( 5.017)	Data  0.001 ( 4.441)	Loss 1.0511e-01 (8.3696e-02) 
2023-05-27 12:49:59.484708: train Epoch: [30][ 48/193]	Time  9.617 ( 5.111)	Data  9.036 ( 4.535)	Loss 7.2543e-02 (8.3469e-02) 
2023-05-27 12:50:00.052448: train Epoch: [30][ 49/193]	Time  0.568 ( 5.020)	Data  0.001 ( 4.445)	Loss 6.5407e-02 (8.3107e-02) 
2023-05-27 12:50:09.918947: train Epoch: [30][ 50/193]	Time  9.867 ( 5.115)	Data  9.301 ( 4.540)	Loss 9.0386e-02 (8.3250e-02) 
2023-05-27 12:50:10.491318: train Epoch: [30][ 51/193]	Time  0.572 ( 5.027)	Data  0.001 ( 4.453)	Loss 8.8803e-02 (8.3357e-02) 
2023-05-27 12:50:20.269803: train Epoch: [30][ 52/193]	Time  9.778 ( 5.117)	Data  9.211 ( 4.542)	Loss 8.8018e-02 (8.3445e-02) 
2023-05-27 12:50:20.849069: train Epoch: [30][ 53/193]	Time  0.579 ( 5.033)	Data  0.001 ( 4.458)	Loss 7.1353e-02 (8.3221e-02) 
2023-05-27 12:50:30.229751: train Epoch: [30][ 54/193]	Time  9.381 ( 5.112)	Data  8.802 ( 4.537)	Loss 7.7777e-02 (8.3122e-02) 
2023-05-27 12:50:30.828117: train Epoch: [30][ 55/193]	Time  0.598 ( 5.032)	Data  0.001 ( 4.456)	Loss 1.0436e-01 (8.3501e-02) 
2023-05-27 12:50:40.686491: train Epoch: [30][ 56/193]	Time  9.858 ( 5.116)	Data  9.285 ( 4.541)	Loss 1.2407e-01 (8.4213e-02) 
2023-05-27 12:50:41.288742: train Epoch: [30][ 57/193]	Time  0.602 ( 5.038)	Data  0.001 ( 4.463)	Loss 7.9367e-02 (8.4129e-02) 
2023-05-27 12:50:50.879932: train Epoch: [30][ 58/193]	Time  9.591 ( 5.116)	Data  9.024 ( 4.540)	Loss 7.1001e-02 (8.3907e-02) 
2023-05-27 12:50:51.452679: train Epoch: [30][ 59/193]	Time  0.573 ( 5.040)	Data  0.001 ( 4.464)	Loss 5.8168e-02 (8.3478e-02) 
2023-05-27 12:51:00.739279: train Epoch: [30][ 60/193]	Time  9.287 ( 5.109)	Data  8.713 ( 4.534)	Loss 6.6464e-02 (8.3199e-02) 
2023-05-27 12:51:01.304925: train Epoch: [30][ 61/193]	Time  0.566 ( 5.036)	Data  0.001 ( 4.461)	Loss 1.0038e-01 (8.3476e-02) 
2023-05-27 12:51:10.947023: train Epoch: [30][ 62/193]	Time  9.642 ( 5.109)	Data  9.066 ( 4.534)	Loss 2.0996e-01 (8.5484e-02) 
2023-05-27 12:51:11.536822: train Epoch: [30][ 63/193]	Time  0.590 ( 5.039)	Data  0.001 ( 4.463)	Loss 6.2608e-02 (8.5126e-02) 
2023-05-27 12:51:21.493699: train Epoch: [30][ 64/193]	Time  9.957 ( 5.114)	Data  9.359 ( 4.538)	Loss 9.3333e-02 (8.5253e-02) 
2023-05-27 12:51:22.058684: train Epoch: [30][ 65/193]	Time  0.565 ( 5.045)	Data  0.001 ( 4.470)	Loss 5.8114e-02 (8.4841e-02) 
2023-05-27 12:51:31.313067: train Epoch: [30][ 66/193]	Time  9.254 ( 5.108)	Data  8.689 ( 4.533)	Loss 8.0405e-02 (8.4775e-02) 
2023-05-27 12:51:31.879699: train Epoch: [30][ 67/193]	Time  0.567 ( 5.041)	Data  0.001 ( 4.466)	Loss 5.3632e-02 (8.4317e-02) 
2023-05-27 12:51:41.333874: train Epoch: [30][ 68/193]	Time  9.454 ( 5.105)	Data  8.888 ( 4.530)	Loss 6.4341e-02 (8.4028e-02) 
2023-05-27 12:51:41.901111: train Epoch: [30][ 69/193]	Time  0.567 ( 5.041)	Data  0.001 ( 4.465)	Loss 1.0386e-01 (8.4311e-02) 
2023-05-27 12:51:50.829922: train Epoch: [30][ 70/193]	Time  8.929 ( 5.095)	Data  8.363 ( 4.520)	Loss 1.4295e-01 (8.5137e-02) 
2023-05-27 12:51:51.395754: train Epoch: [30][ 71/193]	Time  0.566 ( 5.032)	Data  0.001 ( 4.457)	Loss 8.3321e-02 (8.5112e-02) 
2023-05-27 12:52:01.245582: train Epoch: [30][ 72/193]	Time  9.850 ( 5.098)	Data  9.271 ( 4.523)	Loss 5.1330e-02 (8.4649e-02) 
2023-05-27 12:52:01.898439: train Epoch: [30][ 73/193]	Time  0.653 ( 5.038)	Data  0.001 ( 4.462)	Loss 5.7675e-02 (8.4284e-02) 
2023-05-27 12:52:11.067077: train Epoch: [30][ 74/193]	Time  9.169 ( 5.093)	Data  8.576 ( 4.517)	Loss 4.5938e-02 (8.3773e-02) 
2023-05-27 12:52:11.635711: train Epoch: [30][ 75/193]	Time  0.569 ( 5.034)	Data  0.001 ( 4.458)	Loss 7.3187e-02 (8.3634e-02) 
2023-05-27 12:52:21.209275: train Epoch: [30][ 76/193]	Time  9.574 ( 5.093)	Data  9.007 ( 4.517)	Loss 5.9971e-02 (8.3326e-02) 
2023-05-27 12:52:21.775030: train Epoch: [30][ 77/193]	Time  0.566 ( 5.035)	Data  0.001 ( 4.459)	Loss 6.7510e-02 (8.3124e-02) 
2023-05-27 12:52:31.173957: train Epoch: [30][ 78/193]	Time  9.399 ( 5.090)	Data  8.832 ( 4.514)	Loss 5.6314e-02 (8.2784e-02) 
2023-05-27 12:52:31.740651: train Epoch: [30][ 79/193]	Time  0.567 ( 5.033)	Data  0.001 ( 4.458)	Loss 6.9596e-02 (8.2620e-02) 
2023-05-27 12:52:41.325416: train Epoch: [30][ 80/193]	Time  9.585 ( 5.090)	Data  8.995 ( 4.514)	Loss 1.3620e-01 (8.3281e-02) 
2023-05-27 12:52:41.907137: train Epoch: [30][ 81/193]	Time  0.582 ( 5.035)	Data  0.001 ( 4.459)	Loss 1.3008e-01 (8.3852e-02) 
2023-05-27 12:52:51.706102: train Epoch: [30][ 82/193]	Time  9.799 ( 5.092)	Data  9.232 ( 4.516)	Loss 7.0704e-02 (8.3693e-02) 
2023-05-27 12:52:52.272543: train Epoch: [30][ 83/193]	Time  0.566 ( 5.038)	Data  0.001 ( 4.463)	Loss 7.9922e-02 (8.3648e-02) 
2023-05-27 12:53:01.628225: train Epoch: [30][ 84/193]	Time  9.356 ( 5.089)	Data  8.783 ( 4.513)	Loss 9.4216e-02 (8.3773e-02) 
2023-05-27 12:53:02.202874: train Epoch: [30][ 85/193]	Time  0.575 ( 5.037)	Data  0.001 ( 4.461)	Loss 6.2301e-02 (8.3523e-02) 
2023-05-27 12:53:11.524566: train Epoch: [30][ 86/193]	Time  9.322 ( 5.086)	Data  8.749 ( 4.510)	Loss 8.0479e-02 (8.3488e-02) 
2023-05-27 12:53:12.098036: train Epoch: [30][ 87/193]	Time  0.573 ( 5.034)	Data  0.001 ( 4.459)	Loss 6.3013e-02 (8.3255e-02) 
2023-05-27 12:53:21.323174: train Epoch: [30][ 88/193]	Time  9.225 ( 5.082)	Data  8.650 ( 4.506)	Loss 7.9075e-02 (8.3208e-02) 
2023-05-27 12:53:21.900897: train Epoch: [30][ 89/193]	Time  0.578 ( 5.032)	Data  0.001 ( 4.456)	Loss 9.0656e-02 (8.3291e-02) 
2023-05-27 12:53:30.114261: train Epoch: [30][ 90/193]	Time  8.213 ( 5.066)	Data  7.621 ( 4.491)	Loss 5.5023e-02 (8.2981e-02) 
2023-05-27 12:53:30.687194: train Epoch: [30][ 91/193]	Time  0.573 ( 5.018)	Data  0.001 ( 4.442)	Loss 1.0874e-01 (8.3261e-02) 
2023-05-27 12:53:39.804466: train Epoch: [30][ 92/193]	Time  9.117 ( 5.062)	Data  8.549 ( 4.486)	Loss 1.1785e-01 (8.3632e-02) 
2023-05-27 12:53:40.399544: train Epoch: [30][ 93/193]	Time  0.595 ( 5.014)	Data  0.001 ( 4.438)	Loss 8.6777e-02 (8.3666e-02) 
2023-05-27 12:53:49.833452: train Epoch: [30][ 94/193]	Time  9.434 ( 5.061)	Data  8.860 ( 4.485)	Loss 5.3721e-02 (8.3351e-02) 
2023-05-27 12:53:50.430464: train Epoch: [30][ 95/193]	Time  0.597 ( 5.014)	Data  0.001 ( 4.438)	Loss 9.1771e-02 (8.3438e-02) 
2023-05-27 12:54:00.048914: train Epoch: [30][ 96/193]	Time  9.618 ( 5.062)	Data  8.956 ( 4.485)	Loss 9.7038e-02 (8.3579e-02) 
2023-05-27 12:54:00.625210: train Epoch: [30][ 97/193]	Time  0.576 ( 5.016)	Data  0.001 ( 4.439)	Loss 7.7822e-02 (8.3520e-02) 
2023-05-27 12:54:10.159140: train Epoch: [30][ 98/193]	Time  9.534 ( 5.062)	Data  8.957 ( 4.485)	Loss 6.9058e-02 (8.3374e-02) 
2023-05-27 12:54:10.726023: train Epoch: [30][ 99/193]	Time  0.567 ( 5.017)	Data  0.001 ( 4.440)	Loss 7.6816e-02 (8.3308e-02) 
2023-05-27 12:54:20.508631: train Epoch: [30][100/193]	Time  9.783 ( 5.064)	Data  9.211 ( 4.487)	Loss 1.4470e-01 (8.3916e-02) 
2023-05-27 12:54:21.075115: train Epoch: [30][101/193]	Time  0.566 ( 5.020)	Data  0.001 ( 4.443)	Loss 9.0021e-02 (8.3976e-02) 
2023-05-27 12:54:30.575749: train Epoch: [30][102/193]	Time  9.501 ( 5.063)	Data  8.932 ( 4.487)	Loss 2.4211e-01 (8.5511e-02) 
2023-05-27 12:54:31.166704: train Epoch: [30][103/193]	Time  0.591 ( 5.020)	Data  0.001 ( 4.444)	Loss 6.1512e-02 (8.5280e-02) 
2023-05-27 12:54:40.640562: train Epoch: [30][104/193]	Time  9.474 ( 5.063)	Data  8.891 ( 4.486)	Loss 1.0235e-01 (8.5443e-02) 
2023-05-27 12:54:41.207354: train Epoch: [30][105/193]	Time  0.567 ( 5.020)	Data  0.001 ( 4.444)	Loss 1.1473e-01 (8.5719e-02) 
2023-05-27 12:54:51.317910: train Epoch: [30][106/193]	Time 10.111 ( 5.068)	Data  9.546 ( 4.491)	Loss 1.0424e-01 (8.5892e-02) 
2023-05-27 12:54:51.886843: train Epoch: [30][107/193]	Time  0.569 ( 5.026)	Data  0.001 ( 4.450)	Loss 8.0271e-02 (8.5840e-02) 
2023-05-27 12:55:01.577166: train Epoch: [30][108/193]	Time  9.690 ( 5.069)	Data  9.100 ( 4.492)	Loss 6.5784e-02 (8.5656e-02) 
2023-05-27 12:55:02.201520: train Epoch: [30][109/193]	Time  0.624 ( 5.029)	Data  0.001 ( 4.452)	Loss 1.2223e-01 (8.5989e-02) 
2023-05-27 12:55:11.837844: train Epoch: [30][110/193]	Time  9.636 ( 5.070)	Data  9.065 ( 4.493)	Loss 1.0521e-01 (8.6162e-02) 
2023-05-27 12:55:12.412037: train Epoch: [30][111/193]	Time  0.574 ( 5.030)	Data  0.001 ( 4.453)	Loss 1.0798e-01 (8.6357e-02) 
2023-05-27 12:55:22.150167: train Epoch: [30][112/193]	Time  9.738 ( 5.072)	Data  9.174 ( 4.495)	Loss 6.3069e-02 (8.6151e-02) 
2023-05-27 12:55:22.735343: train Epoch: [30][113/193]	Time  0.585 ( 5.032)	Data  0.001 ( 4.455)	Loss 1.2935e-01 (8.6530e-02) 
2023-05-27 12:55:32.275135: train Epoch: [30][114/193]	Time  9.540 ( 5.071)	Data  8.942 ( 4.494)	Loss 4.7524e-02 (8.6190e-02) 
2023-05-27 12:55:32.840503: train Epoch: [30][115/193]	Time  0.565 ( 5.033)	Data  0.001 ( 4.456)	Loss 5.0813e-02 (8.5885e-02) 
2023-05-27 12:55:42.465573: train Epoch: [30][116/193]	Time  9.625 ( 5.072)	Data  9.059 ( 4.495)	Loss 6.1975e-02 (8.5681e-02) 
2023-05-27 12:55:43.032540: train Epoch: [30][117/193]	Time  0.567 ( 5.034)	Data  0.001 ( 4.457)	Loss 5.3861e-02 (8.5411e-02) 
2023-05-27 12:55:52.280126: train Epoch: [30][118/193]	Time  9.248 ( 5.069)	Data  8.673 ( 4.492)	Loss 7.0677e-02 (8.5288e-02) 
2023-05-27 12:55:52.846939: train Epoch: [30][119/193]	Time  0.567 ( 5.032)	Data  0.001 ( 4.455)	Loss 6.0966e-02 (8.5085e-02) 
2023-05-27 12:56:02.136567: train Epoch: [30][120/193]	Time  9.290 ( 5.067)	Data  8.720 ( 4.490)	Loss 1.5656e-01 (8.5676e-02) 
2023-05-27 12:56:02.715992: train Epoch: [30][121/193]	Time  0.579 ( 5.030)	Data  0.001 ( 4.453)	Loss 1.2014e-01 (8.5958e-02) 
2023-05-27 12:56:12.543664: train Epoch: [30][122/193]	Time  9.828 ( 5.069)	Data  9.255 ( 4.492)	Loss 6.2247e-02 (8.5765e-02) 
2023-05-27 12:56:13.120165: train Epoch: [30][123/193]	Time  0.576 ( 5.033)	Data  0.001 ( 4.456)	Loss 8.5065e-02 (8.5760e-02) 
2023-05-27 12:56:22.816407: train Epoch: [30][124/193]	Time  9.696 ( 5.070)	Data  9.130 ( 4.494)	Loss 1.6471e-01 (8.6391e-02) 
2023-05-27 12:56:23.383349: train Epoch: [30][125/193]	Time  0.567 ( 5.034)	Data  0.001 ( 4.458)	Loss 1.0736e-01 (8.6558e-02) 
2023-05-27 12:56:32.823270: train Epoch: [30][126/193]	Time  9.440 ( 5.069)	Data  8.868 ( 4.493)	Loss 2.5895e-02 (8.6080e-02) 
2023-05-27 12:56:33.388739: train Epoch: [30][127/193]	Time  0.565 ( 5.034)	Data  0.001 ( 4.458)	Loss 7.6223e-02 (8.6003e-02) 
2023-05-27 12:56:43.082501: train Epoch: [30][128/193]	Time  9.694 ( 5.070)	Data  9.116 ( 4.494)	Loss 9.4753e-02 (8.6071e-02) 
2023-05-27 12:56:43.671725: train Epoch: [30][129/193]	Time  0.589 ( 5.035)	Data  0.001 ( 4.459)	Loss 5.8530e-02 (8.5859e-02) 
2023-05-27 12:56:53.170895: train Epoch: [30][130/193]	Time  9.499 ( 5.070)	Data  8.923 ( 4.493)	Loss 1.3235e-01 (8.6214e-02) 
2023-05-27 12:56:53.744447: train Epoch: [30][131/193]	Time  0.574 ( 5.035)	Data  0.001 ( 4.459)	Loss 1.3405e-01 (8.6576e-02) 
2023-05-27 12:57:03.104662: train Epoch: [30][132/193]	Time  9.360 ( 5.068)	Data  8.794 ( 4.492)	Loss 8.4337e-02 (8.6560e-02) 
2023-05-27 12:57:03.679919: train Epoch: [30][133/193]	Time  0.575 ( 5.034)	Data  0.001 ( 4.458)	Loss 9.8655e-02 (8.6650e-02) 
2023-05-27 12:57:12.990160: train Epoch: [30][134/193]	Time  9.310 ( 5.066)	Data  8.736 ( 4.490)	Loss 5.7858e-02 (8.6437e-02) 
2023-05-27 12:57:13.566433: train Epoch: [30][135/193]	Time  0.576 ( 5.033)	Data  0.001 ( 4.457)	Loss 1.2046e-01 (8.6687e-02) 
2023-05-27 12:57:23.634787: train Epoch: [30][136/193]	Time 10.068 ( 5.070)	Data  9.498 ( 4.494)	Loss 8.0894e-02 (8.6644e-02) 
2023-05-27 12:57:24.201430: train Epoch: [30][137/193]	Time  0.567 ( 5.037)	Data  0.001 ( 4.461)	Loss 7.9286e-02 (8.6591e-02) 
2023-05-27 12:57:33.912687: train Epoch: [30][138/193]	Time  9.711 ( 5.071)	Data  9.144 ( 4.495)	Loss 5.3401e-02 (8.6352e-02) 
2023-05-27 12:57:34.495551: train Epoch: [30][139/193]	Time  0.583 ( 5.039)	Data  0.001 ( 4.463)	Loss 8.4563e-02 (8.6340e-02) 
2023-05-27 12:57:44.381328: train Epoch: [30][140/193]	Time  9.886 ( 5.073)	Data  9.277 ( 4.497)	Loss 7.7254e-02 (8.6275e-02) 
2023-05-27 12:57:44.960262: train Epoch: [30][141/193]	Time  0.579 ( 5.042)	Data  0.001 ( 4.465)	Loss 1.2511e-01 (8.6549e-02) 
2023-05-27 12:57:54.672220: train Epoch: [30][142/193]	Time  9.712 ( 5.074)	Data  9.146 ( 4.498)	Loss 3.3674e-01 (8.8298e-02) 
2023-05-27 12:57:55.239210: train Epoch: [30][143/193]	Time  0.567 ( 5.043)	Data  0.001 ( 4.467)	Loss 9.9862e-02 (8.8378e-02) 
2023-05-27 12:58:04.830869: train Epoch: [30][144/193]	Time  9.592 ( 5.074)	Data  9.008 ( 4.498)	Loss 1.2235e-01 (8.8613e-02) 
2023-05-27 12:58:05.400123: train Epoch: [30][145/193]	Time  0.569 ( 5.043)	Data  0.001 ( 4.467)	Loss 1.3878e-01 (8.8956e-02) 
2023-05-27 12:58:15.361096: train Epoch: [30][146/193]	Time  9.961 ( 5.077)	Data  9.384 ( 4.501)	Loss 7.0327e-02 (8.8830e-02) 
2023-05-27 12:58:15.962156: train Epoch: [30][147/193]	Time  0.601 ( 5.047)	Data  0.001 ( 4.470)	Loss 7.8077e-02 (8.8757e-02) 
2023-05-27 12:58:25.368209: train Epoch: [30][148/193]	Time  9.406 ( 5.076)	Data  8.841 ( 4.500)	Loss 1.0521e-01 (8.8867e-02) 
2023-05-27 12:58:25.934362: train Epoch: [30][149/193]	Time  0.566 ( 5.046)	Data  0.001 ( 4.470)	Loss 8.5272e-02 (8.8843e-02) 
2023-05-27 12:58:35.391250: train Epoch: [30][150/193]	Time  9.457 ( 5.075)	Data  8.890 ( 4.499)	Loss 1.8285e-01 (8.9466e-02) 
2023-05-27 12:58:35.969860: train Epoch: [30][151/193]	Time  0.579 ( 5.045)	Data  0.001 ( 4.469)	Loss 1.3574e-01 (8.9770e-02) 
2023-05-27 12:58:46.107350: train Epoch: [30][152/193]	Time 10.137 ( 5.079)	Data  9.564 ( 4.503)	Loss 7.3475e-02 (8.9664e-02) 
2023-05-27 12:58:46.683352: train Epoch: [30][153/193]	Time  0.576 ( 5.049)	Data  0.001 ( 4.473)	Loss 1.1501e-01 (8.9829e-02) 
2023-05-27 12:58:56.143441: train Epoch: [30][154/193]	Time  9.460 ( 5.078)	Data  8.883 ( 4.502)	Loss 9.9812e-02 (8.9893e-02) 
2023-05-27 12:58:56.712809: train Epoch: [30][155/193]	Time  0.569 ( 5.049)	Data  0.001 ( 4.473)	Loss 1.3508e-01 (9.0183e-02) 
2023-05-27 12:59:06.044044: train Epoch: [30][156/193]	Time  9.331 ( 5.076)	Data  8.766 ( 4.500)	Loss 8.9839e-02 (9.0180e-02) 
2023-05-27 12:59:06.625091: train Epoch: [30][157/193]	Time  0.581 ( 5.048)	Data  0.001 ( 4.472)	Loss 7.3109e-02 (9.0072e-02) 
2023-05-27 12:59:16.202372: train Epoch: [30][158/193]	Time  9.577 ( 5.076)	Data  8.990 ( 4.500)	Loss 1.1800e-01 (9.0248e-02) 
2023-05-27 12:59:16.804625: train Epoch: [30][159/193]	Time  0.602 ( 5.048)	Data  0.001 ( 4.472)	Loss 1.7100e-01 (9.0753e-02) 
2023-05-27 12:59:26.279320: train Epoch: [30][160/193]	Time  9.475 ( 5.076)	Data  8.909 ( 4.500)	Loss 1.0852e-01 (9.0863e-02) 
2023-05-27 12:59:26.903886: train Epoch: [30][161/193]	Time  0.625 ( 5.048)	Data  0.059 ( 4.472)	Loss 9.4154e-02 (9.0883e-02) 
2023-05-27 12:59:35.767269: train Epoch: [30][162/193]	Time  8.863 ( 5.072)	Data  8.295 ( 4.496)	Loss 8.7227e-02 (9.0861e-02) 
2023-05-27 12:59:36.805703: train Epoch: [30][163/193]	Time  1.038 ( 5.047)	Data  0.458 ( 4.471)	Loss 1.3761e-01 (9.1146e-02) 
2023-05-27 12:59:46.246116: train Epoch: [30][164/193]	Time  9.440 ( 5.074)	Data  8.867 ( 4.498)	Loss 1.0450e-01 (9.1227e-02) 
2023-05-27 12:59:46.831909: train Epoch: [30][165/193]	Time  0.586 ( 5.047)	Data  0.001 ( 4.471)	Loss 5.4739e-02 (9.1007e-02) 
2023-05-27 12:59:56.415199: train Epoch: [30][166/193]	Time  9.583 ( 5.074)	Data  9.011 ( 4.498)	Loss 1.4849e-01 (9.1351e-02) 
2023-05-27 12:59:56.984338: train Epoch: [30][167/193]	Time  0.569 ( 5.047)	Data  0.001 ( 4.471)	Loss 8.5078e-02 (9.1314e-02) 
2023-05-27 13:00:06.895776: train Epoch: [30][168/193]	Time  9.911 ( 5.076)	Data  9.345 ( 4.500)	Loss 1.9309e-01 (9.1916e-02) 
2023-05-27 13:00:07.531187: train Epoch: [30][169/193]	Time  0.635 ( 5.050)	Data  0.001 ( 4.473)	Loss 1.2594e-01 (9.2116e-02) 
2023-05-27 13:00:16.920896: train Epoch: [30][170/193]	Time  9.390 ( 5.075)	Data  8.809 ( 4.499)	Loss 2.1547e-01 (9.2838e-02) 
2023-05-27 13:00:17.495454: train Epoch: [30][171/193]	Time  0.575 ( 5.049)	Data  0.001 ( 4.473)	Loss 9.3948e-02 (9.2844e-02) 
2023-05-27 13:00:26.688176: train Epoch: [30][172/193]	Time  9.193 ( 5.073)	Data  8.597 ( 4.496)	Loss 1.4561e-01 (9.3149e-02) 
2023-05-27 13:00:27.394296: train Epoch: [30][173/193]	Time  0.706 ( 5.048)	Data  0.140 ( 4.471)	Loss 1.6811e-01 (9.3580e-02) 
2023-05-27 13:00:36.729986: train Epoch: [30][174/193]	Time  9.336 ( 5.072)	Data  8.767 ( 4.496)	Loss 8.6861e-02 (9.3542e-02) 
2023-05-27 13:00:37.325483: train Epoch: [30][175/193]	Time  0.595 ( 5.047)	Data  0.019 ( 4.471)	Loss 1.5464e-01 (9.3889e-02) 
2023-05-27 13:00:46.657344: train Epoch: [30][176/193]	Time  9.332 ( 5.071)	Data  8.760 ( 4.495)	Loss 8.6571e-02 (9.3847e-02) 
2023-05-27 13:00:47.240045: train Epoch: [30][177/193]	Time  0.583 ( 5.046)	Data  0.001 ( 4.470)	Loss 5.7598e-02 (9.3644e-02) 
2023-05-27 13:00:57.230384: train Epoch: [30][178/193]	Time  9.990 ( 5.074)	Data  9.425 ( 4.497)	Loss 8.2261e-02 (9.3580e-02) 
2023-05-27 13:00:57.808523: train Epoch: [30][179/193]	Time  0.578 ( 5.049)	Data  0.013 ( 4.472)	Loss 2.2087e-01 (9.4287e-02) 
2023-05-27 13:01:06.970882: train Epoch: [30][180/193]	Time  9.162 ( 5.071)	Data  8.585 ( 4.495)	Loss 8.8256e-02 (9.4254e-02) 
2023-05-27 13:01:07.975076: train Epoch: [30][181/193]	Time  1.004 ( 5.049)	Data  0.434 ( 4.473)	Loss 1.5038e-01 (9.4562e-02) 
2023-05-27 13:01:16.847054: train Epoch: [30][182/193]	Time  8.872 ( 5.070)	Data  8.304 ( 4.494)	Loss 3.6659e-02 (9.4246e-02) 
2023-05-27 13:01:18.038336: train Epoch: [30][183/193]	Time  1.191 ( 5.049)	Data  0.603 ( 4.473)	Loss 1.0928e-01 (9.4328e-02) 
2023-05-27 13:01:27.068854: train Epoch: [30][184/193]	Time  9.031 ( 5.070)	Data  8.423 ( 4.494)	Loss 1.0705e-01 (9.4397e-02) 
2023-05-27 13:01:28.081513: train Epoch: [30][185/193]	Time  1.013 ( 5.048)	Data  0.448 ( 4.472)	Loss 7.3999e-02 (9.4287e-02) 
2023-05-27 13:01:36.745226: train Epoch: [30][186/193]	Time  8.664 ( 5.068)	Data  8.098 ( 4.492)	Loss 7.1444e-02 (9.4165e-02) 
2023-05-27 13:01:38.204426: train Epoch: [30][187/193]	Time  1.459 ( 5.049)	Data  0.892 ( 4.472)	Loss 2.9296e-01 (9.5222e-02) 
2023-05-27 13:01:46.793885: train Epoch: [30][188/193]	Time  8.589 ( 5.067)	Data  8.022 ( 4.491)	Loss 1.5769e-01 (9.5553e-02) 
2023-05-27 13:01:47.844491: train Epoch: [30][189/193]	Time  1.051 ( 5.046)	Data  0.478 ( 4.470)	Loss 8.5452e-02 (9.5499e-02) 
2023-05-27 13:01:56.489535: train Epoch: [30][190/193]	Time  8.645 ( 5.065)	Data  8.069 ( 4.489)	Loss 1.0128e-01 (9.5530e-02) 
2023-05-27 13:01:58.226122: train Epoch: [30][191/193]	Time  1.737 ( 5.048)	Data  1.165 ( 4.472)	Loss 8.8086e-02 (9.5491e-02) 
2023-05-27 13:02:05.427303: train Epoch: [30][192/193]	Time  7.201 ( 5.059)	Data  6.615 ( 4.483)	Loss 5.7514e-02 (9.5294e-02) 
2023-05-27 13:02:05.605265: Train Epoch done in 976.5431967580225 s 
2023-05-27 13:02:12.326231: val Epoch: [30][ 0/72]	Time  5.867 ( 5.867)	Data  5.645 ( 5.645)	Loss 5.7879e-02 (5.7879e-02) 
2023-05-27 13:02:12.559248: val Epoch: [30][ 1/72]	Time  0.233 ( 3.050)	Data  0.126 ( 2.886)	Loss 6.0332e-02 (5.9105e-02) 
2023-05-27 13:02:17.386594: val Epoch: [30][ 2/72]	Time  4.827 ( 3.643)	Data  4.680 ( 3.484)	Loss 1.1086e-01 (7.6355e-02) 
2023-05-27 13:02:17.539979: val Epoch: [30][ 3/72]	Time  0.153 ( 2.770)	Data  0.026 ( 2.619)	Loss 1.8767e-01 (1.0418e-01) 
2023-05-27 13:02:22.458792: val Epoch: [30][ 4/72]	Time  4.919 ( 3.200)	Data  4.813 ( 3.058)	Loss 1.4947e-01 (1.1324e-01) 
2023-05-27 13:02:22.719268: val Epoch: [30][ 5/72]	Time  0.260 ( 2.710)	Data  0.155 ( 2.574)	Loss 1.8729e-01 (1.2558e-01) 
2023-05-27 13:02:27.249009: val Epoch: [30][ 6/72]	Time  4.530 ( 2.970)	Data  4.423 ( 2.838)	Loss 1.0470e-01 (1.2260e-01) 
2023-05-27 13:02:27.974858: val Epoch: [30][ 7/72]	Time  0.726 ( 2.689)	Data  0.619 ( 2.561)	Loss 4.4954e-01 (1.6347e-01) 
2023-05-27 13:02:32.410519: val Epoch: [30][ 8/72]	Time  4.436 ( 2.883)	Data  4.330 ( 2.757)	Loss 1.4326e-01 (1.6122e-01) 
2023-05-27 13:02:33.018461: val Epoch: [30][ 9/72]	Time  0.608 ( 2.656)	Data  0.502 ( 2.532)	Loss 2.9190e-01 (1.7429e-01) 
2023-05-27 13:02:37.605129: val Epoch: [30][10/72]	Time  4.587 ( 2.831)	Data  4.477 ( 2.709)	Loss 1.7274e-01 (1.7415e-01) 
2023-05-27 13:02:38.098978: val Epoch: [30][11/72]	Time  0.494 ( 2.637)	Data  0.370 ( 2.514)	Loss 5.6496e-02 (1.6434e-01) 
2023-05-27 13:02:42.556984: val Epoch: [30][12/72]	Time  4.458 ( 2.777)	Data  4.344 ( 2.655)	Loss 1.1379e-01 (1.6046e-01) 
2023-05-27 13:02:43.092439: val Epoch: [30][13/72]	Time  0.535 ( 2.617)	Data  0.414 ( 2.495)	Loss 5.6331e-02 (1.5302e-01) 
2023-05-27 13:02:47.865288: val Epoch: [30][14/72]	Time  4.773 ( 2.760)	Data  4.595 ( 2.635)	Loss 3.7033e-01 (1.6751e-01) 
2023-05-27 13:02:47.975002: val Epoch: [30][15/72]	Time  0.110 ( 2.595)	Data  0.001 ( 2.470)	Loss 1.4614e-01 (1.6617e-01) 
2023-05-27 13:02:52.817556: val Epoch: [30][16/72]	Time  4.843 ( 2.727)	Data  4.734 ( 2.603)	Loss 1.9040e-01 (1.6760e-01) 
2023-05-27 13:02:52.926806: val Epoch: [30][17/72]	Time  0.109 ( 2.582)	Data  0.001 ( 2.459)	Loss 9.1433e-02 (1.6336e-01) 
2023-05-27 13:02:57.706521: val Epoch: [30][18/72]	Time  4.780 ( 2.697)	Data  4.671 ( 2.575)	Loss 5.7114e-02 (1.5777e-01) 
2023-05-27 13:02:58.015785: val Epoch: [30][19/72]	Time  0.309 ( 2.578)	Data  0.201 ( 2.456)	Loss 1.5897e-01 (1.5783e-01) 
2023-05-27 13:03:02.906995: val Epoch: [30][20/72]	Time  4.891 ( 2.688)	Data  4.779 ( 2.567)	Loss 1.8586e-01 (1.5917e-01) 
2023-05-27 13:03:03.062314: val Epoch: [30][21/72]	Time  0.155 ( 2.573)	Data  0.039 ( 2.452)	Loss 8.4131e-02 (1.5576e-01) 
2023-05-27 13:03:08.172020: val Epoch: [30][22/72]	Time  5.110 ( 2.683)	Data  5.001 ( 2.563)	Loss 1.3013e-01 (1.5464e-01) 
2023-05-27 13:03:08.293577: val Epoch: [30][23/72]	Time  0.122 ( 2.576)	Data  0.001 ( 2.456)	Loss 2.9185e-01 (1.6036e-01) 
2023-05-27 13:03:13.550262: val Epoch: [30][24/72]	Time  5.257 ( 2.684)	Data  5.137 ( 2.563)	Loss 6.0379e-02 (1.5636e-01) 
2023-05-27 13:03:13.663164: val Epoch: [30][25/72]	Time  0.113 ( 2.585)	Data  0.001 ( 2.465)	Loss 7.4693e-02 (1.5322e-01) 
2023-05-27 13:03:18.539386: val Epoch: [30][26/72]	Time  4.876 ( 2.670)	Data  4.750 ( 2.549)	Loss 9.1797e-02 (1.5094e-01) 
2023-05-27 13:03:18.647652: val Epoch: [30][27/72]	Time  0.108 ( 2.578)	Data  0.001 ( 2.458)	Loss 7.4230e-02 (1.4820e-01) 
2023-05-27 13:03:23.258087: val Epoch: [30][28/72]	Time  4.610 ( 2.648)	Data  4.502 ( 2.529)	Loss 3.5232e-02 (1.4431e-01) 
2023-05-27 13:03:23.367085: val Epoch: [30][29/72]	Time  0.109 ( 2.564)	Data  0.001 ( 2.445)	Loss 1.2283e-01 (1.4359e-01) 
2023-05-27 13:03:28.392127: val Epoch: [30][30/72]	Time  5.025 ( 2.643)	Data  4.913 ( 2.524)	Loss 1.1735e-01 (1.4275e-01) 
2023-05-27 13:03:28.501719: val Epoch: [30][31/72]	Time  0.110 ( 2.564)	Data  0.000 ( 2.445)	Loss 4.9390e-02 (1.3983e-01) 
2023-05-27 13:03:33.441152: val Epoch: [30][32/72]	Time  4.939 ( 2.636)	Data  4.832 ( 2.518)	Loss 9.6883e-02 (1.3853e-01) 
2023-05-27 13:03:33.547280: val Epoch: [30][33/72]	Time  0.106 ( 2.561)	Data  0.000 ( 2.444)	Loss 9.6342e-02 (1.3729e-01) 
2023-05-27 13:03:38.513436: val Epoch: [30][34/72]	Time  4.966 ( 2.630)	Data  4.860 ( 2.513)	Loss 9.5432e-02 (1.3609e-01) 
2023-05-27 13:03:38.619169: val Epoch: [30][35/72]	Time  0.106 ( 2.560)	Data  0.001 ( 2.443)	Loss 4.0384e-01 (1.4353e-01) 
2023-05-27 13:03:43.413075: val Epoch: [30][36/72]	Time  4.794 ( 2.620)	Data  4.687 ( 2.504)	Loss 4.3666e-02 (1.4083e-01) 
2023-05-27 13:03:43.519209: val Epoch: [30][37/72]	Time  0.106 ( 2.554)	Data  0.001 ( 2.438)	Loss 7.0661e-02 (1.3898e-01) 
2023-05-27 13:03:49.047144: val Epoch: [30][38/72]	Time  5.528 ( 2.630)	Data  5.408 ( 2.514)	Loss 8.8664e-02 (1.3769e-01) 
2023-05-27 13:03:49.155705: val Epoch: [30][39/72]	Time  0.109 ( 2.567)	Data  0.001 ( 2.451)	Loss 3.6254e-01 (1.4331e-01) 
2023-05-27 13:03:54.069720: val Epoch: [30][40/72]	Time  4.914 ( 2.625)	Data  4.806 ( 2.508)	Loss 6.9979e-02 (1.4152e-01) 
2023-05-27 13:03:54.178613: val Epoch: [30][41/72]	Time  0.109 ( 2.565)	Data  0.001 ( 2.449)	Loss 5.7558e-02 (1.3953e-01) 
2023-05-27 13:03:59.159780: val Epoch: [30][42/72]	Time  4.981 ( 2.621)	Data  4.873 ( 2.505)	Loss 1.5280e-01 (1.3983e-01) 
2023-05-27 13:03:59.267884: val Epoch: [30][43/72]	Time  0.108 ( 2.564)	Data  0.001 ( 2.448)	Loss 1.0489e-01 (1.3904e-01) 
2023-05-27 13:04:03.967527: val Epoch: [30][44/72]	Time  4.700 ( 2.611)	Data  4.591 ( 2.496)	Loss 3.6199e-02 (1.3675e-01) 
2023-05-27 13:04:04.161345: val Epoch: [30][45/72]	Time  0.194 ( 2.559)	Data  0.085 ( 2.443)	Loss 6.8311e-02 (1.3527e-01) 
2023-05-27 13:04:09.122906: val Epoch: [30][46/72]	Time  4.962 ( 2.610)	Data  4.853 ( 2.495)	Loss 2.4332e-01 (1.3757e-01) 
2023-05-27 13:04:09.231461: val Epoch: [30][47/72]	Time  0.109 ( 2.558)	Data  0.001 ( 2.443)	Loss 4.8912e-01 (1.4489e-01) 
2023-05-27 13:04:13.822506: val Epoch: [30][48/72]	Time  4.591 ( 2.599)	Data  4.478 ( 2.484)	Loss 9.2716e-02 (1.4383e-01) 
2023-05-27 13:04:14.150538: val Epoch: [30][49/72]	Time  0.328 ( 2.554)	Data  0.214 ( 2.439)	Loss 2.9003e-01 (1.4675e-01) 
2023-05-27 13:04:18.626813: val Epoch: [30][50/72]	Time  4.476 ( 2.592)	Data  4.368 ( 2.477)	Loss 6.7081e-02 (1.4519e-01) 
2023-05-27 13:04:19.203610: val Epoch: [30][51/72]	Time  0.577 ( 2.553)	Data  0.466 ( 2.438)	Loss 4.4069e-02 (1.4324e-01) 
2023-05-27 13:04:23.581142: val Epoch: [30][52/72]	Time  4.378 ( 2.587)	Data  4.270 ( 2.473)	Loss 6.3145e-02 (1.4173e-01) 
2023-05-27 13:04:24.493747: val Epoch: [30][53/72]	Time  0.913 ( 2.556)	Data  0.802 ( 2.442)	Loss 4.9156e-01 (1.4821e-01) 
2023-05-27 13:04:28.916182: val Epoch: [30][54/72]	Time  4.422 ( 2.590)	Data  4.307 ( 2.476)	Loss 7.5165e-02 (1.4688e-01) 
2023-05-27 13:04:29.697451: val Epoch: [30][55/72]	Time  0.781 ( 2.558)	Data  0.676 ( 2.443)	Loss 1.7747e-01 (1.4743e-01) 
2023-05-27 13:04:33.914864: val Epoch: [30][56/72]	Time  4.217 ( 2.587)	Data  4.112 ( 2.473)	Loss 5.0235e-02 (1.4572e-01) 
2023-05-27 13:04:34.875049: val Epoch: [30][57/72]	Time  0.960 ( 2.559)	Data  0.855 ( 2.445)	Loss 5.6787e-01 (1.5300e-01) 
2023-05-27 13:04:38.800462: val Epoch: [30][58/72]	Time  3.925 ( 2.582)	Data  3.817 ( 2.468)	Loss 4.9314e-02 (1.5124e-01) 
2023-05-27 13:04:39.835233: val Epoch: [30][59/72]	Time  1.035 ( 2.556)	Data  0.927 ( 2.442)	Loss 6.2176e-02 (1.4976e-01) 
2023-05-27 13:04:43.977513: val Epoch: [30][60/72]	Time  4.142 ( 2.582)	Data  4.034 ( 2.468)	Loss 7.6827e-02 (1.4856e-01) 
2023-05-27 13:04:44.706913: val Epoch: [30][61/72]	Time  0.729 ( 2.552)	Data  0.621 ( 2.439)	Loss 4.4630e-02 (1.4689e-01) 
2023-05-27 13:04:49.093560: val Epoch: [30][62/72]	Time  4.387 ( 2.581)	Data  4.269 ( 2.468)	Loss 4.0900e-01 (1.5105e-01) 
2023-05-27 13:04:49.796831: val Epoch: [30][63/72]	Time  0.703 ( 2.552)	Data  0.587 ( 2.438)	Loss 5.3046e-02 (1.4952e-01) 
2023-05-27 13:04:54.308620: val Epoch: [30][64/72]	Time  4.512 ( 2.582)	Data  4.403 ( 2.469)	Loss 1.8839e-01 (1.5011e-01) 
2023-05-27 13:04:54.928353: val Epoch: [30][65/72]	Time  0.620 ( 2.553)	Data  0.505 ( 2.439)	Loss 9.9331e-02 (1.4935e-01) 
2023-05-27 13:04:59.176579: val Epoch: [30][66/72]	Time  4.248 ( 2.578)	Data  4.135 ( 2.464)	Loss 9.2202e-02 (1.4849e-01) 
2023-05-27 13:04:59.879472: val Epoch: [30][67/72]	Time  0.703 ( 2.550)	Data  0.587 ( 2.437)	Loss 6.9499e-02 (1.4733e-01) 
2023-05-27 13:05:04.181070: val Epoch: [30][68/72]	Time  4.302 ( 2.576)	Data  4.196 ( 2.462)	Loss 1.9506e-01 (1.4802e-01) 
2023-05-27 13:05:05.112000: val Epoch: [30][69/72]	Time  0.931 ( 2.552)	Data  0.817 ( 2.439)	Loss 7.2419e-02 (1.4694e-01) 
2023-05-27 13:05:09.055947: val Epoch: [30][70/72]	Time  3.944 ( 2.572)	Data  3.839 ( 2.458)	Loss 8.6843e-02 (1.4610e-01) 
2023-05-27 13:05:10.021704: val Epoch: [30][71/72]	Time  0.966 ( 2.549)	Data  0.861 ( 2.436)	Loss 1.2522e-01 (1.4581e-01) 
2023-05-27 13:05:10.362674: Epoch 30 :Val : ['ET : 0.7145190238952637', 'TC : 0.75244140625', 'WT : 0.8536781668663025'] 
2023-05-27 13:05:10.363721: Epoch 30 :Val : ['ET : 0.7145190238952637', 'TC : 0.75244140625', 'WT : 0.8536781668663025'] 
2023-05-27 13:05:10.367063: Val epoch done in 184.76180313600344 s 
2023-05-27 13:05:10.372946: Batches per epoch:  193 
2023-05-27 13:05:22.309518: train Epoch: [31][  0/193]	Time 11.936 (11.936)	Data 11.327 (11.327)	Loss 1.2906e-01 (1.2906e-01) 
2023-05-27 13:05:22.877766: train Epoch: [31][  1/193]	Time  0.568 ( 6.252)	Data  0.001 ( 5.664)	Loss 7.3495e-02 (1.0128e-01) 
2023-05-27 13:05:32.079558: train Epoch: [31][  2/193]	Time  9.202 ( 7.235)	Data  8.634 ( 6.654)	Loss 7.7752e-02 (9.3435e-02) 
2023-05-27 13:05:32.651632: train Epoch: [31][  3/193]	Time  0.572 ( 5.570)	Data  0.001 ( 4.991)	Loss 5.5277e-02 (8.3895e-02) 
2023-05-27 13:05:42.314922: train Epoch: [31][  4/193]	Time  9.663 ( 6.388)	Data  9.098 ( 5.812)	Loss 9.8599e-02 (8.6836e-02) 
2023-05-27 13:05:42.892207: train Epoch: [31][  5/193]	Time  0.577 ( 5.420)	Data  0.001 ( 4.844)	Loss 8.8873e-02 (8.7176e-02) 
2023-05-27 13:05:51.630543: train Epoch: [31][  6/193]	Time  8.738 ( 5.894)	Data  8.168 ( 5.319)	Loss 8.8317e-02 (8.7339e-02) 
2023-05-27 13:05:52.198486: train Epoch: [31][  7/193]	Time  0.568 ( 5.228)	Data  0.001 ( 4.654)	Loss 1.2026e-01 (9.1453e-02) 
2023-05-27 13:06:00.273371: train Epoch: [31][  8/193]	Time  8.075 ( 5.544)	Data  7.514 ( 4.972)	Loss 5.8295e-02 (8.7769e-02) 
2023-05-27 13:06:00.836459: train Epoch: [31][  9/193]	Time  0.563 ( 5.046)	Data  0.001 ( 4.475)	Loss 5.3706e-02 (8.4363e-02) 
2023-05-27 13:06:10.429264: train Epoch: [31][ 10/193]	Time  9.593 ( 5.460)	Data  9.031 ( 4.889)	Loss 1.1271e-01 (8.6940e-02) 
2023-05-27 13:06:10.992375: train Epoch: [31][ 11/193]	Time  0.563 ( 5.052)	Data  0.001 ( 4.481)	Loss 8.5885e-02 (8.6852e-02) 
2023-05-27 13:06:20.347951: train Epoch: [31][ 12/193]	Time  9.356 ( 5.383)	Data  8.789 ( 4.813)	Loss 9.1474e-02 (8.7208e-02) 
2023-05-27 13:06:20.916814: train Epoch: [31][ 13/193]	Time  0.569 ( 5.039)	Data  0.001 ( 4.469)	Loss 3.7092e-02 (8.3628e-02) 
2023-05-27 13:06:29.888461: train Epoch: [31][ 14/193]	Time  8.972 ( 5.301)	Data  8.405 ( 4.732)	Loss 8.7938e-02 (8.3915e-02) 
2023-05-27 13:06:30.456473: train Epoch: [31][ 15/193]	Time  0.568 ( 5.005)	Data  0.001 ( 4.436)	Loss 9.9581e-02 (8.4895e-02) 
2023-05-27 13:06:40.279555: train Epoch: [31][ 16/193]	Time  9.823 ( 5.289)	Data  9.250 ( 4.719)	Loss 7.2911e-02 (8.4190e-02) 
2023-05-27 13:06:40.845855: train Epoch: [31][ 17/193]	Time  0.566 ( 5.026)	Data  0.001 ( 4.457)	Loss 1.0745e-01 (8.5482e-02) 
2023-05-27 13:06:50.217730: train Epoch: [31][ 18/193]	Time  9.372 ( 5.255)	Data  8.805 ( 4.686)	Loss 5.2802e-02 (8.3762e-02) 
2023-05-27 13:06:50.786265: train Epoch: [31][ 19/193]	Time  0.569 ( 5.021)	Data  0.001 ( 4.452)	Loss 8.2562e-02 (8.3702e-02) 
2023-05-27 13:07:00.510058: train Epoch: [31][ 20/193]	Time  9.724 ( 5.245)	Data  9.157 ( 4.676)	Loss 8.6784e-02 (8.3848e-02) 
2023-05-27 13:07:01.077686: train Epoch: [31][ 21/193]	Time  0.568 ( 5.032)	Data  0.001 ( 4.463)	Loss 7.6675e-02 (8.3522e-02) 
2023-05-27 13:07:10.256400: train Epoch: [31][ 22/193]	Time  9.179 ( 5.212)	Data  8.611 ( 4.643)	Loss 1.2116e-01 (8.5159e-02) 
2023-05-27 13:07:10.818560: train Epoch: [31][ 23/193]	Time  0.562 ( 5.019)	Data  0.001 ( 4.450)	Loss 7.7638e-02 (8.4846e-02) 
2023-05-27 13:07:20.376384: train Epoch: [31][ 24/193]	Time  9.558 ( 5.200)	Data  8.990 ( 4.632)	Loss 1.1657e-01 (8.6115e-02) 
2023-05-27 13:07:20.940978: train Epoch: [31][ 25/193]	Time  0.565 ( 5.022)	Data  0.001 ( 4.453)	Loss 1.3666e-01 (8.8059e-02) 
2023-05-27 13:07:29.290507: train Epoch: [31][ 26/193]	Time  8.350 ( 5.145)	Data  7.788 ( 4.577)	Loss 6.9664e-02 (8.7378e-02) 
2023-05-27 13:07:29.852837: train Epoch: [31][ 27/193]	Time  0.562 ( 4.981)	Data  0.001 ( 4.414)	Loss 4.9682e-02 (8.6031e-02) 
2023-05-27 13:07:37.991464: train Epoch: [31][ 28/193]	Time  8.139 ( 5.090)	Data  7.576 ( 4.523)	Loss 1.0556e-01 (8.6705e-02) 
2023-05-27 13:07:38.554095: train Epoch: [31][ 29/193]	Time  0.563 ( 4.939)	Data  0.001 ( 4.372)	Loss 2.0303e-01 (9.0582e-02) 
2023-05-27 13:07:48.220037: train Epoch: [31][ 30/193]	Time  9.666 ( 5.092)	Data  9.105 ( 4.525)	Loss 1.4816e-01 (9.2439e-02) 
2023-05-27 13:07:48.785245: train Epoch: [31][ 31/193]	Time  0.565 ( 4.950)	Data  0.001 ( 4.383)	Loss 9.7643e-02 (9.2602e-02) 
2023-05-27 13:07:58.121991: train Epoch: [31][ 32/193]	Time  9.337 ( 5.083)	Data  8.776 ( 4.516)	Loss 1.6200e-01 (9.4705e-02) 
2023-05-27 13:07:58.685938: train Epoch: [31][ 33/193]	Time  0.564 ( 4.950)	Data  0.001 ( 4.383)	Loss 7.3668e-02 (9.4086e-02) 
2023-05-27 13:08:08.077692: train Epoch: [31][ 34/193]	Time  9.392 ( 5.077)	Data  8.823 ( 4.510)	Loss 1.2781e-01 (9.5050e-02) 
2023-05-27 13:08:08.643813: train Epoch: [31][ 35/193]	Time  0.566 ( 4.952)	Data  0.001 ( 4.385)	Loss 1.3492e-01 (9.6157e-02) 
2023-05-27 13:08:18.094546: train Epoch: [31][ 36/193]	Time  9.451 ( 5.074)	Data  8.888 ( 4.507)	Loss 1.2871e-01 (9.7037e-02) 
2023-05-27 13:08:18.656892: train Epoch: [31][ 37/193]	Time  0.562 ( 4.955)	Data  0.001 ( 4.388)	Loss 9.0940e-02 (9.6877e-02) 
2023-05-27 13:08:27.921837: train Epoch: [31][ 38/193]	Time  9.265 ( 5.065)	Data  8.698 ( 4.499)	Loss 7.0894e-02 (9.6211e-02) 
2023-05-27 13:08:28.486840: train Epoch: [31][ 39/193]	Time  0.565 ( 4.953)	Data  0.001 ( 4.386)	Loss 9.6992e-02 (9.6230e-02) 
2023-05-27 13:08:37.675556: train Epoch: [31][ 40/193]	Time  9.189 ( 5.056)	Data  8.627 ( 4.490)	Loss 1.1327e-01 (9.6646e-02) 
2023-05-27 13:08:38.245869: train Epoch: [31][ 41/193]	Time  0.570 ( 4.949)	Data  0.009 ( 4.383)	Loss 7.7774e-02 (9.6196e-02) 
2023-05-27 13:08:47.796031: train Epoch: [31][ 42/193]	Time  9.550 ( 5.056)	Data  8.990 ( 4.490)	Loss 1.1829e-01 (9.6710e-02) 
2023-05-27 13:08:48.357834: train Epoch: [31][ 43/193]	Time  0.562 ( 4.954)	Data  0.001 ( 4.388)	Loss 1.2027e-01 (9.7246e-02) 
2023-05-27 13:08:57.345026: train Epoch: [31][ 44/193]	Time  8.987 ( 5.044)	Data  8.416 ( 4.478)	Loss 7.1635e-02 (9.6677e-02) 
2023-05-27 13:08:57.974359: train Epoch: [31][ 45/193]	Time  0.629 ( 4.948)	Data  0.055 ( 4.381)	Loss 2.0007e-01 (9.8924e-02) 
2023-05-27 13:09:08.153452: train Epoch: [31][ 46/193]	Time 10.179 ( 5.059)	Data  9.591 ( 4.492)	Loss 5.9451e-02 (9.8084e-02) 
2023-05-27 13:09:08.718099: train Epoch: [31][ 47/193]	Time  0.565 ( 4.966)	Data  0.001 ( 4.399)	Loss 9.9548e-02 (9.8115e-02) 
2023-05-27 13:09:18.027034: train Epoch: [31][ 48/193]	Time  9.309 ( 5.054)	Data  8.745 ( 4.487)	Loss 8.6818e-02 (9.7884e-02) 
2023-05-27 13:09:18.617524: train Epoch: [31][ 49/193]	Time  0.590 ( 4.965)	Data  0.001 ( 4.398)	Loss 7.0468e-02 (9.7336e-02) 
2023-05-27 13:09:27.799347: train Epoch: [31][ 50/193]	Time  9.182 ( 5.048)	Data  8.619 ( 4.480)	Loss 4.9481e-02 (9.6398e-02) 
2023-05-27 13:09:28.384684: train Epoch: [31][ 51/193]	Time  0.585 ( 4.962)	Data  0.001 ( 4.394)	Loss 8.0459e-02 (9.6091e-02) 
2023-05-27 13:09:37.424674: train Epoch: [31][ 52/193]	Time  9.040 ( 5.039)	Data  8.464 ( 4.471)	Loss 6.2342e-02 (9.5454e-02) 
2023-05-27 13:09:37.986449: train Epoch: [31][ 53/193]	Time  0.562 ( 4.956)	Data  0.001 ( 4.388)	Loss 1.6125e-01 (9.6673e-02) 
2023-05-27 13:09:47.192353: train Epoch: [31][ 54/193]	Time  9.206 ( 5.033)	Data  8.637 ( 4.466)	Loss 6.5997e-02 (9.6115e-02) 
2023-05-27 13:09:47.764131: train Epoch: [31][ 55/193]	Time  0.572 ( 4.953)	Data  0.001 ( 4.386)	Loss 8.6298e-02 (9.5940e-02) 
2023-05-27 13:09:57.457179: train Epoch: [31][ 56/193]	Time  9.693 ( 5.037)	Data  9.121 ( 4.469)	Loss 9.1965e-02 (9.5870e-02) 
2023-05-27 13:09:58.032946: train Epoch: [31][ 57/193]	Time  0.576 ( 4.960)	Data  0.001 ( 4.392)	Loss 1.2847e-01 (9.6432e-02) 
2023-05-27 13:10:07.611372: train Epoch: [31][ 58/193]	Time  9.578 ( 5.038)	Data  9.017 ( 4.470)	Loss 1.2970e-01 (9.6996e-02) 
2023-05-27 13:10:08.174623: train Epoch: [31][ 59/193]	Time  0.563 ( 4.963)	Data  0.001 ( 4.396)	Loss 7.7714e-02 (9.6675e-02) 
2023-05-27 13:10:17.969670: train Epoch: [31][ 60/193]	Time  9.795 ( 5.043)	Data  9.228 ( 4.475)	Loss 8.4559e-02 (9.6476e-02) 
2023-05-27 13:10:18.536938: train Epoch: [31][ 61/193]	Time  0.567 ( 4.970)	Data  0.001 ( 4.403)	Loss 1.2996e-01 (9.7016e-02) 
2023-05-27 13:10:27.788365: train Epoch: [31][ 62/193]	Time  9.251 ( 5.038)	Data  8.679 ( 4.471)	Loss 1.2149e-01 (9.7405e-02) 
2023-05-27 13:10:28.359347: train Epoch: [31][ 63/193]	Time  0.571 ( 4.969)	Data  0.001 ( 4.401)	Loss 7.7016e-02 (9.7086e-02) 
2023-05-27 13:10:37.751198: train Epoch: [31][ 64/193]	Time  9.392 ( 5.037)	Data  8.824 ( 4.469)	Loss 8.7108e-02 (9.6933e-02) 
2023-05-27 13:10:38.319746: train Epoch: [31][ 65/193]	Time  0.569 ( 4.969)	Data  0.001 ( 4.401)	Loss 5.2328e-02 (9.6257e-02) 
2023-05-27 13:10:47.739439: train Epoch: [31][ 66/193]	Time  9.420 ( 5.035)	Data  8.854 ( 4.468)	Loss 1.5768e-01 (9.7173e-02) 
2023-05-27 13:10:48.305939: train Epoch: [31][ 67/193]	Time  0.566 ( 4.970)	Data  0.001 ( 4.402)	Loss 8.4454e-02 (9.6986e-02) 
2023-05-27 13:10:57.514494: train Epoch: [31][ 68/193]	Time  9.209 ( 5.031)	Data  8.645 ( 4.463)	Loss 1.0545e-01 (9.7109e-02) 
2023-05-27 13:10:58.085556: train Epoch: [31][ 69/193]	Time  0.571 ( 4.967)	Data  0.001 ( 4.400)	Loss 6.9311e-02 (9.6712e-02) 
2023-05-27 13:11:07.287860: train Epoch: [31][ 70/193]	Time  9.202 ( 5.027)	Data  8.630 ( 4.459)	Loss 5.9187e-02 (9.6183e-02) 
2023-05-27 13:11:07.856694: train Epoch: [31][ 71/193]	Time  0.569 ( 4.965)	Data  0.001 ( 4.397)	Loss 8.0881e-02 (9.5971e-02) 
2023-05-27 13:11:17.092023: train Epoch: [31][ 72/193]	Time  9.235 ( 5.024)	Data  8.674 ( 4.456)	Loss 6.6501e-02 (9.5567e-02) 
2023-05-27 13:11:17.654527: train Epoch: [31][ 73/193]	Time  0.563 ( 4.963)	Data  0.001 ( 4.396)	Loss 1.3377e-01 (9.6083e-02) 
2023-05-27 13:11:26.831717: train Epoch: [31][ 74/193]	Time  9.177 ( 5.019)	Data  8.615 ( 4.452)	Loss 1.3263e-01 (9.6571e-02) 
2023-05-27 13:11:27.394605: train Epoch: [31][ 75/193]	Time  0.563 ( 4.961)	Data  0.001 ( 4.393)	Loss 2.5478e-01 (9.8652e-02) 
2023-05-27 13:11:36.640326: train Epoch: [31][ 76/193]	Time  9.246 ( 5.016)	Data  8.685 ( 4.449)	Loss 7.0991e-02 (9.8293e-02) 
2023-05-27 13:11:37.390028: train Epoch: [31][ 77/193]	Time  0.750 ( 4.962)	Data  0.188 ( 4.395)	Loss 6.5307e-02 (9.7870e-02) 
2023-05-27 13:11:46.181991: train Epoch: [31][ 78/193]	Time  8.792 ( 5.010)	Data  8.230 ( 4.443)	Loss 6.4393e-02 (9.7447e-02) 
2023-05-27 13:11:47.482123: train Epoch: [31][ 79/193]	Time  1.300 ( 4.964)	Data  0.738 ( 4.397)	Loss 1.0396e-01 (9.7528e-02) 
2023-05-27 13:11:56.204409: train Epoch: [31][ 80/193]	Time  8.722 ( 5.010)	Data  8.130 ( 4.443)	Loss 5.0280e-02 (9.6945e-02) 
2023-05-27 13:11:57.095784: train Epoch: [31][ 81/193]	Time  0.891 ( 4.960)	Data  0.331 ( 4.393)	Loss 8.6776e-02 (9.6821e-02) 
2023-05-27 13:12:06.139591: train Epoch: [31][ 82/193]	Time  9.044 ( 5.009)	Data  8.473 ( 4.442)	Loss 6.5466e-02 (9.6443e-02) 
2023-05-27 13:12:06.980024: train Epoch: [31][ 83/193]	Time  0.840 ( 4.960)	Data  0.274 ( 4.392)	Loss 5.0817e-02 (9.5900e-02) 
2023-05-27 13:12:16.068628: train Epoch: [31][ 84/193]	Time  9.089 ( 5.008)	Data  8.515 ( 4.441)	Loss 6.4231e-02 (9.5527e-02) 
2023-05-27 13:12:16.874436: train Epoch: [31][ 85/193]	Time  0.806 ( 4.959)	Data  0.239 ( 4.392)	Loss 1.1736e-01 (9.5781e-02) 
2023-05-27 13:12:26.462513: train Epoch: [31][ 86/193]	Time  9.588 ( 5.013)	Data  9.018 ( 4.445)	Loss 1.4436e-01 (9.6339e-02) 
2023-05-27 13:12:27.028105: train Epoch: [31][ 87/193]	Time  0.566 ( 4.962)	Data  0.001 ( 4.395)	Loss 8.6016e-02 (9.6222e-02) 
2023-05-27 13:12:35.371664: train Epoch: [31][ 88/193]	Time  8.344 ( 5.000)	Data  7.777 ( 4.433)	Loss 1.1624e-01 (9.6447e-02) 
2023-05-27 13:12:35.958088: train Epoch: [31][ 89/193]	Time  0.586 ( 4.951)	Data  0.001 ( 4.383)	Loss 8.5385e-02 (9.6324e-02) 
2023-05-27 13:12:44.096408: train Epoch: [31][ 90/193]	Time  8.138 ( 4.986)	Data  7.569 ( 4.418)	Loss 1.2962e-01 (9.6690e-02) 
2023-05-27 13:12:44.671709: train Epoch: [31][ 91/193]	Time  0.575 ( 4.938)	Data  0.001 ( 4.370)	Loss 4.6009e-02 (9.6139e-02) 
2023-05-27 13:12:54.031436: train Epoch: [31][ 92/193]	Time  9.360 ( 4.986)	Data  8.787 ( 4.418)	Loss 6.1050e-02 (9.5762e-02) 
2023-05-27 13:12:54.603328: train Epoch: [31][ 93/193]	Time  0.572 ( 4.939)	Data  0.001 ( 4.371)	Loss 1.0320e-01 (9.5841e-02) 
2023-05-27 13:13:03.942547: train Epoch: [31][ 94/193]	Time  9.339 ( 4.985)	Data  8.768 ( 4.417)	Loss 7.8467e-02 (9.5658e-02) 
2023-05-27 13:13:04.518445: train Epoch: [31][ 95/193]	Time  0.576 ( 4.939)	Data  0.001 ( 4.371)	Loss 1.1701e-01 (9.5880e-02) 
2023-05-27 13:13:13.891698: train Epoch: [31][ 96/193]	Time  9.373 ( 4.985)	Data  8.799 ( 4.417)	Loss 1.6412e-01 (9.6584e-02) 
2023-05-27 13:13:14.480584: train Epoch: [31][ 97/193]	Time  0.589 ( 4.940)	Data  0.001 ( 4.372)	Loss 1.0464e-01 (9.6666e-02) 
2023-05-27 13:13:23.913425: train Epoch: [31][ 98/193]	Time  9.433 ( 4.985)	Data  8.869 ( 4.417)	Loss 9.6754e-02 (9.6667e-02) 
2023-05-27 13:13:24.484884: train Epoch: [31][ 99/193]	Time  0.571 ( 4.941)	Data  0.001 ( 4.373)	Loss 5.7395e-02 (9.6274e-02) 
2023-05-27 13:13:33.750032: train Epoch: [31][100/193]	Time  9.265 ( 4.984)	Data  8.690 ( 4.416)	Loss 2.8053e-01 (9.8099e-02) 
2023-05-27 13:13:34.328446: train Epoch: [31][101/193]	Time  0.578 ( 4.941)	Data  0.001 ( 4.372)	Loss 7.3821e-02 (9.7861e-02) 
2023-05-27 13:13:43.478300: train Epoch: [31][102/193]	Time  9.150 ( 4.982)	Data  8.589 ( 4.413)	Loss 1.1359e-01 (9.8013e-02) 
2023-05-27 13:13:44.202112: train Epoch: [31][103/193]	Time  0.724 ( 4.941)	Data  0.147 ( 4.372)	Loss 7.3923e-02 (9.7782e-02) 
2023-05-27 13:13:53.735764: train Epoch: [31][104/193]	Time  9.534 ( 4.984)	Data  8.965 ( 4.416)	Loss 1.2683e-01 (9.8058e-02) 
2023-05-27 13:13:54.303642: train Epoch: [31][105/193]	Time  0.568 ( 4.943)	Data  0.001 ( 4.374)	Loss 6.0557e-02 (9.7705e-02) 
2023-05-27 13:14:03.866339: train Epoch: [31][106/193]	Time  9.563 ( 4.986)	Data  9.000 ( 4.418)	Loss 7.4278e-02 (9.7486e-02) 
2023-05-27 13:14:04.457642: train Epoch: [31][107/193]	Time  0.591 ( 4.945)	Data  0.029 ( 4.377)	Loss 8.5898e-02 (9.7378e-02) 
2023-05-27 13:14:13.733303: train Epoch: [31][108/193]	Time  9.276 ( 4.985)	Data  8.702 ( 4.417)	Loss 1.1167e-01 (9.7509e-02) 
2023-05-27 13:14:14.591438: train Epoch: [31][109/193]	Time  0.858 ( 4.947)	Data  0.292 ( 4.379)	Loss 3.5681e-02 (9.6947e-02) 
2023-05-27 13:14:24.542540: train Epoch: [31][110/193]	Time  9.951 ( 4.993)	Data  9.380 ( 4.424)	Loss 6.6817e-02 (9.6676e-02) 
2023-05-27 13:14:25.120116: train Epoch: [31][111/193]	Time  0.578 ( 4.953)	Data  0.001 ( 4.385)	Loss 9.9653e-02 (9.6703e-02) 
2023-05-27 13:14:34.874894: train Epoch: [31][112/193]	Time  9.755 ( 4.996)	Data  9.192 ( 4.427)	Loss 1.2637e-01 (9.6965e-02) 
2023-05-27 13:14:35.506978: train Epoch: [31][113/193]	Time  0.632 ( 4.957)	Data  0.060 ( 4.389)	Loss 1.0344e-01 (9.7022e-02) 
2023-05-27 13:14:44.984206: train Epoch: [31][114/193]	Time  9.477 ( 4.997)	Data  8.911 ( 4.428)	Loss 8.1803e-02 (9.6890e-02) 
2023-05-27 13:14:45.601069: train Epoch: [31][115/193]	Time  0.617 ( 4.959)	Data  0.001 ( 4.390)	Loss 4.4886e-02 (9.6441e-02) 
2023-05-27 13:14:55.127759: train Epoch: [31][116/193]	Time  9.527 ( 4.998)	Data  8.950 ( 4.429)	Loss 2.3860e-01 (9.7656e-02) 
2023-05-27 13:14:55.712947: train Epoch: [31][117/193]	Time  0.585 ( 4.961)	Data  0.001 ( 4.392)	Loss 1.8350e-01 (9.8384e-02) 
2023-05-27 13:15:05.138876: train Epoch: [31][118/193]	Time  9.426 ( 4.998)	Data  8.862 ( 4.429)	Loss 6.7606e-02 (9.8125e-02) 
2023-05-27 13:15:05.714892: train Epoch: [31][119/193]	Time  0.576 ( 4.961)	Data  0.001 ( 4.392)	Loss 1.2982e-01 (9.8389e-02) 
2023-05-27 13:15:15.270709: train Epoch: [31][120/193]	Time  9.556 ( 4.999)	Data  8.990 ( 4.430)	Loss 1.1224e-01 (9.8504e-02) 
2023-05-27 13:15:15.871892: train Epoch: [31][121/193]	Time  0.601 ( 4.963)	Data  0.001 ( 4.394)	Loss 9.4854e-02 (9.8474e-02) 
2023-05-27 13:15:25.119030: train Epoch: [31][122/193]	Time  9.247 ( 4.998)	Data  8.686 ( 4.429)	Loss 8.0845e-02 (9.8330e-02) 
2023-05-27 13:15:25.684378: train Epoch: [31][123/193]	Time  0.565 ( 4.962)	Data  0.001 ( 4.393)	Loss 9.5809e-02 (9.8310e-02) 
2023-05-27 13:15:35.094398: train Epoch: [31][124/193]	Time  9.410 ( 4.998)	Data  8.847 ( 4.429)	Loss 5.0514e-02 (9.7928e-02) 
2023-05-27 13:15:35.669338: train Epoch: [31][125/193]	Time  0.575 ( 4.963)	Data  0.001 ( 4.394)	Loss 6.6236e-02 (9.7676e-02) 
2023-05-27 13:15:44.943631: train Epoch: [31][126/193]	Time  9.274 ( 4.997)	Data  8.701 ( 4.428)	Loss 1.1018e-01 (9.7775e-02) 
2023-05-27 13:15:45.654273: train Epoch: [31][127/193]	Time  0.711 ( 4.963)	Data  0.129 ( 4.394)	Loss 9.0324e-02 (9.7716e-02) 
2023-05-27 13:15:54.789338: train Epoch: [31][128/193]	Time  9.135 ( 4.995)	Data  8.560 ( 4.426)	Loss 1.2741e-01 (9.7947e-02) 
2023-05-27 13:15:55.380663: train Epoch: [31][129/193]	Time  0.591 ( 4.962)	Data  0.001 ( 4.392)	Loss 7.8377e-02 (9.7796e-02) 
2023-05-27 13:16:04.217741: train Epoch: [31][130/193]	Time  8.837 ( 4.991)	Data  8.271 ( 4.422)	Loss 1.0119e-01 (9.7822e-02) 
2023-05-27 13:16:05.012037: train Epoch: [31][131/193]	Time  0.794 ( 4.959)	Data  0.228 ( 4.390)	Loss 7.4892e-02 (9.7648e-02) 
2023-05-27 13:16:14.323203: train Epoch: [31][132/193]	Time  9.311 ( 4.992)	Data  8.742 ( 4.423)	Loss 1.2398e-01 (9.7846e-02) 
2023-05-27 13:16:15.810026: train Epoch: [31][133/193]	Time  1.487 ( 4.966)	Data  0.911 ( 4.397)	Loss 2.6141e-01 (9.9067e-02) 
2023-05-27 13:16:24.732731: train Epoch: [31][134/193]	Time  8.923 ( 4.995)	Data  8.345 ( 4.426)	Loss 1.0870e-01 (9.9138e-02) 
2023-05-27 13:16:25.802574: train Epoch: [31][135/193]	Time  1.070 ( 4.966)	Data  0.500 ( 4.397)	Loss 6.0343e-02 (9.8853e-02) 
2023-05-27 13:16:34.662824: train Epoch: [31][136/193]	Time  8.860 ( 4.995)	Data  8.280 ( 4.425)	Loss 8.6702e-02 (9.8764e-02) 
2023-05-27 13:16:35.574827: train Epoch: [31][137/193]	Time  0.912 ( 4.965)	Data  0.344 ( 4.396)	Loss 9.8413e-02 (9.8762e-02) 
2023-05-27 13:16:44.741739: train Epoch: [31][138/193]	Time  9.167 ( 4.995)	Data  8.605 ( 4.426)	Loss 8.0456e-02 (9.8630e-02) 
2023-05-27 13:16:45.367601: train Epoch: [31][139/193]	Time  0.626 ( 4.964)	Data  0.051 ( 4.395)	Loss 9.8035e-02 (9.8626e-02) 
2023-05-27 13:16:55.072180: train Epoch: [31][140/193]	Time  9.705 ( 4.998)	Data  9.132 ( 4.428)	Loss 2.4569e-01 (9.9669e-02) 
2023-05-27 13:16:55.647506: train Epoch: [31][141/193]	Time  0.575 ( 4.967)	Data  0.001 ( 4.397)	Loss 5.7830e-02 (9.9374e-02) 
2023-05-27 13:17:05.410372: train Epoch: [31][142/193]	Time  9.763 ( 5.000)	Data  9.192 ( 4.431)	Loss 4.3612e-02 (9.8984e-02) 
2023-05-27 13:17:05.997501: train Epoch: [31][143/193]	Time  0.587 ( 4.970)	Data  0.001 ( 4.400)	Loss 1.1191e-01 (9.9074e-02) 
2023-05-27 13:17:15.259626: train Epoch: [31][144/193]	Time  9.262 ( 4.999)	Data  8.694 ( 4.430)	Loss 2.0538e-01 (9.9807e-02) 
2023-05-27 13:17:15.829751: train Epoch: [31][145/193]	Time  0.570 ( 4.969)	Data  0.001 ( 4.399)	Loss 1.1952e-01 (9.9942e-02) 
2023-05-27 13:17:25.557322: train Epoch: [31][146/193]	Time  9.728 ( 5.001)	Data  9.157 ( 4.432)	Loss 6.6248e-02 (9.9713e-02) 
2023-05-27 13:17:26.130823: train Epoch: [31][147/193]	Time  0.574 ( 4.971)	Data  0.001 ( 4.402)	Loss 2.1912e-01 (1.0052e-01) 
2023-05-27 13:17:35.615533: train Epoch: [31][148/193]	Time  9.485 ( 5.002)	Data  8.910 ( 4.432)	Loss 8.8678e-02 (1.0044e-01) 
2023-05-27 13:17:36.194586: train Epoch: [31][149/193]	Time  0.579 ( 4.972)	Data  0.001 ( 4.402)	Loss 1.4419e-01 (1.0073e-01) 
2023-05-27 13:17:46.004094: train Epoch: [31][150/193]	Time  9.809 ( 5.004)	Data  9.241 ( 4.434)	Loss 5.9286e-02 (1.0046e-01) 
2023-05-27 13:17:46.579834: train Epoch: [31][151/193]	Time  0.576 ( 4.975)	Data  0.001 ( 4.405)	Loss 1.1772e-01 (1.0057e-01) 
2023-05-27 13:17:56.123862: train Epoch: [31][152/193]	Time  9.544 ( 5.005)	Data  8.967 ( 4.435)	Loss 9.1358e-02 (1.0051e-01) 
2023-05-27 13:17:56.693720: train Epoch: [31][153/193]	Time  0.570 ( 4.976)	Data  0.001 ( 4.406)	Loss 2.2454e-01 (1.0132e-01) 
2023-05-27 13:18:06.499067: train Epoch: [31][154/193]	Time  9.805 ( 5.007)	Data  9.222 ( 4.437)	Loss 1.1894e-01 (1.0143e-01) 
2023-05-27 13:18:07.140050: train Epoch: [31][155/193]	Time  0.641 ( 4.979)	Data  0.002 ( 4.409)	Loss 7.1827e-02 (1.0124e-01) 
2023-05-27 13:18:16.642728: train Epoch: [31][156/193]	Time  9.503 ( 5.008)	Data  8.934 ( 4.438)	Loss 4.4504e-02 (1.0088e-01) 
2023-05-27 13:18:17.216821: train Epoch: [31][157/193]	Time  0.574 ( 4.980)	Data  0.002 ( 4.410)	Loss 9.1903e-02 (1.0082e-01) 
2023-05-27 13:18:26.628159: train Epoch: [31][158/193]	Time  9.411 ( 5.008)	Data  8.843 ( 4.438)	Loss 1.0205e-01 (1.0083e-01) 
2023-05-27 13:18:27.214662: train Epoch: [31][159/193]	Time  0.587 ( 4.980)	Data  0.001 ( 4.410)	Loss 8.4009e-02 (1.0072e-01) 
2023-05-27 13:18:36.808233: train Epoch: [31][160/193]	Time  9.594 ( 5.009)	Data  9.025 ( 4.439)	Loss 7.2358e-02 (1.0055e-01) 
2023-05-27 13:18:37.380657: train Epoch: [31][161/193]	Time  0.572 ( 4.982)	Data  0.001 ( 4.411)	Loss 1.5334e-01 (1.0087e-01) 
2023-05-27 13:18:46.988912: train Epoch: [31][162/193]	Time  9.608 ( 5.010)	Data  9.017 ( 4.439)	Loss 1.2733e-01 (1.0104e-01) 
2023-05-27 13:18:47.560776: train Epoch: [31][163/193]	Time  0.572 ( 4.983)	Data  0.001 ( 4.412)	Loss 1.0053e-01 (1.0103e-01) 
2023-05-27 13:18:57.159648: train Epoch: [31][164/193]	Time  9.599 ( 5.011)	Data  9.028 ( 4.440)	Loss 1.3628e-01 (1.0125e-01) 
2023-05-27 13:18:57.725670: train Epoch: [31][165/193]	Time  0.566 ( 4.984)	Data  0.001 ( 4.414)	Loss 9.0360e-02 (1.0118e-01) 
2023-05-27 13:19:07.058478: train Epoch: [31][166/193]	Time  9.333 ( 5.010)	Data  8.743 ( 4.439)	Loss 6.5241e-02 (1.0097e-01) 
2023-05-27 13:19:07.619370: train Epoch: [31][167/193]	Time  0.561 ( 4.984)	Data  0.001 ( 4.413)	Loss 7.5983e-02 (1.0082e-01) 
2023-05-27 13:19:16.920366: train Epoch: [31][168/193]	Time  9.301 ( 5.009)	Data  8.730 ( 4.439)	Loss 7.9700e-02 (1.0069e-01) 
2023-05-27 13:19:17.500327: train Epoch: [31][169/193]	Time  0.580 ( 4.983)	Data  0.001 ( 4.412)	Loss 2.0464e-01 (1.0130e-01) 
2023-05-27 13:19:26.873720: train Epoch: [31][170/193]	Time  9.373 ( 5.009)	Data  8.755 ( 4.438)	Loss 5.8942e-02 (1.0106e-01) 
2023-05-27 13:19:27.435026: train Epoch: [31][171/193]	Time  0.561 ( 4.983)	Data  0.001 ( 4.412)	Loss 1.0829e-01 (1.0110e-01) 
2023-05-27 13:19:36.659331: train Epoch: [31][172/193]	Time  9.224 ( 5.007)	Data  8.643 ( 4.437)	Loss 8.2388e-02 (1.0099e-01) 
2023-05-27 13:19:37.246688: train Epoch: [31][173/193]	Time  0.587 ( 4.982)	Data  0.001 ( 4.411)	Loss 8.7009e-02 (1.0091e-01) 
2023-05-27 13:19:46.605001: train Epoch: [31][174/193]	Time  9.358 ( 5.007)	Data  8.783 ( 4.436)	Loss 1.1321e-01 (1.0098e-01) 
2023-05-27 13:19:47.230851: train Epoch: [31][175/193]	Time  0.626 ( 4.982)	Data  0.001 ( 4.411)	Loss 2.0817e-01 (1.0159e-01) 
2023-05-27 13:19:56.831278: train Epoch: [31][176/193]	Time  9.600 ( 5.008)	Data  9.030 ( 4.437)	Loss 1.4531e-01 (1.0184e-01) 
2023-05-27 13:19:57.416607: train Epoch: [31][177/193]	Time  0.585 ( 4.983)	Data  0.001 ( 4.412)	Loss 1.0409e-01 (1.0185e-01) 
2023-05-27 13:20:06.529727: train Epoch: [31][178/193]	Time  9.113 ( 5.006)	Data  8.535 ( 4.435)	Loss 8.7184e-02 (1.0177e-01) 
2023-05-27 13:20:07.097353: train Epoch: [31][179/193]	Time  0.568 ( 4.982)	Data  0.001 ( 4.410)	Loss 1.0256e-01 (1.0177e-01) 
2023-05-27 13:20:16.794773: train Epoch: [31][180/193]	Time  9.697 ( 5.008)	Data  9.117 ( 4.436)	Loss 1.1153e-01 (1.0183e-01) 
2023-05-27 13:20:17.405424: train Epoch: [31][181/193]	Time  0.611 ( 4.984)	Data  0.002 ( 4.412)	Loss 1.1976e-01 (1.0192e-01) 
2023-05-27 13:20:26.961256: train Epoch: [31][182/193]	Time  9.556 ( 5.009)	Data  8.978 ( 4.437)	Loss 7.2019e-02 (1.0176e-01) 
2023-05-27 13:20:27.529144: train Epoch: [31][183/193]	Time  0.568 ( 4.985)	Data  0.001 ( 4.413)	Loss 1.5940e-01 (1.0207e-01) 
2023-05-27 13:20:36.887926: train Epoch: [31][184/193]	Time  9.359 ( 5.008)	Data  8.790 ( 4.437)	Loss 1.3538e-01 (1.0225e-01) 
2023-05-27 13:20:37.457855: train Epoch: [31][185/193]	Time  0.570 ( 4.984)	Data  0.001 ( 4.413)	Loss 6.5901e-02 (1.0206e-01) 
2023-05-27 13:20:46.988827: train Epoch: [31][186/193]	Time  9.531 ( 5.009)	Data  8.935 ( 4.437)	Loss 1.1541e-01 (1.0213e-01) 
2023-05-27 13:20:47.565370: train Epoch: [31][187/193]	Time  0.577 ( 4.985)	Data  0.001 ( 4.413)	Loss 7.6595e-02 (1.0199e-01) 
2023-05-27 13:20:57.205718: train Epoch: [31][188/193]	Time  9.640 ( 5.010)	Data  9.056 ( 4.438)	Loss 1.4427e-01 (1.0222e-01) 
2023-05-27 13:20:57.767551: train Epoch: [31][189/193]	Time  0.562 ( 4.986)	Data  0.001 ( 4.414)	Loss 7.1869e-02 (1.0206e-01) 
2023-05-27 13:21:06.989819: train Epoch: [31][190/193]	Time  9.222 ( 5.008)	Data  8.647 ( 4.437)	Loss 1.2713e-01 (1.0219e-01) 
2023-05-27 13:21:07.554855: train Epoch: [31][191/193]	Time  0.565 ( 4.985)	Data  0.001 ( 4.414)	Loss 1.1224e-01 (1.0224e-01) 
2023-05-27 13:21:16.031140: train Epoch: [31][192/193]	Time  8.476 ( 5.003)	Data  7.912 ( 4.432)	Loss 6.3488e-02 (1.0204e-01) 
2023-05-27 13:21:16.164107: Train Epoch done in 965.7911884289933 s 
2023-05-27 13:21:22.994986: val Epoch: [31][ 0/72]	Time  5.962 ( 5.962)	Data  5.787 ( 5.787)	Loss 4.1499e-02 (4.1499e-02) 
2023-05-27 13:21:23.104627: val Epoch: [31][ 1/72]	Time  0.110 ( 3.036)	Data  0.002 ( 2.895)	Loss 8.0543e-02 (6.1021e-02) 
2023-05-27 13:21:27.833426: val Epoch: [31][ 2/72]	Time  4.729 ( 3.600)	Data  4.620 ( 3.470)	Loss 5.8580e-02 (6.0208e-02) 
2023-05-27 13:21:27.941478: val Epoch: [31][ 3/72]	Time  0.108 ( 2.727)	Data  0.001 ( 2.602)	Loss 1.4055e-01 (8.0293e-02) 
2023-05-27 13:21:32.841054: val Epoch: [31][ 4/72]	Time  4.900 ( 3.162)	Data  4.788 ( 3.039)	Loss 4.3406e-01 (1.5105e-01) 
2023-05-27 13:21:33.166570: val Epoch: [31][ 5/72]	Time  0.326 ( 2.689)	Data  0.217 ( 2.569)	Loss 1.0848e-01 (1.4395e-01) 
2023-05-27 13:21:37.753872: val Epoch: [31][ 6/72]	Time  4.587 ( 2.960)	Data  4.479 ( 2.842)	Loss 5.0423e-02 (1.3059e-01) 
2023-05-27 13:21:38.050243: val Epoch: [31][ 7/72]	Time  0.296 ( 2.627)	Data  0.188 ( 2.510)	Loss 2.0715e-01 (1.4016e-01) 
2023-05-27 13:21:42.632541: val Epoch: [31][ 8/72]	Time  4.582 ( 2.844)	Data  4.474 ( 2.728)	Loss 6.6728e-02 (1.3200e-01) 
2023-05-27 13:21:42.791959: val Epoch: [31][ 9/72]	Time  0.159 ( 2.576)	Data  0.051 ( 2.461)	Loss 1.2922e-01 (1.3172e-01) 
2023-05-27 13:21:47.604390: val Epoch: [31][10/72]	Time  4.812 ( 2.779)	Data  4.704 ( 2.665)	Loss 4.5724e-02 (1.2391e-01) 
2023-05-27 13:21:48.075925: val Epoch: [31][11/72]	Time  0.472 ( 2.587)	Data  0.363 ( 2.473)	Loss 9.5721e-02 (1.2156e-01) 
2023-05-27 13:21:52.411418: val Epoch: [31][12/72]	Time  4.335 ( 2.721)	Data  4.223 ( 2.607)	Loss 4.0844e-02 (1.1535e-01) 
2023-05-27 13:21:52.957687: val Epoch: [31][13/72]	Time  0.546 ( 2.566)	Data  0.437 ( 2.452)	Loss 1.0306e-01 (1.1447e-01) 
2023-05-27 13:21:57.251524: val Epoch: [31][14/72]	Time  4.294 ( 2.681)	Data  4.186 ( 2.568)	Loss 6.0265e-02 (1.1086e-01) 
2023-05-27 13:21:58.057242: val Epoch: [31][15/72]	Time  0.806 ( 2.564)	Data  0.698 ( 2.451)	Loss 8.1945e-02 (1.0905e-01) 
2023-05-27 13:22:02.267022: val Epoch: [31][16/72]	Time  4.210 ( 2.661)	Data  4.102 ( 2.548)	Loss 1.8082e-01 (1.1327e-01) 
2023-05-27 13:22:02.865547: val Epoch: [31][17/72]	Time  0.599 ( 2.546)	Data  0.490 ( 2.434)	Loss 1.4360e-01 (1.1496e-01) 
2023-05-27 13:22:07.209355: val Epoch: [31][18/72]	Time  4.344 ( 2.641)	Data  4.235 ( 2.529)	Loss 3.4411e-01 (1.2702e-01) 
2023-05-27 13:22:07.787923: val Epoch: [31][19/72]	Time  0.579 ( 2.538)	Data  0.470 ( 2.426)	Loss 8.5777e-02 (1.2495e-01) 
2023-05-27 13:22:11.909348: val Epoch: [31][20/72]	Time  4.121 ( 2.613)	Data  4.014 ( 2.501)	Loss 8.1169e-02 (1.2287e-01) 
2023-05-27 13:22:12.581918: val Epoch: [31][21/72]	Time  0.673 ( 2.525)	Data  0.564 ( 2.413)	Loss 1.1135e-01 (1.2235e-01) 
2023-05-27 13:22:16.435581: val Epoch: [31][22/72]	Time  3.854 ( 2.583)	Data  3.745 ( 2.471)	Loss 6.0771e-02 (1.1967e-01) 
2023-05-27 13:22:17.457093: val Epoch: [31][23/72]	Time  1.022 ( 2.518)	Data  0.913 ( 2.406)	Loss 3.5063e-01 (1.2929e-01) 
2023-05-27 13:22:21.342422: val Epoch: [31][24/72]	Time  3.885 ( 2.572)	Data  3.777 ( 2.461)	Loss 1.8614e-01 (1.3157e-01) 
2023-05-27 13:22:22.173764: val Epoch: [31][25/72]	Time  0.831 ( 2.505)	Data  0.724 ( 2.394)	Loss 6.1784e-02 (1.2888e-01) 
2023-05-27 13:22:26.426342: val Epoch: [31][26/72]	Time  4.253 ( 2.570)	Data  4.142 ( 2.459)	Loss 1.1454e-01 (1.2835e-01) 
2023-05-27 13:22:27.156506: val Epoch: [31][27/72]	Time  0.730 ( 2.504)	Data  0.622 ( 2.393)	Loss 8.2561e-02 (1.2672e-01) 
2023-05-27 13:22:31.305155: val Epoch: [31][28/72]	Time  4.149 ( 2.561)	Data  4.041 ( 2.450)	Loss 1.3078e-01 (1.2686e-01) 
2023-05-27 13:22:32.159020: val Epoch: [31][29/72]	Time  0.854 ( 2.504)	Data  0.746 ( 2.393)	Loss 1.6712e-01 (1.2820e-01) 
2023-05-27 13:22:36.370245: val Epoch: [31][30/72]	Time  4.211 ( 2.559)	Data  4.096 ( 2.448)	Loss 4.9779e-02 (1.2567e-01) 
2023-05-27 13:22:37.070895: val Epoch: [31][31/72]	Time  0.701 ( 2.501)	Data  0.593 ( 2.390)	Loss 6.2056e-02 (1.2368e-01) 
2023-05-27 13:22:41.218395: val Epoch: [31][32/72]	Time  4.147 ( 2.551)	Data  4.035 ( 2.440)	Loss 4.8512e-02 (1.2140e-01) 
2023-05-27 13:22:42.002250: val Epoch: [31][33/72]	Time  0.784 ( 2.499)	Data  0.674 ( 2.388)	Loss 3.8294e-01 (1.2909e-01) 
2023-05-27 13:22:46.014173: val Epoch: [31][34/72]	Time  4.012 ( 2.542)	Data  3.904 ( 2.432)	Loss 5.3770e-02 (1.2694e-01) 
2023-05-27 13:22:46.748764: val Epoch: [31][35/72]	Time  0.735 ( 2.492)	Data  0.626 ( 2.381)	Loss 9.2470e-02 (1.2599e-01) 
2023-05-27 13:22:50.973522: val Epoch: [31][36/72]	Time  4.225 ( 2.539)	Data  4.117 ( 2.428)	Loss 3.1542e-01 (1.3111e-01) 
2023-05-27 13:22:51.638603: val Epoch: [31][37/72]	Time  0.665 ( 2.490)	Data  0.557 ( 2.379)	Loss 4.6357e-01 (1.3985e-01) 
2023-05-27 13:22:55.799111: val Epoch: [31][38/72]	Time  4.161 ( 2.532)	Data  4.052 ( 2.422)	Loss 1.4445e-01 (1.3997e-01) 
2023-05-27 13:22:56.774001: val Epoch: [31][39/72]	Time  0.975 ( 2.494)	Data  0.869 ( 2.383)	Loss 1.0880e-01 (1.3919e-01) 
2023-05-27 13:23:00.562618: val Epoch: [31][40/72]	Time  3.789 ( 2.525)	Data  3.683 ( 2.415)	Loss 3.2757e-02 (1.3660e-01) 
2023-05-27 13:23:01.788109: val Epoch: [31][41/72]	Time  1.225 ( 2.494)	Data  1.120 ( 2.384)	Loss 7.7969e-02 (1.3520e-01) 
2023-05-27 13:23:05.567423: val Epoch: [31][42/72]	Time  3.779 ( 2.524)	Data  3.670 ( 2.414)	Loss 9.6040e-02 (1.3429e-01) 
2023-05-27 13:23:06.757712: val Epoch: [31][43/72]	Time  1.190 ( 2.494)	Data  1.083 ( 2.384)	Loss 6.5884e-02 (1.3274e-01) 
2023-05-27 13:23:10.666145: val Epoch: [31][44/72]	Time  3.908 ( 2.525)	Data  3.801 ( 2.415)	Loss 3.2705e-01 (1.3705e-01) 
2023-05-27 13:23:11.819222: val Epoch: [31][45/72]	Time  1.153 ( 2.495)	Data  1.045 ( 2.385)	Loss 1.7280e-01 (1.3783e-01) 
2023-05-27 13:23:15.910158: val Epoch: [31][46/72]	Time  4.091 ( 2.529)	Data  3.983 ( 2.419)	Loss 5.6486e-01 (1.4692e-01) 
2023-05-27 13:23:17.007137: val Epoch: [31][47/72]	Time  1.097 ( 2.499)	Data  0.990 ( 2.390)	Loss 4.2200e-01 (1.5265e-01) 
2023-05-27 13:23:21.056459: val Epoch: [31][48/72]	Time  4.049 ( 2.531)	Data  3.941 ( 2.421)	Loss 7.4061e-02 (1.5104e-01) 
2023-05-27 13:23:22.209045: val Epoch: [31][49/72]	Time  1.153 ( 2.504)	Data  1.044 ( 2.394)	Loss 5.3154e-02 (1.4909e-01) 
2023-05-27 13:23:25.825076: val Epoch: [31][50/72]	Time  3.616 ( 2.525)	Data  3.503 ( 2.415)	Loss 7.2600e-02 (1.4759e-01) 
2023-05-27 13:23:27.510496: val Epoch: [31][51/72]	Time  1.685 ( 2.509)	Data  1.577 ( 2.399)	Loss 1.0205e-01 (1.4671e-01) 
2023-05-27 13:23:30.731300: val Epoch: [31][52/72]	Time  3.221 ( 2.523)	Data  3.112 ( 2.413)	Loss 1.0687e-01 (1.4596e-01) 
2023-05-27 13:23:32.519578: val Epoch: [31][53/72]	Time  1.788 ( 2.509)	Data  1.683 ( 2.399)	Loss 7.5796e-02 (1.4466e-01) 
2023-05-27 13:23:35.657876: val Epoch: [31][54/72]	Time  3.138 ( 2.520)	Data  3.033 ( 2.411)	Loss 4.1680e-02 (1.4279e-01) 
2023-05-27 13:23:37.471661: val Epoch: [31][55/72]	Time  1.814 ( 2.508)	Data  1.708 ( 2.398)	Loss 7.2639e-02 (1.4153e-01) 
2023-05-27 13:23:40.603240: val Epoch: [31][56/72]	Time  3.132 ( 2.519)	Data  3.026 ( 2.409)	Loss 6.2715e-02 (1.4015e-01) 
2023-05-27 13:23:42.557338: val Epoch: [31][57/72]	Time  1.954 ( 2.509)	Data  1.848 ( 2.400)	Loss 1.3428e-01 (1.4005e-01) 
2023-05-27 13:23:45.930741: val Epoch: [31][58/72]	Time  3.373 ( 2.524)	Data  3.256 ( 2.414)	Loss 3.0241e-01 (1.4280e-01) 
2023-05-27 13:23:47.595262: val Epoch: [31][59/72]	Time  1.665 ( 2.509)	Data  1.559 ( 2.400)	Loss 2.2390e-01 (1.4415e-01) 
2023-05-27 13:23:50.641364: val Epoch: [31][60/72]	Time  3.046 ( 2.518)	Data  2.941 ( 2.409)	Loss 2.0684e-01 (1.4518e-01) 
2023-05-27 13:23:52.383414: val Epoch: [31][61/72]	Time  1.742 ( 2.506)	Data  1.634 ( 2.396)	Loss 4.5618e-02 (1.4358e-01) 
2023-05-27 13:23:55.463576: val Epoch: [31][62/72]	Time  3.080 ( 2.515)	Data  2.971 ( 2.405)	Loss 5.7255e-02 (1.4221e-01) 
2023-05-27 13:23:57.526659: val Epoch: [31][63/72]	Time  2.063 ( 2.508)	Data  1.958 ( 2.398)	Loss 2.1554e-01 (1.4335e-01) 
2023-05-27 13:24:00.427989: val Epoch: [31][64/72]	Time  2.901 ( 2.514)	Data  2.793 ( 2.404)	Loss 1.5748e-01 (1.4357e-01) 
2023-05-27 13:24:02.315386: val Epoch: [31][65/72]	Time  1.887 ( 2.504)	Data  1.782 ( 2.395)	Loss 4.8242e-02 (1.4212e-01) 
2023-05-27 13:24:05.551401: val Epoch: [31][66/72]	Time  3.236 ( 2.515)	Data  3.127 ( 2.406)	Loss 3.1665e-01 (1.4473e-01) 
2023-05-27 13:24:07.456509: val Epoch: [31][67/72]	Time  1.905 ( 2.506)	Data  1.800 ( 2.397)	Loss 8.9953e-02 (1.4392e-01) 
2023-05-27 13:24:10.691450: val Epoch: [31][68/72]	Time  3.235 ( 2.517)	Data  3.125 ( 2.408)	Loss 5.4772e-02 (1.4263e-01) 
2023-05-27 13:24:12.573100: val Epoch: [31][69/72]	Time  1.882 ( 2.508)	Data  1.771 ( 2.398)	Loss 9.9408e-02 (1.4201e-01) 
2023-05-27 13:24:15.597175: val Epoch: [31][70/72]	Time  3.024 ( 2.515)	Data  2.915 ( 2.406)	Loss 6.6194e-02 (1.4095e-01) 
2023-05-27 13:24:17.433547: val Epoch: [31][71/72]	Time  1.836 ( 2.506)	Data  1.731 ( 2.396)	Loss 5.4272e-02 (1.3974e-01) 
2023-05-27 13:24:17.781160: Epoch 31 :Val : ['ET : 0.7375060319900513', 'TC : 0.766167938709259', 'WT : 0.8514483571052551'] 
2023-05-27 13:24:17.784237: Epoch 31 :Val : ['ET : 0.7375060319900513', 'TC : 0.766167938709259', 'WT : 0.8514483571052551'] 
2023-05-27 13:24:17.786734: Val epoch done in 181.62263587099733 s 
2023-05-27 13:24:17.795896: Batches per epoch:  193 
2023-05-27 13:24:29.384740: train Epoch: [32][  0/193]	Time 11.589 (11.589)	Data 10.864 (10.864)	Loss 9.1094e-02 (9.1094e-02) 
2023-05-27 13:24:29.957227: train Epoch: [32][  1/193]	Time  0.573 ( 6.081)	Data  0.001 ( 5.433)	Loss 1.0729e-01 (9.9194e-02) 
2023-05-27 13:24:39.127434: train Epoch: [32][  2/193]	Time  9.170 ( 7.110)	Data  8.606 ( 6.490)	Loss 9.5893e-02 (9.8093e-02) 
2023-05-27 13:24:39.702996: train Epoch: [32][  3/193]	Time  0.576 ( 5.477)	Data  0.001 ( 4.868)	Loss 5.5334e-02 (8.7403e-02) 
2023-05-27 13:24:49.043950: train Epoch: [32][  4/193]	Time  9.341 ( 6.250)	Data  8.750 ( 5.644)	Loss 4.3029e-02 (7.8529e-02) 
2023-05-27 13:24:49.620766: train Epoch: [32][  5/193]	Time  0.577 ( 5.304)	Data  0.001 ( 4.704)	Loss 6.0858e-02 (7.5583e-02) 
2023-05-27 13:24:59.232827: train Epoch: [32][  6/193]	Time  9.612 ( 5.920)	Data  9.029 ( 5.322)	Loss 5.0212e-02 (7.1959e-02) 
2023-05-27 13:24:59.853167: train Epoch: [32][  7/193]	Time  0.620 ( 5.257)	Data  0.001 ( 4.657)	Loss 8.8648e-02 (7.4045e-02) 
2023-05-27 13:25:07.962861: train Epoch: [32][  8/193]	Time  8.110 ( 5.574)	Data  7.544 ( 4.977)	Loss 7.0027e-02 (7.3599e-02) 
2023-05-27 13:25:08.531506: train Epoch: [32][  9/193]	Time  0.569 ( 5.074)	Data  0.001 ( 4.480)	Loss 6.2145e-02 (7.2453e-02) 
2023-05-27 13:25:16.970276: train Epoch: [32][ 10/193]	Time  8.439 ( 5.379)	Data  7.873 ( 4.788)	Loss 1.1833e-01 (7.6624e-02) 
2023-05-27 13:25:17.532703: train Epoch: [32][ 11/193]	Time  0.562 ( 4.978)	Data  0.001 ( 4.389)	Loss 1.3389e-01 (8.1397e-02) 
2023-05-27 13:25:26.799850: train Epoch: [32][ 12/193]	Time  9.267 ( 5.308)	Data  8.697 ( 4.721)	Loss 8.1844e-02 (8.1431e-02) 
2023-05-27 13:25:27.360757: train Epoch: [32][ 13/193]	Time  0.561 ( 4.969)	Data  0.001 ( 4.384)	Loss 8.0018e-02 (8.1330e-02) 
2023-05-27 13:25:36.690837: train Epoch: [32][ 14/193]	Time  9.330 ( 5.260)	Data  8.761 ( 4.675)	Loss 1.0106e-01 (8.2645e-02) 
2023-05-27 13:25:37.257735: train Epoch: [32][ 15/193]	Time  0.567 ( 4.966)	Data  0.001 ( 4.383)	Loss 8.1378e-02 (8.2566e-02) 
2023-05-27 13:25:46.515348: train Epoch: [32][ 16/193]	Time  9.258 ( 5.219)	Data  8.682 ( 4.636)	Loss 1.3771e-01 (8.5810e-02) 
2023-05-27 13:25:47.081767: train Epoch: [32][ 17/193]	Time  0.566 ( 4.960)	Data  0.001 ( 4.379)	Loss 3.4241e-02 (8.2945e-02) 
2023-05-27 13:25:56.517067: train Epoch: [32][ 18/193]	Time  9.435 ( 5.196)	Data  8.861 ( 4.614)	Loss 9.0904e-02 (8.3364e-02) 
2023-05-27 13:25:57.095672: train Epoch: [32][ 19/193]	Time  0.579 ( 4.965)	Data  0.001 ( 4.384)	Loss 8.2923e-02 (8.3342e-02) 
2023-05-27 13:26:06.797742: train Epoch: [32][ 20/193]	Time  9.702 ( 5.191)	Data  9.142 ( 4.610)	Loss 8.1829e-02 (8.3270e-02) 
2023-05-27 13:26:07.358429: train Epoch: [32][ 21/193]	Time  0.561 ( 4.980)	Data  0.001 ( 4.401)	Loss 7.4745e-02 (8.2882e-02) 
2023-05-27 13:26:16.636841: train Epoch: [32][ 22/193]	Time  9.278 ( 5.167)	Data  8.716 ( 4.588)	Loss 9.4880e-02 (8.3404e-02) 
2023-05-27 13:26:17.198137: train Epoch: [32][ 23/193]	Time  0.561 ( 4.975)	Data  0.001 ( 4.397)	Loss 3.6054e-02 (8.1431e-02) 
2023-05-27 13:26:26.358215: train Epoch: [32][ 24/193]	Time  9.160 ( 5.142)	Data  8.583 ( 4.565)	Loss 8.3178e-02 (8.1501e-02) 
2023-05-27 13:26:26.924381: train Epoch: [32][ 25/193]	Time  0.566 ( 4.966)	Data  0.001 ( 4.389)	Loss 6.5726e-02 (8.0894e-02) 
2023-05-27 13:26:35.020996: train Epoch: [32][ 26/193]	Time  8.097 ( 5.082)	Data  7.530 ( 4.506)	Loss 1.5551e-01 (8.3658e-02) 
2023-05-27 13:26:35.583434: train Epoch: [32][ 27/193]	Time  0.562 ( 4.921)	Data  0.001 ( 4.345)	Loss 6.4235e-02 (8.2964e-02) 
2023-05-27 13:26:43.998512: train Epoch: [32][ 28/193]	Time  8.415 ( 5.041)	Data  7.843 ( 4.465)	Loss 8.6723e-02 (8.3094e-02) 
2023-05-27 13:26:44.561416: train Epoch: [32][ 29/193]	Time  0.563 ( 4.892)	Data  0.001 ( 4.316)	Loss 5.6073e-02 (8.2193e-02) 
2023-05-27 13:26:54.316214: train Epoch: [32][ 30/193]	Time  9.755 ( 5.049)	Data  9.193 ( 4.474)	Loss 6.0143e-02 (8.1482e-02) 
2023-05-27 13:26:54.878670: train Epoch: [32][ 31/193]	Time  0.562 ( 4.909)	Data  0.001 ( 4.334)	Loss 6.8024e-02 (8.1061e-02) 
2023-05-27 13:27:03.638417: train Epoch: [32][ 32/193]	Time  8.760 ( 5.026)	Data  8.199 ( 4.451)	Loss 7.7705e-02 (8.0960e-02) 
2023-05-27 13:27:04.203778: train Epoch: [32][ 33/193]	Time  0.565 ( 4.894)	Data  0.001 ( 4.320)	Loss 1.3367e-01 (8.2510e-02) 
2023-05-27 13:27:13.238980: train Epoch: [32][ 34/193]	Time  9.035 ( 5.013)	Data  8.463 ( 4.439)	Loss 1.2016e-01 (8.3586e-02) 
2023-05-27 13:27:13.803462: train Epoch: [32][ 35/193]	Time  0.564 ( 4.889)	Data  0.001 ( 4.315)	Loss 6.8764e-02 (8.3174e-02) 
2023-05-27 13:27:23.449633: train Epoch: [32][ 36/193]	Time  9.646 ( 5.018)	Data  9.084 ( 4.444)	Loss 1.3407e-01 (8.4549e-02) 
2023-05-27 13:27:24.020365: train Epoch: [32][ 37/193]	Time  0.571 ( 4.901)	Data  0.001 ( 4.327)	Loss 9.9680e-02 (8.4948e-02) 
2023-05-27 13:27:32.883046: train Epoch: [32][ 38/193]	Time  8.863 ( 5.002)	Data  8.294 ( 4.429)	Loss 6.0357e-02 (8.4317e-02) 
2023-05-27 13:27:33.449853: train Epoch: [32][ 39/193]	Time  0.567 ( 4.891)	Data  0.001 ( 4.318)	Loss 1.0107e-01 (8.4736e-02) 
2023-05-27 13:27:43.052255: train Epoch: [32][ 40/193]	Time  9.602 ( 5.006)	Data  9.041 ( 4.433)	Loss 2.3961e-01 (8.8513e-02) 
2023-05-27 13:27:43.614267: train Epoch: [32][ 41/193]	Time  0.562 ( 4.900)	Data  0.001 ( 4.328)	Loss 8.5478e-02 (8.8441e-02) 
2023-05-27 13:27:52.913937: train Epoch: [32][ 42/193]	Time  9.300 ( 5.003)	Data  8.733 ( 4.430)	Loss 6.1289e-02 (8.7810e-02) 
2023-05-27 13:27:53.480846: train Epoch: [32][ 43/193]	Time  0.567 ( 4.902)	Data  0.001 ( 4.330)	Loss 8.9534e-02 (8.7849e-02) 
2023-05-27 13:28:02.517923: train Epoch: [32][ 44/193]	Time  9.037 ( 4.994)	Data  8.466 ( 4.422)	Loss 9.6156e-02 (8.8033e-02) 
2023-05-27 13:28:03.079384: train Epoch: [32][ 45/193]	Time  0.561 ( 4.897)	Data  0.001 ( 4.326)	Loss 9.0855e-02 (8.8095e-02) 
2023-05-27 13:28:11.458725: train Epoch: [32][ 46/193]	Time  8.379 ( 4.972)	Data  7.818 ( 4.400)	Loss 8.0585e-02 (8.7935e-02) 
2023-05-27 13:28:12.019982: train Epoch: [32][ 47/193]	Time  0.561 ( 4.880)	Data  0.001 ( 4.308)	Loss 6.5177e-02 (8.7461e-02) 
2023-05-27 13:28:21.694661: train Epoch: [32][ 48/193]	Time  9.675 ( 4.978)	Data  9.093 ( 4.406)	Loss 7.2737e-02 (8.7160e-02) 
2023-05-27 13:28:22.256124: train Epoch: [32][ 49/193]	Time  0.561 ( 4.889)	Data  0.001 ( 4.318)	Loss 1.1374e-01 (8.7692e-02) 
2023-05-27 13:28:31.858045: train Epoch: [32][ 50/193]	Time  9.602 ( 4.982)	Data  9.009 ( 4.410)	Loss 4.2227e-02 (8.6801e-02) 
2023-05-27 13:28:32.426930: train Epoch: [32][ 51/193]	Time  0.569 ( 4.897)	Data  0.001 ( 4.325)	Loss 6.7946e-02 (8.6438e-02) 
2023-05-27 13:28:41.451068: train Epoch: [32][ 52/193]	Time  9.024 ( 4.975)	Data  8.453 ( 4.403)	Loss 7.5542e-02 (8.6232e-02) 
2023-05-27 13:28:42.013494: train Epoch: [32][ 53/193]	Time  0.562 ( 4.893)	Data  0.001 ( 4.321)	Loss 9.9147e-02 (8.6472e-02) 
2023-05-27 13:28:51.405164: train Epoch: [32][ 54/193]	Time  9.392 ( 4.975)	Data  8.819 ( 4.403)	Loss 6.5348e-02 (8.6087e-02) 
2023-05-27 13:28:51.975351: train Epoch: [32][ 55/193]	Time  0.570 ( 4.896)	Data  0.001 ( 4.324)	Loss 1.1250e-01 (8.6559e-02) 
2023-05-27 13:29:01.919352: train Epoch: [32][ 56/193]	Time  9.944 ( 4.985)	Data  9.356 ( 4.413)	Loss 9.5214e-02 (8.6711e-02) 
2023-05-27 13:29:02.482029: train Epoch: [32][ 57/193]	Time  0.563 ( 4.908)	Data  0.001 ( 4.337)	Loss 8.5201e-02 (8.6685e-02) 
2023-05-27 13:29:12.059639: train Epoch: [32][ 58/193]	Time  9.578 ( 4.988)	Data  8.997 ( 4.416)	Loss 7.1875e-02 (8.6434e-02) 
2023-05-27 13:29:12.636148: train Epoch: [32][ 59/193]	Time  0.576 ( 4.914)	Data  0.001 ( 4.342)	Loss 9.4248e-02 (8.6564e-02) 
2023-05-27 13:29:21.896828: train Epoch: [32][ 60/193]	Time  9.261 ( 4.985)	Data  8.697 ( 4.413)	Loss 8.1886e-02 (8.6487e-02) 
2023-05-27 13:29:22.492787: train Epoch: [32][ 61/193]	Time  0.596 ( 4.914)	Data  0.001 ( 4.342)	Loss 1.5868e-01 (8.7652e-02) 
2023-05-27 13:29:32.222212: train Epoch: [32][ 62/193]	Time  9.729 ( 4.991)	Data  9.131 ( 4.418)	Loss 6.5245e-02 (8.7296e-02) 
2023-05-27 13:29:32.800205: train Epoch: [32][ 63/193]	Time  0.578 ( 4.922)	Data  0.001 ( 4.349)	Loss 8.5991e-02 (8.7276e-02) 
2023-05-27 13:29:41.632983: train Epoch: [32][ 64/193]	Time  8.833 ( 4.982)	Data  8.266 ( 4.410)	Loss 5.8464e-02 (8.6833e-02) 
2023-05-27 13:29:42.202347: train Epoch: [32][ 65/193]	Time  0.569 ( 4.915)	Data  0.001 ( 4.343)	Loss 4.9929e-02 (8.6273e-02) 
2023-05-27 13:29:52.351838: train Epoch: [32][ 66/193]	Time 10.149 ( 4.993)	Data  9.564 ( 4.421)	Loss 9.9201e-02 (8.6466e-02) 
2023-05-27 13:29:52.916728: train Epoch: [32][ 67/193]	Time  0.565 ( 4.928)	Data  0.001 ( 4.356)	Loss 7.8879e-02 (8.6355e-02) 
2023-05-27 13:30:02.516564: train Epoch: [32][ 68/193]	Time  9.600 ( 4.996)	Data  9.023 ( 4.423)	Loss 2.3154e-01 (8.8459e-02) 
2023-05-27 13:30:03.092226: train Epoch: [32][ 69/193]	Time  0.576 ( 4.933)	Data  0.001 ( 4.360)	Loss 7.7569e-02 (8.8303e-02) 
2023-05-27 13:30:12.376999: train Epoch: [32][ 70/193]	Time  9.285 ( 4.994)	Data  8.713 ( 4.421)	Loss 8.6631e-02 (8.8280e-02) 
2023-05-27 13:30:12.951252: train Epoch: [32][ 71/193]	Time  0.574 ( 4.933)	Data  0.001 ( 4.360)	Loss 8.8053e-02 (8.8277e-02) 
2023-05-27 13:30:22.512953: train Epoch: [32][ 72/193]	Time  9.562 ( 4.996)	Data  8.984 ( 4.423)	Loss 9.9519e-02 (8.8431e-02) 
2023-05-27 13:30:23.087056: train Epoch: [32][ 73/193]	Time  0.574 ( 4.936)	Data  0.001 ( 4.364)	Loss 1.1228e-01 (8.8753e-02) 
2023-05-27 13:30:32.672824: train Epoch: [32][ 74/193]	Time  9.586 ( 4.998)	Data  9.013 ( 4.426)	Loss 8.3114e-02 (8.8678e-02) 
2023-05-27 13:30:33.242753: train Epoch: [32][ 75/193]	Time  0.570 ( 4.940)	Data  0.001 ( 4.367)	Loss 9.7260e-02 (8.8791e-02) 
2023-05-27 13:30:42.465956: train Epoch: [32][ 76/193]	Time  9.223 ( 4.996)	Data  8.658 ( 4.423)	Loss 1.1076e-01 (8.9076e-02) 
2023-05-27 13:30:43.042171: train Epoch: [32][ 77/193]	Time  0.576 ( 4.939)	Data  0.001 ( 4.366)	Loss 7.8769e-02 (8.8944e-02) 
2023-05-27 13:30:52.182220: train Epoch: [32][ 78/193]	Time  9.140 ( 4.992)	Data  8.575 ( 4.420)	Loss 9.5116e-02 (8.9022e-02) 
2023-05-27 13:30:52.757873: train Epoch: [32][ 79/193]	Time  0.576 ( 4.937)	Data  0.001 ( 4.364)	Loss 1.0169e-01 (8.9180e-02) 
2023-05-27 13:31:02.456961: train Epoch: [32][ 80/193]	Time  9.699 ( 4.996)	Data  9.131 ( 4.423)	Loss 6.0102e-02 (8.8821e-02) 
2023-05-27 13:31:03.033921: train Epoch: [32][ 81/193]	Time  0.577 ( 4.942)	Data  0.001 ( 4.369)	Loss 9.4137e-02 (8.8886e-02) 
2023-05-27 13:31:12.646361: train Epoch: [32][ 82/193]	Time  9.612 ( 4.998)	Data  9.039 ( 4.426)	Loss 1.4167e-01 (8.9522e-02) 
2023-05-27 13:31:13.232761: train Epoch: [32][ 83/193]	Time  0.586 ( 4.946)	Data  0.001 ( 4.373)	Loss 1.4056e-01 (9.0130e-02) 
2023-05-27 13:31:22.743454: train Epoch: [32][ 84/193]	Time  9.511 ( 4.999)	Data  8.939 ( 4.427)	Loss 2.2218e-01 (9.1683e-02) 
2023-05-27 13:31:23.306299: train Epoch: [32][ 85/193]	Time  0.563 ( 4.948)	Data  0.001 ( 4.375)	Loss 1.0934e-01 (9.1889e-02) 
2023-05-27 13:31:32.547124: train Epoch: [32][ 86/193]	Time  9.241 ( 4.997)	Data  8.671 ( 4.425)	Loss 9.2589e-02 (9.1897e-02) 
2023-05-27 13:31:33.188025: train Epoch: [32][ 87/193]	Time  0.641 ( 4.948)	Data  0.001 ( 4.374)	Loss 7.0068e-02 (9.1649e-02) 
2023-05-27 13:31:41.085224: train Epoch: [32][ 88/193]	Time  7.897 ( 4.981)	Data  7.323 ( 4.407)	Loss 7.4763e-02 (9.1459e-02) 
2023-05-27 13:31:41.655416: train Epoch: [32][ 89/193]	Time  0.570 ( 4.932)	Data  0.001 ( 4.358)	Loss 6.1298e-02 (9.1124e-02) 
2023-05-27 13:31:50.174330: train Epoch: [32][ 90/193]	Time  8.519 ( 4.971)	Data  7.930 ( 4.398)	Loss 6.5108e-02 (9.0838e-02) 
2023-05-27 13:31:50.738507: train Epoch: [32][ 91/193]	Time  0.564 ( 4.923)	Data  0.001 ( 4.350)	Loss 9.2230e-02 (9.0853e-02) 
2023-05-27 13:32:00.172087: train Epoch: [32][ 92/193]	Time  9.434 ( 4.972)	Data  8.849 ( 4.398)	Loss 4.7399e-02 (9.0386e-02) 
2023-05-27 13:32:00.748980: train Epoch: [32][ 93/193]	Time  0.577 ( 4.925)	Data  0.001 ( 4.352)	Loss 1.0420e-01 (9.0533e-02) 
2023-05-27 13:32:10.308854: train Epoch: [32][ 94/193]	Time  9.560 ( 4.974)	Data  8.984 ( 4.400)	Loss 8.2427e-02 (9.0447e-02) 
2023-05-27 13:32:10.899046: train Epoch: [32][ 95/193]	Time  0.590 ( 4.928)	Data  0.001 ( 4.354)	Loss 5.3755e-02 (9.0065e-02) 
2023-05-27 13:32:20.085697: train Epoch: [32][ 96/193]	Time  9.187 ( 4.972)	Data  8.594 ( 4.398)	Loss 8.2904e-02 (8.9991e-02) 
2023-05-27 13:32:20.653117: train Epoch: [32][ 97/193]	Time  0.567 ( 4.927)	Data  0.001 ( 4.353)	Loss 7.5618e-02 (8.9845e-02) 
2023-05-27 13:32:29.900512: train Epoch: [32][ 98/193]	Time  9.247 ( 4.971)	Data  8.661 ( 4.397)	Loss 5.7218e-02 (8.9515e-02) 
2023-05-27 13:32:30.464931: train Epoch: [32][ 99/193]	Time  0.564 ( 4.927)	Data  0.001 ( 4.353)	Loss 7.0803e-02 (8.9328e-02) 
2023-05-27 13:32:39.698271: train Epoch: [32][100/193]	Time  9.233 ( 4.969)	Data  8.663 ( 4.396)	Loss 5.7982e-02 (8.9018e-02) 
2023-05-27 13:32:40.278514: train Epoch: [32][101/193]	Time  0.580 ( 4.926)	Data  0.001 ( 4.352)	Loss 4.3432e-02 (8.8571e-02) 
2023-05-27 13:32:49.617378: train Epoch: [32][102/193]	Time  9.339 ( 4.969)	Data  8.771 ( 4.395)	Loss 9.3074e-02 (8.8614e-02) 
2023-05-27 13:32:50.193031: train Epoch: [32][103/193]	Time  0.576 ( 4.927)	Data  0.001 ( 4.353)	Loss 7.0218e-02 (8.8437e-02) 
2023-05-27 13:32:59.765679: train Epoch: [32][104/193]	Time  9.573 ( 4.971)	Data  9.009 ( 4.397)	Loss 1.5895e-01 (8.9109e-02) 
2023-05-27 13:33:00.368203: train Epoch: [32][105/193]	Time  0.603 ( 4.930)	Data  0.001 ( 4.356)	Loss 1.0905e-01 (8.9297e-02) 
2023-05-27 13:33:09.759779: train Epoch: [32][106/193]	Time  9.392 ( 4.972)	Data  8.826 ( 4.398)	Loss 6.2092e-02 (8.9043e-02) 
2023-05-27 13:33:10.335504: train Epoch: [32][107/193]	Time  0.576 ( 4.931)	Data  0.001 ( 4.357)	Loss 7.1387e-02 (8.8879e-02) 
2023-05-27 13:33:19.423866: train Epoch: [32][108/193]	Time  9.088 ( 4.969)	Data  8.523 ( 4.395)	Loss 4.9149e-02 (8.8515e-02) 
2023-05-27 13:33:20.000572: train Epoch: [32][109/193]	Time  0.577 ( 4.929)	Data  0.001 ( 4.355)	Loss 1.0598e-01 (8.8674e-02) 
2023-05-27 13:33:29.107967: train Epoch: [32][110/193]	Time  9.107 ( 4.967)	Data  8.536 ( 4.393)	Loss 6.7622e-02 (8.8484e-02) 
2023-05-27 13:33:29.671058: train Epoch: [32][111/193]	Time  0.563 ( 4.927)	Data  0.001 ( 4.354)	Loss 6.8389e-02 (8.8305e-02) 
2023-05-27 13:33:39.460881: train Epoch: [32][112/193]	Time  9.790 ( 4.970)	Data  9.227 ( 4.397)	Loss 7.6210e-02 (8.8198e-02) 
2023-05-27 13:33:40.032474: train Epoch: [32][113/193]	Time  0.572 ( 4.932)	Data  0.001 ( 4.358)	Loss 1.3580e-01 (8.8615e-02) 
2023-05-27 13:33:49.559738: train Epoch: [32][114/193]	Time  9.527 ( 4.972)	Data  8.964 ( 4.398)	Loss 1.2283e-01 (8.8913e-02) 
2023-05-27 13:33:50.135810: train Epoch: [32][115/193]	Time  0.576 ( 4.934)	Data  0.001 ( 4.360)	Loss 1.1692e-01 (8.9154e-02) 
2023-05-27 13:33:59.818427: train Epoch: [32][116/193]	Time  9.683 ( 4.975)	Data  9.114 ( 4.401)	Loss 5.7515e-02 (8.8884e-02) 
2023-05-27 13:34:00.384371: train Epoch: [32][117/193]	Time  0.566 ( 4.937)	Data  0.001 ( 4.364)	Loss 4.6353e-02 (8.8523e-02) 
2023-05-27 13:34:09.727692: train Epoch: [32][118/193]	Time  9.343 ( 4.974)	Data  8.779 ( 4.401)	Loss 9.2543e-02 (8.8557e-02) 
2023-05-27 13:34:10.301311: train Epoch: [32][119/193]	Time  0.574 ( 4.938)	Data  0.001 ( 4.364)	Loss 1.2643e-01 (8.8873e-02) 
2023-05-27 13:34:20.195404: train Epoch: [32][120/193]	Time  9.894 ( 4.979)	Data  9.304 ( 4.405)	Loss 5.1854e-02 (8.8567e-02) 
2023-05-27 13:34:20.764557: train Epoch: [32][121/193]	Time  0.569 ( 4.942)	Data  0.001 ( 4.369)	Loss 1.7781e-01 (8.9298e-02) 
2023-05-27 13:34:30.301395: train Epoch: [32][122/193]	Time  9.537 ( 4.980)	Data  8.965 ( 4.406)	Loss 8.5967e-02 (8.9271e-02) 
2023-05-27 13:34:30.869203: train Epoch: [32][123/193]	Time  0.568 ( 4.944)	Data  0.001 ( 4.371)	Loss 4.9814e-02 (8.8953e-02) 
2023-05-27 13:34:40.283024: train Epoch: [32][124/193]	Time  9.414 ( 4.980)	Data  8.844 ( 4.407)	Loss 1.1577e-01 (8.9167e-02) 
2023-05-27 13:34:40.863598: train Epoch: [32][125/193]	Time  0.581 ( 4.945)	Data  0.001 ( 4.372)	Loss 8.3319e-02 (8.9121e-02) 
2023-05-27 13:34:50.203532: train Epoch: [32][126/193]	Time  9.340 ( 4.980)	Data  8.769 ( 4.406)	Loss 1.0426e-01 (8.9240e-02) 
2023-05-27 13:34:50.791380: train Epoch: [32][127/193]	Time  0.588 ( 4.945)	Data  0.001 ( 4.372)	Loss 7.3409e-02 (8.9116e-02) 
2023-05-27 13:35:00.231257: train Epoch: [32][128/193]	Time  9.440 ( 4.980)	Data  8.864 ( 4.407)	Loss 8.6322e-02 (8.9095e-02) 
2023-05-27 13:35:00.805197: train Epoch: [32][129/193]	Time  0.574 ( 4.946)	Data  0.001 ( 4.373)	Loss 6.4233e-02 (8.8903e-02) 
2023-05-27 13:35:10.204219: train Epoch: [32][130/193]	Time  9.399 ( 4.980)	Data  8.830 ( 4.407)	Loss 3.2862e-02 (8.8476e-02) 
2023-05-27 13:35:10.773342: train Epoch: [32][131/193]	Time  0.569 ( 4.947)	Data  0.001 ( 4.373)	Loss 8.2573e-02 (8.8431e-02) 
2023-05-27 13:35:20.007467: train Epoch: [32][132/193]	Time  9.234 ( 4.979)	Data  8.671 ( 4.406)	Loss 1.0266e-01 (8.8538e-02) 
2023-05-27 13:35:20.582264: train Epoch: [32][133/193]	Time  0.575 ( 4.946)	Data  0.001 ( 4.373)	Loss 8.0312e-02 (8.8477e-02) 
2023-05-27 13:35:29.742805: train Epoch: [32][134/193]	Time  9.161 ( 4.977)	Data  8.592 ( 4.404)	Loss 1.2193e-01 (8.8724e-02) 
2023-05-27 13:35:30.307391: train Epoch: [32][135/193]	Time  0.565 ( 4.945)	Data  0.001 ( 4.372)	Loss 7.2479e-02 (8.8605e-02) 
2023-05-27 13:35:39.388828: train Epoch: [32][136/193]	Time  9.081 ( 4.975)	Data  8.519 ( 4.402)	Loss 1.3369e-01 (8.8934e-02) 
2023-05-27 13:35:39.950767: train Epoch: [32][137/193]	Time  0.562 ( 4.943)	Data  0.001 ( 4.370)	Loss 1.0867e-01 (8.9077e-02) 
2023-05-27 13:35:48.966101: train Epoch: [32][138/193]	Time  9.015 ( 4.972)	Data  8.428 ( 4.399)	Loss 7.3818e-02 (8.8967e-02) 
2023-05-27 13:35:49.529281: train Epoch: [32][139/193]	Time  0.563 ( 4.941)	Data  0.001 ( 4.368)	Loss 1.0772e-01 (8.9101e-02) 
2023-05-27 13:35:58.798044: train Epoch: [32][140/193]	Time  9.269 ( 4.972)	Data  8.707 ( 4.399)	Loss 4.8942e-02 (8.8816e-02) 
2023-05-27 13:35:59.360797: train Epoch: [32][141/193]	Time  0.563 ( 4.941)	Data  0.001 ( 4.368)	Loss 7.4078e-02 (8.8712e-02) 
2023-05-27 13:36:08.870764: train Epoch: [32][142/193]	Time  9.510 ( 4.973)	Data  8.948 ( 4.400)	Loss 8.5614e-02 (8.8691e-02) 
2023-05-27 13:36:09.441141: train Epoch: [32][143/193]	Time  0.570 ( 4.942)	Data  0.001 ( 4.369)	Loss 7.9755e-02 (8.8629e-02) 
2023-05-27 13:36:19.185057: train Epoch: [32][144/193]	Time  9.744 ( 4.975)	Data  9.181 ( 4.402)	Loss 3.9914e-02 (8.8293e-02) 
2023-05-27 13:36:19.759320: train Epoch: [32][145/193]	Time  0.574 ( 4.945)	Data  0.001 ( 4.372)	Loss 5.3509e-02 (8.8055e-02) 
2023-05-27 13:36:29.509789: train Epoch: [32][146/193]	Time  9.750 ( 4.978)	Data  9.189 ( 4.405)	Loss 5.9754e-02 (8.7862e-02) 
2023-05-27 13:36:30.074811: train Epoch: [32][147/193]	Time  0.565 ( 4.948)	Data  0.001 ( 4.375)	Loss 9.7844e-02 (8.7929e-02) 
2023-05-27 13:36:39.705312: train Epoch: [32][148/193]	Time  9.630 ( 4.979)	Data  9.057 ( 4.407)	Loss 1.9496e-01 (8.8648e-02) 
2023-05-27 13:36:40.297868: train Epoch: [32][149/193]	Time  0.593 ( 4.950)	Data  0.001 ( 4.377)	Loss 1.0779e-01 (8.8775e-02) 
2023-05-27 13:36:49.447402: train Epoch: [32][150/193]	Time  9.150 ( 4.978)	Data  8.587 ( 4.405)	Loss 1.1496e-01 (8.8949e-02) 
2023-05-27 13:36:50.010467: train Epoch: [32][151/193]	Time  0.563 ( 4.949)	Data  0.001 ( 4.376)	Loss 6.7797e-02 (8.8810e-02) 
2023-05-27 13:36:59.350683: train Epoch: [32][152/193]	Time  9.340 ( 4.977)	Data  8.773 ( 4.405)	Loss 5.6029e-02 (8.8595e-02) 
2023-05-27 13:36:59.917550: train Epoch: [32][153/193]	Time  0.567 ( 4.949)	Data  0.001 ( 4.376)	Loss 5.1352e-02 (8.8354e-02) 
2023-05-27 13:37:09.303096: train Epoch: [32][154/193]	Time  9.386 ( 4.977)	Data  8.818 ( 4.405)	Loss 6.4165e-02 (8.8198e-02) 
2023-05-27 13:37:09.871253: train Epoch: [32][155/193]	Time  0.568 ( 4.949)	Data  0.001 ( 4.377)	Loss 1.5270e-01 (8.8611e-02) 
2023-05-27 13:37:19.873713: train Epoch: [32][156/193]	Time 10.002 ( 4.981)	Data  9.426 ( 4.409)	Loss 8.7141e-02 (8.8602e-02) 
2023-05-27 13:37:20.449398: train Epoch: [32][157/193]	Time  0.576 ( 4.953)	Data  0.001 ( 4.381)	Loss 5.2076e-02 (8.8370e-02) 
2023-05-27 13:37:29.483721: train Epoch: [32][158/193]	Time  9.034 ( 4.979)	Data  8.467 ( 4.407)	Loss 9.2762e-02 (8.8398e-02) 
2023-05-27 13:37:30.052975: train Epoch: [32][159/193]	Time  0.569 ( 4.952)	Data  0.001 ( 4.379)	Loss 7.3925e-02 (8.8308e-02) 
2023-05-27 13:37:39.069942: train Epoch: [32][160/193]	Time  9.017 ( 4.977)	Data  8.450 ( 4.404)	Loss 6.3172e-02 (8.8152e-02) 
2023-05-27 13:37:39.636971: train Epoch: [32][161/193]	Time  0.567 ( 4.950)	Data  0.001 ( 4.377)	Loss 9.4580e-02 (8.8191e-02) 
2023-05-27 13:37:48.600600: train Epoch: [32][162/193]	Time  8.964 ( 4.974)	Data  8.403 ( 4.402)	Loss 8.6378e-02 (8.8180e-02) 
2023-05-27 13:37:49.163426: train Epoch: [32][163/193]	Time  0.563 ( 4.947)	Data  0.001 ( 4.375)	Loss 1.1409e-01 (8.8338e-02) 
2023-05-27 13:37:58.588328: train Epoch: [32][164/193]	Time  9.425 ( 4.974)	Data  8.862 ( 4.402)	Loss 7.8114e-02 (8.8276e-02) 
2023-05-27 13:37:59.151000: train Epoch: [32][165/193]	Time  0.563 ( 4.948)	Data  0.001 ( 4.376)	Loss 1.2064e-01 (8.8471e-02) 
2023-05-27 13:38:08.551308: train Epoch: [32][166/193]	Time  9.400 ( 4.975)	Data  8.837 ( 4.403)	Loss 1.6061e-01 (8.8903e-02) 
2023-05-27 13:38:09.114123: train Epoch: [32][167/193]	Time  0.563 ( 4.948)	Data  0.001 ( 4.376)	Loss 2.7949e-01 (9.0038e-02) 
2023-05-27 13:38:18.572805: train Epoch: [32][168/193]	Time  9.459 ( 4.975)	Data  8.898 ( 4.403)	Loss 1.5330e-01 (9.0412e-02) 
2023-05-27 13:38:19.134152: train Epoch: [32][169/193]	Time  0.561 ( 4.949)	Data  0.001 ( 4.377)	Loss 1.2841e-01 (9.0635e-02) 
2023-05-27 13:38:28.701592: train Epoch: [32][170/193]	Time  9.567 ( 4.976)	Data  9.007 ( 4.404)	Loss 8.0152e-02 (9.0574e-02) 
2023-05-27 13:38:29.263107: train Epoch: [32][171/193]	Time  0.562 ( 4.950)	Data  0.001 ( 4.379)	Loss 5.8745e-02 (9.0389e-02) 
2023-05-27 13:38:38.504409: train Epoch: [32][172/193]	Time  9.241 ( 4.975)	Data  8.680 ( 4.404)	Loss 8.3132e-02 (9.0347e-02) 
2023-05-27 13:38:39.067674: train Epoch: [32][173/193]	Time  0.563 ( 4.950)	Data  0.001 ( 4.378)	Loss 8.9414e-02 (9.0342e-02) 
2023-05-27 13:38:48.373201: train Epoch: [32][174/193]	Time  9.306 ( 4.975)	Data  8.738 ( 4.403)	Loss 6.2993e-02 (9.0185e-02) 
2023-05-27 13:38:48.940654: train Epoch: [32][175/193]	Time  0.567 ( 4.950)	Data  0.001 ( 4.378)	Loss 4.8694e-02 (8.9950e-02) 
2023-05-27 13:38:58.022026: train Epoch: [32][176/193]	Time  9.081 ( 4.973)	Data  8.509 ( 4.401)	Loss 1.0749e-01 (9.0049e-02) 
2023-05-27 13:38:58.590089: train Epoch: [32][177/193]	Time  0.568 ( 4.948)	Data  0.001 ( 4.377)	Loss 7.1341e-02 (8.9944e-02) 
2023-05-27 13:39:08.089021: train Epoch: [32][178/193]	Time  9.499 ( 4.974)	Data  8.936 ( 4.402)	Loss 1.4137e-01 (9.0231e-02) 
2023-05-27 13:39:08.651898: train Epoch: [32][179/193]	Time  0.563 ( 4.949)	Data  0.001 ( 4.378)	Loss 9.5547e-02 (9.0261e-02) 
2023-05-27 13:39:17.866501: train Epoch: [32][180/193]	Time  9.215 ( 4.973)	Data  8.653 ( 4.401)	Loss 7.8006e-02 (9.0193e-02) 
2023-05-27 13:39:18.434102: train Epoch: [32][181/193]	Time  0.568 ( 4.949)	Data  0.001 ( 4.377)	Loss 5.2177e-02 (8.9984e-02) 
2023-05-27 13:39:27.975245: train Epoch: [32][182/193]	Time  9.541 ( 4.974)	Data  8.976 ( 4.402)	Loss 8.4223e-02 (8.9952e-02) 
2023-05-27 13:39:28.537851: train Epoch: [32][183/193]	Time  0.563 ( 4.950)	Data  0.001 ( 4.378)	Loss 8.2879e-02 (8.9914e-02) 
2023-05-27 13:39:38.116486: train Epoch: [32][184/193]	Time  9.579 ( 4.975)	Data  9.011 ( 4.403)	Loss 8.1076e-02 (8.9866e-02) 
2023-05-27 13:39:38.682633: train Epoch: [32][185/193]	Time  0.566 ( 4.951)	Data  0.001 ( 4.380)	Loss 7.3364e-02 (8.9778e-02) 
2023-05-27 13:39:48.345131: train Epoch: [32][186/193]	Time  9.663 ( 4.976)	Data  9.083 ( 4.405)	Loss 8.4108e-02 (8.9747e-02) 
2023-05-27 13:39:48.905959: train Epoch: [32][187/193]	Time  0.561 ( 4.953)	Data  0.001 ( 4.381)	Loss 1.1180e-01 (8.9865e-02) 
2023-05-27 13:39:58.158651: train Epoch: [32][188/193]	Time  9.253 ( 4.975)	Data  8.692 ( 4.404)	Loss 7.7535e-02 (8.9799e-02) 
2023-05-27 13:39:58.720417: train Epoch: [32][189/193]	Time  0.562 ( 4.952)	Data  0.001 ( 4.381)	Loss 6.7373e-02 (8.9681e-02) 
2023-05-27 13:40:07.470863: train Epoch: [32][190/193]	Time  8.750 ( 4.972)	Data  8.177 ( 4.401)	Loss 5.9596e-02 (8.9524e-02) 
2023-05-27 13:40:08.032637: train Epoch: [32][191/193]	Time  0.562 ( 4.949)	Data  0.001 ( 4.378)	Loss 8.4448e-02 (8.9497e-02) 
2023-05-27 13:40:16.284625: train Epoch: [32][192/193]	Time  8.252 ( 4.966)	Data  7.681 ( 4.395)	Loss 6.8395e-02 (8.9388e-02) 
2023-05-27 13:40:16.421435: Train Epoch done in 958.625560379005 s 
2023-05-27 13:40:23.164629: val Epoch: [32][ 0/72]	Time  5.952 ( 5.952)	Data  5.771 ( 5.771)	Loss 4.5052e-02 (4.5052e-02) 
2023-05-27 13:40:23.389931: val Epoch: [32][ 1/72]	Time  0.225 ( 3.089)	Data  0.119 ( 2.945)	Loss 1.0619e-01 (7.5623e-02) 
2023-05-27 13:40:27.836154: val Epoch: [32][ 2/72]	Time  4.446 ( 3.541)	Data  4.339 ( 3.410)	Loss 1.4537e-01 (9.8871e-02) 
2023-05-27 13:40:28.415848: val Epoch: [32][ 3/72]	Time  0.580 ( 2.801)	Data  0.471 ( 2.675)	Loss 5.1531e-02 (8.7036e-02) 
2023-05-27 13:40:32.851953: val Epoch: [32][ 4/72]	Time  4.436 ( 3.128)	Data  4.327 ( 3.005)	Loss 6.4047e-02 (8.2438e-02) 
2023-05-27 13:40:33.326919: val Epoch: [32][ 5/72]	Time  0.475 ( 2.686)	Data  0.366 ( 2.565)	Loss 1.7092e-01 (9.7186e-02) 
2023-05-27 13:40:37.803461: val Epoch: [32][ 6/72]	Time  4.476 ( 2.942)	Data  4.367 ( 2.823)	Loss 5.1527e-01 (1.5691e-01) 
2023-05-27 13:40:38.497298: val Epoch: [32][ 7/72]	Time  0.694 ( 2.661)	Data  0.587 ( 2.543)	Loss 8.4751e-02 (1.4789e-01) 
2023-05-27 13:40:42.579599: val Epoch: [32][ 8/72]	Time  4.082 ( 2.819)	Data  3.976 ( 2.703)	Loss 2.2168e-01 (1.5609e-01) 
2023-05-27 13:40:43.348239: val Epoch: [32][ 9/72]	Time  0.769 ( 2.614)	Data  0.662 ( 2.499)	Loss 6.3071e-02 (1.4679e-01) 
2023-05-27 13:40:47.497303: val Epoch: [32][10/72]	Time  4.149 ( 2.753)	Data  4.043 ( 2.639)	Loss 2.3093e-01 (1.5444e-01) 
2023-05-27 13:40:48.237755: val Epoch: [32][11/72]	Time  0.740 ( 2.585)	Data  0.634 ( 2.472)	Loss 4.1501e-02 (1.4503e-01) 
2023-05-27 13:40:52.385638: val Epoch: [32][12/72]	Time  4.148 ( 2.706)	Data  4.038 ( 2.592)	Loss 5.8563e-02 (1.3838e-01) 
2023-05-27 13:40:53.292305: val Epoch: [32][13/72]	Time  0.907 ( 2.577)	Data  0.794 ( 2.464)	Loss 4.8535e-02 (1.3196e-01) 
2023-05-27 13:40:57.320262: val Epoch: [32][14/72]	Time  4.028 ( 2.674)	Data  3.923 ( 2.561)	Loss 1.1028e-01 (1.3051e-01) 
2023-05-27 13:40:58.370686: val Epoch: [32][15/72]	Time  1.050 ( 2.572)	Data  0.942 ( 2.460)	Loss 3.2141e-01 (1.4244e-01) 
2023-05-27 13:41:02.309085: val Epoch: [32][16/72]	Time  3.938 ( 2.653)	Data  3.833 ( 2.541)	Loss 8.3608e-02 (1.3898e-01) 
2023-05-27 13:41:03.360738: val Epoch: [32][17/72]	Time  1.052 ( 2.564)	Data  0.946 ( 2.452)	Loss 6.7039e-02 (1.3499e-01) 
2023-05-27 13:41:06.902559: val Epoch: [32][18/72]	Time  3.542 ( 2.615)	Data  3.436 ( 2.504)	Loss 4.2315e-02 (1.3011e-01) 
2023-05-27 13:41:08.664927: val Epoch: [32][19/72]	Time  1.762 ( 2.573)	Data  1.633 ( 2.460)	Loss 6.1116e-02 (1.2666e-01) 
2023-05-27 13:41:11.848545: val Epoch: [32][20/72]	Time  3.184 ( 2.602)	Data  3.074 ( 2.490)	Loss 1.0613e-01 (1.2568e-01) 
2023-05-27 13:41:13.579915: val Epoch: [32][21/72]	Time  1.731 ( 2.562)	Data  1.624 ( 2.450)	Loss 3.6575e-01 (1.3659e-01) 
2023-05-27 13:41:16.560496: val Epoch: [32][22/72]	Time  2.981 ( 2.580)	Data  2.875 ( 2.469)	Loss 7.2943e-02 (1.3383e-01) 
2023-05-27 13:41:18.880690: val Epoch: [32][23/72]	Time  2.320 ( 2.569)	Data  2.209 ( 2.458)	Loss 5.3922e-02 (1.3050e-01) 
2023-05-27 13:41:21.337743: val Epoch: [32][24/72]	Time  2.457 ( 2.565)	Data  2.349 ( 2.454)	Loss 6.0559e-02 (1.2770e-01) 
2023-05-27 13:41:23.855595: val Epoch: [32][25/72]	Time  2.518 ( 2.563)	Data  2.401 ( 2.452)	Loss 9.7691e-02 (1.2655e-01) 
2023-05-27 13:41:26.199592: val Epoch: [32][26/72]	Time  2.344 ( 2.555)	Data  2.235 ( 2.444)	Loss 3.7570e-01 (1.3577e-01) 
2023-05-27 13:41:29.012374: val Epoch: [32][27/72]	Time  2.813 ( 2.564)	Data  2.682 ( 2.452)	Loss 2.0090e-01 (1.3810e-01) 
2023-05-27 13:41:31.051796: val Epoch: [32][28/72]	Time  2.039 ( 2.546)	Data  1.930 ( 2.434)	Loss 6.6043e-02 (1.3561e-01) 
2023-05-27 13:41:33.769663: val Epoch: [32][29/72]	Time  2.718 ( 2.552)	Data  2.609 ( 2.440)	Loss 5.1433e-02 (1.3281e-01) 
2023-05-27 13:41:35.868206: val Epoch: [32][30/72]	Time  2.099 ( 2.537)	Data  1.990 ( 2.425)	Loss 9.3686e-02 (1.3155e-01) 
2023-05-27 13:41:38.905243: val Epoch: [32][31/72]	Time  3.037 ( 2.553)	Data  2.915 ( 2.441)	Loss 7.0487e-02 (1.2964e-01) 
2023-05-27 13:41:40.745356: val Epoch: [32][32/72]	Time  1.840 ( 2.531)	Data  1.735 ( 2.419)	Loss 1.1520e-01 (1.2920e-01) 
2023-05-27 13:41:43.717128: val Epoch: [32][33/72]	Time  2.972 ( 2.544)	Data  2.866 ( 2.432)	Loss 8.9464e-02 (1.2803e-01) 
2023-05-27 13:41:45.677762: val Epoch: [32][34/72]	Time  1.961 ( 2.528)	Data  1.843 ( 2.416)	Loss 1.2091e-01 (1.2783e-01) 
2023-05-27 13:41:48.817731: val Epoch: [32][35/72]	Time  3.140 ( 2.545)	Data  3.030 ( 2.433)	Loss 7.0386e-02 (1.2623e-01) 
2023-05-27 13:41:50.645268: val Epoch: [32][36/72]	Time  1.828 ( 2.525)	Data  1.719 ( 2.413)	Loss 4.1523e-02 (1.2394e-01) 
2023-05-27 13:41:54.031241: val Epoch: [32][37/72]	Time  3.386 ( 2.548)	Data  3.276 ( 2.436)	Loss 7.9986e-02 (1.2279e-01) 
2023-05-27 13:41:55.679991: val Epoch: [32][38/72]	Time  1.649 ( 2.525)	Data  1.541 ( 2.413)	Loss 2.8420e-01 (1.2693e-01) 
2023-05-27 13:41:58.728887: val Epoch: [32][39/72]	Time  3.049 ( 2.538)	Data  2.931 ( 2.426)	Loss 5.4936e-02 (1.2513e-01) 
2023-05-27 13:42:00.802585: val Epoch: [32][40/72]	Time  2.074 ( 2.527)	Data  1.957 ( 2.415)	Loss 9.6532e-02 (1.2443e-01) 
2023-05-27 13:42:03.748506: val Epoch: [32][41/72]	Time  2.946 ( 2.537)	Data  2.836 ( 2.425)	Loss 8.3407e-02 (1.2345e-01) 
2023-05-27 13:42:05.682964: val Epoch: [32][42/72]	Time  1.934 ( 2.523)	Data  1.824 ( 2.411)	Loss 4.8688e-02 (1.2171e-01) 
2023-05-27 13:42:08.988140: val Epoch: [32][43/72]	Time  3.305 ( 2.540)	Data  3.196 ( 2.429)	Loss 2.4247e-01 (1.2446e-01) 
2023-05-27 13:42:10.465968: val Epoch: [32][44/72]	Time  1.478 ( 2.517)	Data  1.351 ( 2.405)	Loss 6.1510e-02 (1.2306e-01) 
2023-05-27 13:42:13.968485: val Epoch: [32][45/72]	Time  3.503 ( 2.538)	Data  3.378 ( 2.426)	Loss 3.6238e-02 (1.2117e-01) 
2023-05-27 13:42:15.456883: val Epoch: [32][46/72]	Time  1.488 ( 2.516)	Data  1.378 ( 2.403)	Loss 8.7078e-02 (1.2045e-01) 
2023-05-27 13:42:18.759892: val Epoch: [32][47/72]	Time  3.303 ( 2.532)	Data  3.194 ( 2.420)	Loss 3.2544e-01 (1.2472e-01) 
2023-05-27 13:42:20.477837: val Epoch: [32][48/72]	Time  1.718 ( 2.516)	Data  1.601 ( 2.403)	Loss 4.3468e-01 (1.3104e-01) 
2023-05-27 13:42:24.069053: val Epoch: [32][49/72]	Time  3.591 ( 2.537)	Data  3.474 ( 2.425)	Loss 8.7558e-02 (1.3017e-01) 
2023-05-27 13:42:25.324487: val Epoch: [32][50/72]	Time  1.255 ( 2.512)	Data  1.147 ( 2.400)	Loss 1.2106e-01 (1.2999e-01) 
2023-05-27 13:42:29.163456: val Epoch: [32][51/72]	Time  3.839 ( 2.538)	Data  3.730 ( 2.425)	Loss 3.6586e-02 (1.2820e-01) 
2023-05-27 13:42:30.218997: val Epoch: [32][52/72]	Time  1.056 ( 2.510)	Data  0.916 ( 2.397)	Loss 1.2194e-01 (1.2808e-01) 
2023-05-27 13:42:34.189163: val Epoch: [32][53/72]	Time  3.970 ( 2.537)	Data  3.848 ( 2.424)	Loss 6.3025e-02 (1.2687e-01) 
2023-05-27 13:42:35.349446: val Epoch: [32][54/72]	Time  1.160 ( 2.512)	Data  1.053 ( 2.399)	Loss 7.4003e-02 (1.2591e-01) 
2023-05-27 13:42:39.223301: val Epoch: [32][55/72]	Time  3.874 ( 2.536)	Data  3.746 ( 2.423)	Loss 4.1858e-01 (1.3114e-01) 
2023-05-27 13:42:40.207103: val Epoch: [32][56/72]	Time  0.984 ( 2.509)	Data  0.868 ( 2.395)	Loss 8.7143e-02 (1.3037e-01) 
2023-05-27 13:42:44.315493: val Epoch: [32][57/72]	Time  4.108 ( 2.536)	Data  3.995 ( 2.423)	Loss 3.8191e-02 (1.2878e-01) 
2023-05-27 13:42:45.221833: val Epoch: [32][58/72]	Time  0.906 ( 2.509)	Data  0.798 ( 2.395)	Loss 3.3972e-01 (1.3235e-01) 
2023-05-27 13:42:49.432600: val Epoch: [32][59/72]	Time  4.211 ( 2.537)	Data  4.098 ( 2.424)	Loss 2.6448e-01 (1.3456e-01) 
2023-05-27 13:42:50.402017: val Epoch: [32][60/72]	Time  0.969 ( 2.511)	Data  0.860 ( 2.398)	Loss 1.0225e-01 (1.3403e-01) 
2023-05-27 13:42:54.529046: val Epoch: [32][61/72]	Time  4.127 ( 2.537)	Data  4.018 ( 2.424)	Loss 1.6546e-01 (1.3453e-01) 
2023-05-27 13:42:55.280819: val Epoch: [32][62/72]	Time  0.752 ( 2.509)	Data  0.647 ( 2.396)	Loss 3.3646e-02 (1.3293e-01) 
2023-05-27 13:42:59.835682: val Epoch: [32][63/72]	Time  4.555 ( 2.541)	Data  4.440 ( 2.428)	Loss 8.7094e-02 (1.3222e-01) 
2023-05-27 13:43:00.562220: val Epoch: [32][64/72]	Time  0.727 ( 2.513)	Data  0.611 ( 2.400)	Loss 6.6868e-02 (1.3121e-01) 
2023-05-27 13:43:04.896095: val Epoch: [32][65/72]	Time  4.334 ( 2.541)	Data  4.219 ( 2.428)	Loss 5.7308e-02 (1.3009e-01) 
2023-05-27 13:43:05.583394: val Epoch: [32][66/72]	Time  0.687 ( 2.513)	Data  0.580 ( 2.400)	Loss 1.7544e-01 (1.3077e-01) 
2023-05-27 13:43:10.040842: val Epoch: [32][67/72]	Time  4.457 ( 2.542)	Data  4.349 ( 2.429)	Loss 5.2516e-01 (1.3657e-01) 
2023-05-27 13:43:10.607441: val Epoch: [32][68/72]	Time  0.567 ( 2.513)	Data  0.459 ( 2.400)	Loss 1.0397e-01 (1.3610e-01) 
2023-05-27 13:43:14.938339: val Epoch: [32][69/72]	Time  4.331 ( 2.539)	Data  4.225 ( 2.426)	Loss 4.0690e-02 (1.3473e-01) 
2023-05-27 13:43:15.540356: val Epoch: [32][70/72]	Time  0.602 ( 2.512)	Data  0.493 ( 2.399)	Loss 7.8503e-02 (1.3394e-01) 
2023-05-27 13:43:19.444382: val Epoch: [32][71/72]	Time  3.904 ( 2.531)	Data  3.792 ( 2.418)	Loss 1.4596e-01 (1.3411e-01) 
2023-05-27 13:43:19.754337: Epoch 32 :Val : ['ET : 0.7401502132415771', 'TC : 0.7786743640899658', 'WT : 0.8552601337432861'] 
2023-05-27 13:43:19.761325: Epoch 32 :Val : ['ET : 0.7401502132415771', 'TC : 0.7786743640899658', 'WT : 0.8552601337432861'] 
2023-05-27 13:43:19.766144: Saving the model with DSC 0.7935588359832764 
2023-05-27 13:43:20.580565: Val epoch done in 184.15913891600212 s 
2023-05-27 13:43:20.603025: Batches per epoch:  193 
2023-05-27 13:43:32.306134: train Epoch: [33][  0/193]	Time 11.703 (11.703)	Data 11.103 (11.103)	Loss 6.5569e-02 (6.5569e-02) 
2023-05-27 13:43:32.882986: train Epoch: [33][  1/193]	Time  0.577 ( 6.140)	Data  0.001 ( 5.552)	Loss 8.5910e-02 (7.5739e-02) 
2023-05-27 13:43:42.481404: train Epoch: [33][  2/193]	Time  9.598 ( 7.293)	Data  9.023 ( 6.709)	Loss 7.1571e-02 (7.4350e-02) 
2023-05-27 13:43:43.073581: train Epoch: [33][  3/193]	Time  0.592 ( 5.618)	Data  0.001 ( 5.032)	Loss 1.4180e-01 (9.1212e-02) 
2023-05-27 13:43:52.402260: train Epoch: [33][  4/193]	Time  9.329 ( 6.360)	Data  8.766 ( 5.779)	Loss 8.1086e-02 (8.9186e-02) 
2023-05-27 13:43:52.968261: train Epoch: [33][  5/193]	Time  0.566 ( 5.394)	Data  0.001 ( 4.816)	Loss 8.8250e-02 (8.9030e-02) 
2023-05-27 13:44:02.763242: train Epoch: [33][  6/193]	Time  9.795 ( 6.023)	Data  9.225 ( 5.446)	Loss 1.2700e-01 (9.4455e-02) 
2023-05-27 13:44:03.354768: train Epoch: [33][  7/193]	Time  0.592 ( 5.344)	Data  0.001 ( 4.765)	Loss 6.6802e-02 (9.0998e-02) 
2023-05-27 13:44:12.520052: train Epoch: [33][  8/193]	Time  9.165 ( 5.769)	Data  8.594 ( 5.191)	Loss 1.1825e-01 (9.4026e-02) 
2023-05-27 13:44:13.105796: train Epoch: [33][  9/193]	Time  0.586 ( 5.250)	Data  0.001 ( 4.672)	Loss 8.6215e-02 (9.3245e-02) 
2023-05-27 13:44:20.949229: train Epoch: [33][ 10/193]	Time  7.843 ( 5.486)	Data  7.282 ( 4.909)	Loss 1.5339e-01 (9.8713e-02) 
2023-05-27 13:44:21.511243: train Epoch: [33][ 11/193]	Time  0.562 ( 5.076)	Data  0.001 ( 4.500)	Loss 7.0153e-02 (9.6333e-02) 
2023-05-27 13:44:31.115887: train Epoch: [33][ 12/193]	Time  9.605 ( 5.424)	Data  9.030 ( 4.848)	Loss 6.5072e-02 (9.3928e-02) 
2023-05-27 13:44:31.681182: train Epoch: [33][ 13/193]	Time  0.565 ( 5.077)	Data  0.001 ( 4.502)	Loss 7.8807e-02 (9.2848e-02) 
2023-05-27 13:44:41.010990: train Epoch: [33][ 14/193]	Time  9.330 ( 5.361)	Data  8.767 ( 4.787)	Loss 1.0510e-01 (9.3665e-02) 
2023-05-27 13:44:41.584707: train Epoch: [33][ 15/193]	Time  0.574 ( 5.061)	Data  0.001 ( 4.487)	Loss 5.3246e-02 (9.1139e-02) 
2023-05-27 13:44:51.048256: train Epoch: [33][ 16/193]	Time  9.464 ( 5.320)	Data  8.902 ( 4.747)	Loss 7.5865e-02 (9.0240e-02) 
2023-05-27 13:44:51.637762: train Epoch: [33][ 17/193]	Time  0.589 ( 5.057)	Data  0.001 ( 4.483)	Loss 3.5021e-02 (8.7172e-02) 
2023-05-27 13:45:00.816294: train Epoch: [33][ 18/193]	Time  9.179 ( 5.274)	Data  8.617 ( 4.701)	Loss 1.5350e-01 (9.0664e-02) 
2023-05-27 13:45:01.379666: train Epoch: [33][ 19/193]	Time  0.563 ( 5.039)	Data  0.001 ( 4.466)	Loss 8.6154e-02 (9.0438e-02) 
2023-05-27 13:45:11.069696: train Epoch: [33][ 20/193]	Time  9.690 ( 5.260)	Data  9.126 ( 4.688)	Loss 9.9027e-02 (9.0847e-02) 
2023-05-27 13:45:11.631524: train Epoch: [33][ 21/193]	Time  0.562 ( 5.047)	Data  0.001 ( 4.475)	Loss 1.3562e-01 (9.2882e-02) 
2023-05-27 13:45:21.141830: train Epoch: [33][ 22/193]	Time  9.510 ( 5.241)	Data  8.945 ( 4.669)	Loss 1.1741e-01 (9.3949e-02) 
2023-05-27 13:45:21.707751: train Epoch: [33][ 23/193]	Time  0.566 ( 5.046)	Data  0.001 ( 4.475)	Loss 4.9723e-02 (9.2106e-02) 
2023-05-27 13:45:30.005593: train Epoch: [33][ 24/193]	Time  8.298 ( 5.176)	Data  7.730 ( 4.605)	Loss 1.1315e-01 (9.2948e-02) 
2023-05-27 13:45:30.572581: train Epoch: [33][ 25/193]	Time  0.567 ( 4.999)	Data  0.001 ( 4.428)	Loss 4.7032e-02 (9.1182e-02) 
2023-05-27 13:45:39.056760: train Epoch: [33][ 26/193]	Time  8.484 ( 5.128)	Data  7.913 ( 4.557)	Loss 9.6034e-02 (9.1362e-02) 
2023-05-27 13:45:39.626985: train Epoch: [33][ 27/193]	Time  0.570 ( 4.965)	Data  0.001 ( 4.394)	Loss 8.1633e-02 (9.1014e-02) 
2023-05-27 13:45:49.359511: train Epoch: [33][ 28/193]	Time  9.733 ( 5.130)	Data  9.166 ( 4.559)	Loss 1.0617e-01 (9.1537e-02) 
2023-05-27 13:45:49.932322: train Epoch: [33][ 29/193]	Time  0.573 ( 4.978)	Data  0.001 ( 4.407)	Loss 4.4863e-02 (8.9981e-02) 
2023-05-27 13:45:58.913360: train Epoch: [33][ 30/193]	Time  8.981 ( 5.107)	Data  8.408 ( 4.536)	Loss 6.7564e-02 (8.9258e-02) 
2023-05-27 13:45:59.487812: train Epoch: [33][ 31/193]	Time  0.574 ( 4.965)	Data  0.001 ( 4.394)	Loss 6.4660e-02 (8.8489e-02) 
2023-05-27 13:46:09.239527: train Epoch: [33][ 32/193]	Time  9.752 ( 5.110)	Data  9.184 ( 4.539)	Loss 1.2838e-01 (8.9698e-02) 
2023-05-27 13:46:09.819474: train Epoch: [33][ 33/193]	Time  0.580 ( 4.977)	Data  0.001 ( 4.406)	Loss 7.0676e-02 (8.9139e-02) 
2023-05-27 13:46:19.076280: train Epoch: [33][ 34/193]	Time  9.257 ( 5.099)	Data  8.691 ( 4.528)	Loss 8.1439e-02 (8.8919e-02) 
2023-05-27 13:46:19.639063: train Epoch: [33][ 35/193]	Time  0.563 ( 4.973)	Data  0.001 ( 4.402)	Loss 6.2708e-02 (8.8191e-02) 
2023-05-27 13:46:28.944378: train Epoch: [33][ 36/193]	Time  9.305 ( 5.090)	Data  8.733 ( 4.519)	Loss 6.2773e-02 (8.7504e-02) 
2023-05-27 13:46:29.512330: train Epoch: [33][ 37/193]	Time  0.568 ( 4.971)	Data  0.001 ( 4.401)	Loss 8.5236e-02 (8.7444e-02) 
2023-05-27 13:46:39.167869: train Epoch: [33][ 38/193]	Time  9.656 ( 5.091)	Data  9.086 ( 4.521)	Loss 6.4724e-02 (8.6861e-02) 
2023-05-27 13:46:39.741424: train Epoch: [33][ 39/193]	Time  0.574 ( 4.978)	Data  0.001 ( 4.408)	Loss 6.0236e-02 (8.6196e-02) 
2023-05-27 13:46:49.249973: train Epoch: [33][ 40/193]	Time  9.509 ( 5.089)	Data  8.932 ( 4.518)	Loss 6.9643e-02 (8.5792e-02) 
2023-05-27 13:46:49.822988: train Epoch: [33][ 41/193]	Time  0.573 ( 4.981)	Data  0.001 ( 4.410)	Loss 6.2153e-02 (8.5229e-02) 
2023-05-27 13:46:59.468862: train Epoch: [33][ 42/193]	Time  9.646 ( 5.090)	Data  9.079 ( 4.519)	Loss 1.1948e-01 (8.6026e-02) 
2023-05-27 13:47:00.036590: train Epoch: [33][ 43/193]	Time  0.568 ( 4.987)	Data  0.001 ( 4.416)	Loss 8.7143e-02 (8.6051e-02) 
2023-05-27 13:47:09.431673: train Epoch: [33][ 44/193]	Time  9.395 ( 5.085)	Data  8.792 ( 4.514)	Loss 5.3321e-02 (8.5324e-02) 
2023-05-27 13:47:10.000284: train Epoch: [33][ 45/193]	Time  0.569 ( 4.987)	Data  0.001 ( 4.415)	Loss 5.0469e-02 (8.4566e-02) 
2023-05-27 13:47:19.804238: train Epoch: [33][ 46/193]	Time  9.804 ( 5.089)	Data  9.236 ( 4.518)	Loss 5.0261e-02 (8.3836e-02) 
2023-05-27 13:47:20.370437: train Epoch: [33][ 47/193]	Time  0.566 ( 4.995)	Data  0.001 ( 4.424)	Loss 5.7274e-02 (8.3283e-02) 
2023-05-27 13:47:29.576046: train Epoch: [33][ 48/193]	Time  9.206 ( 5.081)	Data  8.634 ( 4.510)	Loss 4.6391e-02 (8.2530e-02) 
2023-05-27 13:47:30.139319: train Epoch: [33][ 49/193]	Time  0.563 ( 4.991)	Data  0.001 ( 4.420)	Loss 9.1901e-02 (8.2717e-02) 
2023-05-27 13:47:39.547657: train Epoch: [33][ 50/193]	Time  9.408 ( 5.077)	Data  8.840 ( 4.506)	Loss 7.5618e-02 (8.2578e-02) 
2023-05-27 13:47:40.126043: train Epoch: [33][ 51/193]	Time  0.578 ( 4.991)	Data  0.001 ( 4.420)	Loss 8.2506e-02 (8.2577e-02) 
2023-05-27 13:47:49.609856: train Epoch: [33][ 52/193]	Time  9.484 ( 5.076)	Data  8.922 ( 4.505)	Loss 1.2040e-01 (8.3290e-02) 
2023-05-27 13:47:50.177203: train Epoch: [33][ 53/193]	Time  0.567 ( 4.992)	Data  0.001 ( 4.421)	Loss 1.1293e-01 (8.3839e-02) 
2023-05-27 13:47:59.667735: train Epoch: [33][ 54/193]	Time  9.491 ( 5.074)	Data  8.929 ( 4.503)	Loss 2.1151e-01 (8.6161e-02) 
2023-05-27 13:48:00.230127: train Epoch: [33][ 55/193]	Time  0.562 ( 4.993)	Data  0.001 ( 4.423)	Loss 8.9031e-02 (8.6212e-02) 
2023-05-27 13:48:09.837927: train Epoch: [33][ 56/193]	Time  9.608 ( 5.074)	Data  9.033 ( 4.504)	Loss 5.3318e-02 (8.5635e-02) 
2023-05-27 13:48:10.400796: train Epoch: [33][ 57/193]	Time  0.563 ( 4.997)	Data  0.001 ( 4.426)	Loss 6.2983e-02 (8.5244e-02) 
2023-05-27 13:48:19.606080: train Epoch: [33][ 58/193]	Time  9.205 ( 5.068)	Data  8.631 ( 4.497)	Loss 7.4854e-02 (8.5068e-02) 
2023-05-27 13:48:20.172745: train Epoch: [33][ 59/193]	Time  0.567 ( 4.993)	Data  0.001 ( 4.422)	Loss 7.4235e-02 (8.4888e-02) 
2023-05-27 13:48:29.251439: train Epoch: [33][ 60/193]	Time  9.079 ( 5.060)	Data  8.510 ( 4.489)	Loss 8.4794e-02 (8.4886e-02) 
2023-05-27 13:48:29.825121: train Epoch: [33][ 61/193]	Time  0.574 ( 4.987)	Data  0.001 ( 4.417)	Loss 4.5316e-02 (8.4248e-02) 
2023-05-27 13:48:40.457170: train Epoch: [33][ 62/193]	Time 10.632 ( 5.077)	Data 10.068 ( 4.507)	Loss 8.9415e-02 (8.4330e-02) 
2023-05-27 13:48:41.028188: train Epoch: [33][ 63/193]	Time  0.571 ( 5.007)	Data  0.001 ( 4.436)	Loss 2.1680e-01 (8.6400e-02) 
2023-05-27 13:48:53.057874: train Epoch: [33][ 64/193]	Time 12.030 ( 5.115)	Data 11.469 ( 4.544)	Loss 9.1505e-02 (8.6478e-02) 
2023-05-27 13:48:53.618559: train Epoch: [33][ 65/193]	Time  0.561 ( 5.046)	Data  0.001 ( 4.476)	Loss 6.2284e-02 (8.6112e-02) 
2023-05-27 13:49:05.318391: train Epoch: [33][ 66/193]	Time 11.700 ( 5.145)	Data 11.129 ( 4.575)	Loss 1.2912e-01 (8.6753e-02) 
2023-05-27 13:49:05.880345: train Epoch: [33][ 67/193]	Time  0.562 ( 5.078)	Data  0.001 ( 4.508)	Loss 4.0582e-02 (8.6074e-02) 
2023-05-27 13:49:16.745792: train Epoch: [33][ 68/193]	Time 10.865 ( 5.161)	Data 10.296 ( 4.592)	Loss 1.1926e-01 (8.6555e-02) 
2023-05-27 13:49:17.307647: train Epoch: [33][ 69/193]	Time  0.562 ( 5.096)	Data  0.001 ( 4.526)	Loss 7.8190e-02 (8.6436e-02) 
2023-05-27 13:49:25.966113: train Epoch: [33][ 70/193]	Time  8.658 ( 5.146)	Data  8.093 ( 4.576)	Loss 6.9755e-02 (8.6201e-02) 
2023-05-27 13:49:26.533515: train Epoch: [33][ 71/193]	Time  0.567 ( 5.082)	Data  0.001 ( 4.513)	Loss 4.6233e-02 (8.5646e-02) 
2023-05-27 13:49:36.792275: train Epoch: [33][ 72/193]	Time 10.259 ( 5.153)	Data  9.698 ( 4.584)	Loss 7.2088e-02 (8.5460e-02) 
2023-05-27 13:49:37.355563: train Epoch: [33][ 73/193]	Time  0.563 ( 5.091)	Data  0.001 ( 4.522)	Loss 7.2302e-02 (8.5282e-02) 
2023-05-27 13:49:49.475599: train Epoch: [33][ 74/193]	Time 12.120 ( 5.185)	Data 11.546 ( 4.615)	Loss 9.1302e-02 (8.5363e-02) 
2023-05-27 13:49:50.038826: train Epoch: [33][ 75/193]	Time  0.563 ( 5.124)	Data  0.001 ( 4.555)	Loss 1.1817e-01 (8.5794e-02) 
2023-05-27 13:50:01.985613: train Epoch: [33][ 76/193]	Time 11.947 ( 5.213)	Data 11.380 ( 4.643)	Loss 1.2951e-01 (8.6362e-02) 
2023-05-27 13:50:02.552840: train Epoch: [33][ 77/193]	Time  0.567 ( 5.153)	Data  0.001 ( 4.584)	Loss 1.7863e-01 (8.7545e-02) 
2023-05-27 13:50:12.336847: train Epoch: [33][ 78/193]	Time  9.784 ( 5.212)	Data  9.222 ( 4.643)	Loss 6.0326e-02 (8.7200e-02) 
2023-05-27 13:50:12.898342: train Epoch: [33][ 79/193]	Time  0.561 ( 5.154)	Data  0.001 ( 4.585)	Loss 1.0907e-01 (8.7474e-02) 
2023-05-27 13:50:21.956664: train Epoch: [33][ 80/193]	Time  9.058 ( 5.202)	Data  8.491 ( 4.633)	Loss 8.8269e-02 (8.7484e-02) 
2023-05-27 13:50:22.531542: train Epoch: [33][ 81/193]	Time  0.575 ( 5.145)	Data  0.001 ( 4.576)	Loss 8.2350e-02 (8.7421e-02) 
2023-05-27 13:50:31.913075: train Epoch: [33][ 82/193]	Time  9.382 ( 5.196)	Data  8.812 ( 4.627)	Loss 7.2537e-02 (8.7242e-02) 
2023-05-27 13:50:32.475865: train Epoch: [33][ 83/193]	Time  0.563 ( 5.141)	Data  0.001 ( 4.572)	Loss 6.1671e-02 (8.6937e-02) 
2023-05-27 13:50:43.278600: train Epoch: [33][ 84/193]	Time 10.803 ( 5.208)	Data 10.241 ( 4.639)	Loss 7.1759e-02 (8.6759e-02) 
2023-05-27 13:50:43.840016: train Epoch: [33][ 85/193]	Time  0.561 ( 5.154)	Data  0.001 ( 4.585)	Loss 8.3648e-02 (8.6722e-02) 
2023-05-27 13:50:55.975885: train Epoch: [33][ 86/193]	Time 12.136 ( 5.234)	Data 11.573 ( 4.665)	Loss 9.0040e-02 (8.6761e-02) 
2023-05-27 13:50:56.543030: train Epoch: [33][ 87/193]	Time  0.567 ( 5.181)	Data  0.001 ( 4.612)	Loss 7.5957e-02 (8.6638e-02) 
2023-05-27 13:51:06.757827: train Epoch: [33][ 88/193]	Time 10.215 ( 5.238)	Data  9.654 ( 4.669)	Loss 8.0954e-02 (8.6574e-02) 
2023-05-27 13:51:07.320766: train Epoch: [33][ 89/193]	Time  0.563 ( 5.186)	Data  0.001 ( 4.617)	Loss 6.6844e-02 (8.6355e-02) 
2023-05-27 13:51:18.662061: train Epoch: [33][ 90/193]	Time 11.341 ( 5.253)	Data 10.769 ( 4.685)	Loss 1.0109e-01 (8.6517e-02) 
2023-05-27 13:51:19.228749: train Epoch: [33][ 91/193]	Time  0.567 ( 5.202)	Data  0.001 ( 4.634)	Loss 7.5283e-02 (8.6395e-02) 
2023-05-27 13:51:30.891082: train Epoch: [33][ 92/193]	Time 11.662 ( 5.272)	Data 11.090 ( 4.703)	Loss 1.0098e-01 (8.6551e-02) 
2023-05-27 13:51:31.481314: train Epoch: [33][ 93/193]	Time  0.590 ( 5.222)	Data  0.030 ( 4.653)	Loss 7.6861e-02 (8.6448e-02) 
2023-05-27 13:51:43.453520: train Epoch: [33][ 94/193]	Time 11.972 ( 5.293)	Data 11.411 ( 4.725)	Loss 5.4112e-02 (8.6108e-02) 
2023-05-27 13:51:44.015409: train Epoch: [33][ 95/193]	Time  0.562 ( 5.244)	Data  0.001 ( 4.675)	Loss 5.1270e-02 (8.5745e-02) 
2023-05-27 13:51:56.238466: train Epoch: [33][ 96/193]	Time 12.223 ( 5.316)	Data 11.662 ( 4.747)	Loss 8.4367e-02 (8.5731e-02) 
2023-05-27 13:51:56.800337: train Epoch: [33][ 97/193]	Time  0.562 ( 5.267)	Data  0.001 ( 4.699)	Loss 4.1588e-02 (8.5280e-02) 
2023-05-27 13:52:09.136471: train Epoch: [33][ 98/193]	Time 12.336 ( 5.339)	Data 11.764 ( 4.770)	Loss 8.7880e-02 (8.5307e-02) 
2023-05-27 13:52:09.697324: train Epoch: [33][ 99/193]	Time  0.561 ( 5.291)	Data  0.001 ( 4.723)	Loss 2.5587e-01 (8.7012e-02) 
2023-05-27 13:52:21.621084: train Epoch: [33][100/193]	Time 11.924 ( 5.357)	Data 11.363 ( 4.788)	Loss 1.0013e-01 (8.7142e-02) 
2023-05-27 13:52:22.183105: train Epoch: [33][101/193]	Time  0.562 ( 5.310)	Data  0.001 ( 4.741)	Loss 7.1873e-02 (8.6992e-02) 
2023-05-27 13:52:33.958722: train Epoch: [33][102/193]	Time 11.776 ( 5.372)	Data 11.194 ( 4.804)	Loss 7.0355e-02 (8.6831e-02) 
2023-05-27 13:52:34.520703: train Epoch: [33][103/193]	Time  0.562 ( 5.326)	Data  0.001 ( 4.758)	Loss 7.0749e-02 (8.6676e-02) 
2023-05-27 13:52:47.295192: train Epoch: [33][104/193]	Time 12.774 ( 5.397)	Data 12.204 ( 4.829)	Loss 7.3898e-02 (8.6555e-02) 
2023-05-27 13:52:47.891865: train Epoch: [33][105/193]	Time  0.597 ( 5.352)	Data  0.001 ( 4.783)	Loss 2.7907e-01 (8.8371e-02) 
2023-05-27 13:53:01.749136: train Epoch: [33][106/193]	Time 13.857 ( 5.431)	Data 13.278 ( 4.863)	Loss 9.7620e-02 (8.8457e-02) 
2023-05-27 13:53:02.325618: train Epoch: [33][107/193]	Time  0.576 ( 5.386)	Data  0.001 ( 4.818)	Loss 7.4485e-02 (8.8328e-02) 
2023-05-27 13:53:14.613865: train Epoch: [33][108/193]	Time 12.288 ( 5.450)	Data 11.711 ( 4.881)	Loss 8.9035e-02 (8.8334e-02) 
2023-05-27 13:53:15.214349: train Epoch: [33][109/193]	Time  0.600 ( 5.406)	Data  0.001 ( 4.837)	Loss 9.2736e-02 (8.8374e-02) 
2023-05-27 13:53:27.875950: train Epoch: [33][110/193]	Time 12.662 ( 5.471)	Data 12.091 ( 4.902)	Loss 1.1838e-01 (8.8645e-02) 
2023-05-27 13:53:28.513178: train Epoch: [33][111/193]	Time  0.637 ( 5.428)	Data  0.001 ( 4.858)	Loss 1.5136e-01 (8.9205e-02) 
2023-05-27 13:53:40.686029: train Epoch: [33][112/193]	Time 12.173 ( 5.487)	Data 11.601 ( 4.918)	Loss 9.5950e-02 (8.9264e-02) 
2023-05-27 13:53:41.270424: train Epoch: [33][113/193]	Time  0.584 ( 5.444)	Data  0.001 ( 4.875)	Loss 1.0562e-01 (8.9408e-02) 
2023-05-27 13:53:53.620711: train Epoch: [33][114/193]	Time 12.350 ( 5.504)	Data 11.788 ( 4.935)	Loss 9.4322e-02 (8.9451e-02) 
2023-05-27 13:53:54.184888: train Epoch: [33][115/193]	Time  0.564 ( 5.462)	Data  0.001 ( 4.892)	Loss 6.6680e-02 (8.9254e-02) 
2023-05-27 13:54:06.507516: train Epoch: [33][116/193]	Time 12.323 ( 5.521)	Data 11.760 ( 4.951)	Loss 1.7563e-01 (8.9993e-02) 
2023-05-27 13:54:07.070810: train Epoch: [33][117/193]	Time  0.563 ( 5.479)	Data  0.001 ( 4.909)	Loss 6.6062e-02 (8.9790e-02) 
2023-05-27 13:54:19.010205: train Epoch: [33][118/193]	Time 11.939 ( 5.533)	Data 11.378 ( 4.963)	Loss 1.5397e-01 (9.0329e-02) 
2023-05-27 13:54:19.572993: train Epoch: [33][119/193]	Time  0.563 ( 5.491)	Data  0.001 ( 4.922)	Loss 8.0441e-02 (9.0247e-02) 
2023-05-27 13:54:31.720481: train Epoch: [33][120/193]	Time 12.147 ( 5.546)	Data 11.578 ( 4.977)	Loss 9.5059e-02 (9.0286e-02) 
2023-05-27 13:54:32.283568: train Epoch: [33][121/193]	Time  0.563 ( 5.506)	Data  0.001 ( 4.936)	Loss 7.7235e-02 (9.0179e-02) 
2023-05-27 13:54:43.999822: train Epoch: [33][122/193]	Time 11.716 ( 5.556)	Data 11.146 ( 4.987)	Loss 7.2515e-02 (9.0036e-02) 
2023-05-27 13:54:45.112812: train Epoch: [33][123/193]	Time  1.113 ( 5.520)	Data  0.522 ( 4.951)	Loss 1.8545e-01 (9.0805e-02) 
2023-05-27 13:54:56.921989: train Epoch: [33][124/193]	Time 11.809 ( 5.571)	Data 11.239 ( 5.001)	Loss 8.1654e-02 (9.0732e-02) 
2023-05-27 13:54:58.114838: train Epoch: [33][125/193]	Time  1.193 ( 5.536)	Data  0.622 ( 4.966)	Loss 4.6009e-02 (9.0377e-02) 
2023-05-27 13:55:09.796486: train Epoch: [33][126/193]	Time 11.682 ( 5.584)	Data 11.114 ( 5.015)	Loss 1.2246e-01 (9.0630e-02) 
2023-05-27 13:55:11.071750: train Epoch: [33][127/193]	Time  1.275 ( 5.551)	Data  0.706 ( 4.981)	Loss 9.2641e-02 (9.0645e-02) 
2023-05-27 13:55:22.924476: train Epoch: [33][128/193]	Time 11.853 ( 5.599)	Data 11.282 ( 5.030)	Loss 1.5364e-01 (9.1134e-02) 
2023-05-27 13:55:23.963543: train Epoch: [33][129/193]	Time  1.039 ( 5.564)	Data  0.476 ( 4.995)	Loss 1.1584e-01 (9.1324e-02) 
2023-05-27 13:55:35.294464: train Epoch: [33][130/193]	Time 11.331 ( 5.608)	Data 10.769 ( 5.039)	Loss 8.8991e-02 (9.1306e-02) 
2023-05-27 13:55:36.765475: train Epoch: [33][131/193]	Time  1.471 ( 5.577)	Data  0.908 ( 5.008)	Loss 1.4424e-01 (9.1707e-02) 
2023-05-27 13:55:48.244148: train Epoch: [33][132/193]	Time 11.479 ( 5.621)	Data 10.901 ( 5.052)	Loss 1.0581e-01 (9.1813e-02) 
2023-05-27 13:55:49.575015: train Epoch: [33][133/193]	Time  1.331 ( 5.589)	Data  0.769 ( 5.020)	Loss 1.1893e-01 (9.2015e-02) 
2023-05-27 13:56:01.468158: train Epoch: [33][134/193]	Time 11.893 ( 5.636)	Data 11.314 ( 5.067)	Loss 8.6315e-02 (9.1973e-02) 
2023-05-27 13:56:02.573813: train Epoch: [33][135/193]	Time  1.106 ( 5.603)	Data  0.538 ( 5.033)	Loss 3.4128e-01 (9.3806e-02) 
2023-05-27 13:56:13.554168: train Epoch: [33][136/193]	Time 10.980 ( 5.642)	Data 10.409 ( 5.073)	Loss 2.2313e-01 (9.4750e-02) 
2023-05-27 13:56:15.239282: train Epoch: [33][137/193]	Time  1.685 ( 5.613)	Data  1.122 ( 5.044)	Loss 1.2793e-01 (9.4991e-02) 
2023-05-27 13:56:26.513798: train Epoch: [33][138/193]	Time 11.275 ( 5.654)	Data 10.700 ( 5.085)	Loss 6.9102e-02 (9.4804e-02) 
2023-05-27 13:56:28.058997: train Epoch: [33][139/193]	Time  1.545 ( 5.625)	Data  0.984 ( 5.055)	Loss 9.6999e-02 (9.4820e-02) 
2023-05-27 13:56:39.056671: train Epoch: [33][140/193]	Time 10.998 ( 5.663)	Data 10.418 ( 5.093)	Loss 1.6264e-01 (9.5301e-02) 
2023-05-27 13:56:40.809134: train Epoch: [33][141/193]	Time  1.752 ( 5.635)	Data  1.189 ( 5.066)	Loss 1.1454e-01 (9.5437e-02) 
2023-05-27 13:56:51.535647: train Epoch: [33][142/193]	Time 10.726 ( 5.671)	Data 10.145 ( 5.101)	Loss 9.1263e-02 (9.5407e-02) 
2023-05-27 13:56:53.753194: train Epoch: [33][143/193]	Time  2.218 ( 5.647)	Data  1.655 ( 5.077)	Loss 5.8414e-02 (9.5151e-02) 
2023-05-27 13:57:04.559633: train Epoch: [33][144/193]	Time 10.806 ( 5.682)	Data 10.244 ( 5.113)	Loss 8.8263e-02 (9.5103e-02) 
2023-05-27 13:57:06.336852: train Epoch: [33][145/193]	Time  1.777 ( 5.656)	Data  1.216 ( 5.086)	Loss 8.1517e-02 (9.5010e-02) 
2023-05-27 13:57:16.831577: train Epoch: [33][146/193]	Time 10.495 ( 5.689)	Data  9.927 ( 5.119)	Loss 8.3711e-02 (9.4933e-02) 
2023-05-27 13:57:18.870821: train Epoch: [33][147/193]	Time  2.039 ( 5.664)	Data  1.478 ( 5.095)	Loss 4.3485e-02 (9.4585e-02) 
2023-05-27 13:57:29.444243: train Epoch: [33][148/193]	Time 10.573 ( 5.697)	Data  9.982 ( 5.128)	Loss 6.2986e-02 (9.4373e-02) 
2023-05-27 13:57:31.399927: train Epoch: [33][149/193]	Time  1.956 ( 5.672)	Data  1.394 ( 5.103)	Loss 1.5011e-01 (9.4745e-02) 
2023-05-27 13:57:42.010953: train Epoch: [33][150/193]	Time 10.611 ( 5.705)	Data 10.029 ( 5.135)	Loss 5.7784e-02 (9.4500e-02) 
2023-05-27 13:57:44.265591: train Epoch: [33][151/193]	Time  2.255 ( 5.682)	Data  1.693 ( 5.113)	Loss 3.0898e-01 (9.5911e-02) 
2023-05-27 13:57:54.759164: train Epoch: [33][152/193]	Time 10.494 ( 5.713)	Data  9.926 ( 5.144)	Loss 1.0692e-01 (9.5983e-02) 
2023-05-27 13:57:56.568344: train Epoch: [33][153/193]	Time  1.809 ( 5.688)	Data  1.248 ( 5.119)	Loss 8.4558e-02 (9.5909e-02) 
2023-05-27 13:58:08.105819: train Epoch: [33][154/193]	Time 11.537 ( 5.726)	Data 10.967 ( 5.156)	Loss 1.3920e-01 (9.6188e-02) 
2023-05-27 13:58:09.473266: train Epoch: [33][155/193]	Time  1.367 ( 5.698)	Data  0.805 ( 5.129)	Loss 9.9295e-02 (9.6208e-02) 
2023-05-27 13:58:20.996977: train Epoch: [33][156/193]	Time 11.524 ( 5.735)	Data 10.928 ( 5.166)	Loss 6.4239e-02 (9.6005e-02) 
2023-05-27 13:58:22.454133: train Epoch: [33][157/193]	Time  1.457 ( 5.708)	Data  0.886 ( 5.138)	Loss 1.0897e-01 (9.6087e-02) 
2023-05-27 13:58:33.438236: train Epoch: [33][158/193]	Time 10.984 ( 5.741)	Data 10.415 ( 5.172)	Loss 5.6909e-02 (9.5840e-02) 
2023-05-27 13:58:34.759955: train Epoch: [33][159/193]	Time  1.322 ( 5.713)	Data  0.753 ( 5.144)	Loss 2.0640e-01 (9.6531e-02) 
2023-05-27 13:58:46.690579: train Epoch: [33][160/193]	Time 11.931 ( 5.752)	Data 11.361 ( 5.183)	Loss 6.7475e-02 (9.6351e-02) 
2023-05-27 13:58:47.999907: train Epoch: [33][161/193]	Time  1.309 ( 5.725)	Data  0.747 ( 5.155)	Loss 2.0770e-01 (9.7038e-02) 
2023-05-27 13:58:59.570756: train Epoch: [33][162/193]	Time 11.571 ( 5.761)	Data 11.008 ( 5.191)	Loss 1.0172e-01 (9.7067e-02) 
2023-05-27 13:59:00.631827: train Epoch: [33][163/193]	Time  1.061 ( 5.732)	Data  0.498 ( 5.163)	Loss 1.0873e-01 (9.7138e-02) 
2023-05-27 13:59:12.292383: train Epoch: [33][164/193]	Time 11.661 ( 5.768)	Data 11.088 ( 5.198)	Loss 2.0325e-01 (9.7781e-02) 
2023-05-27 13:59:13.343094: train Epoch: [33][165/193]	Time  1.051 ( 5.739)	Data  0.489 ( 5.170)	Loss 8.6009e-02 (9.7710e-02) 
2023-05-27 13:59:24.533073: train Epoch: [33][166/193]	Time 11.190 ( 5.772)	Data 10.620 ( 5.203)	Loss 1.6613e-01 (9.8120e-02) 
2023-05-27 13:59:25.337012: train Epoch: [33][167/193]	Time  0.804 ( 5.742)	Data  0.237 ( 5.173)	Loss 8.3560e-02 (9.8033e-02) 
2023-05-27 13:59:37.453895: train Epoch: [33][168/193]	Time 12.117 ( 5.780)	Data 11.548 ( 5.211)	Loss 7.7157e-02 (9.7910e-02) 
2023-05-27 13:59:38.064454: train Epoch: [33][169/193]	Time  0.611 ( 5.750)	Data  0.042 ( 5.180)	Loss 5.5573e-02 (9.7661e-02) 
2023-05-27 13:59:50.754519: train Epoch: [33][170/193]	Time 12.690 ( 5.790)	Data 12.125 ( 5.221)	Loss 8.8632e-02 (9.7608e-02) 
2023-05-27 13:59:51.333506: train Epoch: [33][171/193]	Time  0.579 ( 5.760)	Data  0.001 ( 5.191)	Loss 1.0779e-01 (9.7667e-02) 
2023-05-27 14:00:03.393847: train Epoch: [33][172/193]	Time 12.060 ( 5.796)	Data 11.494 ( 5.227)	Loss 2.9067e-01 (9.8783e-02) 
2023-05-27 14:00:03.956608: train Epoch: [33][173/193]	Time  0.563 ( 5.766)	Data  0.001 ( 5.197)	Loss 1.0583e-01 (9.8823e-02) 
2023-05-27 14:00:16.438523: train Epoch: [33][174/193]	Time 12.482 ( 5.805)	Data 11.919 ( 5.236)	Loss 8.2113e-02 (9.8728e-02) 
2023-05-27 14:00:17.009975: train Epoch: [33][175/193]	Time  0.571 ( 5.775)	Data  0.001 ( 5.206)	Loss 6.2375e-02 (9.8521e-02) 
2023-05-27 14:00:28.804720: train Epoch: [33][176/193]	Time 11.795 ( 5.809)	Data 11.226 ( 5.240)	Loss 1.3174e-01 (9.8709e-02) 
2023-05-27 14:00:29.382477: train Epoch: [33][177/193]	Time  0.578 ( 5.780)	Data  0.001 ( 5.210)	Loss 5.0978e-02 (9.8441e-02) 
2023-05-27 14:00:42.038494: train Epoch: [33][178/193]	Time 12.656 ( 5.818)	Data 12.075 ( 5.249)	Loss 9.5067e-02 (9.8422e-02) 
2023-05-27 14:00:42.625450: train Epoch: [33][179/193]	Time  0.587 ( 5.789)	Data  0.001 ( 5.220)	Loss 1.1613e-01 (9.8520e-02) 
2023-05-27 14:00:54.436775: train Epoch: [33][180/193]	Time 11.811 ( 5.822)	Data 11.246 ( 5.253)	Loss 1.2317e-01 (9.8656e-02) 
2023-05-27 14:00:55.070753: train Epoch: [33][181/193]	Time  0.634 ( 5.794)	Data  0.068 ( 5.224)	Loss 1.2946e-01 (9.8826e-02) 
2023-05-27 14:01:07.342264: train Epoch: [33][182/193]	Time 12.272 ( 5.829)	Data 11.663 ( 5.260)	Loss 7.0519e-02 (9.8671e-02) 
2023-05-27 14:01:07.987319: train Epoch: [33][183/193]	Time  0.645 ( 5.801)	Data  0.072 ( 5.231)	Loss 1.0524e-01 (9.8707e-02) 
2023-05-27 14:01:20.322887: train Epoch: [33][184/193]	Time 12.336 ( 5.836)	Data 11.774 ( 5.267)	Loss 8.5455e-02 (9.8635e-02) 
2023-05-27 14:01:20.884429: train Epoch: [33][185/193]	Time  0.562 ( 5.808)	Data  0.001 ( 5.238)	Loss 1.1260e-01 (9.8710e-02) 
2023-05-27 14:01:33.004843: train Epoch: [33][186/193]	Time 12.120 ( 5.842)	Data 11.527 ( 5.272)	Loss 3.1105e-01 (9.9846e-02) 
2023-05-27 14:01:33.566355: train Epoch: [33][187/193]	Time  0.562 ( 5.814)	Data  0.001 ( 5.244)	Loss 1.2013e-01 (9.9954e-02) 
2023-05-27 14:01:46.101578: train Epoch: [33][188/193]	Time 12.535 ( 5.849)	Data 11.917 ( 5.279)	Loss 5.5084e-02 (9.9716e-02) 
2023-05-27 14:01:46.668656: train Epoch: [33][189/193]	Time  0.567 ( 5.821)	Data  0.001 ( 5.252)	Loss 8.4338e-02 (9.9635e-02) 
2023-05-27 14:01:58.932551: train Epoch: [33][190/193]	Time 12.264 ( 5.855)	Data 11.678 ( 5.285)	Loss 1.1741e-01 (9.9728e-02) 
2023-05-27 14:01:59.494020: train Epoch: [33][191/193]	Time  0.561 ( 5.828)	Data  0.001 ( 5.258)	Loss 4.9355e-02 (9.9466e-02) 
2023-05-27 14:02:10.376468: train Epoch: [33][192/193]	Time 10.882 ( 5.854)	Data 10.311 ( 5.284)	Loss 7.9200e-02 (9.9361e-02) 
2023-05-27 14:02:10.581402: Train Epoch done in 1129.9784424390236 s 
2023-05-27 14:02:19.470270: val Epoch: [33][ 0/72]	Time  7.768 ( 7.768)	Data  7.298 ( 7.298)	Loss 3.0826e-01 (3.0826e-01) 
2023-05-27 14:02:19.584803: val Epoch: [33][ 1/72]	Time  0.115 ( 3.941)	Data  0.001 ( 3.650)	Loss 9.2991e-02 (2.0063e-01) 
2023-05-27 14:02:25.512854: val Epoch: [33][ 2/72]	Time  5.928 ( 4.604)	Data  5.820 ( 4.373)	Loss 3.7572e-01 (2.5899e-01) 
2023-05-27 14:02:25.619050: val Epoch: [33][ 3/72]	Time  0.106 ( 3.479)	Data  0.001 ( 3.280)	Loss 1.0122e-01 (2.1955e-01) 
2023-05-27 14:02:31.827687: val Epoch: [33][ 4/72]	Time  6.209 ( 4.025)	Data  6.099 ( 3.844)	Loss 1.2546e-01 (2.0073e-01) 
2023-05-27 14:02:31.937310: val Epoch: [33][ 5/72]	Time  0.110 ( 3.373)	Data  0.001 ( 3.203)	Loss 5.6790e-02 (1.7674e-01) 
2023-05-27 14:02:38.182938: val Epoch: [33][ 6/72]	Time  6.246 ( 3.783)	Data  6.137 ( 3.622)	Loss 5.8838e-02 (1.5990e-01) 
2023-05-27 14:02:38.290854: val Epoch: [33][ 7/72]	Time  0.108 ( 3.324)	Data  0.001 ( 3.170)	Loss 1.6695e-01 (1.6078e-01) 
2023-05-27 14:02:44.674987: val Epoch: [33][ 8/72]	Time  6.384 ( 3.664)	Data  6.279 ( 3.515)	Loss 5.2847e-02 (1.4879e-01) 
2023-05-27 14:02:44.780245: val Epoch: [33][ 9/72]	Time  0.105 ( 3.308)	Data  0.000 ( 3.164)	Loss 5.6858e-01 (1.9077e-01) 
2023-05-27 14:02:50.900522: val Epoch: [33][10/72]	Time  6.120 ( 3.563)	Data  6.014 ( 3.423)	Loss 3.7072e-01 (2.0713e-01) 
2023-05-27 14:02:51.005884: val Epoch: [33][11/72]	Time  0.105 ( 3.275)	Data  0.001 ( 3.138)	Loss 5.4969e-02 (1.9445e-01) 
2023-05-27 14:02:57.241965: val Epoch: [33][12/72]	Time  6.236 ( 3.503)	Data  6.131 ( 3.368)	Loss 1.5083e-01 (1.9109e-01) 
2023-05-27 14:02:57.347745: val Epoch: [33][13/72]	Time  0.106 ( 3.260)	Data  0.001 ( 3.127)	Loss 6.1283e-02 (1.8182e-01) 
2023-05-27 14:03:03.546607: val Epoch: [33][14/72]	Time  6.199 ( 3.456)	Data  6.088 ( 3.325)	Loss 6.5268e-02 (1.7405e-01) 
2023-05-27 14:03:03.656759: val Epoch: [33][15/72]	Time  0.110 ( 3.247)	Data  0.001 ( 3.117)	Loss 4.5919e-02 (1.6604e-01) 
2023-05-27 14:03:09.729510: val Epoch: [33][16/72]	Time  6.073 ( 3.413)	Data  5.965 ( 3.284)	Loss 8.1207e-02 (1.6105e-01) 
2023-05-27 14:03:09.836654: val Epoch: [33][17/72]	Time  0.107 ( 3.230)	Data  0.000 ( 3.102)	Loss 6.9496e-02 (1.5596e-01) 
2023-05-27 14:03:16.141250: val Epoch: [33][18/72]	Time  6.305 ( 3.392)	Data  6.199 ( 3.265)	Loss 8.2381e-02 (1.5209e-01) 
2023-05-27 14:03:16.248157: val Epoch: [33][19/72]	Time  0.107 ( 3.227)	Data  0.001 ( 3.102)	Loss 1.2480e-01 (1.5073e-01) 
2023-05-27 14:03:22.652361: val Epoch: [33][20/72]	Time  6.404 ( 3.379)	Data  6.299 ( 3.254)	Loss 4.7148e-02 (1.4579e-01) 
2023-05-27 14:03:22.757937: val Epoch: [33][21/72]	Time  0.106 ( 3.230)	Data  0.000 ( 3.106)	Loss 8.5482e-02 (1.4305e-01) 
2023-05-27 14:03:28.659114: val Epoch: [33][22/72]	Time  5.901 ( 3.346)	Data  5.792 ( 3.223)	Loss 8.4215e-02 (1.4050e-01) 
2023-05-27 14:03:28.769751: val Epoch: [33][23/72]	Time  0.111 ( 3.211)	Data  0.001 ( 3.089)	Loss 6.1007e-02 (1.3718e-01) 
2023-05-27 14:03:34.855256: val Epoch: [33][24/72]	Time  6.086 ( 3.326)	Data  5.981 ( 3.204)	Loss 4.7297e-01 (1.5061e-01) 
2023-05-27 14:03:35.045558: val Epoch: [33][25/72]	Time  0.190 ( 3.206)	Data  0.084 ( 3.084)	Loss 1.1616e-01 (1.4929e-01) 
2023-05-27 14:03:41.052698: val Epoch: [33][26/72]	Time  6.007 ( 3.309)	Data  5.901 ( 3.189)	Loss 7.2776e-02 (1.4646e-01) 
2023-05-27 14:03:41.804670: val Epoch: [33][27/72]	Time  0.752 ( 3.218)	Data  0.645 ( 3.098)	Loss 1.0026e-01 (1.4481e-01) 
2023-05-27 14:03:47.071932: val Epoch: [33][28/72]	Time  5.267 ( 3.289)	Data  5.162 ( 3.169)	Loss 7.9993e-02 (1.4257e-01) 
2023-05-27 14:03:48.454648: val Epoch: [33][29/72]	Time  1.383 ( 3.225)	Data  1.263 ( 3.105)	Loss 1.1293e-01 (1.4158e-01) 
2023-05-27 14:03:53.125055: val Epoch: [33][30/72]	Time  4.670 ( 3.272)	Data  4.561 ( 3.152)	Loss 6.2155e-02 (1.3902e-01) 
2023-05-27 14:03:54.426010: val Epoch: [33][31/72]	Time  1.301 ( 3.210)	Data  1.180 ( 3.091)	Loss 5.3299e-02 (1.3634e-01) 
2023-05-27 14:03:59.174855: val Epoch: [33][32/72]	Time  4.749 ( 3.257)	Data  4.643 ( 3.138)	Loss 5.1744e-02 (1.3378e-01) 
2023-05-27 14:04:00.510586: val Epoch: [33][33/72]	Time  1.336 ( 3.200)	Data  1.230 ( 3.082)	Loss 6.0648e-02 (1.3163e-01) 
2023-05-27 14:04:05.239970: val Epoch: [33][34/72]	Time  4.729 ( 3.244)	Data  4.624 ( 3.126)	Loss 2.6410e-01 (1.3541e-01) 
2023-05-27 14:04:06.993138: val Epoch: [33][35/72]	Time  1.753 ( 3.203)	Data  1.647 ( 3.085)	Loss 3.9216e-01 (1.4254e-01) 
2023-05-27 14:04:11.371417: val Epoch: [33][36/72]	Time  4.378 ( 3.234)	Data  4.273 ( 3.117)	Loss 8.1182e-02 (1.4089e-01) 
2023-05-27 14:04:13.520943: val Epoch: [33][37/72]	Time  2.150 ( 3.206)	Data  2.030 ( 3.088)	Loss 7.2623e-02 (1.3909e-01) 
2023-05-27 14:04:17.639113: val Epoch: [33][38/72]	Time  4.118 ( 3.229)	Data  4.013 ( 3.112)	Loss 1.1911e-01 (1.3858e-01) 
2023-05-27 14:04:20.296365: val Epoch: [33][39/72]	Time  2.657 ( 3.215)	Data  2.552 ( 3.098)	Loss 8.6251e-02 (1.3727e-01) 
2023-05-27 14:04:23.834823: val Epoch: [33][40/72]	Time  3.538 ( 3.223)	Data  3.432 ( 3.106)	Loss 5.0120e-02 (1.3514e-01) 
2023-05-27 14:04:26.694781: val Epoch: [33][41/72]	Time  2.860 ( 3.214)	Data  2.755 ( 3.098)	Loss 1.0642e-01 (1.3446e-01) 
2023-05-27 14:04:30.124926: val Epoch: [33][42/72]	Time  3.430 ( 3.219)	Data  3.325 ( 3.103)	Loss 9.6574e-02 (1.3358e-01) 
2023-05-27 14:04:33.007323: val Epoch: [33][43/72]	Time  2.882 ( 3.211)	Data  2.776 ( 3.096)	Loss 3.0255e-01 (1.3742e-01) 
2023-05-27 14:04:36.514545: val Epoch: [33][44/72]	Time  3.507 ( 3.218)	Data  3.401 ( 3.102)	Loss 9.8403e-02 (1.3655e-01) 
2023-05-27 14:04:39.469319: val Epoch: [33][45/72]	Time  2.955 ( 3.212)	Data  2.841 ( 3.097)	Loss 1.3561e-01 (1.3653e-01) 
2023-05-27 14:04:42.584326: val Epoch: [33][46/72]	Time  3.115 ( 3.210)	Data  3.008 ( 3.095)	Loss 8.4723e-02 (1.3543e-01) 
2023-05-27 14:04:45.733000: val Epoch: [33][47/72]	Time  3.149 ( 3.209)	Data  3.042 ( 3.094)	Loss 1.9381e-01 (1.3665e-01) 
2023-05-27 14:04:49.179401: val Epoch: [33][48/72]	Time  3.446 ( 3.214)	Data  3.341 ( 3.099)	Loss 3.1310e-01 (1.4025e-01) 
2023-05-27 14:04:51.855064: val Epoch: [33][49/72]	Time  2.676 ( 3.203)	Data  2.566 ( 3.088)	Loss 6.6406e-02 (1.3877e-01) 
2023-05-27 14:04:55.252056: val Epoch: [33][50/72]	Time  3.397 ( 3.207)	Data  3.292 ( 3.092)	Loss 2.4624e-01 (1.4088e-01) 
2023-05-27 14:04:58.015119: val Epoch: [33][51/72]	Time  2.763 ( 3.198)	Data  2.657 ( 3.084)	Loss 5.6891e-02 (1.3926e-01) 
2023-05-27 14:05:01.495404: val Epoch: [33][52/72]	Time  3.480 ( 3.204)	Data  3.375 ( 3.089)	Loss 5.0509e-01 (1.4616e-01) 
2023-05-27 14:05:04.428227: val Epoch: [33][53/72]	Time  2.933 ( 3.199)	Data  2.827 ( 3.084)	Loss 2.1495e-01 (1.4744e-01) 
2023-05-27 14:05:07.608110: val Epoch: [33][54/72]	Time  3.180 ( 3.198)	Data  3.073 ( 3.084)	Loss 5.2887e-02 (1.4572e-01) 
2023-05-27 14:05:10.768377: val Epoch: [33][55/72]	Time  3.160 ( 3.198)	Data  3.055 ( 3.084)	Loss 2.4582e-01 (1.4751e-01) 
2023-05-27 14:05:13.890616: val Epoch: [33][56/72]	Time  3.122 ( 3.196)	Data  3.017 ( 3.082)	Loss 1.5755e-01 (1.4768e-01) 
2023-05-27 14:05:16.148592: val Epoch: [33][57/72]	Time  2.258 ( 3.180)	Data  2.151 ( 3.066)	Loss 6.5650e-02 (1.4627e-01) 
2023-05-27 14:05:18.744526: val Epoch: [33][58/72]	Time  2.596 ( 3.170)	Data  2.491 ( 3.057)	Loss 6.3369e-02 (1.4486e-01) 
2023-05-27 14:05:21.367473: val Epoch: [33][59/72]	Time  2.623 ( 3.161)	Data  2.507 ( 3.047)	Loss 3.4569e-01 (1.4821e-01) 
2023-05-27 14:05:23.807196: val Epoch: [33][60/72]	Time  2.440 ( 3.149)	Data  2.335 ( 3.036)	Loss 2.0308e-01 (1.4911e-01) 
2023-05-27 14:05:26.260262: val Epoch: [33][61/72]	Time  2.453 ( 3.138)	Data  2.237 ( 3.023)	Loss 7.0948e-02 (1.4785e-01) 
2023-05-27 14:05:28.840499: val Epoch: [33][62/72]	Time  2.580 ( 3.129)	Data  2.468 ( 3.014)	Loss 1.1090e-01 (1.4726e-01) 
2023-05-27 14:05:30.930650: val Epoch: [33][63/72]	Time  2.090 ( 3.113)	Data  1.981 ( 2.998)	Loss 5.2954e-02 (1.4579e-01) 
2023-05-27 14:05:33.890965: val Epoch: [33][64/72]	Time  2.960 ( 3.111)	Data  2.850 ( 2.996)	Loss 1.4634e-01 (1.4580e-01) 
2023-05-27 14:05:35.769373: val Epoch: [33][65/72]	Time  1.878 ( 3.092)	Data  1.770 ( 2.977)	Loss 1.9029e-01 (1.4647e-01) 
2023-05-27 14:05:39.178797: val Epoch: [33][66/72]	Time  3.409 ( 3.097)	Data  3.301 ( 2.982)	Loss 1.9233e-01 (1.4716e-01) 
2023-05-27 14:05:40.954740: val Epoch: [33][67/72]	Time  1.776 ( 3.077)	Data  1.628 ( 2.962)	Loss 3.3837e-01 (1.4997e-01) 
2023-05-27 14:05:44.244005: val Epoch: [33][68/72]	Time  3.289 ( 3.080)	Data  3.181 ( 2.965)	Loss 5.3930e-02 (1.4858e-01) 
2023-05-27 14:05:46.136399: val Epoch: [33][69/72]	Time  1.892 ( 3.063)	Data  1.783 ( 2.948)	Loss 7.4177e-02 (1.4751e-01) 
2023-05-27 14:05:49.178915: val Epoch: [33][70/72]	Time  3.043 ( 3.063)	Data  2.937 ( 2.948)	Loss 2.9208e-01 (1.4955e-01) 
2023-05-27 14:05:51.056182: val Epoch: [33][71/72]	Time  1.877 ( 3.047)	Data  1.754 ( 2.932)	Loss 1.0862e-01 (1.4898e-01) 
2023-05-27 14:05:51.400327: Epoch 33 :Val : ['ET : 0.7302044630050659', 'TC : 0.7612048387527466', 'WT : 0.8268835544586182'] 
2023-05-27 14:05:51.401299: Epoch 33 :Val : ['ET : 0.7302044630050659', 'TC : 0.7612048387527466', 'WT : 0.8268835544586182'] 
2023-05-27 14:05:51.406262: Val epoch done in 220.82486027097912 s 
2023-05-27 14:05:51.416997: Batches per epoch:  193 
2023-05-27 14:06:04.291204: train Epoch: [34][  0/193]	Time 12.874 (12.874)	Data 12.260 (12.260)	Loss 8.9767e-02 (8.9767e-02) 
2023-05-27 14:06:04.857872: train Epoch: [34][  1/193]	Time  0.567 ( 6.720)	Data  0.001 ( 6.130)	Loss 2.0070e-01 (1.4523e-01) 
2023-05-27 14:06:16.740990: train Epoch: [34][  2/193]	Time 11.883 ( 8.441)	Data 11.303 ( 7.855)	Loss 8.4224e-02 (1.2490e-01) 
2023-05-27 14:06:17.304463: train Epoch: [34][  3/193]	Time  0.563 ( 6.472)	Data  0.001 ( 5.891)	Loss 8.6133e-02 (1.1521e-01) 
2023-05-27 14:06:29.015681: train Epoch: [34][  4/193]	Time 11.711 ( 7.520)	Data 11.139 ( 6.941)	Loss 1.2094e-01 (1.1635e-01) 
2023-05-27 14:06:29.583513: train Epoch: [34][  5/193]	Time  0.568 ( 6.361)	Data  0.001 ( 5.784)	Loss 9.8261e-02 (1.1334e-01) 
2023-05-27 14:06:41.757780: train Epoch: [34][  6/193]	Time 12.174 ( 7.191)	Data 11.605 ( 6.616)	Loss 6.9132e-02 (1.0702e-01) 
2023-05-27 14:06:42.325145: train Epoch: [34][  7/193]	Time  0.567 ( 6.363)	Data  0.001 ( 5.789)	Loss 6.8661e-02 (1.0223e-01) 
2023-05-27 14:06:54.522321: train Epoch: [34][  8/193]	Time 12.197 ( 7.012)	Data 11.635 ( 6.438)	Loss 6.1178e-02 (9.7666e-02) 
2023-05-27 14:06:55.085320: train Epoch: [34][  9/193]	Time  0.563 ( 6.367)	Data  0.001 ( 5.795)	Loss 7.9773e-02 (9.5877e-02) 
2023-05-27 14:07:06.520024: train Epoch: [34][ 10/193]	Time 11.435 ( 6.828)	Data 10.869 ( 6.256)	Loss 9.2547e-02 (9.5574e-02) 
2023-05-27 14:07:07.085555: train Epoch: [34][ 11/193]	Time  0.566 ( 6.306)	Data  0.001 ( 5.735)	Loss 4.9134e-02 (9.1704e-02) 
2023-05-27 14:07:19.038759: train Epoch: [34][ 12/193]	Time 11.953 ( 6.740)	Data 11.391 ( 6.170)	Loss 9.7026e-02 (9.2114e-02) 
2023-05-27 14:07:19.601593: train Epoch: [34][ 13/193]	Time  0.563 ( 6.299)	Data  0.001 ( 5.729)	Loss 5.4919e-02 (8.9457e-02) 
2023-05-27 14:07:31.673421: train Epoch: [34][ 14/193]	Time 12.072 ( 6.684)	Data 11.510 ( 6.115)	Loss 1.3123e-01 (9.2242e-02) 
2023-05-27 14:07:32.236213: train Epoch: [34][ 15/193]	Time  0.563 ( 6.301)	Data  0.001 ( 5.732)	Loss 8.4397e-02 (9.1752e-02) 
2023-05-27 14:07:43.968677: train Epoch: [34][ 16/193]	Time 11.732 ( 6.621)	Data 11.166 ( 6.052)	Loss 6.5727e-02 (9.0221e-02) 
2023-05-27 14:07:44.534562: train Epoch: [34][ 17/193]	Time  0.566 ( 6.284)	Data  0.001 ( 5.716)	Loss 8.6406e-02 (9.0009e-02) 
2023-05-27 14:07:56.009860: train Epoch: [34][ 18/193]	Time 11.475 ( 6.557)	Data 10.912 ( 5.989)	Loss 1.1694e-01 (9.1426e-02) 
2023-05-27 14:07:56.572952: train Epoch: [34][ 19/193]	Time  0.563 ( 6.258)	Data  0.001 ( 5.690)	Loss 5.1696e-01 (1.1270e-01) 
2023-05-27 14:08:08.613666: train Epoch: [34][ 20/193]	Time 12.041 ( 6.533)	Data 11.478 ( 5.966)	Loss 8.2406e-02 (1.1126e-01) 
2023-05-27 14:08:09.178617: train Epoch: [34][ 21/193]	Time  0.565 ( 6.262)	Data  0.001 ( 5.694)	Loss 6.0043e-02 (1.0893e-01) 
2023-05-27 14:08:19.699567: train Epoch: [34][ 22/193]	Time 10.521 ( 6.447)	Data  9.958 ( 5.880)	Loss 1.1431e-01 (1.0917e-01) 
2023-05-27 14:08:20.264696: train Epoch: [34][ 23/193]	Time  0.565 ( 6.202)	Data  0.001 ( 5.635)	Loss 7.9791e-02 (1.0794e-01) 
2023-05-27 14:08:29.953808: train Epoch: [34][ 24/193]	Time  9.689 ( 6.341)	Data  9.101 ( 5.774)	Loss 1.0121e-01 (1.0767e-01) 
2023-05-27 14:08:30.516719: train Epoch: [34][ 25/193]	Time  0.563 ( 6.119)	Data  0.001 ( 5.552)	Loss 8.1441e-02 (1.0666e-01) 
2023-05-27 14:08:39.485955: train Epoch: [34][ 26/193]	Time  8.969 ( 6.225)	Data  8.405 ( 5.657)	Loss 4.8955e-02 (1.0453e-01) 
2023-05-27 14:08:40.106342: train Epoch: [34][ 27/193]	Time  0.620 ( 6.025)	Data  0.045 ( 5.457)	Loss 7.6697e-02 (1.0353e-01) 
2023-05-27 14:08:50.856059: train Epoch: [34][ 28/193]	Time 10.750 ( 6.188)	Data 10.188 ( 5.620)	Loss 7.2309e-02 (1.0246e-01) 
2023-05-27 14:08:51.822105: train Epoch: [34][ 29/193]	Time  0.966 ( 6.013)	Data  0.405 ( 5.446)	Loss 9.0592e-02 (1.0206e-01) 
2023-05-27 14:09:03.060724: train Epoch: [34][ 30/193]	Time 11.239 ( 6.182)	Data 10.674 ( 5.615)	Loss 7.7855e-02 (1.0128e-01) 
2023-05-27 14:09:04.279548: train Epoch: [34][ 31/193]	Time  1.219 ( 6.027)	Data  0.657 ( 5.460)	Loss 4.4099e-02 (9.9493e-02) 
2023-05-27 14:09:15.402526: train Epoch: [34][ 32/193]	Time 11.123 ( 6.181)	Data 10.558 ( 5.614)	Loss 9.8310e-02 (9.9457e-02) 
2023-05-27 14:09:15.966141: train Epoch: [34][ 33/193]	Time  0.564 ( 6.016)	Data  0.001 ( 5.449)	Loss 1.0849e-01 (9.9722e-02) 
2023-05-27 14:09:25.280845: train Epoch: [34][ 34/193]	Time  9.315 ( 6.110)	Data  8.743 ( 5.543)	Loss 2.3238e-01 (1.0351e-01) 
2023-05-27 14:09:25.856856: train Epoch: [34][ 35/193]	Time  0.576 ( 5.957)	Data  0.014 ( 5.390)	Loss 1.5853e-01 (1.0504e-01) 
2023-05-27 14:09:35.280011: train Epoch: [34][ 36/193]	Time  9.423 ( 6.050)	Data  8.859 ( 5.483)	Loss 9.6987e-02 (1.0482e-01) 
2023-05-27 14:09:35.843589: train Epoch: [34][ 37/193]	Time  0.564 ( 5.906)	Data  0.001 ( 5.339)	Loss 5.7450e-02 (1.0358e-01) 
2023-05-27 14:09:45.792801: train Epoch: [34][ 38/193]	Time  9.949 ( 6.010)	Data  9.387 ( 5.443)	Loss 7.5068e-02 (1.0285e-01) 
2023-05-27 14:09:46.355730: train Epoch: [34][ 39/193]	Time  0.563 ( 5.873)	Data  0.001 ( 5.307)	Loss 1.2189e-01 (1.0332e-01) 
2023-05-27 14:09:55.944292: train Epoch: [34][ 40/193]	Time  9.589 ( 5.964)	Data  9.025 ( 5.398)	Loss 9.6037e-02 (1.0314e-01) 
2023-05-27 14:09:56.517781: train Epoch: [34][ 41/193]	Time  0.573 ( 5.836)	Data  0.001 ( 5.269)	Loss 1.6332e-01 (1.0458e-01) 
2023-05-27 14:10:08.159093: train Epoch: [34][ 42/193]	Time 11.641 ( 5.971)	Data 11.073 ( 5.404)	Loss 1.0959e-01 (1.0469e-01) 
2023-05-27 14:10:08.731288: train Epoch: [34][ 43/193]	Time  0.572 ( 5.848)	Data  0.001 ( 5.281)	Loss 9.4767e-02 (1.0447e-01) 
2023-05-27 14:10:20.826415: train Epoch: [34][ 44/193]	Time 12.095 ( 5.987)	Data 11.531 ( 5.420)	Loss 1.5176e-01 (1.0552e-01) 
2023-05-27 14:10:21.401495: train Epoch: [34][ 45/193]	Time  0.575 ( 5.869)	Data  0.001 ( 5.302)	Loss 1.5014e-01 (1.0649e-01) 
2023-05-27 14:10:33.298306: train Epoch: [34][ 46/193]	Time 11.897 ( 5.997)	Data 11.296 ( 5.430)	Loss 1.0626e-01 (1.0648e-01) 
2023-05-27 14:10:33.860270: train Epoch: [34][ 47/193]	Time  0.562 ( 5.884)	Data  0.001 ( 5.317)	Loss 5.5976e-02 (1.0543e-01) 
2023-05-27 14:10:43.715846: train Epoch: [34][ 48/193]	Time  9.856 ( 5.965)	Data  9.256 ( 5.397)	Loss 1.1705e-01 (1.0567e-01) 
2023-05-27 14:10:44.286147: train Epoch: [34][ 49/193]	Time  0.570 ( 5.857)	Data  0.001 ( 5.289)	Loss 1.2547e-01 (1.0606e-01) 
2023-05-27 14:10:53.634006: train Epoch: [34][ 50/193]	Time  9.348 ( 5.926)	Data  8.765 ( 5.357)	Loss 6.2281e-02 (1.0521e-01) 
2023-05-27 14:10:54.197041: train Epoch: [34][ 51/193]	Time  0.563 ( 5.823)	Data  0.001 ( 5.254)	Loss 1.0503e-01 (1.0520e-01) 
2023-05-27 14:11:03.857269: train Epoch: [34][ 52/193]	Time  9.660 ( 5.895)	Data  9.089 ( 5.327)	Loss 7.6825e-02 (1.0467e-01) 
2023-05-27 14:11:04.426664: train Epoch: [34][ 53/193]	Time  0.569 ( 5.796)	Data  0.001 ( 5.228)	Loss 6.4351e-02 (1.0392e-01) 
2023-05-27 14:11:13.733092: train Epoch: [34][ 54/193]	Time  9.306 ( 5.860)	Data  8.673 ( 5.291)	Loss 5.5227e-02 (1.0304e-01) 
2023-05-27 14:11:14.301871: train Epoch: [34][ 55/193]	Time  0.569 ( 5.766)	Data  0.001 ( 5.196)	Loss 1.5040e-01 (1.0388e-01) 
2023-05-27 14:11:23.717370: train Epoch: [34][ 56/193]	Time  9.416 ( 5.830)	Data  8.805 ( 5.260)	Loss 6.6878e-02 (1.0323e-01) 
2023-05-27 14:11:24.285317: train Epoch: [34][ 57/193]	Time  0.568 ( 5.739)	Data  0.001 ( 5.169)	Loss 7.0129e-02 (1.0266e-01) 
2023-05-27 14:11:34.239529: train Epoch: [34][ 58/193]	Time  9.954 ( 5.811)	Data  9.385 ( 5.240)	Loss 8.1931e-02 (1.0231e-01) 
2023-05-27 14:11:34.808192: train Epoch: [34][ 59/193]	Time  0.569 ( 5.723)	Data  0.001 ( 5.153)	Loss 2.6232e-01 (1.0498e-01) 
2023-05-27 14:11:46.659836: train Epoch: [34][ 60/193]	Time 11.852 ( 5.824)	Data 11.280 ( 5.253)	Loss 8.5927e-02 (1.0466e-01) 
2023-05-27 14:11:47.232095: train Epoch: [34][ 61/193]	Time  0.572 ( 5.739)	Data  0.001 ( 5.169)	Loss 1.1843e-01 (1.0489e-01) 
2023-05-27 14:11:59.023356: train Epoch: [34][ 62/193]	Time 11.791 ( 5.835)	Data 11.231 ( 5.265)	Loss 1.1805e-01 (1.0510e-01) 
2023-05-27 14:11:59.585245: train Epoch: [34][ 63/193]	Time  0.562 ( 5.753)	Data  0.001 ( 5.183)	Loss 1.2637e-01 (1.0543e-01) 
2023-05-27 14:12:11.439598: train Epoch: [34][ 64/193]	Time 11.854 ( 5.846)	Data 11.208 ( 5.275)	Loss 6.3721e-02 (1.0479e-01) 
2023-05-27 14:12:12.006366: train Epoch: [34][ 65/193]	Time  0.567 ( 5.766)	Data  0.001 ( 5.196)	Loss 6.3853e-02 (1.0417e-01) 
2023-05-27 14:12:24.075259: train Epoch: [34][ 66/193]	Time 12.069 ( 5.861)	Data 11.490 ( 5.289)	Loss 7.4858e-02 (1.0373e-01) 
2023-05-27 14:12:24.636836: train Epoch: [34][ 67/193]	Time  0.562 ( 5.783)	Data  0.001 ( 5.212)	Loss 9.4653e-02 (1.0360e-01) 
2023-05-27 14:12:36.839247: train Epoch: [34][ 68/193]	Time 12.202 ( 5.876)	Data 11.631 ( 5.305)	Loss 1.3788e-01 (1.0409e-01) 
2023-05-27 14:12:37.407950: train Epoch: [34][ 69/193]	Time  0.569 ( 5.800)	Data  0.001 ( 5.229)	Loss 1.8319e-01 (1.0522e-01) 
2023-05-27 14:12:49.375778: train Epoch: [34][ 70/193]	Time 11.968 ( 5.887)	Data 11.379 ( 5.316)	Loss 1.0542e-01 (1.0522e-01) 
2023-05-27 14:12:49.945510: train Epoch: [34][ 71/193]	Time  0.570 ( 5.813)	Data  0.001 ( 5.242)	Loss 5.1389e-02 (1.0448e-01) 
2023-05-27 14:13:01.385535: train Epoch: [34][ 72/193]	Time 11.440 ( 5.890)	Data 10.879 ( 5.319)	Loss 1.0766e-01 (1.0452e-01) 
2023-05-27 14:13:01.955789: train Epoch: [34][ 73/193]	Time  0.570 ( 5.818)	Data  0.001 ( 5.247)	Loss 7.5048e-02 (1.0412e-01) 
2023-05-27 14:13:13.709677: train Epoch: [34][ 74/193]	Time 11.754 ( 5.897)	Data 11.126 ( 5.325)	Loss 8.1025e-02 (1.0381e-01) 
2023-05-27 14:13:14.275492: train Epoch: [34][ 75/193]	Time  0.566 ( 5.827)	Data  0.001 ( 5.255)	Loss 6.3450e-02 (1.0328e-01) 
2023-05-27 14:13:25.906713: train Epoch: [34][ 76/193]	Time 11.631 ( 5.902)	Data 11.058 ( 5.331)	Loss 1.3676e-01 (1.0372e-01) 
2023-05-27 14:13:26.549805: train Epoch: [34][ 77/193]	Time  0.643 ( 5.835)	Data  0.001 ( 5.262)	Loss 1.3986e-01 (1.0418e-01) 
2023-05-27 14:13:38.743958: train Epoch: [34][ 78/193]	Time 12.194 ( 5.916)	Data 11.625 ( 5.343)	Loss 1.4803e-01 (1.0474e-01) 
2023-05-27 14:13:39.308992: train Epoch: [34][ 79/193]	Time  0.565 ( 5.849)	Data  0.001 ( 5.276)	Loss 8.9435e-02 (1.0455e-01) 
2023-05-27 14:13:51.109176: train Epoch: [34][ 80/193]	Time 11.800 ( 5.922)	Data 11.233 ( 5.350)	Loss 2.3633e-01 (1.0617e-01) 
2023-05-27 14:13:51.681449: train Epoch: [34][ 81/193]	Time  0.572 ( 5.857)	Data  0.001 ( 5.285)	Loss 1.3615e-01 (1.0654e-01) 
2023-05-27 14:14:03.836567: train Epoch: [34][ 82/193]	Time 12.155 ( 5.933)	Data 11.552 ( 5.360)	Loss 7.8213e-02 (1.0620e-01) 
2023-05-27 14:14:04.466841: train Epoch: [34][ 83/193]	Time  0.630 ( 5.870)	Data  0.005 ( 5.296)	Loss 7.4350e-02 (1.0582e-01) 
2023-05-27 14:14:16.536545: train Epoch: [34][ 84/193]	Time 12.070 ( 5.943)	Data 11.503 ( 5.369)	Loss 1.1160e-01 (1.0589e-01) 
2023-05-27 14:14:17.114820: train Epoch: [34][ 85/193]	Time  0.578 ( 5.880)	Data  0.001 ( 5.307)	Loss 5.5660e-02 (1.0530e-01) 
2023-05-27 14:14:27.910788: train Epoch: [34][ 86/193]	Time 10.796 ( 5.937)	Data 10.235 ( 5.364)	Loss 5.8427e-02 (1.0476e-01) 
2023-05-27 14:14:28.488508: train Epoch: [34][ 87/193]	Time  0.578 ( 5.876)	Data  0.001 ( 5.303)	Loss 1.3582e-01 (1.0512e-01) 
2023-05-27 14:14:39.555239: train Epoch: [34][ 88/193]	Time 11.067 ( 5.934)	Data 10.487 ( 5.361)	Loss 5.7463e-02 (1.0458e-01) 
2023-05-27 14:14:40.134639: train Epoch: [34][ 89/193]	Time  0.579 ( 5.875)	Data  0.001 ( 5.301)	Loss 4.3104e-02 (1.0390e-01) 
2023-05-27 14:14:52.332327: train Epoch: [34][ 90/193]	Time 12.198 ( 5.944)	Data 11.587 ( 5.370)	Loss 1.5665e-01 (1.0448e-01) 
2023-05-27 14:14:52.904254: train Epoch: [34][ 91/193]	Time  0.572 ( 5.886)	Data  0.001 ( 5.312)	Loss 7.1834e-02 (1.0412e-01) 
2023-05-27 14:15:04.921739: train Epoch: [34][ 92/193]	Time 12.017 ( 5.952)	Data 11.431 ( 5.378)	Loss 1.3015e-01 (1.0440e-01) 
2023-05-27 14:15:05.490024: train Epoch: [34][ 93/193]	Time  0.568 ( 5.894)	Data  0.001 ( 5.321)	Loss 3.5070e-01 (1.0702e-01) 
2023-05-27 14:15:17.571327: train Epoch: [34][ 94/193]	Time 12.081 ( 5.960)	Data 11.512 ( 5.386)	Loss 5.4140e-02 (1.0647e-01) 
2023-05-27 14:15:18.141344: train Epoch: [34][ 95/193]	Time  0.570 ( 5.903)	Data  0.001 ( 5.330)	Loss 8.4132e-02 (1.0623e-01) 
2023-05-27 14:15:30.236772: train Epoch: [34][ 96/193]	Time 12.095 ( 5.967)	Data 11.528 ( 5.394)	Loss 1.1545e-01 (1.0633e-01) 
2023-05-27 14:15:30.824751: train Epoch: [34][ 97/193]	Time  0.588 ( 5.912)	Data  0.001 ( 5.339)	Loss 1.3765e-01 (1.0665e-01) 
2023-05-27 14:15:42.919383: train Epoch: [34][ 98/193]	Time 12.095 ( 5.975)	Data 11.520 ( 5.401)	Loss 7.3644e-02 (1.0631e-01) 
2023-05-27 14:15:43.487784: train Epoch: [34][ 99/193]	Time  0.568 ( 5.921)	Data  0.001 ( 5.347)	Loss 9.4637e-02 (1.0620e-01) 
2023-05-27 14:15:55.452254: train Epoch: [34][100/193]	Time 11.964 ( 5.981)	Data 11.395 ( 5.407)	Loss 7.2833e-02 (1.0587e-01) 
2023-05-27 14:15:56.027248: train Epoch: [34][101/193]	Time  0.575 ( 5.928)	Data  0.001 ( 5.354)	Loss 6.8207e-02 (1.0550e-01) 
2023-05-27 14:16:08.143560: train Epoch: [34][102/193]	Time 12.116 ( 5.988)	Data 11.547 ( 5.414)	Loss 1.2005e-01 (1.0564e-01) 
2023-05-27 14:16:08.709090: train Epoch: [34][103/193]	Time  0.566 ( 5.935)	Data  0.001 ( 5.362)	Loss 9.4859e-02 (1.0554e-01) 
2023-05-27 14:16:20.939846: train Epoch: [34][104/193]	Time 12.231 ( 5.995)	Data 11.649 ( 5.422)	Loss 8.1672e-02 (1.0531e-01) 
2023-05-27 14:16:21.511979: train Epoch: [34][105/193]	Time  0.572 ( 5.944)	Data  0.001 ( 5.371)	Loss 5.1616e-02 (1.0480e-01) 
2023-05-27 14:16:33.063916: train Epoch: [34][106/193]	Time 11.552 ( 5.997)	Data 10.989 ( 5.423)	Loss 1.1253e-01 (1.0487e-01) 
2023-05-27 14:16:33.650944: train Epoch: [34][107/193]	Time  0.587 ( 5.947)	Data  0.001 ( 5.373)	Loss 9.4833e-02 (1.0478e-01) 
2023-05-27 14:16:45.624865: train Epoch: [34][108/193]	Time 11.974 ( 6.002)	Data 11.412 ( 5.428)	Loss 1.4235e-01 (1.0513e-01) 
2023-05-27 14:16:46.188183: train Epoch: [34][109/193]	Time  0.563 ( 5.952)	Data  0.001 ( 5.379)	Loss 1.1485e-01 (1.0521e-01) 
2023-05-27 14:16:58.157713: train Epoch: [34][110/193]	Time 11.970 ( 6.007)	Data 11.406 ( 5.433)	Loss 1.6777e-01 (1.0578e-01) 
2023-05-27 14:16:58.722981: train Epoch: [34][111/193]	Time  0.565 ( 5.958)	Data  0.001 ( 5.385)	Loss 4.9976e-02 (1.0528e-01) 
2023-05-27 14:17:10.422380: train Epoch: [34][112/193]	Time 11.699 ( 6.009)	Data 11.101 ( 5.435)	Loss 2.0223e-01 (1.0614e-01) 
2023-05-27 14:17:10.984580: train Epoch: [34][113/193]	Time  0.562 ( 5.961)	Data  0.001 ( 5.388)	Loss 6.7342e-02 (1.0580e-01) 
2023-05-27 14:17:23.254473: train Epoch: [34][114/193]	Time 12.270 ( 6.016)	Data 11.695 ( 5.443)	Loss 2.6031e-01 (1.0714e-01) 
2023-05-27 14:17:23.821518: train Epoch: [34][115/193]	Time  0.567 ( 5.969)	Data  0.001 ( 5.396)	Loss 8.6257e-02 (1.0696e-01) 
2023-05-27 14:17:35.330946: train Epoch: [34][116/193]	Time 11.509 ( 6.016)	Data 10.939 ( 5.443)	Loss 6.3189e-02 (1.0659e-01) 
2023-05-27 14:17:35.926396: train Epoch: [34][117/193]	Time  0.595 ( 5.970)	Data  0.001 ( 5.397)	Loss 1.4359e-01 (1.0690e-01) 
2023-05-27 14:17:47.388494: train Epoch: [34][118/193]	Time 11.462 ( 6.017)	Data 10.900 ( 5.443)	Loss 1.0737e-01 (1.0690e-01) 
2023-05-27 14:17:47.959154: train Epoch: [34][119/193]	Time  0.571 ( 5.971)	Data  0.001 ( 5.398)	Loss 1.0451e-01 (1.0688e-01) 
2023-05-27 14:18:00.129605: train Epoch: [34][120/193]	Time 12.170 ( 6.022)	Data 11.602 ( 5.449)	Loss 1.6374e-01 (1.0735e-01) 
2023-05-27 14:18:00.695279: train Epoch: [34][121/193]	Time  0.566 ( 5.978)	Data  0.001 ( 5.404)	Loss 1.1061e-01 (1.0738e-01) 
2023-05-27 14:18:12.836535: train Epoch: [34][122/193]	Time 12.141 ( 6.028)	Data 11.579 ( 5.455)	Loss 6.6679e-02 (1.0705e-01) 
2023-05-27 14:18:13.415698: train Epoch: [34][123/193]	Time  0.579 ( 5.984)	Data  0.001 ( 5.411)	Loss 1.5712e-01 (1.0745e-01) 
2023-05-27 14:18:25.170923: train Epoch: [34][124/193]	Time 11.755 ( 6.030)	Data 11.194 ( 5.457)	Loss 8.7256e-02 (1.0729e-01) 
2023-05-27 14:18:25.735686: train Epoch: [34][125/193]	Time  0.565 ( 5.987)	Data  0.001 ( 5.414)	Loss 7.9528e-02 (1.0707e-01) 
2023-05-27 14:18:36.907353: train Epoch: [34][126/193]	Time 11.172 ( 6.027)	Data 10.600 ( 5.454)	Loss 9.8320e-02 (1.0700e-01) 
2023-05-27 14:18:37.467714: train Epoch: [34][127/193]	Time  0.560 ( 5.985)	Data  0.001 ( 5.412)	Loss 1.2467e-01 (1.0714e-01) 
2023-05-27 14:18:48.925574: train Epoch: [34][128/193]	Time 11.458 ( 6.027)	Data 10.889 ( 5.454)	Loss 7.3300e-02 (1.0688e-01) 
2023-05-27 14:18:49.505506: train Epoch: [34][129/193]	Time  0.580 ( 5.985)	Data  0.001 ( 5.412)	Loss 1.4504e-01 (1.0717e-01) 
2023-05-27 14:19:01.324273: train Epoch: [34][130/193]	Time 11.819 ( 6.030)	Data 11.242 ( 5.457)	Loss 8.5321e-02 (1.0701e-01) 
2023-05-27 14:19:01.887096: train Epoch: [34][131/193]	Time  0.563 ( 5.988)	Data  0.001 ( 5.416)	Loss 1.2805e-01 (1.0716e-01) 
2023-05-27 14:19:13.615040: train Epoch: [34][132/193]	Time 11.728 ( 6.032)	Data 11.165 ( 5.459)	Loss 1.2428e-01 (1.0729e-01) 
2023-05-27 14:19:14.186079: train Epoch: [34][133/193]	Time  0.571 ( 5.991)	Data  0.001 ( 5.418)	Loss 9.8831e-02 (1.0723e-01) 
2023-05-27 14:19:25.993209: train Epoch: [34][134/193]	Time 11.807 ( 6.034)	Data 11.234 ( 5.461)	Loss 1.2701e-01 (1.0738e-01) 
2023-05-27 14:19:26.569465: train Epoch: [34][135/193]	Time  0.576 ( 5.994)	Data  0.001 ( 5.421)	Loss 8.3427e-02 (1.0720e-01) 
2023-05-27 14:19:38.314062: train Epoch: [34][136/193]	Time 11.745 ( 6.036)	Data 11.180 ( 5.463)	Loss 7.5568e-02 (1.0697e-01) 
2023-05-27 14:19:38.880436: train Epoch: [34][137/193]	Time  0.566 ( 5.996)	Data  0.001 ( 5.423)	Loss 1.1012e-01 (1.0699e-01) 
2023-05-27 14:19:50.498897: train Epoch: [34][138/193]	Time 11.618 ( 6.037)	Data 11.051 ( 5.464)	Loss 6.6372e-02 (1.0670e-01) 
2023-05-27 14:19:51.060359: train Epoch: [34][139/193]	Time  0.561 ( 5.997)	Data  0.001 ( 5.425)	Loss 2.0036e-01 (1.0737e-01) 
2023-05-27 14:20:02.573294: train Epoch: [34][140/193]	Time 11.513 ( 6.037)	Data 10.946 ( 5.464)	Loss 5.2430e-02 (1.0698e-01) 
2023-05-27 14:20:03.153798: train Epoch: [34][141/193]	Time  0.581 ( 5.998)	Data  0.001 ( 5.426)	Loss 1.0272e-01 (1.0695e-01) 
2023-05-27 14:20:15.515567: train Epoch: [34][142/193]	Time 12.362 ( 6.043)	Data 11.779 ( 5.470)	Loss 1.0789e-01 (1.0696e-01) 
2023-05-27 14:20:16.089261: train Epoch: [34][143/193]	Time  0.574 ( 6.005)	Data  0.001 ( 5.432)	Loss 1.3560e-01 (1.0715e-01) 
2023-05-27 14:20:27.953921: train Epoch: [34][144/193]	Time 11.865 ( 6.045)	Data 11.303 ( 5.473)	Loss 1.1482e-01 (1.0721e-01) 
2023-05-27 14:20:28.529332: train Epoch: [34][145/193]	Time  0.575 ( 6.008)	Data  0.001 ( 5.435)	Loss 7.5984e-02 (1.0699e-01) 
2023-05-27 14:20:40.667775: train Epoch: [34][146/193]	Time 12.138 ( 6.049)	Data 11.568 ( 5.477)	Loss 6.9979e-02 (1.0674e-01) 
2023-05-27 14:20:41.240607: train Epoch: [34][147/193]	Time  0.573 ( 6.012)	Data  0.001 ( 5.440)	Loss 6.8882e-02 (1.0649e-01) 
2023-05-27 14:20:52.951237: train Epoch: [34][148/193]	Time 11.711 ( 6.051)	Data 11.139 ( 5.478)	Loss 9.4227e-02 (1.0640e-01) 
2023-05-27 14:20:53.542562: train Epoch: [34][149/193]	Time  0.591 ( 6.014)	Data  0.001 ( 5.442)	Loss 9.3111e-02 (1.0632e-01) 
2023-05-27 14:21:04.923937: train Epoch: [34][150/193]	Time 11.381 ( 6.050)	Data 10.808 ( 5.477)	Loss 1.4195e-01 (1.0655e-01) 
2023-05-27 14:21:05.495488: train Epoch: [34][151/193]	Time  0.572 ( 6.014)	Data  0.001 ( 5.441)	Loss 1.0685e-01 (1.0655e-01) 
2023-05-27 14:21:16.785459: train Epoch: [34][152/193]	Time 11.290 ( 6.048)	Data 10.722 ( 5.476)	Loss 6.8245e-02 (1.0630e-01) 
2023-05-27 14:21:17.358398: train Epoch: [34][153/193]	Time  0.573 ( 6.013)	Data  0.001 ( 5.440)	Loss 1.0575e-01 (1.0630e-01) 
2023-05-27 14:21:27.439737: train Epoch: [34][154/193]	Time 10.081 ( 6.039)	Data  9.519 ( 5.466)	Loss 1.2098e-01 (1.0639e-01) 
2023-05-27 14:21:28.015495: train Epoch: [34][155/193]	Time  0.576 ( 6.004)	Data  0.001 ( 5.431)	Loss 1.0523e-01 (1.0639e-01) 
2023-05-27 14:21:39.721526: train Epoch: [34][156/193]	Time 11.706 ( 6.040)	Data 11.145 ( 5.468)	Loss 4.7453e-02 (1.0601e-01) 
2023-05-27 14:21:40.313826: train Epoch: [34][157/193]	Time  0.592 ( 6.006)	Data  0.001 ( 5.433)	Loss 9.9403e-02 (1.0597e-01) 
2023-05-27 14:21:52.732002: train Epoch: [34][158/193]	Time 12.418 ( 6.046)	Data 11.844 ( 5.473)	Loss 7.2955e-02 (1.0576e-01) 
2023-05-27 14:21:53.339595: train Epoch: [34][159/193]	Time  0.608 ( 6.012)	Data  0.001 ( 5.439)	Loss 9.6738e-02 (1.0571e-01) 
2023-05-27 14:22:04.942803: train Epoch: [34][160/193]	Time 11.603 ( 6.047)	Data 11.036 ( 5.474)	Loss 7.3982e-02 (1.0551e-01) 
2023-05-27 14:22:05.509643: train Epoch: [34][161/193]	Time  0.567 ( 6.013)	Data  0.001 ( 5.440)	Loss 1.5564e-01 (1.0582e-01) 
2023-05-27 14:22:17.548128: train Epoch: [34][162/193]	Time 12.038 ( 6.050)	Data 11.474 ( 5.477)	Loss 8.4515e-02 (1.0569e-01) 
2023-05-27 14:22:18.133381: train Epoch: [34][163/193]	Time  0.585 ( 6.017)	Data  0.001 ( 5.444)	Loss 6.0415e-02 (1.0541e-01) 
2023-05-27 14:22:29.910140: train Epoch: [34][164/193]	Time 11.777 ( 6.051)	Data 11.205 ( 5.479)	Loss 1.0778e-01 (1.0543e-01) 
2023-05-27 14:22:30.478837: train Epoch: [34][165/193]	Time  0.569 ( 6.018)	Data  0.001 ( 5.446)	Loss 2.5392e-01 (1.0632e-01) 
2023-05-27 14:22:42.723229: train Epoch: [34][166/193]	Time 12.244 ( 6.056)	Data 11.680 ( 5.483)	Loss 1.8650e-01 (1.0680e-01) 
2023-05-27 14:22:43.313969: train Epoch: [34][167/193]	Time  0.591 ( 6.023)	Data  0.001 ( 5.450)	Loss 1.0494e-01 (1.0679e-01) 
2023-05-27 14:22:55.454015: train Epoch: [34][168/193]	Time 12.140 ( 6.059)	Data 11.566 ( 5.487)	Loss 1.0702e-01 (1.0679e-01) 
2023-05-27 14:22:56.028917: train Epoch: [34][169/193]	Time  0.575 ( 6.027)	Data  0.001 ( 5.454)	Loss 1.1550e-01 (1.0684e-01) 
2023-05-27 14:23:07.566392: train Epoch: [34][170/193]	Time 11.537 ( 6.059)	Data 10.975 ( 5.487)	Loss 5.9015e-02 (1.0656e-01) 
2023-05-27 14:23:08.144261: train Epoch: [34][171/193]	Time  0.578 ( 6.027)	Data  0.001 ( 5.455)	Loss 6.8375e-02 (1.0634e-01) 
2023-05-27 14:23:20.310869: train Epoch: [34][172/193]	Time 12.167 ( 6.063)	Data 11.587 ( 5.490)	Loss 7.0917e-02 (1.0614e-01) 
2023-05-27 14:23:20.881379: train Epoch: [34][173/193]	Time  0.571 ( 6.031)	Data  0.001 ( 5.459)	Loss 6.9574e-02 (1.0593e-01) 
2023-05-27 14:23:32.842166: train Epoch: [34][174/193]	Time 11.961 ( 6.065)	Data 11.399 ( 5.493)	Loss 1.0999e-01 (1.0595e-01) 
2023-05-27 14:23:33.403390: train Epoch: [34][175/193]	Time  0.561 ( 6.034)	Data  0.001 ( 5.461)	Loss 7.2760e-02 (1.0576e-01) 
2023-05-27 14:23:45.737824: train Epoch: [34][176/193]	Time 12.334 ( 6.070)	Data 11.763 ( 5.497)	Loss 6.8793e-02 (1.0555e-01) 
2023-05-27 14:23:46.305000: train Epoch: [34][177/193]	Time  0.567 ( 6.039)	Data  0.001 ( 5.466)	Loss 8.4043e-02 (1.0543e-01) 
2023-05-27 14:23:58.058414: train Epoch: [34][178/193]	Time 11.753 ( 6.071)	Data 11.191 ( 5.498)	Loss 7.6548e-02 (1.0527e-01) 
2023-05-27 14:23:58.637236: train Epoch: [34][179/193]	Time  0.579 ( 6.040)	Data  0.001 ( 5.468)	Loss 8.2751e-02 (1.0514e-01) 
2023-05-27 14:24:10.600311: train Epoch: [34][180/193]	Time 11.963 ( 6.073)	Data 11.387 ( 5.500)	Loss 7.4114e-02 (1.0497e-01) 
2023-05-27 14:24:11.180727: train Epoch: [34][181/193]	Time  0.580 ( 6.043)	Data  0.001 ( 5.470)	Loss 1.2658e-01 (1.0509e-01) 
2023-05-27 14:24:23.563875: train Epoch: [34][182/193]	Time 12.383 ( 6.077)	Data 11.815 ( 5.505)	Loss 6.6949e-02 (1.0488e-01) 
2023-05-27 14:24:24.193586: train Epoch: [34][183/193]	Time  0.630 ( 6.048)	Data  0.001 ( 5.475)	Loss 7.2074e-02 (1.0470e-01) 
2023-05-27 14:24:36.192145: train Epoch: [34][184/193]	Time 11.999 ( 6.080)	Data 11.430 ( 5.507)	Loss 4.4163e-02 (1.0438e-01) 
2023-05-27 14:24:36.773627: train Epoch: [34][185/193]	Time  0.581 ( 6.050)	Data  0.001 ( 5.477)	Loss 6.3967e-02 (1.0416e-01) 
2023-05-27 14:24:48.933894: train Epoch: [34][186/193]	Time 12.160 ( 6.083)	Data 11.578 ( 5.510)	Loss 9.5692e-02 (1.0411e-01) 
2023-05-27 14:24:49.502742: train Epoch: [34][187/193]	Time  0.569 ( 6.054)	Data  0.001 ( 5.481)	Loss 5.6363e-02 (1.0386e-01) 
2023-05-27 14:25:01.370215: train Epoch: [34][188/193]	Time 11.867 ( 6.084)	Data 11.296 ( 5.511)	Loss 4.1475e-02 (1.0353e-01) 
2023-05-27 14:25:01.936942: train Epoch: [34][189/193]	Time  0.567 ( 6.055)	Data  0.001 ( 5.482)	Loss 1.1945e-01 (1.0361e-01) 
2023-05-27 14:25:12.956237: train Epoch: [34][190/193]	Time 11.019 ( 6.081)	Data 10.454 ( 5.508)	Loss 1.6077e-01 (1.0391e-01) 
2023-05-27 14:25:13.541005: train Epoch: [34][191/193]	Time  0.585 ( 6.053)	Data  0.001 ( 5.480)	Loss 1.1646e-01 (1.0398e-01) 
2023-05-27 14:25:24.660167: train Epoch: [34][192/193]	Time 11.119 ( 6.079)	Data 10.556 ( 5.506)	Loss 9.6344e-02 (1.0394e-01) 
2023-05-27 14:25:24.875214: Train Epoch done in 1173.458257952996 s 
2023-05-27 14:25:33.570425: val Epoch: [34][ 0/72]	Time  7.243 ( 7.243)	Data  7.071 ( 7.071)	Loss 6.5070e-02 (6.5070e-02) 
2023-05-27 14:25:33.680275: val Epoch: [34][ 1/72]	Time  0.110 ( 3.676)	Data  0.002 ( 3.536)	Loss 6.1144e-02 (6.3107e-02) 
2023-05-27 14:25:39.590623: val Epoch: [34][ 2/72]	Time  5.910 ( 4.421)	Data  5.798 ( 4.290)	Loss 6.8427e-02 (6.4880e-02) 
2023-05-27 14:25:40.107898: val Epoch: [34][ 3/72]	Time  0.517 ( 3.445)	Data  0.408 ( 3.320)	Loss 8.3764e-02 (6.9601e-02) 
2023-05-27 14:25:45.583220: val Epoch: [34][ 4/72]	Time  5.475 ( 3.851)	Data  5.368 ( 3.729)	Loss 1.1668e-01 (7.9016e-02) 
2023-05-27 14:25:46.620629: val Epoch: [34][ 5/72]	Time  1.037 ( 3.382)	Data  0.929 ( 3.263)	Loss 7.2358e-02 (7.7906e-02) 
2023-05-27 14:25:51.998920: val Epoch: [34][ 6/72]	Time  5.378 ( 3.667)	Data  5.269 ( 3.549)	Loss 9.0814e-02 (7.9750e-02) 
2023-05-27 14:25:52.739194: val Epoch: [34][ 7/72]	Time  0.740 ( 3.301)	Data  0.635 ( 3.185)	Loss 4.7518e-02 (7.5721e-02) 
2023-05-27 14:25:57.985540: val Epoch: [34][ 8/72]	Time  5.246 ( 3.518)	Data  5.141 ( 3.402)	Loss 7.4035e-02 (7.5534e-02) 
2023-05-27 14:25:58.996269: val Epoch: [34][ 9/72]	Time  1.011 ( 3.267)	Data  0.905 ( 3.153)	Loss 5.6141e-02 (7.3595e-02) 
2023-05-27 14:26:03.967376: val Epoch: [34][10/72]	Time  4.971 ( 3.422)	Data  4.851 ( 3.307)	Loss 1.3584e-01 (7.9254e-02) 
2023-05-27 14:26:05.163603: val Epoch: [34][11/72]	Time  1.196 ( 3.236)	Data  1.092 ( 3.122)	Loss 1.3554e-01 (8.3944e-02) 
2023-05-27 14:26:10.188808: val Epoch: [34][12/72]	Time  5.025 ( 3.374)	Data  4.920 ( 3.261)	Loss 6.5408e-02 (8.2519e-02) 
2023-05-27 14:26:11.544808: val Epoch: [34][13/72]	Time  1.356 ( 3.230)	Data  1.250 ( 3.117)	Loss 8.0208e-02 (8.2353e-02) 
2023-05-27 14:26:16.489935: val Epoch: [34][14/72]	Time  4.945 ( 3.344)	Data  4.810 ( 3.230)	Loss 3.2412e-01 (9.8472e-02) 
2023-05-27 14:26:17.788926: val Epoch: [34][15/72]	Time  1.299 ( 3.216)	Data  1.190 ( 3.102)	Loss 4.0976e-02 (9.4878e-02) 
2023-05-27 14:26:22.879492: val Epoch: [34][16/72]	Time  5.091 ( 3.327)	Data  4.971 ( 3.212)	Loss 1.0993e-01 (9.5764e-02) 
2023-05-27 14:26:24.218062: val Epoch: [34][17/72]	Time  1.339 ( 3.216)	Data  1.229 ( 3.102)	Loss 1.0473e-01 (9.6262e-02) 
2023-05-27 14:26:29.371854: val Epoch: [34][18/72]	Time  5.154 ( 3.318)	Data  5.010 ( 3.203)	Loss 3.4726e-01 (1.0947e-01) 
2023-05-27 14:26:30.417083: val Epoch: [34][19/72]	Time  1.045 ( 3.204)	Data  0.935 ( 3.089)	Loss 1.7908e-01 (1.1295e-01) 
2023-05-27 14:26:35.756857: val Epoch: [34][20/72]	Time  5.340 ( 3.306)	Data  5.230 ( 3.191)	Loss 3.8741e-02 (1.0942e-01) 
2023-05-27 14:26:36.745905: val Epoch: [34][21/72]	Time  0.989 ( 3.201)	Data  0.879 ( 3.086)	Loss 7.5636e-02 (1.0788e-01) 
2023-05-27 14:26:41.629303: val Epoch: [34][22/72]	Time  4.883 ( 3.274)	Data  4.773 ( 3.159)	Loss 4.9926e-02 (1.0536e-01) 
2023-05-27 14:26:43.510492: val Epoch: [34][23/72]	Time  1.881 ( 3.216)	Data  1.774 ( 3.102)	Loss 2.4410e-01 (1.1114e-01) 
2023-05-27 14:26:47.887044: val Epoch: [34][24/72]	Time  4.377 ( 3.262)	Data  4.269 ( 3.148)	Loss 2.9305e-01 (1.1842e-01) 
2023-05-27 14:26:49.626379: val Epoch: [34][25/72]	Time  1.739 ( 3.204)	Data  1.631 ( 3.090)	Loss 3.5446e-02 (1.1523e-01) 
2023-05-27 14:26:54.355681: val Epoch: [34][26/72]	Time  4.729 ( 3.260)	Data  4.567 ( 3.145)	Loss 1.3552e-01 (1.1598e-01) 
2023-05-27 14:26:55.968448: val Epoch: [34][27/72]	Time  1.613 ( 3.201)	Data  1.508 ( 3.086)	Loss 1.3136e-01 (1.1653e-01) 
2023-05-27 14:27:00.483576: val Epoch: [34][28/72]	Time  4.515 ( 3.247)	Data  4.409 ( 3.132)	Loss 3.8005e-02 (1.1382e-01) 
2023-05-27 14:27:02.228508: val Epoch: [34][29/72]	Time  1.745 ( 3.197)	Data  1.639 ( 3.082)	Loss 1.3758e-01 (1.1461e-01) 
2023-05-27 14:27:06.925376: val Epoch: [34][30/72]	Time  4.697 ( 3.245)	Data  4.589 ( 3.131)	Loss 1.5278e-01 (1.1584e-01) 
2023-05-27 14:27:08.323161: val Epoch: [34][31/72]	Time  1.398 ( 3.187)	Data  1.290 ( 3.073)	Loss 3.8571e-02 (1.1343e-01) 
2023-05-27 14:27:13.572825: val Epoch: [34][32/72]	Time  5.250 ( 3.250)	Data  5.133 ( 3.136)	Loss 9.0976e-02 (1.1275e-01) 
2023-05-27 14:27:14.683463: val Epoch: [34][33/72]	Time  1.111 ( 3.187)	Data  1.004 ( 3.073)	Loss 9.4904e-02 (1.1222e-01) 
2023-05-27 14:27:19.802715: val Epoch: [34][34/72]	Time  5.119 ( 3.242)	Data  5.005 ( 3.128)	Loss 1.1843e-01 (1.1240e-01) 
2023-05-27 14:27:20.779780: val Epoch: [34][35/72]	Time  0.977 ( 3.179)	Data  0.869 ( 3.065)	Loss 4.9021e-02 (1.1064e-01) 
2023-05-27 14:27:26.132823: val Epoch: [34][36/72]	Time  5.353 ( 3.238)	Data  5.246 ( 3.124)	Loss 9.6238e-02 (1.1025e-01) 
2023-05-27 14:27:27.264772: val Epoch: [34][37/72]	Time  1.132 ( 3.183)	Data  1.024 ( 3.069)	Loss 9.2802e-02 (1.0979e-01) 
2023-05-27 14:27:32.046648: val Epoch: [34][38/72]	Time  4.782 ( 3.224)	Data  4.673 ( 3.110)	Loss 4.3653e-02 (1.0810e-01) 
2023-05-27 14:27:33.590415: val Epoch: [34][39/72]	Time  1.544 ( 3.182)	Data  1.439 ( 3.068)	Loss 5.8623e-02 (1.0686e-01) 
2023-05-27 14:27:37.185848: val Epoch: [34][40/72]	Time  3.595 ( 3.192)	Data  3.467 ( 3.078)	Loss 6.0485e-02 (1.0573e-01) 
2023-05-27 14:27:38.743912: val Epoch: [34][41/72]	Time  1.558 ( 3.153)	Data  1.453 ( 3.039)	Loss 3.9745e-01 (1.1267e-01) 
2023-05-27 14:27:42.374714: val Epoch: [34][42/72]	Time  3.631 ( 3.164)	Data  3.519 ( 3.051)	Loss 2.9698e-01 (1.1696e-01) 
2023-05-27 14:27:43.792364: val Epoch: [34][43/72]	Time  1.418 ( 3.124)	Data  1.306 ( 3.011)	Loss 6.0140e-02 (1.1567e-01) 
2023-05-27 14:27:47.511778: val Epoch: [34][44/72]	Time  3.719 ( 3.137)	Data  3.613 ( 3.024)	Loss 1.5992e-01 (1.1665e-01) 
2023-05-27 14:27:48.679431: val Epoch: [34][45/72]	Time  1.168 ( 3.095)	Data  1.061 ( 2.982)	Loss 1.1971e-01 (1.1672e-01) 
2023-05-27 14:27:53.447416: val Epoch: [34][46/72]	Time  4.768 ( 3.130)	Data  4.643 ( 3.017)	Loss 2.6445e-01 (1.1986e-01) 
2023-05-27 14:27:54.789948: val Epoch: [34][47/72]	Time  1.343 ( 3.093)	Data  1.238 ( 2.980)	Loss 4.5482e-02 (1.1831e-01) 
2023-05-27 14:27:59.807822: val Epoch: [34][48/72]	Time  5.018 ( 3.132)	Data  4.905 ( 3.019)	Loss 4.1818e-01 (1.2443e-01) 
2023-05-27 14:28:00.879401: val Epoch: [34][49/72]	Time  1.072 ( 3.091)	Data  0.959 ( 2.978)	Loss 5.8984e-02 (1.2312e-01) 
2023-05-27 14:28:06.123714: val Epoch: [34][50/72]	Time  5.244 ( 3.133)	Data  5.135 ( 3.020)	Loss 5.4173e-02 (1.2177e-01) 
2023-05-27 14:28:07.401318: val Epoch: [34][51/72]	Time  1.278 ( 3.098)	Data  1.169 ( 2.985)	Loss 7.0237e-02 (1.2078e-01) 
2023-05-27 14:28:12.391369: val Epoch: [34][52/72]	Time  4.990 ( 3.133)	Data  4.882 ( 3.020)	Loss 3.5197e-01 (1.2514e-01) 
2023-05-27 14:28:13.572706: val Epoch: [34][53/72]	Time  1.181 ( 3.097)	Data  1.074 ( 2.984)	Loss 1.7099e-01 (1.2599e-01) 
2023-05-27 14:28:18.334815: val Epoch: [34][54/72]	Time  4.762 ( 3.127)	Data  4.639 ( 3.014)	Loss 5.7777e-02 (1.2475e-01) 
2023-05-27 14:28:20.049768: val Epoch: [34][55/72]	Time  1.715 ( 3.102)	Data  1.607 ( 2.989)	Loss 4.1236e-01 (1.2989e-01) 
2023-05-27 14:28:24.478301: val Epoch: [34][56/72]	Time  4.429 ( 3.125)	Data  4.321 ( 3.013)	Loss 6.6650e-02 (1.2878e-01) 
2023-05-27 14:28:26.397362: val Epoch: [34][57/72]	Time  1.919 ( 3.105)	Data  1.800 ( 2.992)	Loss 5.2386e-02 (1.2746e-01) 
2023-05-27 14:28:30.783684: val Epoch: [34][58/72]	Time  4.386 ( 3.126)	Data  4.281 ( 3.014)	Loss 1.2183e-01 (1.2737e-01) 
2023-05-27 14:28:32.845428: val Epoch: [34][59/72]	Time  2.062 ( 3.109)	Data  1.956 ( 2.996)	Loss 9.1444e-02 (1.2677e-01) 
2023-05-27 14:28:37.161414: val Epoch: [34][60/72]	Time  4.316 ( 3.128)	Data  4.176 ( 3.015)	Loss 5.5608e-02 (1.2560e-01) 
2023-05-27 14:28:39.156439: val Epoch: [34][61/72]	Time  1.995 ( 3.110)	Data  1.882 ( 2.997)	Loss 1.0822e-01 (1.2532e-01) 
2023-05-27 14:28:43.182659: val Epoch: [34][62/72]	Time  4.026 ( 3.125)	Data  3.919 ( 3.012)	Loss 6.1025e-02 (1.2430e-01) 
2023-05-27 14:28:45.171643: val Epoch: [34][63/72]	Time  1.989 ( 3.107)	Data  1.867 ( 2.994)	Loss 7.9061e-02 (1.2359e-01) 
2023-05-27 14:28:49.522360: val Epoch: [34][64/72]	Time  4.351 ( 3.126)	Data  4.241 ( 3.013)	Loss 5.7450e-01 (1.3053e-01) 
2023-05-27 14:28:51.104131: val Epoch: [34][65/72]	Time  1.582 ( 3.103)	Data  1.473 ( 2.990)	Loss 9.3632e-02 (1.2997e-01) 
2023-05-27 14:28:55.453284: val Epoch: [34][66/72]	Time  4.349 ( 3.121)	Data  4.240 ( 3.008)	Loss 5.2287e-02 (1.2881e-01) 
2023-05-27 14:28:57.364352: val Epoch: [34][67/72]	Time  1.911 ( 3.103)	Data  1.775 ( 2.990)	Loss 5.9643e-02 (1.2779e-01) 
2023-05-27 14:29:02.136880: val Epoch: [34][68/72]	Time  4.773 ( 3.128)	Data  4.665 ( 3.015)	Loss 1.8437e-01 (1.2861e-01) 
2023-05-27 14:29:03.541080: val Epoch: [34][69/72]	Time  1.404 ( 3.103)	Data  1.284 ( 2.990)	Loss 5.1353e-02 (1.2751e-01) 
2023-05-27 14:29:08.201994: val Epoch: [34][70/72]	Time  4.661 ( 3.125)	Data  4.556 ( 3.012)	Loss 2.1446e-01 (1.2873e-01) 
2023-05-27 14:29:09.553614: val Epoch: [34][71/72]	Time  1.352 ( 3.100)	Data  1.236 ( 2.987)	Loss 8.1172e-02 (1.2807e-01) 
2023-05-27 14:29:09.888075: Epoch 34 :Val : ['ET : 0.7402780055999756', 'TC : 0.7892964482307434', 'WT : 0.8612297177314758'] 
2023-05-27 14:29:09.889128: Epoch 34 :Val : ['ET : 0.7402780055999756', 'TC : 0.7892964482307434', 'WT : 0.8612297177314758'] 
2023-05-27 14:29:09.892868: Saving the model with DSC 0.8038527369499207 
2023-05-27 14:29:10.911759: Val epoch done in 226.03653929400025 s 
2023-05-27 14:29:11.193972: Batches per epoch:  193 
2023-05-27 14:29:25.727922: train Epoch: [35][  0/193]	Time 14.533 (14.533)	Data 13.931 (13.931)	Loss 3.7508e-02 (3.7508e-02) 
2023-05-27 14:29:26.297879: train Epoch: [35][  1/193]	Time  0.570 ( 7.552)	Data  0.001 ( 6.966)	Loss 4.3842e-02 (4.0675e-02) 
2023-05-27 14:29:38.374634: train Epoch: [35][  2/193]	Time 12.077 ( 9.060)	Data 11.510 ( 8.481)	Loss 8.1678e-02 (5.4342e-02) 
2023-05-27 14:29:38.943050: train Epoch: [35][  3/193]	Time  0.568 ( 6.937)	Data  0.001 ( 6.361)	Loss 8.6759e-02 (6.2447e-02) 
2023-05-27 14:29:50.846056: train Epoch: [35][  4/193]	Time 11.903 ( 7.930)	Data 11.340 ( 7.357)	Loss 1.0606e-01 (7.1169e-02) 
2023-05-27 14:29:51.416089: train Epoch: [35][  5/193]	Time  0.570 ( 6.704)	Data  0.001 ( 6.131)	Loss 9.8269e-02 (7.5686e-02) 
2023-05-27 14:30:03.614508: train Epoch: [35][  6/193]	Time 12.198 ( 7.489)	Data 11.636 ( 6.917)	Loss 5.3154e-02 (7.2467e-02) 
2023-05-27 14:30:04.180682: train Epoch: [35][  7/193]	Time  0.566 ( 6.623)	Data  0.001 ( 6.053)	Loss 5.4151e-02 (7.0177e-02) 
2023-05-27 14:30:16.365934: train Epoch: [35][  8/193]	Time 12.185 ( 7.241)	Data 11.623 ( 6.671)	Loss 7.1471e-02 (7.0321e-02) 
2023-05-27 14:30:16.931330: train Epoch: [35][  9/193]	Time  0.565 ( 6.574)	Data  0.001 ( 6.004)	Loss 5.9257e-02 (6.9215e-02) 
2023-05-27 14:30:28.518551: train Epoch: [35][ 10/193]	Time 11.587 ( 7.029)	Data 11.018 ( 6.460)	Loss 5.9751e-02 (6.8354e-02) 
2023-05-27 14:30:29.102974: train Epoch: [35][ 11/193]	Time  0.584 ( 6.492)	Data  0.001 ( 5.922)	Loss 9.7209e-02 (7.0759e-02) 
2023-05-27 14:30:41.162343: train Epoch: [35][ 12/193]	Time 12.059 ( 6.921)	Data 11.497 ( 6.351)	Loss 8.3999e-02 (7.1777e-02) 
2023-05-27 14:30:41.758245: train Epoch: [35][ 13/193]	Time  0.596 ( 6.469)	Data  0.001 ( 5.897)	Loss 1.4104e-01 (7.6724e-02) 
2023-05-27 14:30:53.864367: train Epoch: [35][ 14/193]	Time 12.106 ( 6.845)	Data 11.536 ( 6.273)	Loss 6.9283e-02 (7.6228e-02) 
2023-05-27 14:30:54.429559: train Epoch: [35][ 15/193]	Time  0.565 ( 6.452)	Data  0.001 ( 5.881)	Loss 1.0501e-01 (7.8027e-02) 
2023-05-27 14:31:06.632121: train Epoch: [35][ 16/193]	Time 12.203 ( 6.790)	Data 11.634 ( 6.220)	Loss 1.4235e-01 (8.1811e-02) 
2023-05-27 14:31:07.196805: train Epoch: [35][ 17/193]	Time  0.565 ( 6.445)	Data  0.001 ( 5.874)	Loss 9.9428e-02 (8.2789e-02) 
2023-05-27 14:31:19.036181: train Epoch: [35][ 18/193]	Time 11.839 ( 6.729)	Data 11.278 ( 6.159)	Loss 7.7617e-02 (8.2517e-02) 
2023-05-27 14:31:19.601292: train Epoch: [35][ 19/193]	Time  0.565 ( 6.420)	Data  0.001 ( 5.851)	Loss 5.5450e-02 (8.1164e-02) 
2023-05-27 14:31:31.611261: train Epoch: [35][ 20/193]	Time 12.010 ( 6.687)	Data 11.447 ( 6.117)	Loss 7.5974e-02 (8.0917e-02) 
2023-05-27 14:31:32.176295: train Epoch: [35][ 21/193]	Time  0.565 ( 6.408)	Data  0.001 ( 5.839)	Loss 1.1583e-01 (8.2503e-02) 
2023-05-27 14:31:43.417411: train Epoch: [35][ 22/193]	Time 11.241 ( 6.618)	Data 10.674 ( 6.049)	Loss 4.9022e-02 (8.1048e-02) 
2023-05-27 14:31:43.992705: train Epoch: [35][ 23/193]	Time  0.575 ( 6.367)	Data  0.001 ( 5.797)	Loss 2.6483e-01 (8.8705e-02) 
2023-05-27 14:31:54.965781: train Epoch: [35][ 24/193]	Time 10.973 ( 6.551)	Data 10.395 ( 5.981)	Loss 4.9321e-02 (8.7130e-02) 
2023-05-27 14:31:55.530651: train Epoch: [35][ 25/193]	Time  0.565 ( 6.321)	Data  0.001 ( 5.751)	Loss 3.9933e-02 (8.5314e-02) 
2023-05-27 14:32:07.790127: train Epoch: [35][ 26/193]	Time 12.259 ( 6.541)	Data 11.696 ( 5.971)	Loss 1.2380e-01 (8.6740e-02) 
2023-05-27 14:32:08.355802: train Epoch: [35][ 27/193]	Time  0.566 ( 6.327)	Data  0.001 ( 5.758)	Loss 5.4212e-02 (8.5578e-02) 
2023-05-27 14:32:20.426461: train Epoch: [35][ 28/193]	Time 12.071 ( 6.525)	Data 11.509 ( 5.956)	Loss 9.8302e-02 (8.6017e-02) 
2023-05-27 14:32:20.991106: train Epoch: [35][ 29/193]	Time  0.565 ( 6.327)	Data  0.001 ( 5.758)	Loss 9.6193e-02 (8.6356e-02) 
2023-05-27 14:32:33.145616: train Epoch: [35][ 30/193]	Time 12.155 ( 6.515)	Data 11.594 ( 5.946)	Loss 1.0278e-01 (8.6886e-02) 
2023-05-27 14:32:33.711375: train Epoch: [35][ 31/193]	Time  0.566 ( 6.329)	Data  0.001 ( 5.760)	Loss 6.6051e-02 (8.6235e-02) 
2023-05-27 14:32:45.690379: train Epoch: [35][ 32/193]	Time 11.979 ( 6.500)	Data 11.410 ( 5.932)	Loss 8.2466e-02 (8.6120e-02) 
2023-05-27 14:32:46.255650: train Epoch: [35][ 33/193]	Time  0.565 ( 6.325)	Data  0.001 ( 5.757)	Loss 5.8542e-02 (8.5309e-02) 
2023-05-27 14:32:58.167196: train Epoch: [35][ 34/193]	Time 11.912 ( 6.485)	Data 11.344 ( 5.917)	Loss 7.8846e-02 (8.5125e-02) 
2023-05-27 14:32:58.740034: train Epoch: [35][ 35/193]	Time  0.573 ( 6.321)	Data  0.001 ( 5.752)	Loss 7.7684e-02 (8.4918e-02) 
2023-05-27 14:33:10.812546: train Epoch: [35][ 36/193]	Time 12.072 ( 6.476)	Data 11.502 ( 5.908)	Loss 9.0170e-02 (8.5060e-02) 
2023-05-27 14:33:11.385354: train Epoch: [35][ 37/193]	Time  0.573 ( 6.321)	Data  0.001 ( 5.752)	Loss 8.9985e-02 (8.5189e-02) 
2023-05-27 14:33:23.275533: train Epoch: [35][ 38/193]	Time 11.890 ( 6.464)	Data 11.318 ( 5.895)	Loss 1.1843e-01 (8.6042e-02) 
2023-05-27 14:33:23.840809: train Epoch: [35][ 39/193]	Time  0.565 ( 6.316)	Data  0.001 ( 5.748)	Loss 9.2670e-02 (8.6207e-02) 
2023-05-27 14:33:35.972959: train Epoch: [35][ 40/193]	Time 12.132 ( 6.458)	Data 11.554 ( 5.889)	Loss 9.5659e-02 (8.6438e-02) 
2023-05-27 14:33:36.543304: train Epoch: [35][ 41/193]	Time  0.570 ( 6.318)	Data  0.001 ( 5.749)	Loss 9.8379e-02 (8.6722e-02) 
2023-05-27 14:33:48.836737: train Epoch: [35][ 42/193]	Time 12.293 ( 6.457)	Data 11.722 ( 5.888)	Loss 6.3907e-02 (8.6192e-02) 
2023-05-27 14:33:49.409221: train Epoch: [35][ 43/193]	Time  0.572 ( 6.323)	Data  0.001 ( 5.754)	Loss 8.4376e-02 (8.6150e-02) 
2023-05-27 14:34:01.498627: train Epoch: [35][ 44/193]	Time 12.089 ( 6.451)	Data 11.527 ( 5.883)	Loss 7.7373e-02 (8.5955e-02) 
2023-05-27 14:34:02.063157: train Epoch: [35][ 45/193]	Time  0.565 ( 6.323)	Data  0.001 ( 5.755)	Loss 5.6435e-02 (8.5314e-02) 
2023-05-27 14:34:13.971128: train Epoch: [35][ 46/193]	Time 11.908 ( 6.442)	Data 11.336 ( 5.873)	Loss 4.0127e-02 (8.4352e-02) 
2023-05-27 14:34:14.535272: train Epoch: [35][ 47/193]	Time  0.564 ( 6.320)	Data  0.001 ( 5.751)	Loss 9.3744e-02 (8.4548e-02) 
2023-05-27 14:34:26.971316: train Epoch: [35][ 48/193]	Time 12.436 ( 6.444)	Data 11.867 ( 5.876)	Loss 7.3466e-02 (8.4322e-02) 
2023-05-27 14:34:27.563195: train Epoch: [35][ 49/193]	Time  0.592 ( 6.327)	Data  0.001 ( 5.758)	Loss 1.0511e-01 (8.4737e-02) 
2023-05-27 14:34:39.727978: train Epoch: [35][ 50/193]	Time 12.165 ( 6.442)	Data 11.582 ( 5.873)	Loss 6.0829e-02 (8.4269e-02) 
2023-05-27 14:34:40.304189: train Epoch: [35][ 51/193]	Time  0.576 ( 6.329)	Data  0.001 ( 5.760)	Loss 1.3564e-01 (8.5257e-02) 
2023-05-27 14:34:52.330910: train Epoch: [35][ 52/193]	Time 12.027 ( 6.437)	Data 11.462 ( 5.867)	Loss 8.9213e-02 (8.5331e-02) 
2023-05-27 14:34:52.917919: train Epoch: [35][ 53/193]	Time  0.587 ( 6.328)	Data  0.001 ( 5.759)	Loss 5.5254e-02 (8.4774e-02) 
2023-05-27 14:35:05.284988: train Epoch: [35][ 54/193]	Time 12.367 ( 6.438)	Data 11.788 ( 5.868)	Loss 1.3399e-01 (8.5669e-02) 
2023-05-27 14:35:05.868747: train Epoch: [35][ 55/193]	Time  0.584 ( 6.333)	Data  0.001 ( 5.763)	Loss 4.6878e-02 (8.4976e-02) 
2023-05-27 14:35:17.517720: train Epoch: [35][ 56/193]	Time 11.649 ( 6.427)	Data 11.067 ( 5.857)	Loss 7.7622e-02 (8.4847e-02) 
2023-05-27 14:35:18.120523: train Epoch: [35][ 57/193]	Time  0.603 ( 6.326)	Data  0.001 ( 5.756)	Loss 5.1406e-02 (8.4271e-02) 
2023-05-27 14:35:30.108552: train Epoch: [35][ 58/193]	Time 11.988 ( 6.422)	Data 11.409 ( 5.851)	Loss 6.8314e-02 (8.4000e-02) 
2023-05-27 14:35:30.739369: train Epoch: [35][ 59/193]	Time  0.631 ( 6.326)	Data  0.001 ( 5.754)	Loss 1.3593e-01 (8.4866e-02) 
2023-05-27 14:35:42.275662: train Epoch: [35][ 60/193]	Time 11.536 ( 6.411)	Data 10.961 ( 5.839)	Loss 7.0354e-02 (8.4628e-02) 
2023-05-27 14:35:42.881478: train Epoch: [35][ 61/193]	Time  0.606 ( 6.318)	Data  0.001 ( 5.745)	Loss 6.2614e-02 (8.4273e-02) 
2023-05-27 14:35:54.991829: train Epoch: [35][ 62/193]	Time 12.110 ( 6.409)	Data 11.491 ( 5.836)	Loss 7.8409e-02 (8.4180e-02) 
2023-05-27 14:35:55.558008: train Epoch: [35][ 63/193]	Time  0.566 ( 6.318)	Data  0.001 ( 5.745)	Loss 1.0680e-01 (8.4533e-02) 
2023-05-27 14:36:07.363022: train Epoch: [35][ 64/193]	Time 11.805 ( 6.403)	Data 11.239 ( 5.830)	Loss 6.1861e-02 (8.4184e-02) 
2023-05-27 14:36:07.939486: train Epoch: [35][ 65/193]	Time  0.576 ( 6.314)	Data  0.001 ( 5.741)	Loss 1.2163e-01 (8.4752e-02) 
2023-05-27 14:36:20.002346: train Epoch: [35][ 66/193]	Time 12.063 ( 6.400)	Data 11.476 ( 5.827)	Loss 7.2515e-02 (8.4569e-02) 
2023-05-27 14:36:20.586897: train Epoch: [35][ 67/193]	Time  0.585 ( 6.315)	Data  0.001 ( 5.741)	Loss 7.3120e-02 (8.4401e-02) 
2023-05-27 14:36:32.558799: train Epoch: [35][ 68/193]	Time 11.972 ( 6.397)	Data 11.400 ( 5.823)	Loss 7.8731e-02 (8.4318e-02) 
2023-05-27 14:36:33.133372: train Epoch: [35][ 69/193]	Time  0.575 ( 6.313)	Data  0.001 ( 5.740)	Loss 7.3876e-02 (8.4169e-02) 
2023-05-27 14:36:45.487718: train Epoch: [35][ 70/193]	Time 12.354 ( 6.398)	Data 11.785 ( 5.825)	Loss 6.3289e-02 (8.3875e-02) 
2023-05-27 14:36:46.063905: train Epoch: [35][ 71/193]	Time  0.576 ( 6.318)	Data  0.001 ( 5.744)	Loss 9.1201e-02 (8.3977e-02) 
2023-05-27 14:36:58.205755: train Epoch: [35][ 72/193]	Time 12.142 ( 6.397)	Data 11.575 ( 5.824)	Loss 1.0864e-01 (8.4315e-02) 
2023-05-27 14:36:58.813529: train Epoch: [35][ 73/193]	Time  0.608 ( 6.319)	Data  0.001 ( 5.746)	Loss 4.9950e-02 (8.3850e-02) 
2023-05-27 14:37:10.737006: train Epoch: [35][ 74/193]	Time 11.923 ( 6.394)	Data 11.359 ( 5.820)	Loss 1.0547e-01 (8.4139e-02) 
2023-05-27 14:37:11.369606: train Epoch: [35][ 75/193]	Time  0.633 ( 6.318)	Data  0.001 ( 5.744)	Loss 7.9780e-02 (8.4081e-02) 
2023-05-27 14:37:23.136138: train Epoch: [35][ 76/193]	Time 11.767 ( 6.389)	Data 11.197 ( 5.815)	Loss 8.2658e-02 (8.4063e-02) 
2023-05-27 14:37:23.726933: train Epoch: [35][ 77/193]	Time  0.591 ( 6.315)	Data  0.001 ( 5.740)	Loss 5.0347e-02 (8.3630e-02) 
2023-05-27 14:37:35.339770: train Epoch: [35][ 78/193]	Time 11.613 ( 6.382)	Data 11.051 ( 5.807)	Loss 1.2160e-01 (8.4111e-02) 
2023-05-27 14:37:35.932123: train Epoch: [35][ 79/193]	Time  0.592 ( 6.309)	Data  0.001 ( 5.735)	Loss 6.1518e-02 (8.3829e-02) 
2023-05-27 14:37:47.691401: train Epoch: [35][ 80/193]	Time 11.759 ( 6.376)	Data 11.191 ( 5.802)	Loss 1.0970e-01 (8.4148e-02) 
2023-05-27 14:37:48.267484: train Epoch: [35][ 81/193]	Time  0.576 ( 6.306)	Data  0.001 ( 5.731)	Loss 1.0472e-01 (8.4399e-02) 
2023-05-27 14:38:00.041308: train Epoch: [35][ 82/193]	Time 11.774 ( 6.372)	Data 11.205 ( 5.797)	Loss 1.0543e-01 (8.4652e-02) 
2023-05-27 14:38:00.616323: train Epoch: [35][ 83/193]	Time  0.575 ( 6.303)	Data  0.001 ( 5.728)	Loss 5.4362e-02 (8.4292e-02) 
2023-05-27 14:38:11.506687: train Epoch: [35][ 84/193]	Time 10.890 ( 6.357)	Data 10.318 ( 5.782)	Loss 5.2713e-02 (8.3920e-02) 
2023-05-27 14:38:12.074137: train Epoch: [35][ 85/193]	Time  0.567 ( 6.289)	Data  0.001 ( 5.715)	Loss 9.9001e-02 (8.4096e-02) 
2023-05-27 14:38:23.312452: train Epoch: [35][ 86/193]	Time 11.238 ( 6.346)	Data 10.676 ( 5.772)	Loss 7.4483e-02 (8.3985e-02) 
2023-05-27 14:38:23.883053: train Epoch: [35][ 87/193]	Time  0.571 ( 6.281)	Data  0.001 ( 5.706)	Loss 6.6806e-02 (8.3790e-02) 
2023-05-27 14:38:35.375451: train Epoch: [35][ 88/193]	Time 11.492 ( 6.339)	Data 10.919 ( 5.765)	Loss 9.9271e-02 (8.3964e-02) 
2023-05-27 14:38:35.953116: train Epoch: [35][ 89/193]	Time  0.578 ( 6.275)	Data  0.001 ( 5.701)	Loss 4.6616e-02 (8.3549e-02) 
2023-05-27 14:38:48.111495: train Epoch: [35][ 90/193]	Time 12.158 ( 6.340)	Data 11.591 ( 5.766)	Loss 1.5761e-01 (8.4363e-02) 
2023-05-27 14:38:48.689980: train Epoch: [35][ 91/193]	Time  0.578 ( 6.277)	Data  0.001 ( 5.703)	Loss 8.8863e-02 (8.4412e-02) 
2023-05-27 14:39:00.232561: train Epoch: [35][ 92/193]	Time 11.543 ( 6.334)	Data 10.970 ( 5.760)	Loss 8.1404e-02 (8.4379e-02) 
2023-05-27 14:39:00.801070: train Epoch: [35][ 93/193]	Time  0.568 ( 6.272)	Data  0.001 ( 5.698)	Loss 6.3496e-02 (8.4157e-02) 
2023-05-27 14:39:12.074539: train Epoch: [35][ 94/193]	Time 11.273 ( 6.325)	Data 10.712 ( 5.751)	Loss 9.2771e-02 (8.4248e-02) 
2023-05-27 14:39:12.641794: train Epoch: [35][ 95/193]	Time  0.567 ( 6.265)	Data  0.001 ( 5.691)	Loss 9.5273e-02 (8.4363e-02) 
2023-05-27 14:39:24.323620: train Epoch: [35][ 96/193]	Time 11.682 ( 6.321)	Data 11.120 ( 5.747)	Loss 5.3054e-02 (8.4040e-02) 
2023-05-27 14:39:24.891065: train Epoch: [35][ 97/193]	Time  0.567 ( 6.262)	Data  0.001 ( 5.689)	Loss 5.8931e-02 (8.3784e-02) 
2023-05-27 14:39:36.464076: train Epoch: [35][ 98/193]	Time 11.573 ( 6.316)	Data 11.011 ( 5.742)	Loss 4.3143e-02 (8.3373e-02) 
2023-05-27 14:39:37.030133: train Epoch: [35][ 99/193]	Time  0.566 ( 6.258)	Data  0.001 ( 5.685)	Loss 8.2094e-02 (8.3360e-02) 
2023-05-27 14:39:48.697048: train Epoch: [35][100/193]	Time 11.667 ( 6.312)	Data 11.100 ( 5.739)	Loss 6.4313e-02 (8.3172e-02) 
2023-05-27 14:39:49.263418: train Epoch: [35][101/193]	Time  0.566 ( 6.256)	Data  0.001 ( 5.682)	Loss 6.9107e-02 (8.3034e-02) 
2023-05-27 14:40:00.861336: train Epoch: [35][102/193]	Time 11.598 ( 6.307)	Data 11.036 ( 5.734)	Loss 9.6810e-02 (8.3168e-02) 
2023-05-27 14:40:01.426761: train Epoch: [35][103/193]	Time  0.565 ( 6.252)	Data  0.001 ( 5.679)	Loss 7.5544e-02 (8.3094e-02) 
2023-05-27 14:40:12.934599: train Epoch: [35][104/193]	Time 11.508 ( 6.302)	Data 10.935 ( 5.729)	Loss 5.5164e-02 (8.2828e-02) 
2023-05-27 14:40:13.500899: train Epoch: [35][105/193]	Time  0.566 ( 6.248)	Data  0.001 ( 5.675)	Loss 1.7198e-01 (8.3669e-02) 
2023-05-27 14:40:25.275503: train Epoch: [35][106/193]	Time 11.775 ( 6.300)	Data 11.205 ( 5.727)	Loss 6.8682e-02 (8.3529e-02) 
2023-05-27 14:40:25.841062: train Epoch: [35][107/193]	Time  0.566 ( 6.247)	Data  0.001 ( 5.674)	Loss 8.0455e-02 (8.3501e-02) 
2023-05-27 14:40:37.649474: train Epoch: [35][108/193]	Time 11.808 ( 6.298)	Data 11.162 ( 5.724)	Loss 9.3119e-02 (8.3589e-02) 
2023-05-27 14:40:38.214727: train Epoch: [35][109/193]	Time  0.565 ( 6.246)	Data  0.001 ( 5.672)	Loss 9.1689e-02 (8.3663e-02) 
2023-05-27 14:40:50.446088: train Epoch: [35][110/193]	Time 12.231 ( 6.300)	Data 11.578 ( 5.725)	Loss 1.5870e-01 (8.4339e-02) 
2023-05-27 14:40:51.012219: train Epoch: [35][111/193]	Time  0.566 ( 6.248)	Data  0.001 ( 5.674)	Loss 1.0801e-01 (8.4550e-02) 
2023-05-27 14:41:02.958356: train Epoch: [35][112/193]	Time 11.946 ( 6.299)	Data 11.366 ( 5.725)	Loss 9.3992e-02 (8.4634e-02) 
2023-05-27 14:41:03.547360: train Epoch: [35][113/193]	Time  0.589 ( 6.249)	Data  0.001 ( 5.674)	Loss 8.8746e-02 (8.4670e-02) 
2023-05-27 14:41:15.384278: train Epoch: [35][114/193]	Time 11.837 ( 6.297)	Data 11.265 ( 5.723)	Loss 7.1479e-02 (8.4555e-02) 
2023-05-27 14:41:15.953675: train Epoch: [35][115/193]	Time  0.569 ( 6.248)	Data  0.001 ( 5.674)	Loss 9.4426e-02 (8.4640e-02) 
2023-05-27 14:41:28.662387: train Epoch: [35][116/193]	Time 12.709 ( 6.303)	Data 12.144 ( 5.729)	Loss 6.5511e-02 (8.4477e-02) 
2023-05-27 14:41:29.242165: train Epoch: [35][117/193]	Time  0.580 ( 6.255)	Data  0.001 ( 5.680)	Loss 5.5433e-02 (8.4231e-02) 
2023-05-27 14:41:40.948181: train Epoch: [35][118/193]	Time 11.706 ( 6.300)	Data 11.144 ( 5.726)	Loss 7.2250e-02 (8.4130e-02) 
2023-05-27 14:41:41.519694: train Epoch: [35][119/193]	Time  0.571 ( 6.253)	Data  0.001 ( 5.679)	Loss 6.2556e-02 (8.3950e-02) 
2023-05-27 14:41:53.515737: train Epoch: [35][120/193]	Time 11.996 ( 6.300)	Data 11.424 ( 5.726)	Loss 6.8777e-02 (8.3825e-02) 
2023-05-27 14:41:54.119566: train Epoch: [35][121/193]	Time  0.604 ( 6.253)	Data  0.001 ( 5.679)	Loss 6.9511e-02 (8.3707e-02) 
2023-05-27 14:42:05.908927: train Epoch: [35][122/193]	Time 11.789 ( 6.298)	Data 11.213 ( 5.724)	Loss 1.1922e-01 (8.3996e-02) 
2023-05-27 14:42:06.516625: train Epoch: [35][123/193]	Time  0.608 ( 6.253)	Data  0.001 ( 5.678)	Loss 6.3118e-02 (8.3828e-02) 
2023-05-27 14:42:18.283301: train Epoch: [35][124/193]	Time 11.767 ( 6.297)	Data 11.205 ( 5.722)	Loss 9.7701e-02 (8.3939e-02) 
2023-05-27 14:42:18.854906: train Epoch: [35][125/193]	Time  0.572 ( 6.251)	Data  0.001 ( 5.677)	Loss 8.4817e-02 (8.3946e-02) 
2023-05-27 14:42:30.770063: train Epoch: [35][126/193]	Time 11.915 ( 6.296)	Data 11.343 ( 5.722)	Loss 6.3864e-02 (8.3787e-02) 
2023-05-27 14:42:31.350157: train Epoch: [35][127/193]	Time  0.580 ( 6.251)	Data  0.001 ( 5.677)	Loss 5.4466e-02 (8.3558e-02) 
2023-05-27 14:42:43.074984: train Epoch: [35][128/193]	Time 11.725 ( 6.294)	Data 11.155 ( 5.719)	Loss 8.4583e-02 (8.3566e-02) 
2023-05-27 14:42:43.677428: train Epoch: [35][129/193]	Time  0.602 ( 6.250)	Data  0.001 ( 5.675)	Loss 1.3619e-01 (8.3971e-02) 
2023-05-27 14:42:55.933766: train Epoch: [35][130/193]	Time 12.256 ( 6.296)	Data 11.678 ( 5.721)	Loss 1.3141e-01 (8.4333e-02) 
2023-05-27 14:42:56.513207: train Epoch: [35][131/193]	Time  0.579 ( 6.252)	Data  0.001 ( 5.678)	Loss 8.8917e-02 (8.4368e-02) 
2023-05-27 14:43:08.837638: train Epoch: [35][132/193]	Time 12.324 ( 6.298)	Data 11.748 ( 5.723)	Loss 7.9657e-02 (8.4333e-02) 
2023-05-27 14:43:09.410249: train Epoch: [35][133/193]	Time  0.573 ( 6.255)	Data  0.001 ( 5.681)	Loss 8.8759e-02 (8.4366e-02) 
2023-05-27 14:43:21.679681: train Epoch: [35][134/193]	Time 12.269 ( 6.300)	Data 11.704 ( 5.725)	Loss 7.9036e-02 (8.4326e-02) 
2023-05-27 14:43:22.256038: train Epoch: [35][135/193]	Time  0.576 ( 6.258)	Data  0.001 ( 5.683)	Loss 8.2711e-02 (8.4314e-02) 
2023-05-27 14:43:34.565308: train Epoch: [35][136/193]	Time 12.309 ( 6.302)	Data 11.738 ( 5.727)	Loss 6.6651e-02 (8.4185e-02) 
2023-05-27 14:43:35.143067: train Epoch: [35][137/193]	Time  0.578 ( 6.260)	Data  0.001 ( 5.686)	Loss 1.7111e-01 (8.4815e-02) 
2023-05-27 14:43:47.119899: train Epoch: [35][138/193]	Time 11.977 ( 6.302)	Data 11.388 ( 5.727)	Loss 5.1442e-02 (8.4575e-02) 
2023-05-27 14:43:47.686100: train Epoch: [35][139/193]	Time  0.566 ( 6.261)	Data  0.001 ( 5.686)	Loss 9.0453e-02 (8.4617e-02) 
2023-05-27 14:43:59.774628: train Epoch: [35][140/193]	Time 12.089 ( 6.302)	Data 11.516 ( 5.727)	Loss 8.9500e-02 (8.4652e-02) 
2023-05-27 14:44:00.339625: train Epoch: [35][141/193]	Time  0.565 ( 6.262)	Data  0.001 ( 5.687)	Loss 4.9852e-02 (8.4407e-02) 
2023-05-27 14:44:12.509523: train Epoch: [35][142/193]	Time 12.170 ( 6.303)	Data 11.608 ( 5.728)	Loss 3.5233e-01 (8.6280e-02) 
2023-05-27 14:44:13.074718: train Epoch: [35][143/193]	Time  0.565 ( 6.263)	Data  0.001 ( 5.689)	Loss 4.5625e-02 (8.5998e-02) 
2023-05-27 14:44:24.865181: train Epoch: [35][144/193]	Time 11.790 ( 6.301)	Data 11.223 ( 5.727)	Loss 1.0494e-01 (8.6129e-02) 
2023-05-27 14:44:25.430523: train Epoch: [35][145/193]	Time  0.565 ( 6.262)	Data  0.001 ( 5.688)	Loss 5.3474e-02 (8.5905e-02) 
2023-05-27 14:44:37.489441: train Epoch: [35][146/193]	Time 12.059 ( 6.301)	Data 11.494 ( 5.727)	Loss 8.2731e-02 (8.5883e-02) 
2023-05-27 14:44:38.061809: train Epoch: [35][147/193]	Time  0.572 ( 6.263)	Data  0.001 ( 5.688)	Loss 5.7661e-02 (8.5693e-02) 
2023-05-27 14:44:49.836500: train Epoch: [35][148/193]	Time 11.775 ( 6.300)	Data 11.212 ( 5.726)	Loss 5.7454e-02 (8.5503e-02) 
2023-05-27 14:44:50.401483: train Epoch: [35][149/193]	Time  0.565 ( 6.261)	Data  0.001 ( 5.687)	Loss 8.1085e-02 (8.5474e-02) 
2023-05-27 14:45:02.603724: train Epoch: [35][150/193]	Time 12.202 ( 6.301)	Data 11.641 ( 5.727)	Loss 6.4902e-02 (8.5337e-02) 
2023-05-27 14:45:03.171636: train Epoch: [35][151/193]	Time  0.568 ( 6.263)	Data  0.001 ( 5.689)	Loss 2.4440e-01 (8.6384e-02) 
2023-05-27 14:45:15.133997: train Epoch: [35][152/193]	Time 11.962 ( 6.300)	Data 11.395 ( 5.726)	Loss 5.3100e-02 (8.6166e-02) 
2023-05-27 14:45:15.701107: train Epoch: [35][153/193]	Time  0.567 ( 6.263)	Data  0.001 ( 5.689)	Loss 5.4706e-02 (8.5962e-02) 
2023-05-27 14:45:27.737622: train Epoch: [35][154/193]	Time 12.037 ( 6.300)	Data 11.475 ( 5.727)	Loss 1.0533e-01 (8.6087e-02) 
2023-05-27 14:45:28.303697: train Epoch: [35][155/193]	Time  0.566 ( 6.264)	Data  0.001 ( 5.690)	Loss 1.1081e-01 (8.6245e-02) 
2023-05-27 14:45:40.514753: train Epoch: [35][156/193]	Time 12.211 ( 6.301)	Data 11.646 ( 5.728)	Loss 6.4711e-02 (8.6108e-02) 
2023-05-27 14:45:41.086216: train Epoch: [35][157/193]	Time  0.571 ( 6.265)	Data  0.001 ( 5.692)	Loss 7.5130e-02 (8.6039e-02) 
2023-05-27 14:45:52.929838: train Epoch: [35][158/193]	Time 11.844 ( 6.300)	Data 11.269 ( 5.727)	Loss 8.1560e-02 (8.6011e-02) 
2023-05-27 14:45:53.503167: train Epoch: [35][159/193]	Time  0.573 ( 6.264)	Data  0.001 ( 5.691)	Loss 3.1048e-01 (8.7414e-02) 
2023-05-27 14:46:05.346138: train Epoch: [35][160/193]	Time 11.843 ( 6.299)	Data 11.277 ( 5.726)	Loss 8.0691e-02 (8.7372e-02) 
2023-05-27 14:46:05.917061: train Epoch: [35][161/193]	Time  0.571 ( 6.264)	Data  0.001 ( 5.690)	Loss 1.0327e-01 (8.7470e-02) 
2023-05-27 14:46:17.884386: train Epoch: [35][162/193]	Time 11.967 ( 6.299)	Data 11.401 ( 5.725)	Loss 9.8172e-02 (8.7536e-02) 
2023-05-27 14:46:18.457119: train Epoch: [35][163/193]	Time  0.573 ( 6.264)	Data  0.001 ( 5.690)	Loss 1.1964e-01 (8.7731e-02) 
2023-05-27 14:46:30.114481: train Epoch: [35][164/193]	Time 11.657 ( 6.296)	Data 11.097 ( 5.723)	Loss 6.9924e-02 (8.7623e-02) 
2023-05-27 14:46:30.681838: train Epoch: [35][165/193]	Time  0.567 ( 6.262)	Data  0.001 ( 5.689)	Loss 5.1252e-02 (8.7404e-02) 
2023-05-27 14:46:42.382277: train Epoch: [35][166/193]	Time 11.700 ( 6.295)	Data 11.129 ( 5.721)	Loss 4.5000e-02 (8.7150e-02) 
2023-05-27 14:46:42.954892: train Epoch: [35][167/193]	Time  0.573 ( 6.260)	Data  0.001 ( 5.687)	Loss 7.9513e-02 (8.7105e-02) 
2023-05-27 14:46:55.324164: train Epoch: [35][168/193]	Time 12.369 ( 6.297)	Data 11.747 ( 5.723)	Loss 1.1263e-01 (8.7256e-02) 
2023-05-27 14:46:55.896419: train Epoch: [35][169/193]	Time  0.572 ( 6.263)	Data  0.001 ( 5.689)	Loss 1.3398e-01 (8.7531e-02) 
2023-05-27 14:47:07.307181: train Epoch: [35][170/193]	Time 11.411 ( 6.293)	Data 10.843 ( 5.719)	Loss 9.6923e-02 (8.7586e-02) 
2023-05-27 14:47:07.880867: train Epoch: [35][171/193]	Time  0.574 ( 6.260)	Data  0.001 ( 5.686)	Loss 7.8180e-02 (8.7531e-02) 
2023-05-27 14:47:19.968949: train Epoch: [35][172/193]	Time 12.088 ( 6.293)	Data 11.516 ( 5.720)	Loss 1.3829e-01 (8.7825e-02) 
2023-05-27 14:47:20.551348: train Epoch: [35][173/193]	Time  0.582 ( 6.261)	Data  0.001 ( 5.687)	Loss 8.9986e-02 (8.7837e-02) 
2023-05-27 14:47:32.567287: train Epoch: [35][174/193]	Time 12.016 ( 6.294)	Data 11.428 ( 5.720)	Loss 1.9304e-01 (8.8438e-02) 
2023-05-27 14:47:33.133584: train Epoch: [35][175/193]	Time  0.566 ( 6.261)	Data  0.001 ( 5.687)	Loss 1.6467e-01 (8.8871e-02) 
2023-05-27 14:47:44.560392: train Epoch: [35][176/193]	Time 11.427 ( 6.290)	Data 10.851 ( 5.717)	Loss 1.5851e-01 (8.9265e-02) 
2023-05-27 14:47:45.156482: train Epoch: [35][177/193]	Time  0.596 ( 6.258)	Data  0.001 ( 5.684)	Loss 5.3529e-02 (8.9064e-02) 
2023-05-27 14:47:57.323867: train Epoch: [35][178/193]	Time 12.167 ( 6.291)	Data 11.597 ( 5.717)	Loss 1.0858e-01 (8.9173e-02) 
2023-05-27 14:47:57.891375: train Epoch: [35][179/193]	Time  0.567 ( 6.259)	Data  0.001 ( 5.686)	Loss 9.9179e-02 (8.9229e-02) 
2023-05-27 14:48:09.852819: train Epoch: [35][180/193]	Time 11.961 ( 6.291)	Data 11.392 ( 5.717)	Loss 1.0268e-01 (8.9303e-02) 
2023-05-27 14:48:10.444770: train Epoch: [35][181/193]	Time  0.592 ( 6.260)	Data  0.001 ( 5.686)	Loss 9.3357e-02 (8.9325e-02) 
2023-05-27 14:48:21.448176: train Epoch: [35][182/193]	Time 11.003 ( 6.286)	Data 10.440 ( 5.712)	Loss 1.8603e-01 (8.9854e-02) 
2023-05-27 14:48:22.026790: train Epoch: [35][183/193]	Time  0.579 ( 6.255)	Data  0.001 ( 5.681)	Loss 4.1755e-02 (8.9592e-02) 
2023-05-27 14:48:33.944898: train Epoch: [35][184/193]	Time 11.918 ( 6.285)	Data 11.338 ( 5.711)	Loss 7.2712e-02 (8.9501e-02) 
2023-05-27 14:48:34.517929: train Epoch: [35][185/193]	Time  0.573 ( 6.254)	Data  0.001 ( 5.681)	Loss 6.6340e-02 (8.9376e-02) 
2023-05-27 14:48:46.554809: train Epoch: [35][186/193]	Time 12.037 ( 6.285)	Data 11.419 ( 5.711)	Loss 7.5062e-02 (8.9300e-02) 
2023-05-27 14:48:47.129362: train Epoch: [35][187/193]	Time  0.575 ( 6.255)	Data  0.001 ( 5.681)	Loss 4.9878e-02 (8.9090e-02) 
2023-05-27 14:48:59.107962: train Epoch: [35][188/193]	Time 11.979 ( 6.285)	Data 11.376 ( 5.711)	Loss 8.6265e-02 (8.9075e-02) 
2023-05-27 14:48:59.686450: train Epoch: [35][189/193]	Time  0.578 ( 6.255)	Data  0.001 ( 5.681)	Loss 1.3015e-01 (8.9291e-02) 
2023-05-27 14:49:11.788758: train Epoch: [35][190/193]	Time 12.102 ( 6.286)	Data 11.525 ( 5.712)	Loss 6.8946e-02 (8.9185e-02) 
2023-05-27 14:49:12.353582: train Epoch: [35][191/193]	Time  0.565 ( 6.256)	Data  0.001 ( 5.682)	Loss 9.3229e-02 (8.9206e-02) 
2023-05-27 14:49:23.263211: train Epoch: [35][192/193]	Time 10.910 ( 6.280)	Data 10.323 ( 5.706)	Loss 1.1795e-01 (8.9355e-02) 
2023-05-27 14:49:23.472597: Train Epoch done in 1212.2786730549997 s 
2023-05-27 14:49:32.035813: val Epoch: [35][ 0/72]	Time  7.701 ( 7.701)	Data  7.519 ( 7.519)	Loss 3.9155e-02 (3.9155e-02) 
2023-05-27 14:49:32.148183: val Epoch: [35][ 1/72]	Time  0.113 ( 3.907)	Data  0.002 ( 3.761)	Loss 3.6327e-02 (3.7741e-02) 
2023-05-27 14:49:38.427662: val Epoch: [35][ 2/72]	Time  6.279 ( 4.698)	Data  6.163 ( 4.561)	Loss 7.7891e-02 (5.1124e-02) 
2023-05-27 14:49:38.538504: val Epoch: [35][ 3/72]	Time  0.111 ( 3.551)	Data  0.001 ( 3.421)	Loss 4.8645e-02 (5.0504e-02) 
2023-05-27 14:49:44.938643: val Epoch: [35][ 4/72]	Time  6.400 ( 4.121)	Data  6.286 ( 3.994)	Loss 3.8379e-02 (4.8079e-02) 
2023-05-27 14:49:45.053079: val Epoch: [35][ 5/72]	Time  0.114 ( 3.453)	Data  0.001 ( 3.329)	Loss 6.8620e-02 (5.1503e-02) 
2023-05-27 14:49:51.460428: val Epoch: [35][ 6/72]	Time  6.407 ( 3.875)	Data  6.299 ( 3.753)	Loss 8.3664e-02 (5.6097e-02) 
2023-05-27 14:49:51.567141: val Epoch: [35][ 7/72]	Time  0.107 ( 3.404)	Data  0.001 ( 3.284)	Loss 8.1670e-02 (5.9294e-02) 
2023-05-27 14:49:58.038253: val Epoch: [35][ 8/72]	Time  6.471 ( 3.745)	Data  6.363 ( 3.626)	Loss 9.5873e-02 (6.3358e-02) 
2023-05-27 14:49:58.147163: val Epoch: [35][ 9/72]	Time  0.109 ( 3.381)	Data  0.001 ( 3.263)	Loss 8.2787e-02 (6.5301e-02) 
2023-05-27 14:50:03.973241: val Epoch: [35][10/72]	Time  5.826 ( 3.604)	Data  5.717 ( 3.487)	Loss 6.1526e-02 (6.4958e-02) 
2023-05-27 14:50:04.133704: val Epoch: [35][11/72]	Time  0.160 ( 3.317)	Data  0.001 ( 3.196)	Loss 5.7971e-02 (6.4376e-02) 
2023-05-27 14:50:10.349088: val Epoch: [35][12/72]	Time  6.215 ( 3.540)	Data  6.110 ( 3.420)	Loss 1.0496e-01 (6.7498e-02) 
2023-05-27 14:50:10.454256: val Epoch: [35][13/72]	Time  0.105 ( 3.294)	Data  0.001 ( 3.176)	Loss 8.4420e-02 (6.8706e-02) 
2023-05-27 14:50:16.518157: val Epoch: [35][14/72]	Time  6.064 ( 3.479)	Data  5.958 ( 3.361)	Loss 3.7093e-02 (6.6599e-02) 
2023-05-27 14:50:16.623289: val Epoch: [35][15/72]	Time  0.105 ( 3.268)	Data  0.000 ( 3.151)	Loss 5.5363e-02 (6.5897e-02) 
2023-05-27 14:50:22.810667: val Epoch: [35][16/72]	Time  6.187 ( 3.440)	Data  6.081 ( 3.324)	Loss 1.4757e-01 (7.0701e-02) 
2023-05-27 14:50:22.915752: val Epoch: [35][17/72]	Time  0.105 ( 3.255)	Data  0.001 ( 3.139)	Loss 1.0332e-01 (7.2513e-02) 
2023-05-27 14:50:28.932807: val Epoch: [35][18/72]	Time  6.017 ( 3.400)	Data  5.906 ( 3.285)	Loss 5.6892e-02 (7.1691e-02) 
2023-05-27 14:50:29.042572: val Epoch: [35][19/72]	Time  0.110 ( 3.235)	Data  0.000 ( 3.120)	Loss 1.1436e-01 (7.3824e-02) 
2023-05-27 14:50:35.293090: val Epoch: [35][20/72]	Time  6.251 ( 3.379)	Data  6.144 ( 3.264)	Loss 2.8962e-01 (8.4100e-02) 
2023-05-27 14:50:35.398447: val Epoch: [35][21/72]	Time  0.105 ( 3.230)	Data  0.000 ( 3.116)	Loss 9.3829e-02 (8.4543e-02) 
2023-05-27 14:50:41.786087: val Epoch: [35][22/72]	Time  6.388 ( 3.367)	Data  6.278 ( 3.254)	Loss 2.4748e-01 (9.1627e-02) 
2023-05-27 14:50:41.907324: val Epoch: [35][23/72]	Time  0.121 ( 3.232)	Data  0.001 ( 3.118)	Loss 7.6986e-02 (9.1017e-02) 
2023-05-27 14:50:48.178928: val Epoch: [35][24/72]	Time  6.272 ( 3.354)	Data  6.166 ( 3.240)	Loss 3.1905e-01 (1.0014e-01) 
2023-05-27 14:50:48.284552: val Epoch: [35][25/72]	Time  0.106 ( 3.229)	Data  0.001 ( 3.115)	Loss 4.1855e-02 (9.7897e-02) 
2023-05-27 14:50:54.637858: val Epoch: [35][26/72]	Time  6.353 ( 3.345)	Data  6.239 ( 3.231)	Loss 1.3673e-01 (9.9335e-02) 
2023-05-27 14:50:54.753880: val Epoch: [35][27/72]	Time  0.116 ( 3.229)	Data  0.001 ( 3.116)	Loss 6.1279e-02 (9.7976e-02) 
2023-05-27 14:51:00.873409: val Epoch: [35][28/72]	Time  6.120 ( 3.329)	Data  6.014 ( 3.216)	Loss 6.3083e-02 (9.6773e-02) 
2023-05-27 14:51:00.978292: val Epoch: [35][29/72]	Time  0.105 ( 3.221)	Data  0.001 ( 3.108)	Loss 3.4016e-01 (1.0489e-01) 
2023-05-27 14:51:07.272773: val Epoch: [35][30/72]	Time  6.294 ( 3.321)	Data  6.188 ( 3.208)	Loss 3.5479e-01 (1.1295e-01) 
2023-05-27 14:51:07.377599: val Epoch: [35][31/72]	Time  0.105 ( 3.220)	Data  0.000 ( 3.108)	Loss 1.8284e-01 (1.1513e-01) 
2023-05-27 14:51:13.910281: val Epoch: [35][32/72]	Time  6.533 ( 3.320)	Data  6.417 ( 3.208)	Loss 5.6448e-01 (1.2875e-01) 
2023-05-27 14:51:14.020697: val Epoch: [35][33/72]	Time  0.110 ( 3.226)	Data  0.001 ( 3.114)	Loss 5.1583e-02 (1.2648e-01) 
2023-05-27 14:51:20.058755: val Epoch: [35][34/72]	Time  6.038 ( 3.306)	Data  5.925 ( 3.194)	Loss 3.8951e-02 (1.2398e-01) 
2023-05-27 14:51:20.171643: val Epoch: [35][35/72]	Time  0.113 ( 3.218)	Data  0.001 ( 3.105)	Loss 2.7668e-01 (1.2822e-01) 
2023-05-27 14:51:26.368944: val Epoch: [35][36/72]	Time  6.197 ( 3.298)	Data  6.086 ( 3.186)	Loss 9.4874e-02 (1.2732e-01) 
2023-05-27 14:51:26.477502: val Epoch: [35][37/72]	Time  0.109 ( 3.214)	Data  0.001 ( 3.102)	Loss 1.4089e-01 (1.2767e-01) 
2023-05-27 14:51:32.589200: val Epoch: [35][38/72]	Time  6.112 ( 3.289)	Data  6.006 ( 3.176)	Loss 3.2676e-01 (1.3278e-01) 
2023-05-27 14:51:32.694980: val Epoch: [35][39/72]	Time  0.106 ( 3.209)	Data  0.000 ( 3.097)	Loss 5.6580e-02 (1.3087e-01) 
2023-05-27 14:51:38.820618: val Epoch: [35][40/72]	Time  6.126 ( 3.280)	Data  6.019 ( 3.168)	Loss 5.8708e-02 (1.2911e-01) 
2023-05-27 14:51:38.925770: val Epoch: [35][41/72]	Time  0.105 ( 3.205)	Data  0.000 ( 3.093)	Loss 4.3128e-01 (1.3631e-01) 
2023-05-27 14:51:45.135068: val Epoch: [35][42/72]	Time  6.209 ( 3.274)	Data  6.101 ( 3.163)	Loss 8.8272e-02 (1.3519e-01) 
2023-05-27 14:51:45.243759: val Epoch: [35][43/72]	Time  0.109 ( 3.202)	Data  0.001 ( 3.091)	Loss 2.2089e-01 (1.3714e-01) 
2023-05-27 14:51:51.544921: val Epoch: [35][44/72]	Time  6.301 ( 3.271)	Data  6.174 ( 3.159)	Loss 1.3853e-01 (1.3717e-01) 
2023-05-27 14:51:51.651438: val Epoch: [35][45/72]	Time  0.107 ( 3.203)	Data  0.001 ( 3.091)	Loss 4.0735e-01 (1.4304e-01) 
2023-05-27 14:51:57.966295: val Epoch: [35][46/72]	Time  6.315 ( 3.269)	Data  6.206 ( 3.157)	Loss 5.3429e-02 (1.4114e-01) 
2023-05-27 14:51:58.074321: val Epoch: [35][47/72]	Time  0.108 ( 3.203)	Data  0.001 ( 3.091)	Loss 8.9045e-02 (1.4005e-01) 
2023-05-27 14:52:04.085542: val Epoch: [35][48/72]	Time  6.011 ( 3.260)	Data  5.898 ( 3.149)	Loss 1.2424e-01 (1.3973e-01) 
2023-05-27 14:52:04.279843: val Epoch: [35][49/72]	Time  0.194 ( 3.199)	Data  0.001 ( 3.086)	Loss 8.5528e-02 (1.3865e-01) 
2023-05-27 14:52:10.059578: val Epoch: [35][50/72]	Time  5.780 ( 3.250)	Data  5.672 ( 3.136)	Loss 1.2767e-01 (1.3843e-01) 
2023-05-27 14:52:10.167196: val Epoch: [35][51/72]	Time  0.108 ( 3.189)	Data  0.000 ( 3.076)	Loss 5.1023e-02 (1.3675e-01) 
2023-05-27 14:52:16.080970: val Epoch: [35][52/72]	Time  5.914 ( 3.240)	Data  5.807 ( 3.128)	Loss 2.8383e-01 (1.3952e-01) 
2023-05-27 14:52:16.191951: val Epoch: [35][53/72]	Time  0.111 ( 3.183)	Data  0.001 ( 3.070)	Loss 2.0233e-01 (1.4069e-01) 
2023-05-27 14:52:21.912516: val Epoch: [35][54/72]	Time  5.721 ( 3.229)	Data  5.615 ( 3.116)	Loss 6.7974e-02 (1.3936e-01) 
2023-05-27 14:52:22.017884: val Epoch: [35][55/72]	Time  0.105 ( 3.173)	Data  0.001 ( 3.060)	Loss 1.3191e-01 (1.3923e-01) 
2023-05-27 14:52:28.242322: val Epoch: [35][56/72]	Time  6.224 ( 3.226)	Data  6.119 ( 3.114)	Loss 4.8691e-02 (1.3764e-01) 
2023-05-27 14:52:28.348313: val Epoch: [35][57/72]	Time  0.106 ( 3.173)	Data  0.000 ( 3.060)	Loss 2.0266e-01 (1.3876e-01) 
2023-05-27 14:52:34.692849: val Epoch: [35][58/72]	Time  6.345 ( 3.226)	Data  6.235 ( 3.114)	Loss 7.7509e-02 (1.3773e-01) 
2023-05-27 14:52:34.801085: val Epoch: [35][59/72]	Time  0.108 ( 3.174)	Data  0.001 ( 3.062)	Loss 1.6496e-01 (1.3818e-01) 
2023-05-27 14:52:40.651486: val Epoch: [35][60/72]	Time  5.850 ( 3.218)	Data  5.744 ( 3.106)	Loss 5.9648e-02 (1.3689e-01) 
2023-05-27 14:52:40.757139: val Epoch: [35][61/72]	Time  0.106 ( 3.168)	Data  0.000 ( 3.056)	Loss 4.5028e-01 (1.4195e-01) 
2023-05-27 14:52:46.785711: val Epoch: [35][62/72]	Time  6.029 ( 3.214)	Data  5.890 ( 3.101)	Loss 4.2338e-02 (1.4037e-01) 
2023-05-27 14:52:46.896944: val Epoch: [35][63/72]	Time  0.111 ( 3.165)	Data  0.001 ( 3.053)	Loss 1.0463e-01 (1.3981e-01) 
2023-05-27 14:52:53.307922: val Epoch: [35][64/72]	Time  6.411 ( 3.215)	Data  6.301 ( 3.103)	Loss 1.0435e-01 (1.3926e-01) 
2023-05-27 14:52:53.415183: val Epoch: [35][65/72]	Time  0.107 ( 3.168)	Data  0.000 ( 3.056)	Loss 5.7861e-02 (1.3803e-01) 
2023-05-27 14:52:59.329669: val Epoch: [35][66/72]	Time  5.914 ( 3.209)	Data  5.809 ( 3.097)	Loss 5.7623e-02 (1.3683e-01) 
2023-05-27 14:52:59.437826: val Epoch: [35][67/72]	Time  0.108 ( 3.163)	Data  0.001 ( 3.051)	Loss 5.3453e-02 (1.3560e-01) 
2023-05-27 14:53:05.815332: val Epoch: [35][68/72]	Time  6.378 ( 3.210)	Data  6.271 ( 3.098)	Loss 7.9229e-02 (1.3479e-01) 
2023-05-27 14:53:05.925442: val Epoch: [35][69/72]	Time  0.110 ( 3.166)	Data  0.001 ( 3.054)	Loss 7.1046e-02 (1.3388e-01) 
2023-05-27 14:53:11.653093: val Epoch: [35][70/72]	Time  5.728 ( 3.202)	Data  5.623 ( 3.090)	Loss 6.5545e-02 (1.3291e-01) 
2023-05-27 14:53:11.759407: val Epoch: [35][71/72]	Time  0.106 ( 3.159)	Data  0.000 ( 3.047)	Loss 4.4888e-02 (1.3169e-01) 
2023-05-27 14:53:12.129478: Epoch 35 :Val : ['ET : 0.7412734627723694', 'TC : 0.7788397669792175', 'WT : 0.8650068640708923'] 
2023-05-27 14:53:12.133282: Epoch 35 :Val : ['ET : 0.7412734627723694', 'TC : 0.7788397669792175', 'WT : 0.8650068640708923'] 
2023-05-27 14:53:12.137135: Val epoch done in 228.66453840897884 s 
2023-05-27 14:53:12.147821: Batches per epoch:  193 
2023-05-27 14:53:26.122202: train Epoch: [36][  0/193]	Time 13.974 (13.974)	Data 13.378 (13.378)	Loss 8.0018e-02 (8.0018e-02) 
2023-05-27 14:53:26.684955: train Epoch: [36][  1/193]	Time  0.563 ( 7.268)	Data  0.001 ( 6.690)	Loss 2.2009e-01 (1.5005e-01) 
2023-05-27 14:53:38.417901: train Epoch: [36][  2/193]	Time 11.733 ( 8.757)	Data 11.160 ( 8.180)	Loss 1.5594e-01 (1.5202e-01) 
2023-05-27 14:53:38.987622: train Epoch: [36][  3/193]	Time  0.570 ( 6.710)	Data  0.001 ( 6.135)	Loss 8.8289e-02 (1.3608e-01) 
2023-05-27 14:53:50.874673: train Epoch: [36][  4/193]	Time 11.887 ( 7.745)	Data 11.318 ( 7.172)	Loss 5.6274e-02 (1.2012e-01) 
2023-05-27 14:53:51.439618: train Epoch: [36][  5/193]	Time  0.565 ( 6.549)	Data  0.001 ( 5.977)	Loss 7.6145e-02 (1.1279e-01) 
2023-05-27 14:54:03.245638: train Epoch: [36][  6/193]	Time 11.806 ( 7.300)	Data 11.244 ( 6.729)	Loss 8.1761e-02 (1.0836e-01) 
2023-05-27 14:54:03.811335: train Epoch: [36][  7/193]	Time  0.566 ( 6.458)	Data  0.001 ( 5.888)	Loss 1.1740e-01 (1.0949e-01) 
2023-05-27 14:54:15.818974: train Epoch: [36][  8/193]	Time 12.008 ( 7.075)	Data 11.446 ( 6.506)	Loss 8.5048e-02 (1.0677e-01) 
2023-05-27 14:54:16.392437: train Epoch: [36][  9/193]	Time  0.573 ( 6.424)	Data  0.001 ( 5.855)	Loss 4.3962e-02 (1.0049e-01) 
2023-05-27 14:54:27.014171: train Epoch: [36][ 10/193]	Time 10.622 ( 6.806)	Data 10.053 ( 6.237)	Loss 9.1606e-02 (9.9685e-02) 
2023-05-27 14:54:27.579758: train Epoch: [36][ 11/193]	Time  0.566 ( 6.286)	Data  0.001 ( 5.717)	Loss 1.3351e-01 (1.0250e-01) 
2023-05-27 14:54:39.861356: train Epoch: [36][ 12/193]	Time 12.282 ( 6.747)	Data 11.713 ( 6.178)	Loss 1.3068e-01 (1.0467e-01) 
2023-05-27 14:54:40.428903: train Epoch: [36][ 13/193]	Time  0.568 ( 6.306)	Data  0.001 ( 5.737)	Loss 9.9224e-02 (1.0428e-01) 
2023-05-27 14:54:52.196907: train Epoch: [36][ 14/193]	Time 11.768 ( 6.670)	Data 11.207 ( 6.102)	Loss 1.1073e-01 (1.0471e-01) 
2023-05-27 14:54:52.758614: train Epoch: [36][ 15/193]	Time  0.562 ( 6.288)	Data  0.001 ( 5.720)	Loss 6.5376e-02 (1.0225e-01) 
2023-05-27 14:55:05.002238: train Epoch: [36][ 16/193]	Time 12.244 ( 6.638)	Data 11.682 ( 6.071)	Loss 8.8700e-02 (1.0146e-01) 
2023-05-27 14:55:05.565157: train Epoch: [36][ 17/193]	Time  0.563 ( 6.301)	Data  0.001 ( 5.734)	Loss 8.3419e-02 (1.0045e-01) 
2023-05-27 14:55:17.499451: train Epoch: [36][ 18/193]	Time 11.934 ( 6.597)	Data 11.355 ( 6.030)	Loss 9.5852e-02 (1.0021e-01) 
2023-05-27 14:55:18.061661: train Epoch: [36][ 19/193]	Time  0.562 ( 6.296)	Data  0.001 ( 5.728)	Loss 1.2268e-01 (1.0134e-01) 
2023-05-27 14:55:28.369119: train Epoch: [36][ 20/193]	Time 10.307 ( 6.487)	Data  9.746 ( 5.920)	Loss 2.7440e-01 (1.0958e-01) 
2023-05-27 14:55:28.930580: train Epoch: [36][ 21/193]	Time  0.561 ( 6.217)	Data  0.001 ( 5.651)	Loss 3.3449e-01 (1.1980e-01) 
2023-05-27 14:55:39.640342: train Epoch: [36][ 22/193]	Time 10.710 ( 6.413)	Data 10.148 ( 5.846)	Loss 1.3181e-01 (1.2032e-01) 
2023-05-27 14:55:40.202298: train Epoch: [36][ 23/193]	Time  0.562 ( 6.169)	Data  0.001 ( 5.603)	Loss 8.7595e-02 (1.1896e-01) 
2023-05-27 14:55:51.704942: train Epoch: [36][ 24/193]	Time 11.503 ( 6.382)	Data 10.938 ( 5.816)	Loss 6.5326e-02 (1.1681e-01) 
2023-05-27 14:55:52.268140: train Epoch: [36][ 25/193]	Time  0.563 ( 6.158)	Data  0.001 ( 5.592)	Loss 6.2860e-02 (1.1474e-01) 
2023-05-27 14:56:03.957484: train Epoch: [36][ 26/193]	Time 11.689 ( 6.363)	Data 11.102 ( 5.796)	Loss 3.0572e-02 (1.1162e-01) 
2023-05-27 14:56:04.542780: train Epoch: [36][ 27/193]	Time  0.585 ( 6.157)	Data  0.024 ( 5.590)	Loss 8.4396e-02 (1.1065e-01) 
2023-05-27 14:56:16.703953: train Epoch: [36][ 28/193]	Time 12.161 ( 6.364)	Data 11.600 ( 5.797)	Loss 5.1868e-02 (1.0862e-01) 
2023-05-27 14:56:17.265580: train Epoch: [36][ 29/193]	Time  0.562 ( 6.171)	Data  0.001 ( 5.604)	Loss 1.1143e-01 (1.0872e-01) 
2023-05-27 14:56:28.915361: train Epoch: [36][ 30/193]	Time 11.650 ( 6.347)	Data 11.083 ( 5.781)	Loss 1.1229e-01 (1.0883e-01) 
2023-05-27 14:56:29.494997: train Epoch: [36][ 31/193]	Time  0.580 ( 6.167)	Data  0.001 ( 5.600)	Loss 8.0698e-02 (1.0795e-01) 
2023-05-27 14:56:41.225293: train Epoch: [36][ 32/193]	Time 11.730 ( 6.336)	Data 11.159 ( 5.769)	Loss 2.8551e-01 (1.1333e-01) 
2023-05-27 14:56:42.148159: train Epoch: [36][ 33/193]	Time  0.923 ( 6.176)	Data  0.354 ( 5.610)	Loss 7.8049e-02 (1.1229e-01) 
2023-05-27 14:56:53.397165: train Epoch: [36][ 34/193]	Time 11.249 ( 6.321)	Data 10.687 ( 5.755)	Loss 6.0750e-02 (1.1082e-01) 
2023-05-27 14:56:54.373710: train Epoch: [36][ 35/193]	Time  0.977 ( 6.173)	Data  0.415 ( 5.606)	Loss 6.2297e-02 (1.0947e-01) 
2023-05-27 14:57:06.457590: train Epoch: [36][ 36/193]	Time 12.084 ( 6.333)	Data 11.498 ( 5.766)	Loss 7.2966e-02 (1.0849e-01) 
2023-05-27 14:57:07.094715: train Epoch: [36][ 37/193]	Time  0.637 ( 6.183)	Data  0.075 ( 5.616)	Loss 1.1445e-01 (1.0864e-01) 
2023-05-27 14:57:18.418392: train Epoch: [36][ 38/193]	Time 11.324 ( 6.315)	Data 10.759 ( 5.748)	Loss 5.7531e-02 (1.0733e-01) 
2023-05-27 14:57:19.710293: train Epoch: [36][ 39/193]	Time  1.292 ( 6.189)	Data  0.724 ( 5.622)	Loss 7.1193e-02 (1.0643e-01) 
2023-05-27 14:57:30.645734: train Epoch: [36][ 40/193]	Time 10.935 ( 6.305)	Data 10.363 ( 5.738)	Loss 8.1738e-02 (1.0583e-01) 
2023-05-27 14:57:31.778737: train Epoch: [36][ 41/193]	Time  1.133 ( 6.182)	Data  0.571 ( 5.615)	Loss 1.2174e-01 (1.0621e-01) 
2023-05-27 14:57:42.919213: train Epoch: [36][ 42/193]	Time 11.140 ( 6.297)	Data 10.580 ( 5.730)	Loss 3.9433e-02 (1.0465e-01) 
2023-05-27 14:57:44.161555: train Epoch: [36][ 43/193]	Time  1.242 ( 6.182)	Data  0.666 ( 5.615)	Loss 1.0076e-01 (1.0457e-01) 
2023-05-27 14:57:54.796184: train Epoch: [36][ 44/193]	Time 10.635 ( 6.281)	Data 10.069 ( 5.714)	Loss 5.3689e-02 (1.0343e-01) 
2023-05-27 14:57:56.459135: train Epoch: [36][ 45/193]	Time  1.663 ( 6.181)	Data  1.101 ( 5.614)	Loss 6.8780e-02 (1.0268e-01) 
2023-05-27 14:58:07.381463: train Epoch: [36][ 46/193]	Time 10.922 ( 6.282)	Data 10.354 ( 5.715)	Loss 8.3920e-02 (1.0228e-01) 
2023-05-27 14:58:08.665408: train Epoch: [36][ 47/193]	Time  1.284 ( 6.177)	Data  0.722 ( 5.611)	Loss 6.1196e-02 (1.0143e-01) 
2023-05-27 14:58:19.633054: train Epoch: [36][ 48/193]	Time 10.968 ( 6.275)	Data 10.398 ( 5.708)	Loss 8.5249e-02 (1.0110e-01) 
2023-05-27 14:58:21.014469: train Epoch: [36][ 49/193]	Time  1.381 ( 6.177)	Data  0.819 ( 5.611)	Loss 1.0686e-01 (1.0121e-01) 
2023-05-27 14:58:32.068307: train Epoch: [36][ 50/193]	Time 11.054 ( 6.273)	Data 10.484 ( 5.706)	Loss 6.3310e-02 (1.0047e-01) 
2023-05-27 14:58:33.549774: train Epoch: [36][ 51/193]	Time  1.481 ( 6.181)	Data  0.919 ( 5.614)	Loss 7.6636e-02 (1.0001e-01) 
2023-05-27 14:58:44.392534: train Epoch: [36][ 52/193]	Time 10.843 ( 6.269)	Data 10.281 ( 5.702)	Loss 7.7593e-02 (9.9587e-02) 
2023-05-27 14:58:45.727574: train Epoch: [36][ 53/193]	Time  1.335 ( 6.177)	Data  0.768 ( 5.611)	Loss 1.1630e-01 (9.9896e-02) 
2023-05-27 14:58:57.015997: train Epoch: [36][ 54/193]	Time 11.288 ( 6.270)	Data 10.723 ( 5.704)	Loss 7.4744e-02 (9.9439e-02) 
2023-05-27 14:58:57.805891: train Epoch: [36][ 55/193]	Time  0.790 ( 6.172)	Data  0.209 ( 5.606)	Loss 1.0765e-01 (9.9586e-02) 
2023-05-27 14:59:09.218401: train Epoch: [36][ 56/193]	Time 11.413 ( 6.264)	Data 10.846 ( 5.697)	Loss 7.7568e-02 (9.9199e-02) 
2023-05-27 14:59:10.495927: train Epoch: [36][ 57/193]	Time  1.278 ( 6.178)	Data  0.706 ( 5.611)	Loss 6.5882e-02 (9.8625e-02) 
2023-05-27 14:59:21.069004: train Epoch: [36][ 58/193]	Time 10.573 ( 6.253)	Data 10.006 ( 5.686)	Loss 5.5253e-02 (9.7890e-02) 
2023-05-27 14:59:22.595876: train Epoch: [36][ 59/193]	Time  1.527 ( 6.174)	Data  0.953 ( 5.607)	Loss 7.8649e-02 (9.7569e-02) 
2023-05-27 14:59:33.321675: train Epoch: [36][ 60/193]	Time 10.726 ( 6.249)	Data 10.158 ( 5.682)	Loss 4.0045e-02 (9.6626e-02) 
2023-05-27 14:59:35.273297: train Epoch: [36][ 61/193]	Time  1.952 ( 6.179)	Data  1.383 ( 5.612)	Loss 7.6427e-02 (9.6300e-02) 
2023-05-27 14:59:45.118785: train Epoch: [36][ 62/193]	Time  9.845 ( 6.238)	Data  9.272 ( 5.670)	Loss 1.0306e-01 (9.6408e-02) 
2023-05-27 14:59:46.897651: train Epoch: [36][ 63/193]	Time  1.779 ( 6.168)	Data  1.211 ( 5.601)	Loss 9.6856e-02 (9.6415e-02) 
2023-05-27 14:59:57.701253: train Epoch: [36][ 64/193]	Time 10.804 ( 6.239)	Data 10.189 ( 5.671)	Loss 6.5693e-02 (9.5942e-02) 
2023-05-27 14:59:59.142291: train Epoch: [36][ 65/193]	Time  1.441 ( 6.167)	Data  0.866 ( 5.598)	Loss 8.7911e-02 (9.5820e-02) 
2023-05-27 15:00:09.859090: train Epoch: [36][ 66/193]	Time 10.717 ( 6.234)	Data 10.148 ( 5.666)	Loss 9.1148e-02 (9.5751e-02) 
2023-05-27 15:00:11.196412: train Epoch: [36][ 67/193]	Time  1.337 ( 6.162)	Data  0.760 ( 5.594)	Loss 5.6964e-02 (9.5180e-02) 
2023-05-27 15:00:22.125613: train Epoch: [36][ 68/193]	Time 10.929 ( 6.232)	Data 10.360 ( 5.663)	Loss 6.0882e-02 (9.4683e-02) 
2023-05-27 15:00:23.476933: train Epoch: [36][ 69/193]	Time  1.351 ( 6.162)	Data  0.786 ( 5.594)	Loss 8.4802e-02 (9.4542e-02) 
2023-05-27 15:00:34.359972: train Epoch: [36][ 70/193]	Time 10.883 ( 6.228)	Data 10.291 ( 5.660)	Loss 7.4499e-02 (9.4260e-02) 
2023-05-27 15:00:36.186728: train Epoch: [36][ 71/193]	Time  1.827 ( 6.167)	Data  1.252 ( 5.599)	Loss 3.6658e-02 (9.3460e-02) 
2023-05-27 15:00:46.534775: train Epoch: [36][ 72/193]	Time 10.348 ( 6.224)	Data  9.771 ( 5.656)	Loss 6.3499e-02 (9.3049e-02) 
2023-05-27 15:00:47.832274: train Epoch: [36][ 73/193]	Time  1.297 ( 6.158)	Data  0.720 ( 5.589)	Loss 5.8780e-02 (9.2586e-02) 
2023-05-27 15:00:59.184850: train Epoch: [36][ 74/193]	Time 11.353 ( 6.227)	Data 10.782 ( 5.658)	Loss 7.9838e-02 (9.2416e-02) 
2023-05-27 15:01:00.428223: train Epoch: [36][ 75/193]	Time  1.243 ( 6.162)	Data  0.653 ( 5.592)	Loss 8.3929e-02 (9.2305e-02) 
2023-05-27 15:01:11.209230: train Epoch: [36][ 76/193]	Time 10.781 ( 6.222)	Data 10.218 ( 5.652)	Loss 7.5678e-02 (9.2089e-02) 
2023-05-27 15:01:12.348692: train Epoch: [36][ 77/193]	Time  1.139 ( 6.156)	Data  0.561 ( 5.587)	Loss 1.6021e-01 (9.2962e-02) 
2023-05-27 15:01:24.102660: train Epoch: [36][ 78/193]	Time 11.754 ( 6.227)	Data 11.175 ( 5.658)	Loss 1.0580e-01 (9.3125e-02) 
2023-05-27 15:01:25.130324: train Epoch: [36][ 79/193]	Time  1.028 ( 6.162)	Data  0.452 ( 5.593)	Loss 8.6817e-02 (9.3046e-02) 
2023-05-27 15:01:36.578406: train Epoch: [36][ 80/193]	Time 11.448 ( 6.228)	Data 10.796 ( 5.657)	Loss 7.7103e-02 (9.2849e-02) 
2023-05-27 15:01:37.190421: train Epoch: [36][ 81/193]	Time  0.612 ( 6.159)	Data  0.043 ( 5.589)	Loss 5.5639e-02 (9.2395e-02) 
2023-05-27 15:01:48.761561: train Epoch: [36][ 82/193]	Time 11.571 ( 6.224)	Data 11.006 ( 5.654)	Loss 6.0190e-02 (9.2007e-02) 
2023-05-27 15:01:49.659866: train Epoch: [36][ 83/193]	Time  0.898 ( 6.161)	Data  0.320 ( 5.590)	Loss 8.6607e-02 (9.1943e-02) 
2023-05-27 15:02:01.307890: train Epoch: [36][ 84/193]	Time 11.648 ( 6.225)	Data 11.078 ( 5.655)	Loss 5.8100e-02 (9.1545e-02) 
2023-05-27 15:02:02.159095: train Epoch: [36][ 85/193]	Time  0.851 ( 6.163)	Data  0.230 ( 5.592)	Loss 4.3315e-02 (9.0984e-02) 
2023-05-27 15:02:12.334413: train Epoch: [36][ 86/193]	Time 10.175 ( 6.209)	Data  9.605 ( 5.638)	Loss 9.4621e-02 (9.1026e-02) 
2023-05-27 15:02:13.175642: train Epoch: [36][ 87/193]	Time  0.841 ( 6.148)	Data  0.259 ( 5.577)	Loss 1.0462e-01 (9.1180e-02) 
2023-05-27 15:02:23.265383: train Epoch: [36][ 88/193]	Time 10.090 ( 6.192)	Data  9.518 ( 5.621)	Loss 1.0929e-01 (9.1384e-02) 
2023-05-27 15:02:24.247502: train Epoch: [36][ 89/193]	Time  0.982 ( 6.134)	Data  0.417 ( 5.563)	Loss 6.2256e-02 (9.1060e-02) 
2023-05-27 15:02:35.558020: train Epoch: [36][ 90/193]	Time 11.311 ( 6.191)	Data 10.748 ( 5.620)	Loss 1.1383e-01 (9.1310e-02) 
2023-05-27 15:02:36.578244: train Epoch: [36][ 91/193]	Time  1.020 ( 6.135)	Data  0.425 ( 5.564)	Loss 1.2231e-01 (9.1647e-02) 
2023-05-27 15:02:48.202175: train Epoch: [36][ 92/193]	Time 11.624 ( 6.194)	Data 11.060 ( 5.623)	Loss 1.4955e-01 (9.2270e-02) 
2023-05-27 15:02:48.767175: train Epoch: [36][ 93/193]	Time  0.565 ( 6.134)	Data  0.001 ( 5.563)	Loss 1.6033e-01 (9.2994e-02) 
2023-05-27 15:03:00.738033: train Epoch: [36][ 94/193]	Time 11.971 ( 6.196)	Data 11.408 ( 5.625)	Loss 1.1806e-01 (9.3258e-02) 
2023-05-27 15:03:01.400099: train Epoch: [36][ 95/193]	Time  0.662 ( 6.138)	Data  0.094 ( 5.567)	Loss 7.2599e-02 (9.3042e-02) 
2023-05-27 15:03:13.506111: train Epoch: [36][ 96/193]	Time 12.106 ( 6.200)	Data 11.530 ( 5.629)	Loss 7.5227e-02 (9.2859e-02) 
2023-05-27 15:03:14.073743: train Epoch: [36][ 97/193]	Time  0.568 ( 6.142)	Data  0.001 ( 5.571)	Loss 5.0495e-02 (9.2426e-02) 
2023-05-27 15:03:25.975057: train Epoch: [36][ 98/193]	Time 11.901 ( 6.200)	Data 11.336 ( 5.629)	Loss 9.5547e-02 (9.2458e-02) 
2023-05-27 15:03:26.554624: train Epoch: [36][ 99/193]	Time  0.580 ( 6.144)	Data  0.001 ( 5.573)	Loss 1.1393e-01 (9.2673e-02) 
2023-05-27 15:03:38.613522: train Epoch: [36][100/193]	Time 12.059 ( 6.203)	Data 11.486 ( 5.632)	Loss 5.5555e-02 (9.2305e-02) 
2023-05-27 15:03:39.191616: train Epoch: [36][101/193]	Time  0.578 ( 6.147)	Data  0.001 ( 5.576)	Loss 6.7991e-02 (9.2067e-02) 
2023-05-27 15:03:50.911913: train Epoch: [36][102/193]	Time 11.720 ( 6.202)	Data 11.142 ( 5.630)	Loss 6.2365e-02 (9.1778e-02) 
2023-05-27 15:03:51.490113: train Epoch: [36][103/193]	Time  0.578 ( 6.148)	Data  0.001 ( 5.576)	Loss 2.4592e-01 (9.3261e-02) 
2023-05-27 15:04:03.738910: train Epoch: [36][104/193]	Time 12.249 ( 6.206)	Data 11.684 ( 5.634)	Loss 9.8117e-02 (9.3307e-02) 
2023-05-27 15:04:04.375569: train Epoch: [36][105/193]	Time  0.637 ( 6.153)	Data  0.013 ( 5.581)	Loss 9.5253e-02 (9.3325e-02) 
2023-05-27 15:04:16.710547: train Epoch: [36][106/193]	Time 12.335 ( 6.211)	Data 11.753 ( 5.639)	Loss 1.6177e-01 (9.3965e-02) 
2023-05-27 15:04:17.293232: train Epoch: [36][107/193]	Time  0.583 ( 6.159)	Data  0.001 ( 5.587)	Loss 9.6271e-02 (9.3986e-02) 
2023-05-27 15:04:29.013697: train Epoch: [36][108/193]	Time 11.720 ( 6.210)	Data 11.149 ( 5.638)	Loss 1.0438e-01 (9.4082e-02) 
2023-05-27 15:04:29.589819: train Epoch: [36][109/193]	Time  0.576 ( 6.159)	Data  0.001 ( 5.587)	Loss 7.6824e-02 (9.3925e-02) 
2023-05-27 15:04:41.551774: train Epoch: [36][110/193]	Time 11.962 ( 6.211)	Data 11.387 ( 5.639)	Loss 8.2445e-02 (9.3821e-02) 
2023-05-27 15:04:42.118915: train Epoch: [36][111/193]	Time  0.567 ( 6.160)	Data  0.001 ( 5.589)	Loss 7.7552e-02 (9.3676e-02) 
2023-05-27 15:04:54.167001: train Epoch: [36][112/193]	Time 12.048 ( 6.213)	Data 11.483 ( 5.641)	Loss 9.2546e-02 (9.3666e-02) 
2023-05-27 15:04:54.746933: train Epoch: [36][113/193]	Time  0.580 ( 6.163)	Data  0.001 ( 5.591)	Loss 3.9415e-02 (9.3190e-02) 
2023-05-27 15:05:06.651467: train Epoch: [36][114/193]	Time 11.905 ( 6.213)	Data 11.339 ( 5.641)	Loss 1.1526e-01 (9.3382e-02) 
2023-05-27 15:05:07.232513: train Epoch: [36][115/193]	Time  0.581 ( 6.165)	Data  0.001 ( 5.593)	Loss 6.4609e-02 (9.3134e-02) 
2023-05-27 15:05:19.319186: train Epoch: [36][116/193]	Time 12.087 ( 6.215)	Data 11.515 ( 5.643)	Loss 5.6514e-02 (9.2821e-02) 
2023-05-27 15:05:19.910767: train Epoch: [36][117/193]	Time  0.592 ( 6.167)	Data  0.001 ( 5.595)	Loss 6.0873e-02 (9.2550e-02) 
2023-05-27 15:05:31.914659: train Epoch: [36][118/193]	Time 12.004 ( 6.217)	Data 11.429 ( 5.644)	Loss 6.7845e-02 (9.2343e-02) 
2023-05-27 15:05:32.498463: train Epoch: [36][119/193]	Time  0.584 ( 6.170)	Data  0.001 ( 5.597)	Loss 7.5347e-02 (9.2201e-02) 
2023-05-27 15:05:44.496313: train Epoch: [36][120/193]	Time 11.998 ( 6.218)	Data 11.429 ( 5.646)	Loss 1.7123e-01 (9.2854e-02) 
2023-05-27 15:05:45.072788: train Epoch: [36][121/193]	Time  0.576 ( 6.172)	Data  0.001 ( 5.599)	Loss 4.3627e-02 (9.2451e-02) 
2023-05-27 15:05:56.788392: train Epoch: [36][122/193]	Time 11.716 ( 6.217)	Data 11.153 ( 5.645)	Loss 6.1105e-02 (9.2196e-02) 
2023-05-27 15:05:57.354541: train Epoch: [36][123/193]	Time  0.566 ( 6.171)	Data  0.001 ( 5.599)	Loss 9.3809e-02 (9.2209e-02) 
2023-05-27 15:06:08.883786: train Epoch: [36][124/193]	Time 11.529 ( 6.214)	Data 10.947 ( 5.642)	Loss 6.8930e-02 (9.2022e-02) 
2023-05-27 15:06:09.460872: train Epoch: [36][125/193]	Time  0.577 ( 6.169)	Data  0.001 ( 5.597)	Loss 1.0140e-01 (9.2097e-02) 
2023-05-27 15:06:20.957000: train Epoch: [36][126/193]	Time 11.496 ( 6.211)	Data 10.933 ( 5.639)	Loss 4.2515e-02 (9.1707e-02) 
2023-05-27 15:06:21.523047: train Epoch: [36][127/193]	Time  0.566 ( 6.167)	Data  0.001 ( 5.595)	Loss 7.7359e-02 (9.1594e-02) 
2023-05-27 15:06:33.577909: train Epoch: [36][128/193]	Time 12.055 ( 6.213)	Data 11.484 ( 5.641)	Loss 1.1306e-01 (9.1761e-02) 
2023-05-27 15:06:34.170281: train Epoch: [36][129/193]	Time  0.592 ( 6.169)	Data  0.001 ( 5.597)	Loss 7.5009e-02 (9.1632e-02) 
2023-05-27 15:06:46.144238: train Epoch: [36][130/193]	Time 11.974 ( 6.214)	Data 11.400 ( 5.642)	Loss 8.7251e-02 (9.1599e-02) 
2023-05-27 15:06:46.725819: train Epoch: [36][131/193]	Time  0.582 ( 6.171)	Data  0.001 ( 5.599)	Loss 8.1980e-02 (9.1526e-02) 
2023-05-27 15:06:58.476122: train Epoch: [36][132/193]	Time 11.750 ( 6.213)	Data 11.178 ( 5.641)	Loss 5.2772e-02 (9.1234e-02) 
2023-05-27 15:06:59.043985: train Epoch: [36][133/193]	Time  0.568 ( 6.171)	Data  0.001 ( 5.599)	Loss 1.2898e-01 (9.1516e-02) 
2023-05-27 15:07:10.775027: train Epoch: [36][134/193]	Time 11.731 ( 6.212)	Data 11.153 ( 5.640)	Loss 7.8400e-02 (9.1419e-02) 
2023-05-27 15:07:11.361304: train Epoch: [36][135/193]	Time  0.586 ( 6.171)	Data  0.001 ( 5.598)	Loss 9.0600e-02 (9.1413e-02) 
2023-05-27 15:07:23.765140: train Epoch: [36][136/193]	Time 12.404 ( 6.216)	Data 11.829 ( 5.644)	Loss 5.3330e-02 (9.1135e-02) 
2023-05-27 15:07:24.336923: train Epoch: [36][137/193]	Time  0.572 ( 6.175)	Data  0.001 ( 5.603)	Loss 1.4688e-01 (9.1539e-02) 
2023-05-27 15:07:36.352962: train Epoch: [36][138/193]	Time 12.016 ( 6.217)	Data 11.453 ( 5.645)	Loss 1.0086e-01 (9.1606e-02) 
2023-05-27 15:07:36.938993: train Epoch: [36][139/193]	Time  0.586 ( 6.177)	Data  0.001 ( 5.605)	Loss 8.3313e-02 (9.1547e-02) 
2023-05-27 15:07:48.946553: train Epoch: [36][140/193]	Time 12.008 ( 6.218)	Data 11.439 ( 5.646)	Loss 1.1315e-01 (9.1700e-02) 
2023-05-27 15:07:49.521822: train Epoch: [36][141/193]	Time  0.575 ( 6.179)	Data  0.001 ( 5.606)	Loss 6.3443e-02 (9.1501e-02) 
2023-05-27 15:08:01.540541: train Epoch: [36][142/193]	Time 12.019 ( 6.220)	Data 11.443 ( 5.647)	Loss 1.1042e-01 (9.1633e-02) 
2023-05-27 15:08:02.156271: train Epoch: [36][143/193]	Time  0.616 ( 6.181)	Data  0.001 ( 5.608)	Loss 8.2341e-02 (9.1569e-02) 
2023-05-27 15:08:14.343596: train Epoch: [36][144/193]	Time 12.187 ( 6.222)	Data 11.618 ( 5.649)	Loss 1.3027e-01 (9.1835e-02) 
2023-05-27 15:08:14.933485: train Epoch: [36][145/193]	Time  0.590 ( 6.183)	Data  0.001 ( 5.611)	Loss 6.9616e-02 (9.1683e-02) 
2023-05-27 15:08:26.496335: train Epoch: [36][146/193]	Time 11.563 ( 6.220)	Data 10.987 ( 5.647)	Loss 8.4697e-02 (9.1636e-02) 
2023-05-27 15:08:27.078263: train Epoch: [36][147/193]	Time  0.582 ( 6.182)	Data  0.001 ( 5.609)	Loss 5.1144e-02 (9.1362e-02) 
2023-05-27 15:08:38.990913: train Epoch: [36][148/193]	Time 11.913 ( 6.220)	Data 11.336 ( 5.648)	Loss 4.2482e-02 (9.1034e-02) 
2023-05-27 15:08:39.559806: train Epoch: [36][149/193]	Time  0.569 ( 6.183)	Data  0.001 ( 5.610)	Loss 8.9347e-02 (9.1023e-02) 
2023-05-27 15:08:51.597298: train Epoch: [36][150/193]	Time 12.037 ( 6.222)	Data 11.467 ( 5.649)	Loss 4.5636e-02 (9.0722e-02) 
2023-05-27 15:08:52.180561: train Epoch: [36][151/193]	Time  0.583 ( 6.184)	Data  0.001 ( 5.612)	Loss 7.2560e-02 (9.0603e-02) 
2023-05-27 15:09:04.074338: train Epoch: [36][152/193]	Time 11.894 ( 6.222)	Data 11.321 ( 5.649)	Loss 5.8775e-02 (9.0395e-02) 
2023-05-27 15:09:04.668976: train Epoch: [36][153/193]	Time  0.595 ( 6.185)	Data  0.001 ( 5.612)	Loss 7.1602e-02 (9.0273e-02) 
2023-05-27 15:09:15.912305: train Epoch: [36][154/193]	Time 11.243 ( 6.218)	Data 10.673 ( 5.645)	Loss 5.4041e-02 (9.0039e-02) 
2023-05-27 15:09:16.478124: train Epoch: [36][155/193]	Time  0.566 ( 6.182)	Data  0.001 ( 5.609)	Loss 7.6797e-02 (8.9954e-02) 
2023-05-27 15:09:28.718930: train Epoch: [36][156/193]	Time 12.241 ( 6.220)	Data 11.668 ( 5.647)	Loss 6.6390e-02 (8.9804e-02) 
2023-05-27 15:09:29.312292: train Epoch: [36][157/193]	Time  0.593 ( 6.185)	Data  0.001 ( 5.612)	Loss 7.9843e-02 (8.9741e-02) 
2023-05-27 15:09:40.980255: train Epoch: [36][158/193]	Time 11.668 ( 6.219)	Data 11.101 ( 5.646)	Loss 1.0649e-01 (8.9846e-02) 
2023-05-27 15:09:41.545870: train Epoch: [36][159/193]	Time  0.566 ( 6.184)	Data  0.001 ( 5.611)	Loss 7.2054e-02 (8.9735e-02) 
2023-05-27 15:09:53.247961: train Epoch: [36][160/193]	Time 11.702 ( 6.218)	Data 11.140 ( 5.645)	Loss 1.3903e-01 (9.0041e-02) 
2023-05-27 15:09:53.814317: train Epoch: [36][161/193]	Time  0.566 ( 6.183)	Data  0.001 ( 5.610)	Loss 1.2146e-01 (9.0235e-02) 
2023-05-27 15:10:05.491027: train Epoch: [36][162/193]	Time 11.677 ( 6.217)	Data 11.103 ( 5.644)	Loss 7.2835e-02 (9.0128e-02) 
2023-05-27 15:10:06.054060: train Epoch: [36][163/193]	Time  0.563 ( 6.182)	Data  0.001 ( 5.610)	Loss 7.0686e-02 (9.0010e-02) 
2023-05-27 15:10:18.029038: train Epoch: [36][164/193]	Time 11.975 ( 6.217)	Data 11.414 ( 5.645)	Loss 8.5569e-02 (8.9983e-02) 
2023-05-27 15:10:18.591469: train Epoch: [36][165/193]	Time  0.562 ( 6.183)	Data  0.001 ( 5.611)	Loss 7.1916e-02 (8.9874e-02) 
2023-05-27 15:10:30.316725: train Epoch: [36][166/193]	Time 11.725 ( 6.217)	Data 11.163 ( 5.644)	Loss 7.9775e-02 (8.9814e-02) 
2023-05-27 15:10:30.881437: train Epoch: [36][167/193]	Time  0.565 ( 6.183)	Data  0.001 ( 5.610)	Loss 2.3732e-01 (9.0692e-02) 
2023-05-27 15:10:43.099960: train Epoch: [36][168/193]	Time 12.219 ( 6.219)	Data 11.657 ( 5.646)	Loss 6.7927e-02 (9.0557e-02) 
2023-05-27 15:10:43.662695: train Epoch: [36][169/193]	Time  0.563 ( 6.185)	Data  0.001 ( 5.613)	Loss 4.4276e-02 (9.0285e-02) 
2023-05-27 15:10:55.561599: train Epoch: [36][170/193]	Time 11.899 ( 6.219)	Data 11.321 ( 5.646)	Loss 6.3472e-02 (9.0128e-02) 
2023-05-27 15:10:56.128820: train Epoch: [36][171/193]	Time  0.567 ( 6.186)	Data  0.001 ( 5.614)	Loss 8.3520e-02 (9.0089e-02) 
2023-05-27 15:11:07.973046: train Epoch: [36][172/193]	Time 11.844 ( 6.219)	Data 11.283 ( 5.646)	Loss 8.8344e-02 (9.0079e-02) 
2023-05-27 15:11:08.536447: train Epoch: [36][173/193]	Time  0.563 ( 6.186)	Data  0.001 ( 5.614)	Loss 7.6831e-02 (9.0003e-02) 
2023-05-27 15:11:20.197890: train Epoch: [36][174/193]	Time 11.661 ( 6.217)	Data 11.099 ( 5.645)	Loss 6.2408e-02 (8.9846e-02) 
2023-05-27 15:11:20.761396: train Epoch: [36][175/193]	Time  0.564 ( 6.185)	Data  0.001 ( 5.613)	Loss 7.6256e-02 (8.9768e-02) 
2023-05-27 15:11:32.167730: train Epoch: [36][176/193]	Time 11.406 ( 6.215)	Data 10.844 ( 5.643)	Loss 6.2649e-02 (8.9615e-02) 
2023-05-27 15:11:32.730074: train Epoch: [36][177/193]	Time  0.562 ( 6.183)	Data  0.001 ( 5.611)	Loss 7.0292e-02 (8.9507e-02) 
2023-05-27 15:11:43.926897: train Epoch: [36][178/193]	Time 11.197 ( 6.211)	Data 10.617 ( 5.639)	Loss 1.3350e-01 (8.9752e-02) 
2023-05-27 15:11:44.495167: train Epoch: [36][179/193]	Time  0.568 ( 6.180)	Data  0.001 ( 5.608)	Loss 8.3012e-02 (8.9715e-02) 
2023-05-27 15:11:55.103138: train Epoch: [36][180/193]	Time 10.608 ( 6.204)	Data 10.042 ( 5.632)	Loss 1.0167e-01 (8.9781e-02) 
2023-05-27 15:11:55.670236: train Epoch: [36][181/193]	Time  0.567 ( 6.173)	Data  0.001 ( 5.601)	Loss 1.0660e-01 (8.9873e-02) 
2023-05-27 15:12:07.613343: train Epoch: [36][182/193]	Time 11.943 ( 6.205)	Data 11.381 ( 5.633)	Loss 5.9720e-02 (8.9709e-02) 
2023-05-27 15:12:08.175906: train Epoch: [36][183/193]	Time  0.563 ( 6.174)	Data  0.001 ( 5.602)	Loss 8.4288e-02 (8.9679e-02) 
2023-05-27 15:12:20.664976: train Epoch: [36][184/193]	Time 12.489 ( 6.208)	Data 11.922 ( 5.636)	Loss 7.7947e-02 (8.9616e-02) 
2023-05-27 15:12:21.232776: train Epoch: [36][185/193]	Time  0.568 ( 6.178)	Data  0.001 ( 5.606)	Loss 5.4270e-02 (8.9426e-02) 
2023-05-27 15:12:33.108135: train Epoch: [36][186/193]	Time 11.875 ( 6.208)	Data 11.303 ( 5.636)	Loss 4.0713e-02 (8.9165e-02) 
2023-05-27 15:12:33.674422: train Epoch: [36][187/193]	Time  0.566 ( 6.178)	Data  0.001 ( 5.607)	Loss 7.3310e-02 (8.9081e-02) 
2023-05-27 15:12:45.285613: train Epoch: [36][188/193]	Time 11.611 ( 6.207)	Data 11.040 ( 5.635)	Loss 1.1335e-01 (8.9209e-02) 
2023-05-27 15:12:45.848104: train Epoch: [36][189/193]	Time  0.562 ( 6.177)	Data  0.001 ( 5.606)	Loss 5.7434e-02 (8.9042e-02) 
2023-05-27 15:12:56.720667: train Epoch: [36][190/193]	Time 10.873 ( 6.202)	Data 10.299 ( 5.630)	Loss 2.7400e-01 (9.0010e-02) 
2023-05-27 15:12:57.296506: train Epoch: [36][191/193]	Time  0.576 ( 6.173)	Data  0.001 ( 5.601)	Loss 8.6155e-02 (8.9990e-02) 
2023-05-27 15:13:07.752842: train Epoch: [36][192/193]	Time 10.456 ( 6.195)	Data  9.890 ( 5.623)	Loss 8.7103e-02 (8.9975e-02) 
2023-05-27 15:13:07.968072: Train Epoch done in 1195.8202923019999 s 
2023-05-27 15:13:16.321766: val Epoch: [36][ 0/72]	Time  7.632 ( 7.632)	Data  7.448 ( 7.448)	Loss 3.9862e-01 (3.9862e-01) 
2023-05-27 15:13:16.436031: val Epoch: [36][ 1/72]	Time  0.114 ( 3.873)	Data  0.002 ( 3.725)	Loss 1.0791e-01 (2.5326e-01) 
2023-05-27 15:13:22.449763: val Epoch: [36][ 2/72]	Time  6.014 ( 4.587)	Data  5.907 ( 4.452)	Loss 1.6961e-01 (2.2538e-01) 
2023-05-27 15:13:22.692398: val Epoch: [36][ 3/72]	Time  0.243 ( 3.501)	Data  0.136 ( 3.373)	Loss 5.9872e-02 (1.8400e-01) 
2023-05-27 15:13:28.961820: val Epoch: [36][ 4/72]	Time  6.269 ( 4.055)	Data  6.163 ( 3.931)	Loss 7.5365e-02 (1.6227e-01) 
2023-05-27 15:13:29.066998: val Epoch: [36][ 5/72]	Time  0.105 ( 3.396)	Data  0.000 ( 3.276)	Loss 1.1032e-01 (1.5362e-01) 
2023-05-27 15:13:35.454459: val Epoch: [36][ 6/72]	Time  6.387 ( 3.824)	Data  6.278 ( 3.705)	Loss 1.2059e-01 (1.4890e-01) 
2023-05-27 15:13:35.565799: val Epoch: [36][ 7/72]	Time  0.111 ( 3.360)	Data  0.001 ( 3.242)	Loss 3.7881e-02 (1.3502e-01) 
2023-05-27 15:13:42.031192: val Epoch: [36][ 8/72]	Time  6.465 ( 3.705)	Data  6.357 ( 3.588)	Loss 7.9694e-02 (1.2887e-01) 
2023-05-27 15:13:42.139084: val Epoch: [36][ 9/72]	Time  0.108 ( 3.345)	Data  0.001 ( 3.229)	Loss 6.2768e-02 (1.2226e-01) 
2023-05-27 15:13:48.435930: val Epoch: [36][10/72]	Time  6.297 ( 3.613)	Data  6.188 ( 3.498)	Loss 1.4681e-01 (1.2449e-01) 
2023-05-27 15:13:48.544152: val Epoch: [36][11/72]	Time  0.108 ( 3.321)	Data  0.001 ( 3.207)	Loss 9.4007e-02 (1.2195e-01) 
2023-05-27 15:13:54.288180: val Epoch: [36][12/72]	Time  5.744 ( 3.508)	Data  5.629 ( 3.393)	Loss 1.1152e-01 (1.2115e-01) 
2023-05-27 15:13:54.403224: val Epoch: [36][13/72]	Time  0.115 ( 3.265)	Data  0.001 ( 3.151)	Loss 6.0743e-02 (1.1684e-01) 
2023-05-27 15:14:00.754841: val Epoch: [36][14/72]	Time  6.352 ( 3.471)	Data  6.238 ( 3.357)	Loss 2.7108e-01 (1.2712e-01) 
2023-05-27 15:14:00.869413: val Epoch: [36][15/72]	Time  0.115 ( 3.261)	Data  0.001 ( 3.147)	Loss 1.2483e-01 (1.2698e-01) 
2023-05-27 15:14:07.219423: val Epoch: [36][16/72]	Time  6.350 ( 3.443)	Data  6.240 ( 3.329)	Loss 4.3572e-01 (1.4514e-01) 
2023-05-27 15:14:07.329135: val Epoch: [36][17/72]	Time  0.110 ( 3.258)	Data  0.001 ( 3.144)	Loss 3.9636e-01 (1.5909e-01) 
2023-05-27 15:14:13.184484: val Epoch: [36][18/72]	Time  5.855 ( 3.394)	Data  5.748 ( 3.281)	Loss 6.3020e-02 (1.5404e-01) 
2023-05-27 15:14:13.293501: val Epoch: [36][19/72]	Time  0.109 ( 3.230)	Data  0.001 ( 3.117)	Loss 1.6075e-01 (1.5437e-01) 
2023-05-27 15:14:19.672303: val Epoch: [36][20/72]	Time  6.379 ( 3.380)	Data  6.267 ( 3.267)	Loss 5.9618e-02 (1.4986e-01) 
2023-05-27 15:14:19.788092: val Epoch: [36][21/72]	Time  0.116 ( 3.232)	Data  0.001 ( 3.119)	Loss 4.5431e-02 (1.4511e-01) 
2023-05-27 15:14:25.925929: val Epoch: [36][22/72]	Time  6.138 ( 3.358)	Data  6.023 ( 3.245)	Loss 8.4374e-02 (1.4247e-01) 
2023-05-27 15:14:26.038867: val Epoch: [36][23/72]	Time  0.113 ( 3.223)	Data  0.001 ( 3.110)	Loss 9.7832e-02 (1.4061e-01) 
2023-05-27 15:14:32.020855: val Epoch: [36][24/72]	Time  5.982 ( 3.333)	Data  5.871 ( 3.220)	Loss 2.2054e-01 (1.4381e-01) 
2023-05-27 15:14:32.146559: val Epoch: [36][25/72]	Time  0.126 ( 3.210)	Data  0.001 ( 3.096)	Loss 1.3391e-01 (1.4343e-01) 
2023-05-27 15:14:38.098541: val Epoch: [36][26/72]	Time  5.952 ( 3.311)	Data  5.846 ( 3.198)	Loss 5.2772e-02 (1.4007e-01) 
2023-05-27 15:14:38.207579: val Epoch: [36][27/72]	Time  0.109 ( 3.197)	Data  0.000 ( 3.084)	Loss 5.0060e-02 (1.3686e-01) 
2023-05-27 15:14:44.316210: val Epoch: [36][28/72]	Time  6.109 ( 3.297)	Data  5.996 ( 3.184)	Loss 3.9420e-01 (1.4573e-01) 
2023-05-27 15:14:44.427330: val Epoch: [36][29/72]	Time  0.111 ( 3.191)	Data  0.001 ( 3.078)	Loss 1.9193e-01 (1.4727e-01) 
2023-05-27 15:14:50.258606: val Epoch: [36][30/72]	Time  5.831 ( 3.276)	Data  5.723 ( 3.164)	Loss 7.6235e-02 (1.4498e-01) 
2023-05-27 15:14:51.003078: val Epoch: [36][31/72]	Time  0.744 ( 3.197)	Data  0.637 ( 3.085)	Loss 7.1353e-02 (1.4268e-01) 
2023-05-27 15:14:56.373734: val Epoch: [36][32/72]	Time  5.371 ( 3.263)	Data  5.264 ( 3.151)	Loss 4.3132e-02 (1.3966e-01) 
2023-05-27 15:14:57.225413: val Epoch: [36][33/72]	Time  0.852 ( 3.192)	Data  0.722 ( 3.079)	Loss 1.0282e-01 (1.3858e-01) 
2023-05-27 15:15:02.522743: val Epoch: [36][34/72]	Time  5.297 ( 3.252)	Data  5.190 ( 3.140)	Loss 9.2203e-02 (1.3725e-01) 
2023-05-27 15:15:03.360977: val Epoch: [36][35/72]	Time  0.838 ( 3.185)	Data  0.723 ( 3.073)	Loss 1.0303e-01 (1.3630e-01) 
2023-05-27 15:15:08.685559: val Epoch: [36][36/72]	Time  5.325 ( 3.243)	Data  5.219 ( 3.131)	Loss 6.6053e-02 (1.3440e-01) 
2023-05-27 15:15:09.361597: val Epoch: [36][37/72]	Time  0.676 ( 3.176)	Data  0.558 ( 3.063)	Loss 4.8940e-02 (1.3216e-01) 
2023-05-27 15:15:14.865314: val Epoch: [36][38/72]	Time  5.504 ( 3.235)	Data  5.394 ( 3.123)	Loss 7.2935e-02 (1.3064e-01) 
2023-05-27 15:15:15.505155: val Epoch: [36][39/72]	Time  0.640 ( 3.170)	Data  0.533 ( 3.058)	Loss 2.1950e-01 (1.3286e-01) 
2023-05-27 15:15:21.386244: val Epoch: [36][40/72]	Time  5.881 ( 3.237)	Data  5.761 ( 3.124)	Loss 6.4848e-02 (1.3120e-01) 
2023-05-27 15:15:21.904344: val Epoch: [36][41/72]	Time  0.518 ( 3.172)	Data  0.393 ( 3.059)	Loss 2.8464e-01 (1.3485e-01) 
2023-05-27 15:15:27.800698: val Epoch: [36][42/72]	Time  5.896 ( 3.235)	Data  5.783 ( 3.122)	Loss 7.5598e-02 (1.3348e-01) 
2023-05-27 15:15:28.304959: val Epoch: [36][43/72]	Time  0.504 ( 3.173)	Data  0.387 ( 3.060)	Loss 1.1516e-01 (1.3306e-01) 
2023-05-27 15:15:33.428789: val Epoch: [36][44/72]	Time  5.124 ( 3.216)	Data  5.011 ( 3.103)	Loss 8.7714e-02 (1.3205e-01) 
2023-05-27 15:15:34.360127: val Epoch: [36][45/72]	Time  0.931 ( 3.167)	Data  0.818 ( 3.054)	Loss 4.0030e-01 (1.3788e-01) 
2023-05-27 15:15:39.266893: val Epoch: [36][46/72]	Time  4.907 ( 3.204)	Data  4.798 ( 3.091)	Loss 1.7311e-01 (1.3863e-01) 
2023-05-27 15:15:40.558989: val Epoch: [36][47/72]	Time  1.292 ( 3.164)	Data  1.184 ( 3.051)	Loss 4.9031e-02 (1.3677e-01) 
2023-05-27 15:15:45.330679: val Epoch: [36][48/72]	Time  4.772 ( 3.197)	Data  4.664 ( 3.084)	Loss 4.0340e-02 (1.3480e-01) 
2023-05-27 15:15:46.864162: val Epoch: [36][49/72]	Time  1.533 ( 3.163)	Data  1.424 ( 3.051)	Loss 6.2459e-01 (1.4459e-01) 
2023-05-27 15:15:51.280236: val Epoch: [36][50/72]	Time  4.416 ( 3.188)	Data  4.308 ( 3.075)	Loss 5.1375e-02 (1.4277e-01) 
2023-05-27 15:15:53.158676: val Epoch: [36][51/72]	Time  1.878 ( 3.163)	Data  1.770 ( 3.050)	Loss 6.6450e-02 (1.4130e-01) 
2023-05-27 15:15:57.394076: val Epoch: [36][52/72]	Time  4.235 ( 3.183)	Data  4.120 ( 3.070)	Loss 1.2710e-01 (1.4103e-01) 
2023-05-27 15:15:59.231510: val Epoch: [36][53/72]	Time  1.837 ( 3.158)	Data  1.728 ( 3.046)	Loss 5.0493e-02 (1.3935e-01) 
2023-05-27 15:16:03.593058: val Epoch: [36][54/72]	Time  4.362 ( 3.180)	Data  4.253 ( 3.068)	Loss 8.6736e-02 (1.3840e-01) 
2023-05-27 15:16:05.482456: val Epoch: [36][55/72]	Time  1.889 ( 3.157)	Data  1.774 ( 3.044)	Loss 8.8051e-02 (1.3750e-01) 
2023-05-27 15:16:10.084885: val Epoch: [36][56/72]	Time  4.602 ( 3.182)	Data  4.494 ( 3.070)	Loss 2.1674e-01 (1.3889e-01) 
2023-05-27 15:16:12.100683: val Epoch: [36][57/72]	Time  2.016 ( 3.162)	Data  1.896 ( 3.050)	Loss 3.5507e-01 (1.4262e-01) 
2023-05-27 15:16:16.175838: val Epoch: [36][58/72]	Time  4.075 ( 3.178)	Data  3.967 ( 3.065)	Loss 3.8571e-02 (1.4085e-01) 
2023-05-27 15:16:18.465128: val Epoch: [36][59/72]	Time  2.289 ( 3.163)	Data  2.164 ( 3.050)	Loss 5.1320e-02 (1.3936e-01) 
2023-05-27 15:16:22.532681: val Epoch: [36][60/72]	Time  4.068 ( 3.178)	Data  3.957 ( 3.065)	Loss 3.3256e-01 (1.4253e-01) 
2023-05-27 15:16:25.185967: val Epoch: [36][61/72]	Time  2.653 ( 3.169)	Data  2.536 ( 3.057)	Loss 5.4536e-02 (1.4111e-01) 
2023-05-27 15:16:29.075433: val Epoch: [36][62/72]	Time  3.889 ( 3.181)	Data  3.781 ( 3.068)	Loss 5.9823e-02 (1.3982e-01) 
2023-05-27 15:16:31.388448: val Epoch: [36][63/72]	Time  2.313 ( 3.167)	Data  2.192 ( 3.054)	Loss 4.9911e-02 (1.3841e-01) 
2023-05-27 15:16:35.340419: val Epoch: [36][64/72]	Time  3.952 ( 3.179)	Data  3.843 ( 3.066)	Loss 6.6356e-02 (1.3730e-01) 
2023-05-27 15:16:37.964913: val Epoch: [36][65/72]	Time  2.624 ( 3.171)	Data  2.464 ( 3.057)	Loss 1.6704e-01 (1.3775e-01) 
2023-05-27 15:16:41.520229: val Epoch: [36][66/72]	Time  3.555 ( 3.177)	Data  3.446 ( 3.063)	Loss 7.6211e-02 (1.3684e-01) 
2023-05-27 15:16:44.093396: val Epoch: [36][67/72]	Time  2.573 ( 3.168)	Data  2.451 ( 3.054)	Loss 1.4181e-01 (1.3691e-01) 
2023-05-27 15:16:47.770765: val Epoch: [36][68/72]	Time  3.677 ( 3.175)	Data  3.569 ( 3.062)	Loss 3.4268e-01 (1.3989e-01) 
2023-05-27 15:16:50.379479: val Epoch: [36][69/72]	Time  2.609 ( 3.167)	Data  2.468 ( 3.053)	Loss 9.9623e-02 (1.3932e-01) 
2023-05-27 15:16:54.133155: val Epoch: [36][70/72]	Time  3.754 ( 3.175)	Data  3.643 ( 3.061)	Loss 1.0568e-01 (1.3884e-01) 
2023-05-27 15:16:56.252125: val Epoch: [36][71/72]	Time  2.119 ( 3.161)	Data  2.007 ( 3.047)	Loss 4.6639e-02 (1.3756e-01) 
2023-05-27 15:16:56.688721: Epoch 36 :Val : ['ET : 0.7218891978263855', 'TC : 0.7734882831573486', 'WT : 0.8522262573242188'] 
2023-05-27 15:16:56.694584: Epoch 36 :Val : ['ET : 0.7218891978263855', 'TC : 0.7734882831573486', 'WT : 0.8522262573242188'] 
2023-05-27 15:16:56.698350: Val epoch done in 228.73028807897936 s 
2023-05-27 15:16:56.713009: Batches per epoch:  193 
2023-05-27 15:17:11.266916: train Epoch: [37][  0/193]	Time 14.554 (14.554)	Data 13.957 (13.957)	Loss 7.7591e-02 (7.7591e-02) 
2023-05-27 15:17:11.830054: train Epoch: [37][  1/193]	Time  0.563 ( 7.558)	Data  0.001 ( 6.979)	Loss 1.7353e-01 (1.2556e-01) 
2023-05-27 15:17:23.593853: train Epoch: [37][  2/193]	Time 11.764 ( 8.960)	Data 11.198 ( 8.385)	Loss 5.0216e-02 (1.0044e-01) 
2023-05-27 15:17:24.160476: train Epoch: [37][  3/193]	Time  0.567 ( 6.862)	Data  0.001 ( 6.289)	Loss 1.6274e-01 (1.1602e-01) 
2023-05-27 15:17:36.251434: train Epoch: [37][  4/193]	Time 12.091 ( 7.908)	Data 11.526 ( 7.337)	Loss 1.2382e-01 (1.1758e-01) 
2023-05-27 15:17:36.813945: train Epoch: [37][  5/193]	Time  0.563 ( 6.683)	Data  0.001 ( 6.114)	Loss 5.7425e-02 (1.0755e-01) 
2023-05-27 15:17:48.253897: train Epoch: [37][  6/193]	Time 11.440 ( 7.363)	Data 10.879 ( 6.795)	Loss 5.6644e-02 (1.0028e-01) 
2023-05-27 15:17:48.816516: train Epoch: [37][  7/193]	Time  0.563 ( 6.513)	Data  0.001 ( 5.945)	Loss 7.8938e-02 (9.7613e-02) 
2023-05-27 15:18:00.619194: train Epoch: [37][  8/193]	Time 11.803 ( 7.101)	Data 11.231 ( 6.533)	Loss 2.3537e-01 (1.1292e-01) 
2023-05-27 15:18:01.181065: train Epoch: [37][  9/193]	Time  0.562 ( 6.447)	Data  0.001 ( 5.880)	Loss 6.3995e-02 (1.0803e-01) 
2023-05-27 15:18:13.015271: train Epoch: [37][ 10/193]	Time 11.834 ( 6.937)	Data 11.273 ( 6.370)	Loss 5.0583e-02 (1.0280e-01) 
2023-05-27 15:18:13.578235: train Epoch: [37][ 11/193]	Time  0.563 ( 6.405)	Data  0.001 ( 5.839)	Loss 9.2814e-02 (1.0197e-01) 
2023-05-27 15:18:23.914757: train Epoch: [37][ 12/193]	Time 10.337 ( 6.708)	Data  9.768 ( 6.141)	Loss 1.1803e-01 (1.0321e-01) 
2023-05-27 15:18:24.476324: train Epoch: [37][ 13/193]	Time  0.562 ( 6.269)	Data  0.001 ( 5.703)	Loss 4.9655e-02 (9.9382e-02) 
2023-05-27 15:18:36.392130: train Epoch: [37][ 14/193]	Time 11.916 ( 6.645)	Data 11.356 ( 6.080)	Loss 7.6112e-02 (9.7831e-02) 
2023-05-27 15:18:36.953924: train Epoch: [37][ 15/193]	Time  0.562 ( 6.265)	Data  0.001 ( 5.700)	Loss 4.8812e-02 (9.4767e-02) 
2023-05-27 15:18:49.080991: train Epoch: [37][ 16/193]	Time 12.127 ( 6.610)	Data 11.557 ( 6.044)	Loss 7.3246e-02 (9.3501e-02) 
2023-05-27 15:18:49.642356: train Epoch: [37][ 17/193]	Time  0.561 ( 6.274)	Data  0.001 ( 5.708)	Loss 7.6064e-02 (9.2532e-02) 
2023-05-27 15:19:01.063038: train Epoch: [37][ 18/193]	Time 11.421 ( 6.545)	Data 10.854 ( 5.979)	Loss 1.0991e-01 (9.3447e-02) 
2023-05-27 15:19:01.631510: train Epoch: [37][ 19/193]	Time  0.568 ( 6.246)	Data  0.001 ( 5.680)	Loss 5.1965e-02 (9.1373e-02) 
2023-05-27 15:19:12.669333: train Epoch: [37][ 20/193]	Time 11.038 ( 6.474)	Data 10.476 ( 5.909)	Loss 1.0093e-01 (9.1828e-02) 
2023-05-27 15:19:13.231985: train Epoch: [37][ 21/193]	Time  0.563 ( 6.205)	Data  0.001 ( 5.640)	Loss 8.3211e-02 (9.1436e-02) 
2023-05-27 15:19:23.546542: train Epoch: [37][ 22/193]	Time 10.315 ( 6.384)	Data  9.740 ( 5.818)	Loss 1.2504e-01 (9.2897e-02) 
2023-05-27 15:19:24.141646: train Epoch: [37][ 23/193]	Time  0.595 ( 6.143)	Data  0.001 ( 5.576)	Loss 9.1972e-02 (9.2859e-02) 
2023-05-27 15:19:35.050893: train Epoch: [37][ 24/193]	Time 10.909 ( 6.334)	Data 10.338 ( 5.766)	Loss 7.9494e-02 (9.2324e-02) 
2023-05-27 15:19:35.619339: train Epoch: [37][ 25/193]	Time  0.568 ( 6.112)	Data  0.001 ( 5.545)	Loss 6.3750e-02 (9.1225e-02) 
2023-05-27 15:19:47.725442: train Epoch: [37][ 26/193]	Time 12.106 ( 6.334)	Data 11.533 ( 5.767)	Loss 6.9791e-02 (9.0431e-02) 
2023-05-27 15:19:48.295263: train Epoch: [37][ 27/193]	Time  0.570 ( 6.128)	Data  0.001 ( 5.561)	Loss 4.5418e-02 (8.8824e-02) 
2023-05-27 15:19:59.710055: train Epoch: [37][ 28/193]	Time 11.415 ( 6.310)	Data 10.850 ( 5.743)	Loss 9.1491e-02 (8.8916e-02) 
2023-05-27 15:20:00.300489: train Epoch: [37][ 29/193]	Time  0.590 ( 6.120)	Data  0.001 ( 5.552)	Loss 3.7281e-02 (8.7195e-02) 
2023-05-27 15:20:12.230622: train Epoch: [37][ 30/193]	Time 11.930 ( 6.307)	Data 11.366 ( 5.739)	Loss 9.2867e-02 (8.7377e-02) 
2023-05-27 15:20:12.806722: train Epoch: [37][ 31/193]	Time  0.576 ( 6.128)	Data  0.001 ( 5.560)	Loss 5.5969e-02 (8.6396e-02) 
2023-05-27 15:20:24.813049: train Epoch: [37][ 32/193]	Time 12.006 ( 6.306)	Data 11.434 ( 5.738)	Loss 1.2434e-01 (8.7546e-02) 
2023-05-27 15:20:25.382046: train Epoch: [37][ 33/193]	Time  0.569 ( 6.137)	Data  0.001 ( 5.569)	Loss 8.7909e-02 (8.7556e-02) 
2023-05-27 15:20:36.956924: train Epoch: [37][ 34/193]	Time 11.575 ( 6.293)	Data 11.003 ( 5.724)	Loss 7.9083e-02 (8.7314e-02) 
2023-05-27 15:20:37.524508: train Epoch: [37][ 35/193]	Time  0.568 ( 6.134)	Data  0.001 ( 5.565)	Loss 8.7928e-02 (8.7331e-02) 
2023-05-27 15:20:48.954885: train Epoch: [37][ 36/193]	Time 11.430 ( 6.277)	Data 10.866 ( 5.709)	Loss 5.8683e-02 (8.6557e-02) 
2023-05-27 15:20:49.522032: train Epoch: [37][ 37/193]	Time  0.567 ( 6.127)	Data  0.001 ( 5.558)	Loss 5.1193e-02 (8.5627e-02) 
2023-05-27 15:21:01.328584: train Epoch: [37][ 38/193]	Time 11.807 ( 6.272)	Data 11.245 ( 5.704)	Loss 9.4153e-02 (8.5845e-02) 
2023-05-27 15:21:01.894156: train Epoch: [37][ 39/193]	Time  0.566 ( 6.130)	Data  0.001 ( 5.562)	Loss 2.1281e-01 (8.9019e-02) 
2023-05-27 15:21:13.537644: train Epoch: [37][ 40/193]	Time 11.643 ( 6.264)	Data 11.071 ( 5.696)	Loss 8.1669e-02 (8.8840e-02) 
2023-05-27 15:21:14.101446: train Epoch: [37][ 41/193]	Time  0.564 ( 6.128)	Data  0.001 ( 5.560)	Loss 7.1817e-02 (8.8435e-02) 
2023-05-27 15:21:26.107551: train Epoch: [37][ 42/193]	Time 12.006 ( 6.265)	Data 11.444 ( 5.697)	Loss 7.9477e-02 (8.8226e-02) 
2023-05-27 15:21:26.675328: train Epoch: [37][ 43/193]	Time  0.568 ( 6.135)	Data  0.001 ( 5.568)	Loss 9.3792e-02 (8.8353e-02) 
2023-05-27 15:21:38.320438: train Epoch: [37][ 44/193]	Time 11.645 ( 6.258)	Data 11.083 ( 5.690)	Loss 6.1389e-02 (8.7754e-02) 
2023-05-27 15:21:38.885387: train Epoch: [37][ 45/193]	Time  0.565 ( 6.134)	Data  0.001 ( 5.567)	Loss 7.5260e-02 (8.7482e-02) 
2023-05-27 15:21:50.718049: train Epoch: [37][ 46/193]	Time 11.833 ( 6.255)	Data 11.265 ( 5.688)	Loss 8.5715e-02 (8.7444e-02) 
2023-05-27 15:21:51.288204: train Epoch: [37][ 47/193]	Time  0.570 ( 6.137)	Data  0.001 ( 5.569)	Loss 9.5259e-02 (8.7607e-02) 
2023-05-27 15:22:03.113780: train Epoch: [37][ 48/193]	Time 11.826 ( 6.253)	Data 11.246 ( 5.685)	Loss 6.7619e-02 (8.7199e-02) 
2023-05-27 15:22:03.675774: train Epoch: [37][ 49/193]	Time  0.562 ( 6.139)	Data  0.001 ( 5.572)	Loss 4.5111e-02 (8.6358e-02) 
2023-05-27 15:22:15.573434: train Epoch: [37][ 50/193]	Time 11.898 ( 6.252)	Data 11.293 ( 5.684)	Loss 1.7151e-01 (8.8027e-02) 
2023-05-27 15:22:16.161527: train Epoch: [37][ 51/193]	Time  0.588 ( 6.143)	Data  0.001 ( 5.574)	Loss 1.1826e-01 (8.8609e-02) 
2023-05-27 15:22:27.874051: train Epoch: [37][ 52/193]	Time 11.713 ( 6.248)	Data 11.142 ( 5.680)	Loss 5.5688e-02 (8.7987e-02) 
2023-05-27 15:22:28.470997: train Epoch: [37][ 53/193]	Time  0.597 ( 6.144)	Data  0.001 ( 5.574)	Loss 5.1130e-02 (8.7305e-02) 
2023-05-27 15:22:40.503624: train Epoch: [37][ 54/193]	Time 12.033 ( 6.251)	Data 11.459 ( 5.681)	Loss 5.8794e-02 (8.6786e-02) 
2023-05-27 15:22:41.077209: train Epoch: [37][ 55/193]	Time  0.574 ( 6.149)	Data  0.001 ( 5.580)	Loss 6.9669e-02 (8.6481e-02) 
2023-05-27 15:22:52.941533: train Epoch: [37][ 56/193]	Time 11.864 ( 6.250)	Data 11.302 ( 5.680)	Loss 5.6574e-02 (8.5956e-02) 
2023-05-27 15:22:53.503839: train Epoch: [37][ 57/193]	Time  0.562 ( 6.152)	Data  0.001 ( 5.582)	Loss 7.3555e-02 (8.5742e-02) 
2023-05-27 15:23:05.473098: train Epoch: [37][ 58/193]	Time 11.969 ( 6.250)	Data 11.396 ( 5.681)	Loss 9.2409e-02 (8.5855e-02) 
2023-05-27 15:23:06.055934: train Epoch: [37][ 59/193]	Time  0.583 ( 6.156)	Data  0.001 ( 5.586)	Loss 1.9722e-01 (8.7711e-02) 
2023-05-27 15:23:17.458873: train Epoch: [37][ 60/193]	Time 11.403 ( 6.242)	Data 10.840 ( 5.672)	Loss 6.1684e-02 (8.7285e-02) 
2023-05-27 15:23:18.027920: train Epoch: [37][ 61/193]	Time  0.569 ( 6.150)	Data  0.001 ( 5.581)	Loss 5.4664e-02 (8.6759e-02) 
2023-05-27 15:23:29.310825: train Epoch: [37][ 62/193]	Time 11.283 ( 6.232)	Data 10.711 ( 5.662)	Loss 7.2336e-02 (8.6530e-02) 
2023-05-27 15:23:29.877861: train Epoch: [37][ 63/193]	Time  0.567 ( 6.143)	Data  0.001 ( 5.574)	Loss 1.3994e-01 (8.7364e-02) 
2023-05-27 15:23:41.603223: train Epoch: [37][ 64/193]	Time 11.725 ( 6.229)	Data 11.156 ( 5.660)	Loss 1.6768e-01 (8.8600e-02) 
2023-05-27 15:23:42.164685: train Epoch: [37][ 65/193]	Time  0.561 ( 6.143)	Data  0.001 ( 5.574)	Loss 1.9654e-01 (9.0235e-02) 
2023-05-27 15:23:53.955493: train Epoch: [37][ 66/193]	Time 11.791 ( 6.227)	Data 11.224 ( 5.658)	Loss 4.9836e-02 (8.9632e-02) 
2023-05-27 15:23:54.522969: train Epoch: [37][ 67/193]	Time  0.567 ( 6.144)	Data  0.001 ( 5.575)	Loss 7.7169e-02 (8.9449e-02) 
2023-05-27 15:24:06.716088: train Epoch: [37][ 68/193]	Time 12.193 ( 6.232)	Data 11.630 ( 5.663)	Loss 1.4746e-01 (9.0290e-02) 
2023-05-27 15:24:07.279945: train Epoch: [37][ 69/193]	Time  0.564 ( 6.151)	Data  0.001 ( 5.582)	Loss 7.1719e-02 (9.0024e-02) 
2023-05-27 15:24:19.981981: train Epoch: [37][ 70/193]	Time 12.702 ( 6.243)	Data 12.127 ( 5.674)	Loss 1.2828e-01 (9.0563e-02) 
2023-05-27 15:24:20.556663: train Epoch: [37][ 71/193]	Time  0.575 ( 6.164)	Data  0.001 ( 5.595)	Loss 1.2617e-01 (9.1058e-02) 
2023-05-27 15:24:32.544571: train Epoch: [37][ 72/193]	Time 11.988 ( 6.244)	Data 11.426 ( 5.675)	Loss 9.4574e-02 (9.1106e-02) 
2023-05-27 15:24:33.107990: train Epoch: [37][ 73/193]	Time  0.563 ( 6.167)	Data  0.001 ( 5.599)	Loss 1.0638e-01 (9.1312e-02) 
2023-05-27 15:24:45.084529: train Epoch: [37][ 74/193]	Time 11.977 ( 6.245)	Data 11.414 ( 5.676)	Loss 1.1499e-01 (9.1628e-02) 
2023-05-27 15:24:45.647984: train Epoch: [37][ 75/193]	Time  0.563 ( 6.170)	Data  0.001 ( 5.601)	Loss 1.0599e-01 (9.1817e-02) 
2023-05-27 15:24:57.339999: train Epoch: [37][ 76/193]	Time 11.692 ( 6.242)	Data 11.126 ( 5.673)	Loss 1.4226e-01 (9.2472e-02) 
2023-05-27 15:24:57.918399: train Epoch: [37][ 77/193]	Time  0.578 ( 6.169)	Data  0.001 ( 5.600)	Loss 1.0487e-01 (9.2631e-02) 
2023-05-27 15:25:10.096853: train Epoch: [37][ 78/193]	Time 12.178 ( 6.245)	Data 11.599 ( 5.676)	Loss 1.2794e-01 (9.3078e-02) 
2023-05-27 15:25:10.659627: train Epoch: [37][ 79/193]	Time  0.563 ( 6.174)	Data  0.001 ( 5.605)	Loss 7.2963e-02 (9.2827e-02) 
2023-05-27 15:25:22.405880: train Epoch: [37][ 80/193]	Time 11.746 ( 6.243)	Data 11.184 ( 5.674)	Loss 1.0003e-01 (9.2916e-02) 
2023-05-27 15:25:22.969626: train Epoch: [37][ 81/193]	Time  0.564 ( 6.174)	Data  0.001 ( 5.605)	Loss 9.6390e-02 (9.2958e-02) 
2023-05-27 15:25:34.995845: train Epoch: [37][ 82/193]	Time 12.026 ( 6.244)	Data 11.464 ( 5.676)	Loss 1.0733e-01 (9.3131e-02) 
2023-05-27 15:25:35.562173: train Epoch: [37][ 83/193]	Time  0.566 ( 6.177)	Data  0.001 ( 5.608)	Loss 4.7027e-02 (9.2582e-02) 
2023-05-27 15:25:47.431884: train Epoch: [37][ 84/193]	Time 11.870 ( 6.244)	Data 11.298 ( 5.675)	Loss 9.3466e-02 (9.2593e-02) 
2023-05-27 15:25:47.995813: train Epoch: [37][ 85/193]	Time  0.564 ( 6.178)	Data  0.001 ( 5.609)	Loss 9.5742e-02 (9.2629e-02) 
2023-05-27 15:25:59.114723: train Epoch: [37][ 86/193]	Time 11.119 ( 6.234)	Data 10.557 ( 5.666)	Loss 6.4098e-02 (9.2301e-02) 
2023-05-27 15:25:59.677383: train Epoch: [37][ 87/193]	Time  0.563 ( 6.170)	Data  0.001 ( 5.602)	Loss 6.3427e-02 (9.1973e-02) 
2023-05-27 15:26:10.346020: train Epoch: [37][ 88/193]	Time 10.669 ( 6.221)	Data 10.106 ( 5.652)	Loss 1.3395e-01 (9.2445e-02) 
2023-05-27 15:26:10.910573: train Epoch: [37][ 89/193]	Time  0.565 ( 6.158)	Data  0.001 ( 5.589)	Loss 1.1831e-01 (9.2732e-02) 
2023-05-27 15:26:22.605393: train Epoch: [37][ 90/193]	Time 11.695 ( 6.219)	Data 11.133 ( 5.650)	Loss 8.9779e-02 (9.2700e-02) 
2023-05-27 15:26:23.169001: train Epoch: [37][ 91/193]	Time  0.564 ( 6.157)	Data  0.001 ( 5.589)	Loss 1.7802e-01 (9.3627e-02) 
2023-05-27 15:26:35.209363: train Epoch: [37][ 92/193]	Time 12.040 ( 6.220)	Data 11.468 ( 5.652)	Loss 6.5591e-02 (9.3326e-02) 
2023-05-27 15:26:35.772316: train Epoch: [37][ 93/193]	Time  0.563 ( 6.160)	Data  0.001 ( 5.592)	Loss 1.4925e-01 (9.3921e-02) 
2023-05-27 15:26:47.992624: train Epoch: [37][ 94/193]	Time 12.220 ( 6.224)	Data 11.656 ( 5.656)	Loss 1.1103e-01 (9.4101e-02) 
2023-05-27 15:26:48.555444: train Epoch: [37][ 95/193]	Time  0.563 ( 6.165)	Data  0.001 ( 5.597)	Loss 1.0200e-01 (9.4183e-02) 
2023-05-27 15:27:00.692378: train Epoch: [37][ 96/193]	Time 12.137 ( 6.227)	Data 11.572 ( 5.659)	Loss 1.2540e-01 (9.4505e-02) 
2023-05-27 15:27:01.270427: train Epoch: [37][ 97/193]	Time  0.578 ( 6.169)	Data  0.002 ( 5.601)	Loss 1.9484e-01 (9.5529e-02) 
2023-05-27 15:27:13.341192: train Epoch: [37][ 98/193]	Time 12.071 ( 6.229)	Data 11.501 ( 5.660)	Loss 6.6488e-02 (9.5235e-02) 
2023-05-27 15:27:13.905104: train Epoch: [37][ 99/193]	Time  0.564 ( 6.172)	Data  0.001 ( 5.604)	Loss 5.3764e-02 (9.4821e-02) 
2023-05-27 15:27:25.555219: train Epoch: [37][100/193]	Time 11.650 ( 6.226)	Data 11.076 ( 5.658)	Loss 8.9369e-02 (9.4767e-02) 
2023-05-27 15:27:26.118514: train Epoch: [37][101/193]	Time  0.563 ( 6.171)	Data  0.001 ( 5.603)	Loss 9.6731e-02 (9.4786e-02) 
2023-05-27 15:27:38.179863: train Epoch: [37][102/193]	Time 12.061 ( 6.228)	Data 11.491 ( 5.660)	Loss 8.6481e-02 (9.4705e-02) 
2023-05-27 15:27:38.753298: train Epoch: [37][103/193]	Time  0.573 ( 6.173)	Data  0.001 ( 5.605)	Loss 6.6685e-02 (9.4436e-02) 
2023-05-27 15:27:51.180758: train Epoch: [37][104/193]	Time 12.427 ( 6.233)	Data 11.865 ( 5.665)	Loss 1.3089e-01 (9.4783e-02) 
2023-05-27 15:27:51.742625: train Epoch: [37][105/193]	Time  0.562 ( 6.180)	Data  0.001 ( 5.611)	Loss 1.2167e-01 (9.5037e-02) 
2023-05-27 15:28:03.495846: train Epoch: [37][106/193]	Time 11.753 ( 6.232)	Data 11.179 ( 5.664)	Loss 8.6364e-02 (9.4956e-02) 
2023-05-27 15:28:04.063179: train Epoch: [37][107/193]	Time  0.567 ( 6.179)	Data  0.001 ( 5.611)	Loss 6.2652e-02 (9.4656e-02) 
2023-05-27 15:28:15.299451: train Epoch: [37][108/193]	Time 11.236 ( 6.226)	Data 10.661 ( 5.657)	Loss 1.0583e-01 (9.4759e-02) 
2023-05-27 15:28:15.897512: train Epoch: [37][109/193]	Time  0.598 ( 6.174)	Data  0.001 ( 5.606)	Loss 6.3333e-02 (9.4473e-02) 
2023-05-27 15:28:27.845360: train Epoch: [37][110/193]	Time 11.948 ( 6.226)	Data 11.377 ( 5.658)	Loss 1.6597e-01 (9.5117e-02) 
2023-05-27 15:28:28.448108: train Epoch: [37][111/193]	Time  0.603 ( 6.176)	Data  0.001 ( 5.607)	Loss 9.5161e-02 (9.5118e-02) 
2023-05-27 15:28:40.098257: train Epoch: [37][112/193]	Time 11.650 ( 6.225)	Data 11.077 ( 5.656)	Loss 4.9420e-02 (9.4713e-02) 
2023-05-27 15:28:40.745919: train Epoch: [37][113/193]	Time  0.648 ( 6.176)	Data  0.002 ( 5.606)	Loss 1.0486e-01 (9.4802e-02) 
2023-05-27 15:28:52.953838: train Epoch: [37][114/193]	Time 12.208 ( 6.228)	Data 11.626 ( 5.659)	Loss 7.7472e-02 (9.4652e-02) 
2023-05-27 15:28:53.542568: train Epoch: [37][115/193]	Time  0.589 ( 6.180)	Data  0.001 ( 5.610)	Loss 1.3805e-01 (9.5026e-02) 
2023-05-27 15:29:06.221540: train Epoch: [37][116/193]	Time 12.679 ( 6.235)	Data 12.102 ( 5.665)	Loss 1.3544e-01 (9.5371e-02) 
2023-05-27 15:29:06.786205: train Epoch: [37][117/193]	Time  0.565 ( 6.187)	Data  0.001 ( 5.617)	Loss 4.6654e-02 (9.4958e-02) 
2023-05-27 15:29:18.843387: train Epoch: [37][118/193]	Time 12.057 ( 6.236)	Data 11.458 ( 5.666)	Loss 1.1763e-01 (9.5149e-02) 
2023-05-27 15:29:19.413455: train Epoch: [37][119/193]	Time  0.570 ( 6.189)	Data  0.001 ( 5.619)	Loss 6.5226e-02 (9.4900e-02) 
2023-05-27 15:29:31.495356: train Epoch: [37][120/193]	Time 12.082 ( 6.238)	Data 11.502 ( 5.668)	Loss 9.3894e-02 (9.4891e-02) 
2023-05-27 15:29:32.059814: train Epoch: [37][121/193]	Time  0.564 ( 6.191)	Data  0.001 ( 5.621)	Loss 7.7267e-02 (9.4747e-02) 
2023-05-27 15:29:43.988387: train Epoch: [37][122/193]	Time 11.929 ( 6.238)	Data 11.347 ( 5.668)	Loss 7.6613e-02 (9.4599e-02) 
2023-05-27 15:29:44.555888: train Epoch: [37][123/193]	Time  0.568 ( 6.192)	Data  0.001 ( 5.622)	Loss 1.1276e-01 (9.4746e-02) 
2023-05-27 15:29:55.603898: train Epoch: [37][124/193]	Time 11.048 ( 6.231)	Data 10.476 ( 5.661)	Loss 6.8734e-02 (9.4538e-02) 
2023-05-27 15:29:56.191265: train Epoch: [37][125/193]	Time  0.587 ( 6.186)	Data  0.001 ( 5.616)	Loss 1.0277e-01 (9.4603e-02) 
2023-05-27 15:30:07.883740: train Epoch: [37][126/193]	Time 11.692 ( 6.230)	Data 11.130 ( 5.660)	Loss 8.0587e-02 (9.4493e-02) 
2023-05-27 15:30:08.447199: train Epoch: [37][127/193]	Time  0.563 ( 6.185)	Data  0.001 ( 5.615)	Loss 1.2650e-01 (9.4743e-02) 
2023-05-27 15:30:20.133994: train Epoch: [37][128/193]	Time 11.687 ( 6.228)	Data 11.117 ( 5.658)	Loss 7.6200e-02 (9.4599e-02) 
2023-05-27 15:30:20.701644: train Epoch: [37][129/193]	Time  0.568 ( 6.185)	Data  0.001 ( 5.614)	Loss 9.0273e-02 (9.4566e-02) 
2023-05-27 15:30:32.636950: train Epoch: [37][130/193]	Time 11.935 ( 6.228)	Data 11.361 ( 5.658)	Loss 6.3653e-02 (9.4330e-02) 
2023-05-27 15:30:33.201269: train Epoch: [37][131/193]	Time  0.564 ( 6.186)	Data  0.001 ( 5.615)	Loss 5.9702e-02 (9.4067e-02) 
2023-05-27 15:30:45.023320: train Epoch: [37][132/193]	Time 11.822 ( 6.228)	Data 11.256 ( 5.658)	Loss 2.5077e-01 (9.5246e-02) 
2023-05-27 15:30:45.592574: train Epoch: [37][133/193]	Time  0.569 ( 6.186)	Data  0.001 ( 5.616)	Loss 6.3082e-02 (9.5006e-02) 
2023-05-27 15:30:57.386877: train Epoch: [37][134/193]	Time 11.794 ( 6.227)	Data 11.226 ( 5.657)	Loss 8.0108e-02 (9.4895e-02) 
2023-05-27 15:30:57.955116: train Epoch: [37][135/193]	Time  0.568 ( 6.186)	Data  0.001 ( 5.616)	Loss 6.1705e-02 (9.4651e-02) 
2023-05-27 15:31:09.449856: train Epoch: [37][136/193]	Time 11.495 ( 6.224)	Data 10.916 ( 5.654)	Loss 9.1081e-02 (9.4625e-02) 
2023-05-27 15:31:10.017970: train Epoch: [37][137/193]	Time  0.568 ( 6.183)	Data  0.001 ( 5.613)	Loss 5.6771e-02 (9.4351e-02) 
2023-05-27 15:31:21.874462: train Epoch: [37][138/193]	Time 11.856 ( 6.224)	Data 11.295 ( 5.654)	Loss 1.3122e-01 (9.4616e-02) 
2023-05-27 15:31:22.437557: train Epoch: [37][139/193]	Time  0.563 ( 6.184)	Data  0.001 ( 5.614)	Loss 7.9528e-02 (9.4508e-02) 
2023-05-27 15:31:33.749943: train Epoch: [37][140/193]	Time 11.312 ( 6.220)	Data 10.748 ( 5.650)	Loss 1.0917e-01 (9.4612e-02) 
2023-05-27 15:31:34.320417: train Epoch: [37][141/193]	Time  0.570 ( 6.180)	Data  0.001 ( 5.610)	Loss 1.1672e-01 (9.4768e-02) 
2023-05-27 15:31:46.147871: train Epoch: [37][142/193]	Time 11.827 ( 6.220)	Data 11.267 ( 5.650)	Loss 1.0142e-01 (9.4815e-02) 
2023-05-27 15:31:46.711156: train Epoch: [37][143/193]	Time  0.563 ( 6.181)	Data  0.001 ( 5.611)	Loss 7.2097e-02 (9.4657e-02) 
2023-05-27 15:31:58.399916: train Epoch: [37][144/193]	Time 11.689 ( 6.219)	Data 11.108 ( 5.649)	Loss 1.4367e-01 (9.4995e-02) 
2023-05-27 15:31:58.970335: train Epoch: [37][145/193]	Time  0.570 ( 6.180)	Data  0.001 ( 5.610)	Loss 7.7195e-02 (9.4873e-02) 
2023-05-27 15:32:10.519972: train Epoch: [37][146/193]	Time 11.550 ( 6.216)	Data 10.949 ( 5.646)	Loss 9.5090e-02 (9.4874e-02) 
2023-05-27 15:32:11.110256: train Epoch: [37][147/193]	Time  0.590 ( 6.178)	Data  0.001 ( 5.608)	Loss 1.0071e-01 (9.4914e-02) 
2023-05-27 15:32:22.644368: train Epoch: [37][148/193]	Time 11.534 ( 6.214)	Data 10.957 ( 5.644)	Loss 3.3326e-01 (9.6514e-02) 
2023-05-27 15:32:23.236130: train Epoch: [37][149/193]	Time  0.592 ( 6.177)	Data  0.001 ( 5.606)	Loss 1.2097e-01 (9.6677e-02) 
2023-05-27 15:32:35.280922: train Epoch: [37][150/193]	Time 12.045 ( 6.216)	Data 11.481 ( 5.645)	Loss 6.7282e-02 (9.6482e-02) 
2023-05-27 15:32:35.854981: train Epoch: [37][151/193]	Time  0.574 ( 6.179)	Data  0.001 ( 5.608)	Loss 9.1649e-02 (9.6450e-02) 
2023-05-27 15:32:47.605124: train Epoch: [37][152/193]	Time 11.750 ( 6.215)	Data 11.177 ( 5.645)	Loss 5.5846e-02 (9.6185e-02) 
2023-05-27 15:32:48.185764: train Epoch: [37][153/193]	Time  0.581 ( 6.178)	Data  0.001 ( 5.608)	Loss 6.5765e-02 (9.5987e-02) 
2023-05-27 15:32:59.991280: train Epoch: [37][154/193]	Time 11.806 ( 6.215)	Data 11.229 ( 5.644)	Loss 1.1830e-01 (9.6131e-02) 
2023-05-27 15:33:00.582554: train Epoch: [37][155/193]	Time  0.591 ( 6.179)	Data  0.001 ( 5.608)	Loss 1.1828e-01 (9.6273e-02) 
2023-05-27 15:33:12.278436: train Epoch: [37][156/193]	Time 11.696 ( 6.214)	Data 11.094 ( 5.643)	Loss 1.5911e-01 (9.6673e-02) 
2023-05-27 15:33:12.853304: train Epoch: [37][157/193]	Time  0.575 ( 6.178)	Data  0.001 ( 5.607)	Loss 7.6716e-02 (9.6547e-02) 
2023-05-27 15:33:24.814760: train Epoch: [37][158/193]	Time 11.961 ( 6.214)	Data 11.329 ( 5.643)	Loss 8.2104e-02 (9.6456e-02) 
2023-05-27 15:33:25.404976: train Epoch: [37][159/193]	Time  0.590 ( 6.179)	Data  0.001 ( 5.608)	Loss 8.2354e-02 (9.6368e-02) 
2023-05-27 15:33:37.275300: train Epoch: [37][160/193]	Time 11.870 ( 6.215)	Data 11.246 ( 5.643)	Loss 1.3832e-01 (9.6629e-02) 
2023-05-27 15:33:37.844348: train Epoch: [37][161/193]	Time  0.569 ( 6.180)	Data  0.001 ( 5.608)	Loss 8.2327e-02 (9.6540e-02) 
2023-05-27 15:33:49.676867: train Epoch: [37][162/193]	Time 11.833 ( 6.214)	Data 11.260 ( 5.643)	Loss 1.1601e-01 (9.6660e-02) 
2023-05-27 15:33:50.244919: train Epoch: [37][163/193]	Time  0.568 ( 6.180)	Data  0.001 ( 5.609)	Loss 9.0647e-02 (9.6623e-02) 
2023-05-27 15:34:02.419784: train Epoch: [37][164/193]	Time 12.175 ( 6.216)	Data 11.571 ( 5.645)	Loss 5.6901e-02 (9.6382e-02) 
2023-05-27 15:34:02.996656: train Epoch: [37][165/193]	Time  0.577 ( 6.182)	Data  0.001 ( 5.611)	Loss 1.8763e-01 (9.6932e-02) 
2023-05-27 15:34:15.257109: train Epoch: [37][166/193]	Time 12.260 ( 6.219)	Data 11.640 ( 5.647)	Loss 1.7772e-01 (9.7416e-02) 
2023-05-27 15:34:15.825796: train Epoch: [37][167/193]	Time  0.569 ( 6.185)	Data  0.001 ( 5.613)	Loss 6.2474e-02 (9.7208e-02) 
2023-05-27 15:34:26.861184: train Epoch: [37][168/193]	Time 11.035 ( 6.214)	Data 10.470 ( 5.642)	Loss 7.2501e-02 (9.7062e-02) 
2023-05-27 15:34:27.464519: train Epoch: [37][169/193]	Time  0.603 ( 6.181)	Data  0.001 ( 5.609)	Loss 6.6305e-02 (9.6881e-02) 
2023-05-27 15:34:39.008967: train Epoch: [37][170/193]	Time 11.544 ( 6.212)	Data 10.976 ( 5.640)	Loss 8.1785e-02 (9.6792e-02) 
2023-05-27 15:34:39.574190: train Epoch: [37][171/193]	Time  0.565 ( 6.179)	Data  0.001 ( 5.607)	Loss 8.5676e-02 (9.6728e-02) 
2023-05-27 15:34:50.922120: train Epoch: [37][172/193]	Time 11.348 ( 6.209)	Data 10.783 ( 5.637)	Loss 8.7087e-02 (9.6672e-02) 
2023-05-27 15:34:51.495037: train Epoch: [37][173/193]	Time  0.573 ( 6.177)	Data  0.001 ( 5.605)	Loss 1.6388e-01 (9.7058e-02) 
2023-05-27 15:35:03.395024: train Epoch: [37][174/193]	Time 11.900 ( 6.210)	Data 11.324 ( 5.638)	Loss 1.3670e-01 (9.7285e-02) 
2023-05-27 15:35:03.968314: train Epoch: [37][175/193]	Time  0.573 ( 6.178)	Data  0.001 ( 5.606)	Loss 8.4520e-02 (9.7212e-02) 
2023-05-27 15:35:15.429418: train Epoch: [37][176/193]	Time 11.461 ( 6.207)	Data 10.898 ( 5.635)	Loss 9.8648e-02 (9.7220e-02) 
2023-05-27 15:35:15.993357: train Epoch: [37][177/193]	Time  0.564 ( 6.176)	Data  0.001 ( 5.604)	Loss 3.3226e-02 (9.6861e-02) 
2023-05-27 15:35:27.870266: train Epoch: [37][178/193]	Time 11.877 ( 6.208)	Data 11.312 ( 5.636)	Loss 9.1595e-02 (9.6831e-02) 
2023-05-27 15:35:28.438667: train Epoch: [37][179/193]	Time  0.568 ( 6.176)	Data  0.001 ( 5.604)	Loss 6.3834e-02 (9.6648e-02) 
2023-05-27 15:35:39.101657: train Epoch: [37][180/193]	Time 10.663 ( 6.201)	Data 10.077 ( 5.629)	Loss 1.4869e-01 (9.6936e-02) 
2023-05-27 15:35:39.664299: train Epoch: [37][181/193]	Time  0.563 ( 6.170)	Data  0.001 ( 5.598)	Loss 5.4006e-02 (9.6700e-02) 
2023-05-27 15:35:51.163774: train Epoch: [37][182/193]	Time 11.499 ( 6.199)	Data 10.917 ( 5.627)	Loss 1.0845e-01 (9.6764e-02) 
2023-05-27 15:35:51.741001: train Epoch: [37][183/193]	Time  0.577 ( 6.169)	Data  0.001 ( 5.597)	Loss 8.9716e-02 (9.6726e-02) 
2023-05-27 15:36:04.049028: train Epoch: [37][184/193]	Time 12.308 ( 6.202)	Data 11.743 ( 5.630)	Loss 1.0608e-01 (9.6776e-02) 
2023-05-27 15:36:04.613891: train Epoch: [37][185/193]	Time  0.565 ( 6.172)	Data  0.001 ( 5.600)	Loss 4.3457e-02 (9.6490e-02) 
2023-05-27 15:36:16.623827: train Epoch: [37][186/193]	Time 12.010 ( 6.203)	Data 11.441 ( 5.631)	Loss 2.0262e-01 (9.7057e-02) 
2023-05-27 15:36:17.198034: train Epoch: [37][187/193]	Time  0.574 ( 6.173)	Data  0.001 ( 5.601)	Loss 1.0689e-01 (9.7109e-02) 
2023-05-27 15:36:29.142425: train Epoch: [37][188/193]	Time 11.944 ( 6.203)	Data 11.380 ( 5.631)	Loss 1.1083e-01 (9.7182e-02) 
2023-05-27 15:36:29.719718: train Epoch: [37][189/193]	Time  0.577 ( 6.174)	Data  0.001 ( 5.602)	Loss 6.7847e-02 (9.7028e-02) 
2023-05-27 15:36:41.167756: train Epoch: [37][190/193]	Time 11.448 ( 6.201)	Data 10.879 ( 5.629)	Loss 9.5494e-02 (9.7020e-02) 
2023-05-27 15:36:41.737382: train Epoch: [37][191/193]	Time  0.570 ( 6.172)	Data  0.001 ( 5.600)	Loss 7.9757e-02 (9.6930e-02) 
2023-05-27 15:36:52.554239: train Epoch: [37][192/193]	Time 10.817 ( 6.196)	Data 10.249 ( 5.624)	Loss 8.2664e-02 (9.6856e-02) 
2023-05-27 15:36:52.714450: Train Epoch done in 1196.0014907040168 s 
2023-05-27 15:37:01.046921: val Epoch: [37][ 0/72]	Time  7.446 ( 7.446)	Data  7.294 ( 7.294)	Loss 9.5506e-02 (9.5506e-02) 
2023-05-27 15:37:01.153038: val Epoch: [37][ 1/72]	Time  0.106 ( 3.776)	Data  0.001 ( 3.647)	Loss 4.4485e-02 (6.9996e-02) 
2023-05-27 15:37:07.290882: val Epoch: [37][ 2/72]	Time  6.138 ( 4.563)	Data  6.032 ( 4.442)	Loss 3.4733e-01 (1.6244e-01) 
2023-05-27 15:37:07.396217: val Epoch: [37][ 3/72]	Time  0.105 ( 3.449)	Data  0.001 ( 3.332)	Loss 2.7819e-01 (1.9138e-01) 
2023-05-27 15:37:13.488320: val Epoch: [37][ 4/72]	Time  6.092 ( 3.977)	Data  5.986 ( 3.863)	Loss 4.5190e-02 (1.6214e-01) 
2023-05-27 15:37:13.593442: val Epoch: [37][ 5/72]	Time  0.105 ( 3.332)	Data  0.000 ( 3.219)	Loss 4.1730e-02 (1.4207e-01) 
2023-05-27 15:37:19.492213: val Epoch: [37][ 6/72]	Time  5.899 ( 3.699)	Data  5.785 ( 3.586)	Loss 5.9385e-02 (1.3026e-01) 
2023-05-27 15:37:19.603194: val Epoch: [37][ 7/72]	Time  0.111 ( 3.250)	Data  0.001 ( 3.137)	Loss 9.6468e-02 (1.2604e-01) 
2023-05-27 15:37:25.603147: val Epoch: [37][ 8/72]	Time  6.000 ( 3.556)	Data  5.894 ( 3.444)	Loss 1.5264e-01 (1.2899e-01) 
2023-05-27 15:37:25.709300: val Epoch: [37][ 9/72]	Time  0.106 ( 3.211)	Data  0.001 ( 3.099)	Loss 4.1769e-01 (1.5786e-01) 
2023-05-27 15:37:31.885864: val Epoch: [37][10/72]	Time  6.177 ( 3.480)	Data  6.071 ( 3.370)	Loss 1.6168e-01 (1.5821e-01) 
2023-05-27 15:37:31.990757: val Epoch: [37][11/72]	Time  0.105 ( 3.199)	Data  0.001 ( 3.089)	Loss 3.4326e-01 (1.7363e-01) 
2023-05-27 15:37:38.106847: val Epoch: [37][12/72]	Time  6.116 ( 3.424)	Data  6.010 ( 3.314)	Loss 3.3626e-01 (1.8614e-01) 
2023-05-27 15:37:38.211928: val Epoch: [37][13/72]	Time  0.105 ( 3.186)	Data  0.000 ( 3.077)	Loss 1.1201e-01 (1.8084e-01) 
2023-05-27 15:37:44.306214: val Epoch: [37][14/72]	Time  6.094 ( 3.380)	Data  5.989 ( 3.271)	Loss 1.8498e-01 (1.8112e-01) 
2023-05-27 15:37:44.543066: val Epoch: [37][15/72]	Time  0.237 ( 3.184)	Data  0.131 ( 3.075)	Loss 7.1183e-02 (1.7425e-01) 
2023-05-27 15:37:50.780404: val Epoch: [37][16/72]	Time  6.237 ( 3.363)	Data  6.131 ( 3.255)	Loss 3.6821e-01 (1.8566e-01) 
2023-05-27 15:37:50.886142: val Epoch: [37][17/72]	Time  0.106 ( 3.183)	Data  0.000 ( 3.074)	Loss 5.1106e-02 (1.7818e-01) 
2023-05-27 15:37:56.770206: val Epoch: [37][18/72]	Time  5.884 ( 3.325)	Data  5.779 ( 3.216)	Loss 1.1238e-01 (1.7472e-01) 
2023-05-27 15:37:56.875898: val Epoch: [37][19/72]	Time  0.106 ( 3.164)	Data  0.000 ( 3.055)	Loss 6.2807e-02 (1.6912e-01) 
2023-05-27 15:38:03.570518: val Epoch: [37][20/72]	Time  6.695 ( 3.332)	Data  6.589 ( 3.224)	Loss 7.1772e-02 (1.6449e-01) 
2023-05-27 15:38:03.675280: val Epoch: [37][21/72]	Time  0.105 ( 3.185)	Data  0.000 ( 3.077)	Loss 3.8075e-02 (1.5874e-01) 
2023-05-27 15:38:09.819114: val Epoch: [37][22/72]	Time  6.144 ( 3.314)	Data  6.033 ( 3.206)	Loss 7.7082e-02 (1.5519e-01) 
2023-05-27 15:38:09.927393: val Epoch: [37][23/72]	Time  0.108 ( 3.180)	Data  0.001 ( 3.072)	Loss 7.6122e-02 (1.5190e-01) 
2023-05-27 15:38:15.700032: val Epoch: [37][24/72]	Time  5.773 ( 3.284)	Data  5.667 ( 3.176)	Loss 3.4246e-02 (1.4719e-01) 
2023-05-27 15:38:15.805730: val Epoch: [37][25/72]	Time  0.106 ( 3.162)	Data  0.000 ( 3.054)	Loss 5.6317e-02 (1.4370e-01) 
2023-05-27 15:38:21.642697: val Epoch: [37][26/72]	Time  5.837 ( 3.261)	Data  5.719 ( 3.152)	Loss 8.0509e-02 (1.4136e-01) 
2023-05-27 15:38:21.750238: val Epoch: [37][27/72]	Time  0.108 ( 3.148)	Data  0.001 ( 3.040)	Loss 1.5806e-01 (1.4195e-01) 
2023-05-27 15:38:27.958268: val Epoch: [37][28/72]	Time  6.208 ( 3.254)	Data  6.102 ( 3.146)	Loss 8.5668e-02 (1.4001e-01) 
2023-05-27 15:38:28.064131: val Epoch: [37][29/72]	Time  0.106 ( 3.149)	Data  0.000 ( 3.041)	Loss 1.0881e-01 (1.3897e-01) 
2023-05-27 15:38:34.344127: val Epoch: [37][30/72]	Time  6.280 ( 3.250)	Data  6.174 ( 3.142)	Loss 1.2604e-01 (1.3855e-01) 
2023-05-27 15:38:34.448907: val Epoch: [37][31/72]	Time  0.105 ( 3.151)	Data  0.001 ( 3.044)	Loss 6.1066e-02 (1.3613e-01) 
2023-05-27 15:38:40.462883: val Epoch: [37][32/72]	Time  6.014 ( 3.238)	Data  5.906 ( 3.130)	Loss 7.1074e-02 (1.3416e-01) 
2023-05-27 15:38:40.570396: val Epoch: [37][33/72]	Time  0.108 ( 3.146)	Data  0.001 ( 3.038)	Loss 3.1890e-01 (1.3959e-01) 
2023-05-27 15:38:46.959888: val Epoch: [37][34/72]	Time  6.389 ( 3.239)	Data  6.284 ( 3.131)	Loss 8.4755e-02 (1.3803e-01) 
2023-05-27 15:38:47.064724: val Epoch: [37][35/72]	Time  0.105 ( 3.152)	Data  0.000 ( 3.044)	Loss 9.4314e-02 (1.3681e-01) 
2023-05-27 15:38:53.567269: val Epoch: [37][36/72]	Time  6.503 ( 3.242)	Data  6.392 ( 3.135)	Loss 1.8793e-01 (1.3820e-01) 
2023-05-27 15:38:53.674968: val Epoch: [37][37/72]	Time  0.108 ( 3.160)	Data  0.000 ( 3.052)	Loss 3.9199e-02 (1.3559e-01) 
2023-05-27 15:38:59.769680: val Epoch: [37][38/72]	Time  6.095 ( 3.235)	Data  5.990 ( 3.127)	Loss 4.2180e-01 (1.4293e-01) 
2023-05-27 15:38:59.874787: val Epoch: [37][39/72]	Time  0.105 ( 3.157)	Data  0.000 ( 3.049)	Loss 9.9389e-02 (1.4184e-01) 
2023-05-27 15:39:05.484982: val Epoch: [37][40/72]	Time  5.610 ( 3.217)	Data  5.505 ( 3.109)	Loss 4.6353e-02 (1.3951e-01) 
2023-05-27 15:39:05.590026: val Epoch: [37][41/72]	Time  0.105 ( 3.143)	Data  0.000 ( 3.035)	Loss 5.2749e-02 (1.3745e-01) 
2023-05-27 15:39:11.674166: val Epoch: [37][42/72]	Time  6.084 ( 3.211)	Data  5.978 ( 3.104)	Loss 1.2238e-01 (1.3710e-01) 
2023-05-27 15:39:11.779396: val Epoch: [37][43/72]	Time  0.105 ( 3.140)	Data  0.001 ( 3.033)	Loss 8.9440e-02 (1.3601e-01) 
2023-05-27 15:39:17.917039: val Epoch: [37][44/72]	Time  6.138 ( 3.207)	Data  6.030 ( 3.100)	Loss 3.9227e-01 (1.4171e-01) 
2023-05-27 15:39:18.024984: val Epoch: [37][45/72]	Time  0.108 ( 3.140)	Data  0.001 ( 3.032)	Loss 1.0891e-01 (1.4099e-01) 
2023-05-27 15:39:24.185300: val Epoch: [37][46/72]	Time  6.160 ( 3.204)	Data  6.053 ( 3.096)	Loss 4.8120e-02 (1.3902e-01) 
2023-05-27 15:39:24.293040: val Epoch: [37][47/72]	Time  0.108 ( 3.139)	Data  0.001 ( 3.032)	Loss 7.2412e-02 (1.3763e-01) 
2023-05-27 15:39:30.294745: val Epoch: [37][48/72]	Time  6.002 ( 3.198)	Data  5.896 ( 3.090)	Loss 2.0899e-01 (1.3909e-01) 
2023-05-27 15:39:30.399765: val Epoch: [37][49/72]	Time  0.105 ( 3.136)	Data  0.000 ( 3.029)	Loss 5.0673e-02 (1.3732e-01) 
2023-05-27 15:39:36.491667: val Epoch: [37][50/72]	Time  6.092 ( 3.194)	Data  5.986 ( 3.087)	Loss 8.9053e-02 (1.3637e-01) 
2023-05-27 15:39:36.596288: val Epoch: [37][51/72]	Time  0.105 ( 3.135)	Data  0.000 ( 3.027)	Loss 1.4923e-01 (1.3662e-01) 
2023-05-27 15:39:42.796586: val Epoch: [37][52/72]	Time  6.200 ( 3.192)	Data  6.090 ( 3.085)	Loss 5.6240e-02 (1.3510e-01) 
2023-05-27 15:39:42.905093: val Epoch: [37][53/72]	Time  0.109 ( 3.135)	Data  0.001 ( 3.028)	Loss 2.1143e-01 (1.3652e-01) 
2023-05-27 15:39:49.199282: val Epoch: [37][54/72]	Time  6.294 ( 3.193)	Data  6.187 ( 3.085)	Loss 5.4940e-02 (1.3503e-01) 
2023-05-27 15:39:49.304374: val Epoch: [37][55/72]	Time  0.105 ( 3.138)	Data  0.000 ( 3.030)	Loss 9.5146e-02 (1.3432e-01) 
2023-05-27 15:39:55.187548: val Epoch: [37][56/72]	Time  5.883 ( 3.186)	Data  5.778 ( 3.078)	Loss 9.3487e-02 (1.3360e-01) 
2023-05-27 15:39:55.292709: val Epoch: [37][57/72]	Time  0.105 ( 3.133)	Data  0.000 ( 3.025)	Loss 2.9462e-01 (1.3638e-01) 
2023-05-27 15:40:01.549063: val Epoch: [37][58/72]	Time  6.256 ( 3.186)	Data  6.151 ( 3.078)	Loss 6.7837e-02 (1.3522e-01) 
2023-05-27 15:40:01.654052: val Epoch: [37][59/72]	Time  0.105 ( 3.134)	Data  0.001 ( 3.027)	Loss 6.2478e-02 (1.3401e-01) 
2023-05-27 15:40:07.581379: val Epoch: [37][60/72]	Time  5.927 ( 3.180)	Data  5.822 ( 3.073)	Loss 1.5670e-01 (1.3438e-01) 
2023-05-27 15:40:07.686419: val Epoch: [37][61/72]	Time  0.105 ( 3.130)	Data  0.001 ( 3.023)	Loss 4.4299e-02 (1.3293e-01) 
2023-05-27 15:40:13.687875: val Epoch: [37][62/72]	Time  6.001 ( 3.176)	Data  5.893 ( 3.069)	Loss 5.1255e-02 (1.3163e-01) 
2023-05-27 15:40:13.813267: val Epoch: [37][63/72]	Time  0.125 ( 3.128)	Data  0.014 ( 3.021)	Loss 8.2135e-02 (1.3086e-01) 
2023-05-27 15:40:20.030087: val Epoch: [37][64/72]	Time  6.217 ( 3.176)	Data  6.111 ( 3.069)	Loss 7.0758e-02 (1.2993e-01) 
2023-05-27 15:40:20.135255: val Epoch: [37][65/72]	Time  0.105 ( 3.129)	Data  0.000 ( 3.022)	Loss 5.3850e-02 (1.2878e-01) 
2023-05-27 15:40:26.089559: val Epoch: [37][66/72]	Time  5.954 ( 3.171)	Data  5.841 ( 3.064)	Loss 2.0955e-01 (1.2998e-01) 
2023-05-27 15:40:26.330851: val Epoch: [37][67/72]	Time  0.241 ( 3.128)	Data  0.134 ( 3.021)	Loss 3.9969e-01 (1.3395e-01) 
2023-05-27 15:40:32.333611: val Epoch: [37][68/72]	Time  6.003 ( 3.170)	Data  5.897 ( 3.063)	Loss 6.5217e-02 (1.3295e-01) 
2023-05-27 15:40:32.438126: val Epoch: [37][69/72]	Time  0.105 ( 3.126)	Data  0.000 ( 3.019)	Loss 1.0154e-01 (1.3251e-01) 
2023-05-27 15:40:38.399272: val Epoch: [37][70/72]	Time  5.961 ( 3.166)	Data  5.856 ( 3.059)	Loss 6.4825e-02 (1.3155e-01) 
2023-05-27 15:40:38.504122: val Epoch: [37][71/72]	Time  0.105 ( 3.124)	Data  0.000 ( 3.017)	Loss 6.2463e-02 (1.3059e-01) 
2023-05-27 15:40:38.905607: Epoch 37 :Val : ['ET : 0.7111678719520569', 'TC : 0.7800818085670471', 'WT : 0.8669384717941284'] 
2023-05-27 15:40:38.908526: Epoch 37 :Val : ['ET : 0.7111678719520569', 'TC : 0.7800818085670471', 'WT : 0.8669384717941284'] 
2023-05-27 15:40:38.910833: Val epoch done in 226.19638709898572 s 
2023-05-27 15:40:38.916880: Batches per epoch:  193 
2023-05-27 15:40:53.214156: train Epoch: [38][  0/193]	Time 14.297 (14.297)	Data 13.529 (13.529)	Loss 1.0591e-01 (1.0591e-01) 
2023-05-27 15:40:53.801785: train Epoch: [38][  1/193]	Time  0.588 ( 7.442)	Data  0.001 ( 6.765)	Loss 8.3765e-02 (9.4836e-02) 
2023-05-27 15:41:05.920599: train Epoch: [38][  2/193]	Time 12.119 ( 9.001)	Data 11.543 ( 8.358)	Loss 5.9152e-02 (8.2941e-02) 
2023-05-27 15:41:06.495275: train Epoch: [38][  3/193]	Time  0.575 ( 6.895)	Data  0.001 ( 6.269)	Loss 1.3129e-01 (9.5029e-02) 
2023-05-27 15:41:18.052398: train Epoch: [38][  4/193]	Time 11.557 ( 7.827)	Data 10.982 ( 7.211)	Loss 6.8721e-02 (8.9768e-02) 
2023-05-27 15:41:18.758371: train Epoch: [38][  5/193]	Time  0.706 ( 6.640)	Data  0.117 ( 6.029)	Loss 7.5216e-02 (8.7342e-02) 
2023-05-27 15:41:31.458105: train Epoch: [38][  6/193]	Time 12.700 ( 7.506)	Data 12.130 ( 6.901)	Loss 7.1672e-02 (8.5104e-02) 
2023-05-27 15:41:32.020368: train Epoch: [38][  7/193]	Time  0.562 ( 6.638)	Data  0.001 ( 6.038)	Loss 4.6598e-02 (8.0290e-02) 
2023-05-27 15:41:44.498601: train Epoch: [38][  8/193]	Time 12.478 ( 7.287)	Data 11.916 ( 6.691)	Loss 9.1174e-02 (8.1500e-02) 
2023-05-27 15:41:45.061078: train Epoch: [38][  9/193]	Time  0.562 ( 6.614)	Data  0.001 ( 6.022)	Loss 8.9235e-02 (8.2273e-02) 
2023-05-27 15:41:56.952527: train Epoch: [38][ 10/193]	Time 11.891 ( 7.094)	Data 11.302 ( 6.502)	Loss 7.2631e-02 (8.1397e-02) 
2023-05-27 15:41:57.514621: train Epoch: [38][ 11/193]	Time  0.562 ( 6.550)	Data  0.001 ( 5.960)	Loss 1.1699e-01 (8.4363e-02) 
2023-05-27 15:42:09.413214: train Epoch: [38][ 12/193]	Time 11.899 ( 6.961)	Data 11.302 ( 6.371)	Loss 1.9807e-01 (9.3109e-02) 
2023-05-27 15:42:09.982528: train Epoch: [38][ 13/193]	Time  0.569 ( 6.505)	Data  0.001 ( 5.916)	Loss 2.5547e-01 (1.0471e-01) 
2023-05-27 15:42:20.567809: train Epoch: [38][ 14/193]	Time 10.585 ( 6.777)	Data 10.021 ( 6.190)	Loss 8.7474e-02 (1.0356e-01) 
2023-05-27 15:42:21.145606: train Epoch: [38][ 15/193]	Time  0.578 ( 6.389)	Data  0.001 ( 5.803)	Loss 1.1865e-01 (1.0450e-01) 
2023-05-27 15:42:32.586556: train Epoch: [38][ 16/193]	Time 11.441 ( 6.686)	Data 10.879 ( 6.102)	Loss 5.4214e-02 (1.0154e-01) 
2023-05-27 15:42:33.149959: train Epoch: [38][ 17/193]	Time  0.563 ( 6.346)	Data  0.001 ( 5.763)	Loss 7.4772e-02 (1.0006e-01) 
2023-05-27 15:42:45.466808: train Epoch: [38][ 18/193]	Time 12.317 ( 6.661)	Data 11.750 ( 6.078)	Loss 4.5699e-02 (9.7195e-02) 
2023-05-27 15:42:46.033847: train Epoch: [38][ 19/193]	Time  0.567 ( 6.356)	Data  0.001 ( 5.774)	Loss 5.7775e-02 (9.5224e-02) 
2023-05-27 15:42:58.294695: train Epoch: [38][ 20/193]	Time 12.261 ( 6.637)	Data 11.681 ( 6.055)	Loss 7.9317e-02 (9.4466e-02) 
2023-05-27 15:42:58.862063: train Epoch: [38][ 21/193]	Time  0.567 ( 6.361)	Data  0.001 ( 5.780)	Loss 1.6445e-01 (9.7648e-02) 
2023-05-27 15:43:09.575232: train Epoch: [38][ 22/193]	Time 10.713 ( 6.550)	Data 10.146 ( 5.970)	Loss 6.1199e-02 (9.6063e-02) 
2023-05-27 15:43:10.143760: train Epoch: [38][ 23/193]	Time  0.569 ( 6.301)	Data  0.001 ( 5.721)	Loss 5.3420e-02 (9.4286e-02) 
2023-05-27 15:43:20.510120: train Epoch: [38][ 24/193]	Time 10.366 ( 6.464)	Data  9.799 ( 5.884)	Loss 1.7499e-01 (9.7514e-02) 
2023-05-27 15:43:21.077569: train Epoch: [38][ 25/193]	Time  0.567 ( 6.237)	Data  0.001 ( 5.658)	Loss 1.0085e-01 (9.7642e-02) 
2023-05-27 15:43:33.046808: train Epoch: [38][ 26/193]	Time 11.969 ( 6.449)	Data 11.401 ( 5.871)	Loss 7.4324e-02 (9.6779e-02) 
2023-05-27 15:43:33.615423: train Epoch: [38][ 27/193]	Time  0.569 ( 6.239)	Data  0.001 ( 5.661)	Loss 9.7391e-02 (9.6801e-02) 
2023-05-27 15:43:45.660717: train Epoch: [38][ 28/193]	Time 12.045 ( 6.439)	Data 11.471 ( 5.861)	Loss 9.0453e-02 (9.6582e-02) 
2023-05-27 15:43:46.224451: train Epoch: [38][ 29/193]	Time  0.564 ( 6.244)	Data  0.001 ( 5.666)	Loss 8.9264e-02 (9.6338e-02) 
2023-05-27 15:43:58.336359: train Epoch: [38][ 30/193]	Time 12.112 ( 6.433)	Data 11.543 ( 5.856)	Loss 5.4212e-02 (9.4979e-02) 
2023-05-27 15:43:58.901926: train Epoch: [38][ 31/193]	Time  0.566 ( 6.250)	Data  0.001 ( 5.673)	Loss 7.9970e-02 (9.4510e-02) 
2023-05-27 15:44:10.782141: train Epoch: [38][ 32/193]	Time 11.880 ( 6.420)	Data 11.317 ( 5.844)	Loss 2.8523e-01 (1.0029e-01) 
2023-05-27 15:44:11.348607: train Epoch: [38][ 33/193]	Time  0.566 ( 6.248)	Data  0.001 ( 5.672)	Loss 1.0871e-01 (1.0054e-01) 
2023-05-27 15:44:23.416471: train Epoch: [38][ 34/193]	Time 12.068 ( 6.414)	Data 11.495 ( 5.838)	Loss 1.4071e-01 (1.0168e-01) 
2023-05-27 15:44:23.980324: train Epoch: [38][ 35/193]	Time  0.564 ( 6.252)	Data  0.001 ( 5.676)	Loss 9.4945e-02 (1.0150e-01) 
2023-05-27 15:44:35.972464: train Epoch: [38][ 36/193]	Time 11.992 ( 6.407)	Data 11.422 ( 5.831)	Loss 1.3903e-01 (1.0251e-01) 
2023-05-27 15:44:36.541276: train Epoch: [38][ 37/193]	Time  0.569 ( 6.253)	Data  0.001 ( 5.678)	Loss 8.2318e-02 (1.0198e-01) 
2023-05-27 15:44:48.388774: train Epoch: [38][ 38/193]	Time 11.847 ( 6.397)	Data 11.285 ( 5.822)	Loss 1.1788e-01 (1.0239e-01) 
2023-05-27 15:44:48.951329: train Epoch: [38][ 39/193]	Time  0.563 ( 6.251)	Data  0.001 ( 5.676)	Loss 5.9901e-02 (1.0133e-01) 
2023-05-27 15:45:00.750191: train Epoch: [38][ 40/193]	Time 11.799 ( 6.386)	Data 11.236 ( 5.812)	Loss 4.8690e-02 (1.0004e-01) 
2023-05-27 15:45:01.316468: train Epoch: [38][ 41/193]	Time  0.566 ( 6.248)	Data  0.001 ( 5.673)	Loss 6.8312e-02 (9.9287e-02) 
2023-05-27 15:45:13.567308: train Epoch: [38][ 42/193]	Time 12.251 ( 6.387)	Data 11.677 ( 5.813)	Loss 8.2220e-02 (9.8890e-02) 
2023-05-27 15:45:14.129875: train Epoch: [38][ 43/193]	Time  0.563 ( 6.255)	Data  0.001 ( 5.681)	Loss 6.5148e-02 (9.8123e-02) 
2023-05-27 15:45:25.475635: train Epoch: [38][ 44/193]	Time 11.346 ( 6.368)	Data 10.774 ( 5.794)	Loss 9.5454e-02 (9.8064e-02) 
2023-05-27 15:45:26.038926: train Epoch: [38][ 45/193]	Time  0.563 ( 6.242)	Data  0.001 ( 5.668)	Loss 6.2578e-02 (9.7292e-02) 
2023-05-27 15:45:37.875299: train Epoch: [38][ 46/193]	Time 11.836 ( 6.361)	Data 11.274 ( 5.788)	Loss 8.0180e-02 (9.6928e-02) 
2023-05-27 15:45:38.438737: train Epoch: [38][ 47/193]	Time  0.563 ( 6.240)	Data  0.001 ( 5.667)	Loss 1.3271e-01 (9.7674e-02) 
2023-05-27 15:45:50.214035: train Epoch: [38][ 48/193]	Time 11.775 ( 6.353)	Data 11.213 ( 5.780)	Loss 6.1834e-02 (9.6942e-02) 
2023-05-27 15:45:50.776237: train Epoch: [38][ 49/193]	Time  0.562 ( 6.237)	Data  0.001 ( 5.665)	Loss 6.5012e-02 (9.6304e-02) 
2023-05-27 15:46:02.534105: train Epoch: [38][ 50/193]	Time 11.758 ( 6.345)	Data 11.187 ( 5.773)	Loss 5.7524e-02 (9.5543e-02) 
2023-05-27 15:46:03.096098: train Epoch: [38][ 51/193]	Time  0.562 ( 6.234)	Data  0.001 ( 5.662)	Loss 7.7297e-02 (9.5192e-02) 
2023-05-27 15:46:14.942376: train Epoch: [38][ 52/193]	Time 11.846 ( 6.340)	Data 11.238 ( 5.767)	Loss 9.3822e-02 (9.5167e-02) 
2023-05-27 15:46:15.509208: train Epoch: [38][ 53/193]	Time  0.567 ( 6.233)	Data  0.001 ( 5.660)	Loss 1.8681e-01 (9.6864e-02) 
2023-05-27 15:46:27.320997: train Epoch: [38][ 54/193]	Time 11.812 ( 6.335)	Data 11.245 ( 5.762)	Loss 6.5940e-02 (9.6301e-02) 
2023-05-27 15:46:27.887621: train Epoch: [38][ 55/193]	Time  0.567 ( 6.232)	Data  0.001 ( 5.659)	Loss 1.0975e-01 (9.6542e-02) 
2023-05-27 15:46:39.197351: train Epoch: [38][ 56/193]	Time 11.310 ( 6.321)	Data 10.730 ( 5.748)	Loss 5.1255e-02 (9.5747e-02) 
2023-05-27 15:46:39.760409: train Epoch: [38][ 57/193]	Time  0.563 ( 6.221)	Data  0.001 ( 5.649)	Loss 4.7548e-02 (9.4916e-02) 
2023-05-27 15:46:51.590984: train Epoch: [38][ 58/193]	Time 11.831 ( 6.317)	Data 11.247 ( 5.744)	Loss 7.9244e-02 (9.4650e-02) 
2023-05-27 15:46:52.165951: train Epoch: [38][ 59/193]	Time  0.575 ( 6.221)	Data  0.001 ( 5.648)	Loss 1.0974e-01 (9.4902e-02) 
2023-05-27 15:47:03.697500: train Epoch: [38][ 60/193]	Time 11.532 ( 6.308)	Data 10.929 ( 5.735)	Loss 6.8722e-02 (9.4473e-02) 
2023-05-27 15:47:04.265105: train Epoch: [38][ 61/193]	Time  0.568 ( 6.215)	Data  0.001 ( 5.642)	Loss 5.9914e-02 (9.3915e-02) 
2023-05-27 15:47:15.981160: train Epoch: [38][ 62/193]	Time 11.716 ( 6.303)	Data 11.140 ( 5.729)	Loss 1.3008e-01 (9.4489e-02) 
2023-05-27 15:47:16.545906: train Epoch: [38][ 63/193]	Time  0.565 ( 6.213)	Data  0.001 ( 5.640)	Loss 7.4442e-02 (9.4176e-02) 
2023-05-27 15:47:28.357342: train Epoch: [38][ 64/193]	Time 11.811 ( 6.299)	Data 11.219 ( 5.726)	Loss 1.0976e-01 (9.4416e-02) 
2023-05-27 15:47:28.920497: train Epoch: [38][ 65/193]	Time  0.563 ( 6.212)	Data  0.001 ( 5.639)	Loss 6.8351e-02 (9.4021e-02) 
2023-05-27 15:47:40.334582: train Epoch: [38][ 66/193]	Time 11.414 ( 6.290)	Data 10.839 ( 5.717)	Loss 1.2764e-01 (9.4523e-02) 
2023-05-27 15:47:40.937732: train Epoch: [38][ 67/193]	Time  0.603 ( 6.206)	Data  0.001 ( 5.633)	Loss 7.4928e-02 (9.4235e-02) 
2023-05-27 15:47:52.706669: train Epoch: [38][ 68/193]	Time 11.769 ( 6.287)	Data 11.200 ( 5.713)	Loss 3.0874e-02 (9.3316e-02) 
2023-05-27 15:47:53.311236: train Epoch: [38][ 69/193]	Time  0.605 ( 6.206)	Data  0.001 ( 5.632)	Loss 1.6319e-01 (9.4314e-02) 
2023-05-27 15:48:05.023757: train Epoch: [38][ 70/193]	Time 11.713 ( 6.283)	Data 11.148 ( 5.709)	Loss 6.9412e-02 (9.3964e-02) 
2023-05-27 15:48:05.599192: train Epoch: [38][ 71/193]	Time  0.575 ( 6.204)	Data  0.001 ( 5.630)	Loss 6.8056e-02 (9.3604e-02) 
2023-05-27 15:48:17.821609: train Epoch: [38][ 72/193]	Time 12.222 ( 6.286)	Data 11.661 ( 5.713)	Loss 8.2815e-02 (9.3456e-02) 
2023-05-27 15:48:18.396206: train Epoch: [38][ 73/193]	Time  0.575 ( 6.209)	Data  0.001 ( 5.635)	Loss 5.1085e-02 (9.2884e-02) 
2023-05-27 15:48:30.306859: train Epoch: [38][ 74/193]	Time 11.911 ( 6.285)	Data 11.334 ( 5.711)	Loss 1.2245e-01 (9.3278e-02) 
2023-05-27 15:48:30.879005: train Epoch: [38][ 75/193]	Time  0.572 ( 6.210)	Data  0.001 ( 5.636)	Loss 1.0473e-01 (9.3428e-02) 
2023-05-27 15:48:42.187124: train Epoch: [38][ 76/193]	Time 11.308 ( 6.276)	Data 10.738 ( 5.703)	Loss 7.1085e-02 (9.3138e-02) 
2023-05-27 15:48:42.748810: train Epoch: [38][ 77/193]	Time  0.562 ( 6.203)	Data  0.001 ( 5.629)	Loss 8.2350e-02 (9.3000e-02) 
2023-05-27 15:48:54.460116: train Epoch: [38][ 78/193]	Time 11.711 ( 6.273)	Data 11.123 ( 5.699)	Loss 8.9502e-02 (9.2956e-02) 
2023-05-27 15:48:55.023332: train Epoch: [38][ 79/193]	Time  0.563 ( 6.201)	Data  0.001 ( 5.628)	Loss 1.2351e-01 (9.3338e-02) 
2023-05-27 15:49:07.390887: train Epoch: [38][ 80/193]	Time 12.368 ( 6.277)	Data 11.804 ( 5.704)	Loss 6.8156e-02 (9.3027e-02) 
2023-05-27 15:49:07.966453: train Epoch: [38][ 81/193]	Time  0.576 ( 6.208)	Data  0.001 ( 5.634)	Loss 6.9818e-02 (9.2744e-02) 
2023-05-27 15:49:19.939340: train Epoch: [38][ 82/193]	Time 11.973 ( 6.277)	Data 11.401 ( 5.704)	Loss 6.2538e-02 (9.2380e-02) 
2023-05-27 15:49:20.509736: train Epoch: [38][ 83/193]	Time  0.570 ( 6.209)	Data  0.001 ( 5.636)	Loss 8.9114e-02 (9.2341e-02) 
2023-05-27 15:49:32.180216: train Epoch: [38][ 84/193]	Time 11.670 ( 6.274)	Data 11.104 ( 5.700)	Loss 1.0235e-01 (9.2459e-02) 
2023-05-27 15:49:32.742755: train Epoch: [38][ 85/193]	Time  0.563 ( 6.207)	Data  0.001 ( 5.634)	Loss 9.4556e-02 (9.2483e-02) 
2023-05-27 15:49:43.906851: train Epoch: [38][ 86/193]	Time 11.164 ( 6.264)	Data 10.592 ( 5.691)	Loss 9.0809e-02 (9.2464e-02) 
2023-05-27 15:49:44.471089: train Epoch: [38][ 87/193]	Time  0.564 ( 6.199)	Data  0.001 ( 5.626)	Loss 1.0662e-01 (9.2625e-02) 
2023-05-27 15:49:54.841724: train Epoch: [38][ 88/193]	Time 10.371 ( 6.246)	Data  9.783 ( 5.673)	Loss 5.7862e-02 (9.2234e-02) 
2023-05-27 15:49:55.414394: train Epoch: [38][ 89/193]	Time  0.573 ( 6.183)	Data  0.001 ( 5.610)	Loss 4.4113e-02 (9.1699e-02) 
2023-05-27 15:50:06.754293: train Epoch: [38][ 90/193]	Time 11.340 ( 6.240)	Data 10.765 ( 5.667)	Loss 7.6849e-02 (9.1536e-02) 
2023-05-27 15:50:07.315127: train Epoch: [38][ 91/193]	Time  0.561 ( 6.178)	Data  0.001 ( 5.605)	Loss 4.7794e-02 (9.1061e-02) 
2023-05-27 15:50:19.619651: train Epoch: [38][ 92/193]	Time 12.305 ( 6.244)	Data 11.737 ( 5.671)	Loss 5.4152e-02 (9.0664e-02) 
2023-05-27 15:50:20.181358: train Epoch: [38][ 93/193]	Time  0.562 ( 6.184)	Data  0.001 ( 5.611)	Loss 5.5604e-02 (9.0291e-02) 
2023-05-27 15:50:31.732234: train Epoch: [38][ 94/193]	Time 11.551 ( 6.240)	Data 10.977 ( 5.667)	Loss 7.9087e-02 (9.0173e-02) 
2023-05-27 15:50:32.300594: train Epoch: [38][ 95/193]	Time  0.568 ( 6.181)	Data  0.001 ( 5.608)	Loss 8.9962e-02 (9.0171e-02) 
2023-05-27 15:50:44.153664: train Epoch: [38][ 96/193]	Time 11.853 ( 6.240)	Data 11.293 ( 5.667)	Loss 6.7362e-02 (8.9936e-02) 
2023-05-27 15:50:44.715136: train Epoch: [38][ 97/193]	Time  0.561 ( 6.182)	Data  0.001 ( 5.609)	Loss 7.7454e-02 (8.9808e-02) 
2023-05-27 15:50:56.853625: train Epoch: [38][ 98/193]	Time 12.138 ( 6.242)	Data 11.570 ( 5.669)	Loss 1.9481e-01 (9.0869e-02) 
2023-05-27 15:50:57.415868: train Epoch: [38][ 99/193]	Time  0.562 ( 6.185)	Data  0.001 ( 5.613)	Loss 8.7207e-02 (9.0832e-02) 
2023-05-27 15:51:09.139271: train Epoch: [38][100/193]	Time 11.723 ( 6.240)	Data 11.132 ( 5.667)	Loss 7.1556e-02 (9.0641e-02) 
2023-05-27 15:51:09.701629: train Epoch: [38][101/193]	Time  0.562 ( 6.184)	Data  0.001 ( 5.612)	Loss 8.1355e-02 (9.0550e-02) 
2023-05-27 15:51:21.875570: train Epoch: [38][102/193]	Time 12.174 ( 6.242)	Data 11.594 ( 5.670)	Loss 9.1762e-02 (9.0562e-02) 
2023-05-27 15:51:22.438823: train Epoch: [38][103/193]	Time  0.563 ( 6.188)	Data  0.001 ( 5.615)	Loss 4.1633e-02 (9.0092e-02) 
2023-05-27 15:51:34.237373: train Epoch: [38][104/193]	Time 11.799 ( 6.241)	Data 11.184 ( 5.668)	Loss 6.0825e-02 (8.9813e-02) 
2023-05-27 15:51:34.798992: train Epoch: [38][105/193]	Time  0.562 ( 6.188)	Data  0.001 ( 5.615)	Loss 7.5739e-02 (8.9680e-02) 
2023-05-27 15:51:46.287333: train Epoch: [38][106/193]	Time 11.488 ( 6.237)	Data 10.919 ( 5.664)	Loss 5.6827e-02 (8.9373e-02) 
2023-05-27 15:51:46.858436: train Epoch: [38][107/193]	Time  0.571 ( 6.185)	Data  0.001 ( 5.612)	Loss 6.5392e-02 (8.9151e-02) 
2023-05-27 15:51:59.296216: train Epoch: [38][108/193]	Time 12.438 ( 6.242)	Data 11.859 ( 5.669)	Loss 8.8008e-02 (8.9141e-02) 
2023-05-27 15:51:59.888005: train Epoch: [38][109/193]	Time  0.592 ( 6.191)	Data  0.001 ( 5.618)	Loss 5.5560e-02 (8.8835e-02) 
2023-05-27 15:52:11.727520: train Epoch: [38][110/193]	Time 11.839 ( 6.242)	Data 11.275 ( 5.669)	Loss 7.1943e-02 (8.8683e-02) 
2023-05-27 15:52:12.310084: train Epoch: [38][111/193]	Time  0.583 ( 6.191)	Data  0.001 ( 5.618)	Loss 6.2228e-02 (8.8447e-02) 
2023-05-27 15:52:24.350029: train Epoch: [38][112/193]	Time 12.040 ( 6.243)	Data 11.454 ( 5.670)	Loss 1.5101e-01 (8.9001e-02) 
2023-05-27 15:52:24.939011: train Epoch: [38][113/193]	Time  0.589 ( 6.193)	Data  0.001 ( 5.620)	Loss 1.3157e-01 (8.9374e-02) 
2023-05-27 15:52:36.724349: train Epoch: [38][114/193]	Time 11.785 ( 6.242)	Data 11.202 ( 5.669)	Loss 9.1974e-02 (8.9397e-02) 
2023-05-27 15:52:37.327786: train Epoch: [38][115/193]	Time  0.603 ( 6.193)	Data  0.001 ( 5.620)	Loss 9.1809e-02 (8.9417e-02) 
2023-05-27 15:52:48.967506: train Epoch: [38][116/193]	Time 11.640 ( 6.240)	Data 11.075 ( 5.666)	Loss 6.3026e-02 (8.9192e-02) 
2023-05-27 15:52:49.536866: train Epoch: [38][117/193]	Time  0.569 ( 6.192)	Data  0.001 ( 5.618)	Loss 6.8035e-02 (8.9013e-02) 
2023-05-27 15:53:00.482550: train Epoch: [38][118/193]	Time 10.946 ( 6.232)	Data 10.380 ( 5.658)	Loss 9.3799e-02 (8.9053e-02) 
2023-05-27 15:53:01.058943: train Epoch: [38][119/193]	Time  0.576 ( 6.185)	Data  0.001 ( 5.611)	Loss 5.7651e-02 (8.8791e-02) 
2023-05-27 15:53:13.473675: train Epoch: [38][120/193]	Time 12.415 ( 6.236)	Data 11.834 ( 5.663)	Loss 5.4294e-02 (8.8506e-02) 
2023-05-27 15:53:14.044871: train Epoch: [38][121/193]	Time  0.571 ( 6.190)	Data  0.001 ( 5.616)	Loss 1.1237e-01 (8.8702e-02) 
2023-05-27 15:53:26.027978: train Epoch: [38][122/193]	Time 11.983 ( 6.237)	Data 11.413 ( 5.663)	Loss 5.6949e-02 (8.8443e-02) 
2023-05-27 15:53:26.605190: train Epoch: [38][123/193]	Time  0.577 ( 6.191)	Data  0.001 ( 5.618)	Loss 5.8847e-02 (8.8205e-02) 
2023-05-27 15:53:38.771894: train Epoch: [38][124/193]	Time 12.167 ( 6.239)	Data 11.599 ( 5.665)	Loss 7.4381e-02 (8.8094e-02) 
2023-05-27 15:53:39.343033: train Epoch: [38][125/193]	Time  0.571 ( 6.194)	Data  0.001 ( 5.621)	Loss 7.0370e-02 (8.7954e-02) 
2023-05-27 15:53:51.030903: train Epoch: [38][126/193]	Time 11.688 ( 6.237)	Data 11.106 ( 5.664)	Loss 1.0267e-01 (8.8069e-02) 
2023-05-27 15:53:51.603437: train Epoch: [38][127/193]	Time  0.573 ( 6.193)	Data  0.001 ( 5.619)	Loss 7.3594e-02 (8.7956e-02) 
2023-05-27 15:54:02.756845: train Epoch: [38][128/193]	Time 11.153 ( 6.231)	Data 10.575 ( 5.658)	Loss 9.4777e-02 (8.8009e-02) 
2023-05-27 15:54:03.324541: train Epoch: [38][129/193]	Time  0.568 ( 6.188)	Data  0.001 ( 5.614)	Loss 2.4645e-01 (8.9228e-02) 
2023-05-27 15:54:15.200781: train Epoch: [38][130/193]	Time 11.876 ( 6.231)	Data 11.307 ( 5.658)	Loss 8.9182e-02 (8.9228e-02) 
2023-05-27 15:54:15.777041: train Epoch: [38][131/193]	Time  0.576 ( 6.188)	Data  0.001 ( 5.615)	Loss 1.1601e-01 (8.9431e-02) 
2023-05-27 15:54:27.592569: train Epoch: [38][132/193]	Time 11.816 ( 6.231)	Data 11.253 ( 5.657)	Loss 8.6338e-02 (8.9407e-02) 
2023-05-27 15:54:28.158402: train Epoch: [38][133/193]	Time  0.566 ( 6.188)	Data  0.001 ( 5.615)	Loss 1.0978e-01 (8.9559e-02) 
2023-05-27 15:54:39.991683: train Epoch: [38][134/193]	Time 11.833 ( 6.230)	Data 11.270 ( 5.657)	Loss 5.0943e-02 (8.9273e-02) 
2023-05-27 15:54:40.554295: train Epoch: [38][135/193]	Time  0.563 ( 6.189)	Data  0.001 ( 5.615)	Loss 4.3836e-02 (8.8939e-02) 
2023-05-27 15:54:53.255001: train Epoch: [38][136/193]	Time 12.701 ( 6.236)	Data 12.120 ( 5.663)	Loss 7.2423e-02 (8.8819e-02) 
2023-05-27 15:54:53.864573: train Epoch: [38][137/193]	Time  0.610 ( 6.195)	Data  0.001 ( 5.622)	Loss 9.9880e-02 (8.8899e-02) 
2023-05-27 15:55:06.407451: train Epoch: [38][138/193]	Time 12.543 ( 6.241)	Data 11.972 ( 5.668)	Loss 8.6737e-02 (8.8883e-02) 
2023-05-27 15:55:06.983427: train Epoch: [38][139/193]	Time  0.576 ( 6.200)	Data  0.001 ( 5.627)	Loss 4.9797e-02 (8.8604e-02) 
2023-05-27 15:55:19.377842: train Epoch: [38][140/193]	Time 12.394 ( 6.244)	Data 11.832 ( 5.671)	Loss 1.0222e-01 (8.8701e-02) 
2023-05-27 15:55:19.939873: train Epoch: [38][141/193]	Time  0.562 ( 6.204)	Data  0.001 ( 5.631)	Loss 5.3842e-02 (8.8455e-02) 
2023-05-27 15:55:32.383373: train Epoch: [38][142/193]	Time 12.443 ( 6.248)	Data 11.877 ( 5.675)	Loss 7.2353e-02 (8.8343e-02) 
2023-05-27 15:55:32.944391: train Epoch: [38][143/193]	Time  0.561 ( 6.209)	Data  0.001 ( 5.635)	Loss 9.8630e-02 (8.8414e-02) 
2023-05-27 15:55:44.824304: train Epoch: [38][144/193]	Time 11.880 ( 6.248)	Data 11.311 ( 5.675)	Loss 8.9374e-02 (8.8421e-02) 
2023-05-27 15:55:45.392775: train Epoch: [38][145/193]	Time  0.568 ( 6.209)	Data  0.001 ( 5.636)	Loss 6.7475e-02 (8.8277e-02) 
2023-05-27 15:55:57.237261: train Epoch: [38][146/193]	Time 11.844 ( 6.247)	Data 11.278 ( 5.674)	Loss 6.2879e-02 (8.8104e-02) 
2023-05-27 15:55:57.804980: train Epoch: [38][147/193]	Time  0.568 ( 6.209)	Data  0.001 ( 5.636)	Loss 7.6984e-02 (8.8029e-02) 
2023-05-27 15:56:09.360027: train Epoch: [38][148/193]	Time 11.555 ( 6.245)	Data 10.990 ( 5.672)	Loss 7.8759e-02 (8.7967e-02) 
2023-05-27 15:56:09.926176: train Epoch: [38][149/193]	Time  0.566 ( 6.207)	Data  0.001 ( 5.634)	Loss 8.1348e-02 (8.7923e-02) 
2023-05-27 15:56:21.334426: train Epoch: [38][150/193]	Time 11.408 ( 6.241)	Data 10.832 ( 5.668)	Loss 9.9600e-02 (8.8000e-02) 
2023-05-27 15:56:21.978868: train Epoch: [38][151/193]	Time  0.644 ( 6.204)	Data  0.001 ( 5.631)	Loss 1.0791e-01 (8.8131e-02) 
2023-05-27 15:56:34.378697: train Epoch: [38][152/193]	Time 12.400 ( 6.245)	Data 11.835 ( 5.672)	Loss 6.1418e-02 (8.7957e-02) 
2023-05-27 15:56:34.942470: train Epoch: [38][153/193]	Time  0.564 ( 6.208)	Data  0.001 ( 5.635)	Loss 5.9952e-02 (8.7775e-02) 
2023-05-27 15:56:47.167207: train Epoch: [38][154/193]	Time 12.225 ( 6.247)	Data 11.654 ( 5.674)	Loss 9.7809e-02 (8.7840e-02) 
2023-05-27 15:56:47.729139: train Epoch: [38][155/193]	Time  0.562 ( 6.210)	Data  0.001 ( 5.637)	Loss 1.6597e-01 (8.8340e-02) 
2023-05-27 15:57:00.015974: train Epoch: [38][156/193]	Time 12.287 ( 6.249)	Data 11.714 ( 5.676)	Loss 6.2827e-02 (8.8178e-02) 
2023-05-27 15:57:00.608717: train Epoch: [38][157/193]	Time  0.593 ( 6.213)	Data  0.001 ( 5.640)	Loss 8.2730e-02 (8.8143e-02) 
2023-05-27 15:57:12.140681: train Epoch: [38][158/193]	Time 11.532 ( 6.247)	Data 10.956 ( 5.674)	Loss 8.2205e-02 (8.8106e-02) 
2023-05-27 15:57:12.723035: train Epoch: [38][159/193]	Time  0.582 ( 6.211)	Data  0.001 ( 5.638)	Loss 8.2000e-02 (8.8068e-02) 
2023-05-27 15:57:25.071792: train Epoch: [38][160/193]	Time 12.349 ( 6.249)	Data 11.775 ( 5.676)	Loss 7.1953e-02 (8.7968e-02) 
2023-05-27 15:57:25.645769: train Epoch: [38][161/193]	Time  0.574 ( 6.214)	Data  0.001 ( 5.641)	Loss 1.1060e-01 (8.8107e-02) 
2023-05-27 15:57:36.982478: train Epoch: [38][162/193]	Time 11.337 ( 6.246)	Data 10.731 ( 5.672)	Loss 7.1106e-02 (8.8003e-02) 
2023-05-27 15:57:37.554438: train Epoch: [38][163/193]	Time  0.572 ( 6.211)	Data  0.001 ( 5.638)	Loss 3.2289e-01 (8.9435e-02) 
2023-05-27 15:57:49.161188: train Epoch: [38][164/193]	Time 11.607 ( 6.244)	Data 11.027 ( 5.670)	Loss 4.6158e-02 (8.9173e-02) 
2023-05-27 15:57:49.730501: train Epoch: [38][165/193]	Time  0.569 ( 6.210)	Data  0.001 ( 5.636)	Loss 1.0972e-01 (8.9297e-02) 
2023-05-27 15:58:01.573379: train Epoch: [38][166/193]	Time 11.843 ( 6.243)	Data 11.281 ( 5.670)	Loss 6.6346e-02 (8.9159e-02) 
2023-05-27 15:58:02.144572: train Epoch: [38][167/193]	Time  0.571 ( 6.210)	Data  0.001 ( 5.636)	Loss 3.2703e-02 (8.8823e-02) 
2023-05-27 15:58:13.750936: train Epoch: [38][168/193]	Time 11.606 ( 6.242)	Data 11.035 ( 5.668)	Loss 3.1642e-02 (8.8485e-02) 
2023-05-27 15:58:14.317687: train Epoch: [38][169/193]	Time  0.567 ( 6.208)	Data  0.001 ( 5.635)	Loss 6.7510e-02 (8.8362e-02) 
2023-05-27 15:58:25.946361: train Epoch: [38][170/193]	Time 11.629 ( 6.240)	Data 11.068 ( 5.667)	Loss 3.1744e-01 (8.9701e-02) 
2023-05-27 15:58:26.508512: train Epoch: [38][171/193]	Time  0.562 ( 6.207)	Data  0.001 ( 5.634)	Loss 6.5499e-02 (8.9561e-02) 
2023-05-27 15:58:39.037799: train Epoch: [38][172/193]	Time 12.529 ( 6.243)	Data 11.949 ( 5.670)	Loss 9.8926e-02 (8.9615e-02) 
2023-05-27 15:58:39.606234: train Epoch: [38][173/193]	Time  0.568 ( 6.211)	Data  0.001 ( 5.638)	Loss 8.8338e-02 (8.9607e-02) 
2023-05-27 15:58:51.390693: train Epoch: [38][174/193]	Time 11.784 ( 6.243)	Data 11.212 ( 5.670)	Loss 7.0152e-02 (8.9496e-02) 
2023-05-27 15:58:51.959190: train Epoch: [38][175/193]	Time  0.568 ( 6.210)	Data  0.001 ( 5.637)	Loss 1.0112e-01 (8.9562e-02) 
2023-05-27 15:59:03.621573: train Epoch: [38][176/193]	Time 11.662 ( 6.241)	Data 11.091 ( 5.668)	Loss 9.8316e-02 (8.9612e-02) 
2023-05-27 15:59:04.194381: train Epoch: [38][177/193]	Time  0.573 ( 6.209)	Data  0.001 ( 5.636)	Loss 7.3008e-02 (8.9518e-02) 
2023-05-27 15:59:16.085254: train Epoch: [38][178/193]	Time 11.891 ( 6.241)	Data 11.321 ( 5.668)	Loss 7.3771e-02 (8.9431e-02) 
2023-05-27 15:59:16.666385: train Epoch: [38][179/193]	Time  0.581 ( 6.210)	Data  0.001 ( 5.637)	Loss 1.1920e-01 (8.9596e-02) 
2023-05-27 15:59:28.329790: train Epoch: [38][180/193]	Time 11.663 ( 6.240)	Data 11.089 ( 5.667)	Loss 1.3878e-01 (8.9868e-02) 
2023-05-27 15:59:28.892315: train Epoch: [38][181/193]	Time  0.563 ( 6.209)	Data  0.001 ( 5.636)	Loss 4.4228e-02 (8.9617e-02) 
2023-05-27 15:59:40.998801: train Epoch: [38][182/193]	Time 12.106 ( 6.241)	Data 11.533 ( 5.668)	Loss 5.9295e-02 (8.9451e-02) 
2023-05-27 15:59:41.567632: train Epoch: [38][183/193]	Time  0.569 ( 6.210)	Data  0.001 ( 5.637)	Loss 9.9535e-02 (8.9506e-02) 
2023-05-27 15:59:53.318716: train Epoch: [38][184/193]	Time 11.751 ( 6.240)	Data 11.188 ( 5.667)	Loss 5.0908e-02 (8.9297e-02) 
2023-05-27 15:59:53.895186: train Epoch: [38][185/193]	Time  0.576 ( 6.210)	Data  0.001 ( 5.637)	Loss 5.6997e-02 (8.9124e-02) 
2023-05-27 16:00:05.486593: train Epoch: [38][186/193]	Time 11.591 ( 6.238)	Data 11.014 ( 5.665)	Loss 5.9821e-02 (8.8967e-02) 
2023-05-27 16:00:06.057714: train Epoch: [38][187/193]	Time  0.571 ( 6.208)	Data  0.001 ( 5.635)	Loss 9.1533e-02 (8.8981e-02) 
2023-05-27 16:00:18.046580: train Epoch: [38][188/193]	Time 11.989 ( 6.239)	Data 11.426 ( 5.666)	Loss 6.4656e-02 (8.8852e-02) 
2023-05-27 16:00:18.609673: train Epoch: [38][189/193]	Time  0.563 ( 6.209)	Data  0.001 ( 5.636)	Loss 9.1359e-02 (8.8865e-02) 
2023-05-27 16:00:29.364541: train Epoch: [38][190/193]	Time 10.755 ( 6.233)	Data 10.194 ( 5.660)	Loss 7.9863e-02 (8.8818e-02) 
2023-05-27 16:00:29.930406: train Epoch: [38][191/193]	Time  0.566 ( 6.203)	Data  0.001 ( 5.630)	Loss 1.1108e-01 (8.8934e-02) 
2023-05-27 16:00:40.627504: train Epoch: [38][192/193]	Time 10.697 ( 6.226)	Data 10.133 ( 5.654)	Loss 4.5154e-02 (8.8707e-02) 
2023-05-27 16:00:40.823366: Train Epoch done in 1201.9065378560044 s 
2023-05-27 16:00:49.116510: val Epoch: [38][ 0/72]	Time  7.361 ( 7.361)	Data  7.183 ( 7.183)	Loss 1.7930e-01 (1.7930e-01) 
2023-05-27 16:00:49.428570: val Epoch: [38][ 1/72]	Time  0.312 ( 3.836)	Data  0.204 ( 3.693)	Loss 5.8679e-02 (1.1899e-01) 
2023-05-27 16:00:55.290309: val Epoch: [38][ 2/72]	Time  5.862 ( 4.512)	Data  5.747 ( 4.378)	Loss 9.1207e-02 (1.0973e-01) 
2023-05-27 16:00:55.481399: val Epoch: [38][ 3/72]	Time  0.191 ( 3.431)	Data  0.075 ( 3.302)	Loss 8.4643e-02 (1.0346e-01) 
2023-05-27 16:01:01.945684: val Epoch: [38][ 4/72]	Time  6.464 ( 4.038)	Data  6.356 ( 3.913)	Loss 6.5960e-01 (2.1469e-01) 
2023-05-27 16:01:02.055223: val Epoch: [38][ 5/72]	Time  0.110 ( 3.383)	Data  0.001 ( 3.261)	Loss 3.2282e-01 (2.3271e-01) 
2023-05-27 16:01:08.237253: val Epoch: [38][ 6/72]	Time  6.182 ( 3.783)	Data  6.073 ( 3.663)	Loss 1.8141e-01 (2.2538e-01) 
2023-05-27 16:01:08.344946: val Epoch: [38][ 7/72]	Time  0.108 ( 3.324)	Data  0.001 ( 3.205)	Loss 1.0960e-01 (2.1091e-01) 
2023-05-27 16:01:14.227236: val Epoch: [38][ 8/72]	Time  5.882 ( 3.608)	Data  5.777 ( 3.491)	Loss 8.5867e-02 (1.9702e-01) 
2023-05-27 16:01:14.437594: val Epoch: [38][ 9/72]	Time  0.210 ( 3.268)	Data  0.104 ( 3.152)	Loss 6.4122e-02 (1.8373e-01) 
2023-05-27 16:01:20.233427: val Epoch: [38][10/72]	Time  5.796 ( 3.498)	Data  5.687 ( 3.383)	Loss 4.9251e-02 (1.7150e-01) 
2023-05-27 16:01:21.180942: val Epoch: [38][11/72]	Time  0.948 ( 3.285)	Data  0.839 ( 3.171)	Loss 5.2107e-02 (1.6155e-01) 
2023-05-27 16:01:26.243818: val Epoch: [38][12/72]	Time  5.063 ( 3.422)	Data  4.952 ( 3.308)	Loss 1.0432e-01 (1.5715e-01) 
2023-05-27 16:01:27.259495: val Epoch: [38][13/72]	Time  1.016 ( 3.250)	Data  0.910 ( 3.136)	Loss 1.3337e-01 (1.5545e-01) 
2023-05-27 16:01:32.459238: val Epoch: [38][14/72]	Time  5.200 ( 3.380)	Data  5.030 ( 3.263)	Loss 8.1671e-02 (1.5053e-01) 
2023-05-27 16:01:33.799806: val Epoch: [38][15/72]	Time  1.341 ( 3.253)	Data  1.218 ( 3.135)	Loss 9.4997e-02 (1.4706e-01) 
2023-05-27 16:01:38.651075: val Epoch: [38][16/72]	Time  4.851 ( 3.347)	Data  4.738 ( 3.229)	Loss 4.8654e-02 (1.4127e-01) 
2023-05-27 16:01:40.090516: val Epoch: [38][17/72]	Time  1.439 ( 3.241)	Data  1.322 ( 3.123)	Loss 5.5340e-02 (1.3650e-01) 
2023-05-27 16:01:44.669520: val Epoch: [38][18/72]	Time  4.579 ( 3.311)	Data  4.468 ( 3.194)	Loss 4.5319e-02 (1.3170e-01) 
2023-05-27 16:01:46.347783: val Epoch: [38][19/72]	Time  1.678 ( 3.230)	Data  1.572 ( 3.113)	Loss 2.0325e-01 (1.3528e-01) 
2023-05-27 16:01:50.664477: val Epoch: [38][20/72]	Time  4.317 ( 3.281)	Data  4.209 ( 3.165)	Loss 3.7756e-02 (1.3063e-01) 
2023-05-27 16:01:52.421247: val Epoch: [38][21/72]	Time  1.757 ( 3.212)	Data  1.651 ( 3.096)	Loss 2.1024e-01 (1.3425e-01) 
2023-05-27 16:01:56.830345: val Epoch: [38][22/72]	Time  4.409 ( 3.264)	Data  4.301 ( 3.149)	Loss 1.1255e-01 (1.3331e-01) 
2023-05-27 16:01:58.771575: val Epoch: [38][23/72]	Time  1.941 ( 3.209)	Data  1.836 ( 3.094)	Loss 9.5374e-02 (1.3173e-01) 
2023-05-27 16:02:02.955688: val Epoch: [38][24/72]	Time  4.184 ( 3.248)	Data  4.079 ( 3.133)	Loss 5.4263e-02 (1.2863e-01) 
2023-05-27 16:02:04.895908: val Epoch: [38][25/72]	Time  1.940 ( 3.198)	Data  1.827 ( 3.083)	Loss 4.9946e-02 (1.2560e-01) 
2023-05-27 16:02:09.287063: val Epoch: [38][26/72]	Time  4.391 ( 3.242)	Data  4.282 ( 3.127)	Loss 4.6457e-02 (1.2267e-01) 
2023-05-27 16:02:11.197722: val Epoch: [38][27/72]	Time  1.911 ( 3.194)	Data  1.805 ( 3.080)	Loss 6.2719e-02 (1.2053e-01) 
2023-05-27 16:02:15.727469: val Epoch: [38][28/72]	Time  4.530 ( 3.240)	Data  4.424 ( 3.127)	Loss 6.6884e-02 (1.1868e-01) 
2023-05-27 16:02:17.432623: val Epoch: [38][29/72]	Time  1.705 ( 3.189)	Data  1.595 ( 3.076)	Loss 1.0256e-01 (1.1814e-01) 
2023-05-27 16:02:21.860352: val Epoch: [38][30/72]	Time  4.428 ( 3.229)	Data  4.321 ( 3.116)	Loss 5.3141e-01 (1.3147e-01) 
2023-05-27 16:02:23.491912: val Epoch: [38][31/72]	Time  1.632 ( 3.179)	Data  1.524 ( 3.066)	Loss 2.6863e-01 (1.3576e-01) 
2023-05-27 16:02:27.574575: val Epoch: [38][32/72]	Time  4.083 ( 3.207)	Data  3.972 ( 3.093)	Loss 7.8516e-02 (1.3403e-01) 
2023-05-27 16:02:29.854100: val Epoch: [38][33/72]	Time  2.280 ( 3.179)	Data  2.172 ( 3.066)	Loss 8.1841e-02 (1.3249e-01) 
2023-05-27 16:02:33.775254: val Epoch: [38][34/72]	Time  3.921 ( 3.201)	Data  3.800 ( 3.087)	Loss 7.8534e-02 (1.3095e-01) 
2023-05-27 16:02:36.381544: val Epoch: [38][35/72]	Time  2.606 ( 3.184)	Data  2.500 ( 3.071)	Loss 3.4063e-01 (1.3677e-01) 
2023-05-27 16:02:40.082835: val Epoch: [38][36/72]	Time  3.701 ( 3.198)	Data  3.596 ( 3.085)	Loss 2.6508e-01 (1.4024e-01) 
2023-05-27 16:02:42.778280: val Epoch: [38][37/72]	Time  2.695 ( 3.185)	Data  2.590 ( 3.072)	Loss 3.5296e-01 (1.4584e-01) 
2023-05-27 16:02:46.036383: val Epoch: [38][38/72]	Time  3.258 ( 3.187)	Data  3.143 ( 3.074)	Loss 5.9240e-02 (1.4362e-01) 
2023-05-27 16:02:48.874463: val Epoch: [38][39/72]	Time  2.838 ( 3.178)	Data  2.732 ( 3.065)	Loss 5.5789e-02 (1.4142e-01) 
2023-05-27 16:02:52.335816: val Epoch: [38][40/72]	Time  3.461 ( 3.185)	Data  3.357 ( 3.073)	Loss 6.7606e-02 (1.3962e-01) 
2023-05-27 16:02:55.064698: val Epoch: [38][41/72]	Time  2.729 ( 3.174)	Data  2.623 ( 3.062)	Loss 5.6714e-02 (1.3765e-01) 
2023-05-27 16:02:58.719207: val Epoch: [38][42/72]	Time  3.654 ( 3.185)	Data  3.545 ( 3.073)	Loss 3.9674e-01 (1.4367e-01) 
2023-05-27 16:03:01.448805: val Epoch: [38][43/72]	Time  2.730 ( 3.175)	Data  2.624 ( 3.063)	Loss 7.9534e-02 (1.4222e-01) 
2023-05-27 16:03:05.104561: val Epoch: [38][44/72]	Time  3.656 ( 3.186)	Data  3.550 ( 3.074)	Loss 1.1896e-01 (1.4170e-01) 
2023-05-27 16:03:07.606331: val Epoch: [38][45/72]	Time  2.502 ( 3.171)	Data  2.396 ( 3.059)	Loss 4.3139e-02 (1.3956e-01) 
2023-05-27 16:03:11.296656: val Epoch: [38][46/72]	Time  3.690 ( 3.182)	Data  3.577 ( 3.070)	Loss 1.4746e-01 (1.3973e-01) 
2023-05-27 16:03:13.893349: val Epoch: [38][47/72]	Time  2.597 ( 3.170)	Data  2.488 ( 3.058)	Loss 1.2435e-01 (1.3940e-01) 
2023-05-27 16:03:17.399935: val Epoch: [38][48/72]	Time  3.507 ( 3.176)	Data  3.398 ( 3.065)	Loss 1.1750e-01 (1.3896e-01) 
2023-05-27 16:03:20.128950: val Epoch: [38][49/72]	Time  2.729 ( 3.167)	Data  2.621 ( 3.056)	Loss 6.4314e-02 (1.3746e-01) 
2023-05-27 16:03:23.790492: val Epoch: [38][50/72]	Time  3.662 ( 3.177)	Data  3.540 ( 3.065)	Loss 1.0999e-01 (1.3693e-01) 
2023-05-27 16:03:26.314573: val Epoch: [38][51/72]	Time  2.524 ( 3.165)	Data  2.416 ( 3.053)	Loss 4.5359e-01 (1.4302e-01) 
2023-05-27 16:03:29.968761: val Epoch: [38][52/72]	Time  3.654 ( 3.174)	Data  3.546 ( 3.062)	Loss 8.6754e-02 (1.4195e-01) 
2023-05-27 16:03:32.446437: val Epoch: [38][53/72]	Time  2.478 ( 3.161)	Data  2.370 ( 3.049)	Loss 4.9275e-02 (1.4024e-01) 
2023-05-27 16:03:36.221615: val Epoch: [38][54/72]	Time  3.775 ( 3.172)	Data  3.666 ( 3.061)	Loss 3.7663e-01 (1.4454e-01) 
2023-05-27 16:03:38.400048: val Epoch: [38][55/72]	Time  2.178 ( 3.154)	Data  2.070 ( 3.043)	Loss 4.8173e-02 (1.4282e-01) 
2023-05-27 16:03:42.550868: val Epoch: [38][56/72]	Time  4.151 ( 3.172)	Data  4.043 ( 3.060)	Loss 1.0245e-01 (1.4211e-01) 
2023-05-27 16:03:44.376929: val Epoch: [38][57/72]	Time  1.826 ( 3.149)	Data  1.718 ( 3.037)	Loss 6.0615e-02 (1.4070e-01) 
2023-05-27 16:03:48.732356: val Epoch: [38][58/72]	Time  4.355 ( 3.169)	Data  4.247 ( 3.058)	Loss 9.0552e-02 (1.3985e-01) 
2023-05-27 16:03:50.321191: val Epoch: [38][59/72]	Time  1.589 ( 3.143)	Data  1.480 ( 3.031)	Loss 3.6398e-02 (1.3813e-01) 
2023-05-27 16:03:54.880426: val Epoch: [38][60/72]	Time  4.559 ( 3.166)	Data  4.451 ( 3.055)	Loss 1.7307e-01 (1.3870e-01) 
2023-05-27 16:03:56.631894: val Epoch: [38][61/72]	Time  1.751 ( 3.143)	Data  1.643 ( 3.032)	Loss 1.5829e-01 (1.3902e-01) 
2023-05-27 16:04:01.367754: val Epoch: [38][62/72]	Time  4.736 ( 3.168)	Data  4.622 ( 3.057)	Loss 6.0855e-02 (1.3778e-01) 
2023-05-27 16:04:02.557521: val Epoch: [38][63/72]	Time  1.190 ( 3.138)	Data  1.079 ( 3.026)	Loss 5.9724e-02 (1.3656e-01) 
2023-05-27 16:04:08.039840: val Epoch: [38][64/72]	Time  5.482 ( 3.174)	Data  5.373 ( 3.062)	Loss 3.2058e-01 (1.3939e-01) 
2023-05-27 16:04:08.706962: val Epoch: [38][65/72]	Time  0.667 ( 3.136)	Data  0.553 ( 3.024)	Loss 3.7927e-02 (1.3785e-01) 
2023-05-27 16:04:14.198110: val Epoch: [38][66/72]	Time  5.491 ( 3.171)	Data  5.383 ( 3.060)	Loss 5.8284e-02 (1.3666e-01) 
2023-05-27 16:04:15.352354: val Epoch: [38][67/72]	Time  1.154 ( 3.141)	Data  1.038 ( 3.030)	Loss 8.4918e-02 (1.3590e-01) 
2023-05-27 16:04:20.348221: val Epoch: [38][68/72]	Time  4.996 ( 3.168)	Data  4.888 ( 3.057)	Loss 5.9188e-02 (1.3479e-01) 
2023-05-27 16:04:21.578531: val Epoch: [38][69/72]	Time  1.230 ( 3.140)	Data  1.121 ( 3.029)	Loss 7.8167e-02 (1.3398e-01) 
2023-05-27 16:04:27.026606: val Epoch: [38][70/72]	Time  5.448 ( 3.173)	Data  5.329 ( 3.062)	Loss 9.1580e-02 (1.3338e-01) 
2023-05-27 16:04:27.298139: val Epoch: [38][71/72]	Time  0.272 ( 3.133)	Data  0.161 ( 3.021)	Loss 4.2937e-02 (1.3213e-01) 
2023-05-27 16:04:27.679546: Epoch 38 :Val : ['ET : 0.7296317219734192', 'TC : 0.783854067325592', 'WT : 0.8619217276573181'] 
2023-05-27 16:04:27.682383: Epoch 38 :Val : ['ET : 0.7296317219734192', 'TC : 0.783854067325592', 'WT : 0.8619217276573181'] 
2023-05-27 16:04:27.684416: Val epoch done in 226.86105823001708 s 
2023-05-27 16:04:27.690122: Batches per epoch:  193 
2023-05-27 16:04:42.128916: train Epoch: [39][  0/193]	Time 14.438 (14.438)	Data 13.831 (13.831)	Loss 3.9030e-02 (3.9030e-02) 
2023-05-27 16:04:42.713851: train Epoch: [39][  1/193]	Time  0.585 ( 7.512)	Data  0.001 ( 6.916)	Loss 9.8816e-02 (6.8923e-02) 
2023-05-27 16:04:55.248325: train Epoch: [39][  2/193]	Time 12.534 ( 9.186)	Data 11.966 ( 8.599)	Loss 6.0668e-02 (6.6171e-02) 
2023-05-27 16:04:55.815965: train Epoch: [39][  3/193]	Time  0.568 ( 7.031)	Data  0.001 ( 6.449)	Loss 1.4520e-01 (8.5929e-02) 
2023-05-27 16:05:08.378602: train Epoch: [39][  4/193]	Time 12.563 ( 8.138)	Data 11.998 ( 7.559)	Loss 1.0103e-01 (8.8949e-02) 
2023-05-27 16:05:08.952450: train Epoch: [39][  5/193]	Time  0.574 ( 6.877)	Data  0.001 ( 6.299)	Loss 1.0283e-01 (9.1263e-02) 
2023-05-27 16:05:20.963514: train Epoch: [39][  6/193]	Time 12.011 ( 7.610)	Data 11.400 ( 7.028)	Loss 8.3685e-02 (9.0180e-02) 
2023-05-27 16:05:21.532570: train Epoch: [39][  7/193]	Time  0.569 ( 6.730)	Data  0.001 ( 6.150)	Loss 6.3743e-02 (8.6876e-02) 
2023-05-27 16:05:34.083959: train Epoch: [39][  8/193]	Time 12.551 ( 7.377)	Data 11.981 ( 6.798)	Loss 6.2620e-02 (8.4181e-02) 
2023-05-27 16:05:34.646189: train Epoch: [39][  9/193]	Time  0.562 ( 6.696)	Data  0.001 ( 6.118)	Loss 1.9198e-01 (9.4961e-02) 
2023-05-27 16:05:46.992416: train Epoch: [39][ 10/193]	Time 12.346 ( 7.209)	Data 11.784 ( 6.633)	Loss 6.6196e-02 (9.2346e-02) 
2023-05-27 16:05:47.554292: train Epoch: [39][ 11/193]	Time  0.562 ( 6.655)	Data  0.001 ( 6.080)	Loss 1.7347e-01 (9.9106e-02) 
2023-05-27 16:05:59.233183: train Epoch: [39][ 12/193]	Time 11.679 ( 7.042)	Data 11.104 ( 6.467)	Loss 9.1424e-02 (9.8515e-02) 
2023-05-27 16:05:59.796155: train Epoch: [39][ 13/193]	Time  0.563 ( 6.579)	Data  0.001 ( 6.005)	Loss 7.5450e-02 (9.6868e-02) 
2023-05-27 16:06:12.043947: train Epoch: [39][ 14/193]	Time 12.248 ( 6.957)	Data 11.680 ( 6.383)	Loss 8.0268e-02 (9.5761e-02) 
2023-05-27 16:06:12.605864: train Epoch: [39][ 15/193]	Time  0.562 ( 6.557)	Data  0.001 ( 5.984)	Loss 6.2461e-02 (9.3680e-02) 
2023-05-27 16:06:23.413596: train Epoch: [39][ 16/193]	Time 10.808 ( 6.807)	Data 10.240 ( 6.235)	Loss 6.4585e-02 (9.1968e-02) 
2023-05-27 16:06:23.977017: train Epoch: [39][ 17/193]	Time  0.563 ( 6.460)	Data  0.001 ( 5.888)	Loss 7.8530e-02 (9.1222e-02) 
2023-05-27 16:06:36.120925: train Epoch: [39][ 18/193]	Time 12.144 ( 6.759)	Data 11.582 ( 6.188)	Loss 5.0987e-02 (8.9104e-02) 
2023-05-27 16:06:36.683176: train Epoch: [39][ 19/193]	Time  0.562 ( 6.450)	Data  0.001 ( 5.879)	Loss 1.1018e-01 (9.0158e-02) 
2023-05-27 16:06:48.731009: train Epoch: [39][ 20/193]	Time 12.048 ( 6.716)	Data 11.486 ( 6.146)	Loss 9.4444e-02 (9.0362e-02) 
2023-05-27 16:06:49.292636: train Epoch: [39][ 21/193]	Time  0.562 ( 6.436)	Data  0.001 ( 5.866)	Loss 7.6088e-02 (8.9713e-02) 
2023-05-27 16:07:00.086740: train Epoch: [39][ 22/193]	Time 10.794 ( 6.626)	Data 10.231 ( 6.056)	Loss 6.1895e-02 (8.8504e-02) 
2023-05-27 16:07:00.651582: train Epoch: [39][ 23/193]	Time  0.565 ( 6.373)	Data  0.001 ( 5.804)	Loss 6.4240e-02 (8.7493e-02) 
2023-05-27 16:07:11.455492: train Epoch: [39][ 24/193]	Time 10.804 ( 6.551)	Data 10.237 ( 5.981)	Loss 1.2755e-01 (8.9095e-02) 
2023-05-27 16:07:12.018215: train Epoch: [39][ 25/193]	Time  0.563 ( 6.320)	Data  0.001 ( 5.751)	Loss 7.0945e-02 (8.8397e-02) 
2023-05-27 16:07:23.647319: train Epoch: [39][ 26/193]	Time 11.629 ( 6.517)	Data 11.058 ( 5.948)	Loss 1.3344e-01 (9.0065e-02) 
2023-05-27 16:07:24.209816: train Epoch: [39][ 27/193]	Time  0.562 ( 6.304)	Data  0.001 ( 5.735)	Loss 6.8037e-02 (8.9278e-02) 
2023-05-27 16:07:36.048545: train Epoch: [39][ 28/193]	Time 11.839 ( 6.495)	Data 11.273 ( 5.926)	Loss 4.7525e-02 (8.7839e-02) 
2023-05-27 16:07:36.617711: train Epoch: [39][ 29/193]	Time  0.569 ( 6.298)	Data  0.001 ( 5.729)	Loss 7.4808e-02 (8.7404e-02) 
2023-05-27 16:07:48.492041: train Epoch: [39][ 30/193]	Time 11.874 ( 6.477)	Data 11.307 ( 5.909)	Loss 8.2812e-02 (8.7256e-02) 
2023-05-27 16:07:49.059508: train Epoch: [39][ 31/193]	Time  0.567 ( 6.293)	Data  0.001 ( 5.724)	Loss 8.4491e-02 (8.7170e-02) 
2023-05-27 16:08:01.067837: train Epoch: [39][ 32/193]	Time 12.008 ( 6.466)	Data 11.438 ( 5.897)	Loss 5.5952e-02 (8.6224e-02) 
2023-05-27 16:08:01.629630: train Epoch: [39][ 33/193]	Time  0.562 ( 6.292)	Data  0.001 ( 5.724)	Loss 5.0558e-02 (8.5175e-02) 
2023-05-27 16:08:13.888173: train Epoch: [39][ 34/193]	Time 12.259 ( 6.463)	Data 11.684 ( 5.894)	Loss 6.1595e-02 (8.4501e-02) 
2023-05-27 16:08:14.449673: train Epoch: [39][ 35/193]	Time  0.561 ( 6.299)	Data  0.001 ( 5.730)	Loss 1.2273e-01 (8.5563e-02) 
2023-05-27 16:08:26.209264: train Epoch: [39][ 36/193]	Time 11.760 ( 6.446)	Data 11.196 ( 5.878)	Loss 6.7029e-02 (8.5062e-02) 
2023-05-27 16:08:26.784794: train Epoch: [39][ 37/193]	Time  0.576 ( 6.292)	Data  0.001 ( 5.723)	Loss 8.5731e-02 (8.5080e-02) 
2023-05-27 16:08:38.442180: train Epoch: [39][ 38/193]	Time 11.657 ( 6.430)	Data 11.083 ( 5.861)	Loss 1.3915e-01 (8.6466e-02) 
2023-05-27 16:08:39.015716: train Epoch: [39][ 39/193]	Time  0.574 ( 6.283)	Data  0.001 ( 5.714)	Loss 6.0275e-02 (8.5811e-02) 
2023-05-27 16:08:50.927321: train Epoch: [39][ 40/193]	Time 11.912 ( 6.420)	Data 11.347 ( 5.852)	Loss 5.6375e-02 (8.5093e-02) 
2023-05-27 16:08:51.491376: train Epoch: [39][ 41/193]	Time  0.564 ( 6.281)	Data  0.001 ( 5.712)	Loss 6.2805e-02 (8.4563e-02) 
2023-05-27 16:09:03.047628: train Epoch: [39][ 42/193]	Time 11.556 ( 6.404)	Data 10.987 ( 5.835)	Loss 4.9640e-02 (8.3750e-02) 
2023-05-27 16:09:03.614781: train Epoch: [39][ 43/193]	Time  0.567 ( 6.271)	Data  0.001 ( 5.703)	Loss 9.8022e-02 (8.4075e-02) 
2023-05-27 16:09:15.812228: train Epoch: [39][ 44/193]	Time 12.197 ( 6.403)	Data 11.633 ( 5.834)	Loss 9.9812e-02 (8.4424e-02) 
2023-05-27 16:09:16.384497: train Epoch: [39][ 45/193]	Time  0.572 ( 6.276)	Data  0.001 ( 5.708)	Loss 5.3952e-02 (8.3762e-02) 
2023-05-27 16:09:28.048181: train Epoch: [39][ 46/193]	Time 11.664 ( 6.391)	Data 11.093 ( 5.822)	Loss 2.8106e-02 (8.2578e-02) 
2023-05-27 16:09:28.610950: train Epoch: [39][ 47/193]	Time  0.563 ( 6.269)	Data  0.001 ( 5.701)	Loss 8.2980e-02 (8.2586e-02) 
2023-05-27 16:09:40.303561: train Epoch: [39][ 48/193]	Time 11.693 ( 6.380)	Data 11.106 ( 5.811)	Loss 6.8128e-02 (8.2291e-02) 
2023-05-27 16:09:40.870239: train Epoch: [39][ 49/193]	Time  0.567 ( 6.264)	Data  0.001 ( 5.695)	Loss 6.3549e-02 (8.1916e-02) 
2023-05-27 16:09:52.642134: train Epoch: [39][ 50/193]	Time 11.772 ( 6.372)	Data 11.163 ( 5.802)	Loss 8.8274e-02 (8.2041e-02) 
2023-05-27 16:09:53.213061: train Epoch: [39][ 51/193]	Time  0.571 ( 6.260)	Data  0.001 ( 5.691)	Loss 5.9465e-02 (8.1607e-02) 
2023-05-27 16:10:05.108657: train Epoch: [39][ 52/193]	Time 11.896 ( 6.366)	Data 11.290 ( 5.796)	Loss 6.5710e-02 (8.1307e-02) 
2023-05-27 16:10:05.675314: train Epoch: [39][ 53/193]	Time  0.567 ( 6.259)	Data  0.001 ( 5.689)	Loss 6.9453e-02 (8.1087e-02) 
2023-05-27 16:10:16.694604: train Epoch: [39][ 54/193]	Time 11.019 ( 6.346)	Data 10.452 ( 5.775)	Loss 7.4735e-02 (8.0972e-02) 
2023-05-27 16:10:17.272677: train Epoch: [39][ 55/193]	Time  0.578 ( 6.243)	Data  0.001 ( 5.672)	Loss 9.9228e-02 (8.1298e-02) 
2023-05-27 16:10:29.174519: train Epoch: [39][ 56/193]	Time 11.902 ( 6.342)	Data 11.325 ( 5.772)	Loss 7.0751e-02 (8.1113e-02) 
2023-05-27 16:10:29.745776: train Epoch: [39][ 57/193]	Time  0.571 ( 6.242)	Data  0.001 ( 5.672)	Loss 7.1818e-02 (8.0953e-02) 
2023-05-27 16:10:42.061296: train Epoch: [39][ 58/193]	Time 12.316 ( 6.345)	Data 11.751 ( 5.775)	Loss 4.5719e-02 (8.0355e-02) 
2023-05-27 16:10:42.631939: train Epoch: [39][ 59/193]	Time  0.571 ( 6.249)	Data  0.001 ( 5.679)	Loss 5.6598e-02 (7.9959e-02) 
2023-05-27 16:10:54.070678: train Epoch: [39][ 60/193]	Time 11.439 ( 6.334)	Data 10.869 ( 5.764)	Loss 9.7363e-02 (8.0245e-02) 
2023-05-27 16:10:54.645886: train Epoch: [39][ 61/193]	Time  0.575 ( 6.241)	Data  0.001 ( 5.671)	Loss 9.0373e-02 (8.0408e-02) 
2023-05-27 16:11:06.134441: train Epoch: [39][ 62/193]	Time 11.489 ( 6.325)	Data 10.925 ( 5.754)	Loss 3.0428e-02 (7.9615e-02) 
2023-05-27 16:11:06.709749: train Epoch: [39][ 63/193]	Time  0.575 ( 6.235)	Data  0.001 ( 5.664)	Loss 7.8111e-02 (7.9591e-02) 
2023-05-27 16:11:18.124685: train Epoch: [39][ 64/193]	Time 11.415 ( 6.314)	Data 10.853 ( 5.744)	Loss 9.8317e-02 (7.9879e-02) 
2023-05-27 16:11:18.687534: train Epoch: [39][ 65/193]	Time  0.563 ( 6.227)	Data  0.001 ( 5.657)	Loss 1.1047e-01 (8.0343e-02) 
2023-05-27 16:11:30.706672: train Epoch: [39][ 66/193]	Time 12.019 ( 6.314)	Data 11.458 ( 5.744)	Loss 7.1523e-02 (8.0211e-02) 
2023-05-27 16:11:31.268859: train Epoch: [39][ 67/193]	Time  0.562 ( 6.229)	Data  0.001 ( 5.659)	Loss 5.8465e-02 (7.9891e-02) 
2023-05-27 16:11:42.927005: train Epoch: [39][ 68/193]	Time 11.658 ( 6.308)	Data 11.080 ( 5.738)	Loss 1.1858e-01 (8.0452e-02) 
2023-05-27 16:11:43.491597: train Epoch: [39][ 69/193]	Time  0.565 ( 6.226)	Data  0.001 ( 5.656)	Loss 1.0700e-01 (8.0831e-02) 
2023-05-27 16:11:54.803692: train Epoch: [39][ 70/193]	Time 11.312 ( 6.297)	Data 10.752 ( 5.728)	Loss 1.2041e-01 (8.1389e-02) 
2023-05-27 16:11:55.364628: train Epoch: [39][ 71/193]	Time  0.561 ( 6.218)	Data  0.001 ( 5.648)	Loss 1.5700e-01 (8.2439e-02) 
2023-05-27 16:12:07.348963: train Epoch: [39][ 72/193]	Time 11.984 ( 6.297)	Data 11.416 ( 5.727)	Loss 5.4553e-02 (8.2057e-02) 
2023-05-27 16:12:07.911438: train Epoch: [39][ 73/193]	Time  0.562 ( 6.219)	Data  0.001 ( 5.650)	Loss 6.6793e-02 (8.1851e-02) 
2023-05-27 16:12:19.406973: train Epoch: [39][ 74/193]	Time 11.496 ( 6.290)	Data 10.925 ( 5.720)	Loss 5.0751e-02 (8.1436e-02) 
2023-05-27 16:12:19.978795: train Epoch: [39][ 75/193]	Time  0.572 ( 6.214)	Data  0.001 ( 5.645)	Loss 1.7398e-01 (8.2654e-02) 
2023-05-27 16:12:32.077767: train Epoch: [39][ 76/193]	Time 12.099 ( 6.291)	Data 11.518 ( 5.721)	Loss 6.0407e-02 (8.2365e-02) 
2023-05-27 16:12:32.657470: train Epoch: [39][ 77/193]	Time  0.580 ( 6.218)	Data  0.001 ( 5.648)	Loss 5.6002e-02 (8.2027e-02) 
2023-05-27 16:12:44.100033: train Epoch: [39][ 78/193]	Time 11.443 ( 6.284)	Data 10.877 ( 5.714)	Loss 5.8310e-02 (8.1727e-02) 
2023-05-27 16:12:44.669517: train Epoch: [39][ 79/193]	Time  0.569 ( 6.212)	Data  0.001 ( 5.643)	Loss 7.3119e-02 (8.1619e-02) 
2023-05-27 16:12:56.999553: train Epoch: [39][ 80/193]	Time 12.330 ( 6.288)	Data 11.760 ( 5.718)	Loss 1.1504e-01 (8.2032e-02) 
2023-05-27 16:12:57.601792: train Epoch: [39][ 81/193]	Time  0.602 ( 6.218)	Data  0.001 ( 5.648)	Loss 5.9266e-02 (8.1754e-02) 
2023-05-27 16:13:09.280292: train Epoch: [39][ 82/193]	Time 11.679 ( 6.284)	Data 11.108 ( 5.714)	Loss 1.3230e-01 (8.2363e-02) 
2023-05-27 16:13:09.855661: train Epoch: [39][ 83/193]	Time  0.575 ( 6.216)	Data  0.001 ( 5.646)	Loss 5.3956e-02 (8.2025e-02) 
2023-05-27 16:13:21.481874: train Epoch: [39][ 84/193]	Time 11.626 ( 6.280)	Data 11.046 ( 5.710)	Loss 7.9751e-02 (8.1998e-02) 
2023-05-27 16:13:22.051404: train Epoch: [39][ 85/193]	Time  0.570 ( 6.213)	Data  0.001 ( 5.643)	Loss 4.6433e-02 (8.1585e-02) 
2023-05-27 16:13:33.822808: train Epoch: [39][ 86/193]	Time 11.771 ( 6.277)	Data 11.201 ( 5.707)	Loss 8.0878e-02 (8.1576e-02) 
2023-05-27 16:13:34.399507: train Epoch: [39][ 87/193]	Time  0.577 ( 6.213)	Data  0.001 ( 5.642)	Loss 6.8999e-02 (8.1434e-02) 
2023-05-27 16:13:44.899728: train Epoch: [39][ 88/193]	Time 10.500 ( 6.261)	Data  9.932 ( 5.691)	Loss 7.7273e-02 (8.1387e-02) 
2023-05-27 16:13:45.466538: train Epoch: [39][ 89/193]	Time  0.567 ( 6.198)	Data  0.001 ( 5.627)	Loss 5.3937e-02 (8.1082e-02) 
2023-05-27 16:13:56.338903: train Epoch: [39][ 90/193]	Time 10.872 ( 6.249)	Data 10.260 ( 5.678)	Loss 5.5985e-02 (8.0806e-02) 
2023-05-27 16:13:56.907995: train Epoch: [39][ 91/193]	Time  0.569 ( 6.187)	Data  0.001 ( 5.617)	Loss 4.9330e-02 (8.0464e-02) 
2023-05-27 16:14:08.005500: train Epoch: [39][ 92/193]	Time 11.098 ( 6.240)	Data 10.530 ( 5.669)	Loss 5.9139e-02 (8.0235e-02) 
2023-05-27 16:14:08.569066: train Epoch: [39][ 93/193]	Time  0.564 ( 6.180)	Data  0.001 ( 5.609)	Loss 5.1288e-02 (7.9927e-02) 
2023-05-27 16:14:20.277088: train Epoch: [39][ 94/193]	Time 11.708 ( 6.238)	Data 11.141 ( 5.667)	Loss 6.6481e-02 (7.9785e-02) 
2023-05-27 16:14:21.079939: train Epoch: [39][ 95/193]	Time  0.803 ( 6.181)	Data  0.228 ( 5.611)	Loss 6.5487e-02 (7.9636e-02) 
2023-05-27 16:14:32.713754: train Epoch: [39][ 96/193]	Time 11.634 ( 6.237)	Data 11.072 ( 5.667)	Loss 6.7875e-02 (7.9515e-02) 
2023-05-27 16:14:33.511421: train Epoch: [39][ 97/193]	Time  0.798 ( 6.182)	Data  0.224 ( 5.611)	Loss 8.1401e-02 (7.9534e-02) 
2023-05-27 16:14:45.654325: train Epoch: [39][ 98/193]	Time 12.143 ( 6.242)	Data 11.564 ( 5.672)	Loss 1.1660e-01 (7.9909e-02) 
2023-05-27 16:14:46.221081: train Epoch: [39][ 99/193]	Time  0.567 ( 6.185)	Data  0.001 ( 5.615)	Loss 6.5436e-02 (7.9764e-02) 
2023-05-27 16:14:57.795702: train Epoch: [39][100/193]	Time 11.575 ( 6.239)	Data 11.007 ( 5.668)	Loss 7.3043e-02 (7.9697e-02) 
2023-05-27 16:14:58.384405: train Epoch: [39][101/193]	Time  0.589 ( 6.183)	Data  0.001 ( 5.613)	Loss 4.6825e-02 (7.9375e-02) 
2023-05-27 16:15:09.590265: train Epoch: [39][102/193]	Time 11.206 ( 6.232)	Data 10.644 ( 5.662)	Loss 6.0444e-02 (7.9191e-02) 
2023-05-27 16:15:10.251969: train Epoch: [39][103/193]	Time  0.662 ( 6.178)	Data  0.096 ( 5.608)	Loss 1.4896e-01 (7.9862e-02) 
2023-05-27 16:15:22.311780: train Epoch: [39][104/193]	Time 12.060 ( 6.234)	Data 11.496 ( 5.664)	Loss 1.3756e-01 (8.0412e-02) 
2023-05-27 16:15:22.889501: train Epoch: [39][105/193]	Time  0.578 ( 6.181)	Data  0.001 ( 5.611)	Loss 8.1669e-02 (8.0423e-02) 
2023-05-27 16:15:34.757179: train Epoch: [39][106/193]	Time 11.868 ( 6.234)	Data 11.299 ( 5.664)	Loss 7.0512e-02 (8.0331e-02) 
2023-05-27 16:15:35.321680: train Epoch: [39][107/193]	Time  0.564 ( 6.182)	Data  0.001 ( 5.611)	Loss 5.0818e-02 (8.0058e-02) 
2023-05-27 16:15:46.848099: train Epoch: [39][108/193]	Time 11.526 ( 6.231)	Data 10.957 ( 5.660)	Loss 1.1326e-01 (8.0362e-02) 
2023-05-27 16:15:47.414129: train Epoch: [39][109/193]	Time  0.566 ( 6.179)	Data  0.001 ( 5.609)	Loss 1.2594e-01 (8.0776e-02) 
2023-05-27 16:15:59.201252: train Epoch: [39][110/193]	Time 11.787 ( 6.230)	Data 11.225 ( 5.660)	Loss 7.1310e-02 (8.0691e-02) 
2023-05-27 16:15:59.765104: train Epoch: [39][111/193]	Time  0.564 ( 6.179)	Data  0.001 ( 5.609)	Loss 8.2258e-02 (8.0705e-02) 
2023-05-27 16:16:11.668639: train Epoch: [39][112/193]	Time 11.904 ( 6.230)	Data 11.343 ( 5.660)	Loss 1.0486e-01 (8.0919e-02) 
2023-05-27 16:16:12.237890: train Epoch: [39][113/193]	Time  0.569 ( 6.180)	Data  0.001 ( 5.610)	Loss 1.1886e-01 (8.1252e-02) 
2023-05-27 16:16:24.377659: train Epoch: [39][114/193]	Time 12.140 ( 6.232)	Data 11.559 ( 5.662)	Loss 1.0102e-01 (8.1424e-02) 
2023-05-27 16:16:24.956800: train Epoch: [39][115/193]	Time  0.579 ( 6.183)	Data  0.001 ( 5.613)	Loss 1.0836e-01 (8.1656e-02) 
2023-05-27 16:16:36.383906: train Epoch: [39][116/193]	Time 11.427 ( 6.228)	Data 10.864 ( 5.658)	Loss 5.3090e-02 (8.1412e-02) 
2023-05-27 16:16:36.957955: train Epoch: [39][117/193]	Time  0.574 ( 6.180)	Data  0.001 ( 5.610)	Loss 7.1304e-02 (8.1326e-02) 
2023-05-27 16:16:48.807324: train Epoch: [39][118/193]	Time 11.849 ( 6.228)	Data 11.275 ( 5.658)	Loss 1.0813e-01 (8.1551e-02) 
2023-05-27 16:16:49.429078: train Epoch: [39][119/193]	Time  0.622 ( 6.181)	Data  0.001 ( 5.610)	Loss 1.0411e-01 (8.1739e-02) 
2023-05-27 16:17:00.877235: train Epoch: [39][120/193]	Time 11.448 ( 6.225)	Data 10.872 ( 5.654)	Loss 1.2338e-01 (8.2083e-02) 
2023-05-27 16:17:01.467066: train Epoch: [39][121/193]	Time  0.590 ( 6.178)	Data  0.001 ( 5.608)	Loss 6.4712e-02 (8.1941e-02) 
2023-05-27 16:17:13.407737: train Epoch: [39][122/193]	Time 11.941 ( 6.225)	Data 11.344 ( 5.654)	Loss 1.4201e-01 (8.2429e-02) 
2023-05-27 16:17:13.996452: train Epoch: [39][123/193]	Time  0.589 ( 6.180)	Data  0.001 ( 5.609)	Loss 1.0431e-01 (8.2606e-02) 
2023-05-27 16:17:25.708687: train Epoch: [39][124/193]	Time 11.712 ( 6.224)	Data 11.135 ( 5.653)	Loss 7.9022e-02 (8.2577e-02) 
2023-05-27 16:17:26.716640: train Epoch: [39][125/193]	Time  1.008 ( 6.183)	Data  0.403 ( 5.611)	Loss 8.9054e-02 (8.2629e-02) 
2023-05-27 16:17:37.730122: train Epoch: [39][126/193]	Time 11.013 ( 6.221)	Data 10.413 ( 5.649)	Loss 3.0148e-01 (8.4352e-02) 
2023-05-27 16:17:38.430278: train Epoch: [39][127/193]	Time  0.700 ( 6.178)	Data  0.126 ( 5.606)	Loss 1.1439e-01 (8.4586e-02) 
2023-05-27 16:17:49.343586: train Epoch: [39][128/193]	Time 10.913 ( 6.214)	Data 10.332 ( 5.643)	Loss 7.8729e-02 (8.4541e-02) 
2023-05-27 16:17:51.160695: train Epoch: [39][129/193]	Time  1.817 ( 6.181)	Data  1.244 ( 5.609)	Loss 1.2305e-01 (8.4837e-02) 
2023-05-27 16:18:02.350787: train Epoch: [39][130/193]	Time 11.190 ( 6.219)	Data 10.614 ( 5.647)	Loss 6.8313e-02 (8.4711e-02) 
2023-05-27 16:18:03.512471: train Epoch: [39][131/193]	Time  1.162 ( 6.180)	Data  0.574 ( 5.608)	Loss 8.5530e-02 (8.4717e-02) 
2023-05-27 16:18:14.418989: train Epoch: [39][132/193]	Time 10.907 ( 6.216)	Data 10.336 ( 5.644)	Loss 6.0344e-02 (8.4534e-02) 
2023-05-27 16:18:15.588219: train Epoch: [39][133/193]	Time  1.169 ( 6.178)	Data  0.594 ( 5.606)	Loss 9.6454e-02 (8.4623e-02) 
2023-05-27 16:18:27.225041: train Epoch: [39][134/193]	Time 11.637 ( 6.219)	Data 11.074 ( 5.647)	Loss 1.1044e-01 (8.4814e-02) 
2023-05-27 16:18:27.796424: train Epoch: [39][135/193]	Time  0.571 ( 6.177)	Data  0.001 ( 5.605)	Loss 5.1824e-02 (8.4572e-02) 
2023-05-27 16:18:40.153687: train Epoch: [39][136/193]	Time 12.357 ( 6.222)	Data 11.787 ( 5.650)	Loss 1.0325e-01 (8.4708e-02) 
2023-05-27 16:18:40.801077: train Epoch: [39][137/193]	Time  0.647 ( 6.182)	Data  0.067 ( 5.610)	Loss 6.6104e-02 (8.4573e-02) 
2023-05-27 16:18:51.979592: train Epoch: [39][138/193]	Time 11.179 ( 6.218)	Data 10.617 ( 5.646)	Loss 3.8463e-02 (8.4241e-02) 
2023-05-27 16:18:53.609736: train Epoch: [39][139/193]	Time  1.630 ( 6.185)	Data  1.064 ( 5.613)	Loss 7.4949e-02 (8.4175e-02) 
2023-05-27 16:19:04.327026: train Epoch: [39][140/193]	Time 10.717 ( 6.217)	Data 10.148 ( 5.645)	Loss 1.4002e-01 (8.4571e-02) 
2023-05-27 16:19:05.786085: train Epoch: [39][141/193]	Time  1.459 ( 6.184)	Data  0.897 ( 5.612)	Loss 6.1468e-02 (8.4409e-02) 
2023-05-27 16:19:16.786178: train Epoch: [39][142/193]	Time 11.000 ( 6.217)	Data 10.438 ( 5.646)	Loss 9.6318e-02 (8.4492e-02) 
2023-05-27 16:19:18.126153: train Epoch: [39][143/193]	Time  1.340 ( 6.184)	Data  0.777 ( 5.612)	Loss 4.7113e-02 (8.4232e-02) 
2023-05-27 16:19:28.807481: train Epoch: [39][144/193]	Time 10.681 ( 6.215)	Data 10.112 ( 5.643)	Loss 1.2338e-01 (8.4502e-02) 
2023-05-27 16:19:30.804490: train Epoch: [39][145/193]	Time  1.997 ( 6.186)	Data  1.433 ( 5.614)	Loss 2.5827e-01 (8.5692e-02) 
2023-05-27 16:19:41.094540: train Epoch: [39][146/193]	Time 10.290 ( 6.214)	Data  9.728 ( 5.642)	Loss 7.0784e-02 (8.5591e-02) 
2023-05-27 16:19:43.069759: train Epoch: [39][147/193]	Time  1.975 ( 6.185)	Data  1.409 ( 5.614)	Loss 6.7404e-02 (8.5468e-02) 
2023-05-27 16:19:53.014323: train Epoch: [39][148/193]	Time  9.945 ( 6.210)	Data  9.383 ( 5.639)	Loss 7.1742e-02 (8.5376e-02) 
2023-05-27 16:19:55.683790: train Epoch: [39][149/193]	Time  2.669 ( 6.187)	Data  2.108 ( 5.615)	Loss 6.6270e-02 (8.5249e-02) 
2023-05-27 16:20:05.170844: train Epoch: [39][150/193]	Time  9.487 ( 6.208)	Data  8.925 ( 5.637)	Loss 2.1435e-01 (8.6104e-02) 
2023-05-27 16:20:07.835300: train Epoch: [39][151/193]	Time  2.664 ( 6.185)	Data  2.102 ( 5.614)	Loss 1.2470e-01 (8.6357e-02) 
2023-05-27 16:20:17.377679: train Epoch: [39][152/193]	Time  9.542 ( 6.207)	Data  8.970 ( 5.636)	Loss 1.0871e-01 (8.6504e-02) 
2023-05-27 16:20:20.294678: train Epoch: [39][153/193]	Time  2.917 ( 6.186)	Data  2.354 ( 5.615)	Loss 1.0226e-01 (8.6606e-02) 
2023-05-27 16:20:29.756985: train Epoch: [39][154/193]	Time  9.462 ( 6.207)	Data  8.894 ( 5.636)	Loss 8.0726e-02 (8.6568e-02) 
2023-05-27 16:20:32.308671: train Epoch: [39][155/193]	Time  2.552 ( 6.183)	Data  1.985 ( 5.612)	Loss 4.6560e-02 (8.6311e-02) 
2023-05-27 16:20:41.797932: train Epoch: [39][156/193]	Time  9.489 ( 6.205)	Data  8.898 ( 5.633)	Loss 5.7035e-02 (8.6125e-02) 
2023-05-27 16:20:44.550158: train Epoch: [39][157/193]	Time  2.752 ( 6.183)	Data  2.191 ( 5.611)	Loss 6.6284e-02 (8.5999e-02) 
2023-05-27 16:20:54.298746: train Epoch: [39][158/193]	Time  9.749 ( 6.205)	Data  9.133 ( 5.634)	Loss 5.8826e-02 (8.5829e-02) 
2023-05-27 16:20:56.500864: train Epoch: [39][159/193]	Time  2.202 ( 6.180)	Data  1.634 ( 5.609)	Loss 5.2408e-02 (8.5620e-02) 
2023-05-27 16:21:06.738292: train Epoch: [39][160/193]	Time 10.237 ( 6.205)	Data  9.657 ( 5.634)	Loss 3.9664e-02 (8.5334e-02) 
2023-05-27 16:21:09.076505: train Epoch: [39][161/193]	Time  2.338 ( 6.181)	Data  1.775 ( 5.610)	Loss 1.4793e-01 (8.5721e-02) 
2023-05-27 16:21:18.839499: train Epoch: [39][162/193]	Time  9.763 ( 6.203)	Data  9.198 ( 5.632)	Loss 3.9207e-02 (8.5435e-02) 
2023-05-27 16:21:21.063967: train Epoch: [39][163/193]	Time  2.224 ( 6.179)	Data  1.662 ( 5.608)	Loss 1.1878e-01 (8.5639e-02) 
2023-05-27 16:21:31.172314: train Epoch: [39][164/193]	Time 10.108 ( 6.203)	Data  9.520 ( 5.631)	Loss 7.5272e-02 (8.5576e-02) 
2023-05-27 16:21:34.147667: train Epoch: [39][165/193]	Time  2.975 ( 6.183)	Data  2.414 ( 5.612)	Loss 7.8154e-02 (8.5531e-02) 
2023-05-27 16:21:43.425599: train Epoch: [39][166/193]	Time  9.278 ( 6.202)	Data  8.708 ( 5.631)	Loss 1.2862e-01 (8.5789e-02) 
2023-05-27 16:21:46.302163: train Epoch: [39][167/193]	Time  2.877 ( 6.182)	Data  2.315 ( 5.611)	Loss 1.1255e-01 (8.5948e-02) 
2023-05-27 16:21:55.917369: train Epoch: [39][168/193]	Time  9.615 ( 6.203)	Data  9.029 ( 5.631)	Loss 1.5423e-01 (8.6352e-02) 
2023-05-27 16:21:59.129623: train Epoch: [39][169/193]	Time  3.212 ( 6.185)	Data  2.646 ( 5.614)	Loss 1.4226e-01 (8.6681e-02) 
2023-05-27 16:22:08.317783: train Epoch: [39][170/193]	Time  9.188 ( 6.202)	Data  8.625 ( 5.631)	Loss 8.1789e-02 (8.6653e-02) 
2023-05-27 16:22:11.789938: train Epoch: [39][171/193]	Time  3.472 ( 6.187)	Data  2.908 ( 5.615)	Loss 1.1840e-01 (8.6837e-02) 
2023-05-27 16:22:20.393623: train Epoch: [39][172/193]	Time  8.604 ( 6.201)	Data  8.005 ( 5.629)	Loss 7.8661e-02 (8.6790e-02) 
2023-05-27 16:22:23.560014: train Epoch: [39][173/193]	Time  3.166 ( 6.183)	Data  2.599 ( 5.612)	Loss 9.3187e-02 (8.6827e-02) 
2023-05-27 16:22:32.809134: train Epoch: [39][174/193]	Time  9.249 ( 6.201)	Data  8.676 ( 5.629)	Loss 6.0080e-02 (8.6674e-02) 
2023-05-27 16:22:36.540974: train Epoch: [39][175/193]	Time  3.732 ( 6.187)	Data  3.153 ( 5.615)	Loss 9.9038e-02 (8.6744e-02) 
2023-05-27 16:22:45.025098: train Epoch: [39][176/193]	Time  8.484 ( 6.200)	Data  7.916 ( 5.628)	Loss 1.4617e-01 (8.7080e-02) 
2023-05-27 16:22:48.949430: train Epoch: [39][177/193]	Time  3.924 ( 6.187)	Data  3.356 ( 5.615)	Loss 8.9918e-02 (8.7096e-02) 
2023-05-27 16:22:57.511078: train Epoch: [39][178/193]	Time  8.562 ( 6.200)	Data  7.960 ( 5.628)	Loss 1.3295e-01 (8.7352e-02) 
2023-05-27 16:23:01.525864: train Epoch: [39][179/193]	Time  4.015 ( 6.188)	Data  3.451 ( 5.616)	Loss 1.1549e-01 (8.7508e-02) 
2023-05-27 16:23:09.360394: train Epoch: [39][180/193]	Time  7.835 ( 6.197)	Data  7.255 ( 5.625)	Loss 6.9810e-02 (8.7411e-02) 
2023-05-27 16:23:13.403774: train Epoch: [39][181/193]	Time  4.043 ( 6.185)	Data  3.481 ( 5.614)	Loss 9.3725e-02 (8.7445e-02) 
2023-05-27 16:23:21.729139: train Epoch: [39][182/193]	Time  8.325 ( 6.197)	Data  7.759 ( 5.625)	Loss 1.6205e-01 (8.7853e-02) 
2023-05-27 16:23:25.756449: train Epoch: [39][183/193]	Time  4.027 ( 6.185)	Data  3.454 ( 5.614)	Loss 1.2019e-01 (8.8029e-02) 
2023-05-27 16:23:34.689547: train Epoch: [39][184/193]	Time  8.933 ( 6.200)	Data  8.368 ( 5.628)	Loss 1.0363e-01 (8.8113e-02) 
2023-05-27 16:23:37.839409: train Epoch: [39][185/193]	Time  3.150 ( 6.184)	Data  2.588 ( 5.612)	Loss 5.4014e-02 (8.7930e-02) 
2023-05-27 16:23:47.401991: train Epoch: [39][186/193]	Time  9.563 ( 6.202)	Data  8.999 ( 5.630)	Loss 1.3163e-01 (8.8163e-02) 
2023-05-27 16:23:50.193414: train Epoch: [39][187/193]	Time  2.791 ( 6.184)	Data  2.228 ( 5.612)	Loss 4.0262e-02 (8.7909e-02) 
2023-05-27 16:24:00.132703: train Epoch: [39][188/193]	Time  9.939 ( 6.203)	Data  9.368 ( 5.632)	Loss 1.7887e-01 (8.8390e-02) 
2023-05-27 16:24:02.789630: train Epoch: [39][189/193]	Time  2.657 ( 6.185)	Data  2.091 ( 5.613)	Loss 8.6531e-02 (8.8380e-02) 
2023-05-27 16:24:12.837425: train Epoch: [39][190/193]	Time 10.048 ( 6.205)	Data  9.462 ( 5.634)	Loss 9.0640e-02 (8.8392e-02) 
2023-05-27 16:24:15.191918: train Epoch: [39][191/193]	Time  2.355 ( 6.185)	Data  1.794 ( 5.614)	Loss 7.9642e-02 (8.8346e-02) 
2023-05-27 16:24:23.973429: train Epoch: [39][192/193]	Time  8.782 ( 6.198)	Data  8.210 ( 5.627)	Loss 1.0801e-01 (8.8448e-02) 
2023-05-27 16:24:24.141564: Train Epoch done in 1196.4514736080018 s 
2023-05-27 16:24:32.570035: val Epoch: [39][ 0/72]	Time  7.568 ( 7.568)	Data  7.393 ( 7.393)	Loss 4.7267e-02 (4.7267e-02) 
2023-05-27 16:24:32.676658: val Epoch: [39][ 1/72]	Time  0.107 ( 3.838)	Data  0.002 ( 3.697)	Loss 1.1230e-01 (7.9783e-02) 
2023-05-27 16:24:38.742217: val Epoch: [39][ 2/72]	Time  6.066 ( 4.580)	Data  5.960 ( 4.452)	Loss 6.2996e-01 (2.6318e-01) 
2023-05-27 16:24:38.847694: val Epoch: [39][ 3/72]	Time  0.105 ( 3.462)	Data  0.000 ( 3.339)	Loss 9.2862e-02 (2.2060e-01) 
2023-05-27 16:24:44.863858: val Epoch: [39][ 4/72]	Time  6.016 ( 3.973)	Data  5.911 ( 3.853)	Loss 7.6009e-02 (1.9168e-01) 
2023-05-27 16:24:44.969127: val Epoch: [39][ 5/72]	Time  0.105 ( 3.328)	Data  0.000 ( 3.211)	Loss 8.9250e-02 (1.7461e-01) 
2023-05-27 16:24:50.828528: val Epoch: [39][ 6/72]	Time  5.859 ( 3.690)	Data  5.752 ( 3.574)	Loss 5.1930e-02 (1.5708e-01) 
2023-05-27 16:24:51.033023: val Epoch: [39][ 7/72]	Time  0.204 ( 3.254)	Data  0.099 ( 3.140)	Loss 5.6584e-02 (1.4452e-01) 
2023-05-27 16:24:57.058577: val Epoch: [39][ 8/72]	Time  6.026 ( 3.562)	Data  5.915 ( 3.448)	Loss 4.9301e-02 (1.3394e-01) 
2023-05-27 16:24:57.382674: val Epoch: [39][ 9/72]	Time  0.324 ( 3.238)	Data  0.214 ( 3.125)	Loss 4.5183e-02 (1.2507e-01) 
2023-05-27 16:25:03.400287: val Epoch: [39][10/72]	Time  6.018 ( 3.491)	Data  5.907 ( 3.378)	Loss 1.0421e-01 (1.2317e-01) 
2023-05-27 16:25:04.061459: val Epoch: [39][11/72]	Time  0.661 ( 3.255)	Data  0.553 ( 3.142)	Loss 7.0775e-02 (1.1880e-01) 
2023-05-27 16:25:09.670215: val Epoch: [39][12/72]	Time  5.609 ( 3.436)	Data  5.500 ( 3.324)	Loss 4.3256e-02 (1.1299e-01) 
2023-05-27 16:25:10.293109: val Epoch: [39][13/72]	Time  0.623 ( 3.235)	Data  0.515 ( 3.123)	Loss 2.7993e-01 (1.2492e-01) 
2023-05-27 16:25:16.167611: val Epoch: [39][14/72]	Time  5.875 ( 3.411)	Data  5.769 ( 3.299)	Loss 1.3769e-01 (1.2577e-01) 
2023-05-27 16:25:16.551428: val Epoch: [39][15/72]	Time  0.384 ( 3.222)	Data  0.278 ( 3.110)	Loss 2.5085e-01 (1.3359e-01) 
2023-05-27 16:25:22.438981: val Epoch: [39][16/72]	Time  5.888 ( 3.379)	Data  5.782 ( 3.268)	Loss 3.3287e-01 (1.4531e-01) 
2023-05-27 16:25:22.732031: val Epoch: [39][17/72]	Time  0.293 ( 3.207)	Data  0.188 ( 3.097)	Loss 6.9038e-02 (1.4107e-01) 
2023-05-27 16:25:28.744848: val Epoch: [39][18/72]	Time  6.013 ( 3.355)	Data  5.907 ( 3.244)	Loss 1.8610e-01 (1.4344e-01) 
2023-05-27 16:25:29.086468: val Epoch: [39][19/72]	Time  0.342 ( 3.204)	Data  0.236 ( 3.094)	Loss 3.2649e-01 (1.5259e-01) 
2023-05-27 16:25:34.649068: val Epoch: [39][20/72]	Time  5.563 ( 3.317)	Data  5.454 ( 3.206)	Loss 5.6672e-02 (1.4803e-01) 
2023-05-27 16:25:35.095818: val Epoch: [39][21/72]	Time  0.447 ( 3.186)	Data  0.342 ( 3.076)	Loss 6.3722e-02 (1.4419e-01) 
2023-05-27 16:25:41.211010: val Epoch: [39][22/72]	Time  6.115 ( 3.313)	Data  6.010 ( 3.204)	Loss 1.0566e-01 (1.4252e-01) 
2023-05-27 16:25:41.315809: val Epoch: [39][23/72]	Time  0.105 ( 3.180)	Data  0.000 ( 3.070)	Loss 1.3930e-01 (1.4238e-01) 
2023-05-27 16:25:47.184357: val Epoch: [39][24/72]	Time  5.869 ( 3.287)	Data  5.756 ( 3.178)	Loss 1.9375e-01 (1.4444e-01) 
2023-05-27 16:25:47.445801: val Epoch: [39][25/72]	Time  0.261 ( 3.171)	Data  0.148 ( 3.061)	Loss 7.2850e-02 (1.4169e-01) 
2023-05-27 16:25:53.676155: val Epoch: [39][26/72]	Time  6.230 ( 3.284)	Data  6.120 ( 3.174)	Loss 1.0943e-01 (1.4049e-01) 
2023-05-27 16:25:53.785925: val Epoch: [39][27/72]	Time  0.110 ( 3.171)	Data  0.001 ( 3.061)	Loss 6.9550e-02 (1.3796e-01) 
2023-05-27 16:25:59.601969: val Epoch: [39][28/72]	Time  5.816 ( 3.262)	Data  5.708 ( 3.152)	Loss 7.6416e-02 (1.3584e-01) 
2023-05-27 16:25:59.839437: val Epoch: [39][29/72]	Time  0.237 ( 3.161)	Data  0.129 ( 3.052)	Loss 4.1593e-01 (1.4517e-01) 
2023-05-27 16:26:05.459609: val Epoch: [39][30/72]	Time  5.620 ( 3.241)	Data  5.512 ( 3.131)	Loss 4.7275e-02 (1.4201e-01) 
2023-05-27 16:26:06.190457: val Epoch: [39][31/72]	Time  0.731 ( 3.162)	Data  0.623 ( 3.053)	Loss 3.8135e-01 (1.4949e-01) 
2023-05-27 16:26:11.676799: val Epoch: [39][32/72]	Time  5.486 ( 3.233)	Data  5.379 ( 3.123)	Loss 2.4472e-01 (1.5238e-01) 
2023-05-27 16:26:12.605836: val Epoch: [39][33/72]	Time  0.929 ( 3.165)	Data  0.824 ( 3.055)	Loss 1.1434e-01 (1.5126e-01) 
2023-05-27 16:26:18.052904: val Epoch: [39][34/72]	Time  5.447 ( 3.230)	Data  5.339 ( 3.121)	Loss 1.2801e-01 (1.5060e-01) 
2023-05-27 16:26:19.045026: val Epoch: [39][35/72]	Time  0.992 ( 3.168)	Data  0.887 ( 3.059)	Loss 1.3780e-01 (1.5024e-01) 
2023-05-27 16:26:24.368005: val Epoch: [39][36/72]	Time  5.323 ( 3.226)	Data  5.218 ( 3.117)	Loss 1.1677e-01 (1.4934e-01) 
2023-05-27 16:26:25.221984: val Epoch: [39][37/72]	Time  0.854 ( 3.164)	Data  0.738 ( 3.054)	Loss 2.5246e-01 (1.5205e-01) 
2023-05-27 16:26:30.373495: val Epoch: [39][38/72]	Time  5.151 ( 3.215)	Data  5.040 ( 3.105)	Loss 5.1618e-02 (1.4947e-01) 
2023-05-27 16:26:31.245149: val Epoch: [39][39/72]	Time  0.872 ( 3.156)	Data  0.766 ( 3.047)	Loss 4.0541e-02 (1.4675e-01) 
2023-05-27 16:26:36.389712: val Epoch: [39][40/72]	Time  5.145 ( 3.205)	Data  5.039 ( 3.095)	Loss 8.9613e-02 (1.4536e-01) 
2023-05-27 16:26:37.428278: val Epoch: [39][41/72]	Time  1.039 ( 3.153)	Data  0.933 ( 3.044)	Loss 7.3973e-02 (1.4366e-01) 
2023-05-27 16:26:42.543902: val Epoch: [39][42/72]	Time  5.116 ( 3.199)	Data  5.010 ( 3.090)	Loss 4.7199e-02 (1.4141e-01) 
2023-05-27 16:26:43.804247: val Epoch: [39][43/72]	Time  1.260 ( 3.155)	Data  1.155 ( 3.046)	Loss 2.7733e-01 (1.4450e-01) 
2023-05-27 16:26:48.632293: val Epoch: [39][44/72]	Time  4.828 ( 3.192)	Data  4.722 ( 3.083)	Loss 7.1720e-02 (1.4289e-01) 
2023-05-27 16:26:49.817506: val Epoch: [39][45/72]	Time  1.185 ( 3.148)	Data  1.076 ( 3.039)	Loss 6.0486e-02 (1.4109e-01) 
2023-05-27 16:26:54.141014: val Epoch: [39][46/72]	Time  4.324 ( 3.173)	Data  4.218 ( 3.064)	Loss 8.4514e-02 (1.3989e-01) 
2023-05-27 16:26:55.959883: val Epoch: [39][47/72]	Time  1.819 ( 3.145)	Data  1.713 ( 3.036)	Loss 2.2480e-01 (1.4166e-01) 
2023-05-27 16:27:00.064451: val Epoch: [39][48/72]	Time  4.105 ( 3.165)	Data  3.996 ( 3.056)	Loss 8.3747e-02 (1.4048e-01) 
2023-05-27 16:27:02.197698: val Epoch: [39][49/72]	Time  2.133 ( 3.144)	Data  2.025 ( 3.035)	Loss 1.1710e-01 (1.4001e-01) 
2023-05-27 16:27:06.503572: val Epoch: [39][50/72]	Time  4.306 ( 3.167)	Data  4.190 ( 3.058)	Loss 5.3425e-02 (1.3831e-01) 
2023-05-27 16:27:08.654503: val Epoch: [39][51/72]	Time  2.151 ( 3.147)	Data  2.046 ( 3.038)	Loss 1.6921e-01 (1.3891e-01) 
2023-05-27 16:27:12.440485: val Epoch: [39][52/72]	Time  3.786 ( 3.159)	Data  3.676 ( 3.050)	Loss 6.3693e-02 (1.3749e-01) 
2023-05-27 16:27:14.677645: val Epoch: [39][53/72]	Time  2.237 ( 3.142)	Data  2.120 ( 3.033)	Loss 5.2499e-02 (1.3591e-01) 
2023-05-27 16:27:18.326845: val Epoch: [39][54/72]	Time  3.649 ( 3.151)	Data  3.537 ( 3.042)	Loss 5.5723e-02 (1.3446e-01) 
2023-05-27 16:27:21.429979: val Epoch: [39][55/72]	Time  3.103 ( 3.151)	Data  2.994 ( 3.041)	Loss 6.4543e-02 (1.3321e-01) 
2023-05-27 16:27:24.816243: val Epoch: [39][56/72]	Time  3.386 ( 3.155)	Data  3.273 ( 3.046)	Loss 6.0049e-02 (1.3192e-01) 
2023-05-27 16:27:27.433308: val Epoch: [39][57/72]	Time  2.617 ( 3.145)	Data  2.505 ( 3.036)	Loss 1.4191e-01 (1.3210e-01) 
2023-05-27 16:27:31.444100: val Epoch: [39][58/72]	Time  4.011 ( 3.160)	Data  3.906 ( 3.051)	Loss 1.0813e-01 (1.3169e-01) 
2023-05-27 16:27:33.658669: val Epoch: [39][59/72]	Time  2.215 ( 3.144)	Data  2.109 ( 3.035)	Loss 4.5696e-01 (1.3711e-01) 
2023-05-27 16:27:37.860451: val Epoch: [39][60/72]	Time  4.202 ( 3.162)	Data  4.095 ( 3.053)	Loss 5.7073e-02 (1.3580e-01) 
2023-05-27 16:27:40.037004: val Epoch: [39][61/72]	Time  2.177 ( 3.146)	Data  2.069 ( 3.037)	Loss 5.8030e-02 (1.3454e-01) 
2023-05-27 16:27:44.537237: val Epoch: [39][62/72]	Time  4.500 ( 3.167)	Data  4.384 ( 3.058)	Loss 1.2179e-01 (1.3434e-01) 
2023-05-27 16:27:46.181002: val Epoch: [39][63/72]	Time  1.644 ( 3.143)	Data  1.536 ( 3.034)	Loss 1.9928e-01 (1.3536e-01) 
2023-05-27 16:27:50.574476: val Epoch: [39][64/72]	Time  4.393 ( 3.163)	Data  4.288 ( 3.054)	Loss 7.6269e-02 (1.3445e-01) 
2023-05-27 16:27:52.122728: val Epoch: [39][65/72]	Time  1.548 ( 3.138)	Data  1.439 ( 3.029)	Loss 6.0066e-02 (1.3332e-01) 
2023-05-27 16:27:56.828040: val Epoch: [39][66/72]	Time  4.705 ( 3.162)	Data  4.597 ( 3.053)	Loss 1.4023e-01 (1.3342e-01) 
2023-05-27 16:27:58.328429: val Epoch: [39][67/72]	Time  1.500 ( 3.137)	Data  1.395 ( 3.028)	Loss 6.4785e-02 (1.3241e-01) 
2023-05-27 16:28:03.324225: val Epoch: [39][68/72]	Time  4.996 ( 3.164)	Data  4.867 ( 3.055)	Loss 4.8784e-01 (1.3757e-01) 
2023-05-27 16:28:04.831458: val Epoch: [39][69/72]	Time  1.507 ( 3.140)	Data  1.390 ( 3.031)	Loss 1.4456e-01 (1.3767e-01) 
2023-05-27 16:28:09.296375: val Epoch: [39][70/72]	Time  4.465 ( 3.159)	Data  4.341 ( 3.050)	Loss 4.2941e-02 (1.3633e-01) 
2023-05-27 16:28:10.985238: val Epoch: [39][71/72]	Time  1.689 ( 3.139)	Data  1.582 ( 3.029)	Loss 5.6138e-02 (1.3522e-01) 
2023-05-27 16:28:11.364206: Epoch 39 :Val : ['ET : 0.7324126362800598', 'TC : 0.7770781517028809', 'WT : 0.8505556583404541'] 
2023-05-27 16:28:11.367262: Epoch 39 :Val : ['ET : 0.7324126362800598', 'TC : 0.7770781517028809', 'WT : 0.8505556583404541'] 
2023-05-27 16:28:11.369435: Val epoch done in 227.22787667100783 s 
2023-05-27 16:28:11.376526: Batches per epoch:  193 
2023-05-27 16:28:25.948840: train Epoch: [40][  0/193]	Time 14.572 (14.572)	Data 13.937 (13.937)	Loss 6.9323e-02 (6.9323e-02) 
2023-05-27 16:28:26.518579: train Epoch: [40][  1/193]	Time  0.570 ( 7.571)	Data  0.001 ( 6.969)	Loss 1.2766e-01 (9.8492e-02) 
2023-05-27 16:28:38.462208: train Epoch: [40][  2/193]	Time 11.944 ( 9.028)	Data 11.377 ( 8.438)	Loss 1.0760e-01 (1.0153e-01) 
2023-05-27 16:28:39.025944: train Epoch: [40][  3/193]	Time  0.564 ( 6.912)	Data  0.001 ( 6.329)	Loss 7.2126e-02 (9.4177e-02) 
2023-05-27 16:28:51.080511: train Epoch: [40][  4/193]	Time 12.055 ( 7.941)	Data 11.475 ( 7.358)	Loss 1.2914e-01 (1.0117e-01) 
2023-05-27 16:28:51.642950: train Epoch: [40][  5/193]	Time  0.562 ( 6.711)	Data  0.001 ( 6.132)	Loss 1.0589e-01 (1.0196e-01) 
2023-05-27 16:29:03.600532: train Epoch: [40][  6/193]	Time 11.958 ( 7.461)	Data 11.389 ( 6.883)	Loss 9.8927e-02 (1.0152e-01) 
2023-05-27 16:29:04.163568: train Epoch: [40][  7/193]	Time  0.563 ( 6.598)	Data  0.001 ( 6.023)	Loss 7.1136e-02 (9.7726e-02) 
2023-05-27 16:29:16.032113: train Epoch: [40][  8/193]	Time 11.869 ( 7.184)	Data 11.296 ( 6.609)	Loss 1.4259e-01 (1.0271e-01) 
2023-05-27 16:29:16.600957: train Epoch: [40][  9/193]	Time  0.569 ( 6.522)	Data  0.001 ( 5.948)	Loss 2.0212e-01 (1.1265e-01) 
2023-05-27 16:29:28.908976: train Epoch: [40][ 10/193]	Time 12.308 ( 7.048)	Data 11.740 ( 6.474)	Loss 7.9520e-02 (1.0964e-01) 
2023-05-27 16:29:29.475671: train Epoch: [40][ 11/193]	Time  0.567 ( 6.508)	Data  0.001 ( 5.935)	Loss 9.3648e-02 (1.0831e-01) 
2023-05-27 16:29:41.721091: train Epoch: [40][ 12/193]	Time 12.245 ( 6.950)	Data 11.676 ( 6.376)	Loss 1.3384e-01 (1.1027e-01) 
2023-05-27 16:29:42.292200: train Epoch: [40][ 13/193]	Time  0.571 ( 6.494)	Data  0.001 ( 5.921)	Loss 6.7227e-02 (1.0720e-01) 
2023-05-27 16:29:53.984783: train Epoch: [40][ 14/193]	Time 11.693 ( 6.841)	Data 11.123 ( 6.268)	Loss 5.9651e-02 (1.0403e-01) 
2023-05-27 16:29:54.550208: train Epoch: [40][ 15/193]	Time  0.565 ( 6.448)	Data  0.001 ( 5.876)	Loss 6.7453e-02 (1.0174e-01) 
2023-05-27 16:30:06.288328: train Epoch: [40][ 16/193]	Time 11.738 ( 6.759)	Data 11.169 ( 6.188)	Loss 3.8009e-02 (9.7992e-02) 
2023-05-27 16:30:06.855815: train Epoch: [40][ 17/193]	Time  0.567 ( 6.415)	Data  0.001 ( 5.844)	Loss 4.7776e-02 (9.5203e-02) 
2023-05-27 16:30:17.738616: train Epoch: [40][ 18/193]	Time 10.883 ( 6.651)	Data 10.317 ( 6.079)	Loss 6.4275e-02 (9.3575e-02) 
2023-05-27 16:30:18.305244: train Epoch: [40][ 19/193]	Time  0.567 ( 6.346)	Data  0.001 ( 5.775)	Loss 1.1550e-01 (9.4671e-02) 
2023-05-27 16:30:29.559614: train Epoch: [40][ 20/193]	Time 11.254 ( 6.580)	Data 10.678 ( 6.009)	Loss 1.5270e-01 (9.7435e-02) 
2023-05-27 16:30:30.124426: train Epoch: [40][ 21/193]	Time  0.565 ( 6.307)	Data  0.001 ( 5.736)	Loss 8.9427e-02 (9.7071e-02) 
2023-05-27 16:30:41.969513: train Epoch: [40][ 22/193]	Time 11.845 ( 6.548)	Data 11.243 ( 5.975)	Loss 9.2331e-02 (9.6865e-02) 
2023-05-27 16:30:42.536374: train Epoch: [40][ 23/193]	Time  0.567 ( 6.298)	Data  0.001 ( 5.726)	Loss 1.0417e-01 (9.7169e-02) 
2023-05-27 16:30:53.339198: train Epoch: [40][ 24/193]	Time 10.803 ( 6.478)	Data 10.241 ( 5.907)	Loss 7.0766e-02 (9.6113e-02) 
2023-05-27 16:30:53.903168: train Epoch: [40][ 25/193]	Time  0.564 ( 6.251)	Data  0.001 ( 5.680)	Loss 5.6115e-02 (9.4574e-02) 
2023-05-27 16:31:05.264673: train Epoch: [40][ 26/193]	Time 11.362 ( 6.440)	Data 10.795 ( 5.869)	Loss 7.6522e-02 (9.3906e-02) 
2023-05-27 16:31:05.831982: train Epoch: [40][ 27/193]	Time  0.567 ( 6.231)	Data  0.001 ( 5.660)	Loss 4.9426e-02 (9.2317e-02) 
2023-05-27 16:31:17.247901: train Epoch: [40][ 28/193]	Time 11.416 ( 6.409)	Data 10.839 ( 5.838)	Loss 9.5263e-02 (9.2419e-02) 
2023-05-27 16:31:17.815547: train Epoch: [40][ 29/193]	Time  0.568 ( 6.215)	Data  0.001 ( 5.644)	Loss 5.4098e-02 (9.1141e-02) 
2023-05-27 16:31:30.154797: train Epoch: [40][ 30/193]	Time 12.339 ( 6.412)	Data 11.770 ( 5.841)	Loss 8.6294e-02 (9.0985e-02) 
2023-05-27 16:31:30.717667: train Epoch: [40][ 31/193]	Time  0.563 ( 6.229)	Data  0.001 ( 5.659)	Loss 5.1721e-02 (8.9758e-02) 
2023-05-27 16:31:42.806162: train Epoch: [40][ 32/193]	Time 12.088 ( 6.407)	Data 11.525 ( 5.836)	Loss 1.0435e-01 (9.0200e-02) 
2023-05-27 16:31:43.381713: train Epoch: [40][ 33/193]	Time  0.576 ( 6.235)	Data  0.001 ( 5.665)	Loss 5.9150e-02 (8.9287e-02) 
2023-05-27 16:31:54.865844: train Epoch: [40][ 34/193]	Time 11.484 ( 6.385)	Data 10.875 ( 5.814)	Loss 9.1716e-02 (8.9356e-02) 
2023-05-27 16:31:55.428162: train Epoch: [40][ 35/193]	Time  0.562 ( 6.224)	Data  0.001 ( 5.652)	Loss 7.3416e-02 (8.8914e-02) 
2023-05-27 16:32:07.266178: train Epoch: [40][ 36/193]	Time 11.838 ( 6.375)	Data 11.269 ( 5.804)	Loss 1.2120e-01 (8.9786e-02) 
2023-05-27 16:32:07.828230: train Epoch: [40][ 37/193]	Time  0.562 ( 6.222)	Data  0.001 ( 5.651)	Loss 7.7877e-02 (8.9473e-02) 
2023-05-27 16:32:19.749716: train Epoch: [40][ 38/193]	Time 11.921 ( 6.369)	Data 11.360 ( 5.798)	Loss 8.7975e-02 (8.9435e-02) 
2023-05-27 16:32:20.314387: train Epoch: [40][ 39/193]	Time  0.565 ( 6.223)	Data  0.001 ( 5.653)	Loss 5.4634e-02 (8.8564e-02) 
2023-05-27 16:32:32.269527: train Epoch: [40][ 40/193]	Time 11.955 ( 6.363)	Data 11.390 ( 5.793)	Loss 9.2182e-02 (8.8653e-02) 
2023-05-27 16:32:32.843931: train Epoch: [40][ 41/193]	Time  0.574 ( 6.225)	Data  0.001 ( 5.655)	Loss 1.1536e-01 (8.9289e-02) 
2023-05-27 16:32:44.912642: train Epoch: [40][ 42/193]	Time 12.069 ( 6.361)	Data 11.503 ( 5.791)	Loss 1.0748e-01 (8.9712e-02) 
2023-05-27 16:32:45.476204: train Epoch: [40][ 43/193]	Time  0.564 ( 6.230)	Data  0.001 ( 5.659)	Loss 6.9794e-02 (8.9259e-02) 
2023-05-27 16:32:56.933815: train Epoch: [40][ 44/193]	Time 11.458 ( 6.346)	Data 10.891 ( 5.775)	Loss 2.6267e-01 (9.3113e-02) 
2023-05-27 16:32:57.496017: train Epoch: [40][ 45/193]	Time  0.562 ( 6.220)	Data  0.001 ( 5.650)	Loss 3.3608e-02 (9.1819e-02) 
2023-05-27 16:33:09.571235: train Epoch: [40][ 46/193]	Time 12.075 ( 6.345)	Data 11.513 ( 5.775)	Loss 1.3078e-01 (9.2648e-02) 
2023-05-27 16:33:10.135736: train Epoch: [40][ 47/193]	Time  0.564 ( 6.224)	Data  0.001 ( 5.654)	Loss 7.6175e-02 (9.2305e-02) 
2023-05-27 16:33:22.199783: train Epoch: [40][ 48/193]	Time 12.064 ( 6.343)	Data 11.502 ( 5.774)	Loss 8.1292e-02 (9.2080e-02) 
2023-05-27 16:33:22.765181: train Epoch: [40][ 49/193]	Time  0.565 ( 6.228)	Data  0.001 ( 5.658)	Loss 1.0037e-01 (9.2246e-02) 
2023-05-27 16:33:34.942253: train Epoch: [40][ 50/193]	Time 12.177 ( 6.344)	Data 11.604 ( 5.775)	Loss 8.2338e-02 (9.2052e-02) 
2023-05-27 16:33:35.515341: train Epoch: [40][ 51/193]	Time  0.573 ( 6.233)	Data  0.001 ( 5.664)	Loss 5.3268e-02 (9.1306e-02) 
2023-05-27 16:33:47.498323: train Epoch: [40][ 52/193]	Time 11.983 ( 6.342)	Data 11.410 ( 5.772)	Loss 1.6414e-01 (9.2680e-02) 
2023-05-27 16:33:48.074810: train Epoch: [40][ 53/193]	Time  0.576 ( 6.235)	Data  0.001 ( 5.665)	Loss 5.2912e-02 (9.1944e-02) 
2023-05-27 16:34:00.047029: train Epoch: [40][ 54/193]	Time 11.972 ( 6.339)	Data 11.410 ( 5.770)	Loss 1.3944e-01 (9.2807e-02) 
2023-05-27 16:34:00.609935: train Epoch: [40][ 55/193]	Time  0.563 ( 6.236)	Data  0.001 ( 5.667)	Loss 7.9463e-02 (9.2569e-02) 
2023-05-27 16:34:11.662645: train Epoch: [40][ 56/193]	Time 11.053 ( 6.321)	Data 10.479 ( 5.751)	Loss 9.8156e-02 (9.2667e-02) 
2023-05-27 16:34:12.235345: train Epoch: [40][ 57/193]	Time  0.573 ( 6.222)	Data  0.001 ( 5.652)	Loss 6.3241e-02 (9.2159e-02) 
2023-05-27 16:34:24.538023: train Epoch: [40][ 58/193]	Time 12.303 ( 6.325)	Data 11.731 ( 5.755)	Loss 6.2374e-02 (9.1655e-02) 
2023-05-27 16:34:25.104630: train Epoch: [40][ 59/193]	Time  0.567 ( 6.229)	Data  0.001 ( 5.659)	Loss 1.1178e-01 (9.1990e-02) 
2023-05-27 16:34:37.008935: train Epoch: [40][ 60/193]	Time 11.904 ( 6.322)	Data 11.342 ( 5.752)	Loss 7.9162e-02 (9.1780e-02) 
2023-05-27 16:34:37.573468: train Epoch: [40][ 61/193]	Time  0.565 ( 6.229)	Data  0.001 ( 5.660)	Loss 2.3564e-01 (9.4100e-02) 
2023-05-27 16:34:48.750929: train Epoch: [40][ 62/193]	Time 11.177 ( 6.308)	Data 10.610 ( 5.738)	Loss 7.3234e-02 (9.3769e-02) 
2023-05-27 16:34:49.315191: train Epoch: [40][ 63/193]	Time  0.564 ( 6.218)	Data  0.001 ( 5.649)	Loss 1.6341e-01 (9.4857e-02) 
2023-05-27 16:35:01.446718: train Epoch: [40][ 64/193]	Time 12.132 ( 6.309)	Data 11.552 ( 5.739)	Loss 9.8780e-02 (9.4917e-02) 
2023-05-27 16:35:02.011508: train Epoch: [40][ 65/193]	Time  0.565 ( 6.222)	Data  0.001 ( 5.652)	Loss 9.1408e-02 (9.4864e-02) 
2023-05-27 16:35:14.190355: train Epoch: [40][ 66/193]	Time 12.179 ( 6.311)	Data 11.616 ( 5.741)	Loss 6.8187e-02 (9.4466e-02) 
2023-05-27 16:35:14.752637: train Epoch: [40][ 67/193]	Time  0.562 ( 6.226)	Data  0.001 ( 5.657)	Loss 1.4197e-01 (9.5165e-02) 
2023-05-27 16:35:27.166463: train Epoch: [40][ 68/193]	Time 12.414 ( 6.316)	Data 11.852 ( 5.747)	Loss 8.4555e-02 (9.5011e-02) 
2023-05-27 16:35:27.728635: train Epoch: [40][ 69/193]	Time  0.562 ( 6.234)	Data  0.001 ( 5.665)	Loss 1.3898e-01 (9.5639e-02) 
2023-05-27 16:35:39.442994: train Epoch: [40][ 70/193]	Time 11.714 ( 6.311)	Data 11.152 ( 5.742)	Loss 1.1806e-01 (9.5955e-02) 
2023-05-27 16:35:40.006495: train Epoch: [40][ 71/193]	Time  0.564 ( 6.231)	Data  0.001 ( 5.662)	Loss 1.8162e-01 (9.7145e-02) 
2023-05-27 16:35:51.735635: train Epoch: [40][ 72/193]	Time 11.729 ( 6.306)	Data 11.156 ( 5.737)	Loss 4.1592e-02 (9.6384e-02) 
2023-05-27 16:35:52.298370: train Epoch: [40][ 73/193]	Time  0.563 ( 6.229)	Data  0.001 ( 5.660)	Loss 7.2024e-02 (9.6054e-02) 
2023-05-27 16:36:04.136425: train Epoch: [40][ 74/193]	Time 11.838 ( 6.303)	Data 11.277 ( 5.735)	Loss 7.3273e-02 (9.5751e-02) 
2023-05-27 16:36:04.697732: train Epoch: [40][ 75/193]	Time  0.561 ( 6.228)	Data  0.001 ( 5.659)	Loss 6.5715e-02 (9.5355e-02) 
2023-05-27 16:36:16.525613: train Epoch: [40][ 76/193]	Time 11.828 ( 6.301)	Data 11.266 ( 5.732)	Loss 1.3102e-01 (9.5819e-02) 
2023-05-27 16:36:17.088501: train Epoch: [40][ 77/193]	Time  0.563 ( 6.227)	Data  0.001 ( 5.659)	Loss 8.0483e-02 (9.5622e-02) 
2023-05-27 16:36:29.193851: train Epoch: [40][ 78/193]	Time 12.105 ( 6.301)	Data 11.544 ( 5.733)	Loss 7.0153e-02 (9.5300e-02) 
2023-05-27 16:36:29.761743: train Epoch: [40][ 79/193]	Time  0.568 ( 6.230)	Data  0.001 ( 5.662)	Loss 6.1543e-02 (9.4878e-02) 
2023-05-27 16:36:41.385582: train Epoch: [40][ 80/193]	Time 11.624 ( 6.296)	Data 11.051 ( 5.728)	Loss 8.2348e-02 (9.4723e-02) 
2023-05-27 16:36:41.953073: train Epoch: [40][ 81/193]	Time  0.567 ( 6.227)	Data  0.001 ( 5.658)	Loss 1.0862e-01 (9.4893e-02) 
2023-05-27 16:36:53.881530: train Epoch: [40][ 82/193]	Time 11.928 ( 6.295)	Data 11.366 ( 5.727)	Loss 7.3265e-02 (9.4632e-02) 
2023-05-27 16:36:54.452813: train Epoch: [40][ 83/193]	Time  0.571 ( 6.227)	Data  0.001 ( 5.659)	Loss 6.8713e-02 (9.4323e-02) 
2023-05-27 16:37:05.662993: train Epoch: [40][ 84/193]	Time 11.210 ( 6.286)	Data 10.648 ( 5.718)	Loss 5.7722e-02 (9.3893e-02) 
2023-05-27 16:37:06.226564: train Epoch: [40][ 85/193]	Time  0.564 ( 6.219)	Data  0.001 ( 5.651)	Loss 2.6168e-01 (9.5844e-02) 
2023-05-27 16:37:17.676982: train Epoch: [40][ 86/193]	Time 11.450 ( 6.279)	Data 10.887 ( 5.711)	Loss 4.1464e-02 (9.5219e-02) 
2023-05-27 16:37:18.240305: train Epoch: [40][ 87/193]	Time  0.563 ( 6.214)	Data  0.001 ( 5.646)	Loss 6.7681e-02 (9.4906e-02) 
2023-05-27 16:37:30.234098: train Epoch: [40][ 88/193]	Time 11.994 ( 6.279)	Data 11.419 ( 5.711)	Loss 7.7224e-02 (9.4707e-02) 
2023-05-27 16:37:30.796783: train Epoch: [40][ 89/193]	Time  0.563 ( 6.216)	Data  0.001 ( 5.648)	Loss 7.0278e-02 (9.4436e-02) 
2023-05-27 16:37:41.869112: train Epoch: [40][ 90/193]	Time 11.072 ( 6.269)	Data 10.510 ( 5.701)	Loss 1.2983e-01 (9.4825e-02) 
2023-05-27 16:37:42.432448: train Epoch: [40][ 91/193]	Time  0.563 ( 6.207)	Data  0.001 ( 5.639)	Loss 2.1708e-01 (9.6154e-02) 
2023-05-27 16:37:54.034147: train Epoch: [40][ 92/193]	Time 11.602 ( 6.265)	Data 11.039 ( 5.697)	Loss 7.1453e-02 (9.5888e-02) 
2023-05-27 16:37:54.598544: train Epoch: [40][ 93/193]	Time  0.564 ( 6.204)	Data  0.001 ( 5.637)	Loss 6.1618e-02 (9.5523e-02) 
2023-05-27 16:38:06.445793: train Epoch: [40][ 94/193]	Time 11.847 ( 6.264)	Data 11.286 ( 5.696)	Loss 1.1390e-01 (9.5717e-02) 
2023-05-27 16:38:07.011014: train Epoch: [40][ 95/193]	Time  0.565 ( 6.205)	Data  0.001 ( 5.637)	Loss 6.6927e-02 (9.5417e-02) 
2023-05-27 16:38:19.139110: train Epoch: [40][ 96/193]	Time 12.128 ( 6.266)	Data 11.557 ( 5.698)	Loss 6.6874e-02 (9.5123e-02) 
2023-05-27 16:38:19.726726: train Epoch: [40][ 97/193]	Time  0.588 ( 6.208)	Data  0.001 ( 5.640)	Loss 8.6974e-02 (9.5039e-02) 
2023-05-27 16:38:30.946741: train Epoch: [40][ 98/193]	Time 11.220 ( 6.258)	Data 10.658 ( 5.690)	Loss 7.6946e-02 (9.4857e-02) 
2023-05-27 16:38:31.511481: train Epoch: [40][ 99/193]	Time  0.565 ( 6.201)	Data  0.001 ( 5.634)	Loss 5.0273e-02 (9.4411e-02) 
2023-05-27 16:38:43.631948: train Epoch: [40][100/193]	Time 12.120 ( 6.260)	Data 11.559 ( 5.692)	Loss 1.7839e-01 (9.5242e-02) 
2023-05-27 16:38:44.209628: train Epoch: [40][101/193]	Time  0.578 ( 6.204)	Data  0.001 ( 5.636)	Loss 9.9314e-02 (9.5282e-02) 
2023-05-27 16:38:55.647160: train Epoch: [40][102/193]	Time 11.438 ( 6.255)	Data 10.858 ( 5.687)	Loss 1.3813e-01 (9.5698e-02) 
2023-05-27 16:38:56.215504: train Epoch: [40][103/193]	Time  0.568 ( 6.200)	Data  0.001 ( 5.632)	Loss 6.5676e-02 (9.5410e-02) 
2023-05-27 16:39:08.409826: train Epoch: [40][104/193]	Time 12.194 ( 6.257)	Data 11.630 ( 5.690)	Loss 1.3534e-01 (9.5790e-02) 
2023-05-27 16:39:08.987707: train Epoch: [40][105/193]	Time  0.578 ( 6.204)	Data  0.001 ( 5.636)	Loss 1.0607e-01 (9.5887e-02) 
2023-05-27 16:39:20.941929: train Epoch: [40][106/193]	Time 11.954 ( 6.258)	Data 11.366 ( 5.689)	Loss 7.4826e-02 (9.5690e-02) 
2023-05-27 16:39:21.506916: train Epoch: [40][107/193]	Time  0.565 ( 6.205)	Data  0.001 ( 5.637)	Loss 1.1698e-01 (9.5887e-02) 
2023-05-27 16:39:33.354578: train Epoch: [40][108/193]	Time 11.848 ( 6.257)	Data 11.231 ( 5.688)	Loss 6.1352e-02 (9.5570e-02) 
2023-05-27 16:39:33.919969: train Epoch: [40][109/193]	Time  0.565 ( 6.205)	Data  0.001 ( 5.636)	Loss 1.1140e-01 (9.5714e-02) 
2023-05-27 16:39:46.010337: train Epoch: [40][110/193]	Time 12.090 ( 6.258)	Data 11.509 ( 5.689)	Loss 7.7151e-02 (9.5547e-02) 
2023-05-27 16:39:46.605377: train Epoch: [40][111/193]	Time  0.595 ( 6.207)	Data  0.001 ( 5.638)	Loss 8.9622e-02 (9.5494e-02) 
2023-05-27 16:39:58.151694: train Epoch: [40][112/193]	Time 11.546 ( 6.255)	Data 10.955 ( 5.686)	Loss 1.4903e-01 (9.5968e-02) 
2023-05-27 16:39:58.729435: train Epoch: [40][113/193]	Time  0.578 ( 6.205)	Data  0.001 ( 5.636)	Loss 1.3365e-01 (9.6298e-02) 
2023-05-27 16:40:10.178926: train Epoch: [40][114/193]	Time 11.449 ( 6.250)	Data 10.874 ( 5.681)	Loss 9.7914e-02 (9.6312e-02) 
2023-05-27 16:40:10.759320: train Epoch: [40][115/193]	Time  0.580 ( 6.202)	Data  0.001 ( 5.632)	Loss 8.4075e-02 (9.6207e-02) 
2023-05-27 16:40:22.534224: train Epoch: [40][116/193]	Time 11.775 ( 6.249)	Data 11.207 ( 5.680)	Loss 1.4075e-01 (9.6588e-02) 
2023-05-27 16:40:23.102885: train Epoch: [40][117/193]	Time  0.569 ( 6.201)	Data  0.001 ( 5.632)	Loss 1.0318e-01 (9.6643e-02) 
2023-05-27 16:40:34.535689: train Epoch: [40][118/193]	Time 11.433 ( 6.245)	Data 10.860 ( 5.676)	Loss 2.6187e-01 (9.8032e-02) 
2023-05-27 16:40:35.103657: train Epoch: [40][119/193]	Time  0.568 ( 6.198)	Data  0.001 ( 5.628)	Loss 1.1974e-01 (9.8213e-02) 
2023-05-27 16:40:46.921027: train Epoch: [40][120/193]	Time 11.817 ( 6.244)	Data 11.255 ( 5.675)	Loss 1.0324e-01 (9.8254e-02) 
2023-05-27 16:40:47.485222: train Epoch: [40][121/193]	Time  0.564 ( 6.198)	Data  0.001 ( 5.628)	Loss 9.9081e-02 (9.8261e-02) 
2023-05-27 16:40:59.459748: train Epoch: [40][122/193]	Time 11.975 ( 6.245)	Data 11.412 ( 5.675)	Loss 6.1271e-02 (9.7960e-02) 
2023-05-27 16:41:00.022779: train Epoch: [40][123/193]	Time  0.563 ( 6.199)	Data  0.001 ( 5.630)	Loss 1.5763e-01 (9.8442e-02) 
2023-05-27 16:41:12.087657: train Epoch: [40][124/193]	Time 12.065 ( 6.246)	Data 11.497 ( 5.677)	Loss 1.5459e-01 (9.8891e-02) 
2023-05-27 16:41:12.655575: train Epoch: [40][125/193]	Time  0.568 ( 6.201)	Data  0.001 ( 5.632)	Loss 1.4202e-01 (9.9233e-02) 
2023-05-27 16:41:24.533354: train Epoch: [40][126/193]	Time 11.878 ( 6.245)	Data 11.301 ( 5.676)	Loss 6.0576e-02 (9.8929e-02) 
2023-05-27 16:41:25.104225: train Epoch: [40][127/193]	Time  0.571 ( 6.201)	Data  0.001 ( 5.632)	Loss 4.6554e-02 (9.8519e-02) 
2023-05-27 16:41:36.893440: train Epoch: [40][128/193]	Time 11.789 ( 6.244)	Data 11.226 ( 5.675)	Loss 9.1012e-02 (9.8461e-02) 
2023-05-27 16:41:37.457728: train Epoch: [40][129/193]	Time  0.564 ( 6.201)	Data  0.001 ( 5.632)	Loss 2.7073e-01 (9.9786e-02) 
2023-05-27 16:41:49.121684: train Epoch: [40][130/193]	Time 11.664 ( 6.242)	Data 11.101 ( 5.673)	Loss 8.0581e-02 (9.9640e-02) 
2023-05-27 16:41:49.684856: train Epoch: [40][131/193]	Time  0.563 ( 6.199)	Data  0.001 ( 5.630)	Loss 6.1592e-02 (9.9352e-02) 
2023-05-27 16:42:00.978325: train Epoch: [40][132/193]	Time 11.293 ( 6.238)	Data 10.724 ( 5.669)	Loss 1.1640e-01 (9.9480e-02) 
2023-05-27 16:42:01.541724: train Epoch: [40][133/193]	Time  0.563 ( 6.195)	Data  0.001 ( 5.626)	Loss 9.9825e-02 (9.9482e-02) 
2023-05-27 16:42:13.193694: train Epoch: [40][134/193]	Time 11.652 ( 6.236)	Data 11.090 ( 5.667)	Loss 6.7059e-02 (9.9242e-02) 
2023-05-27 16:42:13.757163: train Epoch: [40][135/193]	Time  0.563 ( 6.194)	Data  0.001 ( 5.625)	Loss 6.9385e-02 (9.9023e-02) 
2023-05-27 16:42:25.325506: train Epoch: [40][136/193]	Time 11.568 ( 6.233)	Data 10.975 ( 5.664)	Loss 1.1515e-01 (9.9140e-02) 
2023-05-27 16:42:25.887954: train Epoch: [40][137/193]	Time  0.562 ( 6.192)	Data  0.001 ( 5.623)	Loss 6.9178e-02 (9.8923e-02) 
2023-05-27 16:42:37.638283: train Epoch: [40][138/193]	Time 11.750 ( 6.232)	Data 11.182 ( 5.663)	Loss 8.0884e-02 (9.8793e-02) 
2023-05-27 16:42:38.205073: train Epoch: [40][139/193]	Time  0.567 ( 6.192)	Data  0.001 ( 5.623)	Loss 2.5704e-01 (9.9924e-02) 
2023-05-27 16:42:49.617778: train Epoch: [40][140/193]	Time 11.413 ( 6.229)	Data 10.763 ( 5.659)	Loss 1.4788e-01 (1.0026e-01) 
2023-05-27 16:42:50.181178: train Epoch: [40][141/193]	Time  0.563 ( 6.189)	Data  0.001 ( 5.619)	Loss 7.3555e-02 (1.0008e-01) 
2023-05-27 16:43:02.641804: train Epoch: [40][142/193]	Time 12.461 ( 6.233)	Data 11.896 ( 5.663)	Loss 5.3185e-02 (9.9748e-02) 
2023-05-27 16:43:03.210883: train Epoch: [40][143/193]	Time  0.569 ( 6.193)	Data  0.001 ( 5.624)	Loss 6.9264e-02 (9.9536e-02) 
2023-05-27 16:43:14.813003: train Epoch: [40][144/193]	Time 11.602 ( 6.231)	Data 11.031 ( 5.661)	Loss 8.7356e-02 (9.9452e-02) 
2023-05-27 16:43:15.388455: train Epoch: [40][145/193]	Time  0.575 ( 6.192)	Data  0.001 ( 5.622)	Loss 1.2802e-01 (9.9648e-02) 
2023-05-27 16:43:26.970645: train Epoch: [40][146/193]	Time 11.582 ( 6.229)	Data 11.002 ( 5.659)	Loss 5.1316e-02 (9.9319e-02) 
2023-05-27 16:43:27.538579: train Epoch: [40][147/193]	Time  0.568 ( 6.190)	Data  0.001 ( 5.621)	Loss 1.0136e-01 (9.9333e-02) 
2023-05-27 16:43:39.399152: train Epoch: [40][148/193]	Time 11.861 ( 6.228)	Data 11.268 ( 5.659)	Loss 1.1062e-01 (9.9408e-02) 
2023-05-27 16:43:39.978513: train Epoch: [40][149/193]	Time  0.579 ( 6.191)	Data  0.001 ( 5.621)	Loss 1.0515e-01 (9.9447e-02) 
2023-05-27 16:43:52.087263: train Epoch: [40][150/193]	Time 12.109 ( 6.230)	Data 11.541 ( 5.660)	Loss 9.1537e-02 (9.9394e-02) 
2023-05-27 16:43:52.664856: train Epoch: [40][151/193]	Time  0.578 ( 6.193)	Data  0.001 ( 5.623)	Loss 7.4571e-02 (9.9231e-02) 
2023-05-27 16:44:04.294838: train Epoch: [40][152/193]	Time 11.630 ( 6.228)	Data 11.056 ( 5.658)	Loss 1.1551e-01 (9.9337e-02) 
2023-05-27 16:44:04.879245: train Epoch: [40][153/193]	Time  0.584 ( 6.192)	Data  0.001 ( 5.622)	Loss 8.9322e-02 (9.9272e-02) 
2023-05-27 16:44:17.087743: train Epoch: [40][154/193]	Time 12.208 ( 6.230)	Data 11.613 ( 5.660)	Loss 1.1024e-01 (9.9343e-02) 
2023-05-27 16:44:17.653889: train Epoch: [40][155/193]	Time  0.566 ( 6.194)	Data  0.001 ( 5.624)	Loss 7.5214e-02 (9.9188e-02) 
2023-05-27 16:44:29.150507: train Epoch: [40][156/193]	Time 11.497 ( 6.228)	Data 10.921 ( 5.658)	Loss 5.0983e-02 (9.8881e-02) 
2023-05-27 16:44:29.723091: train Epoch: [40][157/193]	Time  0.573 ( 6.192)	Data  0.001 ( 5.622)	Loss 5.5679e-02 (9.8608e-02) 
2023-05-27 16:44:41.351857: train Epoch: [40][158/193]	Time 11.629 ( 6.226)	Data 11.063 ( 5.656)	Loss 8.8087e-02 (9.8542e-02) 
2023-05-27 16:44:42.505256: train Epoch: [40][159/193]	Time  1.153 ( 6.195)	Data  0.550 ( 5.624)	Loss 1.6569e-01 (9.8962e-02) 
2023-05-27 16:44:53.851983: train Epoch: [40][160/193]	Time 11.347 ( 6.227)	Data 10.776 ( 5.656)	Loss 9.6308e-02 (9.8945e-02) 
2023-05-27 16:44:55.295320: train Epoch: [40][161/193]	Time  1.443 ( 6.197)	Data  0.855 ( 5.627)	Loss 1.2020e-01 (9.9076e-02) 
2023-05-27 16:45:06.692740: train Epoch: [40][162/193]	Time 11.397 ( 6.229)	Data 10.805 ( 5.658)	Loss 6.4833e-02 (9.8866e-02) 
2023-05-27 16:45:07.267272: train Epoch: [40][163/193]	Time  0.575 ( 6.194)	Data  0.001 ( 5.624)	Loss 8.2869e-02 (9.8769e-02) 
2023-05-27 16:45:19.284330: train Epoch: [40][164/193]	Time 12.017 ( 6.230)	Data 11.447 ( 5.659)	Loss 6.4988e-02 (9.8564e-02) 
2023-05-27 16:45:19.868839: train Epoch: [40][165/193]	Time  0.585 ( 6.196)	Data  0.001 ( 5.625)	Loss 7.5124e-02 (9.8423e-02) 
2023-05-27 16:45:31.795439: train Epoch: [40][166/193]	Time 11.927 ( 6.230)	Data 11.353 ( 5.659)	Loss 6.9675e-02 (9.8251e-02) 
2023-05-27 16:45:32.456007: train Epoch: [40][167/193]	Time  0.661 ( 6.197)	Data  0.001 ( 5.626)	Loss 7.4072e-02 (9.8107e-02) 
2023-05-27 16:45:44.625443: train Epoch: [40][168/193]	Time 12.169 ( 6.232)	Data 11.571 ( 5.661)	Loss 1.0213e-01 (9.8130e-02) 
2023-05-27 16:45:45.189954: train Epoch: [40][169/193]	Time  0.564 ( 6.199)	Data  0.001 ( 5.628)	Loss 6.1839e-02 (9.7917e-02) 
2023-05-27 16:45:56.685501: train Epoch: [40][170/193]	Time 11.496 ( 6.230)	Data 10.915 ( 5.659)	Loss 2.2950e-01 (9.8686e-02) 
2023-05-27 16:45:57.269791: train Epoch: [40][171/193]	Time  0.584 ( 6.197)	Data  0.001 ( 5.626)	Loss 9.1114e-02 (9.8642e-02) 
2023-05-27 16:46:08.819683: train Epoch: [40][172/193]	Time 11.550 ( 6.228)	Data 10.980 ( 5.657)	Loss 1.0939e-01 (9.8704e-02) 
2023-05-27 16:46:09.932113: train Epoch: [40][173/193]	Time  1.112 ( 6.199)	Data  0.531 ( 5.627)	Loss 6.8443e-02 (9.8531e-02) 
2023-05-27 16:46:20.950760: train Epoch: [40][174/193]	Time 11.019 ( 6.226)	Data 10.430 ( 5.655)	Loss 1.1298e-01 (9.8613e-02) 
2023-05-27 16:46:22.974409: train Epoch: [40][175/193]	Time  2.024 ( 6.202)	Data  1.463 ( 5.631)	Loss 5.6848e-02 (9.8376e-02) 
2023-05-27 16:46:33.162097: train Epoch: [40][176/193]	Time 10.188 ( 6.225)	Data  9.622 ( 5.653)	Loss 6.8931e-02 (9.8209e-02) 
2023-05-27 16:46:34.040576: train Epoch: [40][177/193]	Time  0.878 ( 6.195)	Data  0.313 ( 5.623)	Loss 8.3994e-02 (9.8130e-02) 
2023-05-27 16:46:45.361852: train Epoch: [40][178/193]	Time 11.321 ( 6.223)	Data 10.751 ( 5.652)	Loss 1.0983e-01 (9.8195e-02) 
2023-05-27 16:46:46.524889: train Epoch: [40][179/193]	Time  1.163 ( 6.195)	Data  0.601 ( 5.624)	Loss 4.8011e-02 (9.7916e-02) 
2023-05-27 16:46:57.500633: train Epoch: [40][180/193]	Time 10.976 ( 6.222)	Data 10.400 ( 5.650)	Loss 6.0435e-02 (9.7709e-02) 
2023-05-27 16:46:59.233814: train Epoch: [40][181/193]	Time  1.733 ( 6.197)	Data  1.172 ( 5.626)	Loss 6.0746e-02 (9.7506e-02) 
2023-05-27 16:47:10.337927: train Epoch: [40][182/193]	Time 11.104 ( 6.224)	Data 10.525 ( 5.653)	Loss 7.6551e-02 (9.7392e-02) 
2023-05-27 16:47:11.102582: train Epoch: [40][183/193]	Time  0.765 ( 6.194)	Data  0.172 ( 5.623)	Loss 9.1829e-02 (9.7361e-02) 
2023-05-27 16:47:22.736927: train Epoch: [40][184/193]	Time 11.634 ( 6.224)	Data 11.069 ( 5.652)	Loss 1.4802e-01 (9.7635e-02) 
2023-05-27 16:47:23.308273: train Epoch: [40][185/193]	Time  0.571 ( 6.193)	Data  0.001 ( 5.622)	Loss 8.7861e-02 (9.7583e-02) 
2023-05-27 16:47:35.390644: train Epoch: [40][186/193]	Time 12.082 ( 6.225)	Data 11.503 ( 5.653)	Loss 9.8628e-02 (9.7588e-02) 
2023-05-27 16:47:35.953109: train Epoch: [40][187/193]	Time  0.562 ( 6.195)	Data  0.001 ( 5.623)	Loss 5.1981e-02 (9.7346e-02) 
2023-05-27 16:47:48.035997: train Epoch: [40][188/193]	Time 12.083 ( 6.226)	Data 11.521 ( 5.654)	Loss 1.5920e-01 (9.7673e-02) 
2023-05-27 16:47:48.598513: train Epoch: [40][189/193]	Time  0.563 ( 6.196)	Data  0.001 ( 5.625)	Loss 4.5162e-02 (9.7396e-02) 
2023-05-27 16:48:00.263341: train Epoch: [40][190/193]	Time 11.665 ( 6.225)	Data 11.096 ( 5.653)	Loss 1.0072e-01 (9.7414e-02) 
2023-05-27 16:48:00.831160: train Epoch: [40][191/193]	Time  0.568 ( 6.195)	Data  0.001 ( 5.624)	Loss 7.1529e-02 (9.7279e-02) 
2023-05-27 16:48:11.395513: train Epoch: [40][192/193]	Time 10.564 ( 6.218)	Data  9.994 ( 5.646)	Loss 8.4415e-02 (9.7212e-02) 
2023-05-27 16:48:11.650300: Train Epoch done in 1200.27381350199 s 
2023-05-27 16:48:20.096284: val Epoch: [40][ 0/72]	Time  7.738 ( 7.738)	Data  7.448 ( 7.448)	Loss 8.9001e-02 (8.9001e-02) 
2023-05-27 16:48:20.217068: val Epoch: [40][ 1/72]	Time  0.121 ( 3.930)	Data  0.001 ( 3.724)	Loss 4.7944e-01 (2.8422e-01) 
2023-05-27 16:48:26.048434: val Epoch: [40][ 2/72]	Time  5.831 ( 4.564)	Data  5.721 ( 4.390)	Loss 5.9311e-02 (2.0925e-01) 
2023-05-27 16:48:26.331616: val Epoch: [40][ 3/72]	Time  0.283 ( 3.493)	Data  0.174 ( 3.336)	Loss 9.0318e-02 (1.7952e-01) 
2023-05-27 16:48:32.443816: val Epoch: [40][ 4/72]	Time  6.112 ( 4.017)	Data  6.002 ( 3.869)	Loss 3.2650e-01 (2.0892e-01) 
2023-05-27 16:48:32.565339: val Epoch: [40][ 5/72]	Time  0.122 ( 3.368)	Data  0.012 ( 3.226)	Loss 6.0221e-02 (1.8413e-01) 
2023-05-27 16:48:38.730666: val Epoch: [40][ 6/72]	Time  6.165 ( 3.768)	Data  6.057 ( 3.631)	Loss 5.8398e-02 (1.6617e-01) 
2023-05-27 16:48:38.839881: val Epoch: [40][ 7/72]	Time  0.109 ( 3.310)	Data  0.001 ( 3.177)	Loss 8.5559e-02 (1.5609e-01) 
2023-05-27 16:48:44.846811: val Epoch: [40][ 8/72]	Time  6.007 ( 3.610)	Data  5.899 ( 3.479)	Loss 3.8456e-02 (1.4302e-01) 
2023-05-27 16:48:44.954077: val Epoch: [40][ 9/72]	Time  0.107 ( 3.260)	Data  0.001 ( 3.132)	Loss 3.1239e-01 (1.5996e-01) 
2023-05-27 16:48:50.731492: val Epoch: [40][10/72]	Time  5.777 ( 3.489)	Data  5.667 ( 3.362)	Loss 4.3868e-02 (1.4941e-01) 
2023-05-27 16:48:51.261040: val Epoch: [40][11/72]	Time  0.530 ( 3.242)	Data  0.424 ( 3.117)	Loss 9.3440e-02 (1.4474e-01) 
2023-05-27 16:48:56.768779: val Epoch: [40][12/72]	Time  5.508 ( 3.416)	Data  5.402 ( 3.293)	Loss 4.9666e-02 (1.3743e-01) 
2023-05-27 16:48:57.436813: val Epoch: [40][13/72]	Time  0.668 ( 3.220)	Data  0.562 ( 3.098)	Loss 4.8634e-01 (1.6235e-01) 
2023-05-27 16:49:03.033981: val Epoch: [40][14/72]	Time  5.597 ( 3.378)	Data  5.484 ( 3.257)	Loss 3.5565e-01 (1.7524e-01) 
2023-05-27 16:49:03.505689: val Epoch: [40][15/72]	Time  0.472 ( 3.197)	Data  0.364 ( 3.076)	Loss 1.0088e-01 (1.7059e-01) 
2023-05-27 16:49:09.241776: val Epoch: [40][16/72]	Time  5.736 ( 3.346)	Data  5.630 ( 3.226)	Loss 4.6044e-02 (1.6326e-01) 
2023-05-27 16:49:09.669156: val Epoch: [40][17/72]	Time  0.427 ( 3.184)	Data  0.322 ( 3.065)	Loss 1.9232e-01 (1.6488e-01) 
2023-05-27 16:49:15.668727: val Epoch: [40][18/72]	Time  6.000 ( 3.332)	Data  5.892 ( 3.214)	Loss 3.5570e-02 (1.5807e-01) 
2023-05-27 16:49:15.949984: val Epoch: [40][19/72]	Time  0.281 ( 3.180)	Data  0.172 ( 3.062)	Loss 8.4628e-02 (1.5440e-01) 
2023-05-27 16:49:21.726645: val Epoch: [40][20/72]	Time  5.777 ( 3.303)	Data  5.671 ( 3.186)	Loss 3.6898e-02 (1.4880e-01) 
2023-05-27 16:49:22.178526: val Epoch: [40][21/72]	Time  0.452 ( 3.174)	Data  0.343 ( 3.057)	Loss 5.1771e-02 (1.4439e-01) 
2023-05-27 16:49:27.550933: val Epoch: [40][22/72]	Time  5.372 ( 3.269)	Data  5.267 ( 3.153)	Loss 6.9153e-02 (1.4112e-01) 
2023-05-27 16:49:28.646193: val Epoch: [40][23/72]	Time  1.095 ( 3.179)	Data  0.990 ( 3.063)	Loss 7.1614e-02 (1.3823e-01) 
2023-05-27 16:49:33.706047: val Epoch: [40][24/72]	Time  5.060 ( 3.254)	Data  4.952 ( 3.138)	Loss 1.5588e-01 (1.3893e-01) 
2023-05-27 16:49:35.018992: val Epoch: [40][25/72]	Time  1.313 ( 3.179)	Data  1.197 ( 3.064)	Loss 1.4894e-01 (1.3932e-01) 
2023-05-27 16:49:39.928390: val Epoch: [40][26/72]	Time  4.909 ( 3.243)	Data  4.801 ( 3.128)	Loss 3.5161e-01 (1.4718e-01) 
2023-05-27 16:49:41.503396: val Epoch: [40][27/72]	Time  1.575 ( 3.184)	Data  1.467 ( 3.069)	Loss 7.9524e-02 (1.4476e-01) 
2023-05-27 16:49:45.746986: val Epoch: [40][28/72]	Time  4.244 ( 3.220)	Data  4.131 ( 3.105)	Loss 1.5013e-01 (1.4495e-01) 
2023-05-27 16:49:47.601781: val Epoch: [40][29/72]	Time  1.855 ( 3.175)	Data  1.747 ( 3.060)	Loss 8.1661e-02 (1.4284e-01) 
2023-05-27 16:49:51.666785: val Epoch: [40][30/72]	Time  4.065 ( 3.204)	Data  3.957 ( 3.089)	Loss 3.0267e-01 (1.4800e-01) 
2023-05-27 16:49:53.781829: val Epoch: [40][31/72]	Time  2.115 ( 3.169)	Data  2.006 ( 3.055)	Loss 5.3338e-02 (1.4504e-01) 
2023-05-27 16:49:57.939190: val Epoch: [40][32/72]	Time  4.157 ( 3.199)	Data  4.049 ( 3.085)	Loss 1.8238e-01 (1.4617e-01) 
2023-05-27 16:49:59.757311: val Epoch: [40][33/72]	Time  1.818 ( 3.159)	Data  1.710 ( 3.045)	Loss 5.6367e-02 (1.4353e-01) 
2023-05-27 16:50:04.517756: val Epoch: [40][34/72]	Time  4.760 ( 3.205)	Data  4.653 ( 3.091)	Loss 6.3410e-02 (1.4124e-01) 
2023-05-27 16:50:06.040279: val Epoch: [40][35/72]	Time  1.523 ( 3.158)	Data  1.415 ( 3.044)	Loss 6.2109e-02 (1.3904e-01) 
2023-05-27 16:50:10.621097: val Epoch: [40][36/72]	Time  4.581 ( 3.196)	Data  4.473 ( 3.083)	Loss 9.7250e-02 (1.3791e-01) 
2023-05-27 16:50:12.281919: val Epoch: [40][37/72]	Time  1.661 ( 3.156)	Data  1.553 ( 3.043)	Loss 8.2707e-02 (1.3646e-01) 
2023-05-27 16:50:16.564998: val Epoch: [40][38/72]	Time  4.283 ( 3.185)	Data  4.175 ( 3.072)	Loss 4.5435e-02 (1.3412e-01) 
2023-05-27 16:50:18.426455: val Epoch: [40][39/72]	Time  1.861 ( 3.152)	Data  1.754 ( 3.039)	Loss 1.1483e-01 (1.3364e-01) 
2023-05-27 16:50:22.604187: val Epoch: [40][40/72]	Time  4.178 ( 3.177)	Data  4.070 ( 3.064)	Loss 1.5913e-01 (1.3426e-01) 
2023-05-27 16:50:24.137631: val Epoch: [40][41/72]	Time  1.533 ( 3.138)	Data  1.425 ( 3.025)	Loss 6.5269e-02 (1.3262e-01) 
2023-05-27 16:50:29.048259: val Epoch: [40][42/72]	Time  4.911 ( 3.179)	Data  4.802 ( 3.066)	Loss 3.3276e-01 (1.3728e-01) 
2023-05-27 16:50:30.387614: val Epoch: [40][43/72]	Time  1.339 ( 3.137)	Data  1.186 ( 3.023)	Loss 3.2878e-01 (1.4163e-01) 
2023-05-27 16:50:35.105741: val Epoch: [40][44/72]	Time  4.718 ( 3.172)	Data  4.608 ( 3.059)	Loss 4.7617e-02 (1.3954e-01) 
2023-05-27 16:50:36.444628: val Epoch: [40][45/72]	Time  1.339 ( 3.132)	Data  1.232 ( 3.019)	Loss 9.0302e-02 (1.3847e-01) 
2023-05-27 16:50:41.493914: val Epoch: [40][46/72]	Time  5.049 ( 3.173)	Data  4.944 ( 3.060)	Loss 1.6246e-01 (1.3898e-01) 
2023-05-27 16:50:42.601640: val Epoch: [40][47/72]	Time  1.108 ( 3.130)	Data  0.999 ( 3.017)	Loss 2.2027e-01 (1.4067e-01) 
2023-05-27 16:50:47.694301: val Epoch: [40][48/72]	Time  5.093 ( 3.170)	Data  4.984 ( 3.057)	Loss 6.8459e-02 (1.3920e-01) 
2023-05-27 16:50:49.105753: val Epoch: [40][49/72]	Time  1.411 ( 3.135)	Data  1.301 ( 3.022)	Loss 1.0074e-01 (1.3843e-01) 
2023-05-27 16:50:54.058898: val Epoch: [40][50/72]	Time  4.953 ( 3.171)	Data  4.844 ( 3.058)	Loss 1.3082e-01 (1.3828e-01) 
2023-05-27 16:50:55.427415: val Epoch: [40][51/72]	Time  1.369 ( 3.136)	Data  1.260 ( 3.023)	Loss 6.7131e-02 (1.3691e-01) 
2023-05-27 16:51:00.172426: val Epoch: [40][52/72]	Time  4.745 ( 3.166)	Data  4.637 ( 3.054)	Loss 5.2882e-02 (1.3533e-01) 
2023-05-27 16:51:01.767822: val Epoch: [40][53/72]	Time  1.595 ( 3.137)	Data  1.487 ( 3.025)	Loss 2.5154e-01 (1.3748e-01) 
2023-05-27 16:51:06.573752: val Epoch: [40][54/72]	Time  4.806 ( 3.168)	Data  4.642 ( 3.054)	Loss 1.1278e-01 (1.3703e-01) 
2023-05-27 16:51:08.212437: val Epoch: [40][55/72]	Time  1.639 ( 3.140)	Data  1.530 ( 3.027)	Loss 7.7407e-02 (1.3596e-01) 
2023-05-27 16:51:12.842353: val Epoch: [40][56/72]	Time  4.630 ( 3.166)	Data  4.521 ( 3.053)	Loss 1.0541e-01 (1.3543e-01) 
2023-05-27 16:51:14.301847: val Epoch: [40][57/72]	Time  1.459 ( 3.137)	Data  1.352 ( 3.024)	Loss 8.9778e-02 (1.3464e-01) 
2023-05-27 16:51:19.033064: val Epoch: [40][58/72]	Time  4.731 ( 3.164)	Data  4.622 ( 3.051)	Loss 1.3013e-01 (1.3457e-01) 
2023-05-27 16:51:20.865699: val Epoch: [40][59/72]	Time  1.833 ( 3.142)	Data  1.703 ( 3.028)	Loss 5.3955e-02 (1.3322e-01) 
2023-05-27 16:51:25.340218: val Epoch: [40][60/72]	Time  4.474 ( 3.164)	Data  4.363 ( 3.050)	Loss 3.6776e-02 (1.3164e-01) 
2023-05-27 16:51:27.118071: val Epoch: [40][61/72]	Time  1.778 ( 3.141)	Data  1.668 ( 3.028)	Loss 4.4993e-02 (1.3024e-01) 
2023-05-27 16:51:31.662886: val Epoch: [40][62/72]	Time  4.545 ( 3.164)	Data  4.435 ( 3.050)	Loss 7.8246e-02 (1.2942e-01) 
2023-05-27 16:51:33.490454: val Epoch: [40][63/72]	Time  1.828 ( 3.143)	Data  1.722 ( 3.029)	Loss 8.5225e-02 (1.2873e-01) 
2023-05-27 16:51:37.655033: val Epoch: [40][64/72]	Time  4.165 ( 3.158)	Data  4.059 ( 3.045)	Loss 5.4420e-02 (1.2758e-01) 
2023-05-27 16:51:39.750997: val Epoch: [40][65/72]	Time  2.096 ( 3.142)	Data  1.990 ( 3.029)	Loss 1.3968e-01 (1.2777e-01) 
2023-05-27 16:51:43.778279: val Epoch: [40][66/72]	Time  4.027 ( 3.156)	Data  3.918 ( 3.043)	Loss 5.4261e-02 (1.2667e-01) 
2023-05-27 16:51:46.031835: val Epoch: [40][67/72]	Time  2.254 ( 3.142)	Data  2.148 ( 3.029)	Loss 1.2197e-01 (1.2660e-01) 
2023-05-27 16:51:49.623081: val Epoch: [40][68/72]	Time  3.591 ( 3.149)	Data  3.486 ( 3.036)	Loss 4.2096e-02 (1.2538e-01) 
2023-05-27 16:51:52.305069: val Epoch: [40][69/72]	Time  2.682 ( 3.142)	Data  2.577 ( 3.029)	Loss 3.9098e-01 (1.2917e-01) 
2023-05-27 16:51:55.573358: val Epoch: [40][70/72]	Time  3.268 ( 3.144)	Data  3.163 ( 3.031)	Loss 6.2712e-02 (1.2823e-01) 
2023-05-27 16:51:58.310986: val Epoch: [40][71/72]	Time  2.738 ( 3.138)	Data  2.632 ( 3.026)	Loss 5.7218e-02 (1.2725e-01) 
2023-05-27 16:51:58.628228: Epoch 40 :Val : ['ET : 0.7280504703521729', 'TC : 0.7974680662155151', 'WT : 0.8577240705490112'] 
2023-05-27 16:51:58.629148: Epoch 40 :Val : ['ET : 0.7280504703521729', 'TC : 0.7974680662155151', 'WT : 0.8577240705490112'] 
2023-05-27 16:51:58.633875: Saving the model with DSC 0.8055797219276428 
2023-05-27 16:51:59.442098: Val epoch done in 227.79178611401585 s 
2023-05-27 16:51:59.479469: Batches per epoch:  193 
2023-05-27 16:52:13.307264: train Epoch: [41][  0/193]	Time 13.827 (13.827)	Data 13.157 (13.157)	Loss 7.9293e-02 (7.9293e-02) 
2023-05-27 16:52:13.991672: train Epoch: [41][  1/193]	Time  0.684 ( 7.256)	Data  0.107 ( 6.632)	Loss 1.1056e-01 (9.4927e-02) 
2023-05-27 16:52:25.585211: train Epoch: [41][  2/193]	Time 11.594 ( 8.702)	Data 11.028 ( 8.097)	Loss 7.9677e-02 (8.9844e-02) 
2023-05-27 16:52:26.147406: train Epoch: [41][  3/193]	Time  0.562 ( 6.667)	Data  0.001 ( 6.073)	Loss 6.2400e-02 (8.2983e-02) 
2023-05-27 16:52:37.753943: train Epoch: [41][  4/193]	Time 11.607 ( 7.655)	Data 11.036 ( 7.066)	Loss 6.2686e-02 (7.8924e-02) 
2023-05-27 16:52:38.321777: train Epoch: [41][  5/193]	Time  0.568 ( 6.474)	Data  0.001 ( 5.888)	Loss 1.0310e-01 (8.2953e-02) 
2023-05-27 16:52:50.403670: train Epoch: [41][  6/193]	Time 12.082 ( 7.275)	Data 11.516 ( 6.692)	Loss 1.4408e-01 (9.1685e-02) 
2023-05-27 16:52:50.970791: train Epoch: [41][  7/193]	Time  0.567 ( 6.436)	Data  0.001 ( 5.856)	Loss 4.7014e-02 (8.6101e-02) 
2023-05-27 16:53:02.729307: train Epoch: [41][  8/193]	Time 11.759 ( 7.028)	Data 11.184 ( 6.448)	Loss 4.5837e-02 (8.1627e-02) 
2023-05-27 16:53:03.291785: train Epoch: [41][  9/193]	Time  0.562 ( 6.381)	Data  0.001 ( 5.803)	Loss 7.0990e-02 (8.0564e-02) 
2023-05-27 16:53:15.362519: train Epoch: [41][ 10/193]	Time 12.071 ( 6.898)	Data 11.510 ( 6.322)	Loss 1.2108e-01 (8.4247e-02) 
2023-05-27 16:53:16.307951: train Epoch: [41][ 11/193]	Time  0.945 ( 6.402)	Data  0.381 ( 5.827)	Loss 9.6689e-02 (8.5284e-02) 
2023-05-27 16:53:28.217096: train Epoch: [41][ 12/193]	Time 11.909 ( 6.826)	Data 11.348 ( 6.252)	Loss 5.7545e-02 (8.3150e-02) 
2023-05-27 16:53:29.774207: train Epoch: [41][ 13/193]	Time  1.557 ( 6.450)	Data  0.997 ( 5.876)	Loss 1.0267e-01 (8.4544e-02) 
2023-05-27 16:53:40.718785: train Epoch: [41][ 14/193]	Time 10.945 ( 6.749)	Data 10.356 ( 6.175)	Loss 1.0596e-01 (8.5972e-02) 
2023-05-27 16:53:42.920915: train Epoch: [41][ 15/193]	Time  2.202 ( 6.465)	Data  1.638 ( 5.891)	Loss 1.7896e-01 (9.1784e-02) 
2023-05-27 16:53:53.306746: train Epoch: [41][ 16/193]	Time 10.386 ( 6.696)	Data  9.793 ( 6.121)	Loss 1.0733e-01 (9.2698e-02) 
2023-05-27 16:53:55.178338: train Epoch: [41][ 17/193]	Time  1.872 ( 6.428)	Data  1.292 ( 5.853)	Loss 9.1514e-02 (9.2632e-02) 
2023-05-27 16:54:06.256923: train Epoch: [41][ 18/193]	Time 11.079 ( 6.672)	Data 10.506 ( 6.098)	Loss 8.0165e-02 (9.1976e-02) 
2023-05-27 16:54:07.918965: train Epoch: [41][ 19/193]	Time  1.662 ( 6.422)	Data  1.102 ( 5.848)	Loss 6.3475e-02 (9.0551e-02) 
2023-05-27 16:54:17.843619: train Epoch: [41][ 20/193]	Time  9.925 ( 6.589)	Data  9.365 ( 6.015)	Loss 9.2847e-02 (9.0660e-02) 
2023-05-27 16:54:19.288827: train Epoch: [41][ 21/193]	Time  1.445 ( 6.355)	Data  0.885 ( 5.782)	Loss 6.4227e-02 (8.9459e-02) 
2023-05-27 16:54:29.897333: train Epoch: [41][ 22/193]	Time 10.608 ( 6.540)	Data 10.037 ( 5.967)	Loss 4.1493e-02 (8.7373e-02) 
2023-05-27 16:54:31.595322: train Epoch: [41][ 23/193]	Time  1.698 ( 6.338)	Data  1.137 ( 5.766)	Loss 6.4609e-02 (8.6425e-02) 
2023-05-27 16:54:41.286300: train Epoch: [41][ 24/193]	Time  9.691 ( 6.472)	Data  9.119 ( 5.900)	Loss 7.0016e-02 (8.5768e-02) 
2023-05-27 16:54:42.843681: train Epoch: [41][ 25/193]	Time  1.557 ( 6.283)	Data  0.997 ( 5.711)	Loss 4.7828e-02 (8.4309e-02) 
2023-05-27 16:54:52.307393: train Epoch: [41][ 26/193]	Time  9.464 ( 6.401)	Data  8.901 ( 5.829)	Loss 6.0554e-02 (8.3429e-02) 
2023-05-27 16:54:54.243649: train Epoch: [41][ 27/193]	Time  1.936 ( 6.242)	Data  1.376 ( 5.670)	Loss 4.5735e-02 (8.2083e-02) 
2023-05-27 16:55:04.544637: train Epoch: [41][ 28/193]	Time 10.301 ( 6.382)	Data  9.737 ( 5.811)	Loss 3.0547e-01 (8.9786e-02) 
2023-05-27 16:55:06.535328: train Epoch: [41][ 29/193]	Time  1.991 ( 6.235)	Data  1.431 ( 5.665)	Loss 8.6006e-02 (8.9660e-02) 
2023-05-27 16:55:16.815390: train Epoch: [41][ 30/193]	Time 10.280 ( 6.366)	Data  9.713 ( 5.795)	Loss 4.9467e-02 (8.8364e-02) 
2023-05-27 16:55:18.495306: train Epoch: [41][ 31/193]	Time  1.680 ( 6.219)	Data  1.113 ( 5.649)	Loss 1.6869e-01 (9.0874e-02) 
2023-05-27 16:55:29.186684: train Epoch: [41][ 32/193]	Time 10.691 ( 6.355)	Data 10.112 ( 5.784)	Loss 1.2417e-01 (9.1883e-02) 
2023-05-27 16:55:30.962173: train Epoch: [41][ 33/193]	Time  1.775 ( 6.220)	Data  1.214 ( 5.650)	Loss 1.3747e-01 (9.3224e-02) 
2023-05-27 16:55:41.419335: train Epoch: [41][ 34/193]	Time 10.457 ( 6.341)	Data  9.881 ( 5.771)	Loss 9.5589e-02 (9.3291e-02) 
2023-05-27 16:55:43.323949: train Epoch: [41][ 35/193]	Time  1.905 ( 6.218)	Data  1.337 ( 5.648)	Loss 1.2188e-01 (9.4085e-02) 
2023-05-27 16:55:53.501414: train Epoch: [41][ 36/193]	Time 10.177 ( 6.325)	Data  9.592 ( 5.754)	Loss 1.4294e-01 (9.5406e-02) 
2023-05-27 16:55:55.306280: train Epoch: [41][ 37/193]	Time  1.805 ( 6.206)	Data  1.244 ( 5.635)	Loss 1.0888e-01 (9.5760e-02) 
2023-05-27 16:56:05.843852: train Epoch: [41][ 38/193]	Time 10.538 ( 6.317)	Data  9.975 ( 5.747)	Loss 1.3634e-01 (9.6801e-02) 
2023-05-27 16:56:07.544095: train Epoch: [41][ 39/193]	Time  1.700 ( 6.202)	Data  1.140 ( 5.632)	Loss 5.9197e-02 (9.5861e-02) 
2023-05-27 16:56:17.861684: train Epoch: [41][ 40/193]	Time 10.318 ( 6.302)	Data  9.705 ( 5.731)	Loss 6.6947e-02 (9.5156e-02) 
2023-05-27 16:56:19.337055: train Epoch: [41][ 41/193]	Time  1.475 ( 6.187)	Data  0.914 ( 5.616)	Loss 5.7914e-02 (9.4269e-02) 
2023-05-27 16:56:30.450537: train Epoch: [41][ 42/193]	Time 11.113 ( 6.302)	Data 10.548 ( 5.731)	Loss 5.1578e-02 (9.3276e-02) 
2023-05-27 16:56:31.973071: train Epoch: [41][ 43/193]	Time  1.523 ( 6.193)	Data  0.957 ( 5.622)	Loss 1.2732e-01 (9.4050e-02) 
2023-05-27 16:56:42.627069: train Epoch: [41][ 44/193]	Time 10.654 ( 6.292)	Data 10.060 ( 5.721)	Loss 6.3195e-02 (9.3364e-02) 
2023-05-27 16:56:44.109026: train Epoch: [41][ 45/193]	Time  1.482 ( 6.188)	Data  0.917 ( 5.617)	Loss 7.5097e-02 (9.2967e-02) 
2023-05-27 16:56:55.209438: train Epoch: [41][ 46/193]	Time 11.100 ( 6.292)	Data 10.497 ( 5.720)	Loss 5.7390e-02 (9.2210e-02) 
2023-05-27 16:56:56.318169: train Epoch: [41][ 47/193]	Time  1.109 ( 6.184)	Data  0.548 ( 5.613)	Loss 1.1238e-01 (9.2630e-02) 
2023-05-27 16:57:07.742350: train Epoch: [41][ 48/193]	Time 11.424 ( 6.291)	Data 10.839 ( 5.719)	Loss 9.2134e-02 (9.2620e-02) 
2023-05-27 16:57:08.778687: train Epoch: [41][ 49/193]	Time  1.036 ( 6.186)	Data  0.472 ( 5.614)	Loss 4.8822e-02 (9.1744e-02) 
2023-05-27 16:57:20.327508: train Epoch: [41][ 50/193]	Time 11.549 ( 6.291)	Data 10.978 ( 5.720)	Loss 1.4163e-01 (9.2722e-02) 
2023-05-27 16:57:20.952905: train Epoch: [41][ 51/193]	Time  0.625 ( 6.182)	Data  0.065 ( 5.611)	Loss 9.4562e-02 (9.2758e-02) 
2023-05-27 16:57:32.425724: train Epoch: [41][ 52/193]	Time 11.473 ( 6.282)	Data 10.862 ( 5.710)	Loss 9.7877e-02 (9.2854e-02) 
2023-05-27 16:57:33.627079: train Epoch: [41][ 53/193]	Time  1.201 ( 6.188)	Data  0.634 ( 5.616)	Loss 9.0354e-02 (9.2808e-02) 
2023-05-27 16:57:44.494743: train Epoch: [41][ 54/193]	Time 10.868 ( 6.273)	Data 10.305 ( 5.701)	Loss 1.2484e-01 (9.3391e-02) 
2023-05-27 16:57:46.246685: train Epoch: [41][ 55/193]	Time  1.752 ( 6.192)	Data  1.192 ( 5.621)	Loss 1.0405e-01 (9.3581e-02) 
2023-05-27 16:57:56.168146: train Epoch: [41][ 56/193]	Time  9.921 ( 6.258)	Data  9.346 ( 5.686)	Loss 1.1835e-01 (9.4015e-02) 
2023-05-27 16:57:57.967777: train Epoch: [41][ 57/193]	Time  1.800 ( 6.181)	Data  1.234 ( 5.609)	Loss 6.6382e-02 (9.3539e-02) 
2023-05-27 16:58:08.295748: train Epoch: [41][ 58/193]	Time 10.328 ( 6.251)	Data  9.743 ( 5.679)	Loss 1.6648e-01 (9.4775e-02) 
2023-05-27 16:58:10.423642: train Epoch: [41][ 59/193]	Time  2.128 ( 6.182)	Data  1.567 ( 5.611)	Loss 5.9976e-02 (9.4195e-02) 
2023-05-27 16:58:20.895043: train Epoch: [41][ 60/193]	Time 10.471 ( 6.253)	Data  9.903 ( 5.681)	Loss 7.9815e-02 (9.3959e-02) 
2023-05-27 16:58:22.796552: train Epoch: [41][ 61/193]	Time  1.902 ( 6.183)	Data  1.341 ( 5.611)	Loss 1.2627e-01 (9.4481e-02) 
2023-05-27 16:58:33.634138: train Epoch: [41][ 62/193]	Time 10.838 ( 6.256)	Data 10.276 ( 5.685)	Loss 7.3812e-02 (9.4152e-02) 
2023-05-27 16:58:35.086349: train Epoch: [41][ 63/193]	Time  1.452 ( 6.181)	Data  0.891 ( 5.610)	Loss 9.4834e-02 (9.4163e-02) 
2023-05-27 16:58:45.213677: train Epoch: [41][ 64/193]	Time 10.127 ( 6.242)	Data  9.553 ( 5.671)	Loss 1.8114e-01 (9.5501e-02) 
2023-05-27 16:58:47.490380: train Epoch: [41][ 65/193]	Time  2.277 ( 6.182)	Data  1.715 ( 5.611)	Loss 4.8082e-02 (9.4783e-02) 
2023-05-27 16:58:57.590674: train Epoch: [41][ 66/193]	Time 10.100 ( 6.240)	Data  9.540 ( 5.670)	Loss 3.4172e-02 (9.3878e-02) 
2023-05-27 16:58:59.335335: train Epoch: [41][ 67/193]	Time  1.745 ( 6.174)	Data  1.184 ( 5.604)	Loss 4.6534e-02 (9.3182e-02) 
2023-05-27 16:59:09.872015: train Epoch: [41][ 68/193]	Time 10.537 ( 6.238)	Data  9.975 ( 5.667)	Loss 1.0699e-01 (9.3382e-02) 
2023-05-27 16:59:11.995971: train Epoch: [41][ 69/193]	Time  2.124 ( 6.179)	Data  1.562 ( 5.608)	Loss 4.4284e-02 (9.2681e-02) 
2023-05-27 16:59:22.379238: train Epoch: [41][ 70/193]	Time 10.383 ( 6.238)	Data  9.815 ( 5.668)	Loss 6.0526e-02 (9.2228e-02) 
2023-05-27 16:59:24.301710: train Epoch: [41][ 71/193]	Time  1.922 ( 6.178)	Data  1.356 ( 5.608)	Loss 1.0102e-01 (9.2350e-02) 
2023-05-27 16:59:35.035805: train Epoch: [41][ 72/193]	Time 10.734 ( 6.240)	Data 10.160 ( 5.670)	Loss 1.1833e-01 (9.2706e-02) 
2023-05-27 16:59:36.901399: train Epoch: [41][ 73/193]	Time  1.866 ( 6.181)	Data  1.300 ( 5.611)	Loss 8.6663e-02 (9.2624e-02) 
2023-05-27 16:59:47.637928: train Epoch: [41][ 74/193]	Time 10.737 ( 6.242)	Data 10.172 ( 5.672)	Loss 1.5141e-01 (9.3408e-02) 
2023-05-27 16:59:49.194175: train Epoch: [41][ 75/193]	Time  1.556 ( 6.180)	Data  0.990 ( 5.610)	Loss 1.5733e-01 (9.4249e-02) 
2023-05-27 17:00:00.698362: train Epoch: [41][ 76/193]	Time 11.504 ( 6.250)	Data 10.937 ( 5.679)	Loss 1.1669e-01 (9.4540e-02) 
2023-05-27 17:00:01.751166: train Epoch: [41][ 77/193]	Time  1.053 ( 6.183)	Data  0.485 ( 5.613)	Loss 7.6665e-02 (9.4311e-02) 
2023-05-27 17:00:13.685311: train Epoch: [41][ 78/193]	Time 11.934 ( 6.256)	Data 11.363 ( 5.686)	Loss 8.6981e-02 (9.4218e-02) 
2023-05-27 17:00:14.252183: train Epoch: [41][ 79/193]	Time  0.567 ( 6.185)	Data  0.001 ( 5.615)	Loss 1.5523e-01 (9.4981e-02) 
2023-05-27 17:00:26.363134: train Epoch: [41][ 80/193]	Time 12.111 ( 6.258)	Data 11.545 ( 5.688)	Loss 7.4621e-02 (9.4730e-02) 
2023-05-27 17:00:26.929488: train Epoch: [41][ 81/193]	Time  0.566 ( 6.188)	Data  0.001 ( 5.618)	Loss 6.9682e-02 (9.4424e-02) 
2023-05-27 17:00:38.802734: train Epoch: [41][ 82/193]	Time 11.873 ( 6.257)	Data 11.307 ( 5.687)	Loss 1.0041e-01 (9.4496e-02) 
2023-05-27 17:00:39.369838: train Epoch: [41][ 83/193]	Time  0.567 ( 6.189)	Data  0.001 ( 5.619)	Loss 6.7594e-02 (9.4176e-02) 
2023-05-27 17:00:51.138303: train Epoch: [41][ 84/193]	Time 11.768 ( 6.255)	Data 11.208 ( 5.685)	Loss 1.2252e-01 (9.4509e-02) 
2023-05-27 17:00:51.700777: train Epoch: [41][ 85/193]	Time  0.562 ( 6.189)	Data  0.001 ( 5.619)	Loss 1.9094e-01 (9.5631e-02) 
2023-05-27 17:01:04.167075: train Epoch: [41][ 86/193]	Time 12.466 ( 6.261)	Data 11.892 ( 5.691)	Loss 9.3492e-02 (9.5606e-02) 
2023-05-27 17:01:04.737687: train Epoch: [41][ 87/193]	Time  0.571 ( 6.196)	Data  0.001 ( 5.626)	Loss 6.3734e-02 (9.5244e-02) 
2023-05-27 17:01:15.647742: train Epoch: [41][ 88/193]	Time 10.910 ( 6.249)	Data 10.345 ( 5.679)	Loss 8.3395e-02 (9.5111e-02) 
2023-05-27 17:01:16.221129: train Epoch: [41][ 89/193]	Time  0.573 ( 6.186)	Data  0.001 ( 5.616)	Loss 4.5480e-02 (9.4559e-02) 
2023-05-27 17:01:26.903244: train Epoch: [41][ 90/193]	Time 10.682 ( 6.235)	Data 10.118 ( 5.666)	Loss 6.2229e-02 (9.4204e-02) 
2023-05-27 17:01:27.472353: train Epoch: [41][ 91/193]	Time  0.569 ( 6.174)	Data  0.001 ( 5.604)	Loss 7.0305e-02 (9.3944e-02) 
2023-05-27 17:01:39.166525: train Epoch: [41][ 92/193]	Time 11.694 ( 6.233)	Data 11.131 ( 5.664)	Loss 6.2742e-02 (9.3609e-02) 
2023-05-27 17:01:39.738577: train Epoch: [41][ 93/193]	Time  0.572 ( 6.173)	Data  0.001 ( 5.603)	Loss 1.3245e-01 (9.4022e-02) 
2023-05-27 17:01:51.633126: train Epoch: [41][ 94/193]	Time 11.895 ( 6.233)	Data 11.322 ( 5.664)	Loss 6.8687e-02 (9.3755e-02) 
2023-05-27 17:01:52.365113: train Epoch: [41][ 95/193]	Time  0.732 ( 6.176)	Data  0.161 ( 5.606)	Loss 1.2670e-01 (9.4099e-02) 
2023-05-27 17:02:04.712339: train Epoch: [41][ 96/193]	Time 12.347 ( 6.240)	Data 11.777 ( 5.670)	Loss 5.3398e-02 (9.3679e-02) 
2023-05-27 17:02:05.776600: train Epoch: [41][ 97/193]	Time  1.064 ( 6.187)	Data  0.498 ( 5.617)	Loss 7.9031e-02 (9.3529e-02) 
2023-05-27 17:02:17.304886: train Epoch: [41][ 98/193]	Time 11.528 ( 6.241)	Data 10.960 ( 5.671)	Loss 4.9768e-02 (9.3087e-02) 
2023-05-27 17:02:18.460703: train Epoch: [41][ 99/193]	Time  1.156 ( 6.190)	Data  0.596 ( 5.620)	Loss 8.3455e-02 (9.2991e-02) 
2023-05-27 17:02:30.418140: train Epoch: [41][100/193]	Time 11.957 ( 6.247)	Data 11.398 ( 5.678)	Loss 5.5058e-02 (9.2616e-02) 
2023-05-27 17:02:31.031888: train Epoch: [41][101/193]	Time  0.614 ( 6.192)	Data  0.055 ( 5.622)	Loss 1.1783e-01 (9.2863e-02) 
2023-05-27 17:02:42.827711: train Epoch: [41][102/193]	Time 11.796 ( 6.246)	Data 11.228 ( 5.677)	Loss 7.7645e-02 (9.2715e-02) 
2023-05-27 17:02:43.388424: train Epoch: [41][103/193]	Time  0.561 ( 6.191)	Data  0.001 ( 5.622)	Loss 1.2674e-01 (9.3042e-02) 
2023-05-27 17:02:55.580352: train Epoch: [41][104/193]	Time 12.192 ( 6.249)	Data 11.632 ( 5.679)	Loss 7.8043e-02 (9.2899e-02) 
2023-05-27 17:02:56.390548: train Epoch: [41][105/193]	Time  0.810 ( 6.197)	Data  0.240 ( 5.628)	Loss 9.5052e-02 (9.2920e-02) 
2023-05-27 17:03:07.980714: train Epoch: [41][106/193]	Time 11.590 ( 6.248)	Data 11.025 ( 5.679)	Loss 4.4566e-02 (9.2468e-02) 
2023-05-27 17:03:08.922630: train Epoch: [41][107/193]	Time  0.942 ( 6.199)	Data  0.375 ( 5.629)	Loss 5.2866e-02 (9.2101e-02) 
2023-05-27 17:03:20.441330: train Epoch: [41][108/193]	Time 11.519 ( 6.247)	Data 10.954 ( 5.678)	Loss 8.4240e-02 (9.2029e-02) 
2023-05-27 17:03:21.077652: train Epoch: [41][109/193]	Time  0.636 ( 6.196)	Data  0.071 ( 5.627)	Loss 5.4445e-02 (9.1687e-02) 
2023-05-27 17:03:32.449604: train Epoch: [41][110/193]	Time 11.372 ( 6.243)	Data 10.802 ( 5.674)	Loss 8.3222e-02 (9.1611e-02) 
2023-05-27 17:03:33.773070: train Epoch: [41][111/193]	Time  1.323 ( 6.199)	Data  0.759 ( 5.630)	Loss 3.8081e-02 (9.1133e-02) 
2023-05-27 17:03:44.798931: train Epoch: [41][112/193]	Time 11.026 ( 6.242)	Data 10.460 ( 5.673)	Loss 8.6918e-02 (9.1096e-02) 
2023-05-27 17:03:46.569196: train Epoch: [41][113/193]	Time  1.770 ( 6.203)	Data  1.176 ( 5.633)	Loss 5.4413e-02 (9.0774e-02) 
2023-05-27 17:03:57.205650: train Epoch: [41][114/193]	Time 10.636 ( 6.241)	Data 10.074 ( 5.672)	Loss 6.0075e-02 (9.0507e-02) 
2023-05-27 17:03:58.412613: train Epoch: [41][115/193]	Time  1.207 ( 6.198)	Data  0.636 ( 5.629)	Loss 8.7515e-02 (9.0481e-02) 
2023-05-27 17:04:10.010949: train Epoch: [41][116/193]	Time 11.598 ( 6.244)	Data 11.026 ( 5.675)	Loss 2.3082e-01 (9.1681e-02) 
2023-05-27 17:04:10.573809: train Epoch: [41][117/193]	Time  0.563 ( 6.196)	Data  0.001 ( 5.627)	Loss 6.3712e-02 (9.1444e-02) 
2023-05-27 17:04:22.822619: train Epoch: [41][118/193]	Time 12.249 ( 6.247)	Data 11.688 ( 5.678)	Loss 9.3409e-02 (9.1460e-02) 
2023-05-27 17:04:23.386390: train Epoch: [41][119/193]	Time  0.564 ( 6.199)	Data  0.001 ( 5.630)	Loss 7.2340e-02 (9.1301e-02) 
2023-05-27 17:04:35.354275: train Epoch: [41][120/193]	Time 11.968 ( 6.247)	Data 11.406 ( 5.678)	Loss 8.1042e-02 (9.1216e-02) 
2023-05-27 17:04:35.925153: train Epoch: [41][121/193]	Time  0.571 ( 6.200)	Data  0.001 ( 5.631)	Loss 4.7579e-02 (9.0858e-02) 
2023-05-27 17:04:47.787565: train Epoch: [41][122/193]	Time 11.862 ( 6.246)	Data 11.293 ( 5.677)	Loss 2.3821e-01 (9.2056e-02) 
2023-05-27 17:04:48.357816: train Epoch: [41][123/193]	Time  0.570 ( 6.201)	Data  0.001 ( 5.632)	Loss 6.9084e-02 (9.1871e-02) 
2023-05-27 17:05:00.238875: train Epoch: [41][124/193]	Time 11.881 ( 6.246)	Data 11.305 ( 5.677)	Loss 6.3977e-02 (9.1648e-02) 
2023-05-27 17:05:00.931922: train Epoch: [41][125/193]	Time  0.693 ( 6.202)	Data  0.122 ( 5.633)	Loss 8.6851e-02 (9.1610e-02) 
2023-05-27 17:05:13.093851: train Epoch: [41][126/193]	Time 12.162 ( 6.249)	Data 11.564 ( 5.680)	Loss 9.6075e-02 (9.1645e-02) 
2023-05-27 17:05:13.671338: train Epoch: [41][127/193]	Time  0.577 ( 6.205)	Data  0.001 ( 5.635)	Loss 6.0836e-02 (9.1404e-02) 
2023-05-27 17:05:25.512581: train Epoch: [41][128/193]	Time 11.841 ( 6.248)	Data 11.280 ( 5.679)	Loss 6.9089e-02 (9.1231e-02) 
2023-05-27 17:05:26.075747: train Epoch: [41][129/193]	Time  0.563 ( 6.205)	Data  0.001 ( 5.635)	Loss 9.5246e-02 (9.1262e-02) 
2023-05-27 17:05:38.066204: train Epoch: [41][130/193]	Time 11.990 ( 6.249)	Data 11.427 ( 5.680)	Loss 5.0361e-02 (9.0950e-02) 
2023-05-27 17:05:38.628957: train Epoch: [41][131/193]	Time  0.563 ( 6.206)	Data  0.001 ( 5.637)	Loss 5.7650e-02 (9.0698e-02) 
2023-05-27 17:05:50.405744: train Epoch: [41][132/193]	Time 11.777 ( 6.248)	Data 11.205 ( 5.678)	Loss 6.3146e-02 (9.0491e-02) 
2023-05-27 17:05:50.969709: train Epoch: [41][133/193]	Time  0.564 ( 6.205)	Data  0.001 ( 5.636)	Loss 9.4915e-02 (9.0524e-02) 
2023-05-27 17:06:02.846544: train Epoch: [41][134/193]	Time 11.877 ( 6.247)	Data 11.312 ( 5.678)	Loss 6.1944e-02 (9.0312e-02) 
2023-05-27 17:06:03.422702: train Epoch: [41][135/193]	Time  0.576 ( 6.205)	Data  0.001 ( 5.636)	Loss 1.2109e-01 (9.0538e-02) 
2023-05-27 17:06:15.342416: train Epoch: [41][136/193]	Time 11.920 ( 6.247)	Data 11.352 ( 5.678)	Loss 1.0516e-01 (9.0645e-02) 
2023-05-27 17:06:15.904904: train Epoch: [41][137/193]	Time  0.562 ( 6.206)	Data  0.001 ( 5.637)	Loss 5.3393e-02 (9.0375e-02) 
2023-05-27 17:06:27.534893: train Epoch: [41][138/193]	Time 11.630 ( 6.245)	Data 11.063 ( 5.676)	Loss 1.5869e-01 (9.0866e-02) 
2023-05-27 17:06:28.096545: train Epoch: [41][139/193]	Time  0.562 ( 6.204)	Data  0.001 ( 5.635)	Loss 1.8895e-01 (9.1567e-02) 
2023-05-27 17:06:40.295083: train Epoch: [41][140/193]	Time 12.199 ( 6.247)	Data 11.638 ( 5.678)	Loss 6.1557e-02 (9.1354e-02) 
2023-05-27 17:06:40.864266: train Epoch: [41][141/193]	Time  0.569 ( 6.207)	Data  0.001 ( 5.638)	Loss 6.8528e-02 (9.1193e-02) 
2023-05-27 17:06:52.851910: train Epoch: [41][142/193]	Time 11.988 ( 6.247)	Data 11.419 ( 5.679)	Loss 5.8446e-02 (9.0964e-02) 
2023-05-27 17:06:53.418869: train Epoch: [41][143/193]	Time  0.567 ( 6.208)	Data  0.001 ( 5.639)	Loss 7.0552e-02 (9.0823e-02) 
2023-05-27 17:07:05.189102: train Epoch: [41][144/193]	Time 11.770 ( 6.246)	Data 11.207 ( 5.677)	Loss 1.5563e-01 (9.1270e-02) 
2023-05-27 17:07:05.751736: train Epoch: [41][145/193]	Time  0.563 ( 6.207)	Data  0.001 ( 5.639)	Loss 7.7741e-02 (9.1177e-02) 
2023-05-27 17:07:17.759970: train Epoch: [41][146/193]	Time 12.008 ( 6.247)	Data 11.428 ( 5.678)	Loss 3.4111e-02 (9.0789e-02) 
2023-05-27 17:07:18.321769: train Epoch: [41][147/193]	Time  0.562 ( 6.208)	Data  0.001 ( 5.640)	Loss 7.2200e-02 (9.0663e-02) 
2023-05-27 17:07:30.128937: train Epoch: [41][148/193]	Time 11.807 ( 6.246)	Data 11.245 ( 5.677)	Loss 4.5933e-02 (9.0363e-02) 
2023-05-27 17:07:30.690987: train Epoch: [41][149/193]	Time  0.562 ( 6.208)	Data  0.001 ( 5.639)	Loss 6.2072e-02 (9.0174e-02) 
2023-05-27 17:07:42.605703: train Epoch: [41][150/193]	Time 11.915 ( 6.246)	Data 11.347 ( 5.677)	Loss 9.1472e-02 (9.0183e-02) 
2023-05-27 17:07:43.173484: train Epoch: [41][151/193]	Time  0.568 ( 6.209)	Data  0.001 ( 5.640)	Loss 8.5608e-02 (9.0153e-02) 
2023-05-27 17:07:55.130462: train Epoch: [41][152/193]	Time 11.957 ( 6.246)	Data 11.392 ( 5.677)	Loss 1.1973e-01 (9.0346e-02) 
2023-05-27 17:07:55.697135: train Epoch: [41][153/193]	Time  0.567 ( 6.209)	Data  0.001 ( 5.641)	Loss 6.2439e-02 (9.0165e-02) 
2023-05-27 17:08:07.261507: train Epoch: [41][154/193]	Time 11.564 ( 6.244)	Data 10.993 ( 5.675)	Loss 1.0475e-01 (9.0259e-02) 
2023-05-27 17:08:07.826560: train Epoch: [41][155/193]	Time  0.565 ( 6.207)	Data  0.001 ( 5.639)	Loss 5.8823e-02 (9.0058e-02) 
2023-05-27 17:08:19.719841: train Epoch: [41][156/193]	Time 11.893 ( 6.244)	Data 11.333 ( 5.675)	Loss 8.7543e-02 (9.0042e-02) 
2023-05-27 17:08:20.281718: train Epoch: [41][157/193]	Time  0.562 ( 6.208)	Data  0.001 ( 5.639)	Loss 5.5469e-02 (8.9823e-02) 
2023-05-27 17:08:32.466052: train Epoch: [41][158/193]	Time 12.184 ( 6.245)	Data 11.624 ( 5.677)	Loss 8.7866e-02 (8.9810e-02) 
2023-05-27 17:08:33.026925: train Epoch: [41][159/193]	Time  0.561 ( 6.210)	Data  0.001 ( 5.641)	Loss 8.6266e-02 (8.9788e-02) 
2023-05-27 17:08:44.989453: train Epoch: [41][160/193]	Time 11.963 ( 6.245)	Data 11.396 ( 5.677)	Loss 2.5114e-01 (9.0790e-02) 
2023-05-27 17:08:45.553353: train Epoch: [41][161/193]	Time  0.564 ( 6.210)	Data  0.001 ( 5.642)	Loss 4.0338e-02 (9.0479e-02) 
2023-05-27 17:08:57.727578: train Epoch: [41][162/193]	Time 12.174 ( 6.247)	Data 11.613 ( 5.679)	Loss 8.6237e-02 (9.0453e-02) 
2023-05-27 17:08:58.288177: train Epoch: [41][163/193]	Time  0.561 ( 6.212)	Data  0.001 ( 5.644)	Loss 5.5109e-02 (9.0237e-02) 
2023-05-27 17:09:09.692262: train Epoch: [41][164/193]	Time 11.404 ( 6.244)	Data 10.843 ( 5.675)	Loss 4.5668e-02 (8.9967e-02) 
2023-05-27 17:09:10.254072: train Epoch: [41][165/193]	Time  0.562 ( 6.209)	Data  0.001 ( 5.641)	Loss 7.8411e-02 (8.9898e-02) 
2023-05-27 17:09:22.527915: train Epoch: [41][166/193]	Time 12.274 ( 6.246)	Data 11.713 ( 5.678)	Loss 1.0223e-01 (8.9972e-02) 
2023-05-27 17:09:23.092242: train Epoch: [41][167/193]	Time  0.564 ( 6.212)	Data  0.001 ( 5.644)	Loss 7.6558e-02 (8.9892e-02) 
2023-05-27 17:09:34.692627: train Epoch: [41][168/193]	Time 11.600 ( 6.244)	Data 11.033 ( 5.676)	Loss 6.6360e-02 (8.9752e-02) 
2023-05-27 17:09:35.254435: train Epoch: [41][169/193]	Time  0.562 ( 6.210)	Data  0.001 ( 5.642)	Loss 1.5051e-01 (9.0110e-02) 
2023-05-27 17:09:47.222335: train Epoch: [41][170/193]	Time 11.968 ( 6.244)	Data 11.407 ( 5.676)	Loss 8.4091e-02 (9.0075e-02) 
2023-05-27 17:09:47.783967: train Epoch: [41][171/193]	Time  0.562 ( 6.211)	Data  0.001 ( 5.643)	Loss 1.0626e-01 (9.0169e-02) 
2023-05-27 17:09:59.475500: train Epoch: [41][172/193]	Time 11.692 ( 6.243)	Data 11.130 ( 5.675)	Loss 4.7956e-02 (8.9925e-02) 
2023-05-27 17:10:00.037985: train Epoch: [41][173/193]	Time  0.562 ( 6.210)	Data  0.001 ( 5.642)	Loss 7.2047e-02 (8.9822e-02) 
2023-05-27 17:10:11.301844: train Epoch: [41][174/193]	Time 11.264 ( 6.239)	Data 10.702 ( 5.671)	Loss 6.0856e-02 (8.9656e-02) 
2023-05-27 17:10:11.863572: train Epoch: [41][175/193]	Time  0.562 ( 6.207)	Data  0.001 ( 5.639)	Loss 9.6786e-02 (8.9697e-02) 
2023-05-27 17:10:23.553206: train Epoch: [41][176/193]	Time 11.690 ( 6.238)	Data 11.114 ( 5.670)	Loss 7.1229e-02 (8.9593e-02) 
2023-05-27 17:10:24.115256: train Epoch: [41][177/193]	Time  0.562 ( 6.206)	Data  0.001 ( 5.638)	Loss 7.4619e-02 (8.9509e-02) 
2023-05-27 17:10:35.528252: train Epoch: [41][178/193]	Time 11.413 ( 6.235)	Data 10.853 ( 5.667)	Loss 1.3671e-01 (8.9772e-02) 
2023-05-27 17:10:36.089119: train Epoch: [41][179/193]	Time  0.561 ( 6.203)	Data  0.001 ( 5.636)	Loss 1.5075e-01 (9.0111e-02) 
2023-05-27 17:10:47.940586: train Epoch: [41][180/193]	Time 11.851 ( 6.235)	Data 11.285 ( 5.667)	Loss 5.0396e-02 (8.9892e-02) 
2023-05-27 17:10:48.505411: train Epoch: [41][181/193]	Time  0.565 ( 6.203)	Data  0.001 ( 5.636)	Loss 9.3072e-02 (8.9909e-02) 
2023-05-27 17:11:00.092549: train Epoch: [41][182/193]	Time 11.587 ( 6.233)	Data 11.026 ( 5.665)	Loss 5.0466e-02 (8.9693e-02) 
2023-05-27 17:11:00.658957: train Epoch: [41][183/193]	Time  0.566 ( 6.202)	Data  0.001 ( 5.634)	Loss 7.3552e-02 (8.9606e-02) 
2023-05-27 17:11:12.335857: train Epoch: [41][184/193]	Time 11.677 ( 6.232)	Data 11.071 ( 5.664)	Loss 2.8489e-02 (8.9275e-02) 
2023-05-27 17:11:12.902876: train Epoch: [41][185/193]	Time  0.567 ( 6.201)	Data  0.001 ( 5.633)	Loss 1.8203e-01 (8.9774e-02) 
2023-05-27 17:11:24.447344: train Epoch: [41][186/193]	Time 11.544 ( 6.230)	Data 10.977 ( 5.662)	Loss 5.9968e-02 (8.9615e-02) 
2023-05-27 17:11:25.583343: train Epoch: [41][187/193]	Time  1.136 ( 6.203)	Data  0.570 ( 5.635)	Loss 8.5415e-02 (8.9592e-02) 
2023-05-27 17:11:36.941115: train Epoch: [41][188/193]	Time 11.358 ( 6.230)	Data 10.785 ( 5.662)	Loss 7.0572e-02 (8.9492e-02) 
2023-05-27 17:11:38.179374: train Epoch: [41][189/193]	Time  1.238 ( 6.204)	Data  0.665 ( 5.636)	Loss 4.4221e-02 (8.9253e-02) 
2023-05-27 17:11:49.648201: train Epoch: [41][190/193]	Time 11.469 ( 6.231)	Data 10.870 ( 5.663)	Loss 4.8386e-02 (8.9039e-02) 
2023-05-27 17:11:50.789402: train Epoch: [41][191/193]	Time  1.141 ( 6.205)	Data  0.577 ( 5.637)	Loss 5.6170e-02 (8.8868e-02) 
2023-05-27 17:12:00.976084: train Epoch: [41][192/193]	Time 10.187 ( 6.225)	Data  9.592 ( 5.657)	Loss 9.5259e-02 (8.8901e-02) 
2023-05-27 17:12:01.169689: Train Epoch done in 1201.6902695240278 s 
2023-05-27 17:12:09.722107: val Epoch: [41][ 0/72]	Time  7.614 ( 7.614)	Data  7.440 ( 7.440)	Loss 7.4789e-02 (7.4789e-02) 
2023-05-27 17:12:09.831524: val Epoch: [41][ 1/72]	Time  0.110 ( 3.862)	Data  0.002 ( 3.721)	Loss 6.6157e-02 (7.0473e-02) 
2023-05-27 17:12:15.619833: val Epoch: [41][ 2/72]	Time  5.788 ( 4.504)	Data  5.679 ( 4.374)	Loss 7.0647e-02 (7.0531e-02) 
2023-05-27 17:12:16.024563: val Epoch: [41][ 3/72]	Time  0.405 ( 3.479)	Data  0.297 ( 3.354)	Loss 7.8251e-02 (7.2461e-02) 
2023-05-27 17:12:21.864807: val Epoch: [41][ 4/72]	Time  5.840 ( 3.951)	Data  5.733 ( 3.830)	Loss 5.8320e-02 (6.9633e-02) 
2023-05-27 17:12:22.332925: val Epoch: [41][ 5/72]	Time  0.468 ( 3.371)	Data  0.360 ( 3.252)	Loss 2.9873e-01 (1.0782e-01) 
2023-05-27 17:12:28.281026: val Epoch: [41][ 6/72]	Time  5.948 ( 3.739)	Data  5.840 ( 3.621)	Loss 3.4232e-01 (1.4132e-01) 
2023-05-27 17:12:28.408324: val Epoch: [41][ 7/72]	Time  0.127 ( 3.288)	Data  0.019 ( 3.171)	Loss 1.6228e-01 (1.4394e-01) 
2023-05-27 17:12:34.672811: val Epoch: [41][ 8/72]	Time  6.264 ( 3.618)	Data  6.156 ( 3.503)	Loss 2.4451e-01 (1.5511e-01) 
2023-05-27 17:12:34.780680: val Epoch: [41][ 9/72]	Time  0.108 ( 3.267)	Data  0.001 ( 3.153)	Loss 5.3496e-02 (1.4495e-01) 
2023-05-27 17:12:40.653614: val Epoch: [41][10/72]	Time  5.873 ( 3.504)	Data  5.760 ( 3.390)	Loss 4.8332e-02 (1.3617e-01) 
2023-05-27 17:12:40.763544: val Epoch: [41][11/72]	Time  0.110 ( 3.221)	Data  0.001 ( 3.107)	Loss 4.4150e-02 (1.2850e-01) 
2023-05-27 17:12:46.754265: val Epoch: [41][12/72]	Time  5.991 ( 3.434)	Data  5.881 ( 3.321)	Loss 3.5573e-01 (1.4598e-01) 
2023-05-27 17:12:46.973109: val Epoch: [41][13/72]	Time  0.219 ( 3.205)	Data  0.110 ( 3.091)	Loss 2.5985e-01 (1.5411e-01) 
2023-05-27 17:12:53.253595: val Epoch: [41][14/72]	Time  6.280 ( 3.410)	Data  6.174 ( 3.297)	Loss 7.1792e-02 (1.4862e-01) 
2023-05-27 17:12:53.359629: val Epoch: [41][15/72]	Time  0.106 ( 3.203)	Data  0.001 ( 3.091)	Loss 3.2090e-01 (1.5939e-01) 
2023-05-27 17:12:59.334582: val Epoch: [41][16/72]	Time  5.975 ( 3.366)	Data  5.869 ( 3.254)	Loss 3.6765e-02 (1.5218e-01) 
2023-05-27 17:12:59.439576: val Epoch: [41][17/72]	Time  0.105 ( 3.185)	Data  0.000 ( 3.073)	Loss 2.1698e-01 (1.5578e-01) 
2023-05-27 17:13:05.506020: val Epoch: [41][18/72]	Time  6.066 ( 3.337)	Data  5.961 ( 3.225)	Loss 5.8890e-02 (1.5068e-01) 
2023-05-27 17:13:05.611490: val Epoch: [41][19/72]	Time  0.105 ( 3.175)	Data  0.001 ( 3.064)	Loss 4.4058e-02 (1.4535e-01) 
2023-05-27 17:13:11.762909: val Epoch: [41][20/72]	Time  6.151 ( 3.317)	Data  6.046 ( 3.206)	Loss 3.6695e-01 (1.5590e-01) 
2023-05-27 17:13:11.867915: val Epoch: [41][21/72]	Time  0.105 ( 3.171)	Data  0.001 ( 3.060)	Loss 3.7104e-02 (1.5050e-01) 
2023-05-27 17:13:17.689845: val Epoch: [41][22/72]	Time  5.822 ( 3.286)	Data  5.714 ( 3.176)	Loss 7.1101e-02 (1.4705e-01) 
2023-05-27 17:13:17.807362: val Epoch: [41][23/72]	Time  0.117 ( 3.154)	Data  0.012 ( 3.044)	Loss 1.2267e-01 (1.4603e-01) 
2023-05-27 17:13:24.349264: val Epoch: [41][24/72]	Time  6.542 ( 3.290)	Data  6.432 ( 3.180)	Loss 1.0807e-01 (1.4451e-01) 
2023-05-27 17:13:24.458537: val Epoch: [41][25/72]	Time  0.109 ( 3.167)	Data  0.000 ( 3.057)	Loss 8.2056e-02 (1.4211e-01) 
2023-05-27 17:13:30.885590: val Epoch: [41][26/72]	Time  6.427 ( 3.288)	Data  6.317 ( 3.178)	Loss 3.5742e-01 (1.5009e-01) 
2023-05-27 17:13:30.994361: val Epoch: [41][27/72]	Time  0.109 ( 3.175)	Data  0.000 ( 3.064)	Loss 4.7801e-02 (1.4643e-01) 
2023-05-27 17:13:37.116552: val Epoch: [41][28/72]	Time  6.122 ( 3.276)	Data  6.014 ( 3.166)	Loss 6.6296e-02 (1.4367e-01) 
2023-05-27 17:13:37.224710: val Epoch: [41][29/72]	Time  0.108 ( 3.171)	Data  0.001 ( 3.061)	Loss 1.7982e-01 (1.4487e-01) 
2023-05-27 17:13:43.405069: val Epoch: [41][30/72]	Time  6.180 ( 3.268)	Data  6.071 ( 3.158)	Loss 1.4354e-01 (1.4483e-01) 
2023-05-27 17:13:43.513432: val Epoch: [41][31/72]	Time  0.108 ( 3.169)	Data  0.001 ( 3.059)	Loss 5.5487e-02 (1.4204e-01) 
2023-05-27 17:13:49.560225: val Epoch: [41][32/72]	Time  6.047 ( 3.256)	Data  5.942 ( 3.146)	Loss 5.5541e-02 (1.3942e-01) 
2023-05-27 17:13:49.664708: val Epoch: [41][33/72]	Time  0.104 ( 3.163)	Data  0.001 ( 3.054)	Loss 4.1949e-02 (1.3655e-01) 
2023-05-27 17:13:55.427452: val Epoch: [41][34/72]	Time  5.763 ( 3.238)	Data  5.657 ( 3.128)	Loss 5.9848e-02 (1.3436e-01) 
2023-05-27 17:13:55.532743: val Epoch: [41][35/72]	Time  0.105 ( 3.151)	Data  0.001 ( 3.041)	Loss 1.1361e-01 (1.3378e-01) 
2023-05-27 17:14:01.679977: val Epoch: [41][36/72]	Time  6.147 ( 3.232)	Data  6.041 ( 3.123)	Loss 6.6481e-02 (1.3196e-01) 
2023-05-27 17:14:01.785015: val Epoch: [41][37/72]	Time  0.105 ( 3.149)	Data  0.001 ( 3.040)	Loss 2.9234e-02 (1.2926e-01) 
2023-05-27 17:14:07.900339: val Epoch: [41][38/72]	Time  6.115 ( 3.225)	Data  6.009 ( 3.117)	Loss 4.4572e-01 (1.3738e-01) 
2023-05-27 17:14:08.005343: val Epoch: [41][39/72]	Time  0.105 ( 3.147)	Data  0.001 ( 3.039)	Loss 5.6192e-02 (1.3535e-01) 
2023-05-27 17:14:14.295668: val Epoch: [41][40/72]	Time  6.290 ( 3.224)	Data  6.180 ( 3.115)	Loss 8.8785e-02 (1.3421e-01) 
2023-05-27 17:14:14.402902: val Epoch: [41][41/72]	Time  0.107 ( 3.150)	Data  0.000 ( 3.041)	Loss 7.9528e-02 (1.3291e-01) 
2023-05-27 17:14:20.719896: val Epoch: [41][42/72]	Time  6.317 ( 3.224)	Data  6.211 ( 3.115)	Loss 6.5457e-02 (1.3134e-01) 
2023-05-27 17:14:20.825037: val Epoch: [41][43/72]	Time  0.105 ( 3.153)	Data  0.001 ( 3.044)	Loss 1.5567e-01 (1.3189e-01) 
2023-05-27 17:14:26.701196: val Epoch: [41][44/72]	Time  5.876 ( 3.213)	Data  5.770 ( 3.105)	Loss 9.5478e-02 (1.3108e-01) 
2023-05-27 17:14:26.806729: val Epoch: [41][45/72]	Time  0.106 ( 3.146)	Data  0.000 ( 3.037)	Loss 4.8696e-02 (1.2929e-01) 
2023-05-27 17:14:32.944739: val Epoch: [41][46/72]	Time  6.138 ( 3.209)	Data  6.033 ( 3.101)	Loss 3.9229e-01 (1.3489e-01) 
2023-05-27 17:14:33.050170: val Epoch: [41][47/72]	Time  0.105 ( 3.145)	Data  0.000 ( 3.036)	Loss 5.0430e-02 (1.3313e-01) 
2023-05-27 17:14:38.919054: val Epoch: [41][48/72]	Time  5.869 ( 3.200)	Data  5.763 ( 3.092)	Loss 1.1114e-01 (1.3268e-01) 
2023-05-27 17:14:39.024613: val Epoch: [41][49/72]	Time  0.106 ( 3.138)	Data  0.001 ( 3.030)	Loss 1.0103e-01 (1.3205e-01) 
2023-05-27 17:14:44.830337: val Epoch: [41][50/72]	Time  5.806 ( 3.191)	Data  5.701 ( 3.082)	Loss 9.8835e-02 (1.3140e-01) 
2023-05-27 17:14:44.935337: val Epoch: [41][51/72]	Time  0.105 ( 3.131)	Data  0.000 ( 3.023)	Loss 3.1479e-01 (1.3492e-01) 
2023-05-27 17:14:51.266130: val Epoch: [41][52/72]	Time  6.331 ( 3.192)	Data  6.225 ( 3.084)	Loss 9.6917e-02 (1.3421e-01) 
2023-05-27 17:14:51.371143: val Epoch: [41][53/72]	Time  0.105 ( 3.135)	Data  0.001 ( 3.027)	Loss 6.5153e-02 (1.3293e-01) 
2023-05-27 17:14:57.530164: val Epoch: [41][54/72]	Time  6.159 ( 3.190)	Data  6.049 ( 3.081)	Loss 1.2683e-01 (1.3282e-01) 
2023-05-27 17:14:57.635441: val Epoch: [41][55/72]	Time  0.105 ( 3.134)	Data  0.000 ( 3.026)	Loss 8.2854e-02 (1.3192e-01) 
2023-05-27 17:15:03.561030: val Epoch: [41][56/72]	Time  5.926 ( 3.183)	Data  5.820 ( 3.075)	Loss 1.3110e-01 (1.3191e-01) 
2023-05-27 17:15:03.666989: val Epoch: [41][57/72]	Time  0.106 ( 3.130)	Data  0.001 ( 3.022)	Loss 6.7649e-02 (1.3080e-01) 
2023-05-27 17:15:09.721064: val Epoch: [41][58/72]	Time  6.054 ( 3.180)	Data  5.948 ( 3.072)	Loss 3.6654e-02 (1.2921e-01) 
2023-05-27 17:15:09.825760: val Epoch: [41][59/72]	Time  0.105 ( 3.129)	Data  0.001 ( 3.021)	Loss 2.6962e-01 (1.3155e-01) 
2023-05-27 17:15:16.136405: val Epoch: [41][60/72]	Time  6.311 ( 3.181)	Data  6.205 ( 3.073)	Loss 1.0584e-01 (1.3112e-01) 
2023-05-27 17:15:16.241272: val Epoch: [41][61/72]	Time  0.105 ( 3.131)	Data  0.001 ( 3.023)	Loss 4.8679e-02 (1.2979e-01) 
2023-05-27 17:15:22.411846: val Epoch: [41][62/72]	Time  6.171 ( 3.179)	Data  6.065 ( 3.072)	Loss 6.3918e-02 (1.2875e-01) 
2023-05-27 17:15:22.516720: val Epoch: [41][63/72]	Time  0.105 ( 3.131)	Data  0.001 ( 3.024)	Loss 1.1251e-01 (1.2849e-01) 
2023-05-27 17:15:28.563374: val Epoch: [41][64/72]	Time  6.047 ( 3.176)	Data  5.938 ( 3.069)	Loss 1.2012e-01 (1.2837e-01) 
2023-05-27 17:15:28.671976: val Epoch: [41][65/72]	Time  0.109 ( 3.130)	Data  0.001 ( 3.022)	Loss 7.2734e-02 (1.2752e-01) 
2023-05-27 17:15:34.441437: val Epoch: [41][66/72]	Time  5.769 ( 3.169)	Data  5.660 ( 3.062)	Loss 4.3092e-02 (1.2626e-01) 
2023-05-27 17:15:34.550208: val Epoch: [41][67/72]	Time  0.109 ( 3.124)	Data  0.001 ( 3.017)	Loss 3.1501e-02 (1.2487e-01) 
2023-05-27 17:15:40.374070: val Epoch: [41][68/72]	Time  5.824 ( 3.163)	Data  5.719 ( 3.056)	Loss 1.4282e-01 (1.2513e-01) 
2023-05-27 17:15:40.479313: val Epoch: [41][69/72]	Time  0.105 ( 3.120)	Data  0.000 ( 3.012)	Loss 1.4611e-01 (1.2543e-01) 
2023-05-27 17:15:46.306717: val Epoch: [41][70/72]	Time  5.827 ( 3.158)	Data  5.717 ( 3.050)	Loss 8.9411e-02 (1.2492e-01) 
2023-05-27 17:15:46.416419: val Epoch: [41][71/72]	Time  0.110 ( 3.115)	Data  0.000 ( 3.008)	Loss 8.6547e-02 (1.2439e-01) 
2023-05-27 17:15:46.775323: Epoch 41 :Val : ['ET : 0.7627074718475342', 'TC : 0.7904969453811646', 'WT : 0.8689184188842773'] 
2023-05-27 17:15:46.778128: Epoch 41 :Val : ['ET : 0.7627074718475342', 'TC : 0.7904969453811646', 'WT : 0.8689184188842773'] 
2023-05-27 17:15:46.780195: Saving the model with DSC 0.8097105622291565 
2023-05-27 17:15:47.455560: Val epoch done in 226.28585906297667 s 
2023-05-27 17:15:47.469728: Batches per epoch:  193 
2023-05-27 17:16:01.800688: train Epoch: [42][  0/193]	Time 14.331 (14.331)	Data 13.745 (13.745)	Loss 1.9542e-01 (1.9542e-01) 
2023-05-27 17:16:02.373904: train Epoch: [42][  1/193]	Time  0.573 ( 7.452)	Data  0.001 ( 6.873)	Loss 1.0367e-01 (1.4954e-01) 
2023-05-27 17:16:14.521562: train Epoch: [42][  2/193]	Time 12.148 ( 9.017)	Data 11.585 ( 8.444)	Loss 9.0810e-02 (1.2997e-01) 
2023-05-27 17:16:15.086013: train Epoch: [42][  3/193]	Time  0.564 ( 6.904)	Data  0.001 ( 6.333)	Loss 7.9849e-02 (1.1744e-01) 
2023-05-27 17:16:26.574141: train Epoch: [42][  4/193]	Time 11.488 ( 7.821)	Data 10.926 ( 7.252)	Loss 7.1353e-02 (1.0822e-01) 
2023-05-27 17:16:27.164615: train Epoch: [42][  5/193]	Time  0.590 ( 6.616)	Data  0.027 ( 6.048)	Loss 1.0383e-01 (1.0749e-01) 
2023-05-27 17:16:38.518405: train Epoch: [42][  6/193]	Time 11.354 ( 7.293)	Data 10.782 ( 6.724)	Loss 9.3321e-02 (1.0546e-01) 
2023-05-27 17:16:39.432310: train Epoch: [42][  7/193]	Time  0.914 ( 6.495)	Data  0.352 ( 5.928)	Loss 4.3919e-02 (9.7771e-02) 
2023-05-27 17:16:50.506717: train Epoch: [42][  8/193]	Time 11.074 ( 7.004)	Data 10.507 ( 6.436)	Loss 1.1161e-01 (9.9309e-02) 
2023-05-27 17:16:51.657225: train Epoch: [42][  9/193]	Time  1.151 ( 6.419)	Data  0.589 ( 5.852)	Loss 4.4431e-02 (9.3821e-02) 
2023-05-27 17:17:02.859677: train Epoch: [42][ 10/193]	Time 11.202 ( 6.854)	Data 10.640 ( 6.287)	Loss 9.6803e-02 (9.4092e-02) 
2023-05-27 17:17:03.946916: train Epoch: [42][ 11/193]	Time  1.087 ( 6.373)	Data  0.525 ( 5.807)	Loss 7.6673e-02 (9.2640e-02) 
2023-05-27 17:17:14.939176: train Epoch: [42][ 12/193]	Time 10.992 ( 6.728)	Data 10.431 ( 6.163)	Loss 3.9705e-02 (8.8568e-02) 
2023-05-27 17:17:15.843371: train Epoch: [42][ 13/193]	Time  0.904 ( 6.312)	Data  0.342 ( 5.747)	Loss 1.1587e-01 (9.0519e-02) 
2023-05-27 17:17:27.216760: train Epoch: [42][ 14/193]	Time 11.373 ( 6.650)	Data 10.775 ( 6.082)	Loss 6.1430e-02 (8.8580e-02) 
2023-05-27 17:17:27.924997: train Epoch: [42][ 15/193]	Time  0.708 ( 6.278)	Data  0.149 ( 5.711)	Loss 6.4980e-02 (8.7105e-02) 
2023-05-27 17:17:39.268811: train Epoch: [42][ 16/193]	Time 11.344 ( 6.576)	Data 10.779 ( 6.009)	Loss 6.8296e-02 (8.5998e-02) 
2023-05-27 17:17:39.933920: train Epoch: [42][ 17/193]	Time  0.665 ( 6.248)	Data  0.105 ( 5.681)	Loss 5.1057e-02 (8.4057e-02) 
2023-05-27 17:17:51.644239: train Epoch: [42][ 18/193]	Time 11.710 ( 6.535)	Data 11.141 ( 5.969)	Loss 5.7965e-02 (8.2684e-02) 
2023-05-27 17:17:52.215330: train Epoch: [42][ 19/193]	Time  0.571 ( 6.237)	Data  0.001 ( 5.670)	Loss 9.2886e-02 (8.3194e-02) 
2023-05-27 17:18:03.563843: train Epoch: [42][ 20/193]	Time 11.349 ( 6.481)	Data 10.749 ( 5.912)	Loss 1.1616e-01 (8.4764e-02) 
2023-05-27 17:18:04.144733: train Epoch: [42][ 21/193]	Time  0.581 ( 6.212)	Data  0.014 ( 5.644)	Loss 4.8428e-02 (8.3112e-02) 
2023-05-27 17:18:14.167536: train Epoch: [42][ 22/193]	Time 10.023 ( 6.378)	Data  9.463 ( 5.810)	Loss 9.6625e-02 (8.3700e-02) 
2023-05-27 17:18:15.466615: train Epoch: [42][ 23/193]	Time  1.299 ( 6.167)	Data  0.735 ( 5.599)	Loss 6.0582e-02 (8.2736e-02) 
2023-05-27 17:18:26.852708: train Epoch: [42][ 24/193]	Time 11.386 ( 6.375)	Data 10.818 ( 5.807)	Loss 1.0521e-01 (8.3636e-02) 
2023-05-27 17:18:28.027617: train Epoch: [42][ 25/193]	Time  1.175 ( 6.175)	Data  0.603 ( 5.607)	Loss 1.2711e-01 (8.5308e-02) 
2023-05-27 17:18:37.844418: train Epoch: [42][ 26/193]	Time  9.817 ( 6.310)	Data  9.252 ( 5.742)	Loss 6.4055e-02 (8.4521e-02) 
2023-05-27 17:18:39.335489: train Epoch: [42][ 27/193]	Time  1.491 ( 6.138)	Data  0.900 ( 5.569)	Loss 8.4454e-02 (8.4518e-02) 
2023-05-27 17:18:49.204917: train Epoch: [42][ 28/193]	Time  9.869 ( 6.267)	Data  9.303 ( 5.698)	Loss 8.8495e-02 (8.4655e-02) 
2023-05-27 17:18:50.748248: train Epoch: [42][ 29/193]	Time  1.543 ( 6.109)	Data  0.966 ( 5.540)	Loss 7.3973e-02 (8.4299e-02) 
2023-05-27 17:19:01.253957: train Epoch: [42][ 30/193]	Time 10.506 ( 6.251)	Data  9.936 ( 5.682)	Loss 5.6748e-02 (8.3410e-02) 
2023-05-27 17:19:02.905275: train Epoch: [42][ 31/193]	Time  1.651 ( 6.107)	Data  1.091 ( 5.539)	Loss 8.3601e-02 (8.3416e-02) 
2023-05-27 17:19:13.484031: train Epoch: [42][ 32/193]	Time 10.579 ( 6.243)	Data 10.017 ( 5.674)	Loss 1.0380e-01 (8.4034e-02) 
2023-05-27 17:19:14.898471: train Epoch: [42][ 33/193]	Time  1.414 ( 6.101)	Data  0.853 ( 5.532)	Loss 9.0643e-02 (8.4228e-02) 
2023-05-27 17:19:25.703610: train Epoch: [42][ 34/193]	Time 10.805 ( 6.235)	Data 10.244 ( 5.667)	Loss 1.2207e-01 (8.5309e-02) 
2023-05-27 17:19:27.236295: train Epoch: [42][ 35/193]	Time  1.533 ( 6.105)	Data  0.962 ( 5.536)	Loss 1.1957e-01 (8.6261e-02) 
2023-05-27 17:19:37.732613: train Epoch: [42][ 36/193]	Time 10.496 ( 6.223)	Data  9.934 ( 5.655)	Loss 7.9343e-02 (8.6074e-02) 
2023-05-27 17:19:39.480732: train Epoch: [42][ 37/193]	Time  1.748 ( 6.106)	Data  1.187 ( 5.538)	Loss 5.8264e-02 (8.5342e-02) 
2023-05-27 17:19:49.874086: train Epoch: [42][ 38/193]	Time 10.393 ( 6.215)	Data  9.826 ( 5.648)	Loss 7.2091e-02 (8.5003e-02) 
2023-05-27 17:19:51.581678: train Epoch: [42][ 39/193]	Time  1.708 ( 6.103)	Data  1.133 ( 5.535)	Loss 4.0167e-02 (8.3882e-02) 
2023-05-27 17:20:01.770866: train Epoch: [42][ 40/193]	Time 10.189 ( 6.202)	Data  9.630 ( 5.635)	Loss 4.8086e-02 (8.3009e-02) 
2023-05-27 17:20:04.211984: train Epoch: [42][ 41/193]	Time  2.441 ( 6.113)	Data  1.881 ( 5.545)	Loss 6.8947e-02 (8.2674e-02) 
2023-05-27 17:20:14.056181: train Epoch: [42][ 42/193]	Time  9.844 ( 6.200)	Data  9.284 ( 5.632)	Loss 5.8892e-02 (8.2121e-02) 
2023-05-27 17:20:16.512955: train Epoch: [42][ 43/193]	Time  2.457 ( 6.115)	Data  1.896 ( 5.547)	Loss 4.0035e-02 (8.1164e-02) 
2023-05-27 17:20:25.935437: train Epoch: [42][ 44/193]	Time  9.422 ( 6.188)	Data  8.862 ( 5.621)	Loss 1.0235e-01 (8.1635e-02) 
2023-05-27 17:20:28.767579: train Epoch: [42][ 45/193]	Time  2.832 ( 6.115)	Data  2.263 ( 5.548)	Loss 8.0475e-02 (8.1610e-02) 
2023-05-27 17:20:38.275588: train Epoch: [42][ 46/193]	Time  9.508 ( 6.187)	Data  8.935 ( 5.620)	Loss 9.3682e-02 (8.1867e-02) 
2023-05-27 17:20:41.259167: train Epoch: [42][ 47/193]	Time  2.984 ( 6.121)	Data  2.417 ( 5.553)	Loss 6.5507e-02 (8.1526e-02) 
2023-05-27 17:20:50.222160: train Epoch: [42][ 48/193]	Time  8.963 ( 6.179)	Data  8.353 ( 5.610)	Loss 7.8538e-02 (8.1465e-02) 
2023-05-27 17:20:53.730767: train Epoch: [42][ 49/193]	Time  3.509 ( 6.125)	Data  2.947 ( 5.557)	Loss 1.0331e-01 (8.1902e-02) 
2023-05-27 17:21:02.636988: train Epoch: [42][ 50/193]	Time  8.906 ( 6.180)	Data  8.275 ( 5.610)	Loss 8.4058e-02 (8.1944e-02) 
2023-05-27 17:21:05.969829: train Epoch: [42][ 51/193]	Time  3.333 ( 6.125)	Data  2.766 ( 5.556)	Loss 1.4435e-01 (8.3144e-02) 
2023-05-27 17:21:14.644108: train Epoch: [42][ 52/193]	Time  8.674 ( 6.173)	Data  8.108 ( 5.604)	Loss 6.9542e-02 (8.2887e-02) 
2023-05-27 17:21:18.610553: train Epoch: [42][ 53/193]	Time  3.966 ( 6.132)	Data  3.391 ( 5.563)	Loss 1.0271e-01 (8.3255e-02) 
2023-05-27 17:21:27.293292: train Epoch: [42][ 54/193]	Time  8.683 ( 6.179)	Data  8.114 ( 5.609)	Loss 7.9225e-02 (8.3181e-02) 
2023-05-27 17:21:30.805788: train Epoch: [42][ 55/193]	Time  3.513 ( 6.131)	Data  2.945 ( 5.562)	Loss 1.1916e-01 (8.3824e-02) 
2023-05-27 17:21:39.381216: train Epoch: [42][ 56/193]	Time  8.575 ( 6.174)	Data  8.010 ( 5.605)	Loss 1.6738e-01 (8.5290e-02) 
2023-05-27 17:21:42.739556: train Epoch: [42][ 57/193]	Time  3.358 ( 6.125)	Data  2.793 ( 5.556)	Loss 4.3997e-02 (8.4578e-02) 
2023-05-27 17:21:51.766867: train Epoch: [42][ 58/193]	Time  9.027 ( 6.175)	Data  8.459 ( 5.605)	Loss 7.1321e-02 (8.4353e-02) 
2023-05-27 17:21:54.841493: train Epoch: [42][ 59/193]	Time  3.075 ( 6.123)	Data  2.509 ( 5.554)	Loss 1.3277e-01 (8.5160e-02) 
2023-05-27 17:22:03.892619: train Epoch: [42][ 60/193]	Time  9.051 ( 6.171)	Data  8.477 ( 5.602)	Loss 1.2011e-01 (8.5733e-02) 
2023-05-27 17:22:07.389903: train Epoch: [42][ 61/193]	Time  3.497 ( 6.128)	Data  2.931 ( 5.559)	Loss 4.6608e-02 (8.5102e-02) 
2023-05-27 17:22:16.242866: train Epoch: [42][ 62/193]	Time  8.853 ( 6.171)	Data  8.286 ( 5.602)	Loss 9.0845e-02 (8.5193e-02) 
2023-05-27 17:22:19.383339: train Epoch: [42][ 63/193]	Time  3.140 ( 6.124)	Data  2.555 ( 5.554)	Loss 6.2164e-02 (8.4833e-02) 
2023-05-27 17:22:27.916498: train Epoch: [42][ 64/193]	Time  8.533 ( 6.161)	Data  7.970 ( 5.591)	Loss 6.1666e-02 (8.4477e-02) 
2023-05-27 17:22:31.005812: train Epoch: [42][ 65/193]	Time  3.089 ( 6.114)	Data  2.517 ( 5.545)	Loss 5.9513e-02 (8.4098e-02) 
2023-05-27 17:22:40.306214: train Epoch: [42][ 66/193]	Time  9.300 ( 6.162)	Data  8.739 ( 5.593)	Loss 6.8758e-02 (8.3870e-02) 
2023-05-27 17:22:43.439979: train Epoch: [42][ 67/193]	Time  3.134 ( 6.117)	Data  2.563 ( 5.548)	Loss 7.3791e-02 (8.3721e-02) 
2023-05-27 17:22:52.373620: train Epoch: [42][ 68/193]	Time  8.934 ( 6.158)	Data  8.367 ( 5.589)	Loss 1.3677e-01 (8.4490e-02) 
2023-05-27 17:22:56.072780: train Epoch: [42][ 69/193]	Time  3.699 ( 6.123)	Data  3.120 ( 5.554)	Loss 9.0851e-02 (8.4581e-02) 
2023-05-27 17:23:04.582511: train Epoch: [42][ 70/193]	Time  8.510 ( 6.157)	Data  7.949 ( 5.587)	Loss 8.9637e-02 (8.4652e-02) 
2023-05-27 17:23:08.190884: train Epoch: [42][ 71/193]	Time  3.608 ( 6.121)	Data  3.003 ( 5.551)	Loss 6.2901e-02 (8.4350e-02) 
2023-05-27 17:23:16.905921: train Epoch: [42][ 72/193]	Time  8.715 ( 6.157)	Data  8.148 ( 5.587)	Loss 1.6751e-01 (8.5489e-02) 
2023-05-27 17:23:20.568482: train Epoch: [42][ 73/193]	Time  3.663 ( 6.123)	Data  3.035 ( 5.553)	Loss 5.7583e-02 (8.5112e-02) 
2023-05-27 17:23:28.853910: train Epoch: [42][ 74/193]	Time  8.285 ( 6.152)	Data  7.717 ( 5.581)	Loss 8.4783e-02 (8.5108e-02) 
2023-05-27 17:23:32.830636: train Epoch: [42][ 75/193]	Time  3.977 ( 6.123)	Data  3.370 ( 5.552)	Loss 5.5839e-02 (8.4723e-02) 
2023-05-27 17:23:40.954433: train Epoch: [42][ 76/193]	Time  8.124 ( 6.149)	Data  7.556 ( 5.578)	Loss 6.1248e-02 (8.4418e-02) 
2023-05-27 17:23:45.246807: train Epoch: [42][ 77/193]	Time  4.292 ( 6.125)	Data  3.706 ( 5.554)	Loss 3.6261e-02 (8.3800e-02) 
2023-05-27 17:23:53.348539: train Epoch: [42][ 78/193]	Time  8.102 ( 6.150)	Data  7.531 ( 5.579)	Loss 8.3428e-02 (8.3796e-02) 
2023-05-27 17:23:57.497653: train Epoch: [42][ 79/193]	Time  4.149 ( 6.125)	Data  3.581 ( 5.554)	Loss 7.0753e-02 (8.3633e-02) 
2023-05-27 17:24:05.297177: train Epoch: [42][ 80/193]	Time  7.800 ( 6.146)	Data  7.233 ( 5.575)	Loss 5.7416e-02 (8.3309e-02) 
2023-05-27 17:24:09.802039: train Epoch: [42][ 81/193]	Time  4.505 ( 6.126)	Data  3.935 ( 5.555)	Loss 6.9568e-02 (8.3141e-02) 
2023-05-27 17:24:17.281321: train Epoch: [42][ 82/193]	Time  7.479 ( 6.142)	Data  6.901 ( 5.571)	Loss 9.2588e-02 (8.3255e-02) 
2023-05-27 17:24:21.787951: train Epoch: [42][ 83/193]	Time  4.507 ( 6.123)	Data  3.936 ( 5.552)	Loss 9.2338e-02 (8.3363e-02) 
2023-05-27 17:24:29.925424: train Epoch: [42][ 84/193]	Time  8.137 ( 6.147)	Data  7.557 ( 5.575)	Loss 8.3057e-02 (8.3360e-02) 
2023-05-27 17:24:34.545707: train Epoch: [42][ 85/193]	Time  4.620 ( 6.129)	Data  4.045 ( 5.558)	Loss 8.5834e-02 (8.3389e-02) 
2023-05-27 17:24:41.973263: train Epoch: [42][ 86/193]	Time  7.428 ( 6.144)	Data  6.860 ( 5.573)	Loss 6.6876e-02 (8.3199e-02) 
2023-05-27 17:24:46.379950: train Epoch: [42][ 87/193]	Time  4.407 ( 6.124)	Data  3.844 ( 5.553)	Loss 6.5131e-02 (8.2993e-02) 
2023-05-27 17:24:54.226195: train Epoch: [42][ 88/193]	Time  7.846 ( 6.143)	Data  7.285 ( 5.572)	Loss 6.6679e-02 (8.2810e-02) 
2023-05-27 17:24:58.984531: train Epoch: [42][ 89/193]	Time  4.758 ( 6.128)	Data  4.195 ( 5.557)	Loss 8.1578e-02 (8.2796e-02) 
2023-05-27 17:25:06.164994: train Epoch: [42][ 90/193]	Time  7.180 ( 6.140)	Data  6.619 ( 5.569)	Loss 5.5711e-02 (8.2499e-02) 
2023-05-27 17:25:10.315444: train Epoch: [42][ 91/193]	Time  4.150 ( 6.118)	Data  3.587 ( 5.547)	Loss 6.5855e-02 (8.2318e-02) 
2023-05-27 17:25:17.580754: train Epoch: [42][ 92/193]	Time  7.265 ( 6.130)	Data  6.696 ( 5.560)	Loss 6.1053e-02 (8.2089e-02) 
2023-05-27 17:25:21.267174: train Epoch: [42][ 93/193]	Time  3.686 ( 6.104)	Data  3.123 ( 5.534)	Loss 9.9043e-02 (8.2270e-02) 
2023-05-27 17:25:28.952797: train Epoch: [42][ 94/193]	Time  7.686 ( 6.121)	Data  7.124 ( 5.550)	Loss 1.1417e-01 (8.2605e-02) 
2023-05-27 17:25:33.742366: train Epoch: [42][ 95/193]	Time  4.790 ( 6.107)	Data  4.222 ( 5.537)	Loss 5.8502e-02 (8.2354e-02) 
2023-05-27 17:25:41.169753: train Epoch: [42][ 96/193]	Time  7.427 ( 6.121)	Data  6.866 ( 5.550)	Loss 4.2600e-02 (8.1944e-02) 
2023-05-27 17:25:46.170949: train Epoch: [42][ 97/193]	Time  5.001 ( 6.109)	Data  4.437 ( 5.539)	Loss 7.2422e-02 (8.1847e-02) 
2023-05-27 17:25:53.162571: train Epoch: [42][ 98/193]	Time  6.992 ( 6.118)	Data  6.422 ( 5.548)	Loss 4.5898e-02 (8.1484e-02) 
2023-05-27 17:25:58.687187: train Epoch: [42][ 99/193]	Time  5.525 ( 6.112)	Data  4.963 ( 5.542)	Loss 8.9132e-02 (8.1561e-02) 
2023-05-27 17:26:04.950789: train Epoch: [42][100/193]	Time  6.264 ( 6.114)	Data  5.694 ( 5.543)	Loss 9.6245e-02 (8.1706e-02) 
2023-05-27 17:26:11.386525: train Epoch: [42][101/193]	Time  6.436 ( 6.117)	Data  5.873 ( 5.547)	Loss 6.6821e-02 (8.1560e-02) 
2023-05-27 17:26:17.244076: train Epoch: [42][102/193]	Time  5.858 ( 6.114)	Data  5.297 ( 5.544)	Loss 7.0763e-02 (8.1455e-02) 
2023-05-27 17:26:24.652556: train Epoch: [42][103/193]	Time  7.408 ( 6.127)	Data  6.836 ( 5.557)	Loss 1.1005e-01 (8.1730e-02) 
2023-05-27 17:26:29.506393: train Epoch: [42][104/193]	Time  4.854 ( 6.115)	Data  4.285 ( 5.545)	Loss 2.2695e-01 (8.3113e-02) 
2023-05-27 17:26:37.261930: train Epoch: [42][105/193]	Time  7.756 ( 6.130)	Data  7.191 ( 5.560)	Loss 7.8025e-02 (8.3065e-02) 
2023-05-27 17:26:41.717260: train Epoch: [42][106/193]	Time  4.455 ( 6.114)	Data  3.894 ( 5.545)	Loss 8.0783e-02 (8.3044e-02) 
2023-05-27 17:26:49.343606: train Epoch: [42][107/193]	Time  7.626 ( 6.128)	Data  7.039 ( 5.558)	Loss 8.1987e-02 (8.3034e-02) 
2023-05-27 17:26:53.687227: train Epoch: [42][108/193]	Time  4.344 ( 6.112)	Data  3.783 ( 5.542)	Loss 6.7820e-02 (8.2895e-02) 
2023-05-27 17:27:02.184854: train Epoch: [42][109/193]	Time  8.498 ( 6.134)	Data  7.929 ( 5.564)	Loss 1.1806e-01 (8.3214e-02) 
2023-05-27 17:27:06.173365: train Epoch: [42][110/193]	Time  3.989 ( 6.114)	Data  3.420 ( 5.544)	Loss 6.1081e-02 (8.3015e-02) 
2023-05-27 17:27:14.360943: train Epoch: [42][111/193]	Time  8.188 ( 6.133)	Data  7.625 ( 5.563)	Loss 4.6626e-02 (8.2690e-02) 
2023-05-27 17:27:18.698673: train Epoch: [42][112/193]	Time  4.338 ( 6.117)	Data  3.763 ( 5.547)	Loss 8.5729e-02 (8.2717e-02) 
2023-05-27 17:27:26.461669: train Epoch: [42][113/193]	Time  7.763 ( 6.132)	Data  7.187 ( 5.562)	Loss 6.3197e-02 (8.2546e-02) 
2023-05-27 17:27:30.888973: train Epoch: [42][114/193]	Time  4.427 ( 6.117)	Data  3.866 ( 5.547)	Loss 6.7254e-02 (8.2413e-02) 
2023-05-27 17:27:38.265809: train Epoch: [42][115/193]	Time  7.377 ( 6.128)	Data  6.805 ( 5.558)	Loss 9.9695e-02 (8.2562e-02) 
2023-05-27 17:27:43.049196: train Epoch: [42][116/193]	Time  4.783 ( 6.116)	Data  4.222 ( 5.546)	Loss 6.1718e-02 (8.2383e-02) 
2023-05-27 17:27:50.570727: train Epoch: [42][117/193]	Time  7.522 ( 6.128)	Data  6.947 ( 5.558)	Loss 1.3461e-01 (8.2826e-02) 
2023-05-27 17:27:55.252574: train Epoch: [42][118/193]	Time  4.682 ( 6.116)	Data  4.107 ( 5.546)	Loss 6.8108e-02 (8.2702e-02) 
2023-05-27 17:28:02.599665: train Epoch: [42][119/193]	Time  7.347 ( 6.126)	Data  6.784 ( 5.556)	Loss 6.4590e-02 (8.2551e-02) 
2023-05-27 17:28:07.595290: train Epoch: [42][120/193]	Time  4.996 ( 6.117)	Data  4.425 ( 5.547)	Loss 6.8959e-02 (8.2439e-02) 
2023-05-27 17:28:14.781395: train Epoch: [42][121/193]	Time  7.186 ( 6.125)	Data  6.618 ( 5.556)	Loss 5.1427e-02 (8.2185e-02) 
2023-05-27 17:28:20.291293: train Epoch: [42][122/193]	Time  5.510 ( 6.120)	Data  4.942 ( 5.551)	Loss 5.0031e-02 (8.1923e-02) 
2023-05-27 17:28:27.476384: train Epoch: [42][123/193]	Time  7.185 ( 6.129)	Data  6.609 ( 5.559)	Loss 6.7251e-02 (8.1805e-02) 
2023-05-27 17:28:32.698560: train Epoch: [42][124/193]	Time  5.222 ( 6.122)	Data  4.656 ( 5.552)	Loss 5.4710e-02 (8.1588e-02) 
2023-05-27 17:28:40.164678: train Epoch: [42][125/193]	Time  7.466 ( 6.132)	Data  6.902 ( 5.563)	Loss 8.1690e-02 (8.1589e-02) 
2023-05-27 17:28:45.171620: train Epoch: [42][126/193]	Time  5.007 ( 6.124)	Data  4.434 ( 5.554)	Loss 1.0507e-01 (8.1774e-02) 
2023-05-27 17:28:52.212999: train Epoch: [42][127/193]	Time  7.041 ( 6.131)	Data  6.477 ( 5.561)	Loss 5.1165e-02 (8.1535e-02) 
2023-05-27 17:28:57.591069: train Epoch: [42][128/193]	Time  5.378 ( 6.125)	Data  4.809 ( 5.555)	Loss 1.4021e-01 (8.1990e-02) 
2023-05-27 17:29:04.271027: train Epoch: [42][129/193]	Time  6.680 ( 6.129)	Data  6.119 ( 5.559)	Loss 6.0314e-02 (8.1823e-02) 
2023-05-27 17:29:09.856334: train Epoch: [42][130/193]	Time  5.585 ( 6.125)	Data  5.025 ( 5.555)	Loss 7.1086e-02 (8.1741e-02) 
2023-05-27 17:29:16.614613: train Epoch: [42][131/193]	Time  6.758 ( 6.130)	Data  6.187 ( 5.560)	Loss 8.5969e-02 (8.1773e-02) 
2023-05-27 17:29:22.464340: train Epoch: [42][132/193]	Time  5.850 ( 6.128)	Data  5.284 ( 5.558)	Loss 8.5900e-02 (8.1804e-02) 
2023-05-27 17:29:28.994226: train Epoch: [42][133/193]	Time  6.530 ( 6.131)	Data  5.970 ( 5.561)	Loss 8.7088e-02 (8.1844e-02) 
2023-05-27 17:29:34.656972: train Epoch: [42][134/193]	Time  5.663 ( 6.127)	Data  5.101 ( 5.558)	Loss 4.5784e-02 (8.1576e-02) 
2023-05-27 17:29:40.984653: train Epoch: [42][135/193]	Time  6.328 ( 6.129)	Data  5.761 ( 5.559)	Loss 8.1611e-02 (8.1577e-02) 
2023-05-27 17:29:46.743973: train Epoch: [42][136/193]	Time  5.759 ( 6.126)	Data  5.196 ( 5.557)	Loss 9.9762e-02 (8.1709e-02) 
2023-05-27 17:29:52.986061: train Epoch: [42][137/193]	Time  6.242 ( 6.127)	Data  5.670 ( 5.557)	Loss 8.5838e-02 (8.1739e-02) 
2023-05-27 17:29:59.379284: train Epoch: [42][138/193]	Time  6.393 ( 6.129)	Data  5.800 ( 5.559)	Loss 9.8121e-02 (8.1857e-02) 
2023-05-27 17:30:05.853183: train Epoch: [42][139/193]	Time  6.474 ( 6.131)	Data  5.899 ( 5.562)	Loss 5.4701e-02 (8.1663e-02) 
2023-05-27 17:30:12.124325: train Epoch: [42][140/193]	Time  6.271 ( 6.132)	Data  5.702 ( 5.563)	Loss 5.3831e-02 (8.1466e-02) 
2023-05-27 17:30:18.059833: train Epoch: [42][141/193]	Time  5.936 ( 6.131)	Data  5.372 ( 5.561)	Loss 7.2634e-02 (8.1404e-02) 
2023-05-27 17:30:24.055930: train Epoch: [42][142/193]	Time  5.996 ( 6.130)	Data  5.429 ( 5.560)	Loss 9.0238e-02 (8.1465e-02) 
2023-05-27 17:30:30.326575: train Epoch: [42][143/193]	Time  6.271 ( 6.131)	Data  5.708 ( 5.561)	Loss 5.9788e-02 (8.1315e-02) 
2023-05-27 17:30:36.631067: train Epoch: [42][144/193]	Time  6.304 ( 6.132)	Data  5.737 ( 5.563)	Loss 4.0643e-02 (8.1034e-02) 
2023-05-27 17:30:42.990165: train Epoch: [42][145/193]	Time  6.359 ( 6.134)	Data  5.781 ( 5.564)	Loss 9.2666e-02 (8.1114e-02) 
2023-05-27 17:30:48.651325: train Epoch: [42][146/193]	Time  5.661 ( 6.130)	Data  5.087 ( 5.561)	Loss 1.8179e-01 (8.1799e-02) 
2023-05-27 17:30:55.666904: train Epoch: [42][147/193]	Time  7.016 ( 6.136)	Data  6.424 ( 5.567)	Loss 8.8317e-02 (8.1843e-02) 
2023-05-27 17:31:01.003163: train Epoch: [42][148/193]	Time  5.336 ( 6.131)	Data  4.775 ( 5.561)	Loss 1.1794e-01 (8.2085e-02) 
2023-05-27 17:31:08.354017: train Epoch: [42][149/193]	Time  7.351 ( 6.139)	Data  6.772 ( 5.569)	Loss 5.9282e-02 (8.1933e-02) 
2023-05-27 17:31:13.224394: train Epoch: [42][150/193]	Time  4.870 ( 6.131)	Data  4.302 ( 5.561)	Loss 1.3021e-01 (8.2253e-02) 
2023-05-27 17:31:21.227458: train Epoch: [42][151/193]	Time  8.003 ( 6.143)	Data  7.435 ( 5.573)	Loss 1.4976e-01 (8.2697e-02) 
2023-05-27 17:31:25.377408: train Epoch: [42][152/193]	Time  4.150 ( 6.130)	Data  3.589 ( 5.560)	Loss 1.0793e-01 (8.2862e-02) 
2023-05-27 17:31:33.453160: train Epoch: [42][153/193]	Time  8.076 ( 6.143)	Data  7.500 ( 5.573)	Loss 6.9445e-02 (8.2775e-02) 
2023-05-27 17:31:37.555975: train Epoch: [42][154/193]	Time  4.103 ( 6.130)	Data  3.537 ( 5.560)	Loss 1.2859e-01 (8.3070e-02) 
2023-05-27 17:31:46.478957: train Epoch: [42][155/193]	Time  8.923 ( 6.147)	Data  8.329 ( 5.578)	Loss 7.1035e-02 (8.2993e-02) 
2023-05-27 17:31:49.707766: train Epoch: [42][156/193]	Time  3.229 ( 6.129)	Data  2.663 ( 5.559)	Loss 2.1312e-01 (8.3822e-02) 
2023-05-27 17:31:59.356699: train Epoch: [42][157/193]	Time  9.649 ( 6.151)	Data  9.076 ( 5.581)	Loss 6.8783e-02 (8.3727e-02) 
2023-05-27 17:32:01.790796: train Epoch: [42][158/193]	Time  2.434 ( 6.128)	Data  1.873 ( 5.558)	Loss 4.8009e-02 (8.3502e-02) 
2023-05-27 17:32:10.924518: train Epoch: [42][159/193]	Time  9.134 ( 6.147)	Data  8.572 ( 5.577)	Loss 3.9658e-02 (8.3228e-02) 
2023-05-27 17:32:14.195002: train Epoch: [42][160/193]	Time  3.270 ( 6.129)	Data  2.710 ( 5.559)	Loss 7.4368e-02 (8.3173e-02) 
2023-05-27 17:32:22.904746: train Epoch: [42][161/193]	Time  8.710 ( 6.145)	Data  8.144 ( 5.575)	Loss 1.0764e-01 (8.3324e-02) 
2023-05-27 17:32:26.501808: train Epoch: [42][162/193]	Time  3.597 ( 6.129)	Data  3.037 ( 5.559)	Loss 8.9611e-02 (8.3363e-02) 
2023-05-27 17:32:35.209432: train Epoch: [42][163/193]	Time  8.708 ( 6.145)	Data  8.145 ( 5.575)	Loss 1.3771e-01 (8.3694e-02) 
2023-05-27 17:32:38.425123: train Epoch: [42][164/193]	Time  3.216 ( 6.127)	Data  2.635 ( 5.557)	Loss 8.4323e-02 (8.3698e-02) 
2023-05-27 17:32:47.223867: train Epoch: [42][165/193]	Time  8.799 ( 6.143)	Data  8.238 ( 5.573)	Loss 5.2751e-02 (8.3512e-02) 
2023-05-27 17:32:50.873559: train Epoch: [42][166/193]	Time  3.650 ( 6.128)	Data  3.033 ( 5.558)	Loss 9.3370e-02 (8.3571e-02) 
2023-05-27 17:32:59.677205: train Epoch: [42][167/193]	Time  8.804 ( 6.144)	Data  8.237 ( 5.574)	Loss 5.3660e-02 (8.3393e-02) 
2023-05-27 17:33:02.922291: train Epoch: [42][168/193]	Time  3.245 ( 6.127)	Data  2.669 ( 5.557)	Loss 5.7314e-02 (8.3238e-02) 
2023-05-27 17:33:12.315173: train Epoch: [42][169/193]	Time  9.393 ( 6.146)	Data  8.826 ( 5.576)	Loss 1.2443e-01 (8.3481e-02) 
2023-05-27 17:33:15.098300: train Epoch: [42][170/193]	Time  2.783 ( 6.126)	Data  2.184 ( 5.556)	Loss 1.2119e-01 (8.3701e-02) 
2023-05-27 17:33:23.986446: train Epoch: [42][171/193]	Time  8.888 ( 6.143)	Data  8.327 ( 5.573)	Loss 5.9946e-02 (8.3563e-02) 
2023-05-27 17:33:27.606367: train Epoch: [42][172/193]	Time  3.620 ( 6.128)	Data  2.932 ( 5.557)	Loss 7.9742e-02 (8.3541e-02) 
2023-05-27 17:33:36.033657: train Epoch: [42][173/193]	Time  8.427 ( 6.141)	Data  7.861 ( 5.570)	Loss 1.4085e-01 (8.3870e-02) 
2023-05-27 17:33:39.953078: train Epoch: [42][174/193]	Time  3.919 ( 6.128)	Data  3.342 ( 5.558)	Loss 6.5394e-02 (8.3765e-02) 
2023-05-27 17:33:48.242706: train Epoch: [42][175/193]	Time  8.290 ( 6.141)	Data  7.721 ( 5.570)	Loss 7.6895e-02 (8.3726e-02) 
2023-05-27 17:33:52.180497: train Epoch: [42][176/193]	Time  3.938 ( 6.128)	Data  3.353 ( 5.558)	Loss 1.0111e-01 (8.3824e-02) 
2023-05-27 17:34:00.507384: train Epoch: [42][177/193]	Time  8.327 ( 6.141)	Data  7.767 ( 5.570)	Loss 9.1369e-02 (8.3866e-02) 
2023-05-27 17:34:04.476152: train Epoch: [42][178/193]	Time  3.969 ( 6.129)	Data  3.398 ( 5.558)	Loss 1.1382e-01 (8.4034e-02) 
2023-05-27 17:34:12.359024: train Epoch: [42][179/193]	Time  7.883 ( 6.138)	Data  7.322 ( 5.568)	Loss 1.7407e-01 (8.4534e-02) 
2023-05-27 17:34:16.546444: train Epoch: [42][180/193]	Time  4.187 ( 6.127)	Data  3.603 ( 5.557)	Loss 6.4934e-02 (8.4426e-02) 
2023-05-27 17:34:23.390078: train Epoch: [42][181/193]	Time  6.844 ( 6.131)	Data  6.265 ( 5.561)	Loss 6.7523e-02 (8.4333e-02) 
2023-05-27 17:34:28.400665: train Epoch: [42][182/193]	Time  5.011 ( 6.125)	Data  4.441 ( 5.555)	Loss 5.4081e-02 (8.4167e-02) 
2023-05-27 17:34:35.946469: train Epoch: [42][183/193]	Time  7.546 ( 6.133)	Data  6.970 ( 5.562)	Loss 8.6903e-02 (8.4182e-02) 
2023-05-27 17:34:40.681118: train Epoch: [42][184/193]	Time  4.735 ( 6.125)	Data  4.164 ( 5.555)	Loss 5.0358e-02 (8.3999e-02) 
2023-05-27 17:34:48.223991: train Epoch: [42][185/193]	Time  7.543 ( 6.133)	Data  6.968 ( 5.562)	Loss 3.1032e-02 (8.3715e-02) 
2023-05-27 17:34:53.784636: train Epoch: [42][186/193]	Time  5.561 ( 6.130)	Data  4.998 ( 5.559)	Loss 6.6352e-02 (8.3622e-02) 
2023-05-27 17:35:00.489589: train Epoch: [42][187/193]	Time  6.705 ( 6.133)	Data  6.142 ( 5.562)	Loss 5.2300e-02 (8.3455e-02) 
2023-05-27 17:35:06.198352: train Epoch: [42][188/193]	Time  5.709 ( 6.131)	Data  5.148 ( 5.560)	Loss 6.8345e-02 (8.3375e-02) 
2023-05-27 17:35:12.828638: train Epoch: [42][189/193]	Time  6.630 ( 6.133)	Data  6.069 ( 5.563)	Loss 1.0099e-01 (8.3468e-02) 
2023-05-27 17:35:18.216177: train Epoch: [42][190/193]	Time  5.388 ( 6.130)	Data  4.822 ( 5.559)	Loss 8.3925e-02 (8.3470e-02) 
2023-05-27 17:35:25.308363: train Epoch: [42][191/193]	Time  7.092 ( 6.135)	Data  6.525 ( 5.564)	Loss 5.4960e-02 (8.3322e-02) 
2023-05-27 17:35:30.093736: train Epoch: [42][192/193]	Time  4.785 ( 6.128)	Data  4.210 ( 5.557)	Loss 1.1002e-01 (8.3460e-02) 
2023-05-27 17:35:30.284043: Train Epoch done in 1182.8143383559946 s 
2023-05-27 17:35:38.648786: val Epoch: [42][ 0/72]	Time  7.663 ( 7.663)	Data  7.411 ( 7.411)	Loss 4.5523e-02 (4.5523e-02) 
2023-05-27 17:35:38.909270: val Epoch: [42][ 1/72]	Time  0.261 ( 3.962)	Data  0.144 ( 3.778)	Loss 6.3670e-02 (5.4596e-02) 
2023-05-27 17:35:44.915772: val Epoch: [42][ 2/72]	Time  6.006 ( 4.643)	Data  5.896 ( 4.484)	Loss 5.3049e-02 (5.4080e-02) 
2023-05-27 17:35:45.024447: val Epoch: [42][ 3/72]	Time  0.109 ( 3.510)	Data  0.001 ( 3.363)	Loss 4.1364e-02 (5.0901e-02) 
2023-05-27 17:35:51.613778: val Epoch: [42][ 4/72]	Time  6.589 ( 4.126)	Data  6.484 ( 3.987)	Loss 9.1736e-02 (5.9068e-02) 
2023-05-27 17:35:51.719723: val Epoch: [42][ 5/72]	Time  0.106 ( 3.456)	Data  0.001 ( 3.323)	Loss 3.8762e-02 (5.5684e-02) 
2023-05-27 17:35:57.602346: val Epoch: [42][ 6/72]	Time  5.883 ( 3.802)	Data  5.773 ( 3.673)	Loss 5.8003e-02 (5.6015e-02) 
2023-05-27 17:35:57.711164: val Epoch: [42][ 7/72]	Time  0.109 ( 3.341)	Data  0.001 ( 3.214)	Loss 1.7821e-01 (7.1290e-02) 
2023-05-27 17:36:04.156880: val Epoch: [42][ 8/72]	Time  6.446 ( 3.686)	Data  6.340 ( 3.561)	Loss 9.5611e-02 (7.3992e-02) 
2023-05-27 17:36:04.261913: val Epoch: [42][ 9/72]	Time  0.105 ( 3.328)	Data  0.001 ( 3.205)	Loss 1.9008e-01 (8.5601e-02) 
2023-05-27 17:36:10.450509: val Epoch: [42][10/72]	Time  6.189 ( 3.588)	Data  6.083 ( 3.467)	Loss 1.0674e-01 (8.7522e-02) 
2023-05-27 17:36:10.555445: val Epoch: [42][11/72]	Time  0.105 ( 3.297)	Data  0.001 ( 3.178)	Loss 1.5341e-01 (9.3013e-02) 
2023-05-27 17:36:16.441239: val Epoch: [42][12/72]	Time  5.886 ( 3.497)	Data  5.775 ( 3.378)	Loss 5.1837e-02 (8.9845e-02) 
2023-05-27 17:36:16.551289: val Epoch: [42][13/72]	Time  0.110 ( 3.255)	Data  0.001 ( 3.136)	Loss 4.2913e-02 (8.6493e-02) 
2023-05-27 17:36:22.889344: val Epoch: [42][14/72]	Time  6.338 ( 3.460)	Data  6.231 ( 3.343)	Loss 9.5509e-02 (8.7094e-02) 
2023-05-27 17:36:23.008826: val Epoch: [42][15/72]	Time  0.119 ( 3.251)	Data  0.000 ( 3.134)	Loss 5.6333e-01 (1.1686e-01) 
2023-05-27 17:36:29.295306: val Epoch: [42][16/72]	Time  6.286 ( 3.430)	Data  6.181 ( 3.313)	Loss 3.6043e-02 (1.1211e-01) 
2023-05-27 17:36:29.400555: val Epoch: [42][17/72]	Time  0.105 ( 3.245)	Data  0.001 ( 3.129)	Loss 7.1301e-02 (1.0984e-01) 
2023-05-27 17:36:35.767857: val Epoch: [42][18/72]	Time  6.367 ( 3.410)	Data  6.257 ( 3.294)	Loss 3.2849e-01 (1.2135e-01) 
2023-05-27 17:36:35.904875: val Epoch: [42][19/72]	Time  0.137 ( 3.246)	Data  0.001 ( 3.129)	Loss 2.9123e-01 (1.2984e-01) 
2023-05-27 17:36:41.935716: val Epoch: [42][20/72]	Time  6.031 ( 3.379)	Data  5.924 ( 3.262)	Loss 3.4366e-02 (1.2529e-01) 
2023-05-27 17:36:42.042043: val Epoch: [42][21/72]	Time  0.106 ( 3.230)	Data  0.001 ( 3.114)	Loss 1.5448e-01 (1.2662e-01) 
2023-05-27 17:36:48.188385: val Epoch: [42][22/72]	Time  6.146 ( 3.357)	Data  6.040 ( 3.241)	Loss 6.2809e-02 (1.2385e-01) 
2023-05-27 17:36:48.294809: val Epoch: [42][23/72]	Time  0.106 ( 3.221)	Data  0.001 ( 3.106)	Loss 1.1860e-01 (1.2363e-01) 
2023-05-27 17:36:54.371136: val Epoch: [42][24/72]	Time  6.076 ( 3.335)	Data  5.971 ( 3.221)	Loss 5.6631e-02 (1.2095e-01) 
2023-05-27 17:36:54.481457: val Epoch: [42][25/72]	Time  0.110 ( 3.211)	Data  0.000 ( 3.097)	Loss 5.4460e-02 (1.1839e-01) 
2023-05-27 17:37:00.640299: val Epoch: [42][26/72]	Time  6.159 ( 3.321)	Data  6.049 ( 3.206)	Loss 2.3112e-01 (1.2257e-01) 
2023-05-27 17:37:00.745513: val Epoch: [42][27/72]	Time  0.105 ( 3.206)	Data  0.000 ( 3.092)	Loss 5.6270e-02 (1.2020e-01) 
2023-05-27 17:37:06.846980: val Epoch: [42][28/72]	Time  6.101 ( 3.306)	Data  5.995 ( 3.192)	Loss 4.2678e-01 (1.3077e-01) 
2023-05-27 17:37:06.952625: val Epoch: [42][29/72]	Time  0.106 ( 3.199)	Data  0.001 ( 3.085)	Loss 7.8839e-02 (1.2904e-01) 
2023-05-27 17:37:13.339687: val Epoch: [42][30/72]	Time  6.387 ( 3.302)	Data  6.282 ( 3.189)	Loss 6.1008e-02 (1.2684e-01) 
2023-05-27 17:37:13.445763: val Epoch: [42][31/72]	Time  0.106 ( 3.202)	Data  0.001 ( 3.089)	Loss 1.4861e-01 (1.2752e-01) 
2023-05-27 17:37:19.798723: val Epoch: [42][32/72]	Time  6.353 ( 3.297)	Data  6.248 ( 3.185)	Loss 8.0805e-02 (1.2611e-01) 
2023-05-27 17:37:19.904007: val Epoch: [42][33/72]	Time  0.105 ( 3.203)	Data  0.000 ( 3.091)	Loss 1.2158e-01 (1.2598e-01) 
2023-05-27 17:37:25.923622: val Epoch: [42][34/72]	Time  6.020 ( 3.284)	Data  5.914 ( 3.172)	Loss 7.7100e-02 (1.2458e-01) 
2023-05-27 17:37:26.032651: val Epoch: [42][35/72]	Time  0.109 ( 3.196)	Data  0.001 ( 3.084)	Loss 1.2612e-01 (1.2462e-01) 
2023-05-27 17:37:32.293048: val Epoch: [42][36/72]	Time  6.260 ( 3.279)	Data  6.139 ( 3.166)	Loss 2.8161e-01 (1.2886e-01) 
2023-05-27 17:37:32.406323: val Epoch: [42][37/72]	Time  0.113 ( 3.195)	Data  0.001 ( 3.083)	Loss 4.0850e-02 (1.2655e-01) 
2023-05-27 17:37:38.814490: val Epoch: [42][38/72]	Time  6.408 ( 3.278)	Data  6.300 ( 3.165)	Loss 7.3907e-02 (1.2520e-01) 
2023-05-27 17:37:38.923668: val Epoch: [42][39/72]	Time  0.109 ( 3.198)	Data  0.001 ( 3.086)	Loss 8.1016e-02 (1.2409e-01) 
2023-05-27 17:37:45.002022: val Epoch: [42][40/72]	Time  6.078 ( 3.269)	Data  5.966 ( 3.156)	Loss 1.4194e-01 (1.2453e-01) 
2023-05-27 17:37:45.112695: val Epoch: [42][41/72]	Time  0.111 ( 3.193)	Data  0.001 ( 3.081)	Loss 6.2032e-01 (1.3633e-01) 
2023-05-27 17:37:51.368358: val Epoch: [42][42/72]	Time  6.256 ( 3.265)	Data  6.147 ( 3.153)	Loss 3.6523e-01 (1.4166e-01) 
2023-05-27 17:37:51.476712: val Epoch: [42][43/72]	Time  0.108 ( 3.193)	Data  0.000 ( 3.081)	Loss 5.9331e-01 (1.5192e-01) 
2023-05-27 17:37:57.534191: val Epoch: [42][44/72]	Time  6.057 ( 3.257)	Data  5.950 ( 3.145)	Loss 6.9315e-02 (1.5009e-01) 
2023-05-27 17:37:57.642699: val Epoch: [42][45/72]	Time  0.109 ( 3.188)	Data  0.001 ( 3.076)	Loss 8.8007e-02 (1.4874e-01) 
2023-05-27 17:38:03.793020: val Epoch: [42][46/72]	Time  6.150 ( 3.251)	Data  6.042 ( 3.139)	Loss 2.4517e-01 (1.5079e-01) 
2023-05-27 17:38:03.900881: val Epoch: [42][47/72]	Time  0.108 ( 3.186)	Data  0.001 ( 3.074)	Loss 8.7027e-02 (1.4946e-01) 
2023-05-27 17:38:09.850460: val Epoch: [42][48/72]	Time  5.950 ( 3.242)	Data  5.832 ( 3.130)	Loss 8.8793e-02 (1.4822e-01) 
2023-05-27 17:38:09.967360: val Epoch: [42][49/72]	Time  0.117 ( 3.180)	Data  0.001 ( 3.068)	Loss 4.6205e-02 (1.4618e-01) 
2023-05-27 17:38:16.061871: val Epoch: [42][50/72]	Time  6.095 ( 3.237)	Data  5.982 ( 3.125)	Loss 4.8844e-02 (1.4427e-01) 
2023-05-27 17:38:16.172531: val Epoch: [42][51/72]	Time  0.111 ( 3.177)	Data  0.001 ( 3.065)	Loss 5.0549e-02 (1.4247e-01) 
2023-05-27 17:38:22.626081: val Epoch: [42][52/72]	Time  6.454 ( 3.238)	Data  6.340 ( 3.127)	Loss 4.5077e-02 (1.4063e-01) 
2023-05-27 17:38:22.763662: val Epoch: [42][53/72]	Time  0.138 ( 3.181)	Data  0.001 ( 3.069)	Loss 5.8246e-02 (1.3911e-01) 
2023-05-27 17:38:28.855755: val Epoch: [42][54/72]	Time  6.092 ( 3.234)	Data  5.980 ( 3.122)	Loss 9.0898e-02 (1.3823e-01) 
2023-05-27 17:38:28.963492: val Epoch: [42][55/72]	Time  0.108 ( 3.178)	Data  0.001 ( 3.066)	Loss 2.4417e-01 (1.4012e-01) 
2023-05-27 17:38:35.024480: val Epoch: [42][56/72]	Time  6.061 ( 3.229)	Data  5.945 ( 3.116)	Loss 3.6497e-01 (1.4407e-01) 
2023-05-27 17:38:35.153847: val Epoch: [42][57/72]	Time  0.129 ( 3.175)	Data  0.001 ( 3.063)	Loss 1.0484e-01 (1.4339e-01) 
2023-05-27 17:38:41.367376: val Epoch: [42][58/72]	Time  6.214 ( 3.227)	Data  6.106 ( 3.114)	Loss 9.0660e-02 (1.4250e-01) 
2023-05-27 17:38:41.473851: val Epoch: [42][59/72]	Time  0.106 ( 3.175)	Data  0.000 ( 3.062)	Loss 1.7315e-01 (1.4301e-01) 
2023-05-27 17:38:47.634347: val Epoch: [42][60/72]	Time  6.160 ( 3.224)	Data  6.050 ( 3.111)	Loss 8.0681e-02 (1.4199e-01) 
2023-05-27 17:38:47.745794: val Epoch: [42][61/72]	Time  0.111 ( 3.174)	Data  0.001 ( 3.061)	Loss 6.1484e-02 (1.4069e-01) 
2023-05-27 17:38:53.490754: val Epoch: [42][62/72]	Time  5.745 ( 3.214)	Data  5.634 ( 3.102)	Loss 5.4323e-02 (1.3932e-01) 
2023-05-27 17:38:53.598717: val Epoch: [42][63/72]	Time  0.108 ( 3.166)	Data  0.000 ( 3.054)	Loss 5.4428e-02 (1.3799e-01) 
2023-05-27 17:38:59.591763: val Epoch: [42][64/72]	Time  5.993 ( 3.209)	Data  5.882 ( 3.097)	Loss 6.8294e-02 (1.3692e-01) 
2023-05-27 17:38:59.712438: val Epoch: [42][65/72]	Time  0.121 ( 3.163)	Data  0.001 ( 3.050)	Loss 6.6335e-02 (1.3585e-01) 
2023-05-27 17:39:05.798965: val Epoch: [42][66/72]	Time  6.087 ( 3.206)	Data  5.971 ( 3.094)	Loss 7.6989e-02 (1.3497e-01) 
2023-05-27 17:39:05.912222: val Epoch: [42][67/72]	Time  0.113 ( 3.161)	Data  0.001 ( 3.048)	Loss 5.8275e-02 (1.3384e-01) 
2023-05-27 17:39:11.893668: val Epoch: [42][68/72]	Time  5.981 ( 3.202)	Data  5.869 ( 3.089)	Loss 1.2674e-01 (1.3374e-01) 
2023-05-27 17:39:12.006517: val Epoch: [42][69/72]	Time  0.113 ( 3.157)	Data  0.000 ( 3.045)	Loss 4.9479e-02 (1.3254e-01) 
2023-05-27 17:39:18.151447: val Epoch: [42][70/72]	Time  6.145 ( 3.200)	Data  6.032 ( 3.087)	Loss 9.3432e-02 (1.3199e-01) 
2023-05-27 17:39:18.263633: val Epoch: [42][71/72]	Time  0.112 ( 3.157)	Data  0.000 ( 3.044)	Loss 6.8722e-02 (1.3111e-01) 
2023-05-27 17:39:18.630980: Epoch 42 :Val : ['ET : 0.7446434497833252', 'TC : 0.7807683944702148', 'WT : 0.8578598499298096'] 
2023-05-27 17:39:18.631905: Epoch 42 :Val : ['ET : 0.7446434497833252', 'TC : 0.7807683944702148', 'WT : 0.8578598499298096'] 
2023-05-27 17:39:18.636666: Val epoch done in 228.3526488430216 s 
2023-05-27 17:39:18.646598: Batches per epoch:  193 
2023-05-27 17:39:32.111808: train Epoch: [43][  0/193]	Time 13.465 (13.465)	Data 12.873 (12.873)	Loss 5.1617e-02 (5.1617e-02) 
2023-05-27 17:39:33.292820: train Epoch: [43][  1/193]	Time  1.181 ( 7.323)	Data  0.619 ( 6.746)	Loss 5.3068e-02 (5.2342e-02) 
2023-05-27 17:39:44.625993: train Epoch: [43][  2/193]	Time 11.333 ( 8.660)	Data 10.772 ( 8.088)	Loss 8.7714e-02 (6.4133e-02) 
2023-05-27 17:39:45.698215: train Epoch: [43][  3/193]	Time  1.072 ( 6.763)	Data  0.509 ( 6.194)	Loss 6.2896e-02 (6.3824e-02) 
2023-05-27 17:39:57.216433: train Epoch: [43][  4/193]	Time 11.518 ( 7.714)	Data 10.957 ( 7.146)	Loss 6.7795e-02 (6.4618e-02) 
2023-05-27 17:39:58.487209: train Epoch: [43][  5/193]	Time  1.271 ( 6.640)	Data  0.709 ( 6.073)	Loss 8.1430e-02 (6.7420e-02) 
2023-05-27 17:40:09.493212: train Epoch: [43][  6/193]	Time 11.006 ( 7.264)	Data 10.436 ( 6.696)	Loss 2.2535e-01 (8.9981e-02) 
2023-05-27 17:40:11.364604: train Epoch: [43][  7/193]	Time  1.871 ( 6.590)	Data  1.302 ( 6.022)	Loss 7.8872e-02 (8.8593e-02) 
2023-05-27 17:40:21.839580: train Epoch: [43][  8/193]	Time 10.475 ( 7.021)	Data  9.913 ( 6.454)	Loss 1.3850e-01 (9.4138e-02) 
2023-05-27 17:40:23.586241: train Epoch: [43][  9/193]	Time  1.747 ( 6.494)	Data  1.186 ( 5.928)	Loss 5.8671e-02 (9.0591e-02) 
2023-05-27 17:40:34.514404: train Epoch: [43][ 10/193]	Time 10.928 ( 6.897)	Data 10.367 ( 6.331)	Loss 9.5889e-02 (9.1073e-02) 
2023-05-27 17:40:35.751820: train Epoch: [43][ 11/193]	Time  1.237 ( 6.425)	Data  0.676 ( 5.860)	Loss 7.3404e-02 (8.9601e-02) 
2023-05-27 17:40:46.893192: train Epoch: [43][ 12/193]	Time 11.141 ( 6.788)	Data 10.579 ( 6.223)	Loss 5.4320e-02 (8.6887e-02) 
2023-05-27 17:40:47.994201: train Epoch: [43][ 13/193]	Time  1.101 ( 6.382)	Data  0.538 ( 5.817)	Loss 1.1933e-01 (8.9204e-02) 
2023-05-27 17:40:59.316780: train Epoch: [43][ 14/193]	Time 11.323 ( 6.711)	Data 10.753 ( 6.146)	Loss 7.6911e-02 (8.8384e-02) 
2023-05-27 17:41:00.513404: train Epoch: [43][ 15/193]	Time  1.197 ( 6.367)	Data  0.635 ( 5.801)	Loss 6.5377e-02 (8.6947e-02) 
2023-05-27 17:41:11.743740: train Epoch: [43][ 16/193]	Time 11.230 ( 6.653)	Data 10.669 ( 6.088)	Loss 6.1947e-02 (8.5476e-02) 
2023-05-27 17:41:12.520812: train Epoch: [43][ 17/193]	Time  0.777 ( 6.326)	Data  0.216 ( 5.762)	Loss 1.0607e-01 (8.6620e-02) 
2023-05-27 17:41:23.785882: train Epoch: [43][ 18/193]	Time 11.265 ( 6.586)	Data 10.703 ( 6.022)	Loss 8.2775e-02 (8.6418e-02) 
2023-05-27 17:41:24.542961: train Epoch: [43][ 19/193]	Time  0.757 ( 6.295)	Data  0.196 ( 5.730)	Loss 5.2572e-02 (8.4725e-02) 
2023-05-27 17:41:36.463548: train Epoch: [43][ 20/193]	Time 11.921 ( 6.563)	Data 11.344 ( 5.998)	Loss 2.6207e-01 (9.3170e-02) 
2023-05-27 17:41:37.662117: train Epoch: [43][ 21/193]	Time  1.199 ( 6.319)	Data  0.632 ( 5.754)	Loss 9.9292e-02 (9.3449e-02) 
2023-05-27 17:41:48.833961: train Epoch: [43][ 22/193]	Time 11.172 ( 6.530)	Data 10.594 ( 5.964)	Loss 1.1840e-01 (9.4533e-02) 
2023-05-27 17:41:50.083768: train Epoch: [43][ 23/193]	Time  1.250 ( 6.310)	Data  0.689 ( 5.744)	Loss 7.0495e-02 (9.3532e-02) 
2023-05-27 17:42:00.672529: train Epoch: [43][ 24/193]	Time 10.589 ( 6.481)	Data 10.018 ( 5.915)	Loss 6.1337e-02 (9.2244e-02) 
2023-05-27 17:42:01.847262: train Epoch: [43][ 25/193]	Time  1.175 ( 6.277)	Data  0.607 ( 5.711)	Loss 7.1274e-02 (9.1437e-02) 
2023-05-27 17:42:11.818192: train Epoch: [43][ 26/193]	Time  9.971 ( 6.414)	Data  9.404 ( 5.848)	Loss 6.8607e-02 (9.0592e-02) 
2023-05-27 17:42:13.185495: train Epoch: [43][ 27/193]	Time  1.367 ( 6.234)	Data  0.801 ( 5.668)	Loss 3.0481e-02 (8.8445e-02) 
2023-05-27 17:42:22.749890: train Epoch: [43][ 28/193]	Time  9.564 ( 6.348)	Data  8.989 ( 5.782)	Loss 1.4536e-01 (9.0408e-02) 
2023-05-27 17:42:24.560488: train Epoch: [43][ 29/193]	Time  1.811 ( 6.197)	Data  1.242 ( 5.631)	Loss 7.0466e-02 (8.9743e-02) 
2023-05-27 17:42:34.057657: train Epoch: [43][ 30/193]	Time  9.497 ( 6.304)	Data  8.931 ( 5.737)	Loss 1.9792e-01 (9.3232e-02) 
2023-05-27 17:42:36.043644: train Epoch: [43][ 31/193]	Time  1.986 ( 6.169)	Data  1.419 ( 5.602)	Loss 7.7200e-02 (9.2731e-02) 
2023-05-27 17:42:46.187801: train Epoch: [43][ 32/193]	Time 10.144 ( 6.289)	Data  9.578 ( 5.723)	Loss 1.3308e-01 (9.3954e-02) 
2023-05-27 17:42:48.796933: train Epoch: [43][ 33/193]	Time  2.609 ( 6.181)	Data  2.041 ( 5.615)	Loss 8.6150e-02 (9.3725e-02) 
2023-05-27 17:42:58.631931: train Epoch: [43][ 34/193]	Time  9.835 ( 6.285)	Data  9.274 ( 5.719)	Loss 1.0207e-01 (9.3963e-02) 
2023-05-27 17:43:00.855895: train Epoch: [43][ 35/193]	Time  2.224 ( 6.172)	Data  1.661 ( 5.606)	Loss 8.1114e-02 (9.3606e-02) 
2023-05-27 17:43:11.399417: train Epoch: [43][ 36/193]	Time 10.544 ( 6.291)	Data  9.973 ( 5.724)	Loss 6.7152e-02 (9.2891e-02) 
2023-05-27 17:43:12.631384: train Epoch: [43][ 37/193]	Time  1.232 ( 6.157)	Data  0.671 ( 5.592)	Loss 5.8833e-02 (9.1995e-02) 
2023-05-27 17:43:23.984892: train Epoch: [43][ 38/193]	Time 11.354 ( 6.291)	Data 10.789 ( 5.725)	Loss 7.3417e-02 (9.1519e-02) 
2023-05-27 17:43:24.550149: train Epoch: [43][ 39/193]	Time  0.565 ( 6.148)	Data  0.001 ( 5.582)	Loss 6.9027e-02 (9.0956e-02) 
2023-05-27 17:43:36.189611: train Epoch: [43][ 40/193]	Time 11.639 ( 6.282)	Data 11.074 ( 5.716)	Loss 1.0169e-01 (9.1218e-02) 
2023-05-27 17:43:36.751249: train Epoch: [43][ 41/193]	Time  0.562 ( 6.145)	Data  0.001 ( 5.580)	Loss 6.6799e-02 (9.0637e-02) 
2023-05-27 17:43:48.552867: train Epoch: [43][ 42/193]	Time 11.802 ( 6.277)	Data 11.241 ( 5.711)	Loss 2.7329e-01 (9.4884e-02) 
2023-05-27 17:43:49.234924: train Epoch: [43][ 43/193]	Time  0.682 ( 6.150)	Data  0.121 ( 5.584)	Loss 5.9224e-02 (9.4074e-02) 
2023-05-27 17:44:00.830720: train Epoch: [43][ 44/193]	Time 11.596 ( 6.271)	Data 11.018 ( 5.705)	Loss 8.9571e-02 (9.3974e-02) 
2023-05-27 17:44:02.175578: train Epoch: [43][ 45/193]	Time  1.345 ( 6.164)	Data  0.784 ( 5.598)	Loss 1.2509e-01 (9.4650e-02) 
2023-05-27 17:44:13.505835: train Epoch: [43][ 46/193]	Time 11.330 ( 6.274)	Data 10.767 ( 5.708)	Loss 7.8606e-02 (9.4309e-02) 
2023-05-27 17:44:14.292508: train Epoch: [43][ 47/193]	Time  0.787 ( 6.159)	Data  0.225 ( 5.594)	Loss 5.1118e-02 (9.3409e-02) 
2023-05-27 17:44:25.520900: train Epoch: [43][ 48/193]	Time 11.228 ( 6.263)	Data 10.657 ( 5.697)	Loss 1.1854e-01 (9.3922e-02) 
2023-05-27 17:44:27.022431: train Epoch: [43][ 49/193]	Time  1.502 ( 6.168)	Data  0.937 ( 5.602)	Loss 1.7298e-01 (9.5503e-02) 
2023-05-27 17:44:37.723092: train Epoch: [43][ 50/193]	Time 10.701 ( 6.256)	Data 10.098 ( 5.690)	Loss 8.0465e-02 (9.5208e-02) 
2023-05-27 17:44:39.549028: train Epoch: [43][ 51/193]	Time  1.826 ( 6.171)	Data  1.261 ( 5.605)	Loss 1.0954e-01 (9.5484e-02) 
2023-05-27 17:44:50.181216: train Epoch: [43][ 52/193]	Time 10.632 ( 6.255)	Data 10.045 ( 5.689)	Loss 5.5895e-02 (9.4737e-02) 
2023-05-27 17:44:52.118171: train Epoch: [43][ 53/193]	Time  1.937 ( 6.175)	Data  1.368 ( 5.609)	Loss 5.0672e-02 (9.3921e-02) 
2023-05-27 17:45:02.519365: train Epoch: [43][ 54/193]	Time 10.401 ( 6.252)	Data  9.832 ( 5.685)	Loss 1.1947e-01 (9.4386e-02) 
2023-05-27 17:45:04.275105: train Epoch: [43][ 55/193]	Time  1.756 ( 6.172)	Data  1.188 ( 5.605)	Loss 1.2285e-01 (9.4894e-02) 
2023-05-27 17:45:15.415144: train Epoch: [43][ 56/193]	Time 11.140 ( 6.259)	Data 10.537 ( 5.692)	Loss 4.0818e-02 (9.3945e-02) 
2023-05-27 17:45:15.981611: train Epoch: [43][ 57/193]	Time  0.566 ( 6.161)	Data  0.001 ( 5.593)	Loss 5.4012e-02 (9.3257e-02) 
2023-05-27 17:45:27.704826: train Epoch: [43][ 58/193]	Time 11.723 ( 6.255)	Data 11.153 ( 5.688)	Loss 5.5633e-02 (9.2619e-02) 
2023-05-27 17:45:29.046977: train Epoch: [43][ 59/193]	Time  1.342 ( 6.173)	Data  0.773 ( 5.606)	Loss 9.3552e-02 (9.2635e-02) 
2023-05-27 17:45:39.987717: train Epoch: [43][ 60/193]	Time 10.941 ( 6.251)	Data 10.364 ( 5.684)	Loss 6.5783e-02 (9.2194e-02) 
2023-05-27 17:45:41.306216: train Epoch: [43][ 61/193]	Time  1.318 ( 6.172)	Data  0.757 ( 5.604)	Loss 8.4910e-02 (9.2077e-02) 
2023-05-27 17:45:52.509460: train Epoch: [43][ 62/193]	Time 11.203 ( 6.252)	Data 10.641 ( 5.684)	Loss 7.9313e-02 (9.1874e-02) 
2023-05-27 17:45:53.242749: train Epoch: [43][ 63/193]	Time  0.733 ( 6.166)	Data  0.160 ( 5.598)	Loss 8.8882e-02 (9.1828e-02) 
2023-05-27 17:46:05.248774: train Epoch: [43][ 64/193]	Time 12.006 ( 6.255)	Data 11.414 ( 5.687)	Loss 1.0858e-01 (9.2085e-02) 
2023-05-27 17:46:05.858943: train Epoch: [43][ 65/193]	Time  0.610 ( 6.170)	Data  0.002 ( 5.601)	Loss 5.9356e-02 (9.1589e-02) 
2023-05-27 17:46:17.209307: train Epoch: [43][ 66/193]	Time 11.350 ( 6.247)	Data 10.776 ( 5.679)	Loss 8.4079e-02 (9.1477e-02) 
2023-05-27 17:46:17.795907: train Epoch: [43][ 67/193]	Time  0.587 ( 6.164)	Data  0.001 ( 5.595)	Loss 1.9152e-01 (9.2948e-02) 
2023-05-27 17:46:30.095285: train Epoch: [43][ 68/193]	Time 12.299 ( 6.253)	Data 11.687 ( 5.683)	Loss 8.2681e-02 (9.2800e-02) 
2023-05-27 17:46:30.667260: train Epoch: [43][ 69/193]	Time  0.572 ( 6.172)	Data  0.001 ( 5.602)	Loss 7.3029e-02 (9.2517e-02) 
2023-05-27 17:46:42.279425: train Epoch: [43][ 70/193]	Time 11.612 ( 6.248)	Data 11.011 ( 5.678)	Loss 8.8202e-02 (9.2456e-02) 
2023-05-27 17:46:42.861474: train Epoch: [43][ 71/193]	Time  0.582 ( 6.170)	Data  0.001 ( 5.599)	Loss 1.0709e-01 (9.2660e-02) 
2023-05-27 17:46:55.025331: train Epoch: [43][ 72/193]	Time 12.164 ( 6.252)	Data 11.592 ( 5.682)	Loss 9.4786e-02 (9.2689e-02) 
2023-05-27 17:46:55.588274: train Epoch: [43][ 73/193]	Time  0.563 ( 6.175)	Data  0.001 ( 5.605)	Loss 8.1862e-02 (9.2543e-02) 
2023-05-27 17:47:07.509856: train Epoch: [43][ 74/193]	Time 11.922 ( 6.252)	Data 11.353 ( 5.681)	Loss 1.5190e-01 (9.3334e-02) 
2023-05-27 17:47:08.333510: train Epoch: [43][ 75/193]	Time  0.824 ( 6.180)	Data  0.257 ( 5.610)	Loss 6.5204e-02 (9.2964e-02) 
2023-05-27 17:47:19.456313: train Epoch: [43][ 76/193]	Time 11.123 ( 6.244)	Data 10.523 ( 5.674)	Loss 7.8651e-02 (9.2778e-02) 
2023-05-27 17:47:20.774011: train Epoch: [43][ 77/193]	Time  1.318 ( 6.181)	Data  0.754 ( 5.611)	Loss 7.3205e-02 (9.2527e-02) 
2023-05-27 17:47:31.943938: train Epoch: [43][ 78/193]	Time 11.170 ( 6.244)	Data 10.593 ( 5.674)	Loss 8.2038e-02 (9.2394e-02) 
2023-05-27 17:47:32.781739: train Epoch: [43][ 79/193]	Time  0.838 ( 6.177)	Data  0.276 ( 5.606)	Loss 1.0984e-01 (9.2612e-02) 
2023-05-27 17:47:44.179317: train Epoch: [43][ 80/193]	Time 11.398 ( 6.241)	Data 10.795 ( 5.670)	Loss 8.3793e-02 (9.2503e-02) 
2023-05-27 17:47:45.398828: train Epoch: [43][ 81/193]	Time  1.220 ( 6.180)	Data  0.645 ( 5.609)	Loss 1.0118e-01 (9.2609e-02) 
2023-05-27 17:47:56.950246: train Epoch: [43][ 82/193]	Time 11.551 ( 6.245)	Data 10.982 ( 5.674)	Loss 9.0063e-02 (9.2579e-02) 
2023-05-27 17:47:57.716621: train Epoch: [43][ 83/193]	Time  0.766 ( 6.179)	Data  0.196 ( 5.609)	Loss 5.5063e-02 (9.2132e-02) 
2023-05-27 17:48:09.018989: train Epoch: [43][ 84/193]	Time 11.302 ( 6.240)	Data 10.691 ( 5.668)	Loss 3.6669e-01 (9.5362e-02) 
2023-05-27 17:48:10.181893: train Epoch: [43][ 85/193]	Time  1.163 ( 6.181)	Data  0.601 ( 5.610)	Loss 8.0963e-02 (9.5195e-02) 
2023-05-27 17:48:21.451175: train Epoch: [43][ 86/193]	Time 11.269 ( 6.239)	Data 10.685 ( 5.668)	Loss 7.4174e-02 (9.4953e-02) 
2023-05-27 17:48:22.488624: train Epoch: [43][ 87/193]	Time  1.037 ( 6.180)	Data  0.459 ( 5.609)	Loss 1.0574e-01 (9.5076e-02) 
2023-05-27 17:48:33.474631: train Epoch: [43][ 88/193]	Time 10.986 ( 6.234)	Data 10.419 ( 5.663)	Loss 1.4778e-01 (9.5668e-02) 
2023-05-27 17:48:34.145490: train Epoch: [43][ 89/193]	Time  0.671 ( 6.172)	Data  0.099 ( 5.601)	Loss 7.6478e-02 (9.5454e-02) 
2023-05-27 17:48:45.456182: train Epoch: [43][ 90/193]	Time 11.311 ( 6.229)	Data 10.744 ( 5.657)	Loss 9.4615e-02 (9.5445e-02) 
2023-05-27 17:48:46.933919: train Epoch: [43][ 91/193]	Time  1.478 ( 6.177)	Data  0.914 ( 5.606)	Loss 1.8639e-01 (9.6434e-02) 
2023-05-27 17:48:57.998538: train Epoch: [43][ 92/193]	Time 11.065 ( 6.230)	Data 10.500 ( 5.659)	Loss 5.9540e-02 (9.6037e-02) 
2023-05-27 17:48:59.436673: train Epoch: [43][ 93/193]	Time  1.438 ( 6.179)	Data  0.878 ( 5.608)	Loss 9.3270e-02 (9.6008e-02) 
2023-05-27 17:49:09.172153: train Epoch: [43][ 94/193]	Time  9.735 ( 6.216)	Data  9.158 ( 5.645)	Loss 1.7898e-01 (9.6881e-02) 
2023-05-27 17:49:10.337867: train Epoch: [43][ 95/193]	Time  1.166 ( 6.163)	Data  0.604 ( 5.593)	Loss 1.5527e-01 (9.7489e-02) 
2023-05-27 17:49:21.141399: train Epoch: [43][ 96/193]	Time 10.804 ( 6.211)	Data 10.242 ( 5.640)	Loss 2.1247e-01 (9.8675e-02) 
2023-05-27 17:49:22.838603: train Epoch: [43][ 97/193]	Time  1.697 ( 6.165)	Data  1.124 ( 5.594)	Loss 5.0610e-02 (9.8184e-02) 
2023-05-27 17:49:33.472499: train Epoch: [43][ 98/193]	Time 10.634 ( 6.210)	Data 10.063 ( 5.640)	Loss 7.2381e-02 (9.7923e-02) 
2023-05-27 17:49:34.786195: train Epoch: [43][ 99/193]	Time  1.314 ( 6.161)	Data  0.751 ( 5.591)	Loss 1.9490e-01 (9.8893e-02) 
2023-05-27 17:49:45.740341: train Epoch: [43][100/193]	Time 10.954 ( 6.209)	Data 10.393 ( 5.638)	Loss 1.5082e-01 (9.9407e-02) 
2023-05-27 17:49:46.957090: train Epoch: [43][101/193]	Time  1.217 ( 6.160)	Data  0.655 ( 5.589)	Loss 8.5651e-02 (9.9273e-02) 
2023-05-27 17:49:57.797953: train Epoch: [43][102/193]	Time 10.841 ( 6.205)	Data 10.274 ( 5.635)	Loss 7.8461e-02 (9.9070e-02) 
2023-05-27 17:49:59.758421: train Epoch: [43][103/193]	Time  1.960 ( 6.165)	Data  1.385 ( 5.594)	Loss 1.0981e-01 (9.9174e-02) 
2023-05-27 17:50:10.110289: train Epoch: [43][104/193]	Time 10.352 ( 6.204)	Data  9.783 ( 5.634)	Loss 6.3292e-02 (9.8832e-02) 
2023-05-27 17:50:11.825948: train Epoch: [43][105/193]	Time  1.716 ( 6.162)	Data  1.154 ( 5.592)	Loss 1.1642e-01 (9.8998e-02) 
2023-05-27 17:50:22.450332: train Epoch: [43][106/193]	Time 10.624 ( 6.204)	Data 10.049 ( 5.633)	Loss 8.0810e-02 (9.8828e-02) 
2023-05-27 17:50:24.204323: train Epoch: [43][107/193]	Time  1.754 ( 6.163)	Data  1.175 ( 5.592)	Loss 5.7307e-02 (9.8444e-02) 
2023-05-27 17:50:34.795820: train Epoch: [43][108/193]	Time 10.591 ( 6.203)	Data  9.997 ( 5.632)	Loss 8.5431e-02 (9.8324e-02) 
2023-05-27 17:50:36.400056: train Epoch: [43][109/193]	Time  1.604 ( 6.161)	Data  1.042 ( 5.591)	Loss 8.4506e-02 (9.8199e-02) 
2023-05-27 17:50:46.834235: train Epoch: [43][110/193]	Time 10.434 ( 6.200)	Data  9.847 ( 5.629)	Loss 7.0439e-02 (9.7948e-02) 
2023-05-27 17:50:48.657418: train Epoch: [43][111/193]	Time  1.823 ( 6.161)	Data  1.249 ( 5.590)	Loss 1.1979e-01 (9.8143e-02) 
2023-05-27 17:50:59.542476: train Epoch: [43][112/193]	Time 10.885 ( 6.203)	Data 10.317 ( 5.632)	Loss 9.2867e-02 (9.8097e-02) 
2023-05-27 17:51:01.282141: train Epoch: [43][113/193]	Time  1.740 ( 6.163)	Data  1.163 ( 5.592)	Loss 1.1785e-01 (9.8270e-02) 
2023-05-27 17:51:11.844783: train Epoch: [43][114/193]	Time 10.563 ( 6.202)	Data  9.993 ( 5.631)	Loss 5.7299e-02 (9.7914e-02) 
2023-05-27 17:51:13.387036: train Epoch: [43][115/193]	Time  1.542 ( 6.162)	Data  0.968 ( 5.591)	Loss 8.2498e-02 (9.7781e-02) 
2023-05-27 17:51:23.789192: train Epoch: [43][116/193]	Time 10.402 ( 6.198)	Data  9.838 ( 5.627)	Loss 1.1127e-01 (9.7896e-02) 
2023-05-27 17:51:25.848815: train Epoch: [43][117/193]	Time  2.060 ( 6.163)	Data  1.485 ( 5.592)	Loss 1.5981e-01 (9.8421e-02) 
2023-05-27 17:51:36.219696: train Epoch: [43][118/193]	Time 10.371 ( 6.198)	Data  9.806 ( 5.627)	Loss 6.7842e-02 (9.8164e-02) 
2023-05-27 17:51:38.157659: train Epoch: [43][119/193]	Time  1.938 ( 6.163)	Data  1.369 ( 5.592)	Loss 4.0391e-02 (9.7682e-02) 
2023-05-27 17:51:48.488605: train Epoch: [43][120/193]	Time 10.331 ( 6.197)	Data  9.765 ( 5.626)	Loss 7.2618e-02 (9.7475e-02) 
2023-05-27 17:51:50.385072: train Epoch: [43][121/193]	Time  1.896 ( 6.162)	Data  1.327 ( 5.591)	Loss 4.6757e-02 (9.7060e-02) 
2023-05-27 17:52:01.492716: train Epoch: [43][122/193]	Time 11.108 ( 6.202)	Data 10.537 ( 5.631)	Loss 5.4559e-02 (9.6714e-02) 
2023-05-27 17:52:02.226511: train Epoch: [43][123/193]	Time  0.734 ( 6.158)	Data  0.172 ( 5.587)	Loss 6.3865e-02 (9.6449e-02) 
2023-05-27 17:52:14.028379: train Epoch: [43][124/193]	Time 11.802 ( 6.203)	Data 11.236 ( 5.632)	Loss 5.5640e-02 (9.6123e-02) 
2023-05-27 17:52:14.590103: train Epoch: [43][125/193]	Time  0.562 ( 6.158)	Data  0.001 ( 5.588)	Loss 1.2361e-01 (9.6341e-02) 
2023-05-27 17:52:26.515852: train Epoch: [43][126/193]	Time 11.926 ( 6.204)	Data 11.364 ( 5.633)	Loss 9.5210e-02 (9.6332e-02) 
2023-05-27 17:52:27.078911: train Epoch: [43][127/193]	Time  0.563 ( 6.160)	Data  0.001 ( 5.589)	Loss 1.3742e-01 (9.6653e-02) 
2023-05-27 17:52:39.262815: train Epoch: [43][128/193]	Time 12.184 ( 6.206)	Data 11.618 ( 5.636)	Loss 5.5996e-02 (9.6338e-02) 
2023-05-27 17:52:39.823264: train Epoch: [43][129/193]	Time  0.560 ( 6.163)	Data  0.001 ( 5.592)	Loss 5.8998e-02 (9.6050e-02) 
2023-05-27 17:52:51.713001: train Epoch: [43][130/193]	Time 11.890 ( 6.207)	Data 11.329 ( 5.636)	Loss 1.3500e-01 (9.6348e-02) 
2023-05-27 17:52:52.273939: train Epoch: [43][131/193]	Time  0.561 ( 6.164)	Data  0.001 ( 5.594)	Loss 6.7905e-02 (9.6132e-02) 
2023-05-27 17:53:04.053976: train Epoch: [43][132/193]	Time 11.780 ( 6.206)	Data 11.219 ( 5.636)	Loss 4.7541e-02 (9.5767e-02) 
2023-05-27 17:53:04.615508: train Epoch: [43][133/193]	Time  0.562 ( 6.164)	Data  0.001 ( 5.594)	Loss 6.0126e-02 (9.5501e-02) 
2023-05-27 17:53:16.495348: train Epoch: [43][134/193]	Time 11.880 ( 6.206)	Data 11.317 ( 5.636)	Loss 6.0745e-02 (9.5244e-02) 
2023-05-27 17:53:17.068844: train Epoch: [43][135/193]	Time  0.574 ( 6.165)	Data  0.001 ( 5.595)	Loss 7.1730e-02 (9.5071e-02) 
2023-05-27 17:53:29.118836: train Epoch: [43][136/193]	Time 12.050 ( 6.208)	Data 11.479 ( 5.638)	Loss 8.5673e-02 (9.5002e-02) 
2023-05-27 17:53:29.677917: train Epoch: [43][137/193]	Time  0.559 ( 6.167)	Data  0.001 ( 5.597)	Loss 5.9025e-02 (9.4741e-02) 
2023-05-27 17:53:41.862008: train Epoch: [43][138/193]	Time 12.184 ( 6.210)	Data 11.624 ( 5.640)	Loss 1.1581e-01 (9.4893e-02) 
2023-05-27 17:53:42.423663: train Epoch: [43][139/193]	Time  0.562 ( 6.170)	Data  0.001 ( 5.600)	Loss 8.3301e-02 (9.4810e-02) 
2023-05-27 17:53:54.588712: train Epoch: [43][140/193]	Time 12.165 ( 6.212)	Data 11.598 ( 5.643)	Loss 5.8483e-02 (9.4552e-02) 
2023-05-27 17:53:55.149843: train Epoch: [43][141/193]	Time  0.561 ( 6.173)	Data  0.001 ( 5.603)	Loss 5.8519e-02 (9.4299e-02) 
2023-05-27 17:54:06.787989: train Epoch: [43][142/193]	Time 11.638 ( 6.211)	Data 11.077 ( 5.641)	Loss 3.8367e-01 (9.6322e-02) 
2023-05-27 17:54:07.350518: train Epoch: [43][143/193]	Time  0.563 ( 6.172)	Data  0.001 ( 5.602)	Loss 1.0338e-01 (9.6371e-02) 
2023-05-27 17:54:19.219457: train Epoch: [43][144/193]	Time 11.869 ( 6.211)	Data 11.302 ( 5.641)	Loss 8.5911e-02 (9.6299e-02) 
2023-05-27 17:54:19.780618: train Epoch: [43][145/193]	Time  0.561 ( 6.172)	Data  0.001 ( 5.603)	Loss 9.3917e-02 (9.6283e-02) 
2023-05-27 17:54:31.102168: train Epoch: [43][146/193]	Time 11.322 ( 6.207)	Data 10.754 ( 5.638)	Loss 6.8822e-02 (9.6096e-02) 
2023-05-27 17:54:31.673075: train Epoch: [43][147/193]	Time  0.571 ( 6.169)	Data  0.001 ( 5.600)	Loss 3.3250e-01 (9.7693e-02) 
2023-05-27 17:54:44.001193: train Epoch: [43][148/193]	Time 12.328 ( 6.210)	Data 11.762 ( 5.641)	Loss 2.0144e-01 (9.8390e-02) 
2023-05-27 17:54:44.580754: train Epoch: [43][149/193]	Time  0.580 ( 6.173)	Data  0.001 ( 5.603)	Loss 1.4269e-01 (9.8685e-02) 
2023-05-27 17:54:56.572093: train Epoch: [43][150/193]	Time 11.991 ( 6.211)	Data 11.413 ( 5.642)	Loss 1.2867e-01 (9.8884e-02) 
2023-05-27 17:54:57.144889: train Epoch: [43][151/193]	Time  0.573 ( 6.174)	Data  0.001 ( 5.605)	Loss 1.9015e-01 (9.9484e-02) 
2023-05-27 17:55:09.185492: train Epoch: [43][152/193]	Time 12.041 ( 6.213)	Data 11.472 ( 5.643)	Loss 1.0735e-01 (9.9535e-02) 
2023-05-27 17:55:09.773298: train Epoch: [43][153/193]	Time  0.588 ( 6.176)	Data  0.001 ( 5.606)	Loss 1.0578e-01 (9.9576e-02) 
2023-05-27 17:55:21.636850: train Epoch: [43][154/193]	Time 11.864 ( 6.213)	Data 11.300 ( 5.643)	Loss 8.8594e-02 (9.9505e-02) 
2023-05-27 17:55:22.225003: train Epoch: [43][155/193]	Time  0.588 ( 6.177)	Data  0.001 ( 5.607)	Loss 1.0643e-01 (9.9549e-02) 
2023-05-27 17:55:34.582928: train Epoch: [43][156/193]	Time 12.358 ( 6.216)	Data 11.781 ( 5.646)	Loss 1.2044e-01 (9.9682e-02) 
2023-05-27 17:55:35.159991: train Epoch: [43][157/193]	Time  0.577 ( 6.180)	Data  0.001 ( 5.611)	Loss 9.2845e-02 (9.9639e-02) 
2023-05-27 17:55:47.080313: train Epoch: [43][158/193]	Time 11.920 ( 6.217)	Data 11.350 ( 5.647)	Loss 1.4063e-01 (9.9897e-02) 
2023-05-27 17:55:47.646192: train Epoch: [43][159/193]	Time  0.566 ( 6.181)	Data  0.001 ( 5.611)	Loss 1.2293e-01 (1.0004e-01) 
2023-05-27 17:55:59.274738: train Epoch: [43][160/193]	Time 11.629 ( 6.215)	Data 11.059 ( 5.645)	Loss 8.1430e-02 (9.9925e-02) 
2023-05-27 17:55:59.839845: train Epoch: [43][161/193]	Time  0.565 ( 6.180)	Data  0.001 ( 5.610)	Loss 1.1370e-01 (1.0001e-01) 
2023-05-27 17:56:11.330901: train Epoch: [43][162/193]	Time 11.491 ( 6.213)	Data 10.920 ( 5.643)	Loss 1.2236e-01 (1.0015e-01) 
2023-05-27 17:56:11.904964: train Epoch: [43][163/193]	Time  0.574 ( 6.178)	Data  0.001 ( 5.609)	Loss 1.5270e-01 (1.0047e-01) 
2023-05-27 17:56:23.939783: train Epoch: [43][164/193]	Time 12.035 ( 6.214)	Data 11.410 ( 5.644)	Loss 2.3357e-01 (1.0127e-01) 
2023-05-27 17:56:24.525033: train Epoch: [43][165/193]	Time  0.585 ( 6.180)	Data  0.001 ( 5.610)	Loss 7.5363e-02 (1.0112e-01) 
2023-05-27 17:56:35.819886: train Epoch: [43][166/193]	Time 11.295 ( 6.211)	Data 10.716 ( 5.640)	Loss 1.6078e-01 (1.0148e-01) 
2023-05-27 17:56:36.445981: train Epoch: [43][167/193]	Time  0.626 ( 6.177)	Data  0.001 ( 5.607)	Loss 1.2248e-01 (1.0160e-01) 
2023-05-27 17:56:47.996059: train Epoch: [43][168/193]	Time 11.550 ( 6.209)	Data 10.989 ( 5.639)	Loss 9.8598e-02 (1.0158e-01) 
2023-05-27 17:56:48.567150: train Epoch: [43][169/193]	Time  0.571 ( 6.176)	Data  0.001 ( 5.605)	Loss 1.5789e-01 (1.0191e-01) 
2023-05-27 17:56:59.991481: train Epoch: [43][170/193]	Time 11.424 ( 6.207)	Data 10.852 ( 5.636)	Loss 1.1127e-01 (1.0197e-01) 
2023-05-27 17:57:00.615164: train Epoch: [43][171/193]	Time  0.624 ( 6.174)	Data  0.001 ( 5.603)	Loss 1.6589e-01 (1.0234e-01) 
2023-05-27 17:57:11.972900: train Epoch: [43][172/193]	Time 11.358 ( 6.204)	Data 10.794 ( 5.633)	Loss 1.0266e-01 (1.0234e-01) 
2023-05-27 17:57:12.565636: train Epoch: [43][173/193]	Time  0.593 ( 6.172)	Data  0.001 ( 5.601)	Loss 1.3710e-01 (1.0254e-01) 
2023-05-27 17:57:24.423576: train Epoch: [43][174/193]	Time 11.858 ( 6.204)	Data 11.280 ( 5.633)	Loss 6.4916e-02 (1.0233e-01) 
2023-05-27 17:57:24.994534: train Epoch: [43][175/193]	Time  0.571 ( 6.172)	Data  0.001 ( 5.601)	Loss 1.0345e-01 (1.0233e-01) 
2023-05-27 17:57:36.632125: train Epoch: [43][176/193]	Time 11.638 ( 6.203)	Data 11.033 ( 5.632)	Loss 9.3900e-02 (1.0229e-01) 
2023-05-27 17:57:37.209607: train Epoch: [43][177/193]	Time  0.578 ( 6.172)	Data  0.001 ( 5.600)	Loss 1.0827e-01 (1.0232e-01) 
2023-05-27 17:57:49.014754: train Epoch: [43][178/193]	Time 11.805 ( 6.203)	Data 11.241 ( 5.632)	Loss 1.5346e-01 (1.0261e-01) 
2023-05-27 17:57:49.593307: train Epoch: [43][179/193]	Time  0.579 ( 6.172)	Data  0.001 ( 5.601)	Loss 7.7676e-02 (1.0247e-01) 
2023-05-27 17:58:00.832843: train Epoch: [43][180/193]	Time 11.240 ( 6.200)	Data 10.667 ( 5.629)	Loss 4.3996e-02 (1.0214e-01) 
2023-05-27 17:58:01.413030: train Epoch: [43][181/193]	Time  0.580 ( 6.169)	Data  0.001 ( 5.598)	Loss 8.9500e-02 (1.0207e-01) 
2023-05-27 17:58:12.412686: train Epoch: [43][182/193]	Time 11.000 ( 6.195)	Data 10.438 ( 5.624)	Loss 1.4018e-01 (1.0228e-01) 
2023-05-27 17:58:12.980823: train Epoch: [43][183/193]	Time  0.568 ( 6.165)	Data  0.001 ( 5.594)	Loss 5.4895e-02 (1.0203e-01) 
2023-05-27 17:58:24.463273: train Epoch: [43][184/193]	Time 11.482 ( 6.194)	Data 10.922 ( 5.622)	Loss 9.5285e-02 (1.0199e-01) 
2023-05-27 17:58:25.024939: train Epoch: [43][185/193]	Time  0.562 ( 6.163)	Data  0.001 ( 5.592)	Loss 6.9786e-02 (1.0182e-01) 
2023-05-27 17:58:36.482260: train Epoch: [43][186/193]	Time 11.457 ( 6.192)	Data 10.897 ( 5.621)	Loss 6.7382e-02 (1.0163e-01) 
2023-05-27 17:58:37.043923: train Epoch: [43][187/193]	Time  0.562 ( 6.162)	Data  0.001 ( 5.591)	Loss 1.2726e-01 (1.0177e-01) 
2023-05-27 17:58:48.760094: train Epoch: [43][188/193]	Time 11.716 ( 6.191)	Data 11.151 ( 5.620)	Loss 2.1945e-01 (1.0239e-01) 
2023-05-27 17:58:49.332641: train Epoch: [43][189/193]	Time  0.573 ( 6.161)	Data  0.001 ( 5.591)	Loss 8.8985e-02 (1.0232e-01) 
2023-05-27 17:59:00.884854: train Epoch: [43][190/193]	Time 11.552 ( 6.190)	Data 10.986 ( 5.619)	Loss 1.0324e-01 (1.0232e-01) 
2023-05-27 17:59:01.445641: train Epoch: [43][191/193]	Time  0.561 ( 6.160)	Data  0.001 ( 5.590)	Loss 9.2056e-02 (1.0227e-01) 
2023-05-27 17:59:12.073741: train Epoch: [43][192/193]	Time 10.628 ( 6.184)	Data 10.055 ( 5.613)	Loss 8.6877e-02 (1.0219e-01) 
2023-05-27 17:59:12.255540: Train Epoch done in 1193.6089945719868 s 
2023-05-27 17:59:20.123042: val Epoch: [43][ 0/72]	Time  7.211 ( 7.211)	Data  7.033 ( 7.033)	Loss 1.0809e-01 (1.0809e-01) 
2023-05-27 17:59:20.232305: val Epoch: [43][ 1/72]	Time  0.109 ( 3.660)	Data  0.001 ( 3.517)	Loss 1.6927e-01 (1.3868e-01) 
2023-05-27 17:59:26.477028: val Epoch: [43][ 2/72]	Time  6.245 ( 4.522)	Data  6.129 ( 4.388)	Loss 8.9502e-02 (1.2229e-01) 
2023-05-27 17:59:26.589962: val Epoch: [43][ 3/72]	Time  0.113 ( 3.420)	Data  0.001 ( 3.291)	Loss 6.8762e-02 (1.0891e-01) 
2023-05-27 17:59:32.863253: val Epoch: [43][ 4/72]	Time  6.273 ( 3.990)	Data  6.160 ( 3.865)	Loss 6.8533e-02 (1.0083e-01) 
2023-05-27 17:59:32.970465: val Epoch: [43][ 5/72]	Time  0.107 ( 3.343)	Data  0.001 ( 3.221)	Loss 8.2915e-02 (9.7846e-02) 
2023-05-27 17:59:39.187023: val Epoch: [43][ 6/72]	Time  6.217 ( 3.754)	Data  6.096 ( 3.632)	Loss 5.9402e-02 (9.2354e-02) 
2023-05-27 17:59:39.303976: val Epoch: [43][ 7/72]	Time  0.117 ( 3.299)	Data  0.001 ( 3.178)	Loss 3.8957e-02 (8.5680e-02) 
2023-05-27 17:59:45.739127: val Epoch: [43][ 8/72]	Time  6.435 ( 3.647)	Data  6.324 ( 3.527)	Loss 1.3065e-01 (9.0676e-02) 
2023-05-27 17:59:45.846654: val Epoch: [43][ 9/72]	Time  0.108 ( 3.293)	Data  0.001 ( 3.175)	Loss 1.4245e-01 (9.5853e-02) 
2023-05-27 17:59:51.891635: val Epoch: [43][10/72]	Time  6.045 ( 3.544)	Data  5.940 ( 3.426)	Loss 1.3574e-01 (9.9479e-02) 
2023-05-27 17:59:51.996464: val Epoch: [43][11/72]	Time  0.105 ( 3.257)	Data  0.000 ( 3.141)	Loss 5.3782e-02 (9.5671e-02) 
2023-05-27 17:59:58.243787: val Epoch: [43][12/72]	Time  6.247 ( 3.487)	Data  6.142 ( 3.371)	Loss 3.7507e-01 (1.1716e-01) 
2023-05-27 17:59:58.349037: val Epoch: [43][13/72]	Time  0.105 ( 3.246)	Data  0.001 ( 3.131)	Loss 1.0269e-01 (1.1613e-01) 
2023-05-27 18:00:04.391523: val Epoch: [43][14/72]	Time  6.042 ( 3.432)	Data  5.937 ( 3.318)	Loss 7.2518e-02 (1.1322e-01) 
2023-05-27 18:00:04.498584: val Epoch: [43][15/72]	Time  0.107 ( 3.224)	Data  0.002 ( 3.111)	Loss 5.4907e-02 (1.0958e-01) 
2023-05-27 18:00:10.706296: val Epoch: [43][16/72]	Time  6.208 ( 3.400)	Data  6.103 ( 3.287)	Loss 1.0053e-01 (1.0904e-01) 
2023-05-27 18:00:10.810675: val Epoch: [43][17/72]	Time  0.104 ( 3.217)	Data  0.000 ( 3.104)	Loss 1.0586e-01 (1.0887e-01) 
2023-05-27 18:00:16.648499: val Epoch: [43][18/72]	Time  5.838 ( 3.355)	Data  5.733 ( 3.242)	Loss 6.8002e-02 (1.0672e-01) 
2023-05-27 18:00:16.754060: val Epoch: [43][19/72]	Time  0.106 ( 3.192)	Data  0.000 ( 3.080)	Loss 8.3041e-02 (1.0553e-01) 
2023-05-27 18:00:22.880577: val Epoch: [43][20/72]	Time  6.127 ( 3.332)	Data  6.017 ( 3.220)	Loss 6.1612e-02 (1.0344e-01) 
2023-05-27 18:00:22.989802: val Epoch: [43][21/72]	Time  0.109 ( 3.185)	Data  0.000 ( 3.074)	Loss 2.7684e-01 (1.1132e-01) 
2023-05-27 18:00:29.080848: val Epoch: [43][22/72]	Time  6.091 ( 3.312)	Data  5.984 ( 3.200)	Loss 1.3967e-01 (1.1256e-01) 
2023-05-27 18:00:29.187195: val Epoch: [43][23/72]	Time  0.106 ( 3.178)	Data  0.000 ( 3.067)	Loss 1.1591e-01 (1.1270e-01) 
2023-05-27 18:00:35.274655: val Epoch: [43][24/72]	Time  6.087 ( 3.295)	Data  5.983 ( 3.184)	Loss 4.6245e-02 (1.1004e-01) 
2023-05-27 18:00:35.379692: val Epoch: [43][25/72]	Time  0.105 ( 3.172)	Data  0.001 ( 3.061)	Loss 1.5780e-01 (1.1187e-01) 
2023-05-27 18:00:41.257669: val Epoch: [43][26/72]	Time  5.878 ( 3.272)	Data  5.770 ( 3.162)	Loss 5.8566e-02 (1.0990e-01) 
2023-05-27 18:00:41.362977: val Epoch: [43][27/72]	Time  0.105 ( 3.159)	Data  0.000 ( 3.049)	Loss 2.3093e-01 (1.1422e-01) 
2023-05-27 18:00:47.564840: val Epoch: [43][28/72]	Time  6.202 ( 3.264)	Data  6.097 ( 3.154)	Loss 1.5586e-01 (1.1566e-01) 
2023-05-27 18:00:47.669412: val Epoch: [43][29/72]	Time  0.105 ( 3.159)	Data  0.000 ( 3.049)	Loss 2.7213e-01 (1.2087e-01) 
2023-05-27 18:00:53.765097: val Epoch: [43][30/72]	Time  6.096 ( 3.253)	Data  5.986 ( 3.143)	Loss 4.7615e-01 (1.3233e-01) 
2023-05-27 18:00:53.873356: val Epoch: [43][31/72]	Time  0.108 ( 3.155)	Data  0.001 ( 3.045)	Loss 1.2930e-01 (1.3224e-01) 
2023-05-27 18:01:00.155628: val Epoch: [43][32/72]	Time  6.282 ( 3.250)	Data  6.177 ( 3.140)	Loss 4.0803e-02 (1.2947e-01) 
2023-05-27 18:01:00.259961: val Epoch: [43][33/72]	Time  0.104 ( 3.157)	Data  0.000 ( 3.048)	Loss 6.7884e-02 (1.2766e-01) 
2023-05-27 18:01:06.599633: val Epoch: [43][34/72]	Time  6.340 ( 3.248)	Data  6.226 ( 3.139)	Loss 5.0516e-02 (1.2545e-01) 
2023-05-27 18:01:06.718406: val Epoch: [43][35/72]	Time  0.119 ( 3.161)	Data  0.001 ( 3.051)	Loss 1.1173e-01 (1.2507e-01) 
2023-05-27 18:01:12.898709: val Epoch: [43][36/72]	Time  6.180 ( 3.243)	Data  6.074 ( 3.133)	Loss 1.1777e-01 (1.2488e-01) 
2023-05-27 18:01:13.004192: val Epoch: [43][37/72]	Time  0.105 ( 3.160)	Data  0.001 ( 3.051)	Loss 9.3264e-02 (1.2404e-01) 
2023-05-27 18:01:19.206657: val Epoch: [43][38/72]	Time  6.202 ( 3.238)	Data  6.096 ( 3.129)	Loss 3.2471e-01 (1.2919e-01) 
2023-05-27 18:01:19.311955: val Epoch: [43][39/72]	Time  0.105 ( 3.160)	Data  0.000 ( 3.051)	Loss 5.7086e-02 (1.2739e-01) 
2023-05-27 18:01:25.140770: val Epoch: [43][40/72]	Time  5.829 ( 3.225)	Data  5.724 ( 3.116)	Loss 5.4087e-02 (1.2560e-01) 
2023-05-27 18:01:25.518296: val Epoch: [43][41/72]	Time  0.378 ( 3.157)	Data  0.272 ( 3.048)	Loss 6.2314e-02 (1.2409e-01) 
2023-05-27 18:01:31.472661: val Epoch: [43][42/72]	Time  5.954 ( 3.222)	Data  5.847 ( 3.113)	Loss 8.8151e-02 (1.2326e-01) 
2023-05-27 18:01:31.635657: val Epoch: [43][43/72]	Time  0.163 ( 3.153)	Data  0.056 ( 3.044)	Loss 6.8318e-02 (1.2201e-01) 
2023-05-27 18:01:37.705375: val Epoch: [43][44/72]	Time  6.070 ( 3.218)	Data  5.962 ( 3.109)	Loss 7.3364e-02 (1.2093e-01) 
2023-05-27 18:01:37.813902: val Epoch: [43][45/72]	Time  0.109 ( 3.150)	Data  0.001 ( 3.041)	Loss 5.3868e-02 (1.1947e-01) 
2023-05-27 18:01:43.788490: val Epoch: [43][46/72]	Time  5.975 ( 3.210)	Data  5.869 ( 3.101)	Loss 2.4483e-01 (1.2214e-01) 
2023-05-27 18:01:43.893714: val Epoch: [43][47/72]	Time  0.105 ( 3.145)	Data  0.000 ( 3.037)	Loss 9.8018e-02 (1.2163e-01) 
2023-05-27 18:01:49.660202: val Epoch: [43][48/72]	Time  5.766 ( 3.199)	Data  5.659 ( 3.090)	Loss 4.3062e-02 (1.2003e-01) 
2023-05-27 18:01:49.767697: val Epoch: [43][49/72]	Time  0.107 ( 3.137)	Data  0.001 ( 3.028)	Loss 3.8143e-01 (1.2526e-01) 
2023-05-27 18:01:55.751681: val Epoch: [43][50/72]	Time  5.984 ( 3.193)	Data  5.872 ( 3.084)	Loss 1.1508e-01 (1.2506e-01) 
2023-05-27 18:01:56.037450: val Epoch: [43][51/72]	Time  0.286 ( 3.137)	Data  0.175 ( 3.028)	Loss 6.1861e-02 (1.2384e-01) 
2023-05-27 18:02:01.971231: val Epoch: [43][52/72]	Time  5.934 ( 3.190)	Data  5.826 ( 3.081)	Loss 8.3960e-02 (1.2309e-01) 
2023-05-27 18:02:02.315433: val Epoch: [43][53/72]	Time  0.344 ( 3.137)	Data  0.237 ( 3.028)	Loss 3.6509e-01 (1.2757e-01) 
2023-05-27 18:02:07.863042: val Epoch: [43][54/72]	Time  5.548 ( 3.181)	Data  5.433 ( 3.072)	Loss 4.6259e-01 (1.3366e-01) 
2023-05-27 18:02:08.258092: val Epoch: [43][55/72]	Time  0.395 ( 3.131)	Data  0.290 ( 3.022)	Loss 5.9804e-02 (1.3234e-01) 
2023-05-27 18:02:13.861720: val Epoch: [43][56/72]	Time  5.604 ( 3.175)	Data  5.499 ( 3.066)	Loss 3.8276e-02 (1.3069e-01) 
2023-05-27 18:02:14.484914: val Epoch: [43][57/72]	Time  0.623 ( 3.131)	Data  0.517 ( 3.022)	Loss 9.6567e-02 (1.3011e-01) 
2023-05-27 18:02:19.910321: val Epoch: [43][58/72]	Time  5.425 ( 3.169)	Data  5.321 ( 3.061)	Loss 6.0230e-02 (1.2892e-01) 
2023-05-27 18:02:20.290121: val Epoch: [43][59/72]	Time  0.380 ( 3.123)	Data  0.259 ( 3.014)	Loss 4.8574e-02 (1.2758e-01) 
2023-05-27 18:02:25.956239: val Epoch: [43][60/72]	Time  5.666 ( 3.165)	Data  5.559 ( 3.056)	Loss 6.4665e-02 (1.2655e-01) 
2023-05-27 18:02:26.459225: val Epoch: [43][61/72]	Time  0.503 ( 3.122)	Data  0.395 ( 3.013)	Loss 1.8298e-01 (1.2746e-01) 
2023-05-27 18:02:32.202727: val Epoch: [43][62/72]	Time  5.743 ( 3.163)	Data  5.628 ( 3.054)	Loss 2.0871e-01 (1.2875e-01) 
2023-05-27 18:02:32.755284: val Epoch: [43][63/72]	Time  0.553 ( 3.123)	Data  0.436 ( 3.013)	Loss 9.8281e-02 (1.2827e-01) 
2023-05-27 18:02:38.054386: val Epoch: [43][64/72]	Time  5.299 ( 3.156)	Data  5.191 ( 3.047)	Loss 7.9195e-02 (1.2752e-01) 
2023-05-27 18:02:38.884646: val Epoch: [43][65/72]	Time  0.830 ( 3.121)	Data  0.726 ( 3.012)	Loss 8.6978e-02 (1.2691e-01) 
2023-05-27 18:02:44.151038: val Epoch: [43][66/72]	Time  5.266 ( 3.153)	Data  5.146 ( 3.044)	Loss 9.1524e-02 (1.2638e-01) 
2023-05-27 18:02:45.292636: val Epoch: [43][67/72]	Time  1.142 ( 3.123)	Data  1.037 ( 3.014)	Loss 3.7143e-01 (1.2998e-01) 
2023-05-27 18:02:50.750681: val Epoch: [43][68/72]	Time  5.458 ( 3.157)	Data  5.350 ( 3.048)	Loss 1.4537e-01 (1.3020e-01) 
2023-05-27 18:02:51.537357: val Epoch: [43][69/72]	Time  0.787 ( 3.123)	Data  0.671 ( 3.014)	Loss 6.6222e-02 (1.2929e-01) 
2023-05-27 18:02:57.026301: val Epoch: [43][70/72]	Time  5.489 ( 3.157)	Data  5.355 ( 3.047)	Loss 1.5851e-01 (1.2970e-01) 
2023-05-27 18:02:57.580801: val Epoch: [43][71/72]	Time  0.555 ( 3.120)	Data  0.446 ( 3.011)	Loss 3.4482e-01 (1.3269e-01) 
2023-05-27 18:02:57.967710: Epoch 43 :Val : ['ET : 0.7310810685157776', 'TC : 0.7885268926620483', 'WT : 0.8529534935951233'] 
2023-05-27 18:02:57.970496: Epoch 43 :Val : ['ET : 0.7310810685157776', 'TC : 0.7885268926620483', 'WT : 0.8529534935951233'] 
2023-05-27 18:02:57.972509: Val epoch done in 225.71697452201624 s 
2023-05-27 18:02:57.979462: Batches per epoch:  193 
2023-05-27 18:03:12.054141: train Epoch: [44][  0/193]	Time 14.074 (14.074)	Data 13.462 (13.462)	Loss 5.2827e-02 (5.2827e-02) 
2023-05-27 18:03:12.616919: train Epoch: [44][  1/193]	Time  0.563 ( 7.319)	Data  0.001 ( 6.731)	Loss 5.1511e-02 (5.2169e-02) 
2023-05-27 18:03:24.454321: train Epoch: [44][  2/193]	Time 11.837 ( 8.825)	Data 11.275 ( 8.246)	Loss 1.3038e-01 (7.8238e-02) 
2023-05-27 18:03:25.015945: train Epoch: [44][  3/193]	Time  0.562 ( 6.759)	Data  0.001 ( 6.185)	Loss 9.7329e-02 (8.3011e-02) 
2023-05-27 18:03:36.808546: train Epoch: [44][  4/193]	Time 11.793 ( 7.766)	Data 11.226 ( 7.193)	Loss 1.0560e-01 (8.7529e-02) 
2023-05-27 18:03:37.370529: train Epoch: [44][  5/193]	Time  0.562 ( 6.565)	Data  0.001 ( 5.994)	Loss 6.5207e-02 (8.3809e-02) 
2023-05-27 18:03:48.947699: train Epoch: [44][  6/193]	Time 11.577 ( 7.281)	Data 11.017 ( 6.712)	Loss 1.3523e-01 (9.1154e-02) 
2023-05-27 18:03:49.510422: train Epoch: [44][  7/193]	Time  0.563 ( 6.441)	Data  0.001 ( 5.873)	Loss 5.7949e-02 (8.7004e-02) 
2023-05-27 18:04:01.046836: train Epoch: [44][  8/193]	Time 11.536 ( 7.007)	Data 10.976 ( 6.440)	Loss 7.4098e-02 (8.5570e-02) 
2023-05-27 18:04:01.608051: train Epoch: [44][  9/193]	Time  0.561 ( 6.363)	Data  0.001 ( 5.796)	Loss 1.0558e-01 (8.7571e-02) 
2023-05-27 18:04:13.236662: train Epoch: [44][ 10/193]	Time 11.629 ( 6.842)	Data 11.060 ( 6.274)	Loss 8.1829e-02 (8.7049e-02) 
2023-05-27 18:04:13.845790: train Epoch: [44][ 11/193]	Time  0.609 ( 6.322)	Data  0.048 ( 5.756)	Loss 1.2108e-01 (8.9885e-02) 
2023-05-27 18:04:26.161000: train Epoch: [44][ 12/193]	Time 12.315 ( 6.783)	Data 11.748 ( 6.217)	Loss 1.0855e-01 (9.1321e-02) 
2023-05-27 18:04:26.726499: train Epoch: [44][ 13/193]	Time  0.565 ( 6.339)	Data  0.001 ( 5.773)	Loss 1.1801e-01 (9.3227e-02) 
2023-05-27 18:04:38.561539: train Epoch: [44][ 14/193]	Time 11.835 ( 6.705)	Data 11.259 ( 6.138)	Loss 6.4303e-02 (9.1299e-02) 
2023-05-27 18:04:39.122594: train Epoch: [44][ 15/193]	Time  0.561 ( 6.321)	Data  0.001 ( 5.755)	Loss 8.9512e-02 (9.1187e-02) 
2023-05-27 18:04:51.006543: train Epoch: [44][ 16/193]	Time 11.884 ( 6.649)	Data 11.248 ( 6.078)	Loss 1.1472e-01 (9.2571e-02) 
2023-05-27 18:04:51.566883: train Epoch: [44][ 17/193]	Time  0.560 ( 6.310)	Data  0.001 ( 5.740)	Loss 1.2308e-01 (9.4266e-02) 
2023-05-27 18:05:03.244295: train Epoch: [44][ 18/193]	Time 11.677 ( 6.593)	Data 11.106 ( 6.023)	Loss 4.2988e-02 (9.1567e-02) 
2023-05-27 18:05:03.817802: train Epoch: [44][ 19/193]	Time  0.574 ( 6.292)	Data  0.001 ( 5.722)	Loss 3.1162e-01 (1.0257e-01) 
2023-05-27 18:05:15.565271: train Epoch: [44][ 20/193]	Time 11.747 ( 6.552)	Data 11.161 ( 5.981)	Loss 9.2387e-02 (1.0209e-01) 
2023-05-27 18:05:16.131243: train Epoch: [44][ 21/193]	Time  0.566 ( 6.280)	Data  0.001 ( 5.709)	Loss 7.1170e-02 (1.0068e-01) 
2023-05-27 18:05:28.277282: train Epoch: [44][ 22/193]	Time 12.146 ( 6.535)	Data 11.577 ( 5.964)	Loss 7.8657e-02 (9.9723e-02) 
2023-05-27 18:05:28.840984: train Epoch: [44][ 23/193]	Time  0.564 ( 6.286)	Data  0.001 ( 5.715)	Loss 6.4084e-02 (9.8238e-02) 
2023-05-27 18:05:40.041032: train Epoch: [44][ 24/193]	Time 11.200 ( 6.482)	Data 10.630 ( 5.912)	Loss 1.4930e-01 (1.0028e-01) 
2023-05-27 18:05:40.615242: train Epoch: [44][ 25/193]	Time  0.574 ( 6.255)	Data  0.001 ( 5.685)	Loss 1.2139e-01 (1.0109e-01) 
2023-05-27 18:05:52.487365: train Epoch: [44][ 26/193]	Time 11.872 ( 6.463)	Data 11.288 ( 5.892)	Loss 6.6081e-02 (9.9795e-02) 
2023-05-27 18:05:53.055959: train Epoch: [44][ 27/193]	Time  0.569 ( 6.253)	Data  0.001 ( 5.682)	Loss 1.0838e-01 (1.0010e-01) 
2023-05-27 18:06:03.752252: train Epoch: [44][ 28/193]	Time 10.696 ( 6.406)	Data 10.124 ( 5.835)	Loss 6.5129e-02 (9.8896e-02) 
2023-05-27 18:06:04.321383: train Epoch: [44][ 29/193]	Time  0.569 ( 6.211)	Data  0.001 ( 5.641)	Loss 1.6919e-01 (1.0124e-01) 
2023-05-27 18:06:14.985028: train Epoch: [44][ 30/193]	Time 10.664 ( 6.355)	Data 10.097 ( 5.784)	Loss 1.3261e-01 (1.0225e-01) 
2023-05-27 18:06:15.556184: train Epoch: [44][ 31/193]	Time  0.571 ( 6.174)	Data  0.001 ( 5.604)	Loss 6.2691e-02 (1.0101e-01) 
2023-05-27 18:06:27.146691: train Epoch: [44][ 32/193]	Time 11.590 ( 6.338)	Data 11.024 ( 5.768)	Loss 1.3977e-01 (1.0219e-01) 
2023-05-27 18:06:27.708330: train Epoch: [44][ 33/193]	Time  0.562 ( 6.168)	Data  0.001 ( 5.598)	Loss 5.7872e-02 (1.0089e-01) 
2023-05-27 18:06:39.533470: train Epoch: [44][ 34/193]	Time 11.825 ( 6.330)	Data 11.257 ( 5.760)	Loss 1.0606e-01 (1.0103e-01) 
2023-05-27 18:06:40.095599: train Epoch: [44][ 35/193]	Time  0.562 ( 6.170)	Data  0.001 ( 5.600)	Loss 6.8767e-02 (1.0014e-01) 
2023-05-27 18:06:51.830022: train Epoch: [44][ 36/193]	Time 11.734 ( 6.320)	Data 11.174 ( 5.751)	Loss 7.8696e-02 (9.9558e-02) 
2023-05-27 18:06:52.392046: train Epoch: [44][ 37/193]	Time  0.562 ( 6.169)	Data  0.001 ( 5.599)	Loss 1.4041e-01 (1.0063e-01) 
2023-05-27 18:07:04.093601: train Epoch: [44][ 38/193]	Time 11.702 ( 6.311)	Data 11.141 ( 5.741)	Loss 8.3966e-02 (1.0021e-01) 
2023-05-27 18:07:04.655674: train Epoch: [44][ 39/193]	Time  0.562 ( 6.167)	Data  0.001 ( 5.598)	Loss 7.6588e-02 (9.9615e-02) 
2023-05-27 18:07:16.565538: train Epoch: [44][ 40/193]	Time 11.910 ( 6.307)	Data 11.345 ( 5.738)	Loss 8.0259e-02 (9.9143e-02) 
2023-05-27 18:07:17.128198: train Epoch: [44][ 41/193]	Time  0.563 ( 6.170)	Data  0.001 ( 5.601)	Loss 6.2065e-02 (9.8260e-02) 
2023-05-27 18:07:29.166727: train Epoch: [44][ 42/193]	Time 12.039 ( 6.307)	Data 11.461 ( 5.738)	Loss 4.4326e-02 (9.7006e-02) 
2023-05-27 18:07:29.728178: train Epoch: [44][ 43/193]	Time  0.561 ( 6.176)	Data  0.001 ( 5.607)	Loss 9.2339e-02 (9.6900e-02) 
2023-05-27 18:07:41.496159: train Epoch: [44][ 44/193]	Time 11.768 ( 6.300)	Data 11.203 ( 5.732)	Loss 7.6256e-02 (9.6441e-02) 
2023-05-27 18:07:42.064746: train Epoch: [44][ 45/193]	Time  0.569 ( 6.176)	Data  0.001 ( 5.607)	Loss 1.6345e-01 (9.7898e-02) 
2023-05-27 18:07:54.074902: train Epoch: [44][ 46/193]	Time 12.010 ( 6.300)	Data 11.450 ( 5.731)	Loss 1.0949e-01 (9.8145e-02) 
2023-05-27 18:07:54.636418: train Epoch: [44][ 47/193]	Time  0.562 ( 6.180)	Data  0.001 ( 5.612)	Loss 4.5277e-02 (9.7043e-02) 
2023-05-27 18:08:07.251009: train Epoch: [44][ 48/193]	Time 12.615 ( 6.312)	Data 12.034 ( 5.743)	Loss 6.9013e-02 (9.6471e-02) 
2023-05-27 18:08:07.813133: train Epoch: [44][ 49/193]	Time  0.562 ( 6.197)	Data  0.001 ( 5.628)	Loss 1.9133e-01 (9.8368e-02) 
2023-05-27 18:08:19.723862: train Epoch: [44][ 50/193]	Time 11.911 ( 6.309)	Data 11.342 ( 5.740)	Loss 9.4660e-02 (9.8296e-02) 
2023-05-27 18:08:20.286227: train Epoch: [44][ 51/193]	Time  0.562 ( 6.198)	Data  0.001 ( 5.630)	Loss 6.8718e-02 (9.7727e-02) 
2023-05-27 18:08:32.170254: train Epoch: [44][ 52/193]	Time 11.884 ( 6.305)	Data 11.322 ( 5.737)	Loss 5.6779e-02 (9.6954e-02) 
2023-05-27 18:08:32.743773: train Epoch: [44][ 53/193]	Time  0.574 ( 6.199)	Data  0.001 ( 5.631)	Loss 6.4248e-02 (9.6349e-02) 
2023-05-27 18:08:44.685426: train Epoch: [44][ 54/193]	Time 11.942 ( 6.304)	Data 11.380 ( 5.736)	Loss 8.6105e-02 (9.6162e-02) 
2023-05-27 18:08:45.247204: train Epoch: [44][ 55/193]	Time  0.562 ( 6.201)	Data  0.001 ( 5.633)	Loss 8.3216e-02 (9.5931e-02) 
2023-05-27 18:08:56.788395: train Epoch: [44][ 56/193]	Time 11.541 ( 6.295)	Data 10.969 ( 5.727)	Loss 1.4098e-01 (9.6722e-02) 
2023-05-27 18:08:57.349414: train Epoch: [44][ 57/193]	Time  0.561 ( 6.196)	Data  0.001 ( 5.628)	Loss 5.1177e-02 (9.5936e-02) 
2023-05-27 18:09:08.496389: train Epoch: [44][ 58/193]	Time 11.147 ( 6.280)	Data 10.586 ( 5.712)	Loss 4.0700e-02 (9.5000e-02) 
2023-05-27 18:09:09.059787: train Epoch: [44][ 59/193]	Time  0.563 ( 6.185)	Data  0.001 ( 5.617)	Loss 4.5503e-02 (9.4175e-02) 
2023-05-27 18:09:21.111760: train Epoch: [44][ 60/193]	Time 12.052 ( 6.281)	Data 11.485 ( 5.713)	Loss 1.0146e-01 (9.4295e-02) 
2023-05-27 18:09:21.673253: train Epoch: [44][ 61/193]	Time  0.561 ( 6.189)	Data  0.001 ( 5.621)	Loss 1.0874e-01 (9.4528e-02) 
2023-05-27 18:09:33.469911: train Epoch: [44][ 62/193]	Time 11.797 ( 6.278)	Data 11.235 ( 5.710)	Loss 5.6658e-02 (9.3926e-02) 
2023-05-27 18:09:34.030232: train Epoch: [44][ 63/193]	Time  0.560 ( 6.188)	Data  0.001 ( 5.621)	Loss 7.0837e-02 (9.3566e-02) 
2023-05-27 18:09:45.216651: train Epoch: [44][ 64/193]	Time 11.186 ( 6.265)	Data 10.608 ( 5.698)	Loss 4.6696e-02 (9.2845e-02) 
2023-05-27 18:09:45.778406: train Epoch: [44][ 65/193]	Time  0.562 ( 6.179)	Data  0.001 ( 5.611)	Loss 1.5911e-01 (9.3849e-02) 
2023-05-27 18:09:57.953979: train Epoch: [44][ 66/193]	Time 12.176 ( 6.268)	Data 11.563 ( 5.700)	Loss 1.3012e-01 (9.4390e-02) 
2023-05-27 18:09:58.520144: train Epoch: [44][ 67/193]	Time  0.566 ( 6.184)	Data  0.001 ( 5.616)	Loss 8.0806e-02 (9.4190e-02) 
2023-05-27 18:10:10.173979: train Epoch: [44][ 68/193]	Time 11.654 ( 6.264)	Data 11.083 ( 5.696)	Loss 1.2581e-01 (9.4649e-02) 
2023-05-27 18:10:10.735813: train Epoch: [44][ 69/193]	Time  0.562 ( 6.182)	Data  0.001 ( 5.614)	Loss 1.0287e-01 (9.4766e-02) 
2023-05-27 18:10:22.561280: train Epoch: [44][ 70/193]	Time 11.825 ( 6.262)	Data 11.247 ( 5.694)	Loss 7.7795e-02 (9.4527e-02) 
2023-05-27 18:10:23.127084: train Epoch: [44][ 71/193]	Time  0.566 ( 6.183)	Data  0.001 ( 5.614)	Loss 8.1982e-02 (9.4353e-02) 
2023-05-27 18:10:35.467004: train Epoch: [44][ 72/193]	Time 12.340 ( 6.267)	Data 11.730 ( 5.698)	Loss 5.6469e-02 (9.3834e-02) 
2023-05-27 18:10:36.031512: train Epoch: [44][ 73/193]	Time  0.564 ( 6.190)	Data  0.001 ( 5.621)	Loss 1.1004e-01 (9.4053e-02) 
2023-05-27 18:10:48.300343: train Epoch: [44][ 74/193]	Time 12.269 ( 6.271)	Data 11.700 ( 5.702)	Loss 7.7310e-02 (9.3830e-02) 
2023-05-27 18:10:48.873163: train Epoch: [44][ 75/193]	Time  0.573 ( 6.196)	Data  0.001 ( 5.627)	Loss 8.3312e-02 (9.3691e-02) 
2023-05-27 18:11:00.994682: train Epoch: [44][ 76/193]	Time 12.122 ( 6.273)	Data 11.555 ( 5.704)	Loss 9.6726e-02 (9.3731e-02) 
2023-05-27 18:11:01.566120: train Epoch: [44][ 77/193]	Time  0.571 ( 6.200)	Data  0.001 ( 5.631)	Loss 9.7398e-02 (9.3778e-02) 
2023-05-27 18:11:13.223217: train Epoch: [44][ 78/193]	Time 11.657 ( 6.269)	Data 11.080 ( 5.700)	Loss 8.0831e-02 (9.3614e-02) 
2023-05-27 18:11:13.791316: train Epoch: [44][ 79/193]	Time  0.568 ( 6.198)	Data  0.001 ( 5.629)	Loss 6.1022e-02 (9.3206e-02) 
2023-05-27 18:11:25.617226: train Epoch: [44][ 80/193]	Time 11.826 ( 6.267)	Data 11.234 ( 5.698)	Loss 4.3021e-02 (9.2587e-02) 
2023-05-27 18:11:26.191638: train Epoch: [44][ 81/193]	Time  0.574 ( 6.198)	Data  0.001 ( 5.629)	Loss 5.6528e-02 (9.2147e-02) 
2023-05-27 18:11:38.009043: train Epoch: [44][ 82/193]	Time 11.817 ( 6.265)	Data 11.245 ( 5.696)	Loss 1.2114e-01 (9.2496e-02) 
2023-05-27 18:11:38.597580: train Epoch: [44][ 83/193]	Time  0.589 ( 6.198)	Data  0.001 ( 5.628)	Loss 8.2368e-02 (9.2376e-02) 
2023-05-27 18:11:50.610680: train Epoch: [44][ 84/193]	Time 12.013 ( 6.266)	Data 11.443 ( 5.697)	Loss 1.1540e-01 (9.2647e-02) 
2023-05-27 18:11:51.182660: train Epoch: [44][ 85/193]	Time  0.572 ( 6.200)	Data  0.001 ( 5.631)	Loss 8.5336e-02 (9.2562e-02) 
2023-05-27 18:12:02.729760: train Epoch: [44][ 86/193]	Time 11.547 ( 6.261)	Data 10.974 ( 5.692)	Loss 4.7292e-02 (9.2041e-02) 
2023-05-27 18:12:03.303473: train Epoch: [44][ 87/193]	Time  0.574 ( 6.197)	Data  0.001 ( 5.627)	Loss 3.4485e-01 (9.4914e-02) 
2023-05-27 18:12:15.084609: train Epoch: [44][ 88/193]	Time 11.781 ( 6.260)	Data 11.205 ( 5.690)	Loss 1.2333e-01 (9.5233e-02) 
2023-05-27 18:12:15.672695: train Epoch: [44][ 89/193]	Time  0.588 ( 6.197)	Data  0.001 ( 5.627)	Loss 1.0507e-01 (9.5343e-02) 
2023-05-27 18:12:27.201095: train Epoch: [44][ 90/193]	Time 11.528 ( 6.255)	Data 10.956 ( 5.685)	Loss 6.6829e-02 (9.5029e-02) 
2023-05-27 18:12:27.767103: train Epoch: [44][ 91/193]	Time  0.566 ( 6.193)	Data  0.001 ( 5.624)	Loss 8.8271e-02 (9.4956e-02) 
2023-05-27 18:12:39.542616: train Epoch: [44][ 92/193]	Time 11.776 ( 6.253)	Data 11.202 ( 5.684)	Loss 9.7147e-02 (9.4979e-02) 
2023-05-27 18:12:40.109858: train Epoch: [44][ 93/193]	Time  0.567 ( 6.193)	Data  0.001 ( 5.623)	Loss 8.9493e-02 (9.4921e-02) 
2023-05-27 18:12:50.852715: train Epoch: [44][ 94/193]	Time 10.743 ( 6.241)	Data 10.168 ( 5.671)	Loss 6.1985e-02 (9.4574e-02) 
2023-05-27 18:12:51.421564: train Epoch: [44][ 95/193]	Time  0.569 ( 6.182)	Data  0.001 ( 5.612)	Loss 7.2194e-02 (9.4341e-02) 
2023-05-27 18:13:03.369460: train Epoch: [44][ 96/193]	Time 11.948 ( 6.241)	Data 11.378 ( 5.671)	Loss 1.1197e-01 (9.4523e-02) 
2023-05-27 18:13:03.940043: train Epoch: [44][ 97/193]	Time  0.571 ( 6.183)	Data  0.001 ( 5.613)	Loss 9.7194e-02 (9.4550e-02) 
2023-05-27 18:13:15.831541: train Epoch: [44][ 98/193]	Time 11.891 ( 6.241)	Data 11.327 ( 5.671)	Loss 7.5923e-02 (9.4362e-02) 
2023-05-27 18:13:16.399826: train Epoch: [44][ 99/193]	Time  0.568 ( 6.184)	Data  0.001 ( 5.615)	Loss 7.4526e-02 (9.4164e-02) 
2023-05-27 18:13:27.995997: train Epoch: [44][100/193]	Time 11.596 ( 6.238)	Data 10.995 ( 5.668)	Loss 1.1761e-01 (9.4396e-02) 
2023-05-27 18:13:28.560541: train Epoch: [44][101/193]	Time  0.565 ( 6.182)	Data  0.001 ( 5.612)	Loss 6.6547e-02 (9.4123e-02) 
2023-05-27 18:13:40.847840: train Epoch: [44][102/193]	Time 12.287 ( 6.241)	Data 11.711 ( 5.671)	Loss 1.0385e-01 (9.4217e-02) 
2023-05-27 18:13:41.445150: train Epoch: [44][103/193]	Time  0.597 ( 6.187)	Data  0.001 ( 5.617)	Loss 9.6495e-02 (9.4239e-02) 
2023-05-27 18:13:53.553353: train Epoch: [44][104/193]	Time 12.108 ( 6.244)	Data 11.545 ( 5.673)	Loss 5.0130e-02 (9.3819e-02) 
2023-05-27 18:13:54.127895: train Epoch: [44][105/193]	Time  0.575 ( 6.190)	Data  0.001 ( 5.620)	Loss 1.2281e-01 (9.4093e-02) 
2023-05-27 18:14:06.810803: train Epoch: [44][106/193]	Time 12.683 ( 6.251)	Data 12.092 ( 5.680)	Loss 1.0355e-01 (9.4181e-02) 
2023-05-27 18:14:07.373450: train Epoch: [44][107/193]	Time  0.563 ( 6.198)	Data  0.001 ( 5.628)	Loss 7.3371e-02 (9.3988e-02) 
2023-05-27 18:14:18.836044: train Epoch: [44][108/193]	Time 11.463 ( 6.246)	Data 10.862 ( 5.676)	Loss 8.2377e-02 (9.3882e-02) 
2023-05-27 18:14:19.402783: train Epoch: [44][109/193]	Time  0.567 ( 6.195)	Data  0.001 ( 5.624)	Loss 7.7116e-02 (9.3729e-02) 
2023-05-27 18:14:31.425853: train Epoch: [44][110/193]	Time 12.023 ( 6.247)	Data 11.452 ( 5.677)	Loss 1.2774e-01 (9.4036e-02) 
2023-05-27 18:14:32.013046: train Epoch: [44][111/193]	Time  0.587 ( 6.197)	Data  0.001 ( 5.626)	Loss 5.8659e-02 (9.3720e-02) 
2023-05-27 18:14:43.960370: train Epoch: [44][112/193]	Time 11.947 ( 6.248)	Data 11.370 ( 5.677)	Loss 5.5368e-02 (9.3380e-02) 
2023-05-27 18:14:44.553506: train Epoch: [44][113/193]	Time  0.593 ( 6.198)	Data  0.001 ( 5.627)	Loss 1.1371e-01 (9.3559e-02) 
2023-05-27 18:14:56.825673: train Epoch: [44][114/193]	Time 12.272 ( 6.251)	Data 11.697 ( 5.680)	Loss 7.5329e-02 (9.3400e-02) 
2023-05-27 18:14:57.394178: train Epoch: [44][115/193]	Time  0.569 ( 6.202)	Data  0.001 ( 5.631)	Loss 8.6848e-02 (9.3344e-02) 
2023-05-27 18:15:08.913163: train Epoch: [44][116/193]	Time 11.519 ( 6.247)	Data 10.946 ( 5.676)	Loss 5.7603e-02 (9.3038e-02) 
2023-05-27 18:15:09.479557: train Epoch: [44][117/193]	Time  0.566 ( 6.199)	Data  0.001 ( 5.628)	Loss 6.2956e-02 (9.2783e-02) 
2023-05-27 18:15:21.459561: train Epoch: [44][118/193]	Time 11.980 ( 6.248)	Data 11.408 ( 5.677)	Loss 9.5937e-02 (9.2810e-02) 
2023-05-27 18:15:22.021654: train Epoch: [44][119/193]	Time  0.562 ( 6.200)	Data  0.001 ( 5.629)	Loss 5.5641e-02 (9.2500e-02) 
2023-05-27 18:15:33.932888: train Epoch: [44][120/193]	Time 11.911 ( 6.248)	Data 11.336 ( 5.677)	Loss 9.3192e-02 (9.2506e-02) 
2023-05-27 18:15:34.522261: train Epoch: [44][121/193]	Time  0.589 ( 6.201)	Data  0.001 ( 5.630)	Loss 1.0447e-01 (9.2604e-02) 
2023-05-27 18:15:46.354658: train Epoch: [44][122/193]	Time 11.832 ( 6.247)	Data 11.261 ( 5.676)	Loss 1.7013e-01 (9.3234e-02) 
2023-05-27 18:15:46.930073: train Epoch: [44][123/193]	Time  0.575 ( 6.201)	Data  0.001 ( 5.630)	Loss 4.4324e-02 (9.2840e-02) 
2023-05-27 18:15:58.570755: train Epoch: [44][124/193]	Time 11.641 ( 6.245)	Data 11.079 ( 5.674)	Loss 6.2153e-02 (9.2594e-02) 
2023-05-27 18:15:59.140489: train Epoch: [44][125/193]	Time  0.570 ( 6.200)	Data  0.001 ( 5.629)	Loss 4.5743e-02 (9.2222e-02) 
2023-05-27 18:16:11.302376: train Epoch: [44][126/193]	Time 12.162 ( 6.247)	Data 11.595 ( 5.676)	Loss 6.8090e-02 (9.2032e-02) 
2023-05-27 18:16:11.869336: train Epoch: [44][127/193]	Time  0.567 ( 6.202)	Data  0.001 ( 5.631)	Loss 8.8805e-02 (9.2007e-02) 
2023-05-27 18:16:23.889397: train Epoch: [44][128/193]	Time 12.020 ( 6.247)	Data 11.453 ( 5.676)	Loss 1.3822e-01 (9.2365e-02) 
2023-05-27 18:16:24.457738: train Epoch: [44][129/193]	Time  0.568 ( 6.204)	Data  0.001 ( 5.633)	Loss 1.3544e-01 (9.2697e-02) 
2023-05-27 18:16:36.763948: train Epoch: [44][130/193]	Time 12.306 ( 6.250)	Data 11.732 ( 5.679)	Loss 5.0517e-02 (9.2375e-02) 
2023-05-27 18:16:37.337591: train Epoch: [44][131/193]	Time  0.574 ( 6.207)	Data  0.001 ( 5.636)	Loss 1.1730e-01 (9.2564e-02) 
2023-05-27 18:16:48.479986: train Epoch: [44][132/193]	Time 11.142 ( 6.244)	Data 10.575 ( 5.673)	Loss 2.0310e-01 (9.3395e-02) 
2023-05-27 18:16:49.041625: train Epoch: [44][133/193]	Time  0.562 ( 6.202)	Data  0.001 ( 5.631)	Loss 5.3585e-02 (9.3098e-02) 
2023-05-27 18:17:00.675924: train Epoch: [44][134/193]	Time 11.634 ( 6.242)	Data 11.074 ( 5.671)	Loss 6.3938e-02 (9.2882e-02) 
2023-05-27 18:17:01.240247: train Epoch: [44][135/193]	Time  0.564 ( 6.200)	Data  0.001 ( 5.630)	Loss 4.7367e-02 (9.2547e-02) 
2023-05-27 18:17:13.130206: train Epoch: [44][136/193]	Time 11.890 ( 6.242)	Data 11.330 ( 5.671)	Loss 2.1592e-01 (9.3448e-02) 
2023-05-27 18:17:13.693036: train Epoch: [44][137/193]	Time  0.563 ( 6.201)	Data  0.001 ( 5.630)	Loss 7.5271e-02 (9.3316e-02) 
2023-05-27 18:17:25.770684: train Epoch: [44][138/193]	Time 12.078 ( 6.243)	Data 11.507 ( 5.673)	Loss 7.1354e-02 (9.3158e-02) 
2023-05-27 18:17:26.341073: train Epoch: [44][139/193]	Time  0.570 ( 6.203)	Data  0.001 ( 5.632)	Loss 9.9161e-02 (9.3201e-02) 
2023-05-27 18:17:37.901664: train Epoch: [44][140/193]	Time 11.561 ( 6.241)	Data 10.996 ( 5.670)	Loss 6.1687e-02 (9.2977e-02) 
2023-05-27 18:17:38.466426: train Epoch: [44][141/193]	Time  0.565 ( 6.201)	Data  0.001 ( 5.630)	Loss 1.3754e-01 (9.3291e-02) 
2023-05-27 18:17:50.539879: train Epoch: [44][142/193]	Time 12.073 ( 6.242)	Data 11.507 ( 5.671)	Loss 6.7138e-02 (9.3108e-02) 
2023-05-27 18:17:51.101087: train Epoch: [44][143/193]	Time  0.561 ( 6.202)	Data  0.001 ( 5.632)	Loss 1.1041e-01 (9.3228e-02) 
2023-05-27 18:18:02.850535: train Epoch: [44][144/193]	Time 11.749 ( 6.240)	Data 11.178 ( 5.670)	Loss 6.6720e-02 (9.3045e-02) 
2023-05-27 18:18:03.422411: train Epoch: [44][145/193]	Time  0.572 ( 6.202)	Data  0.001 ( 5.631)	Loss 7.3545e-02 (9.2912e-02) 
2023-05-27 18:18:15.475738: train Epoch: [44][146/193]	Time 12.053 ( 6.241)	Data 11.485 ( 5.671)	Loss 1.1264e-01 (9.3046e-02) 
2023-05-27 18:18:16.041332: train Epoch: [44][147/193]	Time  0.566 ( 6.203)	Data  0.001 ( 5.633)	Loss 7.2425e-02 (9.2907e-02) 
2023-05-27 18:18:28.388353: train Epoch: [44][148/193]	Time 12.347 ( 6.244)	Data 11.782 ( 5.674)	Loss 1.5919e-01 (9.3352e-02) 
2023-05-27 18:18:28.961888: train Epoch: [44][149/193]	Time  0.574 ( 6.207)	Data  0.001 ( 5.636)	Loss 7.3908e-02 (9.3222e-02) 
2023-05-27 18:18:40.290011: train Epoch: [44][150/193]	Time 11.328 ( 6.240)	Data 10.750 ( 5.670)	Loss 1.5246e-01 (9.3614e-02) 
2023-05-27 18:18:40.873897: train Epoch: [44][151/193]	Time  0.584 ( 6.203)	Data  0.001 ( 5.633)	Loss 8.5442e-02 (9.3561e-02) 
2023-05-27 18:18:52.880996: train Epoch: [44][152/193]	Time 12.007 ( 6.241)	Data 11.436 ( 5.671)	Loss 1.3519e-01 (9.3833e-02) 
2023-05-27 18:18:53.441903: train Epoch: [44][153/193]	Time  0.561 ( 6.204)	Data  0.001 ( 5.634)	Loss 1.6199e-01 (9.4275e-02) 
2023-05-27 18:19:04.770030: train Epoch: [44][154/193]	Time 11.328 ( 6.237)	Data 10.755 ( 5.667)	Loss 8.1984e-02 (9.4196e-02) 
2023-05-27 18:19:05.339172: train Epoch: [44][155/193]	Time  0.569 ( 6.201)	Data  0.001 ( 5.631)	Loss 3.8434e-02 (9.3839e-02) 
2023-05-27 18:19:17.909469: train Epoch: [44][156/193]	Time 12.570 ( 6.242)	Data 12.009 ( 5.671)	Loss 5.8209e-02 (9.3612e-02) 
2023-05-27 18:19:18.470714: train Epoch: [44][157/193]	Time  0.561 ( 6.206)	Data  0.001 ( 5.635)	Loss 2.6948e-02 (9.3190e-02) 
2023-05-27 18:19:29.868661: train Epoch: [44][158/193]	Time 11.398 ( 6.238)	Data 10.823 ( 5.668)	Loss 6.0529e-02 (9.2984e-02) 
2023-05-27 18:19:30.435859: train Epoch: [44][159/193]	Time  0.567 ( 6.203)	Data  0.001 ( 5.633)	Loss 1.0702e-01 (9.3072e-02) 
2023-05-27 18:19:41.888321: train Epoch: [44][160/193]	Time 11.452 ( 6.235)	Data 10.874 ( 5.665)	Loss 9.0773e-02 (9.3058e-02) 
2023-05-27 18:19:42.449437: train Epoch: [44][161/193]	Time  0.561 ( 6.200)	Data  0.001 ( 5.630)	Loss 9.4824e-02 (9.3069e-02) 
2023-05-27 18:19:54.595270: train Epoch: [44][162/193]	Time 12.146 ( 6.237)	Data 11.585 ( 5.667)	Loss 6.0859e-02 (9.2871e-02) 
2023-05-27 18:19:55.156346: train Epoch: [44][163/193]	Time  0.561 ( 6.202)	Data  0.001 ( 5.632)	Loss 7.3879e-02 (9.2755e-02) 
2023-05-27 18:20:06.593637: train Epoch: [44][164/193]	Time 11.437 ( 6.234)	Data 10.876 ( 5.664)	Loss 4.5768e-02 (9.2470e-02) 
2023-05-27 18:20:07.156932: train Epoch: [44][165/193]	Time  0.563 ( 6.200)	Data  0.001 ( 5.630)	Loss 9.1874e-02 (9.2467e-02) 
2023-05-27 18:20:19.032572: train Epoch: [44][166/193]	Time 11.876 ( 6.234)	Data 11.316 ( 5.664)	Loss 7.7306e-02 (9.2376e-02) 
2023-05-27 18:20:19.600823: train Epoch: [44][167/193]	Time  0.568 ( 6.200)	Data  0.001 ( 5.630)	Loss 5.9434e-02 (9.2180e-02) 
2023-05-27 18:20:31.287519: train Epoch: [44][168/193]	Time 11.687 ( 6.233)	Data 11.111 ( 5.663)	Loss 3.7432e-02 (9.1856e-02) 
2023-05-27 18:20:31.850188: train Epoch: [44][169/193]	Time  0.563 ( 6.199)	Data  0.001 ( 5.629)	Loss 8.3461e-02 (9.1807e-02) 
2023-05-27 18:20:44.131631: train Epoch: [44][170/193]	Time 12.281 ( 6.235)	Data 11.720 ( 5.665)	Loss 7.3581e-02 (9.1700e-02) 
2023-05-27 18:20:44.692705: train Epoch: [44][171/193]	Time  0.561 ( 6.202)	Data  0.001 ( 5.632)	Loss 6.9070e-02 (9.1568e-02) 
2023-05-27 18:20:56.699005: train Epoch: [44][172/193]	Time 12.006 ( 6.235)	Data 11.445 ( 5.666)	Loss 6.8201e-02 (9.1433e-02) 
2023-05-27 18:20:57.259930: train Epoch: [44][173/193]	Time  0.561 ( 6.203)	Data  0.001 ( 5.633)	Loss 6.3386e-02 (9.1272e-02) 
2023-05-27 18:21:09.186362: train Epoch: [44][174/193]	Time 11.926 ( 6.235)	Data 11.355 ( 5.666)	Loss 4.7885e-02 (9.1024e-02) 
2023-05-27 18:21:09.748175: train Epoch: [44][175/193]	Time  0.562 ( 6.203)	Data  0.001 ( 5.634)	Loss 1.1812e-01 (9.1178e-02) 
2023-05-27 18:21:21.331015: train Epoch: [44][176/193]	Time 11.583 ( 6.234)	Data 11.019 ( 5.664)	Loss 1.1327e-01 (9.1303e-02) 
2023-05-27 18:21:21.902808: train Epoch: [44][177/193]	Time  0.572 ( 6.202)	Data  0.001 ( 5.632)	Loss 5.5928e-02 (9.1104e-02) 
2023-05-27 18:21:33.699188: train Epoch: [44][178/193]	Time 11.796 ( 6.233)	Data 11.227 ( 5.663)	Loss 5.9362e-02 (9.0927e-02) 
2023-05-27 18:21:34.259016: train Epoch: [44][179/193]	Time  0.560 ( 6.202)	Data  0.001 ( 5.632)	Loss 5.7237e-02 (9.0740e-02) 
2023-05-27 18:21:45.930114: train Epoch: [44][180/193]	Time 11.671 ( 6.232)	Data 11.106 ( 5.662)	Loss 6.4518e-02 (9.0595e-02) 
2023-05-27 18:21:46.497033: train Epoch: [44][181/193]	Time  0.567 ( 6.201)	Data  0.001 ( 5.631)	Loss 9.1310e-02 (9.0599e-02) 
2023-05-27 18:21:58.547112: train Epoch: [44][182/193]	Time 12.050 ( 6.233)	Data 11.450 ( 5.663)	Loss 2.2274e-01 (9.1321e-02) 
2023-05-27 18:21:59.116813: train Epoch: [44][183/193]	Time  0.570 ( 6.202)	Data  0.001 ( 5.632)	Loss 1.0863e-01 (9.1415e-02) 
2023-05-27 18:22:10.681271: train Epoch: [44][184/193]	Time 11.564 ( 6.231)	Data 10.996 ( 5.661)	Loss 7.5097e-02 (9.1327e-02) 
2023-05-27 18:22:11.259610: train Epoch: [44][185/193]	Time  0.578 ( 6.200)	Data  0.001 ( 5.631)	Loss 7.1518e-02 (9.1220e-02) 
2023-05-27 18:22:23.076298: train Epoch: [44][186/193]	Time 11.817 ( 6.230)	Data 11.252 ( 5.661)	Loss 2.3357e-01 (9.1982e-02) 
2023-05-27 18:22:23.651817: train Epoch: [44][187/193]	Time  0.576 ( 6.200)	Data  0.001 ( 5.631)	Loss 1.0227e-01 (9.2036e-02) 
2023-05-27 18:22:34.875824: train Epoch: [44][188/193]	Time 11.224 ( 6.227)	Data 10.660 ( 5.657)	Loss 3.8674e-02 (9.1754e-02) 
2023-05-27 18:22:35.505511: train Epoch: [44][189/193]	Time  0.630 ( 6.197)	Data  0.001 ( 5.628)	Loss 7.7032e-02 (9.1677e-02) 
2023-05-27 18:22:46.287659: train Epoch: [44][190/193]	Time 10.782 ( 6.222)	Data 10.180 ( 5.651)	Loss 1.1426e-01 (9.1795e-02) 
2023-05-27 18:22:46.858807: train Epoch: [44][191/193]	Time  0.571 ( 6.192)	Data  0.001 ( 5.622)	Loss 9.7114e-02 (9.1822e-02) 
2023-05-27 18:22:57.470326: train Epoch: [44][192/193]	Time 10.612 ( 6.215)	Data 10.041 ( 5.645)	Loss 7.6075e-02 (9.1741e-02) 
2023-05-27 18:22:57.661395: Train Epoch done in 1199.6819659849862 s 
2023-05-27 18:23:05.928416: val Epoch: [44][ 0/72]	Time  7.540 ( 7.540)	Data  7.387 ( 7.387)	Loss 7.4256e-02 (7.4256e-02) 
2023-05-27 18:23:06.268263: val Epoch: [44][ 1/72]	Time  0.340 ( 3.940)	Data  0.234 ( 3.811)	Loss 3.2671e-01 (2.0048e-01) 
2023-05-27 18:23:11.859936: val Epoch: [44][ 2/72]	Time  5.592 ( 4.491)	Data  5.484 ( 4.368)	Loss 1.6860e-01 (1.8985e-01) 
2023-05-27 18:23:12.411414: val Epoch: [44][ 3/72]	Time  0.551 ( 3.506)	Data  0.446 ( 3.388)	Loss 5.2837e-02 (1.5560e-01) 
2023-05-27 18:23:17.833622: val Epoch: [44][ 4/72]	Time  5.422 ( 3.889)	Data  5.313 ( 3.773)	Loss 5.0927e-02 (1.3467e-01) 
2023-05-27 18:23:18.629355: val Epoch: [44][ 5/72]	Time  0.796 ( 3.374)	Data  0.688 ( 3.259)	Loss 1.2121e-01 (1.3242e-01) 
2023-05-27 18:23:23.998569: val Epoch: [44][ 6/72]	Time  5.369 ( 3.659)	Data  5.261 ( 3.545)	Loss 1.4580e-01 (1.3433e-01) 
2023-05-27 18:23:24.924950: val Epoch: [44][ 7/72]	Time  0.926 ( 3.317)	Data  0.818 ( 3.204)	Loss 1.3868e-01 (1.3488e-01) 
2023-05-27 18:23:29.989579: val Epoch: [44][ 8/72]	Time  5.065 ( 3.511)	Data  4.952 ( 3.398)	Loss 4.3409e-02 (1.2471e-01) 
2023-05-27 18:23:31.114244: val Epoch: [44][ 9/72]	Time  1.125 ( 3.273)	Data  1.015 ( 3.160)	Loss 1.8448e-01 (1.3069e-01) 
2023-05-27 18:23:36.032018: val Epoch: [44][10/72]	Time  4.918 ( 3.422)	Data  4.808 ( 3.310)	Loss 1.0672e-01 (1.2851e-01) 
2023-05-27 18:23:36.860129: val Epoch: [44][11/72]	Time  0.828 ( 3.206)	Data  0.721 ( 3.094)	Loss 1.0544e-01 (1.2659e-01) 
2023-05-27 18:23:42.382221: val Epoch: [44][12/72]	Time  5.522 ( 3.384)	Data  5.415 ( 3.272)	Loss 2.1372e-01 (1.3329e-01) 
2023-05-27 18:23:43.062955: val Epoch: [44][13/72]	Time  0.681 ( 3.191)	Data  0.565 ( 3.079)	Loss 3.0788e-01 (1.4576e-01) 
2023-05-27 18:23:48.248620: val Epoch: [44][14/72]	Time  5.186 ( 3.324)	Data  5.080 ( 3.212)	Loss 1.4311e-01 (1.4559e-01) 
2023-05-27 18:23:48.963743: val Epoch: [44][15/72]	Time  0.715 ( 3.161)	Data  0.610 ( 3.050)	Loss 6.5452e-02 (1.4058e-01) 
2023-05-27 18:23:54.431910: val Epoch: [44][16/72]	Time  5.468 ( 3.297)	Data  5.360 ( 3.186)	Loss 6.2664e-02 (1.3599e-01) 
2023-05-27 18:23:55.273618: val Epoch: [44][17/72]	Time  0.842 ( 3.160)	Data  0.734 ( 3.049)	Loss 3.0825e-01 (1.4556e-01) 
2023-05-27 18:24:00.388015: val Epoch: [44][18/72]	Time  5.114 ( 3.263)	Data  5.006 ( 3.152)	Loss 5.9857e-02 (1.4105e-01) 
2023-05-27 18:24:01.441572: val Epoch: [44][19/72]	Time  1.054 ( 3.153)	Data  0.945 ( 3.042)	Loss 8.4908e-02 (1.3825e-01) 
2023-05-27 18:24:06.679658: val Epoch: [44][20/72]	Time  5.238 ( 3.252)	Data  5.133 ( 3.142)	Loss 3.6867e-01 (1.4922e-01) 
2023-05-27 18:24:07.646603: val Epoch: [44][21/72]	Time  0.967 ( 3.148)	Data  0.851 ( 3.038)	Loss 8.6781e-02 (1.4638e-01) 
2023-05-27 18:24:12.826741: val Epoch: [44][22/72]	Time  5.180 ( 3.236)	Data  5.057 ( 3.125)	Loss 1.3890e-01 (1.4606e-01) 
2023-05-27 18:24:13.741879: val Epoch: [44][23/72]	Time  0.915 ( 3.140)	Data  0.810 ( 3.029)	Loss 4.3314e-02 (1.4177e-01) 
2023-05-27 18:24:18.850779: val Epoch: [44][24/72]	Time  5.109 ( 3.219)	Data  4.978 ( 3.107)	Loss 2.3884e-01 (1.4566e-01) 
2023-05-27 18:24:19.799200: val Epoch: [44][25/72]	Time  0.948 ( 3.131)	Data  0.839 ( 3.020)	Loss 1.0538e-01 (1.4411e-01) 
2023-05-27 18:24:25.330843: val Epoch: [44][26/72]	Time  5.532 ( 3.220)	Data  5.382 ( 3.107)	Loss 1.7019e-01 (1.4507e-01) 
2023-05-27 18:24:25.953839: val Epoch: [44][27/72]	Time  0.623 ( 3.127)	Data  0.513 ( 3.014)	Loss 3.6059e-02 (1.4118e-01) 
2023-05-27 18:24:31.585634: val Epoch: [44][28/72]	Time  5.632 ( 3.214)	Data  5.456 ( 3.099)	Loss 2.2735e-01 (1.4415e-01) 
2023-05-27 18:24:32.117449: val Epoch: [44][29/72]	Time  0.532 ( 3.124)	Data  0.423 ( 3.009)	Loss 4.1477e-02 (1.4073e-01) 
2023-05-27 18:24:38.086373: val Epoch: [44][30/72]	Time  5.969 ( 3.216)	Data  5.863 ( 3.102)	Loss 8.0540e-02 (1.3879e-01) 
2023-05-27 18:24:38.309730: val Epoch: [44][31/72]	Time  0.223 ( 3.123)	Data  0.118 ( 3.008)	Loss 1.2402e-01 (1.3833e-01) 
2023-05-27 18:24:44.458677: val Epoch: [44][32/72]	Time  6.149 ( 3.214)	Data  6.043 ( 3.100)	Loss 7.4897e-02 (1.3640e-01) 
2023-05-27 18:24:44.563843: val Epoch: [44][33/72]	Time  0.105 ( 3.123)	Data  0.000 ( 3.009)	Loss 7.0561e-02 (1.3447e-01) 
2023-05-27 18:24:50.594104: val Epoch: [44][34/72]	Time  6.030 ( 3.206)	Data  5.925 ( 3.092)	Loss 8.8752e-02 (1.3316e-01) 
2023-05-27 18:24:50.698780: val Epoch: [44][35/72]	Time  0.105 ( 3.120)	Data  0.000 ( 3.007)	Loss 8.0156e-02 (1.3169e-01) 
2023-05-27 18:24:56.823037: val Epoch: [44][36/72]	Time  6.124 ( 3.201)	Data  6.017 ( 3.088)	Loss 5.2660e-02 (1.2955e-01) 
2023-05-27 18:24:56.930678: val Epoch: [44][37/72]	Time  0.108 ( 3.120)	Data  0.001 ( 3.007)	Loss 4.8940e-02 (1.2743e-01) 
2023-05-27 18:25:03.414877: val Epoch: [44][38/72]	Time  6.484 ( 3.206)	Data  6.374 ( 3.093)	Loss 4.3814e-02 (1.2529e-01) 
2023-05-27 18:25:03.523970: val Epoch: [44][39/72]	Time  0.109 ( 3.128)	Data  0.000 ( 3.016)	Loss 8.3367e-02 (1.2424e-01) 
2023-05-27 18:25:09.963331: val Epoch: [44][40/72]	Time  6.439 ( 3.209)	Data  6.332 ( 3.097)	Loss 1.2696e-01 (1.2431e-01) 
2023-05-27 18:25:10.068738: val Epoch: [44][41/72]	Time  0.105 ( 3.135)	Data  0.001 ( 3.023)	Loss 1.2585e-01 (1.2434e-01) 
2023-05-27 18:25:16.432234: val Epoch: [44][42/72]	Time  6.363 ( 3.210)	Data  6.258 ( 3.098)	Loss 4.3367e-01 (1.3154e-01) 
2023-05-27 18:25:16.537147: val Epoch: [44][43/72]	Time  0.105 ( 3.140)	Data  0.001 ( 3.028)	Loss 4.1285e-02 (1.2949e-01) 
2023-05-27 18:25:22.878142: val Epoch: [44][44/72]	Time  6.341 ( 3.211)	Data  6.235 ( 3.099)	Loss 7.3664e-02 (1.2824e-01) 
2023-05-27 18:25:22.983232: val Epoch: [44][45/72]	Time  0.105 ( 3.143)	Data  0.001 ( 3.032)	Loss 4.6703e-01 (1.3561e-01) 
2023-05-27 18:25:29.220026: val Epoch: [44][46/72]	Time  6.237 ( 3.209)	Data  6.128 ( 3.097)	Loss 3.0971e-01 (1.3931e-01) 
2023-05-27 18:25:29.327834: val Epoch: [44][47/72]	Time  0.108 ( 3.145)	Data  0.001 ( 3.033)	Loss 3.8062e-02 (1.3720e-01) 
2023-05-27 18:25:35.143013: val Epoch: [44][48/72]	Time  5.815 ( 3.199)	Data  5.707 ( 3.088)	Loss 7.3653e-02 (1.3591e-01) 
2023-05-27 18:25:35.251142: val Epoch: [44][49/72]	Time  0.108 ( 3.137)	Data  0.001 ( 3.026)	Loss 4.9223e-02 (1.3417e-01) 
2023-05-27 18:25:41.634233: val Epoch: [44][50/72]	Time  6.383 ( 3.201)	Data  6.272 ( 3.089)	Loss 8.9484e-02 (1.3330e-01) 
2023-05-27 18:25:41.741990: val Epoch: [44][51/72]	Time  0.108 ( 3.141)	Data  0.001 ( 3.030)	Loss 6.2952e-02 (1.3194e-01) 
2023-05-27 18:25:47.559946: val Epoch: [44][52/72]	Time  5.818 ( 3.192)	Data  5.710 ( 3.081)	Loss 3.5558e-02 (1.3013e-01) 
2023-05-27 18:25:47.667548: val Epoch: [44][53/72]	Time  0.108 ( 3.135)	Data  0.001 ( 3.024)	Loss 9.7670e-02 (1.2953e-01) 
2023-05-27 18:25:53.543108: val Epoch: [44][54/72]	Time  5.876 ( 3.185)	Data  5.762 ( 3.073)	Loss 5.9819e-02 (1.2826e-01) 
2023-05-27 18:25:53.653997: val Epoch: [44][55/72]	Time  0.111 ( 3.130)	Data  0.001 ( 3.018)	Loss 6.6382e-02 (1.2715e-01) 
2023-05-27 18:25:59.634721: val Epoch: [44][56/72]	Time  5.981 ( 3.180)	Data  5.869 ( 3.068)	Loss 6.0457e-02 (1.2598e-01) 
2023-05-27 18:25:59.744013: val Epoch: [44][57/72]	Time  0.109 ( 3.127)	Data  0.001 ( 3.016)	Loss 3.9323e-01 (1.3059e-01) 
2023-05-27 18:26:06.320482: val Epoch: [44][58/72]	Time  6.576 ( 3.185)	Data  6.468 ( 3.074)	Loss 1.3633e-01 (1.3069e-01) 
2023-05-27 18:26:06.428766: val Epoch: [44][59/72]	Time  0.108 ( 3.134)	Data  0.001 ( 3.023)	Loss 3.3728e-02 (1.2907e-01) 
2023-05-27 18:26:12.730636: val Epoch: [44][60/72]	Time  6.302 ( 3.186)	Data  6.194 ( 3.075)	Loss 9.7857e-02 (1.2856e-01) 
2023-05-27 18:26:12.844386: val Epoch: [44][61/72]	Time  0.114 ( 3.136)	Data  0.001 ( 3.025)	Loss 6.5245e-02 (1.2754e-01) 
2023-05-27 18:26:19.279656: val Epoch: [44][62/72]	Time  6.435 ( 3.189)	Data  6.327 ( 3.078)	Loss 5.0906e-02 (1.2632e-01) 
2023-05-27 18:26:19.387531: val Epoch: [44][63/72]	Time  0.108 ( 3.141)	Data  0.000 ( 3.030)	Loss 9.3048e-02 (1.2580e-01) 
2023-05-27 18:26:25.385628: val Epoch: [44][64/72]	Time  5.998 ( 3.185)	Data  5.890 ( 3.074)	Loss 5.5836e-02 (1.2473e-01) 
2023-05-27 18:26:25.504380: val Epoch: [44][65/72]	Time  0.119 ( 3.138)	Data  0.000 ( 3.027)	Loss 4.7604e-02 (1.2356e-01) 
2023-05-27 18:26:31.348468: val Epoch: [44][66/72]	Time  5.844 ( 3.179)	Data  5.737 ( 3.068)	Loss 6.4961e-02 (1.2268e-01) 
2023-05-27 18:26:31.456260: val Epoch: [44][67/72]	Time  0.108 ( 3.133)	Data  0.001 ( 3.022)	Loss 9.1799e-02 (1.2223e-01) 
2023-05-27 18:26:37.738368: val Epoch: [44][68/72]	Time  6.282 ( 3.179)	Data  6.167 ( 3.068)	Loss 9.8646e-02 (1.2189e-01) 
2023-05-27 18:26:37.877306: val Epoch: [44][69/72]	Time  0.139 ( 3.136)	Data  0.001 ( 3.024)	Loss 3.3393e-02 (1.2062e-01) 
2023-05-27 18:26:43.766004: val Epoch: [44][70/72]	Time  5.889 ( 3.174)	Data  5.780 ( 3.063)	Loss 4.0830e-01 (1.2467e-01) 
2023-05-27 18:26:43.870805: val Epoch: [44][71/72]	Time  0.105 ( 3.132)	Data  0.000 ( 3.020)	Loss 5.6144e-02 (1.2372e-01) 
2023-05-27 18:26:44.200282: Epoch 44 :Val : ['ET : 0.7429001331329346', 'TC : 0.7957988977432251', 'WT : 0.8664839267730713'] 
2023-05-27 18:26:44.201170: Epoch 44 :Val : ['ET : 0.7429001331329346', 'TC : 0.7957988977432251', 'WT : 0.8664839267730713'] 
2023-05-27 18:26:44.205969: Val epoch done in 226.54456950200256 s 
2023-05-27 18:26:44.219823: Batches per epoch:  193 
2023-05-27 18:26:58.214011: train Epoch: [45][  0/193]	Time 13.994 (13.994)	Data 13.404 (13.404)	Loss 5.5536e-02 (5.5536e-02) 
2023-05-27 18:26:58.776448: train Epoch: [45][  1/193]	Time  0.562 ( 7.278)	Data  0.001 ( 6.703)	Loss 1.1604e-01 (8.5789e-02) 
2023-05-27 18:27:11.157321: train Epoch: [45][  2/193]	Time 12.381 ( 8.979)	Data 11.813 ( 8.406)	Loss 1.2261e-01 (9.8061e-02) 
2023-05-27 18:27:11.721661: train Epoch: [45][  3/193]	Time  0.564 ( 6.875)	Data  0.001 ( 6.305)	Loss 8.1391e-02 (9.3894e-02) 
2023-05-27 18:27:23.408923: train Epoch: [45][  4/193]	Time 11.687 ( 7.838)	Data 11.120 ( 7.268)	Loss 5.8444e-02 (8.6804e-02) 
2023-05-27 18:27:23.972176: train Epoch: [45][  5/193]	Time  0.563 ( 6.625)	Data  0.001 ( 6.057)	Loss 1.7249e-01 (1.0108e-01) 
2023-05-27 18:27:35.971570: train Epoch: [45][  6/193]	Time 11.999 ( 7.393)	Data 11.436 ( 6.825)	Loss 8.7516e-02 (9.9146e-02) 
2023-05-27 18:27:36.535340: train Epoch: [45][  7/193]	Time  0.564 ( 6.539)	Data  0.001 ( 5.972)	Loss 4.5840e-02 (9.2483e-02) 
2023-05-27 18:27:48.021044: train Epoch: [45][  8/193]	Time 11.486 ( 7.089)	Data 10.923 ( 6.522)	Loss 4.4121e-02 (8.7109e-02) 
2023-05-27 18:27:48.946777: train Epoch: [45][  9/193]	Time  0.926 ( 6.473)	Data  0.351 ( 5.905)	Loss 1.0166e-01 (8.8565e-02) 
2023-05-27 18:28:00.785026: train Epoch: [45][ 10/193]	Time 11.838 ( 6.960)	Data 11.276 ( 6.393)	Loss 5.0736e-02 (8.5126e-02) 
2023-05-27 18:28:01.346872: train Epoch: [45][ 11/193]	Time  0.562 ( 6.427)	Data  0.001 ( 5.861)	Loss 1.7124e-01 (9.2302e-02) 
2023-05-27 18:28:12.879342: train Epoch: [45][ 12/193]	Time 11.532 ( 6.820)	Data 10.960 ( 6.253)	Loss 6.9466e-02 (9.0545e-02) 
2023-05-27 18:28:13.443079: train Epoch: [45][ 13/193]	Time  0.564 ( 6.373)	Data  0.001 ( 5.806)	Loss 1.3791e-01 (9.3929e-02) 
2023-05-27 18:28:25.831644: train Epoch: [45][ 14/193]	Time 12.389 ( 6.774)	Data 11.824 ( 6.208)	Loss 1.0033e-01 (9.4355e-02) 
2023-05-27 18:28:26.408184: train Epoch: [45][ 15/193]	Time  0.577 ( 6.387)	Data  0.001 ( 5.820)	Loss 6.0031e-02 (9.2210e-02) 
2023-05-27 18:28:38.275401: train Epoch: [45][ 16/193]	Time 11.867 ( 6.709)	Data 11.305 ( 6.142)	Loss 6.8554e-02 (9.0818e-02) 
2023-05-27 18:28:38.838711: train Epoch: [45][ 17/193]	Time  0.563 ( 6.368)	Data  0.001 ( 5.801)	Loss 7.2508e-02 (8.9801e-02) 
2023-05-27 18:28:50.281553: train Epoch: [45][ 18/193]	Time 11.443 ( 6.635)	Data 10.875 ( 6.068)	Loss 9.4711e-02 (9.0060e-02) 
2023-05-27 18:28:51.183223: train Epoch: [45][ 19/193]	Time  0.902 ( 6.348)	Data  0.340 ( 5.782)	Loss 3.3151e-02 (8.7214e-02) 
2023-05-27 18:29:02.535991: train Epoch: [45][ 20/193]	Time 11.353 ( 6.586)	Data 10.782 ( 6.020)	Loss 1.2214e-01 (8.8877e-02) 
2023-05-27 18:29:03.296988: train Epoch: [45][ 21/193]	Time  0.761 ( 6.322)	Data  0.199 ( 5.755)	Loss 1.0153e-01 (8.9452e-02) 
2023-05-27 18:29:15.132905: train Epoch: [45][ 22/193]	Time 11.836 ( 6.561)	Data 11.274 ( 5.995)	Loss 5.4363e-02 (8.7927e-02) 
2023-05-27 18:29:15.695364: train Epoch: [45][ 23/193]	Time  0.562 ( 6.311)	Data  0.001 ( 5.746)	Loss 5.6993e-02 (8.6638e-02) 
2023-05-27 18:29:27.247986: train Epoch: [45][ 24/193]	Time 11.553 ( 6.521)	Data 10.990 ( 5.955)	Loss 9.7961e-02 (8.7091e-02) 
2023-05-27 18:29:27.810106: train Epoch: [45][ 25/193]	Time  0.562 ( 6.292)	Data  0.001 ( 5.726)	Loss 5.0075e-02 (8.5667e-02) 
2023-05-27 18:29:39.315862: train Epoch: [45][ 26/193]	Time 11.506 ( 6.485)	Data 10.946 ( 5.920)	Loss 1.0606e-01 (8.6422e-02) 
2023-05-27 18:29:39.879776: train Epoch: [45][ 27/193]	Time  0.564 ( 6.274)	Data  0.001 ( 5.708)	Loss 7.2818e-02 (8.5937e-02) 
2023-05-27 18:29:50.241850: train Epoch: [45][ 28/193]	Time 10.362 ( 6.415)	Data  9.794 ( 5.849)	Loss 6.3948e-02 (8.5178e-02) 
2023-05-27 18:29:50.804526: train Epoch: [45][ 29/193]	Time  0.563 ( 6.219)	Data  0.001 ( 5.654)	Loss 1.0684e-01 (8.5900e-02) 
2023-05-27 18:30:00.416276: train Epoch: [45][ 30/193]	Time  9.612 ( 6.329)	Data  9.049 ( 5.764)	Loss 7.0686e-02 (8.5410e-02) 
2023-05-27 18:30:00.980299: train Epoch: [45][ 31/193]	Time  0.564 ( 6.149)	Data  0.001 ( 5.584)	Loss 4.8833e-02 (8.4267e-02) 
2023-05-27 18:30:12.794936: train Epoch: [45][ 32/193]	Time 11.815 ( 6.320)	Data 11.253 ( 5.755)	Loss 1.1152e-01 (8.5092e-02) 
2023-05-27 18:30:13.357743: train Epoch: [45][ 33/193]	Time  0.563 ( 6.151)	Data  0.001 ( 5.586)	Loss 9.3766e-02 (8.5348e-02) 
2023-05-27 18:30:25.141651: train Epoch: [45][ 34/193]	Time 11.784 ( 6.312)	Data 11.216 ( 5.747)	Loss 8.3479e-02 (8.5294e-02) 
2023-05-27 18:30:25.704426: train Epoch: [45][ 35/193]	Time  0.563 ( 6.152)	Data  0.001 ( 5.587)	Loss 5.9986e-02 (8.4591e-02) 
2023-05-27 18:30:37.340381: train Epoch: [45][ 36/193]	Time 11.636 ( 6.301)	Data 11.068 ( 5.736)	Loss 1.0861e-01 (8.5240e-02) 
2023-05-27 18:30:37.903181: train Epoch: [45][ 37/193]	Time  0.563 ( 6.150)	Data  0.001 ( 5.585)	Loss 8.6841e-02 (8.5282e-02) 
2023-05-27 18:30:49.749789: train Epoch: [45][ 38/193]	Time 11.847 ( 6.296)	Data 11.285 ( 5.731)	Loss 9.0643e-02 (8.5420e-02) 
2023-05-27 18:30:50.312002: train Epoch: [45][ 39/193]	Time  0.562 ( 6.152)	Data  0.001 ( 5.588)	Loss 9.2551e-02 (8.5598e-02) 
2023-05-27 18:31:01.913729: train Epoch: [45][ 40/193]	Time 11.602 ( 6.285)	Data 11.040 ( 5.721)	Loss 5.3719e-02 (8.4821e-02) 
2023-05-27 18:31:02.475021: train Epoch: [45][ 41/193]	Time  0.561 ( 6.149)	Data  0.001 ( 5.584)	Loss 7.0598e-02 (8.4482e-02) 
2023-05-27 18:31:14.675432: train Epoch: [45][ 42/193]	Time 12.200 ( 6.290)	Data 11.635 ( 5.725)	Loss 1.8109e-01 (8.6728e-02) 
2023-05-27 18:31:15.243717: train Epoch: [45][ 43/193]	Time  0.568 ( 6.160)	Data  0.001 ( 5.595)	Loss 1.0477e-01 (8.7139e-02) 
2023-05-27 18:31:27.124306: train Epoch: [45][ 44/193]	Time 11.881 ( 6.287)	Data 11.310 ( 5.722)	Loss 6.2080e-02 (8.6582e-02) 
2023-05-27 18:31:27.686311: train Epoch: [45][ 45/193]	Time  0.562 ( 6.162)	Data  0.001 ( 5.598)	Loss 1.3278e-01 (8.7586e-02) 
2023-05-27 18:31:39.392380: train Epoch: [45][ 46/193]	Time 11.706 ( 6.280)	Data 11.139 ( 5.716)	Loss 1.0925e-01 (8.8047e-02) 
2023-05-27 18:31:39.961549: train Epoch: [45][ 47/193]	Time  0.569 ( 6.161)	Data  0.001 ( 5.596)	Loss 1.4088e-01 (8.9148e-02) 
2023-05-27 18:31:51.832781: train Epoch: [45][ 48/193]	Time 11.871 ( 6.278)	Data 11.310 ( 5.713)	Loss 4.5163e-02 (8.8250e-02) 
2023-05-27 18:31:52.398071: train Epoch: [45][ 49/193]	Time  0.565 ( 6.164)	Data  0.001 ( 5.599)	Loss 1.0805e-01 (8.8646e-02) 
2023-05-27 18:32:04.155868: train Epoch: [45][ 50/193]	Time 11.758 ( 6.273)	Data 11.184 ( 5.708)	Loss 4.8897e-02 (8.7867e-02) 
2023-05-27 18:32:04.718908: train Epoch: [45][ 51/193]	Time  0.563 ( 6.163)	Data  0.001 ( 5.599)	Loss 1.4171e-01 (8.8902e-02) 
2023-05-27 18:32:16.382443: train Epoch: [45][ 52/193]	Time 11.664 ( 6.267)	Data 11.095 ( 5.702)	Loss 5.2114e-02 (8.8208e-02) 
2023-05-27 18:32:16.949428: train Epoch: [45][ 53/193]	Time  0.567 ( 6.162)	Data  0.001 ( 5.597)	Loss 5.6619e-02 (8.7623e-02) 
2023-05-27 18:32:29.109995: train Epoch: [45][ 54/193]	Time 12.161 ( 6.271)	Data 11.593 ( 5.706)	Loss 8.1447e-02 (8.7511e-02) 
2023-05-27 18:32:29.686163: train Epoch: [45][ 55/193]	Time  0.576 ( 6.169)	Data  0.001 ( 5.604)	Loss 1.0316e-01 (8.7790e-02) 
2023-05-27 18:32:41.674371: train Epoch: [45][ 56/193]	Time 11.988 ( 6.271)	Data 11.405 ( 5.706)	Loss 5.0257e-02 (8.7132e-02) 
2023-05-27 18:32:42.263328: train Epoch: [45][ 57/193]	Time  0.589 ( 6.173)	Data  0.001 ( 5.607)	Loss 7.1618e-02 (8.6864e-02) 
2023-05-27 18:32:53.921321: train Epoch: [45][ 58/193]	Time 11.658 ( 6.266)	Data 11.085 ( 5.700)	Loss 8.6277e-02 (8.6854e-02) 
2023-05-27 18:32:54.483496: train Epoch: [45][ 59/193]	Time  0.562 ( 6.171)	Data  0.001 ( 5.605)	Loss 5.9480e-02 (8.6398e-02) 
2023-05-27 18:33:05.993083: train Epoch: [45][ 60/193]	Time 11.510 ( 6.259)	Data 10.941 ( 5.693)	Loss 1.7566e-01 (8.7861e-02) 
2023-05-27 18:33:06.580034: train Epoch: [45][ 61/193]	Time  0.587 ( 6.167)	Data  0.001 ( 5.601)	Loss 7.6352e-02 (8.7676e-02) 
2023-05-27 18:33:18.580484: train Epoch: [45][ 62/193]	Time 12.000 ( 6.260)	Data 11.384 ( 5.693)	Loss 7.6192e-02 (8.7493e-02) 
2023-05-27 18:33:19.150088: train Epoch: [45][ 63/193]	Time  0.570 ( 6.171)	Data  0.001 ( 5.604)	Loss 9.3367e-02 (8.7585e-02) 
2023-05-27 18:33:30.497802: train Epoch: [45][ 64/193]	Time 11.348 ( 6.250)	Data 10.783 ( 5.683)	Loss 1.2483e-01 (8.8158e-02) 
2023-05-27 18:33:31.072723: train Epoch: [45][ 65/193]	Time  0.575 ( 6.164)	Data  0.001 ( 5.597)	Loss 6.9370e-02 (8.7874e-02) 
2023-05-27 18:33:43.081835: train Epoch: [45][ 66/193]	Time 12.009 ( 6.252)	Data 11.435 ( 5.684)	Loss 5.0809e-02 (8.7320e-02) 
2023-05-27 18:33:43.652841: train Epoch: [45][ 67/193]	Time  0.571 ( 6.168)	Data  0.001 ( 5.601)	Loss 6.7250e-02 (8.7025e-02) 
2023-05-27 18:33:55.311196: train Epoch: [45][ 68/193]	Time 11.658 ( 6.248)	Data 11.092 ( 5.680)	Loss 1.2347e-01 (8.7553e-02) 
2023-05-27 18:33:55.884448: train Epoch: [45][ 69/193]	Time  0.573 ( 6.167)	Data  0.001 ( 5.599)	Loss 5.1049e-02 (8.7032e-02) 
2023-05-27 18:34:07.534511: train Epoch: [45][ 70/193]	Time 11.650 ( 6.244)	Data 11.080 ( 5.676)	Loss 1.1566e-01 (8.7435e-02) 
2023-05-27 18:34:08.096418: train Epoch: [45][ 71/193]	Time  0.562 ( 6.165)	Data  0.001 ( 5.598)	Loss 1.1252e-01 (8.7784e-02) 
2023-05-27 18:34:20.009526: train Epoch: [45][ 72/193]	Time 11.913 ( 6.244)	Data 11.304 ( 5.676)	Loss 4.3434e-02 (8.7176e-02) 
2023-05-27 18:34:20.570890: train Epoch: [45][ 73/193]	Time  0.561 ( 6.167)	Data  0.001 ( 5.599)	Loss 1.5495e-01 (8.8092e-02) 
2023-05-27 18:34:31.818849: train Epoch: [45][ 74/193]	Time 11.248 ( 6.235)	Data 10.666 ( 5.667)	Loss 7.3247e-02 (8.7894e-02) 
2023-05-27 18:34:32.415843: train Epoch: [45][ 75/193]	Time  0.597 ( 6.160)	Data  0.001 ( 5.592)	Loss 9.2420e-02 (8.7954e-02) 
2023-05-27 18:34:44.302246: train Epoch: [45][ 76/193]	Time 11.886 ( 6.235)	Data 11.298 ( 5.666)	Loss 1.0096e-01 (8.8122e-02) 
2023-05-27 18:34:44.866699: train Epoch: [45][ 77/193]	Time  0.564 ( 6.162)	Data  0.001 ( 5.594)	Loss 8.5264e-02 (8.8086e-02) 
2023-05-27 18:34:56.839385: train Epoch: [45][ 78/193]	Time 11.973 ( 6.236)	Data 11.409 ( 5.667)	Loss 7.1416e-02 (8.7875e-02) 
2023-05-27 18:34:57.417529: train Epoch: [45][ 79/193]	Time  0.578 ( 6.165)	Data  0.001 ( 5.596)	Loss 5.9597e-02 (8.7521e-02) 
2023-05-27 18:35:09.148714: train Epoch: [45][ 80/193]	Time 11.731 ( 6.234)	Data 11.162 ( 5.665)	Loss 6.7418e-02 (8.7273e-02) 
2023-05-27 18:35:09.718673: train Epoch: [45][ 81/193]	Time  0.570 ( 6.165)	Data  0.001 ( 5.596)	Loss 8.5787e-02 (8.7255e-02) 
2023-05-27 18:35:21.787735: train Epoch: [45][ 82/193]	Time 12.069 ( 6.236)	Data 11.477 ( 5.667)	Loss 8.8550e-02 (8.7271e-02) 
2023-05-27 18:35:22.380294: train Epoch: [45][ 83/193]	Time  0.593 ( 6.169)	Data  0.001 ( 5.599)	Loss 5.8361e-02 (8.6926e-02) 
2023-05-27 18:35:34.173368: train Epoch: [45][ 84/193]	Time 11.793 ( 6.235)	Data 11.219 ( 5.666)	Loss 6.1228e-02 (8.6624e-02) 
2023-05-27 18:35:34.774651: train Epoch: [45][ 85/193]	Time  0.601 ( 6.169)	Data  0.001 ( 5.600)	Loss 7.0665e-02 (8.6438e-02) 
2023-05-27 18:35:46.459627: train Epoch: [45][ 86/193]	Time 11.685 ( 6.233)	Data 11.119 ( 5.663)	Loss 9.8612e-02 (8.6578e-02) 
2023-05-27 18:35:47.024957: train Epoch: [45][ 87/193]	Time  0.565 ( 6.168)	Data  0.001 ( 5.599)	Loss 5.0750e-02 (8.6171e-02) 
2023-05-27 18:35:59.000736: train Epoch: [45][ 88/193]	Time 11.976 ( 6.233)	Data 11.389 ( 5.664)	Loss 8.4107e-02 (8.6148e-02) 
2023-05-27 18:35:59.571973: train Epoch: [45][ 89/193]	Time  0.571 ( 6.171)	Data  0.001 ( 5.601)	Loss 8.2268e-02 (8.6105e-02) 
2023-05-27 18:36:11.479764: train Epoch: [45][ 90/193]	Time 11.908 ( 6.234)	Data 11.340 ( 5.664)	Loss 4.7873e-02 (8.5685e-02) 
2023-05-27 18:36:12.044419: train Epoch: [45][ 91/193]	Time  0.565 ( 6.172)	Data  0.001 ( 5.602)	Loss 4.7366e-02 (8.5268e-02) 
2023-05-27 18:36:23.958729: train Epoch: [45][ 92/193]	Time 11.914 ( 6.234)	Data 11.354 ( 5.664)	Loss 9.8600e-02 (8.5412e-02) 
2023-05-27 18:36:24.539004: train Epoch: [45][ 93/193]	Time  0.580 ( 6.174)	Data  0.001 ( 5.604)	Loss 7.7848e-02 (8.5331e-02) 
2023-05-27 18:36:35.146823: train Epoch: [45][ 94/193]	Time 10.608 ( 6.220)	Data 10.047 ( 5.651)	Loss 6.1198e-02 (8.5077e-02) 
2023-05-27 18:36:35.710755: train Epoch: [45][ 95/193]	Time  0.564 ( 6.161)	Data  0.001 ( 5.592)	Loss 4.3505e-02 (8.4644e-02) 
2023-05-27 18:36:46.928657: train Epoch: [45][ 96/193]	Time 11.218 ( 6.213)	Data 10.639 ( 5.644)	Loss 5.1568e-02 (8.4303e-02) 
2023-05-27 18:36:47.502538: train Epoch: [45][ 97/193]	Time  0.574 ( 6.156)	Data  0.001 ( 5.586)	Loss 7.7847e-02 (8.4237e-02) 
2023-05-27 18:36:59.002599: train Epoch: [45][ 98/193]	Time 11.500 ( 6.210)	Data 10.933 ( 5.640)	Loss 6.0424e-02 (8.3997e-02) 
2023-05-27 18:36:59.592670: train Epoch: [45][ 99/193]	Time  0.590 ( 6.154)	Data  0.001 ( 5.584)	Loss 1.3045e-01 (8.4461e-02) 
2023-05-27 18:37:11.722697: train Epoch: [45][100/193]	Time 12.130 ( 6.213)	Data 11.559 ( 5.643)	Loss 1.0329e-01 (8.4648e-02) 
2023-05-27 18:37:12.285596: train Epoch: [45][101/193]	Time  0.563 ( 6.158)	Data  0.001 ( 5.588)	Loss 9.6300e-02 (8.4762e-02) 
2023-05-27 18:37:24.460859: train Epoch: [45][102/193]	Time 12.175 ( 6.216)	Data 11.604 ( 5.646)	Loss 4.7491e-02 (8.4400e-02) 
2023-05-27 18:37:25.022999: train Epoch: [45][103/193]	Time  0.562 ( 6.162)	Data  0.001 ( 5.592)	Loss 5.1368e-02 (8.4082e-02) 
2023-05-27 18:37:37.255358: train Epoch: [45][104/193]	Time 12.232 ( 6.219)	Data 11.655 ( 5.650)	Loss 5.8452e-02 (8.3838e-02) 
2023-05-27 18:37:37.817521: train Epoch: [45][105/193]	Time  0.562 ( 6.166)	Data  0.001 ( 5.596)	Loss 3.7449e-02 (8.3401e-02) 
2023-05-27 18:37:49.747655: train Epoch: [45][106/193]	Time 11.930 ( 6.220)	Data 11.342 ( 5.650)	Loss 4.9657e-02 (8.3085e-02) 
2023-05-27 18:37:50.309516: train Epoch: [45][107/193]	Time  0.562 ( 6.167)	Data  0.001 ( 5.598)	Loss 9.8792e-02 (8.3231e-02) 
2023-05-27 18:38:02.000195: train Epoch: [45][108/193]	Time 11.691 ( 6.218)	Data 11.121 ( 5.648)	Loss 3.9623e-02 (8.2831e-02) 
2023-05-27 18:38:02.576020: train Epoch: [45][109/193]	Time  0.576 ( 6.167)	Data  0.001 ( 5.597)	Loss 8.9241e-02 (8.2889e-02) 
2023-05-27 18:38:13.595406: train Epoch: [45][110/193]	Time 11.019 ( 6.211)	Data 10.445 ( 5.641)	Loss 9.2294e-02 (8.2974e-02) 
2023-05-27 18:38:14.164212: train Epoch: [45][111/193]	Time  0.569 ( 6.160)	Data  0.001 ( 5.590)	Loss 8.4759e-02 (8.2990e-02) 
2023-05-27 18:38:26.011188: train Epoch: [45][112/193]	Time 11.847 ( 6.211)	Data 11.277 ( 5.641)	Loss 5.3928e-02 (8.2733e-02) 
2023-05-27 18:38:26.582040: train Epoch: [45][113/193]	Time  0.571 ( 6.161)	Data  0.001 ( 5.591)	Loss 3.6614e-02 (8.2328e-02) 
2023-05-27 18:38:38.343270: train Epoch: [45][114/193]	Time 11.761 ( 6.210)	Data 11.185 ( 5.640)	Loss 6.5032e-02 (8.2178e-02) 
2023-05-27 18:38:38.906708: train Epoch: [45][115/193]	Time  0.563 ( 6.161)	Data  0.001 ( 5.591)	Loss 7.0879e-02 (8.2080e-02) 
2023-05-27 18:38:50.601475: train Epoch: [45][116/193]	Time 11.695 ( 6.208)	Data 11.119 ( 5.639)	Loss 6.0662e-02 (8.1897e-02) 
2023-05-27 18:38:51.165659: train Epoch: [45][117/193]	Time  0.564 ( 6.161)	Data  0.001 ( 5.591)	Loss 6.5245e-02 (8.1756e-02) 
2023-05-27 18:39:02.846229: train Epoch: [45][118/193]	Time 11.681 ( 6.207)	Data 11.103 ( 5.637)	Loss 8.4502e-02 (8.1779e-02) 
2023-05-27 18:39:03.424199: train Epoch: [45][119/193]	Time  0.578 ( 6.160)	Data  0.001 ( 5.590)	Loss 1.0374e-01 (8.1962e-02) 
2023-05-27 18:39:14.373049: train Epoch: [45][120/193]	Time 10.949 ( 6.200)	Data 10.386 ( 5.630)	Loss 7.9707e-02 (8.1943e-02) 
2023-05-27 18:39:14.948380: train Epoch: [45][121/193]	Time  0.575 ( 6.154)	Data  0.001 ( 5.584)	Loss 9.8679e-02 (8.2081e-02) 
2023-05-27 18:39:26.420133: train Epoch: [45][122/193]	Time 11.472 ( 6.197)	Data 10.905 ( 5.627)	Loss 4.8343e-02 (8.1806e-02) 
2023-05-27 18:39:26.986829: train Epoch: [45][123/193]	Time  0.567 ( 6.151)	Data  0.001 ( 5.582)	Loss 5.2779e-02 (8.1572e-02) 
2023-05-27 18:39:38.768517: train Epoch: [45][124/193]	Time 11.782 ( 6.196)	Data 11.216 ( 5.627)	Loss 7.4570e-02 (8.1516e-02) 
2023-05-27 18:39:39.337363: train Epoch: [45][125/193]	Time  0.569 ( 6.152)	Data  0.001 ( 5.582)	Loss 8.9950e-02 (8.1583e-02) 
2023-05-27 18:39:50.936344: train Epoch: [45][126/193]	Time 11.599 ( 6.195)	Data 11.016 ( 5.625)	Loss 7.5995e-02 (8.1539e-02) 
2023-05-27 18:39:51.497510: train Epoch: [45][127/193]	Time  0.561 ( 6.151)	Data  0.001 ( 5.581)	Loss 6.5623e-02 (8.1415e-02) 
2023-05-27 18:40:03.214348: train Epoch: [45][128/193]	Time 11.717 ( 6.194)	Data 11.151 ( 5.624)	Loss 7.6979e-02 (8.1380e-02) 
2023-05-27 18:40:03.783476: train Epoch: [45][129/193]	Time  0.569 ( 6.150)	Data  0.001 ( 5.581)	Loss 4.0440e-02 (8.1066e-02) 
2023-05-27 18:40:15.878045: train Epoch: [45][130/193]	Time 12.095 ( 6.196)	Data 11.491 ( 5.626)	Loss 1.0838e-01 (8.1274e-02) 
2023-05-27 18:40:16.443630: train Epoch: [45][131/193]	Time  0.566 ( 6.153)	Data  0.001 ( 5.583)	Loss 5.7785e-02 (8.1096e-02) 
2023-05-27 18:40:28.009046: train Epoch: [45][132/193]	Time 11.565 ( 6.194)	Data 10.995 ( 5.624)	Loss 8.8979e-02 (8.1155e-02) 
2023-05-27 18:40:28.570571: train Epoch: [45][133/193]	Time  0.562 ( 6.152)	Data  0.001 ( 5.582)	Loss 9.8432e-02 (8.1284e-02) 
2023-05-27 18:40:40.819743: train Epoch: [45][134/193]	Time 12.249 ( 6.197)	Data 11.675 ( 5.627)	Loss 4.9656e-02 (8.1050e-02) 
2023-05-27 18:40:41.381711: train Epoch: [45][135/193]	Time  0.562 ( 6.156)	Data  0.001 ( 5.586)	Loss 1.6757e-01 (8.1686e-02) 
2023-05-27 18:40:52.971821: train Epoch: [45][136/193]	Time 11.590 ( 6.195)	Data 11.024 ( 5.625)	Loss 4.7494e-02 (8.1437e-02) 
2023-05-27 18:40:53.533629: train Epoch: [45][137/193]	Time  0.562 ( 6.154)	Data  0.001 ( 5.585)	Loss 6.4598e-02 (8.1315e-02) 
2023-05-27 18:41:05.910805: train Epoch: [45][138/193]	Time 12.377 ( 6.199)	Data 11.807 ( 5.629)	Loss 7.5127e-02 (8.1270e-02) 
2023-05-27 18:41:06.473721: train Epoch: [45][139/193]	Time  0.563 ( 6.159)	Data  0.001 ( 5.589)	Loss 2.0174e-01 (8.2131e-02) 
2023-05-27 18:41:18.583504: train Epoch: [45][140/193]	Time 12.110 ( 6.201)	Data 11.541 ( 5.631)	Loss 9.4798e-02 (8.2220e-02) 
2023-05-27 18:41:19.146017: train Epoch: [45][141/193]	Time  0.563 ( 6.161)	Data  0.001 ( 5.592)	Loss 7.0720e-02 (8.2139e-02) 
2023-05-27 18:41:31.157310: train Epoch: [45][142/193]	Time 12.011 ( 6.202)	Data 11.440 ( 5.633)	Loss 8.7016e-02 (8.2173e-02) 
2023-05-27 18:41:31.721086: train Epoch: [45][143/193]	Time  0.564 ( 6.163)	Data  0.001 ( 5.594)	Loss 7.7697e-02 (8.2142e-02) 
2023-05-27 18:41:43.027279: train Epoch: [45][144/193]	Time 11.306 ( 6.199)	Data 10.742 ( 5.629)	Loss 9.6277e-02 (8.2240e-02) 
2023-05-27 18:41:43.598266: train Epoch: [45][145/193]	Time  0.571 ( 6.160)	Data  0.001 ( 5.591)	Loss 6.7247e-02 (8.2137e-02) 
2023-05-27 18:41:56.298357: train Epoch: [45][146/193]	Time 12.700 ( 6.205)	Data 12.137 ( 5.635)	Loss 1.3452e-01 (8.2494e-02) 
2023-05-27 18:41:56.885978: train Epoch: [45][147/193]	Time  0.588 ( 6.167)	Data  0.001 ( 5.597)	Loss 8.1771e-02 (8.2489e-02) 
2023-05-27 18:42:09.048028: train Epoch: [45][148/193]	Time 12.162 ( 6.207)	Data 11.594 ( 5.637)	Loss 7.6374e-02 (8.2448e-02) 
2023-05-27 18:42:09.623222: train Epoch: [45][149/193]	Time  0.575 ( 6.169)	Data  0.001 ( 5.600)	Loss 8.9390e-02 (8.2494e-02) 
2023-05-27 18:42:22.364110: train Epoch: [45][150/193]	Time 12.741 ( 6.213)	Data 12.163 ( 5.643)	Loss 1.3667e-01 (8.2853e-02) 
2023-05-27 18:42:22.947250: train Epoch: [45][151/193]	Time  0.583 ( 6.176)	Data  0.001 ( 5.606)	Loss 5.7724e-02 (8.2687e-02) 
2023-05-27 18:42:35.258985: train Epoch: [45][152/193]	Time 12.312 ( 6.216)	Data 11.735 ( 5.646)	Loss 5.3169e-02 (8.2494e-02) 
2023-05-27 18:42:35.831703: train Epoch: [45][153/193]	Time  0.573 ( 6.179)	Data  0.001 ( 5.609)	Loss 7.8782e-02 (8.2470e-02) 
2023-05-27 18:42:47.007574: train Epoch: [45][154/193]	Time 11.176 ( 6.212)	Data 10.612 ( 5.642)	Loss 7.1335e-02 (8.2399e-02) 
2023-05-27 18:42:47.571741: train Epoch: [45][155/193]	Time  0.564 ( 6.175)	Data  0.001 ( 5.606)	Loss 1.2969e-01 (8.2702e-02) 
2023-05-27 18:43:00.242248: train Epoch: [45][156/193]	Time 12.671 ( 6.217)	Data 12.097 ( 5.647)	Loss 6.5812e-02 (8.2594e-02) 
2023-05-27 18:43:00.829185: train Epoch: [45][157/193]	Time  0.587 ( 6.181)	Data  0.001 ( 5.611)	Loss 8.4404e-02 (8.2606e-02) 
2023-05-27 18:43:12.411194: train Epoch: [45][158/193]	Time 11.582 ( 6.215)	Data 11.014 ( 5.645)	Loss 9.4199e-02 (8.2678e-02) 
2023-05-27 18:43:12.973613: train Epoch: [45][159/193]	Time  0.562 ( 6.180)	Data  0.001 ( 5.610)	Loss 7.0212e-02 (8.2601e-02) 
2023-05-27 18:43:24.616424: train Epoch: [45][160/193]	Time 11.643 ( 6.214)	Data 11.079 ( 5.644)	Loss 5.4144e-02 (8.2424e-02) 
2023-05-27 18:43:25.184599: train Epoch: [45][161/193]	Time  0.568 ( 6.179)	Data  0.001 ( 5.609)	Loss 9.9569e-02 (8.2530e-02) 
2023-05-27 18:43:37.559186: train Epoch: [45][162/193]	Time 12.375 ( 6.217)	Data 11.814 ( 5.647)	Loss 7.7639e-02 (8.2500e-02) 
2023-05-27 18:43:38.125082: train Epoch: [45][163/193]	Time  0.566 ( 6.182)	Data  0.001 ( 5.613)	Loss 1.7283e-01 (8.3050e-02) 
2023-05-27 18:43:50.863124: train Epoch: [45][164/193]	Time 12.738 ( 6.222)	Data 12.165 ( 5.652)	Loss 1.4330e-01 (8.3416e-02) 
2023-05-27 18:43:51.431828: train Epoch: [45][165/193]	Time  0.569 ( 6.188)	Data  0.001 ( 5.618)	Loss 8.9567e-02 (8.3453e-02) 
2023-05-27 18:44:03.323564: train Epoch: [45][166/193]	Time 11.892 ( 6.222)	Data 11.327 ( 5.652)	Loss 1.4250e-01 (8.3806e-02) 
2023-05-27 18:44:03.888161: train Epoch: [45][167/193]	Time  0.565 ( 6.188)	Data  0.001 ( 5.619)	Loss 7.7231e-02 (8.3767e-02) 
2023-05-27 18:44:15.495519: train Epoch: [45][168/193]	Time 11.607 ( 6.221)	Data 11.045 ( 5.651)	Loss 4.1472e-02 (8.3517e-02) 
2023-05-27 18:44:16.083077: train Epoch: [45][169/193]	Time  0.588 ( 6.187)	Data  0.001 ( 5.618)	Loss 7.8341e-02 (8.3486e-02) 
2023-05-27 18:44:27.843540: train Epoch: [45][170/193]	Time 11.760 ( 6.220)	Data 11.197 ( 5.650)	Loss 6.2182e-02 (8.3362e-02) 
2023-05-27 18:44:28.406806: train Epoch: [45][171/193]	Time  0.563 ( 6.187)	Data  0.001 ( 5.617)	Loss 9.8745e-02 (8.3451e-02) 
2023-05-27 18:44:40.395543: train Epoch: [45][172/193]	Time 11.989 ( 6.221)	Data 11.415 ( 5.651)	Loss 1.6676e-01 (8.3933e-02) 
2023-05-27 18:44:40.965515: train Epoch: [45][173/193]	Time  0.570 ( 6.188)	Data  0.001 ( 5.619)	Loss 7.0070e-02 (8.3853e-02) 
2023-05-27 18:44:53.053428: train Epoch: [45][174/193]	Time 12.088 ( 6.222)	Data 11.516 ( 5.652)	Loss 1.1643e-01 (8.4039e-02) 
2023-05-27 18:44:53.617349: train Epoch: [45][175/193]	Time  0.564 ( 6.190)	Data  0.001 ( 5.620)	Loss 7.9315e-02 (8.4012e-02) 
2023-05-27 18:45:04.656214: train Epoch: [45][176/193]	Time 11.039 ( 6.217)	Data 10.477 ( 5.648)	Loss 5.3409e-02 (8.3840e-02) 
2023-05-27 18:45:05.219104: train Epoch: [45][177/193]	Time  0.563 ( 6.185)	Data  0.001 ( 5.616)	Loss 7.3401e-02 (8.3781e-02) 
2023-05-27 18:45:17.382611: train Epoch: [45][178/193]	Time 12.163 ( 6.219)	Data 11.590 ( 5.649)	Loss 8.2270e-02 (8.3772e-02) 
2023-05-27 18:45:17.944225: train Epoch: [45][179/193]	Time  0.562 ( 6.187)	Data  0.001 ( 5.618)	Loss 6.9229e-02 (8.3692e-02) 
2023-05-27 18:45:29.687135: train Epoch: [45][180/193]	Time 11.743 ( 6.218)	Data 11.181 ( 5.649)	Loss 7.4328e-02 (8.3640e-02) 
2023-05-27 18:45:30.270355: train Epoch: [45][181/193]	Time  0.583 ( 6.187)	Data  0.001 ( 5.618)	Loss 1.5727e-01 (8.4045e-02) 
2023-05-27 18:45:42.419028: train Epoch: [45][182/193]	Time 12.149 ( 6.220)	Data 11.587 ( 5.650)	Loss 7.7584e-02 (8.4009e-02) 
2023-05-27 18:45:42.984042: train Epoch: [45][183/193]	Time  0.565 ( 6.189)	Data  0.001 ( 5.619)	Loss 7.7510e-02 (8.3974e-02) 
2023-05-27 18:45:55.108418: train Epoch: [45][184/193]	Time 12.124 ( 6.221)	Data 11.563 ( 5.652)	Loss 5.4210e-02 (8.3813e-02) 
2023-05-27 18:45:55.672178: train Epoch: [45][185/193]	Time  0.564 ( 6.191)	Data  0.001 ( 5.621)	Loss 5.4355e-02 (8.3655e-02) 
2023-05-27 18:46:07.482743: train Epoch: [45][186/193]	Time 11.811 ( 6.221)	Data 11.234 ( 5.651)	Loss 8.0251e-02 (8.3636e-02) 
2023-05-27 18:46:08.051470: train Epoch: [45][187/193]	Time  0.569 ( 6.191)	Data  0.001 ( 5.621)	Loss 7.8930e-02 (8.3611e-02) 
2023-05-27 18:46:20.179047: train Epoch: [45][188/193]	Time 12.128 ( 6.222)	Data 11.559 ( 5.653)	Loss 4.9752e-02 (8.3432e-02) 
2023-05-27 18:46:20.747311: train Epoch: [45][189/193]	Time  0.568 ( 6.192)	Data  0.001 ( 5.623)	Loss 9.0969e-02 (8.3472e-02) 
2023-05-27 18:46:31.853466: train Epoch: [45][190/193]	Time 11.106 ( 6.218)	Data 10.539 ( 5.649)	Loss 1.3579e-01 (8.3746e-02) 
2023-05-27 18:46:32.421307: train Epoch: [45][191/193]	Time  0.568 ( 6.189)	Data  0.001 ( 5.619)	Loss 1.0053e-01 (8.3833e-02) 
2023-05-27 18:46:43.353462: train Epoch: [45][192/193]	Time 10.932 ( 6.213)	Data 10.361 ( 5.644)	Loss 9.0650e-02 (8.3869e-02) 
2023-05-27 18:46:43.531230: Train Epoch done in 1199.3114369270043 s 
2023-05-27 18:46:51.387211: val Epoch: [45][ 0/72]	Time  7.124 ( 7.124)	Data  6.968 ( 6.968)	Loss 9.9815e-02 (9.9815e-02) 
2023-05-27 18:46:51.497416: val Epoch: [45][ 1/72]	Time  0.110 ( 3.617)	Data  0.001 ( 3.485)	Loss 5.6336e-02 (7.8075e-02) 
2023-05-27 18:46:57.302760: val Epoch: [45][ 2/72]	Time  5.805 ( 4.347)	Data  5.693 ( 4.221)	Loss 8.0082e-02 (7.8744e-02) 
2023-05-27 18:46:57.702159: val Epoch: [45][ 3/72]	Time  0.399 ( 3.360)	Data  0.293 ( 3.239)	Loss 5.5734e-02 (7.2992e-02) 
2023-05-27 18:47:03.653408: val Epoch: [45][ 4/72]	Time  5.951 ( 3.878)	Data  5.843 ( 3.760)	Loss 5.5409e-01 (1.6921e-01) 
2023-05-27 18:47:03.758089: val Epoch: [45][ 5/72]	Time  0.105 ( 3.249)	Data  0.000 ( 3.133)	Loss 6.2127e-02 (1.5136e-01) 
2023-05-27 18:47:09.896730: val Epoch: [45][ 6/72]	Time  6.139 ( 3.662)	Data  6.030 ( 3.547)	Loss 3.3284e-01 (1.7729e-01) 
2023-05-27 18:47:10.299090: val Epoch: [45][ 7/72]	Time  0.402 ( 3.255)	Data  0.281 ( 3.139)	Loss 1.7136e-01 (1.7655e-01) 
2023-05-27 18:47:16.215975: val Epoch: [45][ 8/72]	Time  5.917 ( 3.550)	Data  5.810 ( 3.435)	Loss 5.8527e-02 (1.6343e-01) 
2023-05-27 18:47:16.633034: val Epoch: [45][ 9/72]	Time  0.417 ( 3.237)	Data  0.307 ( 3.123)	Loss 6.4142e-02 (1.5351e-01) 
2023-05-27 18:47:22.292545: val Epoch: [45][10/72]	Time  5.660 ( 3.457)	Data  5.542 ( 3.343)	Loss 2.2543e-01 (1.6004e-01) 
2023-05-27 18:47:22.999908: val Epoch: [45][11/72]	Time  0.707 ( 3.228)	Data  0.599 ( 3.114)	Loss 1.4686e-01 (1.5895e-01) 
2023-05-27 18:47:28.538166: val Epoch: [45][12/72]	Time  5.538 ( 3.406)	Data  5.428 ( 3.292)	Loss 6.1430e-02 (1.5144e-01) 
2023-05-27 18:47:28.966092: val Epoch: [45][13/72]	Time  0.428 ( 3.193)	Data  0.293 ( 3.078)	Loss 4.8219e-02 (1.4407e-01) 
2023-05-27 18:47:34.575421: val Epoch: [45][14/72]	Time  5.609 ( 3.354)	Data  5.497 ( 3.239)	Loss 1.0509e-01 (1.4147e-01) 
2023-05-27 18:47:35.260737: val Epoch: [45][15/72]	Time  0.685 ( 3.187)	Data  0.562 ( 3.072)	Loss 6.3586e-02 (1.3660e-01) 
2023-05-27 18:47:40.589333: val Epoch: [45][16/72]	Time  5.329 ( 3.313)	Data  5.214 ( 3.198)	Loss 5.1604e-02 (1.3160e-01) 
2023-05-27 18:47:41.632865: val Epoch: [45][17/72]	Time  1.044 ( 3.187)	Data  0.934 ( 3.072)	Loss 3.5732e-01 (1.4414e-01) 
2023-05-27 18:47:46.937494: val Epoch: [45][18/72]	Time  5.305 ( 3.299)	Data  5.197 ( 3.184)	Loss 1.6545e-01 (1.4527e-01) 
2023-05-27 18:47:47.554972: val Epoch: [45][19/72]	Time  0.617 ( 3.165)	Data  0.496 ( 3.049)	Loss 5.9809e-02 (1.4099e-01) 
2023-05-27 18:47:53.017908: val Epoch: [45][20/72]	Time  5.463 ( 3.274)	Data  5.358 ( 3.159)	Loss 1.2141e-01 (1.4006e-01) 
2023-05-27 18:47:53.377873: val Epoch: [45][21/72]	Time  0.360 ( 3.142)	Data  0.255 ( 3.027)	Loss 7.5577e-02 (1.3713e-01) 
2023-05-27 18:47:59.123191: val Epoch: [45][22/72]	Time  5.745 ( 3.255)	Data  5.638 ( 3.141)	Loss 8.3114e-02 (1.3478e-01) 
2023-05-27 18:47:59.647974: val Epoch: [45][23/72]	Time  0.525 ( 3.141)	Data  0.407 ( 3.027)	Loss 2.9347e-01 (1.4139e-01) 
2023-05-27 18:48:05.477525: val Epoch: [45][24/72]	Time  5.830 ( 3.249)	Data  5.724 ( 3.135)	Loss 5.0383e-02 (1.3775e-01) 
2023-05-27 18:48:06.076339: val Epoch: [45][25/72]	Time  0.599 ( 3.147)	Data  0.490 ( 3.033)	Loss 9.6490e-02 (1.3617e-01) 
2023-05-27 18:48:11.810289: val Epoch: [45][26/72]	Time  5.734 ( 3.243)	Data  5.628 ( 3.129)	Loss 6.6943e-02 (1.3360e-01) 
2023-05-27 18:48:12.052954: val Epoch: [45][27/72]	Time  0.243 ( 3.135)	Data  0.133 ( 3.022)	Loss 5.3441e-02 (1.3074e-01) 
2023-05-27 18:48:18.381842: val Epoch: [45][28/72]	Time  6.329 ( 3.245)	Data  6.220 ( 3.132)	Loss 8.2253e-02 (1.2907e-01) 
2023-05-27 18:48:18.508308: val Epoch: [45][29/72]	Time  0.126 ( 3.142)	Data  0.001 ( 3.028)	Loss 1.3061e-01 (1.2912e-01) 
2023-05-27 18:48:24.440851: val Epoch: [45][30/72]	Time  5.933 ( 3.232)	Data  5.822 ( 3.118)	Loss 1.4446e-01 (1.2961e-01) 
2023-05-27 18:48:24.550601: val Epoch: [45][31/72]	Time  0.110 ( 3.134)	Data  0.000 ( 3.021)	Loss 4.4967e-02 (1.2697e-01) 
2023-05-27 18:48:30.339870: val Epoch: [45][32/72]	Time  5.789 ( 3.214)	Data  5.681 ( 3.101)	Loss 4.6577e-02 (1.2453e-01) 
2023-05-27 18:48:30.447523: val Epoch: [45][33/72]	Time  0.108 ( 3.123)	Data  0.001 ( 3.010)	Loss 8.5072e-02 (1.2337e-01) 
2023-05-27 18:48:36.758369: val Epoch: [45][34/72]	Time  6.311 ( 3.214)	Data  6.199 ( 3.101)	Loss 6.5586e-02 (1.2172e-01) 
2023-05-27 18:48:36.863358: val Epoch: [45][35/72]	Time  0.105 ( 3.128)	Data  0.000 ( 3.015)	Loss 5.9174e-02 (1.1998e-01) 
2023-05-27 18:48:43.125196: val Epoch: [45][36/72]	Time  6.262 ( 3.212)	Data  6.150 ( 3.100)	Loss 3.7262e-01 (1.2681e-01) 
2023-05-27 18:48:43.236736: val Epoch: [45][37/72]	Time  0.112 ( 3.131)	Data  0.001 ( 3.018)	Loss 4.0337e-02 (1.2454e-01) 
2023-05-27 18:48:49.143485: val Epoch: [45][38/72]	Time  5.907 ( 3.202)	Data  5.799 ( 3.090)	Loss 3.5386e-01 (1.3042e-01) 
2023-05-27 18:48:49.251276: val Epoch: [45][39/72]	Time  0.108 ( 3.125)	Data  0.001 ( 3.012)	Loss 1.8597e-01 (1.3180e-01) 
2023-05-27 18:48:55.563973: val Epoch: [45][40/72]	Time  6.313 ( 3.202)	Data  6.204 ( 3.090)	Loss 2.8869e-01 (1.3563e-01) 
2023-05-27 18:48:55.672202: val Epoch: [45][41/72]	Time  0.108 ( 3.129)	Data  0.001 ( 3.017)	Loss 4.8864e-02 (1.3356e-01) 
2023-05-27 18:49:02.030527: val Epoch: [45][42/72]	Time  6.358 ( 3.204)	Data  6.250 ( 3.092)	Loss 9.7249e-02 (1.3272e-01) 
2023-05-27 18:49:02.136800: val Epoch: [45][43/72]	Time  0.106 ( 3.133)	Data  0.001 ( 3.022)	Loss 4.5376e-02 (1.3073e-01) 
2023-05-27 18:49:08.780598: val Epoch: [45][44/72]	Time  6.644 ( 3.212)	Data  6.532 ( 3.100)	Loss 9.7288e-02 (1.2999e-01) 
2023-05-27 18:49:08.889920: val Epoch: [45][45/72]	Time  0.109 ( 3.144)	Data  0.000 ( 3.032)	Loss 5.1887e-01 (1.3845e-01) 
2023-05-27 18:49:15.314633: val Epoch: [45][46/72]	Time  6.425 ( 3.214)	Data  6.316 ( 3.102)	Loss 5.0013e-02 (1.3656e-01) 
2023-05-27 18:49:15.420635: val Epoch: [45][47/72]	Time  0.106 ( 3.149)	Data  0.000 ( 3.037)	Loss 3.6281e-02 (1.3447e-01) 
2023-05-27 18:49:21.432876: val Epoch: [45][48/72]	Time  6.012 ( 3.208)	Data  5.904 ( 3.096)	Loss 8.4908e-02 (1.3346e-01) 
2023-05-27 18:49:21.537136: val Epoch: [45][49/72]	Time  0.104 ( 3.145)	Data  0.000 ( 3.034)	Loss 1.4351e-01 (1.3366e-01) 
2023-05-27 18:49:27.979256: val Epoch: [45][50/72]	Time  6.442 ( 3.210)	Data  6.336 ( 3.099)	Loss 8.5316e-02 (1.3272e-01) 
2023-05-27 18:49:28.089402: val Epoch: [45][51/72]	Time  0.110 ( 3.151)	Data  0.001 ( 3.039)	Loss 6.2882e-02 (1.3137e-01) 
2023-05-27 18:49:33.882731: val Epoch: [45][52/72]	Time  5.793 ( 3.200)	Data  5.687 ( 3.089)	Loss 3.5504e-02 (1.2956e-01) 
2023-05-27 18:49:33.989513: val Epoch: [45][53/72]	Time  0.107 ( 3.143)	Data  0.000 ( 3.032)	Loss 3.3558e-01 (1.3338e-01) 
2023-05-27 18:49:40.118247: val Epoch: [45][54/72]	Time  6.129 ( 3.197)	Data  6.021 ( 3.086)	Loss 8.0579e-02 (1.3242e-01) 
2023-05-27 18:49:40.225802: val Epoch: [45][55/72]	Time  0.108 ( 3.142)	Data  0.000 ( 3.031)	Loss 9.8772e-02 (1.3182e-01) 
2023-05-27 18:49:46.247762: val Epoch: [45][56/72]	Time  6.022 ( 3.193)	Data  5.915 ( 3.082)	Loss 5.1636e-02 (1.3041e-01) 
2023-05-27 18:49:46.413708: val Epoch: [45][57/72]	Time  0.166 ( 3.141)	Data  0.000 ( 3.029)	Loss 1.2410e-01 (1.3030e-01) 
2023-05-27 18:49:52.497080: val Epoch: [45][58/72]	Time  6.083 ( 3.190)	Data  5.906 ( 3.077)	Loss 3.7607e-02 (1.2873e-01) 
2023-05-27 18:49:52.648492: val Epoch: [45][59/72]	Time  0.151 ( 3.140)	Data  0.001 ( 3.026)	Loss 7.3483e-02 (1.2781e-01) 
2023-05-27 18:49:58.860045: val Epoch: [45][60/72]	Time  6.212 ( 3.190)	Data  6.069 ( 3.076)	Loss 1.5126e-01 (1.2820e-01) 
2023-05-27 18:49:58.983985: val Epoch: [45][61/72]	Time  0.124 ( 3.141)	Data  0.001 ( 3.026)	Loss 6.5181e-02 (1.2718e-01) 
2023-05-27 18:50:04.775420: val Epoch: [45][62/72]	Time  5.791 ( 3.183)	Data  5.684 ( 3.069)	Loss 3.9696e-02 (1.2579e-01) 
2023-05-27 18:50:04.882949: val Epoch: [45][63/72]	Time  0.108 ( 3.135)	Data  0.000 ( 3.021)	Loss 1.2692e-01 (1.2581e-01) 
2023-05-27 18:50:11.553089: val Epoch: [45][64/72]	Time  6.670 ( 3.189)	Data  6.476 ( 3.074)	Loss 2.4118e-01 (1.2758e-01) 
2023-05-27 18:50:11.681917: val Epoch: [45][65/72]	Time  0.129 ( 3.143)	Data  0.001 ( 3.027)	Loss 1.0143e-01 (1.2719e-01) 
2023-05-27 18:50:17.158221: val Epoch: [45][66/72]	Time  5.476 ( 3.178)	Data  5.360 ( 3.062)	Loss 4.8352e-02 (1.2601e-01) 
2023-05-27 18:50:17.275520: val Epoch: [45][67/72]	Time  0.117 ( 3.133)	Data  0.001 ( 3.017)	Loss 1.1629e-01 (1.2587e-01) 
2023-05-27 18:50:23.374030: val Epoch: [45][68/72]	Time  6.098 ( 3.176)	Data  5.977 ( 3.060)	Loss 1.3872e-01 (1.2605e-01) 
2023-05-27 18:50:23.486356: val Epoch: [45][69/72]	Time  0.112 ( 3.132)	Data  0.001 ( 3.016)	Loss 7.8625e-02 (1.2538e-01) 
2023-05-27 18:50:29.527380: val Epoch: [45][70/72]	Time  6.041 ( 3.173)	Data  5.839 ( 3.056)	Loss 4.7272e-01 (1.3027e-01) 
2023-05-27 18:50:29.687260: val Epoch: [45][71/72]	Time  0.160 ( 3.131)	Data  0.000 ( 3.014)	Loss 9.9908e-02 (1.2985e-01) 
2023-05-27 18:50:30.112396: Epoch 45 :Val : ['ET : 0.7405267357826233', 'TC : 0.7877875566482544', 'WT : 0.8500143885612488'] 
2023-05-27 18:50:30.115246: Epoch 45 :Val : ['ET : 0.7405267357826233', 'TC : 0.7877875566482544', 'WT : 0.8500143885612488'] 
2023-05-27 18:50:30.119091: Val epoch done in 226.58787295999355 s 
2023-05-27 18:50:30.333285: Batches per epoch:  193 
2023-05-27 18:50:44.264110: train Epoch: [46][  0/193]	Time 13.930 (13.930)	Data 13.343 (13.343)	Loss 4.2279e-02 (4.2279e-02) 
2023-05-27 18:50:44.826539: train Epoch: [46][  1/193]	Time  0.562 ( 7.246)	Data  0.001 ( 6.672)	Loss 4.8620e-02 (4.5450e-02) 
2023-05-27 18:50:56.747285: train Epoch: [46][  2/193]	Time 11.921 ( 8.804)	Data 11.356 ( 8.233)	Loss 6.5915e-02 (5.2271e-02) 
2023-05-27 18:50:57.308644: train Epoch: [46][  3/193]	Time  0.561 ( 6.744)	Data  0.001 ( 6.175)	Loss 1.4991e-01 (7.6680e-02) 
2023-05-27 18:51:09.528172: train Epoch: [46][  4/193]	Time 12.220 ( 7.839)	Data 11.651 ( 7.270)	Loss 1.0631e-01 (8.2605e-02) 
2023-05-27 18:51:10.090143: train Epoch: [46][  5/193]	Time  0.562 ( 6.626)	Data  0.001 ( 6.059)	Loss 5.9947e-02 (7.8829e-02) 
2023-05-27 18:51:21.774949: train Epoch: [46][  6/193]	Time 11.685 ( 7.349)	Data 11.117 ( 6.781)	Loss 1.3613e-01 (8.7015e-02) 
2023-05-27 18:51:22.341321: train Epoch: [46][  7/193]	Time  0.566 ( 6.501)	Data  0.001 ( 5.934)	Loss 4.2044e-02 (8.1394e-02) 
2023-05-27 18:51:34.831775: train Epoch: [46][  8/193]	Time 12.490 ( 7.166)	Data 11.916 ( 6.598)	Loss 5.9036e-02 (7.8909e-02) 
2023-05-27 18:51:35.396902: train Epoch: [46][  9/193]	Time  0.565 ( 6.506)	Data  0.001 ( 5.939)	Loss 4.5288e-02 (7.5547e-02) 
2023-05-27 18:51:47.549314: train Epoch: [46][ 10/193]	Time 12.152 ( 7.020)	Data 11.587 ( 6.452)	Loss 1.3636e-01 (8.1075e-02) 
2023-05-27 18:51:48.117499: train Epoch: [46][ 11/193]	Time  0.568 ( 6.482)	Data  0.001 ( 5.915)	Loss 5.3060e-02 (7.8741e-02) 
2023-05-27 18:51:59.983736: train Epoch: [46][ 12/193]	Time 11.866 ( 6.896)	Data 11.301 ( 6.329)	Loss 4.6159e-02 (7.6235e-02) 
2023-05-27 18:52:00.550781: train Epoch: [46][ 13/193]	Time  0.567 ( 6.444)	Data  0.001 ( 5.877)	Loss 8.3192e-02 (7.6732e-02) 
2023-05-27 18:52:12.110818: train Epoch: [46][ 14/193]	Time 11.560 ( 6.785)	Data 10.993 ( 6.218)	Loss 7.0506e-02 (7.6317e-02) 
2023-05-27 18:52:12.672411: train Epoch: [46][ 15/193]	Time  0.562 ( 6.396)	Data  0.001 ( 5.829)	Loss 6.5768e-02 (7.5657e-02) 
2023-05-27 18:52:23.880406: train Epoch: [46][ 16/193]	Time 11.208 ( 6.679)	Data 10.638 ( 6.112)	Loss 6.3519e-02 (7.4943e-02) 
2023-05-27 18:52:24.443051: train Epoch: [46][ 17/193]	Time  0.563 ( 6.339)	Data  0.001 ( 5.773)	Loss 4.1726e-02 (7.3098e-02) 
2023-05-27 18:52:35.982149: train Epoch: [46][ 18/193]	Time 11.539 ( 6.613)	Data 10.974 ( 6.046)	Loss 5.1078e-02 (7.1939e-02) 
2023-05-27 18:52:36.548806: train Epoch: [46][ 19/193]	Time  0.567 ( 6.311)	Data  0.001 ( 5.744)	Loss 7.6654e-02 (7.2175e-02) 
2023-05-27 18:52:48.457763: train Epoch: [46][ 20/193]	Time 11.909 ( 6.577)	Data 11.343 ( 6.011)	Loss 3.2911e-01 (8.4409e-02) 
2023-05-27 18:52:49.020294: train Epoch: [46][ 21/193]	Time  0.563 ( 6.304)	Data  0.001 ( 5.738)	Loss 6.8283e-02 (8.3676e-02) 
2023-05-27 18:53:01.056208: train Epoch: [46][ 22/193]	Time 12.036 ( 6.553)	Data 11.476 ( 5.987)	Loss 6.4119e-02 (8.2826e-02) 
2023-05-27 18:53:01.617594: train Epoch: [46][ 23/193]	Time  0.561 ( 6.303)	Data  0.001 ( 5.738)	Loss 1.2169e-01 (8.4446e-02) 
2023-05-27 18:53:13.945337: train Epoch: [46][ 24/193]	Time 12.328 ( 6.544)	Data 11.760 ( 5.979)	Loss 7.2087e-02 (8.3951e-02) 
2023-05-27 18:53:14.524154: train Epoch: [46][ 25/193]	Time  0.579 ( 6.315)	Data  0.001 ( 5.749)	Loss 8.8430e-02 (8.4124e-02) 
2023-05-27 18:53:25.943841: train Epoch: [46][ 26/193]	Time 11.420 ( 6.504)	Data 10.858 ( 5.938)	Loss 5.8919e-02 (8.3190e-02) 
2023-05-27 18:53:26.505173: train Epoch: [46][ 27/193]	Time  0.561 ( 6.292)	Data  0.001 ( 5.726)	Loss 2.6532e-01 (8.9695e-02) 
2023-05-27 18:53:37.056635: train Epoch: [46][ 28/193]	Time 10.551 ( 6.439)	Data  9.991 ( 5.873)	Loss 4.5366e-02 (8.8166e-02) 
2023-05-27 18:53:37.618343: train Epoch: [46][ 29/193]	Time  0.562 ( 6.243)	Data  0.001 ( 5.677)	Loss 8.7802e-02 (8.8154e-02) 
2023-05-27 18:53:48.124952: train Epoch: [46][ 30/193]	Time 10.507 ( 6.380)	Data  9.944 ( 5.815)	Loss 1.2970e-01 (8.9494e-02) 
2023-05-27 18:53:48.686502: train Epoch: [46][ 31/193]	Time  0.562 ( 6.199)	Data  0.001 ( 5.633)	Loss 1.3219e-01 (9.0829e-02) 
2023-05-27 18:54:00.628725: train Epoch: [46][ 32/193]	Time 11.942 ( 6.373)	Data 11.371 ( 5.807)	Loss 1.5726e-01 (9.2842e-02) 
2023-05-27 18:54:01.191269: train Epoch: [46][ 33/193]	Time  0.563 ( 6.202)	Data  0.001 ( 5.636)	Loss 6.5642e-02 (9.2042e-02) 
2023-05-27 18:54:12.628681: train Epoch: [46][ 34/193]	Time 11.437 ( 6.351)	Data 10.875 ( 5.786)	Loss 5.2627e-02 (9.0916e-02) 
2023-05-27 18:54:13.191218: train Epoch: [46][ 35/193]	Time  0.563 ( 6.190)	Data  0.001 ( 5.625)	Loss 3.8073e-02 (8.9448e-02) 
2023-05-27 18:54:24.842012: train Epoch: [46][ 36/193]	Time 11.651 ( 6.338)	Data 11.090 ( 5.773)	Loss 7.2006e-02 (8.8976e-02) 
2023-05-27 18:54:25.406505: train Epoch: [46][ 37/193]	Time  0.564 ( 6.186)	Data  0.001 ( 5.621)	Loss 5.4448e-02 (8.8068e-02) 
2023-05-27 18:54:37.008633: train Epoch: [46][ 38/193]	Time 11.602 ( 6.325)	Data 11.041 ( 5.760)	Loss 8.7636e-02 (8.8057e-02) 
2023-05-27 18:54:37.569851: train Epoch: [46][ 39/193]	Time  0.561 ( 6.181)	Data  0.001 ( 5.616)	Loss 5.9079e-02 (8.7332e-02) 
2023-05-27 18:54:49.079256: train Epoch: [46][ 40/193]	Time 11.509 ( 6.311)	Data 10.938 ( 5.746)	Loss 1.0130e-01 (8.7673e-02) 
2023-05-27 18:54:49.640752: train Epoch: [46][ 41/193]	Time  0.561 ( 6.174)	Data  0.001 ( 5.609)	Loss 5.5698e-02 (8.6912e-02) 
2023-05-27 18:55:01.520833: train Epoch: [46][ 42/193]	Time 11.880 ( 6.307)	Data 11.317 ( 5.742)	Loss 9.9243e-02 (8.7198e-02) 
2023-05-27 18:55:02.122926: train Epoch: [46][ 43/193]	Time  0.602 ( 6.177)	Data  0.001 ( 5.611)	Loss 4.1917e-02 (8.6169e-02) 
2023-05-27 18:55:13.116118: train Epoch: [46][ 44/193]	Time 10.993 ( 6.284)	Data 10.433 ( 5.718)	Loss 7.2907e-02 (8.5875e-02) 
2023-05-27 18:55:13.677407: train Epoch: [46][ 45/193]	Time  0.561 ( 6.160)	Data  0.001 ( 5.594)	Loss 1.0206e-01 (8.6227e-02) 
2023-05-27 18:55:25.459728: train Epoch: [46][ 46/193]	Time 11.782 ( 6.279)	Data 11.222 ( 5.714)	Loss 5.1226e-02 (8.5482e-02) 
2023-05-27 18:55:26.021198: train Epoch: [46][ 47/193]	Time  0.561 ( 6.160)	Data  0.001 ( 5.595)	Loss 5.8212e-02 (8.4914e-02) 
2023-05-27 18:55:37.327470: train Epoch: [46][ 48/193]	Time 11.306 ( 6.265)	Data 10.740 ( 5.700)	Loss 4.2270e-02 (8.4043e-02) 
2023-05-27 18:55:37.887398: train Epoch: [46][ 49/193]	Time  0.560 ( 6.151)	Data  0.001 ( 5.586)	Loss 9.3129e-02 (8.4225e-02) 
2023-05-27 18:55:49.210831: train Epoch: [46][ 50/193]	Time 11.323 ( 6.252)	Data 10.763 ( 5.687)	Loss 8.3151e-02 (8.4204e-02) 
2023-05-27 18:55:49.772136: train Epoch: [46][ 51/193]	Time  0.561 ( 6.143)	Data  0.001 ( 5.578)	Loss 8.5458e-02 (8.4228e-02) 
2023-05-27 18:56:01.726688: train Epoch: [46][ 52/193]	Time 11.955 ( 6.253)	Data 11.393 ( 5.688)	Loss 9.7273e-02 (8.4474e-02) 
2023-05-27 18:56:02.288276: train Epoch: [46][ 53/193]	Time  0.562 ( 6.147)	Data  0.001 ( 5.582)	Loss 1.0781e-01 (8.4906e-02) 
2023-05-27 18:56:14.606844: train Epoch: [46][ 54/193]	Time 12.319 ( 6.259)	Data 11.757 ( 5.695)	Loss 5.2511e-02 (8.4317e-02) 
2023-05-27 18:56:15.169726: train Epoch: [46][ 55/193]	Time  0.563 ( 6.158)	Data  0.001 ( 5.593)	Loss 7.8496e-02 (8.4213e-02) 
2023-05-27 18:56:27.227661: train Epoch: [46][ 56/193]	Time 12.058 ( 6.261)	Data 11.490 ( 5.697)	Loss 1.0517e-01 (8.4581e-02) 
2023-05-27 18:56:27.790652: train Epoch: [46][ 57/193]	Time  0.563 ( 6.163)	Data  0.001 ( 5.598)	Loss 6.0712e-02 (8.4170e-02) 
2023-05-27 18:56:39.322872: train Epoch: [46][ 58/193]	Time 11.532 ( 6.254)	Data 10.970 ( 5.689)	Loss 5.5665e-02 (8.3686e-02) 
2023-05-27 18:56:39.885560: train Epoch: [46][ 59/193]	Time  0.563 ( 6.159)	Data  0.001 ( 5.595)	Loss 7.2640e-02 (8.3502e-02) 
2023-05-27 18:56:51.595138: train Epoch: [46][ 60/193]	Time 11.710 ( 6.250)	Data 11.149 ( 5.686)	Loss 7.6814e-02 (8.3393e-02) 
2023-05-27 18:56:52.158499: train Epoch: [46][ 61/193]	Time  0.563 ( 6.158)	Data  0.001 ( 5.594)	Loss 6.6092e-02 (8.3114e-02) 
2023-05-27 18:57:04.017442: train Epoch: [46][ 62/193]	Time 11.859 ( 6.249)	Data 11.286 ( 5.684)	Loss 9.1693e-02 (8.3250e-02) 
2023-05-27 18:57:04.579988: train Epoch: [46][ 63/193]	Time  0.563 ( 6.160)	Data  0.001 ( 5.595)	Loss 6.9043e-02 (8.3028e-02) 
2023-05-27 18:57:15.661609: train Epoch: [46][ 64/193]	Time 11.082 ( 6.236)	Data 10.519 ( 5.671)	Loss 6.9562e-02 (8.2821e-02) 
2023-05-27 18:57:16.224913: train Epoch: [46][ 65/193]	Time  0.563 ( 6.150)	Data  0.001 ( 5.585)	Loss 5.6984e-02 (8.2429e-02) 
2023-05-27 18:57:28.058832: train Epoch: [46][ 66/193]	Time 11.834 ( 6.235)	Data 11.273 ( 5.670)	Loss 6.9423e-02 (8.2235e-02) 
2023-05-27 18:57:28.620421: train Epoch: [46][ 67/193]	Time  0.562 ( 6.151)	Data  0.001 ( 5.587)	Loss 9.6617e-02 (8.2447e-02) 
2023-05-27 18:57:40.169534: train Epoch: [46][ 68/193]	Time 11.549 ( 6.229)	Data 10.987 ( 5.665)	Loss 2.3467e-01 (8.4653e-02) 
2023-05-27 18:57:40.732650: train Epoch: [46][ 69/193]	Time  0.563 ( 6.149)	Data  0.001 ( 5.584)	Loss 8.5366e-02 (8.4663e-02) 
2023-05-27 18:57:53.145645: train Epoch: [46][ 70/193]	Time 12.413 ( 6.237)	Data 11.844 ( 5.672)	Loss 8.1585e-02 (8.4620e-02) 
2023-05-27 18:57:53.715071: train Epoch: [46][ 71/193]	Time  0.569 ( 6.158)	Data  0.001 ( 5.594)	Loss 8.4362e-02 (8.4616e-02) 
2023-05-27 18:58:05.824170: train Epoch: [46][ 72/193]	Time 12.109 ( 6.240)	Data 11.548 ( 5.675)	Loss 9.8002e-02 (8.4799e-02) 
2023-05-27 18:58:06.393382: train Epoch: [46][ 73/193]	Time  0.569 ( 6.163)	Data  0.001 ( 5.598)	Loss 2.0468e-01 (8.6419e-02) 
2023-05-27 18:58:18.738217: train Epoch: [46][ 74/193]	Time 12.345 ( 6.245)	Data 11.773 ( 5.681)	Loss 1.0445e-01 (8.6660e-02) 
2023-05-27 18:58:19.314723: train Epoch: [46][ 75/193]	Time  0.577 ( 6.171)	Data  0.002 ( 5.606)	Loss 8.8629e-02 (8.6686e-02) 
2023-05-27 18:58:31.334331: train Epoch: [46][ 76/193]	Time 12.020 ( 6.247)	Data 11.446 ( 5.682)	Loss 3.4195e-01 (9.0001e-02) 
2023-05-27 18:58:31.912521: train Epoch: [46][ 77/193]	Time  0.578 ( 6.174)	Data  0.001 ( 5.609)	Loss 6.1017e-02 (8.9629e-02) 
2023-05-27 18:58:43.687821: train Epoch: [46][ 78/193]	Time 11.775 ( 6.245)	Data 11.199 ( 5.680)	Loss 2.2600e-01 (9.1355e-02) 
2023-05-27 18:58:44.276606: train Epoch: [46][ 79/193]	Time  0.589 ( 6.174)	Data  0.001 ( 5.609)	Loss 1.4062e-01 (9.1971e-02) 
2023-05-27 18:58:55.708589: train Epoch: [46][ 80/193]	Time 11.432 ( 6.239)	Data 10.869 ( 5.674)	Loss 5.7723e-02 (9.1548e-02) 
2023-05-27 18:58:56.270464: train Epoch: [46][ 81/193]	Time  0.562 ( 6.170)	Data  0.001 ( 5.605)	Loss 6.3112e-02 (9.1202e-02) 
2023-05-27 18:59:08.114163: train Epoch: [46][ 82/193]	Time 11.844 ( 6.238)	Data 11.282 ( 5.673)	Loss 8.5051e-02 (9.1128e-02) 
2023-05-27 18:59:08.676536: train Epoch: [46][ 83/193]	Time  0.562 ( 6.171)	Data  0.001 ( 5.605)	Loss 7.2593e-02 (9.0907e-02) 
2023-05-27 18:59:20.565797: train Epoch: [46][ 84/193]	Time 11.889 ( 6.238)	Data 11.317 ( 5.673)	Loss 6.1347e-02 (9.0559e-02) 
2023-05-27 18:59:21.128671: train Epoch: [46][ 85/193]	Time  0.563 ( 6.172)	Data  0.001 ( 5.607)	Loss 1.4393e-01 (9.1180e-02) 
2023-05-27 18:59:32.890879: train Epoch: [46][ 86/193]	Time 11.762 ( 6.236)	Data 11.195 ( 5.671)	Loss 8.9701e-02 (9.1163e-02) 
2023-05-27 18:59:33.453111: train Epoch: [46][ 87/193]	Time  0.562 ( 6.172)	Data  0.001 ( 5.606)	Loss 4.7794e-02 (9.0670e-02) 
2023-05-27 18:59:45.255070: train Epoch: [46][ 88/193]	Time 11.802 ( 6.235)	Data 11.241 ( 5.670)	Loss 1.2027e-01 (9.1002e-02) 
2023-05-27 18:59:45.818398: train Epoch: [46][ 89/193]	Time  0.563 ( 6.172)	Data  0.001 ( 5.607)	Loss 8.9495e-02 (9.0986e-02) 
2023-05-27 18:59:57.435637: train Epoch: [46][ 90/193]	Time 11.617 ( 6.232)	Data 11.057 ( 5.667)	Loss 5.7661e-02 (9.0620e-02) 
2023-05-27 18:59:57.998199: train Epoch: [46][ 91/193]	Time  0.563 ( 6.170)	Data  0.001 ( 5.605)	Loss 5.6112e-02 (9.0244e-02) 
2023-05-27 19:00:10.177042: train Epoch: [46][ 92/193]	Time 12.179 ( 6.235)	Data 11.611 ( 5.670)	Loss 7.5009e-02 (9.0081e-02) 
2023-05-27 19:00:10.740175: train Epoch: [46][ 93/193]	Time  0.563 ( 6.175)	Data  0.001 ( 5.609)	Loss 6.6234e-02 (8.9827e-02) 
2023-05-27 19:00:22.036775: train Epoch: [46][ 94/193]	Time 11.297 ( 6.228)	Data 10.735 ( 5.663)	Loss 5.2510e-02 (8.9434e-02) 
2023-05-27 19:00:22.601873: train Epoch: [46][ 95/193]	Time  0.565 ( 6.169)	Data  0.001 ( 5.604)	Loss 6.1952e-02 (8.9148e-02) 
2023-05-27 19:00:33.306161: train Epoch: [46][ 96/193]	Time 10.704 ( 6.216)	Data 10.138 ( 5.651)	Loss 1.4693e-01 (8.9743e-02) 
2023-05-27 19:00:33.874114: train Epoch: [46][ 97/193]	Time  0.568 ( 6.159)	Data  0.001 ( 5.593)	Loss 5.0549e-02 (8.9344e-02) 
2023-05-27 19:00:44.592831: train Epoch: [46][ 98/193]	Time 10.719 ( 6.205)	Data 10.152 ( 5.639)	Loss 8.7342e-02 (8.9323e-02) 
2023-05-27 19:00:45.160295: train Epoch: [46][ 99/193]	Time  0.567 ( 6.148)	Data  0.001 ( 5.583)	Loss 1.4357e-01 (8.9866e-02) 
2023-05-27 19:00:57.275244: train Epoch: [46][100/193]	Time 12.115 ( 6.207)	Data 11.542 ( 5.642)	Loss 6.6037e-02 (8.9630e-02) 
2023-05-27 19:00:57.843833: train Epoch: [46][101/193]	Time  0.569 ( 6.152)	Data  0.001 ( 5.587)	Loss 1.1771e-01 (8.9905e-02) 
2023-05-27 19:01:09.352121: train Epoch: [46][102/193]	Time 11.508 ( 6.204)	Data 10.941 ( 5.639)	Loss 1.2442e-01 (9.0240e-02) 
2023-05-27 19:01:09.922635: train Epoch: [46][103/193]	Time  0.571 ( 6.150)	Data  0.001 ( 5.585)	Loss 1.3197e-01 (9.0642e-02) 
2023-05-27 19:01:22.023097: train Epoch: [46][104/193]	Time 12.100 ( 6.207)	Data 11.536 ( 5.641)	Loss 8.8000e-02 (9.0616e-02) 
2023-05-27 19:01:22.597687: train Epoch: [46][105/193]	Time  0.575 ( 6.153)	Data  0.001 ( 5.588)	Loss 1.0165e-01 (9.0720e-02) 
2023-05-27 19:01:33.988530: train Epoch: [46][106/193]	Time 11.391 ( 6.202)	Data 10.828 ( 5.637)	Loss 8.1223e-02 (9.0632e-02) 
2023-05-27 19:01:34.552212: train Epoch: [46][107/193]	Time  0.564 ( 6.150)	Data  0.001 ( 5.585)	Loss 9.8439e-02 (9.0704e-02) 
2023-05-27 19:01:47.264465: train Epoch: [46][108/193]	Time 12.712 ( 6.210)	Data 12.134 ( 5.645)	Loss 1.6046e-01 (9.1344e-02) 
2023-05-27 19:01:47.837889: train Epoch: [46][109/193]	Time  0.573 ( 6.159)	Data  0.001 ( 5.594)	Loss 1.7802e-01 (9.2132e-02) 
2023-05-27 19:01:59.082582: train Epoch: [46][110/193]	Time 11.245 ( 6.205)	Data 10.684 ( 5.639)	Loss 9.0408e-02 (9.2116e-02) 
2023-05-27 19:01:59.646745: train Epoch: [46][111/193]	Time  0.564 ( 6.155)	Data  0.001 ( 5.589)	Loss 1.0312e-01 (9.2215e-02) 
2023-05-27 19:02:11.589853: train Epoch: [46][112/193]	Time 11.943 ( 6.206)	Data 11.382 ( 5.640)	Loss 8.1951e-02 (9.2124e-02) 
2023-05-27 19:02:12.153722: train Epoch: [46][113/193]	Time  0.564 ( 6.156)	Data  0.001 ( 5.591)	Loss 9.7448e-02 (9.2170e-02) 
2023-05-27 19:02:24.418099: train Epoch: [46][114/193]	Time 12.264 ( 6.209)	Data 11.702 ( 5.644)	Loss 1.3916e-01 (9.2579e-02) 
2023-05-27 19:02:24.980953: train Epoch: [46][115/193]	Time  0.563 ( 6.161)	Data  0.001 ( 5.595)	Loss 8.1611e-02 (9.2485e-02) 
2023-05-27 19:02:36.757672: train Epoch: [46][116/193]	Time 11.777 ( 6.209)	Data 11.210 ( 5.643)	Loss 5.8874e-02 (9.2197e-02) 
2023-05-27 19:02:37.324024: train Epoch: [46][117/193]	Time  0.566 ( 6.161)	Data  0.001 ( 5.596)	Loss 6.8481e-02 (9.1996e-02) 
2023-05-27 19:02:50.020371: train Epoch: [46][118/193]	Time 12.696 ( 6.216)	Data 12.134 ( 5.651)	Loss 8.5391e-02 (9.1941e-02) 
2023-05-27 19:02:50.584833: train Epoch: [46][119/193]	Time  0.564 ( 6.169)	Data  0.001 ( 5.603)	Loss 1.2551e-01 (9.2220e-02) 
2023-05-27 19:03:02.713697: train Epoch: [46][120/193]	Time 12.129 ( 6.218)	Data 11.560 ( 5.653)	Loss 1.3561e-01 (9.2579e-02) 
2023-05-27 19:03:03.276368: train Epoch: [46][121/193]	Time  0.563 ( 6.172)	Data  0.001 ( 5.606)	Loss 7.6302e-02 (9.2446e-02) 
2023-05-27 19:03:15.623174: train Epoch: [46][122/193]	Time 12.347 ( 6.222)	Data 11.773 ( 5.656)	Loss 8.1785e-02 (9.2359e-02) 
2023-05-27 19:03:16.187448: train Epoch: [46][123/193]	Time  0.564 ( 6.176)	Data  0.001 ( 5.611)	Loss 7.8042e-02 (9.2244e-02) 
2023-05-27 19:03:27.720420: train Epoch: [46][124/193]	Time 11.533 ( 6.219)	Data 10.958 ( 5.654)	Loss 6.5852e-02 (9.2032e-02) 
2023-05-27 19:03:28.288806: train Epoch: [46][125/193]	Time  0.568 ( 6.174)	Data  0.001 ( 5.609)	Loss 4.8955e-02 (9.1691e-02) 
2023-05-27 19:03:40.093075: train Epoch: [46][126/193]	Time 11.804 ( 6.219)	Data 11.222 ( 5.653)	Loss 4.3280e-02 (9.1309e-02) 
2023-05-27 19:03:40.660831: train Epoch: [46][127/193]	Time  0.568 ( 6.174)	Data  0.001 ( 5.609)	Loss 7.3141e-02 (9.1167e-02) 
2023-05-27 19:03:51.983378: train Epoch: [46][128/193]	Time 11.323 ( 6.214)	Data 10.745 ( 5.649)	Loss 7.4225e-02 (9.1036e-02) 
2023-05-27 19:03:52.558750: train Epoch: [46][129/193]	Time  0.575 ( 6.171)	Data  0.001 ( 5.605)	Loss 1.0511e-01 (9.1144e-02) 
2023-05-27 19:04:05.258385: train Epoch: [46][130/193]	Time 12.700 ( 6.221)	Data 12.126 ( 5.655)	Loss 6.4119e-02 (9.0938e-02) 
2023-05-27 19:04:05.820475: train Epoch: [46][131/193]	Time  0.562 ( 6.178)	Data  0.001 ( 5.612)	Loss 1.0837e-01 (9.1070e-02) 
2023-05-27 19:04:17.578948: train Epoch: [46][132/193]	Time 11.758 ( 6.220)	Data 11.173 ( 5.654)	Loss 6.3437e-02 (9.0862e-02) 
2023-05-27 19:04:18.148505: train Epoch: [46][133/193]	Time  0.570 ( 6.178)	Data  0.001 ( 5.612)	Loss 6.4157e-02 (9.0663e-02) 
2023-05-27 19:04:30.035115: train Epoch: [46][134/193]	Time 11.887 ( 6.220)	Data 11.325 ( 5.654)	Loss 6.6177e-02 (9.0482e-02) 
2023-05-27 19:04:30.597668: train Epoch: [46][135/193]	Time  0.563 ( 6.178)	Data  0.001 ( 5.613)	Loss 7.0993e-02 (9.0338e-02) 
2023-05-27 19:04:42.544078: train Epoch: [46][136/193]	Time 11.946 ( 6.221)	Data 11.386 ( 5.655)	Loss 1.2114e-01 (9.0563e-02) 
2023-05-27 19:04:43.110039: train Epoch: [46][137/193]	Time  0.566 ( 6.180)	Data  0.001 ( 5.614)	Loss 1.0640e-01 (9.0678e-02) 
2023-05-27 19:04:54.893689: train Epoch: [46][138/193]	Time 11.784 ( 6.220)	Data 11.216 ( 5.654)	Loss 8.9417e-02 (9.0669e-02) 
2023-05-27 19:04:55.457132: train Epoch: [46][139/193]	Time  0.563 ( 6.179)	Data  0.001 ( 5.614)	Loss 8.1172e-02 (9.0601e-02) 
2023-05-27 19:05:07.299880: train Epoch: [46][140/193]	Time 11.843 ( 6.220)	Data 11.282 ( 5.654)	Loss 4.7054e-02 (9.0292e-02) 
2023-05-27 19:05:07.862364: train Epoch: [46][141/193]	Time  0.562 ( 6.180)	Data  0.001 ( 5.614)	Loss 4.3746e-02 (8.9964e-02) 
2023-05-27 19:05:19.251383: train Epoch: [46][142/193]	Time 11.389 ( 6.216)	Data 10.818 ( 5.650)	Loss 1.0073e-01 (9.0040e-02) 
2023-05-27 19:05:19.818905: train Epoch: [46][143/193]	Time  0.568 ( 6.177)	Data  0.001 ( 5.611)	Loss 9.5315e-02 (9.0076e-02) 
2023-05-27 19:05:31.401060: train Epoch: [46][144/193]	Time 11.582 ( 6.21