2023-05-25 00:03:48.301618: Created model 
2023-05-25 00:03:48.302769: total number of trainable parameters 20757084 
2023-05-25 00:03:48.305880: <bound method EDiceLoss.metric of EDiceLoss()> 
2023-05-25 00:03:48.313354: Train dataset number of batch: 193 
2023-05-25 00:03:48.313519: Val dataset number of batch: 72 
2023-05-25 00:03:48.313561: Bench Test dataset number of batch: 25 
2023-05-25 00:03:48.313682: start training now! 
2023-05-25 00:03:48.313734: Batches per epoch:  193 
2023-05-25 00:03:53.781295: train Epoch: [0][  0/193]	Time  5.467 ( 5.467)	Data  3.288 ( 3.288)	Loss 8.5694e-01 (8.5694e-01) 
2023-05-25 00:03:54.915936: train Epoch: [0][  1/193]	Time  1.135 ( 3.301)	Data  0.001 ( 1.644)	Loss 8.2048e-01 (8.3871e-01) 
2023-05-25 00:03:56.002083: train Epoch: [0][  2/193]	Time  1.086 ( 2.563)	Data  0.001 ( 1.097)	Loss 8.1049e-01 (8.2930e-01) 
2023-05-25 00:03:57.168593: train Epoch: [0][  3/193]	Time  1.166 ( 2.214)	Data  0.001 ( 0.823)	Loss 8.2401e-01 (8.2798e-01) 
2023-05-25 00:03:58.297385: train Epoch: [0][  4/193]	Time  1.129 ( 1.997)	Data  0.001 ( 0.658)	Loss 8.4334e-01 (8.3105e-01) 
2023-05-25 00:03:59.451477: train Epoch: [0][  5/193]	Time  1.154 ( 1.856)	Data  0.001 ( 0.549)	Loss 8.1466e-01 (8.2832e-01) 
2023-05-25 00:04:00.537269: train Epoch: [0][  6/193]	Time  1.086 ( 1.746)	Data  0.001 ( 0.471)	Loss 8.0907e-01 (8.2557e-01) 
2023-05-25 00:04:01.618155: train Epoch: [0][  7/193]	Time  1.081 ( 1.663)	Data  0.001 ( 0.412)	Loss 8.4513e-01 (8.2802e-01) 
2023-05-25 00:04:03.028627: train Epoch: [0][  8/193]	Time  1.410 ( 1.635)	Data  0.391 ( 0.410)	Loss 8.4505e-01 (8.2991e-01) 
2023-05-25 00:04:04.414326: train Epoch: [0][  9/193]	Time  1.386 ( 1.610)	Data  0.213 ( 0.390)	Loss 8.2308e-01 (8.2923e-01) 
2023-05-25 00:04:05.841365: train Epoch: [0][ 10/193]	Time  1.427 ( 1.593)	Data  0.355 ( 0.387)	Loss 7.9140e-01 (8.2579e-01) 
2023-05-25 00:04:06.982398: train Epoch: [0][ 11/193]	Time  1.141 ( 1.556)	Data  0.204 ( 0.372)	Loss 7.9357e-01 (8.2310e-01) 
2023-05-25 00:04:08.452815: train Epoch: [0][ 12/193]	Time  1.470 ( 1.549)	Data  0.479 ( 0.380)	Loss 8.0729e-01 (8.2189e-01) 
2023-05-25 00:04:10.026885: train Epoch: [0][ 13/193]	Time  1.574 ( 1.551)	Data  0.521 ( 0.390)	Loss 7.9354e-01 (8.1986e-01) 
2023-05-25 00:04:11.331473: train Epoch: [0][ 14/193]	Time  1.305 ( 1.535)	Data  0.273 ( 0.382)	Loss 7.5529e-01 (8.1556e-01) 
2023-05-25 00:04:13.016589: train Epoch: [0][ 15/193]	Time  1.685 ( 1.544)	Data  0.571 ( 0.394)	Loss 7.6261e-01 (8.1225e-01) 
2023-05-25 00:04:14.198630: train Epoch: [0][ 16/193]	Time  1.182 ( 1.523)	Data  0.170 ( 0.381)	Loss 7.5744e-01 (8.0902e-01) 
2023-05-25 00:04:16.048273: train Epoch: [0][ 17/193]	Time  1.850 ( 1.541)	Data  0.625 ( 0.394)	Loss 7.5494e-01 (8.0602e-01) 
2023-05-25 00:04:17.371404: train Epoch: [0][ 18/193]	Time  1.323 ( 1.529)	Data  0.087 ( 0.378)	Loss 7.3903e-01 (8.0249e-01) 
2023-05-25 00:04:18.959319: train Epoch: [0][ 19/193]	Time  1.588 ( 1.532)	Data  0.300 ( 0.374)	Loss 7.8404e-01 (8.0157e-01) 
2023-05-25 00:04:20.206724: train Epoch: [0][ 20/193]	Time  1.247 ( 1.519)	Data  0.001 ( 0.357)	Loss 7.4038e-01 (7.9866e-01) 
2023-05-25 00:04:21.695951: train Epoch: [0][ 21/193]	Time  1.489 ( 1.517)	Data  0.284 ( 0.353)	Loss 7.2517e-01 (7.9532e-01) 
2023-05-25 00:04:22.790444: train Epoch: [0][ 22/193]	Time  1.095 ( 1.499)	Data  0.066 ( 0.341)	Loss 7.3786e-01 (7.9282e-01) 
2023-05-25 00:04:24.370778: train Epoch: [0][ 23/193]	Time  1.580 ( 1.502)	Data  0.570 ( 0.350)	Loss 7.0176e-01 (7.8902e-01) 
2023-05-25 00:04:25.821503: train Epoch: [0][ 24/193]	Time  1.451 ( 1.500)	Data  0.399 ( 0.352)	Loss 7.4647e-01 (7.8732e-01) 
2023-05-25 00:04:27.626687: train Epoch: [0][ 25/193]	Time  1.805 ( 1.512)	Data  0.423 ( 0.355)	Loss 6.8895e-01 (7.8354e-01) 
2023-05-25 00:04:28.781552: train Epoch: [0][ 26/193]	Time  1.155 ( 1.499)	Data  0.142 ( 0.347)	Loss 7.3669e-01 (7.8180e-01) 
2023-05-25 00:04:30.314123: train Epoch: [0][ 27/193]	Time  1.533 ( 1.500)	Data  0.225 ( 0.343)	Loss 7.4601e-01 (7.8052e-01) 
2023-05-25 00:04:31.703975: train Epoch: [0][ 28/193]	Time  1.390 ( 1.496)	Data  0.347 ( 0.343)	Loss 7.0715e-01 (7.7799e-01) 
2023-05-25 00:04:32.768652: train Epoch: [0][ 29/193]	Time  1.065 ( 1.482)	Data  0.088 ( 0.334)	Loss 6.8953e-01 (7.7505e-01) 
2023-05-25 00:04:34.639081: train Epoch: [0][ 30/193]	Time  1.870 ( 1.494)	Data  0.765 ( 0.348)	Loss 6.9093e-01 (7.7233e-01) 
2023-05-25 00:04:35.755386: train Epoch: [0][ 31/193]	Time  1.116 ( 1.483)	Data  0.066 ( 0.339)	Loss 6.9080e-01 (7.6978e-01) 
2023-05-25 00:04:37.768358: train Epoch: [0][ 32/193]	Time  2.013 ( 1.499)	Data  0.645 ( 0.349)	Loss 6.6562e-01 (7.6663e-01) 
2023-05-25 00:04:38.925987: train Epoch: [0][ 33/193]	Time  1.158 ( 1.489)	Data  0.001 ( 0.338)	Loss 7.5632e-01 (7.6632e-01) 
2023-05-25 00:04:40.441967: train Epoch: [0][ 34/193]	Time  1.516 ( 1.489)	Data  0.306 ( 0.338)	Loss 6.8993e-01 (7.6414e-01) 
2023-05-25 00:04:41.460704: train Epoch: [0][ 35/193]	Time  1.019 ( 1.476)	Data  0.001 ( 0.328)	Loss 7.0559e-01 (7.6252e-01) 
2023-05-25 00:04:43.300786: train Epoch: [0][ 36/193]	Time  1.840 ( 1.486)	Data  0.521 ( 0.333)	Loss 6.4543e-01 (7.5935e-01) 
2023-05-25 00:04:44.440193: train Epoch: [0][ 37/193]	Time  1.139 ( 1.477)	Data  0.001 ( 0.325)	Loss 7.2917e-01 (7.5856e-01) 
2023-05-25 00:04:46.185552: train Epoch: [0][ 38/193]	Time  1.745 ( 1.484)	Data  0.379 ( 0.326)	Loss 6.6257e-01 (7.5610e-01) 
2023-05-25 00:04:47.373272: train Epoch: [0][ 39/193]	Time  1.188 ( 1.476)	Data  0.001 ( 0.318)	Loss 6.4780e-01 (7.5339e-01) 
2023-05-25 00:04:48.906582: train Epoch: [0][ 40/193]	Time  1.533 ( 1.478)	Data  0.304 ( 0.318)	Loss 6.5157e-01 (7.5090e-01) 
2023-05-25 00:04:50.160362: train Epoch: [0][ 41/193]	Time  1.254 ( 1.473)	Data  0.001 ( 0.310)	Loss 6.2623e-01 (7.4794e-01) 
2023-05-25 00:04:51.554431: train Epoch: [0][ 42/193]	Time  1.394 ( 1.471)	Data  0.308 ( 0.310)	Loss 7.0442e-01 (7.4692e-01) 
2023-05-25 00:04:52.746654: train Epoch: [0][ 43/193]	Time  1.192 ( 1.464)	Data  0.121 ( 0.306)	Loss 7.1003e-01 (7.4609e-01) 
2023-05-25 00:04:54.653094: train Epoch: [0][ 44/193]	Time  1.906 ( 1.474)	Data  0.602 ( 0.312)	Loss 6.2970e-01 (7.4350e-01) 
2023-05-25 00:04:55.757692: train Epoch: [0][ 45/193]	Time  1.105 ( 1.466)	Data  0.001 ( 0.306)	Loss 6.7053e-01 (7.4191e-01) 
2023-05-25 00:04:57.536465: train Epoch: [0][ 46/193]	Time  1.779 ( 1.473)	Data  0.460 ( 0.309)	Loss 6.2833e-01 (7.3950e-01) 
2023-05-25 00:04:58.444234: train Epoch: [0][ 47/193]	Time  0.908 ( 1.461)	Data  0.001 ( 0.302)	Loss 6.3745e-01 (7.3737e-01) 
2023-05-25 00:05:00.426854: train Epoch: [0][ 48/193]	Time  1.983 ( 1.472)	Data  0.538 ( 0.307)	Loss 6.3016e-01 (7.3518e-01) 
2023-05-25 00:05:01.559552: train Epoch: [0][ 49/193]	Time  1.133 ( 1.465)	Data  0.153 ( 0.304)	Loss 5.6231e-01 (7.3173e-01) 
2023-05-25 00:05:02.779243: train Epoch: [0][ 50/193]	Time  1.220 ( 1.460)	Data  0.263 ( 0.303)	Loss 6.7103e-01 (7.3054e-01) 
2023-05-25 00:05:04.781127: train Epoch: [0][ 51/193]	Time  2.002 ( 1.471)	Data  0.764 ( 0.312)	Loss 5.8008e-01 (7.2764e-01) 
2023-05-25 00:05:05.923475: train Epoch: [0][ 52/193]	Time  1.142 ( 1.464)	Data  0.001 ( 0.306)	Loss 7.1295e-01 (7.2736e-01) 
2023-05-25 00:05:07.491627: train Epoch: [0][ 53/193]	Time  1.568 ( 1.466)	Data  0.471 ( 0.309)	Loss 6.2821e-01 (7.2553e-01) 
2023-05-25 00:05:08.498971: train Epoch: [0][ 54/193]	Time  1.007 ( 1.458)	Data  0.001 ( 0.304)	Loss 5.7912e-01 (7.2287e-01) 
2023-05-25 00:05:10.204905: train Epoch: [0][ 55/193]	Time  1.706 ( 1.462)	Data  0.782 ( 0.312)	Loss 5.6605e-01 (7.2007e-01) 
2023-05-25 00:05:11.244705: train Epoch: [0][ 56/193]	Time  1.040 ( 1.455)	Data  0.001 ( 0.307)	Loss 5.8653e-01 (7.1772e-01) 
2023-05-25 00:05:13.590434: train Epoch: [0][ 57/193]	Time  2.346 ( 1.470)	Data  1.144 ( 0.321)	Loss 5.7923e-01 (7.1534e-01) 
2023-05-25 00:05:14.551436: train Epoch: [0][ 58/193]	Time  0.961 ( 1.462)	Data  0.001 ( 0.316)	Loss 5.4109e-01 (7.1238e-01) 
2023-05-25 00:05:16.652154: train Epoch: [0][ 59/193]	Time  2.101 ( 1.472)	Data  0.684 ( 0.322)	Loss 5.7780e-01 (7.1014e-01) 
2023-05-25 00:05:17.610138: train Epoch: [0][ 60/193]	Time  0.958 ( 1.464)	Data  0.001 ( 0.317)	Loss 4.9087e-01 (7.0654e-01) 
2023-05-25 00:05:19.148667: train Epoch: [0][ 61/193]	Time  1.539 ( 1.465)	Data  0.415 ( 0.318)	Loss 5.3478e-01 (7.0377e-01) 
2023-05-25 00:05:20.395407: train Epoch: [0][ 62/193]	Time  1.247 ( 1.462)	Data  0.001 ( 0.313)	Loss 5.5131e-01 (7.0135e-01) 
2023-05-25 00:05:22.018523: train Epoch: [0][ 63/193]	Time  1.623 ( 1.464)	Data  0.471 ( 0.316)	Loss 5.9866e-01 (6.9975e-01) 
2023-05-25 00:05:23.349095: train Epoch: [0][ 64/193]	Time  1.331 ( 1.462)	Data  0.001 ( 0.311)	Loss 6.9991e-01 (6.9975e-01) 
2023-05-25 00:05:24.832275: train Epoch: [0][ 65/193]	Time  1.483 ( 1.462)	Data  0.440 ( 0.313)	Loss 5.9756e-01 (6.9820e-01) 
2023-05-25 00:05:25.950947: train Epoch: [0][ 66/193]	Time  1.119 ( 1.457)	Data  0.001 ( 0.308)	Loss 4.4415e-01 (6.9441e-01) 
2023-05-25 00:05:27.674737: train Epoch: [0][ 67/193]	Time  1.724 ( 1.461)	Data  0.647 ( 0.313)	Loss 3.7553e-01 (6.8972e-01) 
2023-05-25 00:05:28.671972: train Epoch: [0][ 68/193]	Time  0.997 ( 1.454)	Data  0.001 ( 0.309)	Loss 4.9363e-01 (6.8688e-01) 
2023-05-25 00:05:30.602040: train Epoch: [0][ 69/193]	Time  1.930 ( 1.461)	Data  0.710 ( 0.314)	Loss 4.1383e-01 (6.8298e-01) 
2023-05-25 00:05:31.609885: train Epoch: [0][ 70/193]	Time  1.008 ( 1.455)	Data  0.001 ( 0.310)	Loss 5.8583e-01 (6.8161e-01) 
2023-05-25 00:05:33.349463: train Epoch: [0][ 71/193]	Time  1.740 ( 1.459)	Data  0.512 ( 0.313)	Loss 4.3170e-01 (6.7814e-01) 
2023-05-25 00:05:34.501883: train Epoch: [0][ 72/193]	Time  1.152 ( 1.455)	Data  0.001 ( 0.309)	Loss 3.8279e-01 (6.7409e-01) 
2023-05-25 00:05:35.948815: train Epoch: [0][ 73/193]	Time  1.447 ( 1.455)	Data  0.440 ( 0.310)	Loss 4.3693e-01 (6.7089e-01) 
2023-05-25 00:05:37.250842: train Epoch: [0][ 74/193]	Time  1.302 ( 1.452)	Data  0.001 ( 0.306)	Loss 4.0683e-01 (6.6737e-01) 
2023-05-25 00:05:38.665546: train Epoch: [0][ 75/193]	Time  1.415 ( 1.452)	Data  0.368 ( 0.307)	Loss 6.1821e-01 (6.6672e-01) 
2023-05-25 00:05:40.016993: train Epoch: [0][ 76/193]	Time  1.351 ( 1.451)	Data  0.001 ( 0.303)	Loss 3.6243e-01 (6.6277e-01) 
2023-05-25 00:05:41.480815: train Epoch: [0][ 77/193]	Time  1.464 ( 1.451)	Data  0.388 ( 0.304)	Loss 3.2517e-01 (6.5844e-01) 
2023-05-25 00:05:42.651157: train Epoch: [0][ 78/193]	Time  1.170 ( 1.447)	Data  0.001 ( 0.300)	Loss 5.5633e-01 (6.5715e-01) 
2023-05-25 00:05:44.534005: train Epoch: [0][ 79/193]	Time  1.883 ( 1.453)	Data  0.544 ( 0.303)	Loss 3.9597e-01 (6.5388e-01) 
2023-05-25 00:05:45.682310: train Epoch: [0][ 80/193]	Time  1.148 ( 1.449)	Data  0.001 ( 0.300)	Loss 6.2840e-01 (6.5357e-01) 
2023-05-25 00:05:47.238431: train Epoch: [0][ 81/193]	Time  1.556 ( 1.450)	Data  0.297 ( 0.300)	Loss 4.9198e-01 (6.5160e-01) 
2023-05-25 00:05:48.202884: train Epoch: [0][ 82/193]	Time  0.964 ( 1.444)	Data  0.001 ( 0.296)	Loss 3.6208e-01 (6.4811e-01) 
2023-05-25 00:05:49.899606: train Epoch: [0][ 83/193]	Time  1.697 ( 1.447)	Data  0.532 ( 0.299)	Loss 5.1971e-01 (6.4658e-01) 
2023-05-25 00:05:50.840733: train Epoch: [0][ 84/193]	Time  0.941 ( 1.441)	Data  0.001 ( 0.295)	Loss 3.8369e-01 (6.4349e-01) 
2023-05-25 00:05:52.934242: train Epoch: [0][ 85/193]	Time  2.094 ( 1.449)	Data  0.707 ( 0.300)	Loss 3.8949e-01 (6.4054e-01) 
2023-05-25 00:05:54.065735: train Epoch: [0][ 86/193]	Time  1.131 ( 1.445)	Data  0.001 ( 0.297)	Loss 4.2227e-01 (6.3803e-01) 
2023-05-25 00:05:55.287827: train Epoch: [0][ 87/193]	Time  1.222 ( 1.443)	Data  0.165 ( 0.295)	Loss 3.5782e-01 (6.3484e-01) 
2023-05-25 00:05:56.254284: train Epoch: [0][ 88/193]	Time  0.966 ( 1.438)	Data  0.001 ( 0.292)	Loss 4.6667e-01 (6.3295e-01) 
2023-05-25 00:05:58.079598: train Epoch: [0][ 89/193]	Time  1.825 ( 1.442)	Data  0.699 ( 0.296)	Loss 4.1064e-01 (6.3048e-01) 
2023-05-25 00:05:59.276223: train Epoch: [0][ 90/193]	Time  1.197 ( 1.439)	Data  0.001 ( 0.293)	Loss 4.8090e-01 (6.2884e-01) 
2023-05-25 00:06:01.025481: train Epoch: [0][ 91/193]	Time  1.749 ( 1.443)	Data  0.512 ( 0.295)	Loss 4.5519e-01 (6.2695e-01) 
2023-05-25 00:06:02.131548: train Epoch: [0][ 92/193]	Time  1.106 ( 1.439)	Data  0.001 ( 0.292)	Loss 4.8843e-01 (6.2546e-01) 
2023-05-25 00:06:03.580293: train Epoch: [0][ 93/193]	Time  1.449 ( 1.439)	Data  0.463 ( 0.294)	Loss 3.8231e-01 (6.2288e-01) 
2023-05-25 00:06:04.630277: train Epoch: [0][ 94/193]	Time  1.050 ( 1.435)	Data  0.001 ( 0.291)	Loss 5.1995e-01 (6.2179e-01) 
2023-05-25 00:06:06.640622: train Epoch: [0][ 95/193]	Time  2.010 ( 1.441)	Data  0.806 ( 0.296)	Loss 3.9712e-01 (6.1945e-01) 
2023-05-25 00:06:07.640589: train Epoch: [0][ 96/193]	Time  1.000 ( 1.436)	Data  0.001 ( 0.293)	Loss 3.9000e-01 (6.1709e-01) 
2023-05-25 00:06:09.153757: train Epoch: [0][ 97/193]	Time  1.513 ( 1.437)	Data  0.491 ( 0.295)	Loss 1.6096e-01 (6.1243e-01) 
2023-05-25 00:06:10.143005: train Epoch: [0][ 98/193]	Time  0.989 ( 1.433)	Data  0.001 ( 0.292)	Loss 2.7923e-01 (6.0907e-01) 
2023-05-25 00:06:12.225152: train Epoch: [0][ 99/193]	Time  2.082 ( 1.439)	Data  0.782 ( 0.297)	Loss 2.9156e-01 (6.0589e-01) 
2023-05-25 00:06:13.399004: train Epoch: [0][100/193]	Time  1.174 ( 1.436)	Data  0.001 ( 0.294)	Loss 4.5617e-01 (6.0441e-01) 
2023-05-25 00:06:14.780042: train Epoch: [0][101/193]	Time  1.381 ( 1.436)	Data  0.286 ( 0.294)	Loss 3.6239e-01 (6.0204e-01) 
2023-05-25 00:06:16.133951: train Epoch: [0][102/193]	Time  1.354 ( 1.435)	Data  0.001 ( 0.291)	Loss 2.9826e-01 (5.9909e-01) 
2023-05-25 00:06:17.532945: train Epoch: [0][103/193]	Time  1.399 ( 1.435)	Data  0.285 ( 0.291)	Loss 3.1464e-01 (5.9635e-01) 
2023-05-25 00:06:18.777922: train Epoch: [0][104/193]	Time  1.245 ( 1.433)	Data  0.001 ( 0.289)	Loss 4.3344e-01 (5.9480e-01) 
2023-05-25 00:06:20.386375: train Epoch: [0][105/193]	Time  1.608 ( 1.435)	Data  0.444 ( 0.290)	Loss 3.4350e-01 (5.9243e-01) 
2023-05-25 00:06:21.384993: train Epoch: [0][106/193]	Time  0.999 ( 1.431)	Data  0.001 ( 0.287)	Loss 4.5851e-01 (5.9118e-01) 
2023-05-25 00:06:22.862885: train Epoch: [0][107/193]	Time  1.478 ( 1.431)	Data  0.575 ( 0.290)	Loss 3.3969e-01 (5.8885e-01) 
2023-05-25 00:06:23.830918: train Epoch: [0][108/193]	Time  0.968 ( 1.427)	Data  0.001 ( 0.287)	Loss 5.2820e-01 (5.8829e-01) 
2023-05-25 00:06:25.901008: train Epoch: [0][109/193]	Time  2.070 ( 1.433)	Data  0.903 ( 0.293)	Loss 4.0030e-01 (5.8658e-01) 
2023-05-25 00:06:26.868502: train Epoch: [0][110/193]	Time  0.967 ( 1.428)	Data  0.001 ( 0.290)	Loss 4.0814e-01 (5.8498e-01) 
2023-05-25 00:06:28.769536: train Epoch: [0][111/193]	Time  1.901 ( 1.433)	Data  0.626 ( 0.293)	Loss 3.9504e-01 (5.8328e-01) 
2023-05-25 00:06:29.765234: train Epoch: [0][112/193]	Time  0.996 ( 1.429)	Data  0.001 ( 0.291)	Loss 3.0664e-01 (5.8083e-01) 
2023-05-25 00:06:31.503572: train Epoch: [0][113/193]	Time  1.738 ( 1.431)	Data  0.480 ( 0.292)	Loss 4.0860e-01 (5.7932e-01) 
2023-05-25 00:06:32.532751: train Epoch: [0][114/193]	Time  1.029 ( 1.428)	Data  0.001 ( 0.290)	Loss 5.2389e-01 (5.7884e-01) 
2023-05-25 00:06:34.260766: train Epoch: [0][115/193]	Time  1.728 ( 1.431)	Data  0.500 ( 0.292)	Loss 4.6620e-01 (5.7787e-01) 
2023-05-25 00:06:35.309597: train Epoch: [0][116/193]	Time  1.049 ( 1.427)	Data  0.001 ( 0.289)	Loss 2.7506e-01 (5.7528e-01) 
2023-05-25 00:06:36.920434: train Epoch: [0][117/193]	Time  1.611 ( 1.429)	Data  0.424 ( 0.290)	Loss 2.8915e-01 (5.7286e-01) 
2023-05-25 00:06:38.072700: train Epoch: [0][118/193]	Time  1.152 ( 1.427)	Data  0.001 ( 0.288)	Loss 3.1637e-01 (5.7070e-01) 
2023-05-25 00:06:39.816366: train Epoch: [0][119/193]	Time  1.744 ( 1.429)	Data  0.517 ( 0.290)	Loss 3.1638e-01 (5.6858e-01) 
2023-05-25 00:06:41.064989: train Epoch: [0][120/193]	Time  1.249 ( 1.428)	Data  0.001 ( 0.287)	Loss 2.9023e-01 (5.6628e-01) 
2023-05-25 00:06:42.689623: train Epoch: [0][121/193]	Time  1.625 ( 1.429)	Data  0.360 ( 0.288)	Loss 2.8532e-01 (5.6398e-01) 
2023-05-25 00:06:43.976648: train Epoch: [0][122/193]	Time  1.287 ( 1.428)	Data  0.001 ( 0.286)	Loss 2.8118e-01 (5.6168e-01) 
2023-05-25 00:06:45.255275: train Epoch: [0][123/193]	Time  1.279 ( 1.427)	Data  0.241 ( 0.285)	Loss 3.1689e-01 (5.5970e-01) 
2023-05-25 00:06:46.620258: train Epoch: [0][124/193]	Time  1.365 ( 1.426)	Data  0.001 ( 0.283)	Loss 2.9299e-01 (5.5757e-01) 
2023-05-25 00:06:47.959941: train Epoch: [0][125/193]	Time  1.340 ( 1.426)	Data  0.320 ( 0.283)	Loss 2.9805e-01 (5.5551e-01) 
2023-05-25 00:06:48.932851: train Epoch: [0][126/193]	Time  0.973 ( 1.422)	Data  0.001 ( 0.281)	Loss 1.4796e-01 (5.5230e-01) 
2023-05-25 00:06:50.511521: train Epoch: [0][127/193]	Time  1.579 ( 1.423)	Data  0.612 ( 0.284)	Loss 3.2499e-01 (5.5053e-01) 
2023-05-25 00:06:51.431545: train Epoch: [0][128/193]	Time  0.920 ( 1.420)	Data  0.001 ( 0.282)	Loss 4.3565e-01 (5.4964e-01) 
2023-05-25 00:06:53.437139: train Epoch: [0][129/193]	Time  2.006 ( 1.424)	Data  1.044 ( 0.287)	Loss 2.2425e-01 (5.4713e-01) 
2023-05-25 00:06:54.466474: train Epoch: [0][130/193]	Time  1.029 ( 1.421)	Data  0.001 ( 0.285)	Loss 3.1351e-01 (5.4535e-01) 
2023-05-25 00:06:56.311725: train Epoch: [0][131/193]	Time  1.845 ( 1.424)	Data  0.857 ( 0.290)	Loss 2.6509e-01 (5.4323e-01) 
2023-05-25 00:06:57.350113: train Epoch: [0][132/193]	Time  1.038 ( 1.421)	Data  0.001 ( 0.287)	Loss 4.2913e-01 (5.4237e-01) 
2023-05-25 00:06:59.531653: train Epoch: [0][133/193]	Time  2.182 ( 1.427)	Data  0.799 ( 0.291)	Loss 2.5634e-01 (5.4023e-01) 
2023-05-25 00:07:00.638826: train Epoch: [0][134/193]	Time  1.107 ( 1.425)	Data  0.001 ( 0.289)	Loss 4.7153e-01 (5.3972e-01) 
2023-05-25 00:07:02.094471: train Epoch: [0][135/193]	Time  1.456 ( 1.425)	Data  0.225 ( 0.289)	Loss 3.4315e-01 (5.3828e-01) 
2023-05-25 00:07:03.268048: train Epoch: [0][136/193]	Time  1.174 ( 1.423)	Data  0.001 ( 0.286)	Loss 3.4691e-01 (5.3688e-01) 
2023-05-25 00:07:04.761513: train Epoch: [0][137/193]	Time  1.493 ( 1.424)	Data  0.342 ( 0.287)	Loss 3.0080e-01 (5.3517e-01) 
2023-05-25 00:07:06.171507: train Epoch: [0][138/193]	Time  1.410 ( 1.423)	Data  0.001 ( 0.285)	Loss 3.1877e-01 (5.3362e-01) 
2023-05-25 00:07:07.646123: train Epoch: [0][139/193]	Time  1.475 ( 1.424)	Data  0.289 ( 0.285)	Loss 4.5312e-01 (5.3304e-01) 
2023-05-25 00:07:08.664559: train Epoch: [0][140/193]	Time  1.018 ( 1.421)	Data  0.001 ( 0.283)	Loss 1.7642e-01 (5.3051e-01) 
2023-05-25 00:07:10.306159: train Epoch: [0][141/193]	Time  1.642 ( 1.422)	Data  0.529 ( 0.285)	Loss 3.1424e-01 (5.2899e-01) 
2023-05-25 00:07:11.581336: train Epoch: [0][142/193]	Time  1.275 ( 1.421)	Data  0.001 ( 0.283)	Loss 2.4117e-01 (5.2698e-01) 
2023-05-25 00:07:13.174984: train Epoch: [0][143/193]	Time  1.594 ( 1.423)	Data  0.465 ( 0.284)	Loss 2.9421e-01 (5.2536e-01) 
2023-05-25 00:07:14.378381: train Epoch: [0][144/193]	Time  1.203 ( 1.421)	Data  0.001 ( 0.282)	Loss 3.5824e-01 (5.2421e-01) 
2023-05-25 00:07:15.899567: train Epoch: [0][145/193]	Time  1.521 ( 1.422)	Data  0.456 ( 0.283)	Loss 4.3042e-01 (5.2356e-01) 
2023-05-25 00:07:16.942594: train Epoch: [0][146/193]	Time  1.043 ( 1.419)	Data  0.001 ( 0.281)	Loss 2.3834e-01 (5.2162e-01) 
2023-05-25 00:07:18.893283: train Epoch: [0][147/193]	Time  1.951 ( 1.423)	Data  0.594 ( 0.283)	Loss 4.1076e-01 (5.2087e-01) 
2023-05-25 00:07:20.005857: train Epoch: [0][148/193]	Time  1.113 ( 1.421)	Data  0.001 ( 0.281)	Loss 2.7021e-01 (5.1919e-01) 
2023-05-25 00:07:21.618789: train Epoch: [0][149/193]	Time  1.613 ( 1.422)	Data  0.281 ( 0.281)	Loss 3.1604e-01 (5.1784e-01) 
2023-05-25 00:07:22.680044: train Epoch: [0][150/193]	Time  1.061 ( 1.420)	Data  0.001 ( 0.280)	Loss 1.8073e-01 (5.1561e-01) 
2023-05-25 00:07:24.224962: train Epoch: [0][151/193]	Time  1.545 ( 1.420)	Data  0.271 ( 0.279)	Loss 4.4659e-01 (5.1515e-01) 
2023-05-25 00:07:25.310870: train Epoch: [0][152/193]	Time  1.086 ( 1.418)	Data  0.001 ( 0.278)	Loss 3.0053e-01 (5.1375e-01) 
2023-05-25 00:07:27.041412: train Epoch: [0][153/193]	Time  1.731 ( 1.420)	Data  0.407 ( 0.279)	Loss 3.4644e-01 (5.1266e-01) 
2023-05-25 00:07:28.174069: train Epoch: [0][154/193]	Time  1.133 ( 1.418)	Data  0.001 ( 0.277)	Loss 6.0008e-01 (5.1323e-01) 
2023-05-25 00:07:29.723402: train Epoch: [0][155/193]	Time  1.549 ( 1.419)	Data  0.374 ( 0.277)	Loss 3.0167e-01 (5.1187e-01) 
2023-05-25 00:07:30.839586: train Epoch: [0][156/193]	Time  1.116 ( 1.417)	Data  0.001 ( 0.276)	Loss 3.3416e-01 (5.1074e-01) 
2023-05-25 00:07:32.408195: train Epoch: [0][157/193]	Time  1.569 ( 1.418)	Data  0.472 ( 0.277)	Loss 4.0625e-01 (5.1008e-01) 
2023-05-25 00:07:33.590845: train Epoch: [0][158/193]	Time  1.183 ( 1.417)	Data  0.001 ( 0.275)	Loss 2.8954e-01 (5.0869e-01) 
2023-05-25 00:07:35.342638: train Epoch: [0][159/193]	Time  1.752 ( 1.419)	Data  0.607 ( 0.277)	Loss 3.0411e-01 (5.0741e-01) 
2023-05-25 00:07:36.478180: train Epoch: [0][160/193]	Time  1.136 ( 1.417)	Data  0.001 ( 0.275)	Loss 3.8931e-01 (5.0668e-01) 
2023-05-25 00:07:38.057887: train Epoch: [0][161/193]	Time  1.580 ( 1.418)	Data  0.563 ( 0.277)	Loss 2.5022e-01 (5.0509e-01) 
2023-05-25 00:07:39.142537: train Epoch: [0][162/193]	Time  1.085 ( 1.416)	Data  0.001 ( 0.276)	Loss 3.9188e-01 (5.0440e-01) 
2023-05-25 00:07:41.064254: train Epoch: [0][163/193]	Time  1.922 ( 1.419)	Data  0.597 ( 0.277)	Loss 1.8314e-01 (5.0244e-01) 
2023-05-25 00:07:42.124109: train Epoch: [0][164/193]	Time  1.060 ( 1.417)	Data  0.001 ( 0.276)	Loss 3.8295e-01 (5.0172e-01) 
2023-05-25 00:07:43.683076: train Epoch: [0][165/193]	Time  1.559 ( 1.418)	Data  0.344 ( 0.276)	Loss 2.5087e-01 (5.0021e-01) 
2023-05-25 00:07:44.799589: train Epoch: [0][166/193]	Time  1.117 ( 1.416)	Data  0.001 ( 0.275)	Loss 3.4530e-01 (4.9928e-01) 
2023-05-25 00:07:46.127112: train Epoch: [0][167/193]	Time  1.327 ( 1.416)	Data  0.317 ( 0.275)	Loss 3.9597e-01 (4.9866e-01) 
2023-05-25 00:07:47.183014: train Epoch: [0][168/193]	Time  1.056 ( 1.413)	Data  0.001 ( 0.273)	Loss 3.1001e-01 (4.9755e-01) 
2023-05-25 00:07:48.889751: train Epoch: [0][169/193]	Time  1.707 ( 1.415)	Data  0.522 ( 0.275)	Loss 3.3979e-01 (4.9662e-01) 
2023-05-25 00:07:50.102429: train Epoch: [0][170/193]	Time  1.213 ( 1.414)	Data  0.001 ( 0.273)	Loss 4.0307e-01 (4.9607e-01) 
2023-05-25 00:07:51.767751: train Epoch: [0][171/193]	Time  1.665 ( 1.415)	Data  0.520 ( 0.275)	Loss 2.1736e-01 (4.9445e-01) 
2023-05-25 00:07:52.917138: train Epoch: [0][172/193]	Time  1.149 ( 1.414)	Data  0.002 ( 0.273)	Loss 3.0568e-01 (4.9336e-01) 
2023-05-25 00:07:54.462238: train Epoch: [0][173/193]	Time  1.545 ( 1.415)	Data  0.471 ( 0.274)	Loss 3.9500e-01 (4.9279e-01) 
2023-05-25 00:07:55.645123: train Epoch: [0][174/193]	Time  1.183 ( 1.413)	Data  0.001 ( 0.273)	Loss 2.8117e-01 (4.9159e-01) 
2023-05-25 00:07:57.335269: train Epoch: [0][175/193]	Time  1.690 ( 1.415)	Data  0.575 ( 0.274)	Loss 5.5358e-01 (4.9194e-01) 
2023-05-25 00:07:58.390777: train Epoch: [0][176/193]	Time  1.056 ( 1.413)	Data  0.001 ( 0.273)	Loss 2.5059e-01 (4.9057e-01) 
2023-05-25 00:08:00.141720: train Epoch: [0][177/193]	Time  1.751 ( 1.415)	Data  0.600 ( 0.275)	Loss 1.9894e-01 (4.8894e-01) 
2023-05-25 00:08:01.107326: train Epoch: [0][178/193]	Time  0.966 ( 1.412)	Data  0.001 ( 0.273)	Loss 2.9614e-01 (4.8786e-01) 
2023-05-25 00:08:02.950652: train Epoch: [0][179/193]	Time  1.843 ( 1.415)	Data  0.683 ( 0.275)	Loss 2.2038e-01 (4.8637e-01) 
2023-05-25 00:08:03.919035: train Epoch: [0][180/193]	Time  0.968 ( 1.412)	Data  0.001 ( 0.274)	Loss 3.9113e-01 (4.8585e-01) 
2023-05-25 00:08:05.978384: train Epoch: [0][181/193]	Time  2.059 ( 1.416)	Data  0.794 ( 0.277)	Loss 2.7829e-01 (4.8471e-01) 
2023-05-25 00:08:06.967323: train Epoch: [0][182/193]	Time  0.989 ( 1.413)	Data  0.001 ( 0.275)	Loss 3.2159e-01 (4.8381e-01) 
2023-05-25 00:08:08.489272: train Epoch: [0][183/193]	Time  1.522 ( 1.414)	Data  0.475 ( 0.276)	Loss 2.9934e-01 (4.8281e-01) 
2023-05-25 00:08:09.654619: train Epoch: [0][184/193]	Time  1.165 ( 1.413)	Data  0.001 ( 0.275)	Loss 2.6507e-01 (4.8164e-01) 
2023-05-25 00:08:11.306309: train Epoch: [0][185/193]	Time  1.652 ( 1.414)	Data  0.470 ( 0.276)	Loss 2.5188e-01 (4.8040e-01) 
2023-05-25 00:08:12.279506: train Epoch: [0][186/193]	Time  0.973 ( 1.412)	Data  0.001 ( 0.274)	Loss 4.1197e-01 (4.8003e-01) 
2023-05-25 00:08:13.944654: train Epoch: [0][187/193]	Time  1.665 ( 1.413)	Data  0.356 ( 0.275)	Loss 2.7343e-01 (4.7894e-01) 
2023-05-25 00:08:14.972777: train Epoch: [0][188/193]	Time  1.028 ( 1.411)	Data  0.001 ( 0.273)	Loss 3.5693e-01 (4.7829e-01) 
2023-05-25 00:08:16.225103: train Epoch: [0][189/193]	Time  1.252 ( 1.410)	Data  0.190 ( 0.273)	Loss 2.5903e-01 (4.7714e-01) 
2023-05-25 00:08:17.538282: train Epoch: [0][190/193]	Time  1.313 ( 1.410)	Data  0.001 ( 0.271)	Loss 2.3885e-01 (4.7589e-01) 
2023-05-25 00:08:18.734553: train Epoch: [0][191/193]	Time  1.196 ( 1.408)	Data  0.197 ( 0.271)	Loss 3.1849e-01 (4.7507e-01) 
2023-05-25 00:08:19.720613: train Epoch: [0][192/193]	Time  0.986 ( 1.406)	Data  0.001 ( 0.270)	Loss 4.4494e-01 (4.7491e-01) 
2023-05-25 00:08:19.772386: Train Epoch done in 271.4586487109773 s 
2023-05-25 00:08:23.022744: val Epoch: [0][ 0/72]	Time  2.008 ( 2.008)	Data  1.647 ( 1.647)	Loss 4.8733e-01 (4.8733e-01) 
2023-05-25 00:08:23.453022: val Epoch: [0][ 1/72]	Time  0.430 ( 1.219)	Data  0.002 ( 0.824)	Loss 3.6880e-01 (4.2807e-01) 
2023-05-25 00:08:24.301711: val Epoch: [0][ 2/72]	Time  0.849 ( 1.096)	Data  0.514 ( 0.721)	Loss 1.9777e-01 (3.5130e-01) 
2023-05-25 00:08:24.920205: val Epoch: [0][ 3/72]	Time  0.618 ( 0.977)	Data  0.081 ( 0.561)	Loss 3.0125e-01 (3.3879e-01) 
2023-05-25 00:08:25.776744: val Epoch: [0][ 4/72]	Time  0.857 ( 0.953)	Data  0.421 ( 0.533)	Loss 3.5554e-01 (3.4214e-01) 
2023-05-25 00:08:26.233088: val Epoch: [0][ 5/72]	Time  0.456 ( 0.870)	Data  0.131 ( 0.466)	Loss 2.1474e-01 (3.2090e-01) 
2023-05-25 00:08:27.105428: val Epoch: [0][ 6/72]	Time  0.872 ( 0.870)	Data  0.437 ( 0.462)	Loss 5.2529e-01 (3.5010e-01) 
2023-05-25 00:08:27.752436: val Epoch: [0][ 7/72]	Time  0.647 ( 0.842)	Data  0.310 ( 0.443)	Loss 1.9827e-01 (3.3112e-01) 
2023-05-25 00:08:28.336192: val Epoch: [0][ 8/72]	Time  0.584 ( 0.814)	Data  0.289 ( 0.426)	Loss 2.6434e-01 (3.2370e-01) 
2023-05-25 00:08:29.327272: val Epoch: [0][ 9/72]	Time  0.991 ( 0.831)	Data  0.626 ( 0.446)	Loss 1.5067e-01 (3.0640e-01) 
2023-05-25 00:08:29.798924: val Epoch: [0][10/72]	Time  0.472 ( 0.799)	Data  0.123 ( 0.416)	Loss 3.5132e-01 (3.1048e-01) 
2023-05-25 00:08:30.852469: val Epoch: [0][11/72]	Time  1.054 ( 0.820)	Data  0.746 ( 0.444)	Loss 2.7510e-01 (3.0753e-01) 
2023-05-25 00:08:31.162946: val Epoch: [0][12/72]	Time  0.310 ( 0.781)	Data  0.001 ( 0.410)	Loss 4.2025e-01 (3.1621e-01) 
2023-05-25 00:08:32.437324: val Epoch: [0][13/72]	Time  1.274 ( 0.816)	Data  0.918 ( 0.446)	Loss 1.8905e-01 (3.0712e-01) 
2023-05-25 00:08:32.854742: val Epoch: [0][14/72]	Time  0.417 ( 0.789)	Data  0.001 ( 0.416)	Loss 4.1479e-01 (3.1430e-01) 
2023-05-25 00:08:33.803448: val Epoch: [0][15/72]	Time  0.949 ( 0.799)	Data  0.670 ( 0.432)	Loss 1.7632e-01 (3.0568e-01) 
2023-05-25 00:08:34.152005: val Epoch: [0][16/72]	Time  0.349 ( 0.773)	Data  0.004 ( 0.407)	Loss 3.6622e-01 (3.0924e-01) 
2023-05-25 00:08:35.299505: val Epoch: [0][17/72]	Time  1.147 ( 0.794)	Data  0.854 ( 0.432)	Loss 2.9032e-01 (3.0819e-01) 
2023-05-25 00:08:35.555621: val Epoch: [0][18/72]	Time  0.256 ( 0.765)	Data  0.001 ( 0.409)	Loss 2.7661e-01 (3.0653e-01) 
2023-05-25 00:08:36.833919: val Epoch: [0][19/72]	Time  1.278 ( 0.791)	Data  0.931 ( 0.435)	Loss 2.6758e-01 (3.0458e-01) 
2023-05-25 00:08:37.209977: val Epoch: [0][20/72]	Time  0.376 ( 0.771)	Data  0.001 ( 0.415)	Loss 2.9689e-01 (3.0421e-01) 
2023-05-25 00:08:38.310213: val Epoch: [0][21/72]	Time  1.100 ( 0.786)	Data  0.823 ( 0.433)	Loss 3.1346e-01 (3.0463e-01) 
2023-05-25 00:08:38.544702: val Epoch: [0][22/72]	Time  0.234 ( 0.762)	Data  0.001 ( 0.414)	Loss 3.3209e-01 (3.0583e-01) 
2023-05-25 00:08:40.074358: val Epoch: [0][23/72]	Time  1.530 ( 0.794)	Data  1.074 ( 0.442)	Loss 2.8105e-01 (3.0479e-01) 
2023-05-25 00:08:40.414932: val Epoch: [0][24/72]	Time  0.341 ( 0.776)	Data  0.001 ( 0.424)	Loss 1.9100e-01 (3.0024e-01) 
2023-05-25 00:08:41.442676: val Epoch: [0][25/72]	Time  1.028 ( 0.786)	Data  0.655 ( 0.433)	Loss 2.7433e-01 (2.9925e-01) 
2023-05-25 00:08:41.664170: val Epoch: [0][26/72]	Time  0.221 ( 0.765)	Data  0.001 ( 0.417)	Loss 4.1919e-01 (3.0369e-01) 
2023-05-25 00:08:42.876774: val Epoch: [0][27/72]	Time  1.213 ( 0.781)	Data  0.868 ( 0.433)	Loss 5.0428e-01 (3.1085e-01) 
2023-05-25 00:08:43.304043: val Epoch: [0][28/72]	Time  0.427 ( 0.769)	Data  0.001 ( 0.418)	Loss 2.8950e-01 (3.1012e-01) 
2023-05-25 00:08:44.359049: val Epoch: [0][29/72]	Time  1.055 ( 0.778)	Data  0.773 ( 0.430)	Loss 2.1394e-01 (3.0691e-01) 
2023-05-25 00:08:44.847475: val Epoch: [0][30/72]	Time  0.488 ( 0.769)	Data  0.001 ( 0.416)	Loss 2.5300e-01 (3.0517e-01) 
2023-05-25 00:08:45.896830: val Epoch: [0][31/72]	Time  1.049 ( 0.778)	Data  0.761 ( 0.427)	Loss 2.1471e-01 (3.0234e-01) 
2023-05-25 00:08:46.083942: val Epoch: [0][32/72]	Time  0.187 ( 0.760)	Data  0.001 ( 0.414)	Loss 4.2272e-01 (3.0599e-01) 
2023-05-25 00:08:47.519750: val Epoch: [0][33/72]	Time  1.436 ( 0.780)	Data  1.077 ( 0.434)	Loss 6.9070e-01 (3.1731e-01) 
2023-05-25 00:08:47.961839: val Epoch: [0][34/72]	Time  0.442 ( 0.770)	Data  0.007 ( 0.421)	Loss 3.3825e-01 (3.1790e-01) 
2023-05-25 00:08:48.936216: val Epoch: [0][35/72]	Time  0.974 ( 0.776)	Data  0.778 ( 0.431)	Loss 3.9623e-01 (3.2008e-01) 
2023-05-25 00:08:49.260230: val Epoch: [0][36/72]	Time  0.324 ( 0.763)	Data  0.000 ( 0.420)	Loss 5.4672e-01 (3.2621e-01) 
2023-05-25 00:08:50.572161: val Epoch: [0][37/72]	Time  1.312 ( 0.778)	Data  0.994 ( 0.435)	Loss 2.7285e-01 (3.2480e-01) 
2023-05-25 00:08:51.018696: val Epoch: [0][38/72]	Time  0.447 ( 0.769)	Data  0.017 ( 0.424)	Loss 1.9679e-01 (3.2152e-01) 
2023-05-25 00:08:51.934350: val Epoch: [0][39/72]	Time  0.916 ( 0.773)	Data  0.698 ( 0.431)	Loss 2.2183e-01 (3.1903e-01) 
2023-05-25 00:08:52.237796: val Epoch: [0][40/72]	Time  0.303 ( 0.762)	Data  0.001 ( 0.420)	Loss 2.5555e-01 (3.1748e-01) 
2023-05-25 00:08:53.523087: val Epoch: [0][41/72]	Time  1.285 ( 0.774)	Data  1.011 ( 0.434)	Loss 2.3227e-01 (3.1545e-01) 
2023-05-25 00:08:54.028553: val Epoch: [0][42/72]	Time  0.505 ( 0.768)	Data  0.001 ( 0.424)	Loss 3.2668e-01 (3.1571e-01) 
2023-05-25 00:08:55.159172: val Epoch: [0][43/72]	Time  1.131 ( 0.776)	Data  0.766 ( 0.432)	Loss 4.7779e-01 (3.1939e-01) 
2023-05-25 00:08:55.831626: val Epoch: [0][44/72]	Time  0.672 ( 0.774)	Data  0.001 ( 0.423)	Loss 2.9063e-01 (3.1876e-01) 
2023-05-25 00:08:56.654072: val Epoch: [0][45/72]	Time  0.822 ( 0.775)	Data  0.459 ( 0.423)	Loss 1.6809e-01 (3.1548e-01) 
2023-05-25 00:08:56.840302: val Epoch: [0][46/72]	Time  0.186 ( 0.762)	Data  0.001 ( 0.414)	Loss 5.2919e-01 (3.2003e-01) 
2023-05-25 00:08:58.080842: val Epoch: [0][47/72]	Time  1.241 ( 0.772)	Data  0.918 ( 0.425)	Loss 6.5188e-01 (3.2694e-01) 
2023-05-25 00:08:58.402245: val Epoch: [0][48/72]	Time  0.321 ( 0.763)	Data  0.001 ( 0.416)	Loss 1.9274e-01 (3.2420e-01) 
2023-05-25 00:08:59.620236: val Epoch: [0][49/72]	Time  1.218 ( 0.772)	Data  0.867 ( 0.425)	Loss 2.7005e-01 (3.2312e-01) 
2023-05-25 00:08:59.904282: val Epoch: [0][50/72]	Time  0.284 ( 0.763)	Data  0.001 ( 0.417)	Loss 2.5472e-01 (3.2178e-01) 
2023-05-25 00:09:00.985919: val Epoch: [0][51/72]	Time  1.082 ( 0.769)	Data  0.703 ( 0.422)	Loss 2.7515e-01 (3.2088e-01) 
2023-05-25 00:09:01.348498: val Epoch: [0][52/72]	Time  0.363 ( 0.761)	Data  0.001 ( 0.414)	Loss 6.7171e-01 (3.2750e-01) 
2023-05-25 00:09:02.399445: val Epoch: [0][53/72]	Time  1.051 ( 0.766)	Data  0.640 ( 0.419)	Loss 2.3657e-01 (3.2582e-01) 
2023-05-25 00:09:02.721309: val Epoch: [0][54/72]	Time  0.322 ( 0.758)	Data  0.001 ( 0.411)	Loss 4.8023e-01 (3.2862e-01) 
2023-05-25 00:09:03.732152: val Epoch: [0][55/72]	Time  1.011 ( 0.763)	Data  0.666 ( 0.416)	Loss 3.9339e-01 (3.2978e-01) 
2023-05-25 00:09:03.925300: val Epoch: [0][56/72]	Time  0.193 ( 0.753)	Data  0.001 ( 0.408)	Loss 1.7885e-01 (3.2713e-01) 
2023-05-25 00:09:05.010026: val Epoch: [0][57/72]	Time  1.085 ( 0.759)	Data  0.803 ( 0.415)	Loss 2.5555e-01 (3.2590e-01) 
2023-05-25 00:09:05.408657: val Epoch: [0][58/72]	Time  0.399 ( 0.752)	Data  0.002 ( 0.408)	Loss 2.8316e-01 (3.2517e-01) 
2023-05-25 00:09:06.593639: val Epoch: [0][59/72]	Time  1.185 ( 0.760)	Data  0.779 ( 0.414)	Loss 2.5933e-01 (3.2408e-01) 
2023-05-25 00:09:06.851755: val Epoch: [0][60/72]	Time  0.258 ( 0.751)	Data  0.001 ( 0.407)	Loss 2.7966e-01 (3.2335e-01) 
2023-05-25 00:09:07.887761: val Epoch: [0][61/72]	Time  1.036 ( 0.756)	Data  0.723 ( 0.413)	Loss 2.0725e-01 (3.2148e-01) 
2023-05-25 00:09:08.271342: val Epoch: [0][62/72]	Time  0.384 ( 0.750)	Data  0.001 ( 0.406)	Loss 2.5299e-01 (3.2039e-01) 
2023-05-25 00:09:09.352938: val Epoch: [0][63/72]	Time  1.082 ( 0.755)	Data  0.716 ( 0.411)	Loss 3.2634e-01 (3.2048e-01) 
2023-05-25 00:09:09.639129: val Epoch: [0][64/72]	Time  0.286 ( 0.748)	Data  0.001 ( 0.405)	Loss 3.4229e-01 (3.2082e-01) 
2023-05-25 00:09:10.706346: val Epoch: [0][65/72]	Time  1.067 ( 0.753)	Data  0.762 ( 0.410)	Loss 2.4340e-01 (3.1964e-01) 
2023-05-25 00:09:10.905827: val Epoch: [0][66/72]	Time  0.199 ( 0.745)	Data  0.001 ( 0.404)	Loss 5.2987e-01 (3.2278e-01) 
2023-05-25 00:09:12.288887: val Epoch: [0][67/72]	Time  1.383 ( 0.754)	Data  0.999 ( 0.413)	Loss 4.9283e-01 (3.2528e-01) 
2023-05-25 00:09:12.714123: val Epoch: [0][68/72]	Time  0.425 ( 0.749)	Data  0.001 ( 0.407)	Loss 3.0269e-01 (3.2496e-01) 
2023-05-25 00:09:13.434943: val Epoch: [0][69/72]	Time  0.721 ( 0.749)	Data  0.482 ( 0.408)	Loss 1.2580e-01 (3.2211e-01) 
2023-05-25 00:09:13.763225: val Epoch: [0][70/72]	Time  0.328 ( 0.743)	Data  0.001 ( 0.402)	Loss 2.2160e-01 (3.2069e-01) 
2023-05-25 00:09:14.692284: val Epoch: [0][71/72]	Time  0.929 ( 0.746)	Data  0.583 ( 0.405)	Loss 5.5927e-01 (3.2401e-01) 
2023-05-25 00:09:14.973542: Epoch 0 :Val : ['ET : 0.4204910099506378', 'TC : 0.5212029814720154', 'WT : 0.7093007564544678'] 
2023-05-25 00:09:14.976481: Epoch 0 :Val : ['ET : 0.4204910099506378', 'TC : 0.5212029814720154', 'WT : 0.7093007564544678'] 
2023-05-25 00:09:14.979313: Saving the model with DSC 0.5452064275741577 
2023-05-25 00:09:15.982337: Val epoch done in 56.20993702101987 s 
2023-05-25 00:09:15.995847: Batches per epoch:  193 
2023-05-25 00:09:20.509162: train Epoch: [1][  0/193]	Time  4.513 ( 4.513)	Data  3.110 ( 3.110)	Loss 1.9193e-01 (1.9193e-01) 
2023-05-25 00:09:21.560243: train Epoch: [1][  1/193]	Time  1.051 ( 2.782)	Data  0.002 ( 1.556)	Loss 2.6324e-01 (2.2758e-01) 
2023-05-25 00:09:22.796909: train Epoch: [1][  2/193]	Time  1.237 ( 2.267)	Data  0.216 ( 1.109)	Loss 2.5522e-01 (2.3680e-01) 
2023-05-25 00:09:23.861835: train Epoch: [1][  3/193]	Time  1.065 ( 1.966)	Data  0.001 ( 0.832)	Loss 2.0176e-01 (2.2804e-01) 
2023-05-25 00:09:25.657797: train Epoch: [1][  4/193]	Time  1.796 ( 1.932)	Data  0.515 ( 0.769)	Loss 3.2692e-01 (2.4781e-01) 
2023-05-25 00:09:26.986816: train Epoch: [1][  5/193]	Time  1.329 ( 1.832)	Data  0.001 ( 0.641)	Loss 3.8651e-01 (2.7093e-01) 
2023-05-25 00:09:28.075781: train Epoch: [1][  6/193]	Time  1.089 ( 1.726)	Data  0.055 ( 0.557)	Loss 2.3727e-01 (2.6612e-01) 
2023-05-25 00:09:29.159627: train Epoch: [1][  7/193]	Time  1.084 ( 1.645)	Data  0.001 ( 0.488)	Loss 2.3008e-01 (2.6162e-01) 
2023-05-25 00:09:30.843367: train Epoch: [1][  8/193]	Time  1.684 ( 1.650)	Data  0.626 ( 0.503)	Loss 3.4153e-01 (2.7050e-01) 
2023-05-25 00:09:31.981270: train Epoch: [1][  9/193]	Time  1.138 ( 1.598)	Data  0.001 ( 0.453)	Loss 2.1477e-01 (2.6492e-01) 
2023-05-25 00:09:33.864207: train Epoch: [1][ 10/193]	Time  1.883 ( 1.624)	Data  0.473 ( 0.455)	Loss 3.0149e-01 (2.6825e-01) 
2023-05-25 00:09:34.927245: train Epoch: [1][ 11/193]	Time  1.063 ( 1.578)	Data  0.001 ( 0.417)	Loss 2.9163e-01 (2.7020e-01) 
2023-05-25 00:09:36.433964: train Epoch: [1][ 12/193]	Time  1.507 ( 1.572)	Data  0.211 ( 0.401)	Loss 2.8012e-01 (2.7096e-01) 
2023-05-25 00:09:37.450722: train Epoch: [1][ 13/193]	Time  1.017 ( 1.532)	Data  0.001 ( 0.372)	Loss 3.8170e-01 (2.7887e-01) 
2023-05-25 00:09:38.865371: train Epoch: [1][ 14/193]	Time  1.415 ( 1.525)	Data  0.390 ( 0.374)	Loss 1.9437e-01 (2.7324e-01) 
2023-05-25 00:09:40.046824: train Epoch: [1][ 15/193]	Time  1.181 ( 1.503)	Data  0.069 ( 0.355)	Loss 4.5477e-01 (2.8458e-01) 
2023-05-25 00:09:41.663160: train Epoch: [1][ 16/193]	Time  1.616 ( 1.510)	Data  0.592 ( 0.369)	Loss 2.8081e-01 (2.8436e-01) 
2023-05-25 00:09:42.836470: train Epoch: [1][ 17/193]	Time  1.173 ( 1.491)	Data  0.151 ( 0.357)	Loss 3.6032e-01 (2.8858e-01) 
2023-05-25 00:09:44.521634: train Epoch: [1][ 18/193]	Time  1.685 ( 1.501)	Data  0.676 ( 0.373)	Loss 4.6299e-01 (2.9776e-01) 
2023-05-25 00:09:45.737583: train Epoch: [1][ 19/193]	Time  1.216 ( 1.487)	Data  0.204 ( 0.365)	Loss 2.7752e-01 (2.9675e-01) 
2023-05-25 00:09:47.343130: train Epoch: [1][ 20/193]	Time  1.606 ( 1.493)	Data  0.563 ( 0.374)	Loss 2.9083e-01 (2.9647e-01) 
2023-05-25 00:09:49.078718: train Epoch: [1][ 21/193]	Time  1.736 ( 1.504)	Data  0.496 ( 0.380)	Loss 4.1808e-01 (3.0199e-01) 
2023-05-25 00:09:50.030016: train Epoch: [1][ 22/193]	Time  0.951 ( 1.480)	Data  0.009 ( 0.364)	Loss 1.9283e-01 (2.9725e-01) 
2023-05-25 00:09:52.012288: train Epoch: [1][ 23/193]	Time  1.982 ( 1.501)	Data  0.701 ( 0.378)	Loss 2.5556e-01 (2.9551e-01) 
2023-05-25 00:09:52.949849: train Epoch: [1][ 24/193]	Time  0.938 ( 1.478)	Data  0.001 ( 0.363)	Loss 4.3083e-01 (3.0092e-01) 
2023-05-25 00:09:55.007716: train Epoch: [1][ 25/193]	Time  2.058 ( 1.500)	Data  0.757 ( 0.378)	Loss 2.6379e-01 (2.9950e-01) 
2023-05-25 00:09:56.008518: train Epoch: [1][ 26/193]	Time  1.001 ( 1.482)	Data  0.001 ( 0.364)	Loss 3.0681e-01 (2.9977e-01) 
2023-05-25 00:09:57.882749: train Epoch: [1][ 27/193]	Time  1.874 ( 1.496)	Data  0.513 ( 0.369)	Loss 2.3288e-01 (2.9738e-01) 
2023-05-25 00:09:58.933801: train Epoch: [1][ 28/193]	Time  1.051 ( 1.481)	Data  0.001 ( 0.356)	Loss 2.6925e-01 (2.9641e-01) 
2023-05-25 00:10:00.649448: train Epoch: [1][ 29/193]	Time  1.716 ( 1.488)	Data  0.528 ( 0.362)	Loss 2.4371e-01 (2.9465e-01) 
2023-05-25 00:10:01.832125: train Epoch: [1][ 30/193]	Time  1.183 ( 1.479)	Data  0.001 ( 0.351)	Loss 2.4034e-01 (2.9290e-01) 
2023-05-25 00:10:03.402586: train Epoch: [1][ 31/193]	Time  1.570 ( 1.481)	Data  0.566 ( 0.357)	Loss 1.4657e-01 (2.8833e-01) 
2023-05-25 00:10:04.553204: train Epoch: [1][ 32/193]	Time  1.151 ( 1.471)	Data  0.077 ( 0.349)	Loss 1.9966e-01 (2.8564e-01) 
2023-05-25 00:10:06.586447: train Epoch: [1][ 33/193]	Time  2.033 ( 1.488)	Data  0.830 ( 0.363)	Loss 1.5656e-01 (2.8184e-01) 
2023-05-25 00:10:07.754844: train Epoch: [1][ 34/193]	Time  1.168 ( 1.479)	Data  0.001 ( 0.353)	Loss 5.6911e-01 (2.9005e-01) 
2023-05-25 00:10:09.617870: train Epoch: [1][ 35/193]	Time  1.863 ( 1.489)	Data  0.619 ( 0.360)	Loss 4.1321e-01 (2.9347e-01) 
2023-05-25 00:10:10.709463: train Epoch: [1][ 36/193]	Time  1.092 ( 1.479)	Data  0.001 ( 0.350)	Loss 3.2421e-01 (2.9430e-01) 
2023-05-25 00:10:12.280627: train Epoch: [1][ 37/193]	Time  1.571 ( 1.481)	Data  0.592 ( 0.357)	Loss 2.4501e-01 (2.9301e-01) 
2023-05-25 00:10:13.223024: train Epoch: [1][ 38/193]	Time  0.942 ( 1.467)	Data  0.001 ( 0.348)	Loss 2.9150e-01 (2.9297e-01) 
2023-05-25 00:10:15.295026: train Epoch: [1][ 39/193]	Time  2.072 ( 1.482)	Data  0.964 ( 0.363)	Loss 2.1580e-01 (2.9104e-01) 
2023-05-25 00:10:16.313826: train Epoch: [1][ 40/193]	Time  1.019 ( 1.471)	Data  0.001 ( 0.354)	Loss 1.9384e-01 (2.8867e-01) 
2023-05-25 00:10:18.228812: train Epoch: [1][ 41/193]	Time  1.915 ( 1.482)	Data  0.800 ( 0.365)	Loss 2.8132e-01 (2.8849e-01) 
2023-05-25 00:10:19.217737: train Epoch: [1][ 42/193]	Time  0.989 ( 1.470)	Data  0.001 ( 0.356)	Loss 2.0140e-01 (2.8647e-01) 
2023-05-25 00:10:21.105176: train Epoch: [1][ 43/193]	Time  1.887 ( 1.480)	Data  0.687 ( 0.364)	Loss 2.6565e-01 (2.8599e-01) 
2023-05-25 00:10:22.057575: train Epoch: [1][ 44/193]	Time  0.952 ( 1.468)	Data  0.001 ( 0.356)	Loss 2.8942e-01 (2.8607e-01) 
2023-05-25 00:10:23.955146: train Epoch: [1][ 45/193]	Time  1.898 ( 1.477)	Data  0.591 ( 0.361)	Loss 1.4938e-01 (2.8310e-01) 
2023-05-25 00:10:25.163136: train Epoch: [1][ 46/193]	Time  1.208 ( 1.472)	Data  0.001 ( 0.353)	Loss 3.0938e-01 (2.8366e-01) 
2023-05-25 00:10:26.707467: train Epoch: [1][ 47/193]	Time  1.544 ( 1.473)	Data  0.375 ( 0.354)	Loss 4.1256e-01 (2.8634e-01) 
2023-05-25 00:10:28.053776: train Epoch: [1][ 48/193]	Time  1.346 ( 1.471)	Data  0.125 ( 0.349)	Loss 2.9280e-01 (2.8647e-01) 
2023-05-25 00:10:29.449631: train Epoch: [1][ 49/193]	Time  1.396 ( 1.469)	Data  0.360 ( 0.349)	Loss 2.5886e-01 (2.8592e-01) 
2023-05-25 00:10:30.701828: train Epoch: [1][ 50/193]	Time  1.252 ( 1.465)	Data  0.240 ( 0.347)	Loss 2.7749e-01 (2.8576e-01) 
2023-05-25 00:10:32.336572: train Epoch: [1][ 51/193]	Time  1.635 ( 1.468)	Data  0.494 ( 0.350)	Loss 3.9959e-01 (2.8795e-01) 
2023-05-25 00:10:33.641102: train Epoch: [1][ 52/193]	Time  1.305 ( 1.465)	Data  0.272 ( 0.348)	Loss 3.8351e-01 (2.8975e-01) 
2023-05-25 00:10:35.278774: train Epoch: [1][ 53/193]	Time  1.638 ( 1.468)	Data  0.424 ( 0.350)	Loss 2.6654e-01 (2.8932e-01) 
2023-05-25 00:10:36.757479: train Epoch: [1][ 54/193]	Time  1.479 ( 1.468)	Data  0.397 ( 0.351)	Loss 2.2609e-01 (2.8817e-01) 
2023-05-25 00:10:37.998864: train Epoch: [1][ 55/193]	Time  1.241 ( 1.464)	Data  0.213 ( 0.348)	Loss 4.5369e-01 (2.9113e-01) 
2023-05-25 00:10:39.605303: train Epoch: [1][ 56/193]	Time  1.606 ( 1.467)	Data  0.493 ( 0.351)	Loss 2.1261e-01 (2.8975e-01) 
2023-05-25 00:10:40.764790: train Epoch: [1][ 57/193]	Time  1.159 ( 1.462)	Data  0.168 ( 0.348)	Loss 1.9053e-01 (2.8804e-01) 
2023-05-25 00:10:42.393196: train Epoch: [1][ 58/193]	Time  1.628 ( 1.464)	Data  0.616 ( 0.352)	Loss 2.8909e-01 (2.8805e-01) 
2023-05-25 00:10:43.850190: train Epoch: [1][ 59/193]	Time  1.457 ( 1.464)	Data  0.365 ( 0.352)	Loss 3.0806e-01 (2.8839e-01) 
2023-05-25 00:10:45.401234: train Epoch: [1][ 60/193]	Time  1.551 ( 1.466)	Data  0.381 ( 0.353)	Loss 2.2543e-01 (2.8736e-01) 
2023-05-25 00:10:46.810386: train Epoch: [1][ 61/193]	Time  1.409 ( 1.465)	Data  0.339 ( 0.353)	Loss 2.8642e-01 (2.8734e-01) 
2023-05-25 00:10:48.030903: train Epoch: [1][ 62/193]	Time  1.221 ( 1.461)	Data  0.233 ( 0.351)	Loss 2.5502e-01 (2.8683e-01) 
2023-05-25 00:10:49.735056: train Epoch: [1][ 63/193]	Time  1.704 ( 1.465)	Data  0.580 ( 0.354)	Loss 2.1324e-01 (2.8568e-01) 
2023-05-25 00:10:51.020917: train Epoch: [1][ 64/193]	Time  1.286 ( 1.462)	Data  0.072 ( 0.350)	Loss 2.6972e-01 (2.8543e-01) 
2023-05-25 00:10:52.610189: train Epoch: [1][ 65/193]	Time  1.589 ( 1.464)	Data  0.415 ( 0.351)	Loss 2.1503e-01 (2.8437e-01) 
2023-05-25 00:10:53.791207: train Epoch: [1][ 66/193]	Time  1.181 ( 1.460)	Data  0.001 ( 0.346)	Loss 4.4036e-01 (2.8669e-01) 
2023-05-25 00:10:55.372077: train Epoch: [1][ 67/193]	Time  1.581 ( 1.461)	Data  0.480 ( 0.348)	Loss 2.4180e-01 (2.8603e-01) 
2023-05-25 00:10:56.434074: train Epoch: [1][ 68/193]	Time  1.062 ( 1.456)	Data  0.001 ( 0.343)	Loss 3.5938e-01 (2.8710e-01) 
2023-05-25 00:10:58.375386: train Epoch: [1][ 69/193]	Time  1.941 ( 1.463)	Data  0.625 ( 0.347)	Loss 3.5512e-01 (2.8807e-01) 
2023-05-25 00:10:59.369431: train Epoch: [1][ 70/193]	Time  0.994 ( 1.456)	Data  0.001 ( 0.342)	Loss 3.1058e-01 (2.8839e-01) 
2023-05-25 00:11:01.128933: train Epoch: [1][ 71/193]	Time  1.759 ( 1.460)	Data  0.602 ( 0.345)	Loss 2.4254e-01 (2.8775e-01) 
2023-05-25 00:11:02.257195: train Epoch: [1][ 72/193]	Time  1.128 ( 1.456)	Data  0.001 ( 0.341)	Loss 2.2318e-01 (2.8686e-01) 
2023-05-25 00:11:03.863938: train Epoch: [1][ 73/193]	Time  1.607 ( 1.458)	Data  0.495 ( 0.343)	Loss 2.2226e-01 (2.8599e-01) 
2023-05-25 00:11:05.059492: train Epoch: [1][ 74/193]	Time  1.196 ( 1.454)	Data  0.001 ( 0.338)	Loss 3.0909e-01 (2.8630e-01) 
2023-05-25 00:11:06.686686: train Epoch: [1][ 75/193]	Time  1.627 ( 1.456)	Data  0.513 ( 0.341)	Loss 2.9037e-01 (2.8635e-01) 
2023-05-25 00:11:07.883265: train Epoch: [1][ 76/193]	Time  1.197 ( 1.453)	Data  0.001 ( 0.336)	Loss 2.4021e-01 (2.8575e-01) 
2023-05-25 00:11:09.561398: train Epoch: [1][ 77/193]	Time  1.678 ( 1.456)	Data  0.425 ( 0.337)	Loss 3.9626e-01 (2.8717e-01) 
2023-05-25 00:11:10.810343: train Epoch: [1][ 78/193]	Time  1.249 ( 1.453)	Data  0.002 ( 0.333)	Loss 2.9259e-01 (2.8724e-01) 
2023-05-25 00:11:12.083400: train Epoch: [1][ 79/193]	Time  1.273 ( 1.451)	Data  0.184 ( 0.331)	Loss 2.2297e-01 (2.8644e-01) 
2023-05-25 00:11:13.321371: train Epoch: [1][ 80/193]	Time  1.238 ( 1.448)	Data  0.001 ( 0.327)	Loss 3.7024e-01 (2.8747e-01) 
2023-05-25 00:11:14.980289: train Epoch: [1][ 81/193]	Time  1.659 ( 1.451)	Data  0.469 ( 0.329)	Loss 3.0905e-01 (2.8773e-01) 
2023-05-25 00:11:16.001280: train Epoch: [1][ 82/193]	Time  1.021 ( 1.446)	Data  0.001 ( 0.325)	Loss 2.9444e-01 (2.8781e-01) 
2023-05-25 00:11:17.929614: train Epoch: [1][ 83/193]	Time  1.928 ( 1.452)	Data  0.561 ( 0.328)	Loss 4.2407e-01 (2.8944e-01) 
2023-05-25 00:11:19.043899: train Epoch: [1][ 84/193]	Time  1.114 ( 1.448)	Data  0.001 ( 0.324)	Loss 1.9192e-01 (2.8829e-01) 
2023-05-25 00:11:20.477094: train Epoch: [1][ 85/193]	Time  1.433 ( 1.447)	Data  0.282 ( 0.323)	Loss 2.6780e-01 (2.8805e-01) 
2023-05-25 00:11:21.497785: train Epoch: [1][ 86/193]	Time  1.021 ( 1.443)	Data  0.001 ( 0.320)	Loss 2.4711e-01 (2.8758e-01) 
2023-05-25 00:11:23.049483: train Epoch: [1][ 87/193]	Time  1.552 ( 1.444)	Data  0.505 ( 0.322)	Loss 3.7448e-01 (2.8857e-01) 
2023-05-25 00:11:24.467785: train Epoch: [1][ 88/193]	Time  1.418 ( 1.443)	Data  0.001 ( 0.318)	Loss 3.2068e-01 (2.8893e-01) 
2023-05-25 00:11:26.157120: train Epoch: [1][ 89/193]	Time  1.689 ( 1.446)	Data  0.457 ( 0.320)	Loss 3.2311e-01 (2.8931e-01) 
2023-05-25 00:11:27.136001: train Epoch: [1][ 90/193]	Time  0.979 ( 1.441)	Data  0.001 ( 0.316)	Loss 1.9447e-01 (2.8827e-01) 
2023-05-25 00:11:29.067811: train Epoch: [1][ 91/193]	Time  1.932 ( 1.446)	Data  0.725 ( 0.321)	Loss 2.4078e-01 (2.8775e-01) 
2023-05-25 00:11:30.298408: train Epoch: [1][ 92/193]	Time  1.231 ( 1.444)	Data  0.001 ( 0.317)	Loss 4.2418e-01 (2.8922e-01) 
2023-05-25 00:11:31.864473: train Epoch: [1][ 93/193]	Time  1.566 ( 1.445)	Data  0.480 ( 0.319)	Loss 3.0146e-01 (2.8935e-01) 
2023-05-25 00:11:33.135215: train Epoch: [1][ 94/193]	Time  1.271 ( 1.444)	Data  0.001 ( 0.316)	Loss 3.3352e-01 (2.8981e-01) 
2023-05-25 00:11:34.565172: train Epoch: [1][ 95/193]	Time  1.430 ( 1.443)	Data  0.354 ( 0.316)	Loss 2.9986e-01 (2.8992e-01) 
2023-05-25 00:11:35.780445: train Epoch: [1][ 96/193]	Time  1.215 ( 1.441)	Data  0.001 ( 0.313)	Loss 4.7837e-01 (2.9186e-01) 
2023-05-25 00:11:37.440193: train Epoch: [1][ 97/193]	Time  1.660 ( 1.443)	Data  0.511 ( 0.315)	Loss 2.6811e-01 (2.9162e-01) 
2023-05-25 00:11:38.599058: train Epoch: [1][ 98/193]	Time  1.159 ( 1.440)	Data  0.001 ( 0.312)	Loss 2.9947e-01 (2.9170e-01) 
2023-05-25 00:11:40.185461: train Epoch: [1][ 99/193]	Time  1.586 ( 1.442)	Data  0.517 ( 0.314)	Loss 3.1905e-01 (2.9197e-01) 
2023-05-25 00:11:41.207562: train Epoch: [1][100/193]	Time  1.022 ( 1.438)	Data  0.001 ( 0.311)	Loss 2.1945e-01 (2.9125e-01) 
2023-05-25 00:11:43.093310: train Epoch: [1][101/193]	Time  1.886 ( 1.442)	Data  0.643 ( 0.314)	Loss 1.8440e-01 (2.9020e-01) 
2023-05-25 00:11:44.228122: train Epoch: [1][102/193]	Time  1.135 ( 1.439)	Data  0.001 ( 0.311)	Loss 5.0311e-01 (2.9227e-01) 
2023-05-25 00:11:45.977117: train Epoch: [1][103/193]	Time  1.749 ( 1.442)	Data  0.429 ( 0.312)	Loss 4.5550e-01 (2.9384e-01) 
2023-05-25 00:11:46.992682: train Epoch: [1][104/193]	Time  1.016 ( 1.438)	Data  0.001 ( 0.309)	Loss 3.8838e-01 (2.9474e-01) 
2023-05-25 00:11:48.490041: train Epoch: [1][105/193]	Time  1.497 ( 1.439)	Data  0.335 ( 0.309)	Loss 3.2106e-01 (2.9499e-01) 
2023-05-25 00:11:49.701098: train Epoch: [1][106/193]	Time  1.211 ( 1.436)	Data  0.001 ( 0.306)	Loss 2.7896e-01 (2.9484e-01) 
2023-05-25 00:11:51.144452: train Epoch: [1][107/193]	Time  1.443 ( 1.437)	Data  0.414 ( 0.307)	Loss 4.3392e-01 (2.9613e-01) 
2023-05-25 00:11:52.236091: train Epoch: [1][108/193]	Time  1.092 ( 1.433)	Data  0.001 ( 0.305)	Loss 3.1625e-01 (2.9631e-01) 
2023-05-25 00:11:54.072587: train Epoch: [1][109/193]	Time  1.837 ( 1.437)	Data  0.731 ( 0.308)	Loss 3.8329e-01 (2.9710e-01) 
2023-05-25 00:11:55.092114: train Epoch: [1][110/193]	Time  1.020 ( 1.433)	Data  0.001 ( 0.306)	Loss 2.7911e-01 (2.9694e-01) 
2023-05-25 00:11:56.636654: train Epoch: [1][111/193]	Time  1.545 ( 1.434)	Data  0.554 ( 0.308)	Loss 2.5915e-01 (2.9660e-01) 
2023-05-25 00:11:57.607720: train Epoch: [1][112/193]	Time  0.971 ( 1.430)	Data  0.001 ( 0.305)	Loss 4.1571e-01 (2.9766e-01) 
2023-05-25 00:11:59.747362: train Epoch: [1][113/193]	Time  2.140 ( 1.436)	Data  0.899 ( 0.310)	Loss 2.6790e-01 (2.9740e-01) 
2023-05-25 00:12:00.803856: train Epoch: [1][114/193]	Time  1.057 ( 1.433)	Data  0.001 ( 0.308)	Loss 2.0093e-01 (2.9656e-01) 
2023-05-25 00:12:02.584757: train Epoch: [1][115/193]	Time  1.781 ( 1.436)	Data  0.456 ( 0.309)	Loss 2.9507e-01 (2.9655e-01) 
2023-05-25 00:12:03.700231: train Epoch: [1][116/193]	Time  1.116 ( 1.433)	Data  0.002 ( 0.306)	Loss 2.7528e-01 (2.9636e-01) 
2023-05-25 00:12:05.265256: train Epoch: [1][117/193]	Time  1.565 ( 1.434)	Data  0.305 ( 0.306)	Loss 2.4452e-01 (2.9592e-01) 
2023-05-25 00:12:06.241370: train Epoch: [1][118/193]	Time  0.976 ( 1.431)	Data  0.001 ( 0.304)	Loss 4.4030e-01 (2.9714e-01) 
2023-05-25 00:12:08.200068: train Epoch: [1][119/193]	Time  1.959 ( 1.435)	Data  0.570 ( 0.306)	Loss 3.4990e-01 (2.9758e-01) 
2023-05-25 00:12:09.258018: train Epoch: [1][120/193]	Time  1.058 ( 1.432)	Data  0.001 ( 0.303)	Loss 2.0680e-01 (2.9683e-01) 
2023-05-25 00:12:10.615214: train Epoch: [1][121/193]	Time  1.357 ( 1.431)	Data  0.250 ( 0.303)	Loss 2.6983e-01 (2.9661e-01) 
2023-05-25 00:12:11.792264: train Epoch: [1][122/193]	Time  1.177 ( 1.429)	Data  0.001 ( 0.301)	Loss 2.9651e-01 (2.9660e-01) 
2023-05-25 00:12:13.366551: train Epoch: [1][123/193]	Time  1.574 ( 1.430)	Data  0.517 ( 0.302)	Loss 2.9192e-01 (2.9657e-01) 
2023-05-25 00:12:14.633386: train Epoch: [1][124/193]	Time  1.267 ( 1.429)	Data  0.001 ( 0.300)	Loss 1.8878e-01 (2.9570e-01) 
2023-05-25 00:12:16.191838: train Epoch: [1][125/193]	Time  1.558 ( 1.430)	Data  0.349 ( 0.300)	Loss 3.1283e-01 (2.9584e-01) 
2023-05-25 00:12:17.347715: train Epoch: [1][126/193]	Time  1.156 ( 1.428)	Data  0.001 ( 0.298)	Loss 2.1113e-01 (2.9517e-01) 
2023-05-25 00:12:18.667866: train Epoch: [1][127/193]	Time  1.320 ( 1.427)	Data  0.374 ( 0.299)	Loss 1.7848e-01 (2.9426e-01) 
2023-05-25 00:12:19.625942: train Epoch: [1][128/193]	Time  0.958 ( 1.423)	Data  0.001 ( 0.296)	Loss 3.0374e-01 (2.9434e-01) 
2023-05-25 00:12:21.604908: train Epoch: [1][129/193]	Time  1.979 ( 1.428)	Data  0.830 ( 0.300)	Loss 5.7812e-01 (2.9652e-01) 
2023-05-25 00:12:22.544284: train Epoch: [1][130/193]	Time  0.939 ( 1.424)	Data  0.001 ( 0.298)	Loss 2.0472e-01 (2.9582e-01) 
2023-05-25 00:12:24.439277: train Epoch: [1][131/193]	Time  1.895 ( 1.428)	Data  0.796 ( 0.302)	Loss 2.9870e-01 (2.9584e-01) 
2023-05-25 00:12:25.546846: train Epoch: [1][132/193]	Time  1.108 ( 1.425)	Data  0.003 ( 0.300)	Loss 2.2529e-01 (2.9531e-01) 
2023-05-25 00:12:27.318080: train Epoch: [1][133/193]	Time  1.771 ( 1.428)	Data  0.617 ( 0.302)	Loss 2.1045e-01 (2.9468e-01) 
2023-05-25 00:12:28.361959: train Epoch: [1][134/193]	Time  1.044 ( 1.425)	Data  0.001 ( 0.300)	Loss 2.5986e-01 (2.9442e-01) 
2023-05-25 00:12:29.918406: train Epoch: [1][135/193]	Time  1.556 ( 1.426)	Data  0.610 ( 0.302)	Loss 2.1373e-01 (2.9382e-01) 
2023-05-25 00:12:31.049278: train Epoch: [1][136/193]	Time  1.131 ( 1.424)	Data  0.001 ( 0.300)	Loss 2.9434e-01 (2.9383e-01) 
2023-05-25 00:12:32.639121: train Epoch: [1][137/193]	Time  1.590 ( 1.425)	Data  0.590 ( 0.302)	Loss 2.1598e-01 (2.9326e-01) 
2023-05-25 00:12:33.659865: train Epoch: [1][138/193]	Time  1.021 ( 1.422)	Data  0.001 ( 0.300)	Loss 3.1807e-01 (2.9344e-01) 
2023-05-25 00:12:35.683941: train Epoch: [1][139/193]	Time  2.024 ( 1.426)	Data  0.781 ( 0.303)	Loss 2.0237e-01 (2.9279e-01) 
2023-05-25 00:12:36.806676: train Epoch: [1][140/193]	Time  1.123 ( 1.424)	Data  0.001 ( 0.301)	Loss 2.3585e-01 (2.9239e-01) 
2023-05-25 00:12:38.197276: train Epoch: [1][141/193]	Time  1.391 ( 1.424)	Data  0.390 ( 0.302)	Loss 2.6782e-01 (2.9222e-01) 
2023-05-25 00:12:39.220877: train Epoch: [1][142/193]	Time  1.024 ( 1.421)	Data  0.010 ( 0.300)	Loss 3.3039e-01 (2.9248e-01) 
2023-05-25 00:12:41.118747: train Epoch: [1][143/193]	Time  1.898 ( 1.424)	Data  0.601 ( 0.302)	Loss 2.3058e-01 (2.9205e-01) 
2023-05-25 00:12:42.179356: train Epoch: [1][144/193]	Time  1.061 ( 1.422)	Data  0.001 ( 0.300)	Loss 2.2922e-01 (2.9162e-01) 
2023-05-25 00:12:43.761760: train Epoch: [1][145/193]	Time  1.582 ( 1.423)	Data  0.266 ( 0.299)	Loss 2.4095e-01 (2.9127e-01) 
2023-05-25 00:12:44.962130: train Epoch: [1][146/193]	Time  1.200 ( 1.422)	Data  0.131 ( 0.298)	Loss 3.2282e-01 (2.9149e-01) 
2023-05-25 00:12:46.201740: train Epoch: [1][147/193]	Time  1.240 ( 1.420)	Data  0.148 ( 0.297)	Loss 2.3896e-01 (2.9113e-01) 
2023-05-25 00:12:47.856946: train Epoch: [1][148/193]	Time  1.655 ( 1.422)	Data  0.517 ( 0.299)	Loss 2.3411e-01 (2.9075e-01) 
2023-05-25 00:12:48.898251: train Epoch: [1][149/193]	Time  1.041 ( 1.419)	Data  0.035 ( 0.297)	Loss 5.3069e-01 (2.9235e-01) 
2023-05-25 00:12:50.633566: train Epoch: [1][150/193]	Time  1.735 ( 1.421)	Data  0.690 ( 0.300)	Loss 2.5992e-01 (2.9213e-01) 
2023-05-25 00:12:51.748943: train Epoch: [1][151/193]	Time  1.115 ( 1.419)	Data  0.001 ( 0.298)	Loss 3.2382e-01 (2.9234e-01) 
2023-05-25 00:12:53.724521: train Epoch: [1][152/193]	Time  1.976 ( 1.423)	Data  0.696 ( 0.300)	Loss 2.3576e-01 (2.9197e-01) 
2023-05-25 00:12:54.713060: train Epoch: [1][153/193]	Time  0.989 ( 1.420)	Data  0.001 ( 0.298)	Loss 5.1539e-01 (2.9342e-01) 
2023-05-25 00:12:56.701113: train Epoch: [1][154/193]	Time  1.988 ( 1.424)	Data  0.689 ( 0.301)	Loss 1.9274e-01 (2.9277e-01) 
2023-05-25 00:12:57.713432: train Epoch: [1][155/193]	Time  1.012 ( 1.421)	Data  0.001 ( 0.299)	Loss 2.3861e-01 (2.9243e-01) 
2023-05-25 00:12:59.477795: train Epoch: [1][156/193]	Time  1.764 ( 1.423)	Data  0.601 ( 0.301)	Loss 4.8869e-01 (2.9368e-01) 
2023-05-25 00:13:00.527457: train Epoch: [1][157/193]	Time  1.050 ( 1.421)	Data  0.001 ( 0.299)	Loss 1.4233e-01 (2.9272e-01) 
2023-05-25 00:13:02.133071: train Epoch: [1][158/193]	Time  1.606 ( 1.422)	Data  0.546 ( 0.300)	Loss 2.3730e-01 (2.9237e-01) 
2023-05-25 00:13:03.413441: train Epoch: [1][159/193]	Time  1.280 ( 1.421)	Data  0.001 ( 0.299)	Loss 2.8159e-01 (2.9230e-01) 
2023-05-25 00:13:05.002511: train Epoch: [1][160/193]	Time  1.589 ( 1.422)	Data  0.519 ( 0.300)	Loss 4.5183e-01 (2.9329e-01) 
2023-05-25 00:13:06.240458: train Epoch: [1][161/193]	Time  1.238 ( 1.421)	Data  0.001 ( 0.298)	Loss 2.0126e-01 (2.9273e-01) 
2023-05-25 00:13:07.972286: train Epoch: [1][162/193]	Time  1.732 ( 1.423)	Data  0.536 ( 0.300)	Loss 2.0489e-01 (2.9219e-01) 
2023-05-25 00:13:09.150240: train Epoch: [1][163/193]	Time  1.178 ( 1.422)	Data  0.001 ( 0.298)	Loss 2.7775e-01 (2.9210e-01) 
2023-05-25 00:13:10.665027: train Epoch: [1][164/193]	Time  1.515 ( 1.422)	Data  0.424 ( 0.298)	Loss 2.6766e-01 (2.9195e-01) 
2023-05-25 00:13:11.718595: train Epoch: [1][165/193]	Time  1.054 ( 1.420)	Data  0.001 ( 0.297)	Loss 2.2893e-01 (2.9157e-01) 
2023-05-25 00:13:13.310713: train Epoch: [1][166/193]	Time  1.592 ( 1.421)	Data  0.592 ( 0.298)	Loss 3.0056e-01 (2.9162e-01) 
2023-05-25 00:13:14.390030: train Epoch: [1][167/193]	Time  1.079 ( 1.419)	Data  0.001 ( 0.297)	Loss 3.6426e-01 (2.9206e-01) 
2023-05-25 00:13:16.451618: train Epoch: [1][168/193]	Time  2.062 ( 1.423)	Data  0.754 ( 0.299)	Loss 2.2708e-01 (2.9167e-01) 
2023-05-25 00:13:17.444974: train Epoch: [1][169/193]	Time  0.993 ( 1.420)	Data  0.001 ( 0.298)	Loss 2.9885e-01 (2.9171e-01) 
2023-05-25 00:13:19.187634: train Epoch: [1][170/193]	Time  1.743 ( 1.422)	Data  0.480 ( 0.299)	Loss 3.0786e-01 (2.9181e-01) 
2023-05-25 00:13:20.201621: train Epoch: [1][171/193]	Time  1.014 ( 1.420)	Data  0.001 ( 0.297)	Loss 2.9258e-01 (2.9181e-01) 
2023-05-25 00:13:21.876087: train Epoch: [1][172/193]	Time  1.674 ( 1.421)	Data  0.507 ( 0.298)	Loss 3.2083e-01 (2.9198e-01) 
2023-05-25 00:13:22.898497: train Epoch: [1][173/193]	Time  1.022 ( 1.419)	Data  0.001 ( 0.296)	Loss 1.9614e-01 (2.9143e-01) 
2023-05-25 00:13:24.703413: train Epoch: [1][174/193]	Time  1.805 ( 1.421)	Data  0.651 ( 0.299)	Loss 2.3150e-01 (2.9109e-01) 
2023-05-25 00:13:25.656205: train Epoch: [1][175/193]	Time  0.953 ( 1.419)	Data  0.001 ( 0.297)	Loss 3.5402e-01 (2.9145e-01) 
2023-05-25 00:13:27.411569: train Epoch: [1][176/193]	Time  1.755 ( 1.420)	Data  0.688 ( 0.299)	Loss 2.8860e-01 (2.9143e-01) 
2023-05-25 00:13:28.497149: train Epoch: [1][177/193]	Time  1.086 ( 1.419)	Data  0.001 ( 0.297)	Loss 4.0545e-01 (2.9207e-01) 
2023-05-25 00:13:30.100033: train Epoch: [1][178/193]	Time  1.603 ( 1.420)	Data  0.553 ( 0.299)	Loss 1.6994e-01 (2.9139e-01) 
2023-05-25 00:13:31.142935: train Epoch: [1][179/193]	Time  1.043 ( 1.417)	Data  0.001 ( 0.297)	Loss 1.9956e-01 (2.9088e-01) 
2023-05-25 00:13:32.863203: train Epoch: [1][180/193]	Time  1.720 ( 1.419)	Data  0.721 ( 0.299)	Loss 2.4250e-01 (2.9061e-01) 
2023-05-25 00:13:33.953817: train Epoch: [1][181/193]	Time  1.091 ( 1.417)	Data  0.001 ( 0.298)	Loss 2.2328e-01 (2.9024e-01) 
2023-05-25 00:13:35.628243: train Epoch: [1][182/193]	Time  1.674 ( 1.419)	Data  0.689 ( 0.300)	Loss 1.8355e-01 (2.8966e-01) 
2023-05-25 00:13:36.723512: train Epoch: [1][183/193]	Time  1.095 ( 1.417)	Data  0.001 ( 0.298)	Loss 2.4068e-01 (2.8939e-01) 
2023-05-25 00:13:38.766566: train Epoch: [1][184/193]	Time  2.043 ( 1.420)	Data  0.833 ( 0.301)	Loss 2.1655e-01 (2.8900e-01) 
2023-05-25 00:13:39.839310: train Epoch: [1][185/193]	Time  1.073 ( 1.419)	Data  0.001 ( 0.300)	Loss 3.0548e-01 (2.8909e-01) 
2023-05-25 00:13:41.683239: train Epoch: [1][186/193]	Time  1.844 ( 1.421)	Data  0.632 ( 0.301)	Loss 2.4447e-01 (2.8885e-01) 
2023-05-25 00:13:42.667535: train Epoch: [1][187/193]	Time  0.984 ( 1.418)	Data  0.001 ( 0.300)	Loss 3.3130e-01 (2.8907e-01) 
2023-05-25 00:13:44.330616: train Epoch: [1][188/193]	Time  1.663 ( 1.420)	Data  0.628 ( 0.302)	Loss 2.8498e-01 (2.8905e-01) 
2023-05-25 00:13:45.403778: train Epoch: [1][189/193]	Time  1.073 ( 1.418)	Data  0.001 ( 0.300)	Loss 2.3503e-01 (2.8877e-01) 
2023-05-25 00:13:47.365917: train Epoch: [1][190/193]	Time  1.962 ( 1.421)	Data  0.604 ( 0.302)	Loss 3.1669e-01 (2.8891e-01) 
2023-05-25 00:13:48.343815: train Epoch: [1][191/193]	Time  0.978 ( 1.418)	Data  0.001 ( 0.300)	Loss 1.6271e-01 (2.8826e-01) 
2023-05-25 00:13:49.405719: train Epoch: [1][192/193]	Time  1.062 ( 1.417)	Data  0.001 ( 0.298)	Loss 2.2383e-01 (2.8792e-01) 
2023-05-25 00:13:49.468134: Train Epoch done in 273.47237324505113 s 
2023-05-25 00:13:52.588271: val Epoch: [1][ 0/72]	Time  2.170 ( 2.170)	Data  1.652 ( 1.652)	Loss 1.6286e-01 (1.6286e-01) 
2023-05-25 00:13:53.044052: val Epoch: [1][ 1/72]	Time  0.456 ( 1.313)	Data  0.002 ( 0.827)	Loss 3.3154e-01 (2.4720e-01) 
2023-05-25 00:13:53.752138: val Epoch: [1][ 2/72]	Time  0.708 ( 1.111)	Data  0.384 ( 0.680)	Loss 4.2585e-01 (3.0675e-01) 
2023-05-25 00:13:54.192900: val Epoch: [1][ 3/72]	Time  0.441 ( 0.944)	Data  0.007 ( 0.511)	Loss 5.4699e-01 (3.6681e-01) 
2023-05-25 00:13:55.178759: val Epoch: [1][ 4/72]	Time  0.986 ( 0.952)	Data  0.684 ( 0.546)	Loss 1.9356e-01 (3.3216e-01) 
2023-05-25 00:13:55.537579: val Epoch: [1][ 5/72]	Time  0.359 ( 0.853)	Data  0.001 ( 0.455)	Loss 2.0740e-01 (3.1137e-01) 
2023-05-25 00:13:56.581615: val Epoch: [1][ 6/72]	Time  1.044 ( 0.881)	Data  0.683 ( 0.488)	Loss 2.1715e-01 (2.9791e-01) 
2023-05-25 00:13:56.956066: val Epoch: [1][ 7/72]	Time  0.374 ( 0.817)	Data  0.001 ( 0.427)	Loss 1.6444e-01 (2.8122e-01) 
2023-05-25 00:13:58.049044: val Epoch: [1][ 8/72]	Time  1.093 ( 0.848)	Data  0.702 ( 0.457)	Loss 4.5885e-01 (3.0096e-01) 
2023-05-25 00:13:58.374121: val Epoch: [1][ 9/72]	Time  0.325 ( 0.796)	Data  0.001 ( 0.412)	Loss 1.7224e-01 (2.8809e-01) 
2023-05-25 00:13:59.446560: val Epoch: [1][10/72]	Time  1.072 ( 0.821)	Data  0.732 ( 0.441)	Loss 1.5505e-01 (2.7599e-01) 
2023-05-25 00:13:59.773111: val Epoch: [1][11/72]	Time  0.327 ( 0.780)	Data  0.001 ( 0.404)	Loss 2.4062e-01 (2.7305e-01) 
2023-05-25 00:14:00.686503: val Epoch: [1][12/72]	Time  0.913 ( 0.790)	Data  0.723 ( 0.429)	Loss 2.2452e-01 (2.6931e-01) 
2023-05-25 00:14:01.089401: val Epoch: [1][13/72]	Time  0.403 ( 0.762)	Data  0.071 ( 0.403)	Loss 3.0140e-01 (2.7160e-01) 
2023-05-25 00:14:02.273838: val Epoch: [1][14/72]	Time  1.184 ( 0.790)	Data  0.810 ( 0.430)	Loss 3.6315e-01 (2.7771e-01) 
2023-05-25 00:14:02.614650: val Epoch: [1][15/72]	Time  0.341 ( 0.762)	Data  0.001 ( 0.403)	Loss 3.3439e-01 (2.8125e-01) 
2023-05-25 00:14:03.876859: val Epoch: [1][16/72]	Time  1.262 ( 0.792)	Data  0.764 ( 0.425)	Loss 3.0587e-01 (2.8270e-01) 
2023-05-25 00:14:04.107518: val Epoch: [1][17/72]	Time  0.231 ( 0.761)	Data  0.001 ( 0.401)	Loss 1.3471e-01 (2.7448e-01) 
2023-05-25 00:14:05.094506: val Epoch: [1][18/72]	Time  0.987 ( 0.772)	Data  0.717 ( 0.418)	Loss 2.7386e-01 (2.7444e-01) 
2023-05-25 00:14:05.405134: val Epoch: [1][19/72]	Time  0.311 ( 0.749)	Data  0.001 ( 0.397)	Loss 3.7246e-01 (2.7935e-01) 
2023-05-25 00:14:06.631538: val Epoch: [1][20/72]	Time  1.226 ( 0.772)	Data  0.860 ( 0.419)	Loss 3.4450e-01 (2.8245e-01) 
2023-05-25 00:14:06.869055: val Epoch: [1][21/72]	Time  0.237 ( 0.748)	Data  0.001 ( 0.400)	Loss 1.7656e-01 (2.7764e-01) 
2023-05-25 00:14:07.916672: val Epoch: [1][22/72]	Time  1.048 ( 0.761)	Data  0.843 ( 0.419)	Loss 3.6791e-01 (2.8156e-01) 
2023-05-25 00:14:08.291293: val Epoch: [1][23/72]	Time  0.375 ( 0.745)	Data  0.043 ( 0.404)	Loss 1.8344e-01 (2.7747e-01) 
2023-05-25 00:14:09.431710: val Epoch: [1][24/72]	Time  1.140 ( 0.761)	Data  0.794 ( 0.419)	Loss 2.2789e-01 (2.7549e-01) 
2023-05-25 00:14:09.688802: val Epoch: [1][25/72]	Time  0.257 ( 0.741)	Data  0.001 ( 0.403)	Loss 2.9309e-01 (2.7617e-01) 
2023-05-25 00:14:10.966231: val Epoch: [1][26/72]	Time  1.277 ( 0.761)	Data  0.848 ( 0.420)	Loss 5.2101e-01 (2.8523e-01) 
2023-05-25 00:14:11.236847: val Epoch: [1][27/72]	Time  0.271 ( 0.744)	Data  0.001 ( 0.405)	Loss 2.2824e-01 (2.8320e-01) 
2023-05-25 00:14:12.573843: val Epoch: [1][28/72]	Time  1.337 ( 0.764)	Data  0.842 ( 0.420)	Loss 3.1887e-01 (2.8443e-01) 
2023-05-25 00:14:12.860047: val Epoch: [1][29/72]	Time  0.286 ( 0.748)	Data  0.001 ( 0.406)	Loss 2.7530e-01 (2.8412e-01) 
2023-05-25 00:14:13.969042: val Epoch: [1][30/72]	Time  1.109 ( 0.760)	Data  0.731 ( 0.416)	Loss 1.4900e-01 (2.7976e-01) 
2023-05-25 00:14:14.334694: val Epoch: [1][31/72]	Time  0.366 ( 0.747)	Data  0.001 ( 0.403)	Loss 1.3866e-01 (2.7536e-01) 
2023-05-25 00:14:15.512927: val Epoch: [1][32/72]	Time  1.178 ( 0.760)	Data  0.713 ( 0.413)	Loss 1.9553e-01 (2.7294e-01) 
2023-05-25 00:14:16.025560: val Epoch: [1][33/72]	Time  0.513 ( 0.753)	Data  0.001 ( 0.401)	Loss 6.0324e-01 (2.8265e-01) 
2023-05-25 00:14:16.879853: val Epoch: [1][34/72]	Time  0.854 ( 0.756)	Data  0.546 ( 0.405)	Loss 1.5919e-01 (2.7912e-01) 
2023-05-25 00:14:17.097781: val Epoch: [1][35/72]	Time  0.218 ( 0.741)	Data  0.001 ( 0.393)	Loss 4.3206e-01 (2.8337e-01) 
2023-05-25 00:14:18.346588: val Epoch: [1][36/72]	Time  1.249 ( 0.755)	Data  0.944 ( 0.408)	Loss 2.0989e-01 (2.8139e-01) 
2023-05-25 00:14:18.758469: val Epoch: [1][37/72]	Time  0.412 ( 0.746)	Data  0.001 ( 0.398)	Loss 1.9209e-01 (2.7904e-01) 
2023-05-25 00:14:19.918478: val Epoch: [1][38/72]	Time  1.160 ( 0.756)	Data  0.743 ( 0.406)	Loss 2.0911e-01 (2.7724e-01) 
2023-05-25 00:14:20.096454: val Epoch: [1][39/72]	Time  0.178 ( 0.742)	Data  0.001 ( 0.396)	Loss 1.6245e-01 (2.7437e-01) 
2023-05-25 00:14:21.256414: val Epoch: [1][40/72]	Time  1.160 ( 0.752)	Data  0.796 ( 0.406)	Loss 1.6393e-01 (2.7168e-01) 
2023-05-25 00:14:21.676915: val Epoch: [1][41/72]	Time  0.420 ( 0.744)	Data  0.001 ( 0.396)	Loss 2.1218e-01 (2.7026e-01) 
2023-05-25 00:14:22.802760: val Epoch: [1][42/72]	Time  1.126 ( 0.753)	Data  0.679 ( 0.403)	Loss 2.4373e-01 (2.6965e-01) 
2023-05-25 00:14:23.148720: val Epoch: [1][43/72]	Time  0.346 ( 0.744)	Data  0.001 ( 0.394)	Loss 1.6486e-01 (2.6726e-01) 
2023-05-25 00:14:24.091965: val Epoch: [1][44/72]	Time  0.943 ( 0.748)	Data  0.667 ( 0.400)	Loss 6.1849e-01 (2.7507e-01) 
2023-05-25 00:14:24.355469: val Epoch: [1][45/72]	Time  0.263 ( 0.738)	Data  0.001 ( 0.391)	Loss 6.6447e-01 (2.8353e-01) 
2023-05-25 00:14:25.785831: val Epoch: [1][46/72]	Time  1.430 ( 0.753)	Data  0.956 ( 0.403)	Loss 2.4686e-01 (2.8275e-01) 
2023-05-25 00:14:26.159901: val Epoch: [1][47/72]	Time  0.374 ( 0.745)	Data  0.001 ( 0.395)	Loss 1.4702e-01 (2.7993e-01) 
2023-05-25 00:14:27.214335: val Epoch: [1][48/72]	Time  1.054 ( 0.751)	Data  0.615 ( 0.399)	Loss 4.7539e-01 (2.8392e-01) 
2023-05-25 00:14:27.508883: val Epoch: [1][49/72]	Time  0.295 ( 0.742)	Data  0.001 ( 0.391)	Loss 6.9064e-01 (2.9205e-01) 
2023-05-25 00:14:28.657162: val Epoch: [1][50/72]	Time  1.148 ( 0.750)	Data  0.659 ( 0.397)	Loss 4.6942e-01 (2.9553e-01) 
2023-05-25 00:14:29.202115: val Epoch: [1][51/72]	Time  0.545 ( 0.746)	Data  0.001 ( 0.389)	Loss 1.6748e-01 (2.9306e-01) 
2023-05-25 00:14:29.737523: val Epoch: [1][52/72]	Time  0.535 ( 0.742)	Data  0.300 ( 0.387)	Loss 1.4664e-01 (2.9030e-01) 
2023-05-25 00:14:30.122902: val Epoch: [1][53/72]	Time  0.385 ( 0.735)	Data  0.028 ( 0.381)	Loss 1.7828e-01 (2.8823e-01) 
2023-05-25 00:14:31.313076: val Epoch: [1][54/72]	Time  1.190 ( 0.744)	Data  0.754 ( 0.388)	Loss 3.0964e-01 (2.8862e-01) 
2023-05-25 00:14:31.567278: val Epoch: [1][55/72]	Time  0.254 ( 0.735)	Data  0.001 ( 0.381)	Loss 1.7482e-01 (2.8658e-01) 
2023-05-25 00:14:32.569441: val Epoch: [1][56/72]	Time  1.002 ( 0.739)	Data  0.702 ( 0.386)	Loss 1.4268e-01 (2.8406e-01) 
2023-05-25 00:14:32.869233: val Epoch: [1][57/72]	Time  0.300 ( 0.732)	Data  0.001 ( 0.380)	Loss 1.5879e-01 (2.8190e-01) 
2023-05-25 00:14:34.066717: val Epoch: [1][58/72]	Time  1.197 ( 0.740)	Data  0.830 ( 0.387)	Loss 1.4655e-01 (2.7961e-01) 
2023-05-25 00:14:34.487879: val Epoch: [1][59/72]	Time  0.421 ( 0.734)	Data  0.001 ( 0.381)	Loss 3.8298e-01 (2.8133e-01) 
2023-05-25 00:14:35.437544: val Epoch: [1][60/72]	Time  0.950 ( 0.738)	Data  0.672 ( 0.386)	Loss 2.9661e-01 (2.8158e-01) 
2023-05-25 00:14:35.973570: val Epoch: [1][61/72]	Time  0.536 ( 0.735)	Data  0.049 ( 0.380)	Loss 6.4495e-01 (2.8744e-01) 
2023-05-25 00:14:36.956214: val Epoch: [1][62/72]	Time  0.983 ( 0.739)	Data  0.654 ( 0.384)	Loss 4.6921e-01 (2.9033e-01) 
2023-05-25 00:14:37.337017: val Epoch: [1][63/72]	Time  0.381 ( 0.733)	Data  0.001 ( 0.378)	Loss 6.4384e-01 (2.9585e-01) 
2023-05-25 00:14:38.534699: val Epoch: [1][64/72]	Time  1.198 ( 0.740)	Data  0.822 ( 0.385)	Loss 4.4547e-01 (2.9815e-01) 
2023-05-25 00:14:38.749367: val Epoch: [1][65/72]	Time  0.215 ( 0.732)	Data  0.001 ( 0.379)	Loss 2.4313e-01 (2.9732e-01) 
2023-05-25 00:14:39.973089: val Epoch: [1][66/72]	Time  1.224 ( 0.740)	Data  0.864 ( 0.387)	Loss 1.8418e-01 (2.9563e-01) 
2023-05-25 00:14:40.259554: val Epoch: [1][67/72]	Time  0.286 ( 0.733)	Data  0.003 ( 0.381)	Loss 2.3049e-01 (2.9467e-01) 
2023-05-25 00:14:41.584615: val Epoch: [1][68/72]	Time  1.325 ( 0.742)	Data  1.020 ( 0.390)	Loss 2.5027e-01 (2.9403e-01) 
2023-05-25 00:14:41.830890: val Epoch: [1][69/72]	Time  0.246 ( 0.734)	Data  0.001 ( 0.385)	Loss 1.8801e-01 (2.9251e-01) 
2023-05-25 00:14:43.072515: val Epoch: [1][70/72]	Time  1.242 ( 0.742)	Data  0.774 ( 0.390)	Loss 2.5807e-01 (2.9203e-01) 
2023-05-25 00:14:43.339935: val Epoch: [1][71/72]	Time  0.267 ( 0.735)	Data  0.001 ( 0.385)	Loss 4.8319e-01 (2.9468e-01) 
2023-05-25 00:14:43.656106: Epoch 1 :Val : ['ET : 0.516061544418335', 'TC : 0.5488144755363464', 'WT : 0.6933548450469971'] 
2023-05-25 00:14:43.659238: Epoch 1 :Val : ['ET : 0.516061544418335', 'TC : 0.5488144755363464', 'WT : 0.6933548450469971'] 
2023-05-25 00:14:43.662987: Saving the model with DSC 0.5762094855308533 
2023-05-25 00:14:44.832239: Val epoch done in 55.364097439916804 s 
2023-05-25 00:14:44.838371: Batches per epoch:  193 
2023-05-25 00:14:49.291049: train Epoch: [2][  0/193]	Time  4.452 ( 4.452)	Data  3.056 ( 3.056)	Loss 2.3430e-01 (2.3430e-01) 
2023-05-25 00:14:50.333341: train Epoch: [2][  1/193]	Time  1.042 ( 2.747)	Data  0.001 ( 1.528)	Loss 2.1551e-01 (2.2490e-01) 
2023-05-25 00:14:51.583823: train Epoch: [2][  2/193]	Time  1.251 ( 2.248)	Data  0.190 ( 1.082)	Loss 1.2700e-01 (1.9227e-01) 
2023-05-25 00:14:52.739648: train Epoch: [2][  3/193]	Time  1.156 ( 1.975)	Data  0.001 ( 0.812)	Loss 1.9619e-01 (1.9325e-01) 
2023-05-25 00:14:54.367289: train Epoch: [2][  4/193]	Time  1.628 ( 1.906)	Data  0.550 ( 0.760)	Loss 3.7519e-01 (2.2964e-01) 
2023-05-25 00:14:55.578153: train Epoch: [2][  5/193]	Time  1.211 ( 1.790)	Data  0.001 ( 0.633)	Loss 2.1682e-01 (2.2750e-01) 
2023-05-25 00:14:57.156621: train Epoch: [2][  6/193]	Time  1.578 ( 1.760)	Data  0.391 ( 0.599)	Loss 1.9410e-01 (2.2273e-01) 
2023-05-25 00:14:58.263592: train Epoch: [2][  7/193]	Time  1.107 ( 1.678)	Data  0.001 ( 0.524)	Loss 1.9148e-01 (2.1882e-01) 
2023-05-25 00:14:59.694609: train Epoch: [2][  8/193]	Time  1.431 ( 1.651)	Data  0.413 ( 0.512)	Loss 2.3059e-01 (2.2013e-01) 
2023-05-25 00:15:00.775809: train Epoch: [2][  9/193]	Time  1.081 ( 1.594)	Data  0.001 ( 0.461)	Loss 3.1677e-01 (2.2980e-01) 
2023-05-25 00:15:02.733622: train Epoch: [2][ 10/193]	Time  1.958 ( 1.627)	Data  0.648 ( 0.478)	Loss 2.2085e-01 (2.2898e-01) 
2023-05-25 00:15:03.716934: train Epoch: [2][ 11/193]	Time  0.983 ( 1.573)	Data  0.001 ( 0.438)	Loss 2.5074e-01 (2.3080e-01) 
2023-05-25 00:15:05.498380: train Epoch: [2][ 12/193]	Time  1.781 ( 1.589)	Data  0.468 ( 0.440)	Loss 3.5779e-01 (2.4056e-01) 
2023-05-25 00:15:06.603124: train Epoch: [2][ 13/193]	Time  1.105 ( 1.555)	Data  0.001 ( 0.409)	Loss 2.3746e-01 (2.4034e-01) 
2023-05-25 00:15:08.129980: train Epoch: [2][ 14/193]	Time  1.527 ( 1.553)	Data  0.347 ( 0.405)	Loss 2.9405e-01 (2.4392e-01) 
2023-05-25 00:15:09.170460: train Epoch: [2][ 15/193]	Time  1.040 ( 1.521)	Data  0.001 ( 0.379)	Loss 2.9479e-01 (2.4710e-01) 
2023-05-25 00:15:11.021010: train Epoch: [2][ 16/193]	Time  1.851 ( 1.540)	Data  0.529 ( 0.388)	Loss 3.4711e-01 (2.5298e-01) 
2023-05-25 00:15:12.056978: train Epoch: [2][ 17/193]	Time  1.036 ( 1.512)	Data  0.001 ( 0.367)	Loss 3.7327e-01 (2.5967e-01) 
2023-05-25 00:15:13.966726: train Epoch: [2][ 18/193]	Time  1.910 ( 1.533)	Data  0.554 ( 0.377)	Loss 3.2453e-01 (2.6308e-01) 
2023-05-25 00:15:15.098378: train Epoch: [2][ 19/193]	Time  1.132 ( 1.513)	Data  0.001 ( 0.358)	Loss 1.7207e-01 (2.5853e-01) 
2023-05-25 00:15:16.416706: train Epoch: [2][ 20/193]	Time  1.318 ( 1.504)	Data  0.350 ( 0.357)	Loss 2.4683e-01 (2.5797e-01) 
2023-05-25 00:15:17.808464: train Epoch: [2][ 21/193]	Time  1.392 ( 1.499)	Data  0.049 ( 0.343)	Loss 3.1386e-01 (2.6051e-01) 
2023-05-25 00:15:19.301972: train Epoch: [2][ 22/193]	Time  1.494 ( 1.498)	Data  0.473 ( 0.349)	Loss 2.0422e-01 (2.5807e-01) 
2023-05-25 00:15:20.331449: train Epoch: [2][ 23/193]	Time  1.029 ( 1.479)	Data  0.001 ( 0.335)	Loss 2.4337e-01 (2.5745e-01) 
2023-05-25 00:15:22.052227: train Epoch: [2][ 24/193]	Time  1.721 ( 1.489)	Data  0.685 ( 0.349)	Loss 2.5668e-01 (2.5742e-01) 
2023-05-25 00:15:23.125273: train Epoch: [2][ 25/193]	Time  1.073 ( 1.473)	Data  0.002 ( 0.335)	Loss 3.7546e-01 (2.6196e-01) 
2023-05-25 00:15:24.810214: train Epoch: [2][ 26/193]	Time  1.685 ( 1.480)	Data  0.714 ( 0.349)	Loss 4.0154e-01 (2.6713e-01) 
2023-05-25 00:15:25.926501: train Epoch: [2][ 27/193]	Time  1.116 ( 1.467)	Data  0.003 ( 0.337)	Loss 2.0615e-01 (2.6495e-01) 
2023-05-25 00:15:27.506666: train Epoch: [2][ 28/193]	Time  1.580 ( 1.471)	Data  0.615 ( 0.346)	Loss 2.9390e-01 (2.6595e-01) 
2023-05-25 00:15:28.587296: train Epoch: [2][ 29/193]	Time  1.081 ( 1.458)	Data  0.093 ( 0.338)	Loss 2.0791e-01 (2.6402e-01) 
2023-05-25 00:15:30.583175: train Epoch: [2][ 30/193]	Time  1.996 ( 1.476)	Data  0.711 ( 0.350)	Loss 5.6045e-01 (2.7358e-01) 
2023-05-25 00:15:31.654219: train Epoch: [2][ 31/193]	Time  1.071 ( 1.463)	Data  0.001 ( 0.339)	Loss 2.6029e-01 (2.7316e-01) 
2023-05-25 00:15:33.374698: train Epoch: [2][ 32/193]	Time  1.720 ( 1.471)	Data  0.344 ( 0.339)	Loss 2.7597e-01 (2.7325e-01) 
2023-05-25 00:15:34.519768: train Epoch: [2][ 33/193]	Time  1.145 ( 1.461)	Data  0.001 ( 0.329)	Loss 2.0518e-01 (2.7125e-01) 
2023-05-25 00:15:36.089216: train Epoch: [2][ 34/193]	Time  1.569 ( 1.464)	Data  0.424 ( 0.332)	Loss 2.7212e-01 (2.7127e-01) 
2023-05-25 00:15:37.378803: train Epoch: [2][ 35/193]	Time  1.290 ( 1.459)	Data  0.001 ( 0.323)	Loss 1.4481e-01 (2.6776e-01) 
2023-05-25 00:15:38.771673: train Epoch: [2][ 36/193]	Time  1.393 ( 1.458)	Data  0.274 ( 0.322)	Loss 1.8143e-01 (2.6543e-01) 
2023-05-25 00:15:40.108273: train Epoch: [2][ 37/193]	Time  1.337 ( 1.454)	Data  0.057 ( 0.315)	Loss 1.8483e-01 (2.6331e-01) 
2023-05-25 00:15:41.447367: train Epoch: [2][ 38/193]	Time  1.339 ( 1.451)	Data  0.362 ( 0.316)	Loss 2.5296e-01 (2.6304e-01) 
2023-05-25 00:15:42.817167: train Epoch: [2][ 39/193]	Time  1.370 ( 1.449)	Data  0.131 ( 0.311)	Loss 4.8668e-01 (2.6863e-01) 
2023-05-25 00:15:44.470730: train Epoch: [2][ 40/193]	Time  1.654 ( 1.454)	Data  0.456 ( 0.315)	Loss 4.6088e-01 (2.7332e-01) 
2023-05-25 00:15:45.660973: train Epoch: [2][ 41/193]	Time  1.190 ( 1.448)	Data  0.001 ( 0.307)	Loss 3.8206e-01 (2.7591e-01) 
2023-05-25 00:15:47.075037: train Epoch: [2][ 42/193]	Time  1.414 ( 1.447)	Data  0.414 ( 0.310)	Loss 2.4950e-01 (2.7530e-01) 
2023-05-25 00:15:48.184371: train Epoch: [2][ 43/193]	Time  1.109 ( 1.440)	Data  0.127 ( 0.306)	Loss 2.9654e-01 (2.7578e-01) 
2023-05-25 00:15:49.859527: train Epoch: [2][ 44/193]	Time  1.675 ( 1.445)	Data  0.671 ( 0.314)	Loss 1.8317e-01 (2.7372e-01) 
2023-05-25 00:15:50.953855: train Epoch: [2][ 45/193]	Time  1.094 ( 1.437)	Data  0.107 ( 0.309)	Loss 4.6414e-01 (2.7786e-01) 
2023-05-25 00:15:52.592532: train Epoch: [2][ 46/193]	Time  1.639 ( 1.442)	Data  0.703 ( 0.318)	Loss 1.6989e-01 (2.7556e-01) 
2023-05-25 00:15:53.820403: train Epoch: [2][ 47/193]	Time  1.228 ( 1.437)	Data  0.145 ( 0.314)	Loss 2.1929e-01 (2.7439e-01) 
2023-05-25 00:15:55.749982: train Epoch: [2][ 48/193]	Time  1.930 ( 1.447)	Data  0.649 ( 0.321)	Loss 1.9326e-01 (2.7273e-01) 
2023-05-25 00:15:56.786224: train Epoch: [2][ 49/193]	Time  1.036 ( 1.439)	Data  0.001 ( 0.314)	Loss 2.1163e-01 (2.7151e-01) 
2023-05-25 00:15:58.736584: train Epoch: [2][ 50/193]	Time  1.950 ( 1.449)	Data  0.568 ( 0.319)	Loss 1.8634e-01 (2.6984e-01) 
2023-05-25 00:15:59.807458: train Epoch: [2][ 51/193]	Time  1.071 ( 1.442)	Data  0.001 ( 0.313)	Loss 3.7994e-01 (2.7196e-01) 
2023-05-25 00:16:01.122690: train Epoch: [2][ 52/193]	Time  1.315 ( 1.439)	Data  0.272 ( 0.313)	Loss 2.9967e-01 (2.7248e-01) 
2023-05-25 00:16:02.249568: train Epoch: [2][ 53/193]	Time  1.127 ( 1.434)	Data  0.001 ( 0.307)	Loss 4.1306e-01 (2.7509e-01) 
2023-05-25 00:16:03.964777: train Epoch: [2][ 54/193]	Time  1.715 ( 1.439)	Data  0.634 ( 0.313)	Loss 1.5652e-01 (2.7293e-01) 
2023-05-25 00:16:05.104678: train Epoch: [2][ 55/193]	Time  1.140 ( 1.433)	Data  0.001 ( 0.307)	Loss 2.2919e-01 (2.7215e-01) 
2023-05-25 00:16:06.690529: train Epoch: [2][ 56/193]	Time  1.586 ( 1.436)	Data  0.532 ( 0.311)	Loss 1.3297e-01 (2.6971e-01) 
2023-05-25 00:16:07.912677: train Epoch: [2][ 57/193]	Time  1.222 ( 1.432)	Data  0.001 ( 0.306)	Loss 2.3638e-01 (2.6913e-01) 
2023-05-25 00:16:09.463547: train Epoch: [2][ 58/193]	Time  1.551 ( 1.434)	Data  0.532 ( 0.310)	Loss 3.7382e-01 (2.7091e-01) 
2023-05-25 00:16:10.794000: train Epoch: [2][ 59/193]	Time  1.330 ( 1.433)	Data  0.207 ( 0.308)	Loss 3.1594e-01 (2.7166e-01) 
2023-05-25 00:16:12.326594: train Epoch: [2][ 60/193]	Time  1.533 ( 1.434)	Data  0.513 ( 0.311)	Loss 1.8054e-01 (2.7016e-01) 
2023-05-25 00:16:13.504724: train Epoch: [2][ 61/193]	Time  1.178 ( 1.430)	Data  0.198 ( 0.309)	Loss 3.5505e-01 (2.7153e-01) 
2023-05-25 00:16:15.302720: train Epoch: [2][ 62/193]	Time  1.798 ( 1.436)	Data  0.590 ( 0.314)	Loss 4.2135e-01 (2.7391e-01) 
2023-05-25 00:16:16.353717: train Epoch: [2][ 63/193]	Time  1.051 ( 1.430)	Data  0.001 ( 0.309)	Loss 3.4527e-01 (2.7503e-01) 
2023-05-25 00:16:18.096940: train Epoch: [2][ 64/193]	Time  1.743 ( 1.435)	Data  0.444 ( 0.311)	Loss 1.6681e-01 (2.7336e-01) 
2023-05-25 00:16:19.273799: train Epoch: [2][ 65/193]	Time  1.177 ( 1.431)	Data  0.099 ( 0.308)	Loss 1.8876e-01 (2.7208e-01) 
2023-05-25 00:16:20.855697: train Epoch: [2][ 66/193]	Time  1.582 ( 1.433)	Data  0.255 ( 0.307)	Loss 1.4117e-01 (2.7013e-01) 
2023-05-25 00:16:21.986634: train Epoch: [2][ 67/193]	Time  1.131 ( 1.429)	Data  0.134 ( 0.304)	Loss 1.6820e-01 (2.6863e-01) 
2023-05-25 00:16:23.192653: train Epoch: [2][ 68/193]	Time  1.206 ( 1.425)	Data  0.195 ( 0.303)	Loss 1.6883e-01 (2.6718e-01) 
2023-05-25 00:16:25.064730: train Epoch: [2][ 69/193]	Time  1.872 ( 1.432)	Data  0.688 ( 0.308)	Loss 1.0066e-01 (2.6480e-01) 
2023-05-25 00:16:26.213776: train Epoch: [2][ 70/193]	Time  1.149 ( 1.428)	Data  0.001 ( 0.304)	Loss 1.8066e-01 (2.6362e-01) 
2023-05-25 00:16:27.973371: train Epoch: [2][ 71/193]	Time  1.760 ( 1.432)	Data  0.554 ( 0.308)	Loss 2.3753e-01 (2.6325e-01) 
2023-05-25 00:16:29.001740: train Epoch: [2][ 72/193]	Time  1.028 ( 1.427)	Data  0.001 ( 0.303)	Loss 2.0138e-01 (2.6241e-01) 
2023-05-25 00:16:30.908763: train Epoch: [2][ 73/193]	Time  1.907 ( 1.433)	Data  0.593 ( 0.307)	Loss 1.9511e-01 (2.6150e-01) 
2023-05-25 00:16:31.979721: train Epoch: [2][ 74/193]	Time  1.071 ( 1.429)	Data  0.001 ( 0.303)	Loss 1.2192e-01 (2.5964e-01) 
2023-05-25 00:16:33.874865: train Epoch: [2][ 75/193]	Time  1.895 ( 1.435)	Data  0.589 ( 0.307)	Loss 1.6263e-01 (2.5836e-01) 
2023-05-25 00:16:34.842585: train Epoch: [2][ 76/193]	Time  0.968 ( 1.429)	Data  0.001 ( 0.303)	Loss 2.0132e-01 (2.5762e-01) 
2023-05-25 00:16:36.476366: train Epoch: [2][ 77/193]	Time  1.634 ( 1.431)	Data  0.683 ( 0.308)	Loss 1.6858e-01 (2.5648e-01) 
2023-05-25 00:16:37.451859: train Epoch: [2][ 78/193]	Time  0.976 ( 1.425)	Data  0.001 ( 0.304)	Loss 1.8764e-01 (2.5561e-01) 
2023-05-25 00:16:39.634696: train Epoch: [2][ 79/193]	Time  2.183 ( 1.435)	Data  1.115 ( 0.314)	Loss 1.8569e-01 (2.5473e-01) 
2023-05-25 00:16:40.654460: train Epoch: [2][ 80/193]	Time  1.020 ( 1.430)	Data  0.001 ( 0.310)	Loss 1.9739e-01 (2.5402e-01) 
2023-05-25 00:16:42.740646: train Epoch: [2][ 81/193]	Time  2.086 ( 1.438)	Data  0.856 ( 0.317)	Loss 5.8198e-01 (2.5802e-01) 
2023-05-25 00:16:43.753824: train Epoch: [2][ 82/193]	Time  1.013 ( 1.433)	Data  0.001 ( 0.313)	Loss 2.9802e-01 (2.5851e-01) 
2023-05-25 00:16:45.324873: train Epoch: [2][ 83/193]	Time  1.571 ( 1.434)	Data  0.486 ( 0.315)	Loss 1.8992e-01 (2.5769e-01) 
2023-05-25 00:16:46.299401: train Epoch: [2][ 84/193]	Time  0.974 ( 1.429)	Data  0.001 ( 0.311)	Loss 2.1859e-01 (2.5723e-01) 
2023-05-25 00:16:48.040677: train Epoch: [2][ 85/193]	Time  1.741 ( 1.433)	Data  0.714 ( 0.316)	Loss 1.5518e-01 (2.5604e-01) 
2023-05-25 00:16:49.231966: train Epoch: [2][ 86/193]	Time  1.191 ( 1.430)	Data  0.001 ( 0.312)	Loss 2.4463e-01 (2.5591e-01) 
2023-05-25 00:16:50.939321: train Epoch: [2][ 87/193]	Time  1.707 ( 1.433)	Data  0.587 ( 0.316)	Loss 2.0070e-01 (2.5528e-01) 
2023-05-25 00:16:51.973544: train Epoch: [2][ 88/193]	Time  1.034 ( 1.428)	Data  0.001 ( 0.312)	Loss 1.5896e-01 (2.5420e-01) 
2023-05-25 00:16:53.662695: train Epoch: [2][ 89/193]	Time  1.689 ( 1.431)	Data  0.579 ( 0.315)	Loss 1.1095e-01 (2.5261e-01) 
2023-05-25 00:16:54.735178: train Epoch: [2][ 90/193]	Time  1.072 ( 1.427)	Data  0.001 ( 0.312)	Loss 2.0904e-01 (2.5213e-01) 
2023-05-25 00:16:56.412449: train Epoch: [2][ 91/193]	Time  1.677 ( 1.430)	Data  0.589 ( 0.315)	Loss 1.3964e-01 (2.5091e-01) 
2023-05-25 00:16:57.525312: train Epoch: [2][ 92/193]	Time  1.113 ( 1.427)	Data  0.001 ( 0.311)	Loss 1.1089e-01 (2.4940e-01) 
2023-05-25 00:16:59.216116: train Epoch: [2][ 93/193]	Time  1.691 ( 1.430)	Data  0.598 ( 0.314)	Loss 4.1399e-01 (2.5115e-01) 
2023-05-25 00:17:00.198016: train Epoch: [2][ 94/193]	Time  0.982 ( 1.425)	Data  0.001 ( 0.311)	Loss 1.4934e-01 (2.5008e-01) 
2023-05-25 00:17:02.395496: train Epoch: [2][ 95/193]	Time  2.197 ( 1.433)	Data  0.745 ( 0.316)	Loss 2.3392e-01 (2.4991e-01) 
2023-05-25 00:17:03.430252: train Epoch: [2][ 96/193]	Time  1.035 ( 1.429)	Data  0.001 ( 0.312)	Loss 6.7208e-01 (2.5427e-01) 
2023-05-25 00:17:05.219272: train Epoch: [2][ 97/193]	Time  1.789 ( 1.432)	Data  0.458 ( 0.314)	Loss 1.9768e-01 (2.5369e-01) 
2023-05-25 00:17:06.186649: train Epoch: [2][ 98/193]	Time  0.967 ( 1.428)	Data  0.001 ( 0.311)	Loss 2.7372e-01 (2.5389e-01) 
2023-05-25 00:17:07.927811: train Epoch: [2][ 99/193]	Time  1.741 ( 1.431)	Data  0.538 ( 0.313)	Loss 2.0647e-01 (2.5342e-01) 
2023-05-25 00:17:08.905432: train Epoch: [2][100/193]	Time  0.978 ( 1.426)	Data  0.002 ( 0.310)	Loss 1.9812e-01 (2.5287e-01) 
2023-05-25 00:17:10.549602: train Epoch: [2][101/193]	Time  1.644 ( 1.429)	Data  0.647 ( 0.313)	Loss 4.0395e-01 (2.5435e-01) 
2023-05-25 00:17:11.739764: train Epoch: [2][102/193]	Time  1.190 ( 1.426)	Data  0.001 ( 0.310)	Loss 2.3150e-01 (2.5413e-01) 
2023-05-25 00:17:13.370414: train Epoch: [2][103/193]	Time  1.631 ( 1.428)	Data  0.492 ( 0.312)	Loss 1.9104e-01 (2.5352e-01) 
2023-05-25 00:17:14.427243: train Epoch: [2][104/193]	Time  1.057 ( 1.425)	Data  0.001 ( 0.309)	Loss 4.7200e-01 (2.5560e-01) 
2023-05-25 00:17:15.950971: train Epoch: [2][105/193]	Time  1.524 ( 1.426)	Data  0.540 ( 0.311)	Loss 2.9209e-01 (2.5595e-01) 
2023-05-25 00:17:17.042017: train Epoch: [2][106/193]	Time  1.091 ( 1.422)	Data  0.002 ( 0.308)	Loss 2.9172e-01 (2.5628e-01) 
2023-05-25 00:17:19.059938: train Epoch: [2][107/193]	Time  2.018 ( 1.428)	Data  0.687 ( 0.312)	Loss 2.2168e-01 (2.5596e-01) 
2023-05-25 00:17:20.045224: train Epoch: [2][108/193]	Time  0.985 ( 1.424)	Data  0.002 ( 0.309)	Loss 1.4606e-01 (2.5495e-01) 
2023-05-25 00:17:21.606982: train Epoch: [2][109/193]	Time  1.562 ( 1.425)	Data  0.437 ( 0.310)	Loss 1.4752e-01 (2.5398e-01) 
2023-05-25 00:17:22.797462: train Epoch: [2][110/193]	Time  1.190 ( 1.423)	Data  0.001 ( 0.307)	Loss 1.9578e-01 (2.5345e-01) 
2023-05-25 00:17:24.662974: train Epoch: [2][111/193]	Time  1.865 ( 1.427)	Data  0.559 ( 0.309)	Loss 1.4363e-01 (2.5247e-01) 
2023-05-25 00:17:25.711744: train Epoch: [2][112/193]	Time  1.049 ( 1.424)	Data  0.001 ( 0.307)	Loss 1.3503e-01 (2.5143e-01) 
2023-05-25 00:17:27.456154: train Epoch: [2][113/193]	Time  1.744 ( 1.426)	Data  0.495 ( 0.308)	Loss 1.6536e-01 (2.5068e-01) 
2023-05-25 00:17:28.539861: train Epoch: [2][114/193]	Time  1.084 ( 1.423)	Data  0.001 ( 0.306)	Loss 1.8162e-01 (2.5008e-01) 
2023-05-25 00:17:30.108269: train Epoch: [2][115/193]	Time  1.568 ( 1.425)	Data  0.469 ( 0.307)	Loss 1.5517e-01 (2.4926e-01) 
2023-05-25 00:17:31.230829: train Epoch: [2][116/193]	Time  1.123 ( 1.422)	Data  0.001 ( 0.304)	Loss 1.2638e-01 (2.4821e-01) 
2023-05-25 00:17:33.118939: train Epoch: [2][117/193]	Time  1.888 ( 1.426)	Data  0.695 ( 0.308)	Loss 1.4015e-01 (2.4729e-01) 
2023-05-25 00:17:34.373078: train Epoch: [2][118/193]	Time  1.254 ( 1.425)	Data  0.001 ( 0.305)	Loss 2.6685e-01 (2.4746e-01) 
2023-05-25 00:17:35.933032: train Epoch: [2][119/193]	Time  1.560 ( 1.426)	Data  0.439 ( 0.306)	Loss 4.6769e-01 (2.4929e-01) 
2023-05-25 00:17:37.118904: train Epoch: [2][120/193]	Time  1.186 ( 1.424)	Data  0.001 ( 0.304)	Loss 1.3726e-01 (2.4837e-01) 
2023-05-25 00:17:38.777744: train Epoch: [2][121/193]	Time  1.659 ( 1.426)	Data  0.533 ( 0.306)	Loss 3.2257e-01 (2.4897e-01) 
2023-05-25 00:17:39.936452: train Epoch: [2][122/193]	Time  1.159 ( 1.424)	Data  0.001 ( 0.303)	Loss 2.5459e-01 (2.4902e-01) 
2023-05-25 00:17:41.572201: train Epoch: [2][123/193]	Time  1.636 ( 1.425)	Data  0.542 ( 0.305)	Loss 2.3093e-01 (2.4887e-01) 
2023-05-25 00:17:42.613270: train Epoch: [2][124/193]	Time  1.041 ( 1.422)	Data  0.001 ( 0.303)	Loss 1.7746e-01 (2.4830e-01) 
2023-05-25 00:17:44.696870: train Epoch: [2][125/193]	Time  2.084 ( 1.427)	Data  0.728 ( 0.306)	Loss 1.9714e-01 (2.4790e-01) 
2023-05-25 00:17:45.740056: train Epoch: [2][126/193]	Time  1.043 ( 1.424)	Data  0.001 ( 0.304)	Loss 1.8254e-01 (2.4738e-01) 
2023-05-25 00:17:47.455127: train Epoch: [2][127/193]	Time  1.715 ( 1.427)	Data  0.426 ( 0.305)	Loss 2.0870e-01 (2.4708e-01) 
2023-05-25 00:17:48.379228: train Epoch: [2][128/193]	Time  0.924 ( 1.423)	Data  0.001 ( 0.302)	Loss 1.4438e-01 (2.4628e-01) 
2023-05-25 00:17:50.300643: train Epoch: [2][129/193]	Time  1.921 ( 1.427)	Data  0.630 ( 0.305)	Loss 2.3095e-01 (2.4617e-01) 
2023-05-25 00:17:51.239324: train Epoch: [2][130/193]	Time  0.939 ( 1.423)	Data  0.001 ( 0.302)	Loss 2.2754e-01 (2.4602e-01) 
2023-05-25 00:17:53.097602: train Epoch: [2][131/193]	Time  1.858 ( 1.426)	Data  0.632 ( 0.305)	Loss 2.9761e-01 (2.4641e-01) 
2023-05-25 00:17:54.112970: train Epoch: [2][132/193]	Time  1.015 ( 1.423)	Data  0.001 ( 0.303)	Loss 1.7895e-01 (2.4591e-01) 
2023-05-25 00:17:55.942824: train Epoch: [2][133/193]	Time  1.830 ( 1.426)	Data  0.619 ( 0.305)	Loss 2.5150e-01 (2.4595e-01) 
2023-05-25 00:17:56.995736: train Epoch: [2][134/193]	Time  1.053 ( 1.423)	Data  0.001 ( 0.303)	Loss 3.0985e-01 (2.4642e-01) 
2023-05-25 00:17:58.673198: train Epoch: [2][135/193]	Time  1.677 ( 1.425)	Data  0.500 ( 0.304)	Loss 2.2453e-01 (2.4626e-01) 
2023-05-25 00:17:59.971816: train Epoch: [2][136/193]	Time  1.299 ( 1.424)	Data  0.001 ( 0.302)	Loss 1.8612e-01 (2.4582e-01) 
2023-05-25 00:18:01.370620: train Epoch: [2][137/193]	Time  1.399 ( 1.424)	Data  0.334 ( 0.302)	Loss 2.2143e-01 (2.4565e-01) 
2023-05-25 00:18:02.398045: train Epoch: [2][138/193]	Time  1.027 ( 1.421)	Data  0.001 ( 0.300)	Loss 2.7137e-01 (2.4583e-01) 
2023-05-25 00:18:04.328221: train Epoch: [2][139/193]	Time  1.930 ( 1.425)	Data  0.780 ( 0.304)	Loss 2.0426e-01 (2.4553e-01) 
2023-05-25 00:18:05.300574: train Epoch: [2][140/193]	Time  0.972 ( 1.422)	Data  0.001 ( 0.301)	Loss 1.7596e-01 (2.4504e-01) 
2023-05-25 00:18:06.934296: train Epoch: [2][141/193]	Time  1.634 ( 1.423)	Data  0.675 ( 0.304)	Loss 1.6228e-01 (2.4446e-01) 
2023-05-25 00:18:07.900639: train Epoch: [2][142/193]	Time  0.966 ( 1.420)	Data  0.001 ( 0.302)	Loss 3.1162e-01 (2.4493e-01) 
2023-05-25 00:18:09.834417: train Epoch: [2][143/193]	Time  1.934 ( 1.424)	Data  0.872 ( 0.306)	Loss 1.4263e-01 (2.4422e-01) 
2023-05-25 00:18:10.806111: train Epoch: [2][144/193]	Time  0.972 ( 1.420)	Data  0.001 ( 0.304)	Loss 3.4468e-01 (2.4491e-01) 
2023-05-25 00:18:12.795944: train Epoch: [2][145/193]	Time  1.990 ( 1.424)	Data  0.794 ( 0.307)	Loss 3.3280e-01 (2.4551e-01) 
2023-05-25 00:18:13.719470: train Epoch: [2][146/193]	Time  0.924 ( 1.421)	Data  0.001 ( 0.305)	Loss 2.1080e-01 (2.4528e-01) 
2023-05-25 00:18:15.634581: train Epoch: [2][147/193]	Time  1.915 ( 1.424)	Data  0.664 ( 0.307)	Loss 1.7598e-01 (2.4481e-01) 
2023-05-25 00:18:16.569918: train Epoch: [2][148/193]	Time  0.935 ( 1.421)	Data  0.001 ( 0.305)	Loss 1.6890e-01 (2.4430e-01) 
2023-05-25 00:18:18.532511: train Epoch: [2][149/193]	Time  1.963 ( 1.425)	Data  0.642 ( 0.308)	Loss 1.9078e-01 (2.4394e-01) 
2023-05-25 00:18:19.559766: train Epoch: [2][150/193]	Time  1.027 ( 1.422)	Data  0.001 ( 0.306)	Loss 1.5655e-01 (2.4336e-01) 
2023-05-25 00:18:21.082905: train Epoch: [2][151/193]	Time  1.523 ( 1.423)	Data  0.509 ( 0.307)	Loss 1.7190e-01 (2.4289e-01) 
2023-05-25 00:18:22.053712: train Epoch: [2][152/193]	Time  0.971 ( 1.420)	Data  0.001 ( 0.305)	Loss 3.6102e-01 (2.4366e-01) 
2023-05-25 00:18:24.214343: train Epoch: [2][153/193]	Time  2.161 ( 1.425)	Data  0.806 ( 0.308)	Loss 1.9278e-01 (2.4333e-01) 
2023-05-25 00:18:25.169204: train Epoch: [2][154/193]	Time  0.955 ( 1.421)	Data  0.001 ( 0.306)	Loss 1.1139e-01 (2.4248e-01) 
2023-05-25 00:18:26.614545: train Epoch: [2][155/193]	Time  1.445 ( 1.422)	Data  0.446 ( 0.307)	Loss 2.7189e-01 (2.4267e-01) 
2023-05-25 00:18:27.757725: train Epoch: [2][156/193]	Time  1.143 ( 1.420)	Data  0.001 ( 0.305)	Loss 1.6400e-01 (2.4217e-01) 
2023-05-25 00:18:29.488755: train Epoch: [2][157/193]	Time  1.731 ( 1.422)	Data  0.663 ( 0.307)	Loss 3.2844e-01 (2.4272e-01) 
2023-05-25 00:18:30.634153: train Epoch: [2][158/193]	Time  1.145 ( 1.420)	Data  0.001 ( 0.306)	Loss 1.9858e-01 (2.4244e-01) 
2023-05-25 00:18:32.350485: train Epoch: [2][159/193]	Time  1.716 ( 1.422)	Data  0.586 ( 0.307)	Loss 2.2262e-01 (2.4231e-01) 
2023-05-25 00:18:33.405304: train Epoch: [2][160/193]	Time  1.055 ( 1.420)	Data  0.001 ( 0.305)	Loss 2.9587e-01 (2.4265e-01) 
2023-05-25 00:18:35.007201: train Epoch: [2][161/193]	Time  1.602 ( 1.421)	Data  0.632 ( 0.307)	Loss 9.9463e-02 (2.4176e-01) 
2023-05-25 00:18:36.003364: train Epoch: [2][162/193]	Time  0.996 ( 1.418)	Data  0.001 ( 0.306)	Loss 1.6893e-01 (2.4132e-01) 
2023-05-25 00:18:37.778173: train Epoch: [2][163/193]	Time  1.775 ( 1.420)	Data  0.806 ( 0.309)	Loss 1.7909e-01 (2.4094e-01) 
2023-05-25 00:18:38.744731: train Epoch: [2][164/193]	Time  0.967 ( 1.418)	Data  0.001 ( 0.307)	Loss 2.7965e-01 (2.4117e-01) 
2023-05-25 00:18:40.491895: train Epoch: [2][165/193]	Time  1.747 ( 1.420)	Data  0.767 ( 0.309)	Loss 1.9405e-01 (2.4089e-01) 
2023-05-25 00:18:41.543461: train Epoch: [2][166/193]	Time  1.052 ( 1.417)	Data  0.001 ( 0.308)	Loss 1.5153e-01 (2.4035e-01) 
2023-05-25 00:18:43.640527: train Epoch: [2][167/193]	Time  2.097 ( 1.421)	Data  0.747 ( 0.310)	Loss 2.2912e-01 (2.4029e-01) 
2023-05-25 00:18:44.778145: train Epoch: [2][168/193]	Time  1.138 ( 1.420)	Data  0.001 ( 0.308)	Loss 4.0466e-01 (2.4126e-01) 
2023-05-25 00:18:46.222351: train Epoch: [2][169/193]	Time  1.444 ( 1.420)	Data  0.342 ( 0.309)	Loss 1.3517e-01 (2.4063e-01) 
2023-05-25 00:18:47.464330: train Epoch: [2][170/193]	Time  1.242 ( 1.419)	Data  0.001 ( 0.307)	Loss 1.3037e-01 (2.3999e-01) 
2023-05-25 00:18:49.148813: train Epoch: [2][171/193]	Time  1.684 ( 1.420)	Data  0.531 ( 0.308)	Loss 2.8739e-01 (2.4026e-01) 
2023-05-25 00:18:50.388984: train Epoch: [2][172/193]	Time  1.240 ( 1.419)	Data  0.001 ( 0.306)	Loss 2.2232e-01 (2.4016e-01) 
2023-05-25 00:18:51.890329: train Epoch: [2][173/193]	Time  1.501 ( 1.420)	Data  0.464 ( 0.307)	Loss 3.5420e-01 (2.4082e-01) 
2023-05-25 00:18:52.935495: train Epoch: [2][174/193]	Time  1.045 ( 1.418)	Data  0.001 ( 0.305)	Loss 1.4032e-01 (2.4024e-01) 
2023-05-25 00:18:55.162918: train Epoch: [2][175/193]	Time  2.227 ( 1.422)	Data  0.886 ( 0.309)	Loss 1.3534e-01 (2.3965e-01) 
2023-05-25 00:18:56.322826: train Epoch: [2][176/193]	Time  1.160 ( 1.421)	Data  0.001 ( 0.307)	Loss 2.4881e-01 (2.3970e-01) 
2023-05-25 00:18:57.996529: train Epoch: [2][177/193]	Time  1.674 ( 1.422)	Data  0.638 ( 0.309)	Loss 1.5843e-01 (2.3924e-01) 
2023-05-25 00:18:59.080930: train Epoch: [2][178/193]	Time  1.084 ( 1.420)	Data  0.001 ( 0.307)	Loss 2.2085e-01 (2.3914e-01) 
2023-05-25 00:19:00.867550: train Epoch: [2][179/193]	Time  1.787 ( 1.422)	Data  0.797 ( 0.310)	Loss 2.3102e-01 (2.3909e-01) 
2023-05-25 00:19:01.940050: train Epoch: [2][180/193]	Time  1.073 ( 1.420)	Data  0.001 ( 0.308)	Loss 2.4825e-01 (2.3914e-01) 
2023-05-25 00:19:03.710738: train Epoch: [2][181/193]	Time  1.771 ( 1.422)	Data  0.749 ( 0.311)	Loss 2.3364e-01 (2.3911e-01) 
2023-05-25 00:19:04.710978: train Epoch: [2][182/193]	Time  1.000 ( 1.420)	Data  0.001 ( 0.309)	Loss 4.7959e-01 (2.4043e-01) 
2023-05-25 00:19:06.652705: train Epoch: [2][183/193]	Time  1.942 ( 1.423)	Data  0.747 ( 0.311)	Loss 2.4443e-01 (2.4045e-01) 
2023-05-25 00:19:07.745231: train Epoch: [2][184/193]	Time  1.093 ( 1.421)	Data  0.001 ( 0.310)	Loss 1.9330e-01 (2.4019e-01) 
2023-05-25 00:19:09.283961: train Epoch: [2][185/193]	Time  1.539 ( 1.422)	Data  0.494 ( 0.311)	Loss 2.3234e-01 (2.4015e-01) 
2023-05-25 00:19:10.247896: train Epoch: [2][186/193]	Time  0.964 ( 1.419)	Data  0.001 ( 0.309)	Loss 4.3259e-01 (2.4118e-01) 
2023-05-25 00:19:12.298586: train Epoch: [2][187/193]	Time  2.051 ( 1.423)	Data  0.770 ( 0.311)	Loss 2.2295e-01 (2.4108e-01) 
2023-05-25 00:19:13.279132: train Epoch: [2][188/193]	Time  0.981 ( 1.420)	Data  0.002 ( 0.310)	Loss 1.9799e-01 (2.4086e-01) 
2023-05-25 00:19:15.225105: train Epoch: [2][189/193]	Time  1.946 ( 1.423)	Data  0.531 ( 0.311)	Loss 1.7052e-01 (2.4049e-01) 
2023-05-25 00:19:16.313401: train Epoch: [2][190/193]	Time  1.088 ( 1.421)	Data  0.001 ( 0.309)	Loss 1.7341e-01 (2.4014e-01) 
2023-05-25 00:19:17.260389: train Epoch: [2][191/193]	Time  0.947 ( 1.419)	Data  0.001 ( 0.308)	Loss 1.9406e-01 (2.3990e-01) 
2023-05-25 00:19:18.424125: train Epoch: [2][192/193]	Time  1.164 ( 1.418)	Data  0.001 ( 0.306)	Loss 1.8831e-01 (2.3963e-01) 
2023-05-25 00:19:18.487128: Train Epoch done in 273.6487998730736 s 
2023-05-25 00:19:21.570342: val Epoch: [2][ 0/72]	Time  2.058 ( 2.058)	Data  1.679 ( 1.679)	Loss 1.3336e-01 (1.3336e-01) 
2023-05-25 00:19:21.881172: val Epoch: [2][ 1/72]	Time  0.311 ( 1.184)	Data  0.002 ( 0.841)	Loss 1.5356e-01 (1.4346e-01) 
2023-05-25 00:19:23.258881: val Epoch: [2][ 2/72]	Time  1.378 ( 1.249)	Data  0.738 ( 0.806)	Loss 1.8777e-01 (1.5823e-01) 
2023-05-25 00:19:23.605668: val Epoch: [2][ 3/72]	Time  0.347 ( 1.023)	Data  0.001 ( 0.605)	Loss 1.2795e-01 (1.5066e-01) 
2023-05-25 00:19:24.335799: val Epoch: [2][ 4/72]	Time  0.730 ( 0.965)	Data  0.453 ( 0.575)	Loss 2.3646e-01 (1.6782e-01) 
2023-05-25 00:19:24.620546: val Epoch: [2][ 5/72]	Time  0.285 ( 0.851)	Data  0.001 ( 0.479)	Loss 6.3179e-01 (2.4515e-01) 
2023-05-25 00:19:25.928118: val Epoch: [2][ 6/72]	Time  1.308 ( 0.917)	Data  0.914 ( 0.541)	Loss 1.5760e-01 (2.3264e-01) 
2023-05-25 00:19:26.393479: val Epoch: [2][ 7/72]	Time  0.465 ( 0.860)	Data  0.001 ( 0.474)	Loss 1.5983e-01 (2.2354e-01) 
2023-05-25 00:19:27.401695: val Epoch: [2][ 8/72]	Time  1.008 ( 0.877)	Data  0.587 ( 0.486)	Loss 1.0706e-01 (2.1060e-01) 
2023-05-25 00:19:27.717120: val Epoch: [2][ 9/72]	Time  0.315 ( 0.820)	Data  0.001 ( 0.438)	Loss 1.2915e-01 (2.0245e-01) 
2023-05-25 00:19:28.937726: val Epoch: [2][10/72]	Time  1.221 ( 0.857)	Data  0.769 ( 0.468)	Loss 3.0394e-01 (2.1168e-01) 
2023-05-25 00:19:29.245445: val Epoch: [2][11/72]	Time  0.308 ( 0.811)	Data  0.001 ( 0.429)	Loss 1.1642e-01 (2.0374e-01) 
2023-05-25 00:19:30.350778: val Epoch: [2][12/72]	Time  1.105 ( 0.834)	Data  0.678 ( 0.448)	Loss 4.6850e-01 (2.2411e-01) 
2023-05-25 00:19:30.772717: val Epoch: [2][13/72]	Time  0.422 ( 0.804)	Data  0.001 ( 0.416)	Loss 1.1498e-01 (2.1631e-01) 
2023-05-25 00:19:31.577837: val Epoch: [2][14/72]	Time  0.805 ( 0.804)	Data  0.568 ( 0.426)	Loss 1.7281e-01 (2.1341e-01) 
2023-05-25 00:19:31.915606: val Epoch: [2][15/72]	Time  0.338 ( 0.775)	Data  0.001 ( 0.400)	Loss 4.6226e-01 (2.2897e-01) 
2023-05-25 00:19:33.120445: val Epoch: [2][16/72]	Time  1.205 ( 0.800)	Data  0.871 ( 0.427)	Loss 6.1163e-01 (2.5147e-01) 
2023-05-25 00:19:33.401786: val Epoch: [2][17/72]	Time  0.281 ( 0.772)	Data  0.001 ( 0.404)	Loss 3.0751e-01 (2.5459e-01) 
2023-05-25 00:19:34.559337: val Epoch: [2][18/72]	Time  1.158 ( 0.792)	Data  0.783 ( 0.424)	Loss 3.2688e-01 (2.5839e-01) 
2023-05-25 00:19:34.764594: val Epoch: [2][19/72]	Time  0.205 ( 0.763)	Data  0.001 ( 0.403)	Loss 3.1756e-01 (2.6135e-01) 
2023-05-25 00:19:35.970637: val Epoch: [2][20/72]	Time  1.206 ( 0.784)	Data  0.792 ( 0.421)	Loss 1.3719e-01 (2.5544e-01) 
2023-05-25 00:19:36.275288: val Epoch: [2][21/72]	Time  0.305 ( 0.762)	Data  0.001 ( 0.402)	Loss 1.4504e-01 (2.5042e-01) 
2023-05-25 00:19:37.322623: val Epoch: [2][22/72]	Time  1.047 ( 0.774)	Data  0.774 ( 0.418)	Loss 4.5656e-01 (2.5938e-01) 
2023-05-25 00:19:37.941920: val Epoch: [2][23/72]	Time  0.619 ( 0.768)	Data  0.001 ( 0.401)	Loss 1.4776e-01 (2.5473e-01) 
2023-05-25 00:19:38.778798: val Epoch: [2][24/72]	Time  0.837 ( 0.771)	Data  0.581 ( 0.408)	Loss 5.1075e-01 (2.6497e-01) 
2023-05-25 00:19:38.974146: val Epoch: [2][25/72]	Time  0.195 ( 0.749)	Data  0.001 ( 0.392)	Loss 1.0113e-01 (2.5867e-01) 
2023-05-25 00:19:40.318180: val Epoch: [2][26/72]	Time  1.344 ( 0.771)	Data  1.023 ( 0.416)	Loss 3.5272e-01 (2.6215e-01) 
2023-05-25 00:19:40.554396: val Epoch: [2][27/72]	Time  0.236 ( 0.751)	Data  0.001 ( 0.401)	Loss 1.7162e-01 (2.5892e-01) 
2023-05-25 00:19:41.873363: val Epoch: [2][28/72]	Time  1.319 ( 0.771)	Data  0.954 ( 0.420)	Loss 1.8200e-01 (2.5627e-01) 
2023-05-25 00:19:42.133620: val Epoch: [2][29/72]	Time  0.260 ( 0.754)	Data  0.000 ( 0.406)	Loss 4.3352e-01 (2.6218e-01) 
2023-05-25 00:19:43.255270: val Epoch: [2][30/72]	Time  1.122 ( 0.766)	Data  0.791 ( 0.418)	Loss 1.3303e-01 (2.5801e-01) 
2023-05-25 00:19:43.875479: val Epoch: [2][31/72]	Time  0.620 ( 0.761)	Data  0.001 ( 0.405)	Loss 4.9048e-01 (2.6528e-01) 
2023-05-25 00:19:44.946236: val Epoch: [2][32/72]	Time  1.071 ( 0.771)	Data  0.568 ( 0.410)	Loss 2.1178e-01 (2.6365e-01) 
2023-05-25 00:19:45.523193: val Epoch: [2][33/72]	Time  0.577 ( 0.765)	Data  0.001 ( 0.398)	Loss 2.6319e-01 (2.6364e-01) 
2023-05-25 00:19:46.053080: val Epoch: [2][34/72]	Time  0.530 ( 0.758)	Data  0.325 ( 0.396)	Loss 1.5262e-01 (2.6047e-01) 
2023-05-25 00:19:46.346130: val Epoch: [2][35/72]	Time  0.293 ( 0.745)	Data  0.001 ( 0.385)	Loss 4.7743e-01 (2.6649e-01) 
2023-05-25 00:19:47.674314: val Epoch: [2][36/72]	Time  1.328 ( 0.761)	Data  0.964 ( 0.401)	Loss 1.0322e-01 (2.6208e-01) 
2023-05-25 00:19:48.128928: val Epoch: [2][37/72]	Time  0.455 ( 0.753)	Data  0.001 ( 0.390)	Loss 4.0758e-01 (2.6591e-01) 
2023-05-25 00:19:49.023164: val Epoch: [2][38/72]	Time  0.894 ( 0.757)	Data  0.577 ( 0.395)	Loss 1.2775e-01 (2.6237e-01) 
2023-05-25 00:19:49.272987: val Epoch: [2][39/72]	Time  0.250 ( 0.744)	Data  0.001 ( 0.385)	Loss 2.5016e-01 (2.6206e-01) 
2023-05-25 00:19:50.621459: val Epoch: [2][40/72]	Time  1.348 ( 0.759)	Data  0.991 ( 0.400)	Loss 1.0841e-01 (2.5832e-01) 
2023-05-25 00:19:51.095612: val Epoch: [2][41/72]	Time  0.474 ( 0.752)	Data  0.001 ( 0.390)	Loss 1.1171e-01 (2.5482e-01) 
2023-05-25 00:19:52.219752: val Epoch: [2][42/72]	Time  1.124 ( 0.761)	Data  0.729 ( 0.398)	Loss 1.4948e-01 (2.5237e-01) 
2023-05-25 00:19:52.440091: val Epoch: [2][43/72]	Time  0.217 ( 0.748)	Data  0.001 ( 0.389)	Loss 3.9829e-01 (2.5569e-01) 
2023-05-25 00:19:53.448440: val Epoch: [2][44/72]	Time  1.011 ( 0.754)	Data  0.690 ( 0.396)	Loss 2.5676e-01 (2.5571e-01) 
2023-05-25 00:19:53.676886: val Epoch: [2][45/72]	Time  0.228 ( 0.743)	Data  0.001 ( 0.387)	Loss 1.5355e-01 (2.5349e-01) 
2023-05-25 00:19:54.896300: val Epoch: [2][46/72]	Time  1.219 ( 0.753)	Data  0.842 ( 0.397)	Loss 3.4179e-01 (2.5537e-01) 
2023-05-25 00:19:55.337547: val Epoch: [2][47/72]	Time  0.441 ( 0.746)	Data  0.001 ( 0.389)	Loss 1.5907e-01 (2.5337e-01) 
2023-05-25 00:19:56.243932: val Epoch: [2][48/72]	Time  0.906 ( 0.750)	Data  0.521 ( 0.392)	Loss 9.6766e-02 (2.5017e-01) 
2023-05-25 00:19:56.466697: val Epoch: [2][49/72]	Time  0.223 ( 0.739)	Data  0.001 ( 0.384)	Loss 6.8474e-01 (2.5886e-01) 
2023-05-25 00:19:57.480898: val Epoch: [2][50/72]	Time  1.014 ( 0.744)	Data  0.750 ( 0.391)	Loss 1.7429e-01 (2.5720e-01) 
2023-05-25 00:19:57.801382: val Epoch: [2][51/72]	Time  0.320 ( 0.736)	Data  0.001 ( 0.383)	Loss 1.7777e-01 (2.5568e-01) 
2023-05-25 00:19:59.197965: val Epoch: [2][52/72]	Time  1.397 ( 0.749)	Data  0.807 ( 0.391)	Loss 1.9249e-01 (2.5448e-01) 
2023-05-25 00:19:59.406441: val Epoch: [2][53/72]	Time  0.208 ( 0.739)	Data  0.001 ( 0.384)	Loss 2.5774e-01 (2.5454e-01) 
2023-05-25 00:20:00.284934: val Epoch: [2][54/72]	Time  0.878 ( 0.741)	Data  0.559 ( 0.387)	Loss 2.2107e-01 (2.5394e-01) 
2023-05-25 00:20:00.488981: val Epoch: [2][55/72]	Time  0.204 ( 0.732)	Data  0.001 ( 0.380)	Loss 1.3971e-01 (2.5190e-01) 
2023-05-25 00:20:01.902263: val Epoch: [2][56/72]	Time  1.413 ( 0.744)	Data  0.951 ( 0.390)	Loss 5.8100e-01 (2.5767e-01) 
2023-05-25 00:20:02.177768: val Epoch: [2][57/72]	Time  0.275 ( 0.736)	Data  0.001 ( 0.384)	Loss 1.5633e-01 (2.5592e-01) 
2023-05-25 00:20:03.136074: val Epoch: [2][58/72]	Time  0.958 ( 0.739)	Data  0.684 ( 0.389)	Loss 2.0734e-01 (2.5510e-01) 
2023-05-25 00:20:03.662233: val Epoch: [2][59/72]	Time  0.526 ( 0.736)	Data  0.001 ( 0.382)	Loss 1.2328e-01 (2.5290e-01) 
2023-05-25 00:20:04.450628: val Epoch: [2][60/72]	Time  0.788 ( 0.737)	Data  0.548 ( 0.385)	Loss 6.1096e-01 (2.5877e-01) 
2023-05-25 00:20:04.751594: val Epoch: [2][61/72]	Time  0.301 ( 0.730)	Data  0.010 ( 0.379)	Loss 2.3626e-01 (2.5841e-01) 
2023-05-25 00:20:05.948635: val Epoch: [2][62/72]	Time  1.197 ( 0.737)	Data  0.827 ( 0.386)	Loss 3.5450e-01 (2.5993e-01) 
2023-05-25 00:20:06.213674: val Epoch: [2][63/72]	Time  0.265 ( 0.730)	Data  0.003 ( 0.380)	Loss 9.9345e-02 (2.5742e-01) 
2023-05-25 00:20:07.156217: val Epoch: [2][64/72]	Time  0.943 ( 0.733)	Data  0.741 ( 0.386)	Loss 1.2625e-01 (2.5541e-01) 
2023-05-25 00:20:07.661678: val Epoch: [2][65/72]	Time  0.505 ( 0.730)	Data  0.180 ( 0.383)	Loss 1.2724e-01 (2.5346e-01) 
2023-05-25 00:20:08.623458: val Epoch: [2][66/72]	Time  0.962 ( 0.733)	Data  0.604 ( 0.386)	Loss 3.0225e-01 (2.5419e-01) 
2023-05-25 00:20:09.120872: val Epoch: [2][67/72]	Time  0.497 ( 0.730)	Data  0.141 ( 0.382)	Loss 1.0531e-01 (2.5200e-01) 
2023-05-25 00:20:10.330491: val Epoch: [2][68/72]	Time  1.210 ( 0.736)	Data  0.639 ( 0.386)	Loss 3.2409e-01 (2.5305e-01) 
2023-05-25 00:20:10.503525: val Epoch: [2][69/72]	Time  0.173 ( 0.728)	Data  0.001 ( 0.381)	Loss 1.5221e-01 (2.5161e-01) 
2023-05-25 00:20:11.579196: val Epoch: [2][70/72]	Time  1.076 ( 0.733)	Data  0.697 ( 0.385)	Loss 4.2471e-01 (2.5405e-01) 
2023-05-25 00:20:11.922557: val Epoch: [2][71/72]	Time  0.343 ( 0.728)	Data  0.044 ( 0.380)	Loss 4.5025e-01 (2.5677e-01) 
2023-05-25 00:20:12.220564: Epoch 2 :Val : ['ET : 0.5313442945480347', 'TC : 0.5609386563301086', 'WT : 0.7453760504722595'] 
2023-05-25 00:20:12.223410: Epoch 2 :Val : ['ET : 0.5313442945480347', 'TC : 0.5609386563301086', 'WT : 0.7453760504722595'] 
2023-05-25 00:20:12.226010: Saving the model with DSC 0.6031620502471924 
2023-05-25 00:20:13.223800: Val epoch done in 54.73666833189782 s 
2023-05-25 00:20:13.230364: Batches per epoch:  193 
2023-05-25 00:20:17.771392: train Epoch: [3][  0/193]	Time  4.541 ( 4.541)	Data  3.287 ( 3.287)	Loss 2.8106e-01 (2.8106e-01) 
2023-05-25 00:20:18.979142: train Epoch: [3][  1/193]	Time  1.208 ( 2.874)	Data  0.002 ( 1.644)	Loss 5.6803e-01 (4.2454e-01) 
2023-05-25 00:20:20.567427: train Epoch: [3][  2/193]	Time  1.588 ( 2.446)	Data  0.405 ( 1.231)	Loss 2.1714e-01 (3.5541e-01) 
2023-05-25 00:20:21.690897: train Epoch: [3][  3/193]	Time  1.123 ( 2.115)	Data  0.001 ( 0.924)	Loss 1.6276e-01 (3.0725e-01) 
2023-05-25 00:20:23.516486: train Epoch: [3][  4/193]	Time  1.826 ( 2.057)	Data  0.533 ( 0.846)	Loss 1.9402e-01 (2.8460e-01) 
2023-05-25 00:20:24.531683: train Epoch: [3][  5/193]	Time  1.015 ( 1.883)	Data  0.001 ( 0.705)	Loss 2.9196e-01 (2.8583e-01) 
2023-05-25 00:20:26.279584: train Epoch: [3][  6/193]	Time  1.748 ( 1.864)	Data  0.685 ( 0.702)	Loss 3.4207e-01 (2.9386e-01) 
2023-05-25 00:20:27.341625: train Epoch: [3][  7/193]	Time  1.062 ( 1.764)	Data  0.001 ( 0.615)	Loss 2.1195e-01 (2.8362e-01) 
2023-05-25 00:20:29.012487: train Epoch: [3][  8/193]	Time  1.671 ( 1.754)	Data  0.621 ( 0.615)	Loss 1.7608e-01 (2.7168e-01) 
2023-05-25 00:20:29.940752: train Epoch: [3][  9/193]	Time  0.928 ( 1.671)	Data  0.001 ( 0.554)	Loss 1.5742e-01 (2.6025e-01) 
2023-05-25 00:20:31.738052: train Epoch: [3][ 10/193]	Time  1.797 ( 1.682)	Data  0.816 ( 0.578)	Loss 1.5300e-01 (2.5050e-01) 
2023-05-25 00:20:32.694647: train Epoch: [3][ 11/193]	Time  0.957 ( 1.622)	Data  0.001 ( 0.530)	Loss 2.5626e-01 (2.5098e-01) 
2023-05-25 00:20:34.831264: train Epoch: [3][ 12/193]	Time  2.137 ( 1.662)	Data  0.785 ( 0.549)	Loss 1.8047e-01 (2.4556e-01) 
2023-05-25 00:20:35.855469: train Epoch: [3][ 13/193]	Time  1.024 ( 1.616)	Data  0.001 ( 0.510)	Loss 2.5524e-01 (2.4625e-01) 
2023-05-25 00:20:37.512503: train Epoch: [3][ 14/193]	Time  1.657 ( 1.619)	Data  0.470 ( 0.507)	Loss 1.8108e-01 (2.4190e-01) 
2023-05-25 00:20:38.607356: train Epoch: [3][ 15/193]	Time  1.095 ( 1.586)	Data  0.001 ( 0.476)	Loss 1.2425e-01 (2.3455e-01) 
2023-05-25 00:20:40.052265: train Epoch: [3][ 16/193]	Time  1.445 ( 1.578)	Data  0.435 ( 0.473)	Loss 1.4604e-01 (2.2934e-01) 
2023-05-25 00:20:41.203628: train Epoch: [3][ 17/193]	Time  1.151 ( 1.554)	Data  0.001 ( 0.447)	Loss 2.6626e-01 (2.3139e-01) 
2023-05-25 00:20:43.204929: train Epoch: [3][ 18/193]	Time  2.001 ( 1.578)	Data  0.679 ( 0.459)	Loss 2.6036e-01 (2.3292e-01) 
2023-05-25 00:20:44.213468: train Epoch: [3][ 19/193]	Time  1.009 ( 1.549)	Data  0.001 ( 0.436)	Loss 1.3943e-01 (2.2824e-01) 
2023-05-25 00:20:45.636311: train Epoch: [3][ 20/193]	Time  1.423 ( 1.543)	Data  0.433 ( 0.436)	Loss 1.1950e-01 (2.2307e-01) 
2023-05-25 00:20:46.708743: train Epoch: [3][ 21/193]	Time  1.072 ( 1.522)	Data  0.001 ( 0.417)	Loss 9.1638e-02 (2.1709e-01) 
2023-05-25 00:20:48.508996: train Epoch: [3][ 22/193]	Time  1.800 ( 1.534)	Data  0.768 ( 0.432)	Loss 1.3512e-01 (2.1353e-01) 
2023-05-25 00:20:49.532770: train Epoch: [3][ 23/193]	Time  1.024 ( 1.513)	Data  0.001 ( 0.414)	Loss 1.7859e-01 (2.1207e-01) 
2023-05-25 00:20:51.465352: train Epoch: [3][ 24/193]	Time  1.933 ( 1.529)	Data  0.723 ( 0.426)	Loss 1.1681e-01 (2.0826e-01) 
2023-05-25 00:20:52.505156: train Epoch: [3][ 25/193]	Time  1.040 ( 1.511)	Data  0.001 ( 0.410)	Loss 1.4420e-01 (2.0580e-01) 
2023-05-25 00:20:54.387690: train Epoch: [3][ 26/193]	Time  1.883 ( 1.524)	Data  0.556 ( 0.415)	Loss 2.4968e-01 (2.0742e-01) 
2023-05-25 00:20:55.428891: train Epoch: [3][ 27/193]	Time  1.041 ( 1.507)	Data  0.001 ( 0.400)	Loss 2.2167e-01 (2.0793e-01) 
2023-05-25 00:20:56.804218: train Epoch: [3][ 28/193]	Time  1.375 ( 1.503)	Data  0.132 ( 0.391)	Loss 1.9581e-01 (2.0751e-01) 
2023-05-25 00:20:57.825091: train Epoch: [3][ 29/193]	Time  1.021 ( 1.486)	Data  0.001 ( 0.378)	Loss 1.9253e-01 (2.0701e-01) 
2023-05-25 00:20:59.242235: train Epoch: [3][ 30/193]	Time  1.417 ( 1.484)	Data  0.373 ( 0.378)	Loss 1.1476e-01 (2.0404e-01) 
2023-05-25 00:21:00.537220: train Epoch: [3][ 31/193]	Time  1.295 ( 1.478)	Data  0.001 ( 0.366)	Loss 3.0676e-01 (2.0725e-01) 
2023-05-25 00:21:02.003308: train Epoch: [3][ 32/193]	Time  1.466 ( 1.478)	Data  0.419 ( 0.368)	Loss 1.2608e-01 (2.0479e-01) 
2023-05-25 00:21:03.108340: train Epoch: [3][ 33/193]	Time  1.105 ( 1.467)	Data  0.001 ( 0.357)	Loss 2.9749e-01 (2.0751e-01) 
2023-05-25 00:21:04.750502: train Epoch: [3][ 34/193]	Time  1.642 ( 1.472)	Data  0.630 ( 0.365)	Loss 1.3922e-01 (2.0556e-01) 
2023-05-25 00:21:05.930412: train Epoch: [3][ 35/193]	Time  1.180 ( 1.464)	Data  0.001 ( 0.355)	Loss 1.8889e-01 (2.0510e-01) 
2023-05-25 00:21:07.524413: train Epoch: [3][ 36/193]	Time  1.594 ( 1.467)	Data  0.485 ( 0.358)	Loss 1.5663e-01 (2.0379e-01) 
2023-05-25 00:21:08.673922: train Epoch: [3][ 37/193]	Time  1.150 ( 1.459)	Data  0.001 ( 0.349)	Loss 2.5069e-01 (2.0502e-01) 
2023-05-25 00:21:10.017401: train Epoch: [3][ 38/193]	Time  1.343 ( 1.456)	Data  0.368 ( 0.349)	Loss 1.5739e-01 (2.0380e-01) 
2023-05-25 00:21:11.096436: train Epoch: [3][ 39/193]	Time  1.079 ( 1.447)	Data  0.001 ( 0.341)	Loss 1.5850e-01 (2.0267e-01) 
2023-05-25 00:21:13.059501: train Epoch: [3][ 40/193]	Time  1.963 ( 1.459)	Data  0.586 ( 0.347)	Loss 1.6664e-01 (2.0179e-01) 
2023-05-25 00:21:14.100418: train Epoch: [3][ 41/193]	Time  1.041 ( 1.449)	Data  0.001 ( 0.338)	Loss 1.5803e-01 (2.0075e-01) 
2023-05-25 00:21:15.660072: train Epoch: [3][ 42/193]	Time  1.560 ( 1.452)	Data  0.324 ( 0.338)	Loss 1.9472e-01 (2.0061e-01) 
2023-05-25 00:21:16.796751: train Epoch: [3][ 43/193]	Time  1.137 ( 1.445)	Data  0.001 ( 0.330)	Loss 2.1349e-01 (2.0090e-01) 
2023-05-25 00:21:18.262112: train Epoch: [3][ 44/193]	Time  1.465 ( 1.445)	Data  0.394 ( 0.332)	Loss 2.5027e-01 (2.0200e-01) 
2023-05-25 00:21:19.411301: train Epoch: [3][ 45/193]	Time  1.149 ( 1.439)	Data  0.002 ( 0.325)	Loss 1.7005e-01 (2.0130e-01) 
2023-05-25 00:21:21.219634: train Epoch: [3][ 46/193]	Time  1.808 ( 1.447)	Data  0.603 ( 0.331)	Loss 1.1163e-01 (1.9940e-01) 
2023-05-25 00:21:22.191852: train Epoch: [3][ 47/193]	Time  0.972 ( 1.437)	Data  0.001 ( 0.324)	Loss 1.5506e-01 (1.9847e-01) 
2023-05-25 00:21:24.157644: train Epoch: [3][ 48/193]	Time  1.966 ( 1.447)	Data  0.747 ( 0.332)	Loss 1.5489e-01 (1.9758e-01) 
2023-05-25 00:21:25.384017: train Epoch: [3][ 49/193]	Time  1.226 ( 1.443)	Data  0.001 ( 0.326)	Loss 2.9766e-01 (1.9959e-01) 
2023-05-25 00:21:26.831358: train Epoch: [3][ 50/193]	Time  1.447 ( 1.443)	Data  0.397 ( 0.327)	Loss 1.2071e-01 (1.9804e-01) 
2023-05-25 00:21:27.999954: train Epoch: [3][ 51/193]	Time  1.169 ( 1.438)	Data  0.001 ( 0.321)	Loss 1.2310e-01 (1.9660e-01) 
2023-05-25 00:21:29.610874: train Epoch: [3][ 52/193]	Time  1.611 ( 1.441)	Data  0.678 ( 0.328)	Loss 2.1662e-01 (1.9698e-01) 
2023-05-25 00:21:30.708388: train Epoch: [3][ 53/193]	Time  1.098 ( 1.435)	Data  0.001 ( 0.322)	Loss 1.9956e-01 (1.9702e-01) 
2023-05-25 00:21:32.654812: train Epoch: [3][ 54/193]	Time  1.946 ( 1.444)	Data  0.806 ( 0.330)	Loss 1.9638e-01 (1.9701e-01) 
2023-05-25 00:21:33.806814: train Epoch: [3][ 55/193]	Time  1.152 ( 1.439)	Data  0.001 ( 0.324)	Loss 1.2148e-01 (1.9566e-01) 
2023-05-25 00:21:35.330493: train Epoch: [3][ 56/193]	Time  1.524 ( 1.440)	Data  0.513 ( 0.328)	Loss 1.8965e-01 (1.9556e-01) 
2023-05-25 00:21:36.342180: train Epoch: [3][ 57/193]	Time  1.012 ( 1.433)	Data  0.001 ( 0.322)	Loss 1.8056e-01 (1.9530e-01) 
2023-05-25 00:21:38.053512: train Epoch: [3][ 58/193]	Time  1.711 ( 1.438)	Data  0.715 ( 0.329)	Loss 1.5970e-01 (1.9470e-01) 
2023-05-25 00:21:39.060979: train Epoch: [3][ 59/193]	Time  1.007 ( 1.430)	Data  0.001 ( 0.323)	Loss 2.3164e-01 (1.9531e-01) 
2023-05-25 00:21:40.991879: train Epoch: [3][ 60/193]	Time  1.931 ( 1.439)	Data  0.727 ( 0.330)	Loss 1.8463e-01 (1.9514e-01) 
2023-05-25 00:21:41.974966: train Epoch: [3][ 61/193]	Time  0.983 ( 1.431)	Data  0.002 ( 0.325)	Loss 1.5467e-01 (1.9448e-01) 
2023-05-25 00:21:43.912495: train Epoch: [3][ 62/193]	Time  1.938 ( 1.439)	Data  0.552 ( 0.328)	Loss 2.1345e-01 (1.9478e-01) 
2023-05-25 00:21:45.021002: train Epoch: [3][ 63/193]	Time  1.108 ( 1.434)	Data  0.001 ( 0.323)	Loss 1.8211e-01 (1.9459e-01) 
2023-05-25 00:21:46.365476: train Epoch: [3][ 64/193]	Time  1.345 ( 1.433)	Data  0.305 ( 0.323)	Loss 1.8732e-01 (1.9447e-01) 
2023-05-25 00:21:47.559479: train Epoch: [3][ 65/193]	Time  1.194 ( 1.429)	Data  0.001 ( 0.318)	Loss 2.1231e-01 (1.9474e-01) 
2023-05-25 00:21:49.067981: train Epoch: [3][ 66/193]	Time  1.508 ( 1.430)	Data  0.384 ( 0.319)	Loss 1.1618e-01 (1.9357e-01) 
2023-05-25 00:21:50.231019: train Epoch: [3][ 67/193]	Time  1.163 ( 1.426)	Data  0.002 ( 0.314)	Loss 2.3252e-01 (1.9414e-01) 
2023-05-25 00:21:51.918359: train Epoch: [3][ 68/193]	Time  1.687 ( 1.430)	Data  0.505 ( 0.317)	Loss 2.2468e-01 (1.9459e-01) 
2023-05-25 00:21:53.060748: train Epoch: [3][ 69/193]	Time  1.142 ( 1.426)	Data  0.001 ( 0.313)	Loss 1.2933e-01 (1.9366e-01) 
2023-05-25 00:21:54.489074: train Epoch: [3][ 70/193]	Time  1.428 ( 1.426)	Data  0.439 ( 0.314)	Loss 1.7786e-01 (1.9343e-01) 
2023-05-25 00:21:55.487123: train Epoch: [3][ 71/193]	Time  0.998 ( 1.420)	Data  0.001 ( 0.310)	Loss 1.2258e-01 (1.9245e-01) 
2023-05-25 00:21:57.387011: train Epoch: [3][ 72/193]	Time  1.900 ( 1.427)	Data  0.674 ( 0.315)	Loss 1.2593e-01 (1.9154e-01) 
2023-05-25 00:21:58.384506: train Epoch: [3][ 73/193]	Time  0.997 ( 1.421)	Data  0.001 ( 0.311)	Loss 1.8147e-01 (1.9140e-01) 
2023-05-25 00:22:00.258099: train Epoch: [3][ 74/193]	Time  1.874 ( 1.427)	Data  0.504 ( 0.313)	Loss 1.4155e-01 (1.9074e-01) 
2023-05-25 00:22:01.276159: train Epoch: [3][ 75/193]	Time  1.018 ( 1.422)	Data  0.001 ( 0.309)	Loss 1.0612e-01 (1.8962e-01) 
2023-05-25 00:22:02.646578: train Epoch: [3][ 76/193]	Time  1.370 ( 1.421)	Data  0.252 ( 0.308)	Loss 1.3464e-01 (1.8891e-01) 
2023-05-25 00:22:03.638242: train Epoch: [3][ 77/193]	Time  0.992 ( 1.415)	Data  0.001 ( 0.305)	Loss 1.9230e-01 (1.8895e-01) 
2023-05-25 00:22:05.555283: train Epoch: [3][ 78/193]	Time  1.917 ( 1.422)	Data  0.694 ( 0.309)	Loss 1.5502e-01 (1.8852e-01) 
2023-05-25 00:22:06.601463: train Epoch: [3][ 79/193]	Time  1.046 ( 1.417)	Data  0.003 ( 0.306)	Loss 1.8969e-01 (1.8854e-01) 
2023-05-25 00:22:08.243670: train Epoch: [3][ 80/193]	Time  1.642 ( 1.420)	Data  0.367 ( 0.306)	Loss 1.5154e-01 (1.8808e-01) 
2023-05-25 00:22:09.223672: train Epoch: [3][ 81/193]	Time  0.980 ( 1.415)	Data  0.001 ( 0.303)	Loss 1.3478e-01 (1.8743e-01) 
2023-05-25 00:22:11.061590: train Epoch: [3][ 82/193]	Time  1.838 ( 1.420)	Data  0.573 ( 0.306)	Loss 1.7488e-01 (1.8728e-01) 
2023-05-25 00:22:12.100020: train Epoch: [3][ 83/193]	Time  1.038 ( 1.415)	Data  0.001 ( 0.302)	Loss 1.6020e-01 (1.8696e-01) 
2023-05-25 00:22:13.924403: train Epoch: [3][ 84/193]	Time  1.824 ( 1.420)	Data  0.604 ( 0.306)	Loss 4.4443e-01 (1.8999e-01) 
2023-05-25 00:22:15.026055: train Epoch: [3][ 85/193]	Time  1.102 ( 1.416)	Data  0.001 ( 0.302)	Loss 2.5913e-01 (1.9079e-01) 
2023-05-25 00:22:16.733060: train Epoch: [3][ 86/193]	Time  1.707 ( 1.420)	Data  0.427 ( 0.304)	Loss 2.3944e-01 (1.9135e-01) 
2023-05-25 00:22:18.084812: train Epoch: [3][ 87/193]	Time  1.352 ( 1.419)	Data  0.001 ( 0.300)	Loss 1.2632e-01 (1.9061e-01) 
2023-05-25 00:22:19.318084: train Epoch: [3][ 88/193]	Time  1.233 ( 1.417)	Data  0.241 ( 0.300)	Loss 1.8530e-01 (1.9055e-01) 
2023-05-25 00:22:20.539259: train Epoch: [3][ 89/193]	Time  1.221 ( 1.415)	Data  0.001 ( 0.296)	Loss 1.4550e-01 (1.9005e-01) 
2023-05-25 00:22:22.265103: train Epoch: [3][ 90/193]	Time  1.726 ( 1.418)	Data  0.604 ( 0.300)	Loss 4.1592e-01 (1.9253e-01) 
2023-05-25 00:22:23.424005: train Epoch: [3][ 91/193]	Time  1.159 ( 1.415)	Data  0.001 ( 0.296)	Loss 1.5827e-01 (1.9216e-01) 
2023-05-25 00:22:25.057473: train Epoch: [3][ 92/193]	Time  1.633 ( 1.417)	Data  0.492 ( 0.299)	Loss 1.2563e-01 (1.9144e-01) 
2023-05-25 00:22:26.185606: train Epoch: [3][ 93/193]	Time  1.128 ( 1.414)	Data  0.001 ( 0.295)	Loss 2.0968e-01 (1.9164e-01) 
2023-05-25 00:22:27.812416: train Epoch: [3][ 94/193]	Time  1.627 ( 1.417)	Data  0.438 ( 0.297)	Loss 1.7977e-01 (1.9151e-01) 
2023-05-25 00:22:28.842160: train Epoch: [3][ 95/193]	Time  1.030 ( 1.413)	Data  0.001 ( 0.294)	Loss 2.3670e-01 (1.9198e-01) 
2023-05-25 00:22:30.590303: train Epoch: [3][ 96/193]	Time  1.748 ( 1.416)	Data  0.520 ( 0.296)	Loss 1.5325e-01 (1.9159e-01) 
2023-05-25 00:22:31.597204: train Epoch: [3][ 97/193]	Time  1.007 ( 1.412)	Data  0.001 ( 0.293)	Loss 2.3107e-01 (1.9199e-01) 
2023-05-25 00:22:33.016062: train Epoch: [3][ 98/193]	Time  1.419 ( 1.412)	Data  0.449 ( 0.295)	Loss 1.2049e-01 (1.9127e-01) 
2023-05-25 00:22:34.011735: train Epoch: [3][ 99/193]	Time  0.996 ( 1.408)	Data  0.001 ( 0.292)	Loss 1.6929e-01 (1.9105e-01) 
2023-05-25 00:22:35.998391: train Epoch: [3][100/193]	Time  1.987 ( 1.414)	Data  0.681 ( 0.296)	Loss 2.8365e-01 (1.9196e-01) 
2023-05-25 00:22:37.016546: train Epoch: [3][101/193]	Time  1.018 ( 1.410)	Data  0.001 ( 0.293)	Loss 8.2193e-02 (1.9089e-01) 
2023-05-25 00:22:38.173016: train Epoch: [3][102/193]	Time  1.156 ( 1.407)	Data  0.152 ( 0.291)	Loss 1.1755e-01 (1.9017e-01) 
2023-05-25 00:22:39.490537: train Epoch: [3][103/193]	Time  1.318 ( 1.406)	Data  0.001 ( 0.289)	Loss 2.2725e-01 (1.9053e-01) 
2023-05-25 00:22:41.013420: train Epoch: [3][104/193]	Time  1.523 ( 1.407)	Data  0.403 ( 0.290)	Loss 1.1209e-01 (1.8978e-01) 
2023-05-25 00:22:42.126924: train Epoch: [3][105/193]	Time  1.114 ( 1.405)	Data  0.001 ( 0.287)	Loss 1.3642e-01 (1.8928e-01) 
2023-05-25 00:22:43.682980: train Epoch: [3][106/193]	Time  1.556 ( 1.406)	Data  0.537 ( 0.289)	Loss 1.2794e-01 (1.8871e-01) 
2023-05-25 00:22:44.766232: train Epoch: [3][107/193]	Time  1.083 ( 1.403)	Data  0.001 ( 0.287)	Loss 3.4006e-01 (1.9011e-01) 
2023-05-25 00:22:46.420859: train Epoch: [3][108/193]	Time  1.655 ( 1.405)	Data  0.615 ( 0.290)	Loss 1.6425e-01 (1.8987e-01) 
2023-05-25 00:22:47.557106: train Epoch: [3][109/193]	Time  1.136 ( 1.403)	Data  0.001 ( 0.287)	Loss 2.0661e-01 (1.9002e-01) 
2023-05-25 00:22:49.309999: train Epoch: [3][110/193]	Time  1.753 ( 1.406)	Data  0.560 ( 0.289)	Loss 1.8111e-01 (1.8994e-01) 
2023-05-25 00:22:50.313661: train Epoch: [3][111/193]	Time  1.004 ( 1.403)	Data  0.001 ( 0.287)	Loss 1.8044e-01 (1.8986e-01) 
2023-05-25 00:22:52.009053: train Epoch: [3][112/193]	Time  1.695 ( 1.405)	Data  0.509 ( 0.289)	Loss 2.1775e-01 (1.9011e-01) 
2023-05-25 00:22:52.984070: train Epoch: [3][113/193]	Time  0.975 ( 1.401)	Data  0.001 ( 0.286)	Loss 1.1649e-01 (1.8946e-01) 
2023-05-25 00:22:54.841903: train Epoch: [3][114/193]	Time  1.858 ( 1.405)	Data  0.588 ( 0.289)	Loss 4.5077e-01 (1.9173e-01) 
2023-05-25 00:22:55.808857: train Epoch: [3][115/193]	Time  0.967 ( 1.402)	Data  0.001 ( 0.286)	Loss 1.8027e-01 (1.9163e-01) 
2023-05-25 00:22:57.549794: train Epoch: [3][116/193]	Time  1.741 ( 1.404)	Data  0.620 ( 0.289)	Loss 2.2013e-01 (1.9188e-01) 
2023-05-25 00:22:58.551752: train Epoch: [3][117/193]	Time  1.002 ( 1.401)	Data  0.001 ( 0.287)	Loss 1.5840e-01 (1.9159e-01) 
2023-05-25 00:23:00.514680: train Epoch: [3][118/193]	Time  1.963 ( 1.406)	Data  0.643 ( 0.290)	Loss 2.3326e-01 (1.9194e-01) 
2023-05-25 00:23:01.564488: train Epoch: [3][119/193]	Time  1.050 ( 1.403)	Data  0.001 ( 0.287)	Loss 1.3901e-01 (1.9150e-01) 
2023-05-25 00:23:03.110172: train Epoch: [3][120/193]	Time  1.546 ( 1.404)	Data  0.381 ( 0.288)	Loss 1.5131e-01 (1.9117e-01) 
2023-05-25 00:23:04.112001: train Epoch: [3][121/193]	Time  1.002 ( 1.401)	Data  0.001 ( 0.286)	Loss 2.0372e-01 (1.9127e-01) 
2023-05-25 00:23:05.758302: train Epoch: [3][122/193]	Time  1.646 ( 1.403)	Data  0.622 ( 0.289)	Loss 1.6892e-01 (1.9109e-01) 
2023-05-25 00:23:06.862191: train Epoch: [3][123/193]	Time  1.104 ( 1.400)	Data  0.001 ( 0.286)	Loss 1.4937e-01 (1.9075e-01) 
2023-05-25 00:23:08.530591: train Epoch: [3][124/193]	Time  1.668 ( 1.402)	Data  0.614 ( 0.289)	Loss 3.0052e-01 (1.9163e-01) 
2023-05-25 00:23:09.717268: train Epoch: [3][125/193]	Time  1.187 ( 1.401)	Data  0.001 ( 0.287)	Loss 1.9972e-01 (1.9170e-01) 
2023-05-25 00:23:11.269884: train Epoch: [3][126/193]	Time  1.553 ( 1.402)	Data  0.494 ( 0.288)	Loss 1.4663e-01 (1.9134e-01) 
2023-05-25 00:23:12.381274: train Epoch: [3][127/193]	Time  1.111 ( 1.400)	Data  0.001 ( 0.286)	Loss 1.3315e-01 (1.9089e-01) 
2023-05-25 00:23:13.926719: train Epoch: [3][128/193]	Time  1.545 ( 1.401)	Data  0.597 ( 0.288)	Loss 2.0581e-01 (1.9100e-01) 
2023-05-25 00:23:14.912861: train Epoch: [3][129/193]	Time  0.986 ( 1.398)	Data  0.001 ( 0.286)	Loss 1.8144e-01 (1.9093e-01) 
2023-05-25 00:23:16.887239: train Epoch: [3][130/193]	Time  1.974 ( 1.402)	Data  0.711 ( 0.289)	Loss 1.1887e-01 (1.9038e-01) 
2023-05-25 00:23:17.968090: train Epoch: [3][131/193]	Time  1.081 ( 1.400)	Data  0.001 ( 0.287)	Loss 1.5016e-01 (1.9008e-01) 
2023-05-25 00:23:19.627953: train Epoch: [3][132/193]	Time  1.660 ( 1.401)	Data  0.434 ( 0.288)	Loss 1.1353e-01 (1.8950e-01) 
2023-05-25 00:23:20.614085: train Epoch: [3][133/193]	Time  0.986 ( 1.398)	Data  0.001 ( 0.286)	Loss 1.5199e-01 (1.8922e-01) 
2023-05-25 00:23:22.451718: train Epoch: [3][134/193]	Time  1.838 ( 1.402)	Data  0.501 ( 0.288)	Loss 1.9587e-01 (1.8927e-01) 
2023-05-25 00:23:23.421087: train Epoch: [3][135/193]	Time  0.969 ( 1.398)	Data  0.001 ( 0.286)	Loss 2.3722e-01 (1.8962e-01) 
2023-05-25 00:23:25.034213: train Epoch: [3][136/193]	Time  1.613 ( 1.400)	Data  0.303 ( 0.286)	Loss 1.4755e-01 (1.8931e-01) 
2023-05-25 00:23:26.107820: train Epoch: [3][137/193]	Time  1.074 ( 1.398)	Data  0.001 ( 0.284)	Loss 1.8022e-01 (1.8925e-01) 
2023-05-25 00:23:27.561872: train Epoch: [3][138/193]	Time  1.454 ( 1.398)	Data  0.425 ( 0.285)	Loss 1.7588e-01 (1.8915e-01) 
2023-05-25 00:23:28.711352: train Epoch: [3][139/193]	Time  1.149 ( 1.396)	Data  0.001 ( 0.283)	Loss 1.7354e-01 (1.8904e-01) 
2023-05-25 00:23:30.451238: train Epoch: [3][140/193]	Time  1.740 ( 1.399)	Data  0.558 ( 0.285)	Loss 2.9011e-01 (1.8976e-01) 
2023-05-25 00:23:31.782573: train Epoch: [3][141/193]	Time  1.331 ( 1.398)	Data  0.001 ( 0.283)	Loss 3.5912e-01 (1.9095e-01) 
2023-05-25 00:23:32.971342: train Epoch: [3][142/193]	Time  1.189 ( 1.397)	Data  0.185 ( 0.282)	Loss 2.4244e-01 (1.9131e-01) 
2023-05-25 00:23:34.094482: train Epoch: [3][143/193]	Time  1.123 ( 1.395)	Data  0.001 ( 0.280)	Loss 1.3829e-01 (1.9094e-01) 
2023-05-25 00:23:35.763222: train Epoch: [3][144/193]	Time  1.669 ( 1.397)	Data  0.682 ( 0.283)	Loss 1.6161e-01 (1.9074e-01) 
2023-05-25 00:23:36.727690: train Epoch: [3][145/193]	Time  0.964 ( 1.394)	Data  0.001 ( 0.281)	Loss 1.0400e-01 (1.9015e-01) 
2023-05-25 00:23:38.673898: train Epoch: [3][146/193]	Time  1.946 ( 1.398)	Data  0.770 ( 0.284)	Loss 1.1792e-01 (1.8965e-01) 
2023-05-25 00:23:39.686013: train Epoch: [3][147/193]	Time  1.012 ( 1.395)	Data  0.001 ( 0.282)	Loss 1.8175e-01 (1.8960e-01) 
2023-05-25 00:23:41.414392: train Epoch: [3][148/193]	Time  1.728 ( 1.397)	Data  0.559 ( 0.284)	Loss 2.4135e-01 (1.8995e-01) 
2023-05-25 00:23:42.376781: train Epoch: [3][149/193]	Time  0.962 ( 1.394)	Data  0.001 ( 0.282)	Loss 1.8351e-01 (1.8991e-01) 
2023-05-25 00:23:44.316688: train Epoch: [3][150/193]	Time  1.940 ( 1.398)	Data  0.597 ( 0.284)	Loss 8.4570e-02 (1.8921e-01) 
2023-05-25 00:23:45.284459: train Epoch: [3][151/193]	Time  0.968 ( 1.395)	Data  0.001 ( 0.283)	Loss 1.6575e-01 (1.8905e-01) 
2023-05-25 00:23:46.864389: train Epoch: [3][152/193]	Time  1.580 ( 1.396)	Data  0.488 ( 0.284)	Loss 1.5777e-01 (1.8885e-01) 
2023-05-25 00:23:47.918539: train Epoch: [3][153/193]	Time  1.054 ( 1.394)	Data  0.001 ( 0.282)	Loss 2.7625e-01 (1.8942e-01) 
2023-05-25 00:23:49.813251: train Epoch: [3][154/193]	Time  1.895 ( 1.397)	Data  0.740 ( 0.285)	Loss 1.6250e-01 (1.8924e-01) 
2023-05-25 00:23:51.136996: train Epoch: [3][155/193]	Time  1.324 ( 1.397)	Data  0.001 ( 0.283)	Loss 2.9056e-01 (1.8989e-01) 
2023-05-25 00:23:52.563513: train Epoch: [3][156/193]	Time  1.427 ( 1.397)	Data  0.319 ( 0.283)	Loss 1.3115e-01 (1.8952e-01) 
2023-05-25 00:23:53.866765: train Epoch: [3][157/193]	Time  1.303 ( 1.396)	Data  0.001 ( 0.282)	Loss 2.0737e-01 (1.8963e-01) 
2023-05-25 00:23:55.288584: train Epoch: [3][158/193]	Time  1.422 ( 1.397)	Data  0.359 ( 0.282)	Loss 1.5481e-01 (1.8941e-01) 
2023-05-25 00:23:56.428075: train Epoch: [3][159/193]	Time  1.139 ( 1.395)	Data  0.001 ( 0.280)	Loss 1.1034e-01 (1.8892e-01) 
2023-05-25 00:23:58.238485: train Epoch: [3][160/193]	Time  1.810 ( 1.398)	Data  0.543 ( 0.282)	Loss 1.5940e-01 (1.8873e-01) 
2023-05-25 00:23:59.434896: train Epoch: [3][161/193]	Time  1.196 ( 1.396)	Data  0.001 ( 0.280)	Loss 2.1849e-01 (1.8892e-01) 
2023-05-25 00:24:01.024830: train Epoch: [3][162/193]	Time  1.590 ( 1.398)	Data  0.500 ( 0.282)	Loss 1.7590e-01 (1.8884e-01) 
2023-05-25 00:24:02.063720: train Epoch: [3][163/193]	Time  1.039 ( 1.395)	Data  0.001 ( 0.280)	Loss 1.5893e-01 (1.8866e-01) 
2023-05-25 00:24:03.821447: train Epoch: [3][164/193]	Time  1.758 ( 1.398)	Data  0.751 ( 0.283)	Loss 2.4255e-01 (1.8898e-01) 
2023-05-25 00:24:04.865099: train Epoch: [3][165/193]	Time  1.044 ( 1.395)	Data  0.001 ( 0.281)	Loss 2.3614e-01 (1.8927e-01) 
2023-05-25 00:24:06.911824: train Epoch: [3][166/193]	Time  2.047 ( 1.399)	Data  0.776 ( 0.284)	Loss 4.0059e-01 (1.9053e-01) 
2023-05-25 00:24:07.954881: train Epoch: [3][167/193]	Time  1.043 ( 1.397)	Data  0.001 ( 0.282)	Loss 3.7053e-01 (1.9160e-01) 
2023-05-25 00:24:09.771220: train Epoch: [3][168/193]	Time  1.816 ( 1.400)	Data  0.501 ( 0.284)	Loss 1.7890e-01 (1.9153e-01) 
2023-05-25 00:24:10.776828: train Epoch: [3][169/193]	Time  1.006 ( 1.397)	Data  0.001 ( 0.282)	Loss 1.6012e-01 (1.9134e-01) 
2023-05-25 00:24:12.347856: train Epoch: [3][170/193]	Time  1.571 ( 1.398)	Data  0.381 ( 0.283)	Loss 1.9136e-01 (1.9134e-01) 
2023-05-25 00:24:13.289603: train Epoch: [3][171/193]	Time  0.942 ( 1.396)	Data  0.001 ( 0.281)	Loss 1.8343e-01 (1.9130e-01) 
2023-05-25 00:24:15.006897: train Epoch: [3][172/193]	Time  1.717 ( 1.398)	Data  0.695 ( 0.283)	Loss 1.5553e-01 (1.9109e-01) 
2023-05-25 00:24:15.976323: train Epoch: [3][173/193]	Time  0.969 ( 1.395)	Data  0.001 ( 0.282)	Loss 2.8496e-01 (1.9163e-01) 
2023-05-25 00:24:18.054399: train Epoch: [3][174/193]	Time  2.078 ( 1.399)	Data  0.775 ( 0.284)	Loss 1.1867e-01 (1.9121e-01) 
2023-05-25 00:24:19.028286: train Epoch: [3][175/193]	Time  0.974 ( 1.397)	Data  0.001 ( 0.283)	Loss 1.6664e-01 (1.9107e-01) 
2023-05-25 00:24:20.655921: train Epoch: [3][176/193]	Time  1.628 ( 1.398)	Data  0.531 ( 0.284)	Loss 9.4598e-02 (1.9053e-01) 
2023-05-25 00:24:21.829503: train Epoch: [3][177/193]	Time  1.174 ( 1.397)	Data  0.001 ( 0.283)	Loss 1.4539e-01 (1.9028e-01) 
2023-05-25 00:24:23.588417: train Epoch: [3][178/193]	Time  1.759 ( 1.399)	Data  0.550 ( 0.284)	Loss 1.3415e-01 (1.8996e-01) 
2023-05-25 00:24:24.605037: train Epoch: [3][179/193]	Time  1.017 ( 1.397)	Data  0.001 ( 0.283)	Loss 1.4514e-01 (1.8971e-01) 
2023-05-25 00:24:26.182414: train Epoch: [3][180/193]	Time  1.577 ( 1.398)	Data  0.535 ( 0.284)	Loss 1.2799e-01 (1.8937e-01) 
2023-05-25 00:24:27.286619: train Epoch: [3][181/193]	Time  1.104 ( 1.396)	Data  0.001 ( 0.282)	Loss 1.8340e-01 (1.8934e-01) 
2023-05-25 00:24:29.182161: train Epoch: [3][182/193]	Time  1.896 ( 1.399)	Data  0.655 ( 0.284)	Loss 1.7224e-01 (1.8925e-01) 
2023-05-25 00:24:30.143130: train Epoch: [3][183/193]	Time  0.961 ( 1.396)	Data  0.001 ( 0.283)	Loss 3.0678e-01 (1.8988e-01) 
2023-05-25 00:24:31.933767: train Epoch: [3][184/193]	Time  1.791 ( 1.398)	Data  0.546 ( 0.284)	Loss 2.9661e-01 (1.9046e-01) 
2023-05-25 00:24:32.942391: train Epoch: [3][185/193]	Time  1.009 ( 1.396)	Data  0.001 ( 0.283)	Loss 1.6002e-01 (1.9030e-01) 
2023-05-25 00:24:34.655805: train Epoch: [3][186/193]	Time  1.713 ( 1.398)	Data  0.499 ( 0.284)	Loss 1.1441e-01 (1.8989e-01) 
2023-05-25 00:24:35.657770: train Epoch: [3][187/193]	Time  1.002 ( 1.396)	Data  0.001 ( 0.282)	Loss 2.1577e-01 (1.9003e-01) 
2023-05-25 00:24:37.325266: train Epoch: [3][188/193]	Time  1.668 ( 1.397)	Data  0.504 ( 0.284)	Loss 1.2801e-01 (1.8970e-01) 
2023-05-25 00:24:38.477862: train Epoch: [3][189/193]	Time  1.153 ( 1.396)	Data  0.001 ( 0.282)	Loss 1.0325e-01 (1.8925e-01) 
2023-05-25 00:24:40.145765: train Epoch: [3][190/193]	Time  1.668 ( 1.397)	Data  0.547 ( 0.284)	Loss 1.1641e-01 (1.8886e-01) 
2023-05-25 00:24:41.195930: train Epoch: [3][191/193]	Time  1.050 ( 1.396)	Data  0.001 ( 0.282)	Loss 3.0781e-01 (1.8948e-01) 
2023-05-25 00:24:42.405074: train Epoch: [3][192/193]	Time  1.209 ( 1.395)	Data  0.089 ( 0.281)	Loss 2.3139e-01 (1.8970e-01) 
2023-05-25 00:24:42.469421: Train Epoch done in 269.239122907049 s 
2023-05-25 00:24:45.839999: val Epoch: [3][ 0/72]	Time  2.377 ( 2.377)	Data  1.709 ( 1.709)	Loss 4.8328e-01 (4.8328e-01) 
2023-05-25 00:24:46.172217: val Epoch: [3][ 1/72]	Time  0.333 ( 1.355)	Data  0.002 ( 0.856)	Loss 2.5901e-01 (3.7114e-01) 
2023-05-25 00:24:46.894784: val Epoch: [3][ 2/72]	Time  0.723 ( 1.144)	Data  0.332 ( 0.681)	Loss 8.7467e-02 (2.7658e-01) 
2023-05-25 00:24:47.385088: val Epoch: [3][ 3/72]	Time  0.490 ( 0.981)	Data  0.001 ( 0.511)	Loss 2.5339e-01 (2.7079e-01) 
2023-05-25 00:24:48.187894: val Epoch: [3][ 4/72]	Time  0.803 ( 0.945)	Data  0.503 ( 0.509)	Loss 1.8608e-01 (2.5384e-01) 
2023-05-25 00:24:48.418279: val Epoch: [3][ 5/72]	Time  0.230 ( 0.826)	Data  0.001 ( 0.425)	Loss 1.0801e-01 (2.2954e-01) 
2023-05-25 00:24:49.693895: val Epoch: [3][ 6/72]	Time  1.276 ( 0.890)	Data  0.851 ( 0.486)	Loss 1.0312e-01 (2.1148e-01) 
2023-05-25 00:24:50.107968: val Epoch: [3][ 7/72]	Time  0.414 ( 0.831)	Data  0.001 ( 0.425)	Loss 2.0506e-01 (2.1068e-01) 
2023-05-25 00:24:51.055160: val Epoch: [3][ 8/72]	Time  0.947 ( 0.844)	Data  0.633 ( 0.448)	Loss 1.7760e-01 (2.0700e-01) 
2023-05-25 00:24:51.507107: val Epoch: [3][ 9/72]	Time  0.452 ( 0.804)	Data  0.001 ( 0.403)	Loss 1.7196e-01 (2.0350e-01) 
2023-05-25 00:24:52.466976: val Epoch: [3][10/72]	Time  0.960 ( 0.819)	Data  0.556 ( 0.417)	Loss 1.4982e-01 (1.9862e-01) 
2023-05-25 00:24:52.841194: val Epoch: [3][11/72]	Time  0.374 ( 0.782)	Data  0.001 ( 0.383)	Loss 1.5889e-01 (1.9531e-01) 
2023-05-25 00:24:53.858786: val Epoch: [3][12/72]	Time  1.018 ( 0.800)	Data  0.600 ( 0.399)	Loss 1.2660e-01 (1.9002e-01) 
2023-05-25 00:24:54.328750: val Epoch: [3][13/72]	Time  0.470 ( 0.776)	Data  0.062 ( 0.375)	Loss 2.3042e-01 (1.9291e-01) 
2023-05-25 00:24:55.145378: val Epoch: [3][14/72]	Time  0.817 ( 0.779)	Data  0.555 ( 0.387)	Loss 1.2278e-01 (1.8823e-01) 
2023-05-25 00:24:55.694052: val Epoch: [3][15/72]	Time  0.549 ( 0.764)	Data  0.242 ( 0.378)	Loss 2.0082e-01 (1.8902e-01) 
2023-05-25 00:24:56.670186: val Epoch: [3][16/72]	Time  0.976 ( 0.777)	Data  0.574 ( 0.390)	Loss 1.2815e-01 (1.8544e-01) 
2023-05-25 00:24:57.126237: val Epoch: [3][17/72]	Time  0.456 ( 0.759)	Data  0.149 ( 0.376)	Loss 4.0431e-01 (1.9760e-01) 
2023-05-25 00:24:58.033742: val Epoch: [3][18/72]	Time  0.907 ( 0.767)	Data  0.562 ( 0.386)	Loss 2.0324e-01 (1.9789e-01) 
2023-05-25 00:24:58.673866: val Epoch: [3][19/72]	Time  0.640 ( 0.761)	Data  0.199 ( 0.377)	Loss 1.6519e-01 (1.9626e-01) 
2023-05-25 00:24:59.313818: val Epoch: [3][20/72]	Time  0.640 ( 0.755)	Data  0.346 ( 0.375)	Loss 1.2106e-01 (1.9268e-01) 
2023-05-25 00:25:00.090244: val Epoch: [3][21/72]	Time  0.776 ( 0.756)	Data  0.338 ( 0.374)	Loss 1.8580e-01 (1.9237e-01) 
2023-05-25 00:25:00.633266: val Epoch: [3][22/72]	Time  0.543 ( 0.747)	Data  0.298 ( 0.370)	Loss 1.2304e-01 (1.8935e-01) 
2023-05-25 00:25:01.565611: val Epoch: [3][23/72]	Time  0.932 ( 0.754)	Data  0.487 ( 0.375)	Loss 1.9632e-01 (1.8964e-01) 
2023-05-25 00:25:02.215257: val Epoch: [3][24/72]	Time  0.650 ( 0.750)	Data  0.216 ( 0.369)	Loss 3.0694e-01 (1.9433e-01) 
2023-05-25 00:25:02.742523: val Epoch: [3][25/72]	Time  0.527 ( 0.742)	Data  0.253 ( 0.364)	Loss 1.0663e-01 (1.9096e-01) 
2023-05-25 00:25:03.303119: val Epoch: [3][26/72]	Time  0.561 ( 0.735)	Data  0.370 ( 0.365)	Loss 2.1687e-01 (1.9192e-01) 
2023-05-25 00:25:04.280112: val Epoch: [3][27/72]	Time  0.977 ( 0.743)	Data  0.651 ( 0.375)	Loss 1.6614e-01 (1.9100e-01) 
2023-05-25 00:25:04.757039: val Epoch: [3][28/72]	Time  0.477 ( 0.734)	Data  0.218 ( 0.369)	Loss 1.4587e-01 (1.8944e-01) 
2023-05-25 00:25:05.591017: val Epoch: [3][29/72]	Time  0.834 ( 0.738)	Data  0.626 ( 0.378)	Loss 1.0854e-01 (1.8675e-01) 
2023-05-25 00:25:06.166372: val Epoch: [3][30/72]	Time  0.575 ( 0.732)	Data  0.312 ( 0.376)	Loss 3.3526e-01 (1.9154e-01) 
2023-05-25 00:25:07.112581: val Epoch: [3][31/72]	Time  0.946 ( 0.739)	Data  0.600 ( 0.383)	Loss 2.1181e-01 (1.9217e-01) 
2023-05-25 00:25:07.648280: val Epoch: [3][32/72]	Time  0.536 ( 0.733)	Data  0.304 ( 0.380)	Loss 1.2556e-01 (1.9015e-01) 
2023-05-25 00:25:08.870769: val Epoch: [3][33/72]	Time  1.222 ( 0.747)	Data  0.613 ( 0.387)	Loss 6.1184e-01 (2.0255e-01) 
2023-05-25 00:25:09.288650: val Epoch: [3][34/72]	Time  0.418 ( 0.738)	Data  0.015 ( 0.377)	Loss 1.9259e-01 (2.0227e-01) 
2023-05-25 00:25:10.000055: val Epoch: [3][35/72]	Time  0.711 ( 0.737)	Data  0.406 ( 0.377)	Loss 2.2361e-01 (2.0286e-01) 
2023-05-25 00:25:10.553661: val Epoch: [3][36/72]	Time  0.554 ( 0.732)	Data  0.321 ( 0.376)	Loss 1.3232e-01 (2.0096e-01) 
2023-05-25 00:25:11.422500: val Epoch: [3][37/72]	Time  0.869 ( 0.736)	Data  0.609 ( 0.382)	Loss 2.8759e-01 (2.0324e-01) 
2023-05-25 00:25:12.343115: val Epoch: [3][38/72]	Time  0.921 ( 0.741)	Data  0.436 ( 0.383)	Loss 4.3609e-01 (2.0921e-01) 
2023-05-25 00:25:12.880747: val Epoch: [3][39/72]	Time  0.538 ( 0.735)	Data  0.221 ( 0.379)	Loss 1.4544e-01 (2.0761e-01) 
2023-05-25 00:25:13.399139: val Epoch: [3][40/72]	Time  0.518 ( 0.730)	Data  0.317 ( 0.378)	Loss 1.6806e-01 (2.0665e-01) 
2023-05-25 00:25:14.181553: val Epoch: [3][41/72]	Time  0.782 ( 0.731)	Data  0.489 ( 0.381)	Loss 1.1260e-01 (2.0441e-01) 
2023-05-25 00:25:14.900623: val Epoch: [3][42/72]	Time  0.719 ( 0.731)	Data  0.438 ( 0.382)	Loss 4.0930e-01 (2.0917e-01) 
2023-05-25 00:25:15.609914: val Epoch: [3][43/72]	Time  0.709 ( 0.731)	Data  0.336 ( 0.381)	Loss 9.2290e-02 (2.0652e-01) 
2023-05-25 00:25:16.432963: val Epoch: [3][44/72]	Time  0.823 ( 0.733)	Data  0.396 ( 0.381)	Loss 1.3403e-01 (2.0491e-01) 
2023-05-25 00:25:16.876331: val Epoch: [3][45/72]	Time  0.443 ( 0.726)	Data  0.172 ( 0.377)	Loss 1.2359e-01 (2.0314e-01) 
2023-05-25 00:25:17.633571: val Epoch: [3][46/72]	Time  0.757 ( 0.727)	Data  0.554 ( 0.380)	Loss 1.3826e-01 (2.0176e-01) 
2023-05-25 00:25:18.373823: val Epoch: [3][47/72]	Time  0.740 ( 0.727)	Data  0.310 ( 0.379)	Loss 1.1231e-01 (1.9989e-01) 
2023-05-25 00:25:19.252217: val Epoch: [3][48/72]	Time  0.878 ( 0.730)	Data  0.510 ( 0.382)	Loss 1.4693e-01 (1.9881e-01) 
2023-05-25 00:25:19.709772: val Epoch: [3][49/72]	Time  0.458 ( 0.725)	Data  0.091 ( 0.376)	Loss 1.1847e-01 (1.9721e-01) 
2023-05-25 00:25:20.801898: val Epoch: [3][50/72]	Time  1.092 ( 0.732)	Data  0.728 ( 0.383)	Loss 4.2076e-01 (2.0159e-01) 
2023-05-25 00:25:20.999194: val Epoch: [3][51/72]	Time  0.197 ( 0.722)	Data  0.001 ( 0.375)	Loss 1.8369e-01 (2.0125e-01) 
2023-05-25 00:25:22.203329: val Epoch: [3][52/72]	Time  1.204 ( 0.731)	Data  0.848 ( 0.384)	Loss 1.1302e-01 (1.9958e-01) 
2023-05-25 00:25:22.640582: val Epoch: [3][53/72]	Time  0.437 ( 0.726)	Data  0.035 ( 0.378)	Loss 4.2801e-01 (2.0381e-01) 
2023-05-25 00:25:23.767254: val Epoch: [3][54/72]	Time  1.127 ( 0.733)	Data  0.658 ( 0.383)	Loss 1.7647e-01 (2.0331e-01) 
2023-05-25 00:25:23.994391: val Epoch: [3][55/72]	Time  0.227 ( 0.724)	Data  0.001 ( 0.376)	Loss 5.7527e-01 (2.0996e-01) 
2023-05-25 00:25:25.186165: val Epoch: [3][56/72]	Time  1.192 ( 0.732)	Data  0.730 ( 0.382)	Loss 2.9893e-01 (2.1152e-01) 
2023-05-25 00:25:25.600523: val Epoch: [3][57/72]	Time  0.414 ( 0.727)	Data  0.001 ( 0.376)	Loss 4.8435e-01 (2.1622e-01) 
2023-05-25 00:25:26.380078: val Epoch: [3][58/72]	Time  0.780 ( 0.727)	Data  0.566 ( 0.379)	Loss 1.5191e-01 (2.1513e-01) 
2023-05-25 00:25:26.889452: val Epoch: [3][59/72]	Time  0.509 ( 0.724)	Data  0.085 ( 0.374)	Loss 1.2447e-01 (2.1362e-01) 
2023-05-25 00:25:27.947353: val Epoch: [3][60/72]	Time  1.058 ( 0.729)	Data  0.757 ( 0.380)	Loss 6.3005e-01 (2.2045e-01) 
2023-05-25 00:25:28.206611: val Epoch: [3][61/72]	Time  0.259 ( 0.722)	Data  0.001 ( 0.374)	Loss 2.2679e-01 (2.2055e-01) 
2023-05-25 00:25:29.505478: val Epoch: [3][62/72]	Time  1.299 ( 0.731)	Data  0.835 ( 0.381)	Loss 3.0047e-01 (2.2182e-01) 
2023-05-25 00:25:29.855788: val Epoch: [3][63/72]	Time  0.350 ( 0.725)	Data  0.016 ( 0.376)	Loss 2.6542e-01 (2.2250e-01) 
2023-05-25 00:25:31.038974: val Epoch: [3][64/72]	Time  1.183 ( 0.732)	Data  0.699 ( 0.381)	Loss 2.1869e-01 (2.2244e-01) 
2023-05-25 00:25:31.394463: val Epoch: [3][65/72]	Time  0.355 ( 0.726)	Data  0.001 ( 0.375)	Loss 1.8960e-01 (2.2194e-01) 
2023-05-25 00:25:32.262947: val Epoch: [3][66/72]	Time  0.868 ( 0.728)	Data  0.547 ( 0.378)	Loss 6.1103e-01 (2.2775e-01) 
2023-05-25 00:25:32.508468: val Epoch: [3][67/72]	Time  0.246 ( 0.721)	Data  0.003 ( 0.372)	Loss 4.2128e-01 (2.3060e-01) 
2023-05-25 00:25:33.544116: val Epoch: [3][68/72]	Time  1.036 ( 0.726)	Data  0.819 ( 0.379)	Loss 2.0483e-01 (2.3022e-01) 
2023-05-25 00:25:33.905536: val Epoch: [3][69/72]	Time  0.361 ( 0.721)	Data  0.073 ( 0.374)	Loss 3.2666e-01 (2.3160e-01) 
2023-05-25 00:25:35.213589: val Epoch: [3][70/72]	Time  1.308 ( 0.729)	Data  0.774 ( 0.380)	Loss 1.5022e-01 (2.3045e-01) 
2023-05-25 00:25:35.461787: val Epoch: [3][71/72]	Time  0.248 ( 0.722)	Data  0.001 ( 0.375)	Loss 2.0347e-01 (2.3008e-01) 
2023-05-25 00:25:35.743122: Epoch 3 :Val : ['ET : 0.6210584044456482', 'TC : 0.6003041863441467', 'WT : 0.7706420421600342'] 
2023-05-25 00:25:35.746243: Epoch 3 :Val : ['ET : 0.6210584044456482', 'TC : 0.6003041863441467', 'WT : 0.7706420421600342'] 
2023-05-25 00:25:35.749881: Saving the model with DSC 0.649951159954071 
2023-05-25 00:25:36.837440: Val epoch done in 54.36799599498045 s 
2023-05-25 00:25:36.849267: Batches per epoch:  193 
2023-05-25 00:25:41.441163: train Epoch: [4][  0/193]	Time  4.591 ( 4.591)	Data  3.195 ( 3.195)	Loss 2.2037e-01 (2.2037e-01) 
2023-05-25 00:25:42.612721: train Epoch: [4][  1/193]	Time  1.172 ( 2.881)	Data  0.001 ( 1.598)	Loss 1.6050e-01 (1.9043e-01) 
2023-05-25 00:25:43.866889: train Epoch: [4][  2/193]	Time  1.254 ( 2.339)	Data  0.220 ( 1.138)	Loss 1.9418e-01 (1.9168e-01) 
2023-05-25 00:25:45.154958: train Epoch: [4][  3/193]	Time  1.288 ( 2.076)	Data  0.001 ( 0.854)	Loss 1.8131e-01 (1.8909e-01) 
2023-05-25 00:25:46.635059: train Epoch: [4][  4/193]	Time  1.480 ( 1.957)	Data  0.465 ( 0.776)	Loss 6.1798e-02 (1.6363e-01) 
2023-05-25 00:25:47.755649: train Epoch: [4][  5/193]	Time  1.121 ( 1.818)	Data  0.001 ( 0.647)	Loss 4.6279e-01 (2.1349e-01) 
2023-05-25 00:25:49.584784: train Epoch: [4][  6/193]	Time  1.829 ( 1.819)	Data  0.698 ( 0.654)	Loss 9.5755e-02 (1.9667e-01) 
2023-05-25 00:25:50.654599: train Epoch: [4][  7/193]	Time  1.070 ( 1.726)	Data  0.002 ( 0.573)	Loss 2.5095e-01 (2.0346e-01) 
2023-05-25 00:25:52.333870: train Epoch: [4][  8/193]	Time  1.679 ( 1.720)	Data  0.707 ( 0.588)	Loss 1.6675e-01 (1.9938e-01) 
2023-05-25 00:25:53.300423: train Epoch: [4][  9/193]	Time  0.967 ( 1.645)	Data  0.001 ( 0.529)	Loss 1.6116e-01 (1.9556e-01) 
2023-05-25 00:25:55.399571: train Epoch: [4][ 10/193]	Time  2.099 ( 1.686)	Data  0.887 ( 0.562)	Loss 1.7776e-01 (1.9394e-01) 
2023-05-25 00:25:56.392073: train Epoch: [4][ 11/193]	Time  0.993 ( 1.628)	Data  0.001 ( 0.515)	Loss 1.0850e-01 (1.8682e-01) 
2023-05-25 00:25:58.212190: train Epoch: [4][ 12/193]	Time  1.820 ( 1.643)	Data  0.615 ( 0.523)	Loss 1.8993e-01 (1.8706e-01) 
2023-05-25 00:25:59.284281: train Epoch: [4][ 13/193]	Time  1.072 ( 1.602)	Data  0.001 ( 0.485)	Loss 1.4337e-01 (1.8394e-01) 
2023-05-25 00:26:00.857602: train Epoch: [4][ 14/193]	Time  1.573 ( 1.600)	Data  0.515 ( 0.487)	Loss 1.4002e-01 (1.8101e-01) 
2023-05-25 00:26:01.900396: train Epoch: [4][ 15/193]	Time  1.043 ( 1.566)	Data  0.001 ( 0.457)	Loss 2.5869e-01 (1.8586e-01) 
2023-05-25 00:26:03.698923: train Epoch: [4][ 16/193]	Time  1.799 ( 1.579)	Data  0.655 ( 0.469)	Loss 1.5536e-01 (1.8407e-01) 
2023-05-25 00:26:04.969502: train Epoch: [4][ 17/193]	Time  1.271 ( 1.562)	Data  0.001 ( 0.443)	Loss 1.9183e-01 (1.8450e-01) 
2023-05-25 00:26:06.332822: train Epoch: [4][ 18/193]	Time  1.363 ( 1.552)	Data  0.358 ( 0.438)	Loss 1.4497e-01 (1.8242e-01) 
2023-05-25 00:26:07.606849: train Epoch: [4][ 19/193]	Time  1.274 ( 1.538)	Data  0.001 ( 0.416)	Loss 1.7948e-01 (1.8227e-01) 
2023-05-25 00:26:09.242575: train Epoch: [4][ 20/193]	Time  1.636 ( 1.542)	Data  0.547 ( 0.423)	Loss 1.4705e-01 (1.8060e-01) 
2023-05-25 00:26:10.424327: train Epoch: [4][ 21/193]	Time  1.182 ( 1.526)	Data  0.001 ( 0.403)	Loss 1.9748e-01 (1.8136e-01) 
2023-05-25 00:26:11.970761: train Epoch: [4][ 22/193]	Time  1.546 ( 1.527)	Data  0.558 ( 0.410)	Loss 1.3723e-01 (1.7944e-01) 
2023-05-25 00:26:13.008587: train Epoch: [4][ 23/193]	Time  1.038 ( 1.507)	Data  0.001 ( 0.393)	Loss 1.4234e-01 (1.7790e-01) 
2023-05-25 00:26:14.894006: train Epoch: [4][ 24/193]	Time  1.885 ( 1.522)	Data  0.818 ( 0.410)	Loss 1.8734e-01 (1.7828e-01) 
2023-05-25 00:26:16.023210: train Epoch: [4][ 25/193]	Time  1.129 ( 1.507)	Data  0.001 ( 0.394)	Loss 1.5333e-01 (1.7732e-01) 
2023-05-25 00:26:17.719512: train Epoch: [4][ 26/193]	Time  1.696 ( 1.514)	Data  0.722 ( 0.406)	Loss 1.5534e-01 (1.7650e-01) 
2023-05-25 00:26:18.798472: train Epoch: [4][ 27/193]	Time  1.079 ( 1.498)	Data  0.001 ( 0.392)	Loss 1.4078e-01 (1.7523e-01) 
2023-05-25 00:26:20.612425: train Epoch: [4][ 28/193]	Time  1.814 ( 1.509)	Data  0.750 ( 0.404)	Loss 2.0055e-01 (1.7610e-01) 
2023-05-25 00:26:21.576537: train Epoch: [4][ 29/193]	Time  0.964 ( 1.491)	Data  0.001 ( 0.391)	Loss 2.0858e-01 (1.7718e-01) 
2023-05-25 00:26:23.598787: train Epoch: [4][ 30/193]	Time  2.022 ( 1.508)	Data  0.772 ( 0.403)	Loss 1.3807e-01 (1.7592e-01) 
2023-05-25 00:26:24.594962: train Epoch: [4][ 31/193]	Time  0.996 ( 1.492)	Data  0.001 ( 0.391)	Loss 1.5635e-01 (1.7531e-01) 
2023-05-25 00:26:26.330269: train Epoch: [4][ 32/193]	Time  1.735 ( 1.499)	Data  0.581 ( 0.396)	Loss 1.4335e-01 (1.7434e-01) 
2023-05-25 00:26:27.414911: train Epoch: [4][ 33/193]	Time  1.085 ( 1.487)	Data  0.001 ( 0.385)	Loss 1.1074e-01 (1.7247e-01) 
2023-05-25 00:26:28.945016: train Epoch: [4][ 34/193]	Time  1.530 ( 1.488)	Data  0.505 ( 0.388)	Loss 2.8034e-01 (1.7555e-01) 
2023-05-25 00:26:29.986183: train Epoch: [4][ 35/193]	Time  1.041 ( 1.476)	Data  0.001 ( 0.377)	Loss 2.0398e-01 (1.7634e-01) 
2023-05-25 00:26:32.056351: train Epoch: [4][ 36/193]	Time  2.070 ( 1.492)	Data  0.797 ( 0.389)	Loss 2.3750e-01 (1.7800e-01) 
2023-05-25 00:26:33.411700: train Epoch: [4][ 37/193]	Time  1.355 ( 1.488)	Data  0.001 ( 0.379)	Loss 1.1519e-01 (1.7634e-01) 
2023-05-25 00:26:34.613619: train Epoch: [4][ 38/193]	Time  1.202 ( 1.481)	Data  0.188 ( 0.374)	Loss 1.2269e-01 (1.7497e-01) 
2023-05-25 00:26:35.645925: train Epoch: [4][ 39/193]	Time  1.032 ( 1.470)	Data  0.001 ( 0.364)	Loss 1.8264e-01 (1.7516e-01) 
2023-05-25 00:26:37.448049: train Epoch: [4][ 40/193]	Time  1.802 ( 1.478)	Data  0.762 ( 0.374)	Loss 1.7689e-01 (1.7520e-01) 
2023-05-25 00:26:38.463153: train Epoch: [4][ 41/193]	Time  1.015 ( 1.467)	Data  0.001 ( 0.365)	Loss 2.1404e-01 (1.7613e-01) 
2023-05-25 00:26:40.303453: train Epoch: [4][ 42/193]	Time  1.840 ( 1.476)	Data  0.765 ( 0.374)	Loss 1.3568e-01 (1.7518e-01) 
2023-05-25 00:26:41.310029: train Epoch: [4][ 43/193]	Time  1.007 ( 1.465)	Data  0.001 ( 0.366)	Loss 2.3189e-01 (1.7647e-01) 
2023-05-25 00:26:43.110579: train Epoch: [4][ 44/193]	Time  1.801 ( 1.472)	Data  0.713 ( 0.374)	Loss 2.1926e-01 (1.7742e-01) 
2023-05-25 00:26:44.104710: train Epoch: [4][ 45/193]	Time  0.994 ( 1.462)	Data  0.001 ( 0.366)	Loss 1.4844e-01 (1.7679e-01) 
2023-05-25 00:26:46.195853: train Epoch: [4][ 46/193]	Time  2.091 ( 1.475)	Data  0.966 ( 0.378)	Loss 1.5405e-01 (1.7631e-01) 
2023-05-25 00:26:47.239668: train Epoch: [4][ 47/193]	Time  1.044 ( 1.466)	Data  0.001 ( 0.371)	Loss 1.4434e-01 (1.7564e-01) 
2023-05-25 00:26:49.164494: train Epoch: [4][ 48/193]	Time  1.925 ( 1.476)	Data  0.722 ( 0.378)	Loss 1.8871e-01 (1.7591e-01) 
2023-05-25 00:26:50.149656: train Epoch: [4][ 49/193]	Time  0.985 ( 1.466)	Data  0.001 ( 0.370)	Loss 1.5168e-01 (1.7543e-01) 
2023-05-25 00:26:51.808990: train Epoch: [4][ 50/193]	Time  1.659 ( 1.470)	Data  0.512 ( 0.373)	Loss 1.1964e-01 (1.7433e-01) 
2023-05-25 00:26:52.810611: train Epoch: [4][ 51/193]	Time  1.002 ( 1.461)	Data  0.001 ( 0.366)	Loss 2.0404e-01 (1.7490e-01) 
2023-05-25 00:26:54.251363: train Epoch: [4][ 52/193]	Time  1.441 ( 1.460)	Data  0.417 ( 0.367)	Loss 1.4709e-01 (1.7438e-01) 
2023-05-25 00:26:55.391022: train Epoch: [4][ 53/193]	Time  1.140 ( 1.454)	Data  0.001 ( 0.360)	Loss 4.6639e-01 (1.7979e-01) 
2023-05-25 00:26:57.107186: train Epoch: [4][ 54/193]	Time  1.716 ( 1.459)	Data  0.501 ( 0.363)	Loss 1.1523e-01 (1.7861e-01) 
2023-05-25 00:26:58.282353: train Epoch: [4][ 55/193]	Time  1.175 ( 1.454)	Data  0.001 ( 0.356)	Loss 1.4632e-01 (1.7804e-01) 
2023-05-25 00:26:59.542412: train Epoch: [4][ 56/193]	Time  1.260 ( 1.451)	Data  0.251 ( 0.354)	Loss 1.4476e-01 (1.7745e-01) 
2023-05-25 00:27:00.512234: train Epoch: [4][ 57/193]	Time  0.970 ( 1.442)	Data  0.001 ( 0.348)	Loss 1.3971e-01 (1.7680e-01) 
2023-05-25 00:27:02.382544: train Epoch: [4][ 58/193]	Time  1.870 ( 1.450)	Data  0.843 ( 0.357)	Loss 3.3610e-01 (1.7950e-01) 
2023-05-25 00:27:03.478719: train Epoch: [4][ 59/193]	Time  1.096 ( 1.444)	Data  0.001 ( 0.351)	Loss 1.4844e-01 (1.7898e-01) 
2023-05-25 00:27:05.154776: train Epoch: [4][ 60/193]	Time  1.676 ( 1.448)	Data  0.542 ( 0.354)	Loss 1.4452e-01 (1.7842e-01) 
2023-05-25 00:27:06.155531: train Epoch: [4][ 61/193]	Time  1.001 ( 1.440)	Data  0.001 ( 0.348)	Loss 1.4651e-01 (1.7790e-01) 
2023-05-25 00:27:08.076313: train Epoch: [4][ 62/193]	Time  1.921 ( 1.448)	Data  0.609 ( 0.352)	Loss 1.7127e-01 (1.7780e-01) 
2023-05-25 00:27:09.118531: train Epoch: [4][ 63/193]	Time  1.042 ( 1.442)	Data  0.001 ( 0.347)	Loss 1.4873e-01 (1.7734e-01) 
2023-05-25 00:27:10.859797: train Epoch: [4][ 64/193]	Time  1.741 ( 1.446)	Data  0.305 ( 0.346)	Loss 1.4584e-01 (1.7686e-01) 
2023-05-25 00:27:12.008926: train Epoch: [4][ 65/193]	Time  1.149 ( 1.442)	Data  0.001 ( 0.341)	Loss 9.9935e-02 (1.7569e-01) 
2023-05-25 00:27:13.553281: train Epoch: [4][ 66/193]	Time  1.544 ( 1.443)	Data  0.183 ( 0.339)	Loss 2.2085e-01 (1.7637e-01) 
2023-05-25 00:27:14.590961: train Epoch: [4][ 67/193]	Time  1.038 ( 1.437)	Data  0.001 ( 0.334)	Loss 1.8943e-01 (1.7656e-01) 
2023-05-25 00:27:16.119723: train Epoch: [4][ 68/193]	Time  1.529 ( 1.439)	Data  0.439 ( 0.335)	Loss 2.0029e-01 (1.7690e-01) 
2023-05-25 00:27:17.350625: train Epoch: [4][ 69/193]	Time  1.231 ( 1.436)	Data  0.001 ( 0.330)	Loss 1.0985e-01 (1.7595e-01) 
2023-05-25 00:27:18.780160: train Epoch: [4][ 70/193]	Time  1.430 ( 1.436)	Data  0.411 ( 0.331)	Loss 1.9493e-01 (1.7621e-01) 
2023-05-25 00:27:19.932575: train Epoch: [4][ 71/193]	Time  1.152 ( 1.432)	Data  0.001 ( 0.327)	Loss 1.5465e-01 (1.7591e-01) 
2023-05-25 00:27:21.565530: train Epoch: [4][ 72/193]	Time  1.633 ( 1.434)	Data  0.538 ( 0.330)	Loss 2.3708e-01 (1.7675e-01) 
2023-05-25 00:27:22.705393: train Epoch: [4][ 73/193]	Time  1.140 ( 1.430)	Data  0.001 ( 0.325)	Loss 1.5169e-01 (1.7641e-01) 
2023-05-25 00:27:24.287426: train Epoch: [4][ 74/193]	Time  1.582 ( 1.432)	Data  0.579 ( 0.329)	Loss 1.6925e-01 (1.7632e-01) 
2023-05-25 00:27:25.305712: train Epoch: [4][ 75/193]	Time  1.018 ( 1.427)	Data  0.001 ( 0.324)	Loss 1.6230e-01 (1.7613e-01) 
2023-05-25 00:27:27.249951: train Epoch: [4][ 76/193]	Time  1.944 ( 1.434)	Data  0.876 ( 0.332)	Loss 2.8822e-01 (1.7759e-01) 
2023-05-25 00:27:28.288638: train Epoch: [4][ 77/193]	Time  1.039 ( 1.429)	Data  0.002 ( 0.327)	Loss 1.3779e-01 (1.7708e-01) 
2023-05-25 00:27:30.177697: train Epoch: [4][ 78/193]	Time  1.889 ( 1.435)	Data  0.620 ( 0.331)	Loss 1.4335e-01 (1.7665e-01) 
2023-05-25 00:27:31.133323: train Epoch: [4][ 79/193]	Time  0.956 ( 1.429)	Data  0.001 ( 0.327)	Loss 1.3051e-01 (1.7608e-01) 
2023-05-25 00:27:32.971449: train Epoch: [4][ 80/193]	Time  1.838 ( 1.434)	Data  0.544 ( 0.330)	Loss 2.1484e-01 (1.7655e-01) 
2023-05-25 00:27:34.094522: train Epoch: [4][ 81/193]	Time  1.123 ( 1.430)	Data  0.001 ( 0.326)	Loss 2.0964e-01 (1.7696e-01) 
2023-05-25 00:27:35.568167: train Epoch: [4][ 82/193]	Time  1.474 ( 1.430)	Data  0.302 ( 0.325)	Loss 1.5141e-01 (1.7665e-01) 
2023-05-25 00:27:36.646903: train Epoch: [4][ 83/193]	Time  1.079 ( 1.426)	Data  0.001 ( 0.321)	Loss 1.5755e-01 (1.7642e-01) 
2023-05-25 00:27:38.273556: train Epoch: [4][ 84/193]	Time  1.627 ( 1.429)	Data  0.519 ( 0.324)	Loss 1.4640e-01 (1.7607e-01) 
2023-05-25 00:27:39.392836: train Epoch: [4][ 85/193]	Time  1.119 ( 1.425)	Data  0.001 ( 0.320)	Loss 1.0835e-01 (1.7528e-01) 
2023-05-25 00:27:40.898624: train Epoch: [4][ 86/193]	Time  1.506 ( 1.426)	Data  0.453 ( 0.322)	Loss 2.3175e-01 (1.7593e-01) 
2023-05-25 00:27:42.040251: train Epoch: [4][ 87/193]	Time  1.142 ( 1.423)	Data  0.001 ( 0.318)	Loss 1.2643e-01 (1.7537e-01) 
2023-05-25 00:27:43.656401: train Epoch: [4][ 88/193]	Time  1.616 ( 1.425)	Data  0.480 ( 0.320)	Loss 1.9551e-01 (1.7559e-01) 
2023-05-25 00:27:44.631416: train Epoch: [4][ 89/193]	Time  0.975 ( 1.420)	Data  0.001 ( 0.316)	Loss 1.5385e-01 (1.7535e-01) 
2023-05-25 00:27:46.197071: train Epoch: [4][ 90/193]	Time  1.566 ( 1.421)	Data  0.604 ( 0.319)	Loss 1.8358e-01 (1.7544e-01) 
2023-05-25 00:27:47.141318: train Epoch: [4][ 91/193]	Time  0.944 ( 1.416)	Data  0.001 ( 0.316)	Loss 1.7774e-01 (1.7547e-01) 
2023-05-25 00:27:48.955470: train Epoch: [4][ 92/193]	Time  1.814 ( 1.420)	Data  0.889 ( 0.322)	Loss 1.6809e-01 (1.7539e-01) 
2023-05-25 00:27:49.937675: train Epoch: [4][ 93/193]	Time  0.982 ( 1.416)	Data  0.001 ( 0.319)	Loss 1.2376e-01 (1.7484e-01) 
2023-05-25 00:27:51.852416: train Epoch: [4][ 94/193]	Time  1.915 ( 1.421)	Data  0.753 ( 0.323)	Loss 1.9133e-01 (1.7501e-01) 
2023-05-25 00:27:52.903222: train Epoch: [4][ 95/193]	Time  1.051 ( 1.417)	Data  0.001 ( 0.320)	Loss 1.3361e-01 (1.7458e-01) 
2023-05-25 00:27:54.813219: train Epoch: [4][ 96/193]	Time  1.910 ( 1.422)	Data  0.641 ( 0.323)	Loss 2.2417e-01 (1.7509e-01) 
2023-05-25 00:27:55.935655: train Epoch: [4][ 97/193]	Time  1.122 ( 1.419)	Data  0.001 ( 0.320)	Loss 1.6188e-01 (1.7496e-01) 
2023-05-25 00:27:57.357842: train Epoch: [4][ 98/193]	Time  1.422 ( 1.419)	Data  0.318 ( 0.320)	Loss 9.9660e-02 (1.7420e-01) 
2023-05-25 00:27:58.733465: train Epoch: [4][ 99/193]	Time  1.376 ( 1.419)	Data  0.001 ( 0.317)	Loss 1.3255e-01 (1.7378e-01) 
2023-05-25 00:27:59.905011: train Epoch: [4][100/193]	Time  1.172 ( 1.416)	Data  0.186 ( 0.315)	Loss 1.2365e-01 (1.7328e-01) 
2023-05-25 00:28:01.033385: train Epoch: [4][101/193]	Time  1.128 ( 1.414)	Data  0.125 ( 0.313)	Loss 2.1096e-01 (1.7365e-01) 
2023-05-25 00:28:02.943107: train Epoch: [4][102/193]	Time  1.910 ( 1.418)	Data  0.688 ( 0.317)	Loss 1.2097e-01 (1.7314e-01) 
2023-05-25 00:28:04.037834: train Epoch: [4][103/193]	Time  1.095 ( 1.415)	Data  0.016 ( 0.314)	Loss 1.6377e-01 (1.7305e-01) 
2023-05-25 00:28:05.776576: train Epoch: [4][104/193]	Time  1.739 ( 1.418)	Data  0.519 ( 0.316)	Loss 2.1083e-01 (1.7341e-01) 
2023-05-25 00:28:06.789237: train Epoch: [4][105/193]	Time  1.013 ( 1.415)	Data  0.001 ( 0.313)	Loss 1.3788e-01 (1.7308e-01) 
2023-05-25 00:28:08.673156: train Epoch: [4][106/193]	Time  1.884 ( 1.419)	Data  0.518 ( 0.315)	Loss 1.3294e-01 (1.7270e-01) 
2023-05-25 00:28:09.753222: train Epoch: [4][107/193]	Time  1.080 ( 1.416)	Data  0.001 ( 0.312)	Loss 2.3623e-01 (1.7329e-01) 
2023-05-25 00:28:11.445655: train Epoch: [4][108/193]	Time  1.692 ( 1.418)	Data  0.365 ( 0.313)	Loss 1.2848e-01 (1.7288e-01) 
2023-05-25 00:28:12.529490: train Epoch: [4][109/193]	Time  1.084 ( 1.415)	Data  0.003 ( 0.310)	Loss 1.2791e-01 (1.7247e-01) 
2023-05-25 00:28:13.951178: train Epoch: [4][110/193]	Time  1.422 ( 1.415)	Data  0.418 ( 0.311)	Loss 1.5370e-01 (1.7230e-01) 
2023-05-25 00:28:15.245435: train Epoch: [4][111/193]	Time  1.294 ( 1.414)	Data  0.066 ( 0.309)	Loss 1.6863e-01 (1.7227e-01) 
2023-05-25 00:28:17.046320: train Epoch: [4][112/193]	Time  1.801 ( 1.418)	Data  0.606 ( 0.311)	Loss 1.2995e-01 (1.7189e-01) 
2023-05-25 00:28:18.141223: train Epoch: [4][113/193]	Time  1.095 ( 1.415)	Data  0.001 ( 0.309)	Loss 1.1430e-01 (1.7139e-01) 
2023-05-25 00:28:19.558120: train Epoch: [4][114/193]	Time  1.417 ( 1.415)	Data  0.432 ( 0.310)	Loss 1.0524e-01 (1.7081e-01) 
2023-05-25 00:28:20.728968: train Epoch: [4][115/193]	Time  1.171 ( 1.413)	Data  0.151 ( 0.308)	Loss 1.7996e-01 (1.7089e-01) 
2023-05-25 00:28:22.529806: train Epoch: [4][116/193]	Time  1.801 ( 1.416)	Data  0.662 ( 0.311)	Loss 1.4512e-01 (1.7067e-01) 
2023-05-25 00:28:23.670887: train Epoch: [4][117/193]	Time  1.141 ( 1.414)	Data  0.001 ( 0.309)	Loss 1.0668e-01 (1.7013e-01) 
2023-05-25 00:28:25.414859: train Epoch: [4][118/193]	Time  1.744 ( 1.417)	Data  0.479 ( 0.310)	Loss 1.4625e-01 (1.6993e-01) 
2023-05-25 00:28:26.433706: train Epoch: [4][119/193]	Time  1.019 ( 1.413)	Data  0.001 ( 0.308)	Loss 2.2948e-01 (1.7043e-01) 
2023-05-25 00:28:28.009005: train Epoch: [4][120/193]	Time  1.575 ( 1.415)	Data  0.566 ( 0.310)	Loss 1.7066e-01 (1.7043e-01) 
2023-05-25 00:28:29.004237: train Epoch: [4][121/193]	Time  0.995 ( 1.411)	Data  0.014 ( 0.307)	Loss 1.1895e-01 (1.7001e-01) 
2023-05-25 00:28:31.196642: train Epoch: [4][122/193]	Time  2.192 ( 1.417)	Data  0.895 ( 0.312)	Loss 1.4187e-01 (1.6978e-01) 
2023-05-25 00:28:32.241653: train Epoch: [4][123/193]	Time  1.045 ( 1.414)	Data  0.001 ( 0.310)	Loss 1.4429e-01 (1.6957e-01) 
2023-05-25 00:28:33.792546: train Epoch: [4][124/193]	Time  1.551 ( 1.416)	Data  0.448 ( 0.311)	Loss 1.3159e-01 (1.6927e-01) 
2023-05-25 00:28:35.011019: train Epoch: [4][125/193]	Time  1.218 ( 1.414)	Data  0.001 ( 0.308)	Loss 2.0178e-01 (1.6953e-01) 
2023-05-25 00:28:36.736896: train Epoch: [4][126/193]	Time  1.726 ( 1.416)	Data  0.543 ( 0.310)	Loss 9.8635e-02 (1.6897e-01) 
2023-05-25 00:28:37.744653: train Epoch: [4][127/193]	Time  1.008 ( 1.413)	Data  0.001 ( 0.308)	Loss 2.0471e-01 (1.6925e-01) 
2023-05-25 00:28:39.420875: train Epoch: [4][128/193]	Time  1.676 ( 1.415)	Data  0.692 ( 0.311)	Loss 2.3735e-01 (1.6977e-01) 
2023-05-25 00:28:40.457477: train Epoch: [4][129/193]	Time  1.037 ( 1.412)	Data  0.047 ( 0.309)	Loss 1.2204e-01 (1.6941e-01) 
2023-05-25 00:28:42.405549: train Epoch: [4][130/193]	Time  1.948 ( 1.416)	Data  0.878 ( 0.313)	Loss 1.7724e-01 (1.6947e-01) 
2023-05-25 00:28:43.471265: train Epoch: [4][131/193]	Time  1.066 ( 1.414)	Data  0.002 ( 0.311)	Loss 1.3564e-01 (1.6921e-01) 
2023-05-25 00:28:45.313484: train Epoch: [4][132/193]	Time  1.842 ( 1.417)	Data  0.848 ( 0.315)	Loss 1.3721e-01 (1.6897e-01) 
2023-05-25 00:28:46.317911: train Epoch: [4][133/193]	Time  1.004 ( 1.414)	Data  0.001 ( 0.312)	Loss 2.4808e-01 (1.6956e-01) 
2023-05-25 00:28:48.130451: train Epoch: [4][134/193]	Time  1.813 ( 1.417)	Data  0.819 ( 0.316)	Loss 1.6293e-01 (1.6951e-01) 
2023-05-25 00:28:49.110469: train Epoch: [4][135/193]	Time  0.980 ( 1.414)	Data  0.001 ( 0.314)	Loss 1.8576e-01 (1.6963e-01) 
2023-05-25 00:28:51.068916: train Epoch: [4][136/193]	Time  1.958 ( 1.418)	Data  0.914 ( 0.318)	Loss 2.1999e-01 (1.7000e-01) 
2023-05-25 00:28:52.039122: train Epoch: [4][137/193]	Time  0.970 ( 1.414)	Data  0.001 ( 0.316)	Loss 1.3560e-01 (1.6975e-01) 
2023-05-25 00:28:53.996136: train Epoch: [4][138/193]	Time  1.957 ( 1.418)	Data  0.911 ( 0.320)	Loss 8.6136e-02 (1.6915e-01) 
2023-05-25 00:28:54.964836: train Epoch: [4][139/193]	Time  0.969 ( 1.415)	Data  0.001 ( 0.318)	Loss 3.6716e-01 (1.7056e-01) 
2023-05-25 00:28:56.996549: train Epoch: [4][140/193]	Time  2.032 ( 1.419)	Data  0.874 ( 0.322)	Loss 1.3879e-01 (1.7034e-01) 
2023-05-25 00:28:58.015019: train Epoch: [4][141/193]	Time  1.018 ( 1.417)	Data  0.001 ( 0.319)	Loss 3.6896e-01 (1.7174e-01) 
2023-05-25 00:28:59.768495: train Epoch: [4][142/193]	Time  1.753 ( 1.419)	Data  0.536 ( 0.321)	Loss 1.2352e-01 (1.7140e-01) 
2023-05-25 00:29:00.781852: train Epoch: [4][143/193]	Time  1.013 ( 1.416)	Data  0.001 ( 0.319)	Loss 1.5353e-01 (1.7127e-01) 
2023-05-25 00:29:02.593032: train Epoch: [4][144/193]	Time  1.811 ( 1.419)	Data  0.618 ( 0.321)	Loss 9.9651e-02 (1.7078e-01) 
2023-05-25 00:29:03.540574: train Epoch: [4][145/193]	Time  0.948 ( 1.416)	Data  0.001 ( 0.319)	Loss 1.9353e-01 (1.7094e-01) 
2023-05-25 00:29:05.092454: train Epoch: [4][146/193]	Time  1.552 ( 1.417)	Data  0.589 ( 0.320)	Loss 2.2598e-01 (1.7131e-01) 
2023-05-25 00:29:06.131219: train Epoch: [4][147/193]	Time  1.039 ( 1.414)	Data  0.001 ( 0.318)	Loss 1.2684e-01 (1.7101e-01) 
2023-05-25 00:29:08.108073: train Epoch: [4][148/193]	Time  1.977 ( 1.418)	Data  0.881 ( 0.322)	Loss 1.6335e-01 (1.7096e-01) 
2023-05-25 00:29:09.249403: train Epoch: [4][149/193]	Time  1.141 ( 1.416)	Data  0.003 ( 0.320)	Loss 1.7908e-01 (1.7101e-01) 
2023-05-25 00:29:11.001257: train Epoch: [4][150/193]	Time  1.752 ( 1.418)	Data  0.608 ( 0.322)	Loss 2.2591e-01 (1.7138e-01) 
2023-05-25 00:29:12.186570: train Epoch: [4][151/193]	Time  1.185 ( 1.417)	Data  0.001 ( 0.320)	Loss 1.6350e-01 (1.7132e-01) 
2023-05-25 00:29:13.649512: train Epoch: [4][152/193]	Time  1.463 ( 1.417)	Data  0.416 ( 0.320)	Loss 1.0683e-01 (1.7090e-01) 
2023-05-25 00:29:14.705103: train Epoch: [4][153/193]	Time  1.056 ( 1.415)	Data  0.001 ( 0.318)	Loss 1.5608e-01 (1.7081e-01) 
2023-05-25 00:29:16.340101: train Epoch: [4][154/193]	Time  1.635 ( 1.416)	Data  0.522 ( 0.320)	Loss 1.4794e-01 (1.7066e-01) 
2023-05-25 00:29:17.338882: train Epoch: [4][155/193]	Time  0.999 ( 1.413)	Data  0.001 ( 0.318)	Loss 1.9614e-01 (1.7082e-01) 
2023-05-25 00:29:19.292845: train Epoch: [4][156/193]	Time  1.954 ( 1.417)	Data  0.521 ( 0.319)	Loss 6.4760e-01 (1.7386e-01) 
2023-05-25 00:29:20.403050: train Epoch: [4][157/193]	Time  1.110 ( 1.415)	Data  0.001 ( 0.317)	Loss 1.5692e-01 (1.7375e-01) 
2023-05-25 00:29:21.943008: train Epoch: [4][158/193]	Time  1.540 ( 1.416)	Data  0.204 ( 0.316)	Loss 2.3218e-01 (1.7412e-01) 
2023-05-25 00:29:23.063091: train Epoch: [4][159/193]	Time  1.120 ( 1.414)	Data  0.001 ( 0.314)	Loss 1.3836e-01 (1.7390e-01) 
2023-05-25 00:29:24.421517: train Epoch: [4][160/193]	Time  1.358 ( 1.413)	Data  0.328 ( 0.314)	Loss 2.2918e-01 (1.7424e-01) 
2023-05-25 00:29:25.602474: train Epoch: [4][161/193]	Time  1.181 ( 1.412)	Data  0.128 ( 0.313)	Loss 2.4875e-01 (1.7470e-01) 
2023-05-25 00:29:27.221597: train Epoch: [4][162/193]	Time  1.619 ( 1.413)	Data  0.536 ( 0.314)	Loss 1.0082e-01 (1.7425e-01) 
2023-05-25 00:29:28.425038: train Epoch: [4][163/193]	Time  1.203 ( 1.412)	Data  0.167 ( 0.314)	Loss 3.8873e-01 (1.7555e-01) 
2023-05-25 00:29:30.020377: train Epoch: [4][164/193]	Time  1.595 ( 1.413)	Data  0.514 ( 0.315)	Loss 2.3038e-01 (1.7589e-01) 
2023-05-25 00:29:31.228589: train Epoch: [4][165/193]	Time  1.208 ( 1.412)	Data  0.173 ( 0.314)	Loss 4.5021e-01 (1.7754e-01) 
2023-05-25 00:29:32.907719: train Epoch: [4][166/193]	Time  1.679 ( 1.414)	Data  0.530 ( 0.315)	Loss 1.3994e-01 (1.7731e-01) 
2023-05-25 00:29:34.021016: train Epoch: [4][167/193]	Time  1.113 ( 1.412)	Data  0.129 ( 0.314)	Loss 1.8790e-01 (1.7738e-01) 
2023-05-25 00:29:35.596197: train Epoch: [4][168/193]	Time  1.575 ( 1.413)	Data  0.621 ( 0.316)	Loss 2.1830e-01 (1.7762e-01) 
2023-05-25 00:29:36.855969: train Epoch: [4][169/193]	Time  1.260 ( 1.412)	Data  0.280 ( 0.316)	Loss 1.3672e-01 (1.7738e-01) 
2023-05-25 00:29:38.617779: train Epoch: [4][170/193]	Time  1.762 ( 1.414)	Data  0.740 ( 0.318)	Loss 1.7825e-01 (1.7738e-01) 
2023-05-25 00:29:39.618992: train Epoch: [4][171/193]	Time  1.001 ( 1.411)	Data  0.001 ( 0.316)	Loss 1.8730e-01 (1.7744e-01) 
2023-05-25 00:29:41.696424: train Epoch: [4][172/193]	Time  2.077 ( 1.415)	Data  0.886 ( 0.320)	Loss 2.3657e-01 (1.7778e-01) 
2023-05-25 00:29:42.669031: train Epoch: [4][173/193]	Time  0.973 ( 1.413)	Data  0.001 ( 0.318)	Loss 2.1896e-01 (1.7802e-01) 
2023-05-25 00:29:44.270290: train Epoch: [4][174/193]	Time  1.601 ( 1.414)	Data  0.702 ( 0.320)	Loss 1.3610e-01 (1.7778e-01) 
2023-05-25 00:29:45.216561: train Epoch: [4][175/193]	Time  0.946 ( 1.411)	Data  0.001 ( 0.318)	Loss 9.6476e-02 (1.7732e-01) 
2023-05-25 00:29:47.221277: train Epoch: [4][176/193]	Time  2.005 ( 1.415)	Data  1.068 ( 0.322)	Loss 2.0373e-01 (1.7747e-01) 
2023-05-25 00:29:48.363388: train Epoch: [4][177/193]	Time  1.142 ( 1.413)	Data  0.001 ( 0.321)	Loss 2.3423e-01 (1.7779e-01) 
2023-05-25 00:29:50.396217: train Epoch: [4][178/193]	Time  2.033 ( 1.416)	Data  0.750 ( 0.323)	Loss 2.8723e-01 (1.7840e-01) 
2023-05-25 00:29:51.523886: train Epoch: [4][179/193]	Time  1.128 ( 1.415)	Data  0.001 ( 0.321)	Loss 2.5554e-01 (1.7883e-01) 
2023-05-25 00:29:52.917288: train Epoch: [4][180/193]	Time  1.393 ( 1.415)	Data  0.362 ( 0.321)	Loss 1.1561e-01 (1.7848e-01) 
2023-05-25 00:29:54.003735: train Epoch: [4][181/193]	Time  1.086 ( 1.413)	Data  0.001 ( 0.320)	Loss 1.5833e-01 (1.7837e-01) 
2023-05-25 00:29:56.004844: train Epoch: [4][182/193]	Time  2.001 ( 1.416)	Data  0.818 ( 0.322)	Loss 1.6565e-01 (1.7830e-01) 
2023-05-25 00:29:57.060852: train Epoch: [4][183/193]	Time  1.056 ( 1.414)	Data  0.001 ( 0.321)	Loss 2.5279e-01 (1.7870e-01) 
2023-05-25 00:29:58.951762: train Epoch: [4][184/193]	Time  1.891 ( 1.417)	Data  0.623 ( 0.322)	Loss 1.2066e-01 (1.7839e-01) 
2023-05-25 00:30:00.021121: train Epoch: [4][185/193]	Time  1.069 ( 1.415)	Data  0.001 ( 0.321)	Loss 2.1714e-01 (1.7860e-01) 
2023-05-25 00:30:01.789967: train Epoch: [4][186/193]	Time  1.769 ( 1.417)	Data  0.615 ( 0.322)	Loss 1.3841e-01 (1.7838e-01) 
2023-05-25 00:30:02.969268: train Epoch: [4][187/193]	Time  1.179 ( 1.416)	Data  0.001 ( 0.320)	Loss 1.9787e-01 (1.7848e-01) 
2023-05-25 00:30:04.766001: train Epoch: [4][188/193]	Time  1.797 ( 1.418)	Data  0.572 ( 0.322)	Loss 1.3713e-01 (1.7827e-01) 
2023-05-25 00:30:05.981656: train Epoch: [4][189/193]	Time  1.216 ( 1.416)	Data  0.001 ( 0.320)	Loss 4.4634e-01 (1.7968e-01) 
2023-05-25 00:30:07.525176: train Epoch: [4][190/193]	Time  1.544 ( 1.417)	Data  0.349 ( 0.320)	Loss 2.6808e-01 (1.8014e-01) 
2023-05-25 00:30:08.614874: train Epoch: [4][191/193]	Time  1.090 ( 1.415)	Data  0.001 ( 0.319)	Loss 1.1997e-01 (1.7983e-01) 
2023-05-25 00:30:09.622156: train Epoch: [4][192/193]	Time  1.007 ( 1.413)	Data  0.001 ( 0.317)	Loss 2.1438e-01 (1.8001e-01) 
2023-05-25 00:30:09.681668: Train Epoch done in 272.83257463003974 s 
2023-05-25 00:30:12.917599: val Epoch: [4][ 0/72]	Time  2.282 ( 2.282)	Data  1.685 ( 1.685)	Loss 1.5473e-01 (1.5473e-01) 
2023-05-25 00:30:13.272474: val Epoch: [4][ 1/72]	Time  0.355 ( 1.318)	Data  0.002 ( 0.844)	Loss 2.4888e-01 (2.0180e-01) 
2023-05-25 00:30:13.981229: val Epoch: [4][ 2/72]	Time  0.709 ( 1.115)	Data  0.506 ( 0.731)	Loss 1.9715e-01 (2.0025e-01) 
2023-05-25 00:30:14.314270: val Epoch: [4][ 3/72]	Time  0.333 ( 0.920)	Data  0.001 ( 0.549)	Loss 9.5118e-02 (1.7397e-01) 
2023-05-25 00:30:15.434025: val Epoch: [4][ 4/72]	Time  1.120 ( 0.960)	Data  0.864 ( 0.612)	Loss 2.6747e-01 (1.9267e-01) 
2023-05-25 00:30:15.685443: val Epoch: [4][ 5/72]	Time  0.251 ( 0.842)	Data  0.001 ( 0.510)	Loss 1.6157e-01 (1.8749e-01) 
2023-05-25 00:30:17.364084: val Epoch: [4][ 6/72]	Time  1.679 ( 0.961)	Data  0.982 ( 0.577)	Loss 4.6531e-01 (2.2718e-01) 
2023-05-25 00:30:17.716090: val Epoch: [4][ 7/72]	Time  0.352 ( 0.885)	Data  0.001 ( 0.505)	Loss 1.5872e-01 (2.1862e-01) 
2023-05-25 00:30:18.320107: val Epoch: [4][ 8/72]	Time  0.604 ( 0.854)	Data  0.413 ( 0.495)	Loss 1.1492e-01 (2.0710e-01) 
2023-05-25 00:30:18.893705: val Epoch: [4][ 9/72]	Time  0.574 ( 0.826)	Data  0.001 ( 0.446)	Loss 1.2335e-01 (1.9872e-01) 
2023-05-25 00:30:19.857962: val Epoch: [4][10/72]	Time  0.964 ( 0.838)	Data  0.681 ( 0.467)	Loss 2.1735e-01 (2.0042e-01) 
2023-05-25 00:30:20.212872: val Epoch: [4][11/72]	Time  0.355 ( 0.798)	Data  0.001 ( 0.428)	Loss 2.5043e-01 (2.0458e-01) 
2023-05-25 00:30:21.392222: val Epoch: [4][12/72]	Time  1.179 ( 0.827)	Data  0.831 ( 0.459)	Loss 2.2387e-01 (2.0607e-01) 
2023-05-25 00:30:21.650096: val Epoch: [4][13/72]	Time  0.258 ( 0.787)	Data  0.001 ( 0.426)	Loss 3.0874e-01 (2.1340e-01) 
2023-05-25 00:30:22.822673: val Epoch: [4][14/72]	Time  1.173 ( 0.812)	Data  0.840 ( 0.454)	Loss 4.2784e-01 (2.2770e-01) 
2023-05-25 00:30:23.128785: val Epoch: [4][15/72]	Time  0.306 ( 0.781)	Data  0.001 ( 0.426)	Loss 1.8212e-01 (2.2485e-01) 
2023-05-25 00:30:24.387112: val Epoch: [4][16/72]	Time  1.258 ( 0.809)	Data  0.839 ( 0.450)	Loss 1.1841e-01 (2.1859e-01) 
2023-05-25 00:30:24.749281: val Epoch: [4][17/72]	Time  0.362 ( 0.784)	Data  0.001 ( 0.425)	Loss 1.0500e-01 (2.1228e-01) 
2023-05-25 00:30:25.914611: val Epoch: [4][18/72]	Time  1.165 ( 0.804)	Data  0.701 ( 0.440)	Loss 4.4934e-01 (2.2475e-01) 
2023-05-25 00:30:26.211623: val Epoch: [4][19/72]	Time  0.297 ( 0.779)	Data  0.001 ( 0.418)	Loss 1.3536e-01 (2.2028e-01) 
2023-05-25 00:30:27.160712: val Epoch: [4][20/72]	Time  0.949 ( 0.787)	Data  0.676 ( 0.430)	Loss 2.2410e-01 (2.2047e-01) 
2023-05-25 00:30:27.366099: val Epoch: [4][21/72]	Time  0.205 ( 0.760)	Data  0.001 ( 0.410)	Loss 5.2304e-01 (2.3422e-01) 
2023-05-25 00:30:28.790696: val Epoch: [4][22/72]	Time  1.425 ( 0.789)	Data  1.106 ( 0.441)	Loss 3.9565e-01 (2.4124e-01) 
2023-05-25 00:30:29.235672: val Epoch: [4][23/72]	Time  0.445 ( 0.775)	Data  0.001 ( 0.422)	Loss 9.7679e-02 (2.3526e-01) 
2023-05-25 00:30:30.228901: val Epoch: [4][24/72]	Time  0.993 ( 0.784)	Data  0.684 ( 0.433)	Loss 1.7041e-01 (2.3266e-01) 
2023-05-25 00:30:30.540839: val Epoch: [4][25/72]	Time  0.312 ( 0.766)	Data  0.001 ( 0.416)	Loss 2.5480e-01 (2.3351e-01) 
2023-05-25 00:30:31.907267: val Epoch: [4][26/72]	Time  1.366 ( 0.788)	Data  0.929 ( 0.435)	Loss 2.5371e-01 (2.3426e-01) 
2023-05-25 00:30:32.161967: val Epoch: [4][27/72]	Time  0.255 ( 0.769)	Data  0.001 ( 0.420)	Loss 2.8279e-01 (2.3599e-01) 
2023-05-25 00:30:33.207066: val Epoch: [4][28/72]	Time  1.045 ( 0.778)	Data  0.768 ( 0.432)	Loss 2.0395e-01 (2.3489e-01) 
2023-05-25 00:30:33.382526: val Epoch: [4][29/72]	Time  0.175 ( 0.758)	Data  0.001 ( 0.417)	Loss 1.6801e-01 (2.3266e-01) 
2023-05-25 00:30:34.667928: val Epoch: [4][30/72]	Time  1.285 ( 0.775)	Data  0.940 ( 0.434)	Loss 1.2789e-01 (2.2928e-01) 
2023-05-25 00:30:35.054184: val Epoch: [4][31/72]	Time  0.386 ( 0.763)	Data  0.001 ( 0.421)	Loss 3.2639e-01 (2.3232e-01) 
2023-05-25 00:30:36.088647: val Epoch: [4][32/72]	Time  1.034 ( 0.771)	Data  0.697 ( 0.429)	Loss 8.6054e-02 (2.2788e-01) 
2023-05-25 00:30:36.451709: val Epoch: [4][33/72]	Time  0.363 ( 0.759)	Data  0.001 ( 0.416)	Loss 2.3036e-01 (2.2796e-01) 
2023-05-25 00:30:37.421585: val Epoch: [4][34/72]	Time  0.970 ( 0.765)	Data  0.688 ( 0.424)	Loss 1.4807e-01 (2.2567e-01) 
2023-05-25 00:30:37.854973: val Epoch: [4][35/72]	Time  0.433 ( 0.756)	Data  0.001 ( 0.412)	Loss 2.2754e-01 (2.2573e-01) 
2023-05-25 00:30:38.878309: val Epoch: [4][36/72]	Time  1.023 ( 0.763)	Data  0.772 ( 0.422)	Loss 6.1247e-01 (2.3618e-01) 
2023-05-25 00:30:39.197671: val Epoch: [4][37/72]	Time  0.319 ( 0.752)	Data  0.001 ( 0.411)	Loss 2.1427e-01 (2.3560e-01) 
2023-05-25 00:30:40.414357: val Epoch: [4][38/72]	Time  1.217 ( 0.764)	Data  0.874 ( 0.423)	Loss 2.3218e-01 (2.3551e-01) 
2023-05-25 00:30:40.758428: val Epoch: [4][39/72]	Time  0.344 ( 0.753)	Data  0.002 ( 0.412)	Loss 1.6916e-01 (2.3385e-01) 
2023-05-25 00:30:41.754041: val Epoch: [4][40/72]	Time  0.996 ( 0.759)	Data  0.778 ( 0.421)	Loss 2.0671e-01 (2.3319e-01) 
2023-05-25 00:30:42.191792: val Epoch: [4][41/72]	Time  0.438 ( 0.751)	Data  0.001 ( 0.411)	Loss 2.5005e-01 (2.3359e-01) 
2023-05-25 00:30:43.498931: val Epoch: [4][42/72]	Time  1.307 ( 0.764)	Data  0.804 ( 0.420)	Loss 5.2771e-01 (2.4043e-01) 
2023-05-25 00:30:43.685728: val Epoch: [4][43/72]	Time  0.187 ( 0.751)	Data  0.000 ( 0.411)	Loss 1.0960e-01 (2.3746e-01) 
2023-05-25 00:30:44.721498: val Epoch: [4][44/72]	Time  1.036 ( 0.757)	Data  0.631 ( 0.416)	Loss 3.8809e-01 (2.4081e-01) 
2023-05-25 00:30:45.038088: val Epoch: [4][45/72]	Time  0.317 ( 0.748)	Data  0.001 ( 0.407)	Loss 1.2088e-01 (2.3820e-01) 
2023-05-25 00:30:46.040775: val Epoch: [4][46/72]	Time  1.003 ( 0.753)	Data  0.626 ( 0.411)	Loss 9.6866e-02 (2.3519e-01) 
2023-05-25 00:30:46.502725: val Epoch: [4][47/72]	Time  0.462 ( 0.747)	Data  0.001 ( 0.403)	Loss 1.9913e-01 (2.3444e-01) 
2023-05-25 00:30:47.327164: val Epoch: [4][48/72]	Time  0.824 ( 0.749)	Data  0.536 ( 0.406)	Loss 3.0528e-01 (2.3589e-01) 
2023-05-25 00:30:47.544196: val Epoch: [4][49/72]	Time  0.217 ( 0.738)	Data  0.001 ( 0.398)	Loss 5.6074e-01 (2.4238e-01) 
2023-05-25 00:30:48.721808: val Epoch: [4][50/72]	Time  1.178 ( 0.747)	Data  0.871 ( 0.407)	Loss 1.3205e-01 (2.4022e-01) 
2023-05-25 00:30:48.982420: val Epoch: [4][51/72]	Time  0.261 ( 0.737)	Data  0.001 ( 0.399)	Loss 1.9962e-01 (2.3944e-01) 
2023-05-25 00:30:50.211653: val Epoch: [4][52/72]	Time  1.229 ( 0.747)	Data  0.793 ( 0.406)	Loss 1.3938e-01 (2.3755e-01) 
2023-05-25 00:30:50.379404: val Epoch: [4][53/72]	Time  0.168 ( 0.736)	Data  0.001 ( 0.399)	Loss 3.6876e-01 (2.3998e-01) 
2023-05-25 00:30:51.643435: val Epoch: [4][54/72]	Time  1.264 ( 0.746)	Data  0.804 ( 0.406)	Loss 2.2868e-01 (2.3978e-01) 
2023-05-25 00:30:52.092280: val Epoch: [4][55/72]	Time  0.449 ( 0.740)	Data  0.005 ( 0.399)	Loss 1.2210e-01 (2.3768e-01) 
2023-05-25 00:30:53.000516: val Epoch: [4][56/72]	Time  0.908 ( 0.743)	Data  0.498 ( 0.401)	Loss 3.4591e-01 (2.3957e-01) 
2023-05-25 00:30:53.428992: val Epoch: [4][57/72]	Time  0.428 ( 0.738)	Data  0.001 ( 0.394)	Loss 1.9079e-01 (2.3873e-01) 
2023-05-25 00:30:54.364793: val Epoch: [4][58/72]	Time  0.936 ( 0.741)	Data  0.607 ( 0.398)	Loss 1.7636e-01 (2.3768e-01) 
2023-05-25 00:30:54.680218: val Epoch: [4][59/72]	Time  0.315 ( 0.734)	Data  0.003 ( 0.391)	Loss 1.1647e-01 (2.3566e-01) 
2023-05-25 00:30:56.029516: val Epoch: [4][60/72]	Time  1.349 ( 0.744)	Data  0.748 ( 0.397)	Loss 2.9734e-01 (2.3667e-01) 
2023-05-25 00:30:56.397628: val Epoch: [4][61/72]	Time  0.368 ( 0.738)	Data  0.001 ( 0.390)	Loss 1.2251e-01 (2.3483e-01) 
2023-05-25 00:30:57.063909: val Epoch: [4][62/72]	Time  0.666 ( 0.737)	Data  0.488 ( 0.392)	Loss 5.3145e-01 (2.3953e-01) 
2023-05-25 00:30:57.497847: val Epoch: [4][63/72]	Time  0.434 ( 0.732)	Data  0.001 ( 0.386)	Loss 2.2864e-01 (2.3936e-01) 
2023-05-25 00:30:58.558511: val Epoch: [4][64/72]	Time  1.061 ( 0.737)	Data  0.733 ( 0.391)	Loss 1.8920e-01 (2.3859e-01) 
2023-05-25 00:30:58.945719: val Epoch: [4][65/72]	Time  0.387 ( 0.732)	Data  0.003 ( 0.385)	Loss 2.2653e-01 (2.3841e-01) 
2023-05-25 00:31:00.261193: val Epoch: [4][66/72]	Time  1.315 ( 0.741)	Data  0.756 ( 0.391)	Loss 1.4678e-01 (2.3704e-01) 
2023-05-25 00:31:00.493134: val Epoch: [4][67/72]	Time  0.232 ( 0.733)	Data  0.004 ( 0.385)	Loss 9.8506e-02 (2.3500e-01) 
2023-05-25 00:31:01.459635: val Epoch: [4][68/72]	Time  0.966 ( 0.737)	Data  0.546 ( 0.387)	Loss 1.2564e-01 (2.3342e-01) 
2023-05-25 00:31:01.881436: val Epoch: [4][69/72]	Time  0.422 ( 0.732)	Data  0.001 ( 0.382)	Loss 1.4394e-01 (2.3214e-01) 
2023-05-25 00:31:02.709875: val Epoch: [4][70/72]	Time  0.828 ( 0.733)	Data  0.523 ( 0.384)	Loss 3.4917e-01 (2.3379e-01) 
2023-05-25 00:31:02.930970: val Epoch: [4][71/72]	Time  0.221 ( 0.726)	Data  0.001 ( 0.379)	Loss 1.2594e-01 (2.3229e-01) 
2023-05-25 00:31:03.154951: Epoch 4 :Val : ['ET : 0.603283166885376', 'TC : 0.6225566864013672', 'WT : 0.7377784252166748'] 
2023-05-25 00:31:03.156097: Epoch 4 :Val : ['ET : 0.603283166885376', 'TC : 0.6225566864013672', 'WT : 0.7377784252166748'] 
2023-05-25 00:31:03.161486: Saving the model with DSC 0.6500043272972107 
2023-05-25 00:31:04.156806: Val epoch done in 54.47512481198646 s 
2023-05-25 00:31:04.170438: Batches per epoch:  193 
2023-05-25 00:31:08.544867: train Epoch: [5][  0/193]	Time  4.374 ( 4.374)	Data  3.336 ( 3.336)	Loss 1.9167e-01 (1.9167e-01) 
2023-05-25 00:31:09.718580: train Epoch: [5][  1/193]	Time  1.174 ( 2.774)	Data  0.001 ( 1.669)	Loss 1.4536e-01 (1.6852e-01) 
2023-05-25 00:31:11.595320: train Epoch: [5][  2/193]	Time  1.877 ( 2.475)	Data  0.550 ( 1.296)	Loss 2.2286e-01 (1.8663e-01) 
2023-05-25 00:31:12.549157: train Epoch: [5][  3/193]	Time  0.954 ( 2.095)	Data  0.001 ( 0.972)	Loss 9.2286e-02 (1.6304e-01) 
2023-05-25 00:31:14.362145: train Epoch: [5][  4/193]	Time  1.813 ( 2.038)	Data  0.469 ( 0.872)	Loss 1.4545e-01 (1.5952e-01) 
2023-05-25 00:31:15.507947: train Epoch: [5][  5/193]	Time  1.146 ( 1.890)	Data  0.001 ( 0.727)	Loss 1.3477e-01 (1.5540e-01) 
2023-05-25 00:31:16.944280: train Epoch: [5][  6/193]	Time  1.436 ( 1.825)	Data  0.244 ( 0.658)	Loss 8.7997e-02 (1.4577e-01) 
2023-05-25 00:31:17.919884: train Epoch: [5][  7/193]	Time  0.976 ( 1.719)	Data  0.001 ( 0.575)	Loss 1.5260e-01 (1.4662e-01) 
2023-05-25 00:31:19.543777: train Epoch: [5][  8/193]	Time  1.624 ( 1.708)	Data  0.545 ( 0.572)	Loss 4.3933e-01 (1.7915e-01) 
2023-05-25 00:31:21.072266: train Epoch: [5][  9/193]	Time  1.528 ( 1.690)	Data  0.001 ( 0.515)	Loss 1.1675e-01 (1.7291e-01) 
2023-05-25 00:31:22.318577: train Epoch: [5][ 10/193]	Time  1.246 ( 1.650)	Data  0.124 ( 0.479)	Loss 3.1435e-01 (1.8577e-01) 
2023-05-25 00:31:23.250991: train Epoch: [5][ 11/193]	Time  0.932 ( 1.590)	Data  0.001 ( 0.440)	Loss 2.0893e-01 (1.8770e-01) 
2023-05-25 00:31:24.968544: train Epoch: [5][ 12/193]	Time  1.718 ( 1.600)	Data  0.774 ( 0.465)	Loss 1.3956e-01 (1.8399e-01) 
2023-05-25 00:31:25.937477: train Epoch: [5][ 13/193]	Time  0.969 ( 1.555)	Data  0.001 ( 0.432)	Loss 1.3824e-01 (1.8072e-01) 
2023-05-25 00:31:27.821010: train Epoch: [5][ 14/193]	Time  1.884 ( 1.577)	Data  0.902 ( 0.463)	Loss 1.1378e-01 (1.7626e-01) 
2023-05-25 00:31:28.746131: train Epoch: [5][ 15/193]	Time  0.925 ( 1.536)	Data  0.001 ( 0.434)	Loss 2.5110e-01 (1.8094e-01) 
2023-05-25 00:31:30.493700: train Epoch: [5][ 16/193]	Time  1.748 ( 1.548)	Data  0.797 ( 0.456)	Loss 1.2467e-01 (1.7763e-01) 
2023-05-25 00:31:31.443094: train Epoch: [5][ 17/193]	Time  0.949 ( 1.515)	Data  0.001 ( 0.431)	Loss 1.4185e-01 (1.7564e-01) 
2023-05-25 00:31:33.275810: train Epoch: [5][ 18/193]	Time  1.833 ( 1.532)	Data  0.845 ( 0.452)	Loss 1.4079e-01 (1.7381e-01) 
2023-05-25 00:31:34.216424: train Epoch: [5][ 19/193]	Time  0.941 ( 1.502)	Data  0.001 ( 0.430)	Loss 1.6788e-01 (1.7351e-01) 
2023-05-25 00:31:35.911740: train Epoch: [5][ 20/193]	Time  1.695 ( 1.511)	Data  0.738 ( 0.445)	Loss 2.4026e-01 (1.7669e-01) 
2023-05-25 00:31:36.854541: train Epoch: [5][ 21/193]	Time  0.943 ( 1.486)	Data  0.001 ( 0.424)	Loss 1.5090e-01 (1.7552e-01) 
2023-05-25 00:31:38.412764: train Epoch: [5][ 22/193]	Time  1.558 ( 1.489)	Data  0.610 ( 0.432)	Loss 1.1346e-01 (1.7282e-01) 
2023-05-25 00:31:39.371770: train Epoch: [5][ 23/193]	Time  0.959 ( 1.467)	Data  0.001 ( 0.414)	Loss 3.1406e-01 (1.7870e-01) 
2023-05-25 00:31:42.019492: train Epoch: [5][ 24/193]	Time  2.648 ( 1.514)	Data  0.679 ( 0.425)	Loss 1.1403e-01 (1.7612e-01) 
2023-05-25 00:31:43.963037: train Epoch: [5][ 25/193]	Time  1.944 ( 1.530)	Data  0.001 ( 0.409)	Loss 1.5296e-01 (1.7523e-01) 
2023-05-25 00:31:45.931531: train Epoch: [5][ 26/193]	Time  1.968 ( 1.547)	Data  0.001 ( 0.394)	Loss 2.6215e-01 (1.7845e-01) 
2023-05-25 00:31:47.897790: train Epoch: [5][ 27/193]	Time  1.966 ( 1.562)	Data  0.001 ( 0.380)	Loss 1.0845e-01 (1.7595e-01) 
2023-05-25 00:31:49.840614: train Epoch: [5][ 28/193]	Time  1.943 ( 1.575)	Data  0.001 ( 0.367)	Loss 2.1194e-01 (1.7719e-01) 
2023-05-25 00:31:51.796818: train Epoch: [5][ 29/193]	Time  1.956 ( 1.588)	Data  0.001 ( 0.354)	Loss 1.9054e-01 (1.7763e-01) 
2023-05-25 00:31:53.749585: train Epoch: [5][ 30/193]	Time  1.953 ( 1.599)	Data  0.001 ( 0.343)	Loss 1.0003e-01 (1.7513e-01) 
2023-05-25 00:31:55.712589: train Epoch: [5][ 31/193]	Time  1.963 ( 1.611)	Data  0.001 ( 0.332)	Loss 1.2892e-01 (1.7368e-01) 
2023-05-25 00:31:57.661069: train Epoch: [5][ 32/193]	Time  1.948 ( 1.621)	Data  0.001 ( 0.322)	Loss 3.1549e-01 (1.7798e-01) 
2023-05-25 00:31:59.615770: train Epoch: [5][ 33/193]	Time  1.955 ( 1.631)	Data  0.001 ( 0.313)	Loss 2.0717e-01 (1.7884e-01) 
2023-05-25 00:32:01.582630: train Epoch: [5][ 34/193]	Time  1.967 ( 1.640)	Data  0.001 ( 0.304)	Loss 1.5002e-01 (1.7802e-01) 
2023-05-25 00:32:03.532053: train Epoch: [5][ 35/193]	Time  1.949 ( 1.649)	Data  0.001 ( 0.295)	Loss 1.4346e-01 (1.7706e-01) 
2023-05-25 00:32:05.489721: train Epoch: [5][ 36/193]	Time  1.958 ( 1.657)	Data  0.001 ( 0.287)	Loss 1.6565e-01 (1.7675e-01) 
2023-05-25 00:32:07.431958: train Epoch: [5][ 37/193]	Time  1.942 ( 1.665)	Data  0.001 ( 0.280)	Loss 1.3637e-01 (1.7569e-01) 
2023-05-25 00:32:09.354521: train Epoch: [5][ 38/193]	Time  1.923 ( 1.671)	Data  0.001 ( 0.273)	Loss 2.3578e-01 (1.7723e-01) 
2023-05-25 00:32:10.036306: train Epoch: [5][ 39/193]	Time  0.682 ( 1.647)	Data  0.001 ( 0.266)	Loss 1.7354e-01 (1.7713e-01) 
2023-05-25 00:32:10.868810: train Epoch: [5][ 40/193]	Time  0.832 ( 1.627)	Data  0.001 ( 0.260)	Loss 1.9738e-01 (1.7763e-01) 
2023-05-25 00:32:12.507810: train Epoch: [5][ 41/193]	Time  1.639 ( 1.627)	Data  0.001 ( 0.253)	Loss 1.1935e-01 (1.7624e-01) 
2023-05-25 00:32:13.563656: train Epoch: [5][ 42/193]	Time  1.056 ( 1.614)	Data  0.001 ( 0.247)	Loss 1.0671e-01 (1.7462e-01) 
2023-05-25 00:32:14.552639: train Epoch: [5][ 43/193]	Time  0.989 ( 1.600)	Data  0.001 ( 0.242)	Loss 2.8987e-01 (1.7724e-01) 
2023-05-25 00:32:15.740602: train Epoch: [5][ 44/193]	Time  1.188 ( 1.590)	Data  0.001 ( 0.237)	Loss 1.4709e-01 (1.7657e-01) 
2023-05-25 00:32:16.692088: train Epoch: [5][ 45/193]	Time  0.951 ( 1.577)	Data  0.001 ( 0.231)	Loss 1.2619e-01 (1.7548e-01) 
2023-05-25 00:32:17.712269: train Epoch: [5][ 46/193]	Time  1.020 ( 1.565)	Data  0.001 ( 0.227)	Loss 1.2753e-01 (1.7446e-01) 
2023-05-25 00:32:18.848510: train Epoch: [5][ 47/193]	Time  1.136 ( 1.556)	Data  0.001 ( 0.222)	Loss 3.3066e-01 (1.7771e-01) 
2023-05-25 00:32:19.960091: train Epoch: [5][ 48/193]	Time  1.112 ( 1.547)	Data  0.001 ( 0.217)	Loss 1.0175e-01 (1.7616e-01) 
2023-05-25 00:32:20.976833: train Epoch: [5][ 49/193]	Time  1.017 ( 1.536)	Data  0.001 ( 0.213)	Loss 2.7165e-01 (1.7807e-01) 
2023-05-25 00:32:22.773166: train Epoch: [5][ 50/193]	Time  1.796 ( 1.541)	Data  0.743 ( 0.223)	Loss 1.2757e-01 (1.7708e-01) 
2023-05-25 00:32:23.792316: train Epoch: [5][ 51/193]	Time  1.019 ( 1.531)	Data  0.001 ( 0.219)	Loss 1.0442e-01 (1.7568e-01) 
2023-05-25 00:32:25.431843: train Epoch: [5][ 52/193]	Time  1.640 ( 1.533)	Data  0.507 ( 0.225)	Loss 9.4711e-02 (1.7416e-01) 
2023-05-25 00:32:26.482530: train Epoch: [5][ 53/193]	Time  1.051 ( 1.524)	Data  0.001 ( 0.220)	Loss 2.0735e-01 (1.7477e-01) 
2023-05-25 00:32:28.103011: train Epoch: [5][ 54/193]	Time  1.620 ( 1.526)	Data  0.296 ( 0.222)	Loss 1.4252e-01 (1.7418e-01) 
2023-05-25 00:32:29.196589: train Epoch: [5][ 55/193]	Time  1.094 ( 1.518)	Data  0.001 ( 0.218)	Loss 1.1302e-01 (1.7309e-01) 
2023-05-25 00:32:30.539485: train Epoch: [5][ 56/193]	Time  1.343 ( 1.515)	Data  0.226 ( 0.218)	Loss 2.1347e-01 (1.7380e-01) 
2023-05-25 00:32:31.500446: train Epoch: [5][ 57/193]	Time  0.961 ( 1.506)	Data  0.001 ( 0.214)	Loss 1.0175e-01 (1.7256e-01) 
2023-05-25 00:32:33.098712: train Epoch: [5][ 58/193]	Time  1.598 ( 1.507)	Data  0.528 ( 0.220)	Loss 1.0552e-01 (1.7142e-01) 
2023-05-25 00:32:34.521283: train Epoch: [5][ 59/193]	Time  1.423 ( 1.506)	Data  0.242 ( 0.220)	Loss 1.4891e-01 (1.7105e-01) 
2023-05-25 00:32:35.762016: train Epoch: [5][ 60/193]	Time  1.241 ( 1.501)	Data  0.195 ( 0.220)	Loss 8.9200e-02 (1.6971e-01) 
2023-05-25 00:32:37.338860: train Epoch: [5][ 61/193]	Time  1.577 ( 1.503)	Data  0.293 ( 0.221)	Loss 2.9863e-01 (1.7178e-01) 
2023-05-25 00:32:38.396420: train Epoch: [5][ 62/193]	Time  1.058 ( 1.496)	Data  0.070 ( 0.218)	Loss 1.4395e-01 (1.7134e-01) 
2023-05-25 00:32:40.367185: train Epoch: [5][ 63/193]	Time  1.971 ( 1.503)	Data  0.539 ( 0.223)	Loss 1.9709e-01 (1.7175e-01) 
2023-05-25 00:32:41.467233: train Epoch: [5][ 64/193]	Time  1.100 ( 1.497)	Data  0.001 ( 0.220)	Loss 1.6579e-01 (1.7165e-01) 
2023-05-25 00:32:42.869806: train Epoch: [5][ 65/193]	Time  1.403 ( 1.495)	Data  0.237 ( 0.220)	Loss 1.7109e-01 (1.7164e-01) 
2023-05-25 00:32:43.931507: train Epoch: [5][ 66/193]	Time  1.062 ( 1.489)	Data  0.001 ( 0.217)	Loss 2.8396e-01 (1.7332e-01) 
2023-05-25 00:32:45.665173: train Epoch: [5][ 67/193]	Time  1.734 ( 1.493)	Data  0.479 ( 0.221)	Loss 1.2685e-01 (1.7264e-01) 
2023-05-25 00:32:46.660284: train Epoch: [5][ 68/193]	Time  0.995 ( 1.485)	Data  0.001 ( 0.218)	Loss 1.5232e-01 (1.7234e-01) 
2023-05-25 00:32:48.094811: train Epoch: [5][ 69/193]	Time  1.435 ( 1.485)	Data  0.510 ( 0.222)	Loss 1.9839e-01 (1.7272e-01) 
2023-05-25 00:32:49.225051: train Epoch: [5][ 70/193]	Time  1.130 ( 1.480)	Data  0.173 ( 0.221)	Loss 1.1554e-01 (1.7191e-01) 
2023-05-25 00:32:51.197562: train Epoch: [5][ 71/193]	Time  1.973 ( 1.486)	Data  0.654 ( 0.227)	Loss 1.9636e-01 (1.7225e-01) 
2023-05-25 00:32:52.307988: train Epoch: [5][ 72/193]	Time  1.110 ( 1.481)	Data  0.001 ( 0.224)	Loss 1.5150e-01 (1.7197e-01) 
2023-05-25 00:32:53.796435: train Epoch: [5][ 73/193]	Time  1.488 ( 1.481)	Data  0.334 ( 0.225)	Loss 3.0301e-01 (1.7374e-01) 
2023-05-25 00:32:54.853208: train Epoch: [5][ 74/193]	Time  1.057 ( 1.476)	Data  0.001 ( 0.222)	Loss 2.7245e-01 (1.7505e-01) 
2023-05-25 00:32:56.365531: train Epoch: [5][ 75/193]	Time  1.512 ( 1.476)	Data  0.559 ( 0.227)	Loss 1.9208e-01 (1.7528e-01) 
2023-05-25 00:32:57.567021: train Epoch: [5][ 76/193]	Time  1.201 ( 1.473)	Data  0.132 ( 0.226)	Loss 3.7143e-01 (1.7782e-01) 
2023-05-25 00:32:59.391451: train Epoch: [5][ 77/193]	Time  1.824 ( 1.477)	Data  0.573 ( 0.230)	Loss 1.6098e-01 (1.7761e-01) 
2023-05-25 00:33:00.400820: train Epoch: [5][ 78/193]	Time  1.009 ( 1.471)	Data  0.001 ( 0.227)	Loss 1.4598e-01 (1.7721e-01) 
2023-05-25 00:33:02.106410: train Epoch: [5][ 79/193]	Time  1.706 ( 1.474)	Data  0.397 ( 0.229)	Loss 2.2780e-01 (1.7784e-01) 
2023-05-25 00:33:03.069694: train Epoch: [5][ 80/193]	Time  0.963 ( 1.468)	Data  0.001 ( 0.227)	Loss 1.6477e-01 (1.7768e-01) 
2023-05-25 00:33:04.798745: train Epoch: [5][ 81/193]	Time  1.729 ( 1.471)	Data  0.522 ( 0.230)	Loss 1.5031e-01 (1.7735e-01) 
2023-05-25 00:33:05.754035: train Epoch: [5][ 82/193]	Time  0.955 ( 1.465)	Data  0.001 ( 0.227)	Loss 2.2985e-01 (1.7798e-01) 
2023-05-25 00:33:07.476435: train Epoch: [5][ 83/193]	Time  1.722 ( 1.468)	Data  0.595 ( 0.232)	Loss 1.6820e-01 (1.7786e-01) 
2023-05-25 00:33:08.668859: train Epoch: [5][ 84/193]	Time  1.192 ( 1.465)	Data  0.064 ( 0.230)	Loss 1.2994e-01 (1.7730e-01) 
2023-05-25 00:33:10.133482: train Epoch: [5][ 85/193]	Time  1.465 ( 1.465)	Data  0.404 ( 0.232)	Loss 1.7788e-01 (1.7730e-01) 
2023-05-25 00:33:11.315969: train Epoch: [5][ 86/193]	Time  1.182 ( 1.461)	Data  0.151 ( 0.231)	Loss 1.7314e-01 (1.7726e-01) 
2023-05-25 00:33:13.021589: train Epoch: [5][ 87/193]	Time  1.706 ( 1.464)	Data  0.512 ( 0.234)	Loss 1.0495e-01 (1.7643e-01) 
2023-05-25 00:33:14.446567: train Epoch: [5][ 88/193]	Time  1.425 ( 1.464)	Data  0.203 ( 0.234)	Loss 1.5822e-01 (1.7623e-01) 
2023-05-25 00:33:15.670747: train Epoch: [5][ 89/193]	Time  1.224 ( 1.461)	Data  0.248 ( 0.234)	Loss 3.5059e-01 (1.7817e-01) 
2023-05-25 00:33:16.958404: train Epoch: [5][ 90/193]	Time  1.288 ( 1.459)	Data  0.303 ( 0.235)	Loss 2.5407e-01 (1.7900e-01) 
2023-05-25 00:33:18.537229: train Epoch: [5][ 91/193]	Time  1.579 ( 1.461)	Data  0.540 ( 0.238)	Loss 4.2050e-01 (1.8163e-01) 
2023-05-25 00:33:19.592414: train Epoch: [5][ 92/193]	Time  1.055 ( 1.456)	Data  0.024 ( 0.236)	Loss 1.8465e-01 (1.8166e-01) 
2023-05-25 00:33:21.541937: train Epoch: [5][ 93/193]	Time  1.950 ( 1.461)	Data  0.927 ( 0.243)	Loss 1.5918e-01 (1.8142e-01) 
2023-05-25 00:33:22.557393: train Epoch: [5][ 94/193]	Time  1.015 ( 1.457)	Data  0.001 ( 0.240)	Loss 1.3705e-01 (1.8095e-01) 
2023-05-25 00:33:24.584305: train Epoch: [5][ 95/193]	Time  2.027 ( 1.463)	Data  0.947 ( 0.248)	Loss 1.3929e-01 (1.8052e-01) 
2023-05-25 00:33:25.654650: train Epoch: [5][ 96/193]	Time  1.070 ( 1.459)	Data  0.001 ( 0.245)	Loss 1.5629e-01 (1.8027e-01) 
2023-05-25 00:33:27.732794: train Epoch: [5][ 97/193]	Time  2.078 ( 1.465)	Data  0.763 ( 0.251)	Loss 2.5900e-01 (1.8107e-01) 
2023-05-25 00:33:28.835605: train Epoch: [5][ 98/193]	Time  1.103 ( 1.461)	Data  0.001 ( 0.248)	Loss 9.9334e-02 (1.8025e-01) 
2023-05-25 00:33:30.496640: train Epoch: [5][ 99/193]	Time  1.661 ( 1.463)	Data  0.344 ( 0.249)	Loss 1.1432e-01 (1.7959e-01) 
2023-05-25 00:33:31.496365: train Epoch: [5][100/193]	Time  1.000 ( 1.459)	Data  0.001 ( 0.247)	Loss 2.8257e-01 (1.8061e-01) 
2023-05-25 00:33:33.397635: train Epoch: [5][101/193]	Time  1.901 ( 1.463)	Data  0.552 ( 0.250)	Loss 2.7859e-01 (1.8157e-01) 
2023-05-25 00:33:34.385491: train Epoch: [5][102/193]	Time  0.988 ( 1.458)	Data  0.001 ( 0.247)	Loss 1.5093e-01 (1.8127e-01) 
2023-05-25 00:33:36.037296: train Epoch: [5][103/193]	Time  1.652 ( 1.460)	Data  0.439 ( 0.249)	Loss 3.3090e-01 (1.8271e-01) 
2023-05-25 00:33:37.115867: train Epoch: [5][104/193]	Time  1.079 ( 1.457)	Data  0.001 ( 0.247)	Loss 1.2936e-01 (1.8220e-01) 
2023-05-25 00:33:38.737182: train Epoch: [5][105/193]	Time  1.621 ( 1.458)	Data  0.466 ( 0.249)	Loss 1.5250e-01 (1.8192e-01) 
2023-05-25 00:33:40.005667: train Epoch: [5][106/193]	Time  1.268 ( 1.456)	Data  0.001 ( 0.246)	Loss 1.8879e-01 (1.8199e-01) 
2023-05-25 00:33:41.389766: train Epoch: [5][107/193]	Time  1.384 ( 1.456)	Data  0.377 ( 0.248)	Loss 4.9383e-01 (1.8487e-01) 
2023-05-25 00:33:42.587856: train Epoch: [5][108/193]	Time  1.198 ( 1.453)	Data  0.001 ( 0.245)	Loss 2.7021e-01 (1.8566e-01) 
2023-05-25 00:33:44.364814: train Epoch: [5][109/193]	Time  1.777 ( 1.456)	Data  0.712 ( 0.250)	Loss 1.3912e-01 (1.8523e-01) 
2023-05-25 00:33:45.493545: train Epoch: [5][110/193]	Time  1.129 ( 1.453)	Data  0.001 ( 0.247)	Loss 2.1867e-01 (1.8553e-01) 
2023-05-25 00:33:47.223627: train Epoch: [5][111/193]	Time  1.730 ( 1.456)	Data  0.605 ( 0.251)	Loss 1.3578e-01 (1.8509e-01) 
2023-05-25 00:33:48.309777: train Epoch: [5][112/193]	Time  1.086 ( 1.453)	Data  0.001 ( 0.248)	Loss 2.2760e-01 (1.8547e-01) 
2023-05-25 00:33:49.953193: train Epoch: [5][113/193]	Time  1.643 ( 1.454)	Data  0.506 ( 0.251)	Loss 1.9897e-01 (1.8558e-01) 
2023-05-25 00:33:50.944905: train Epoch: [5][114/193]	Time  0.992 ( 1.450)	Data  0.001 ( 0.248)	Loss 2.4310e-01 (1.8608e-01) 
2023-05-25 00:33:52.748351: train Epoch: [5][115/193]	Time  1.803 ( 1.453)	Data  0.617 ( 0.252)	Loss 2.2297e-01 (1.8640e-01) 
2023-05-25 00:33:53.746158: train Epoch: [5][116/193]	Time  0.998 ( 1.449)	Data  0.001 ( 0.249)	Loss 1.9567e-01 (1.8648e-01) 
2023-05-25 00:33:55.645085: train Epoch: [5][117/193]	Time  1.899 ( 1.453)	Data  0.583 ( 0.252)	Loss 2.2898e-01 (1.8684e-01) 
2023-05-25 00:33:56.643770: train Epoch: [5][118/193]	Time  0.999 ( 1.449)	Data  0.001 ( 0.250)	Loss 1.3990e-01 (1.8645e-01) 
2023-05-25 00:33:58.107440: train Epoch: [5][119/193]	Time  1.464 ( 1.449)	Data  0.307 ( 0.251)	Loss 1.5616e-01 (1.8619e-01) 
2023-05-25 00:33:59.111104: train Epoch: [5][120/193]	Time  1.004 ( 1.446)	Data  0.001 ( 0.249)	Loss 1.4552e-01 (1.8586e-01) 
2023-05-25 00:34:00.867048: train Epoch: [5][121/193]	Time  1.756 ( 1.448)	Data  0.623 ( 0.252)	Loss 1.7216e-01 (1.8575e-01) 
2023-05-25 00:34:02.013466: train Epoch: [5][122/193]	Time  1.146 ( 1.446)	Data  0.001 ( 0.250)	Loss 4.7125e-01 (1.8807e-01) 
2023-05-25 00:34:03.420841: train Epoch: [5][123/193]	Time  1.407 ( 1.446)	Data  0.387 ( 0.251)	Loss 1.9542e-01 (1.8813e-01) 
2023-05-25 00:34:04.583221: train Epoch: [5][124/193]	Time  1.162 ( 1.443)	Data  0.001 ( 0.249)	Loss 2.1764e-01 (1.8836e-01) 
2023-05-25 00:34:06.436006: train Epoch: [5][125/193]	Time  1.853 ( 1.447)	Data  0.647 ( 0.252)	Loss 1.1522e-01 (1.8778e-01) 
2023-05-25 00:34:07.588350: train Epoch: [5][126/193]	Time  1.152 ( 1.444)	Data  0.001 ( 0.250)	Loss 1.8261e-01 (1.8774e-01) 
2023-05-25 00:34:09.014302: train Epoch: [5][127/193]	Time  1.426 ( 1.444)	Data  0.433 ( 0.251)	Loss 2.5885e-01 (1.8830e-01) 
2023-05-25 00:34:10.090758: train Epoch: [5][128/193]	Time  1.076 ( 1.441)	Data  0.001 ( 0.249)	Loss 1.6239e-01 (1.8810e-01) 
2023-05-25 00:34:11.809003: train Epoch: [5][129/193]	Time  1.718 ( 1.443)	Data  0.656 ( 0.253)	Loss 5.0525e-01 (1.9054e-01) 
2023-05-25 00:34:12.935880: train Epoch: [5][130/193]	Time  1.127 ( 1.441)	Data  0.001 ( 0.251)	Loss 2.2031e-01 (1.9076e-01) 
2023-05-25 00:34:14.670745: train Epoch: [5][131/193]	Time  1.735 ( 1.443)	Data  0.632 ( 0.253)	Loss 2.6155e-01 (1.9130e-01) 
2023-05-25 00:34:15.780169: train Epoch: [5][132/193]	Time  1.109 ( 1.441)	Data  0.001 ( 0.252)	Loss 9.8361e-02 (1.9060e-01) 
2023-05-25 00:34:17.705360: train Epoch: [5][133/193]	Time  1.925 ( 1.444)	Data  0.602 ( 0.254)	Loss 1.1388e-01 (1.9003e-01) 
2023-05-25 00:34:18.731835: train Epoch: [5][134/193]	Time  1.026 ( 1.441)	Data  0.001 ( 0.252)	Loss 2.2219e-01 (1.9027e-01) 
2023-05-25 00:34:20.373163: train Epoch: [5][135/193]	Time  1.641 ( 1.443)	Data  0.392 ( 0.253)	Loss 1.3554e-01 (1.8986e-01) 
2023-05-25 00:34:21.432189: train Epoch: [5][136/193]	Time  1.059 ( 1.440)	Data  0.001 ( 0.252)	Loss 2.1840e-01 (1.9007e-01) 
2023-05-25 00:34:23.386163: train Epoch: [5][137/193]	Time  1.954 ( 1.444)	Data  0.697 ( 0.255)	Loss 1.7533e-01 (1.8997e-01) 
2023-05-25 00:34:24.647660: train Epoch: [5][138/193]	Time  1.262 ( 1.442)	Data  0.001 ( 0.253)	Loss 9.0241e-02 (1.8925e-01) 
2023-05-25 00:34:25.835433: train Epoch: [5][139/193]	Time  1.188 ( 1.440)	Data  0.149 ( 0.252)	Loss 1.5559e-01 (1.8901e-01) 
2023-05-25 00:34:26.951616: train Epoch: [5][140/193]	Time  1.116 ( 1.438)	Data  0.001 ( 0.250)	Loss 1.4223e-01 (1.8868e-01) 
2023-05-25 00:34:28.705086: train Epoch: [5][141/193]	Time  1.753 ( 1.440)	Data  0.510 ( 0.252)	Loss 2.1128e-01 (1.8884e-01) 
2023-05-25 00:34:29.721107: train Epoch: [5][142/193]	Time  1.016 ( 1.437)	Data  0.001 ( 0.250)	Loss 2.1574e-01 (1.8902e-01) 
2023-05-25 00:34:31.190809: train Epoch: [5][143/193]	Time  1.470 ( 1.438)	Data  0.449 ( 0.252)	Loss 1.7388e-01 (1.8892e-01) 
2023-05-25 00:34:32.249408: train Epoch: [5][144/193]	Time  1.059 ( 1.435)	Data  0.001 ( 0.250)	Loss 1.7440e-01 (1.8882e-01) 
2023-05-25 00:34:34.147056: train Epoch: [5][145/193]	Time  1.898 ( 1.438)	Data  0.597 ( 0.252)	Loss 1.0416e-01 (1.8824e-01) 
2023-05-25 00:34:35.151736: train Epoch: [5][146/193]	Time  1.005 ( 1.435)	Data  0.001 ( 0.251)	Loss 1.5158e-01 (1.8799e-01) 
2023-05-25 00:34:36.757376: train Epoch: [5][147/193]	Time  1.606 ( 1.436)	Data  0.300 ( 0.251)	Loss 1.7304e-01 (1.8789e-01) 
2023-05-25 00:34:37.808116: train Epoch: [5][148/193]	Time  1.051 ( 1.434)	Data  0.001 ( 0.249)	Loss 1.2419e-01 (1.8746e-01) 
2023-05-25 00:34:38.977977: train Epoch: [5][149/193]	Time  1.170 ( 1.432)	Data  0.252 ( 0.249)	Loss 1.6502e-01 (1.8731e-01) 
2023-05-25 00:34:40.128836: train Epoch: [5][150/193]	Time  1.151 ( 1.430)	Data  0.001 ( 0.248)	Loss 1.4366e-01 (1.8702e-01) 
2023-05-25 00:34:41.806258: train Epoch: [5][151/193]	Time  1.677 ( 1.432)	Data  0.588 ( 0.250)	Loss 1.6397e-01 (1.8687e-01) 
2023-05-25 00:34:43.084942: train Epoch: [5][152/193]	Time  1.279 ( 1.431)	Data  0.001 ( 0.248)	Loss 1.7184e-01 (1.8677e-01) 
2023-05-25 00:34:44.305641: train Epoch: [5][153/193]	Time  1.221 ( 1.429)	Data  0.217 ( 0.248)	Loss 1.2241e-01 (1.8635e-01) 
2023-05-25 00:34:45.328196: train Epoch: [5][154/193]	Time  1.023 ( 1.427)	Data  0.001 ( 0.247)	Loss 1.1094e-01 (1.8587e-01) 
2023-05-25 00:34:47.131292: train Epoch: [5][155/193]	Time  1.803 ( 1.429)	Data  0.578 ( 0.249)	Loss 1.4991e-01 (1.8564e-01) 
2023-05-25 00:34:48.193031: train Epoch: [5][156/193]	Time  1.062 ( 1.427)	Data  0.002 ( 0.247)	Loss 1.8049e-01 (1.8560e-01) 
2023-05-25 00:34:49.979571: train Epoch: [5][157/193]	Time  1.787 ( 1.429)	Data  0.336 ( 0.248)	Loss 3.0029e-01 (1.8633e-01) 
2023-05-25 00:34:50.995350: train Epoch: [5][158/193]	Time  1.016 ( 1.427)	Data  0.001 ( 0.246)	Loss 1.0822e-01 (1.8584e-01) 
2023-05-25 00:34:52.454670: train Epoch: [5][159/193]	Time  1.459 ( 1.427)	Data  0.135 ( 0.245)	Loss 1.7634e-01 (1.8578e-01) 
2023-05-25 00:34:53.433887: train Epoch: [5][160/193]	Time  0.979 ( 1.424)	Data  0.001 ( 0.244)	Loss 1.8377e-01 (1.8577e-01) 
2023-05-25 00:34:54.853992: train Epoch: [5][161/193]	Time  1.420 ( 1.424)	Data  0.392 ( 0.245)	Loss 1.8639e-01 (1.8577e-01) 
2023-05-25 00:34:55.921444: train Epoch: [5][162/193]	Time  1.067 ( 1.422)	Data  0.001 ( 0.243)	Loss 2.9652e-01 (1.8645e-01) 
2023-05-25 00:34:57.827049: train Epoch: [5][163/193]	Time  1.906 ( 1.425)	Data  0.681 ( 0.246)	Loss 1.7603e-01 (1.8639e-01) 
2023-05-25 00:34:59.178162: train Epoch: [5][164/193]	Time  1.351 ( 1.424)	Data  0.001 ( 0.245)	Loss 1.8362e-01 (1.8637e-01) 
2023-05-25 00:35:00.542687: train Epoch: [5][165/193]	Time  1.364 ( 1.424)	Data  0.261 ( 0.245)	Loss 1.5873e-01 (1.8620e-01) 
2023-05-25 00:35:01.753747: train Epoch: [5][166/193]	Time  1.211 ( 1.423)	Data  0.001 ( 0.243)	Loss 1.2141e-01 (1.8582e-01) 
2023-05-25 00:35:03.654919: train Epoch: [5][167/193]	Time  1.901 ( 1.425)	Data  0.633 ( 0.246)	Loss 1.1900e-01 (1.8542e-01) 
2023-05-25 00:35:04.710370: train Epoch: [5][168/193]	Time  1.055 ( 1.423)	Data  0.001 ( 0.244)	Loss 2.1032e-01 (1.8556e-01) 
2023-05-25 00:35:06.323409: train Epoch: [5][169/193]	Time  1.613 ( 1.424)	Data  0.461 ( 0.245)	Loss 1.6177e-01 (1.8542e-01) 
2023-05-25 00:35:07.457260: train Epoch: [5][170/193]	Time  1.134 ( 1.423)	Data  0.001 ( 0.244)	Loss 1.3142e-01 (1.8511e-01) 
2023-05-25 00:35:09.172057: train Epoch: [5][171/193]	Time  1.715 ( 1.424)	Data  0.416 ( 0.245)	Loss 1.7967e-01 (1.8508e-01) 
2023-05-25 00:35:10.198863: train Epoch: [5][172/193]	Time  1.027 ( 1.422)	Data  0.001 ( 0.244)	Loss 2.5766e-01 (1.8550e-01) 
2023-05-25 00:35:12.052823: train Epoch: [5][173/193]	Time  1.854 ( 1.425)	Data  0.443 ( 0.245)	Loss 1.2122e-01 (1.8513e-01) 
2023-05-25 00:35:13.044118: train Epoch: [5][174/193]	Time  0.991 ( 1.422)	Data  0.001 ( 0.243)	Loss 1.0700e-01 (1.8468e-01) 
2023-05-25 00:35:14.304159: train Epoch: [5][175/193]	Time  1.260 ( 1.421)	Data  0.221 ( 0.243)	Loss 1.4023e-01 (1.8443e-01) 
2023-05-25 00:35:15.382062: train Epoch: [5][176/193]	Time  1.078 ( 1.419)	Data  0.001 ( 0.242)	Loss 3.4011e-01 (1.8531e-01) 
2023-05-25 00:35:17.174399: train Epoch: [5][177/193]	Time  1.792 ( 1.421)	Data  0.719 ( 0.244)	Loss 2.4265e-01 (1.8563e-01) 
2023-05-25 00:35:18.398747: train Epoch: [5][178/193]	Time  1.224 ( 1.420)	Data  0.001 ( 0.243)	Loss 1.2273e-01 (1.8528e-01) 
2023-05-25 00:35:20.054534: train Epoch: [5][179/193]	Time  1.656 ( 1.422)	Data  0.501 ( 0.245)	Loss 1.3402e-01 (1.8499e-01) 
2023-05-25 00:35:21.262870: train Epoch: [5][180/193]	Time  1.208 ( 1.420)	Data  0.001 ( 0.243)	Loss 1.7666e-01 (1.8495e-01) 
2023-05-25 00:35:22.695996: train Epoch: [5][181/193]	Time  1.433 ( 1.420)	Data  0.325 ( 0.244)	Loss 9.7755e-02 (1.8447e-01) 
2023-05-25 00:35:23.772193: train Epoch: [5][182/193]	Time  1.076 ( 1.419)	Data  0.001 ( 0.242)	Loss 1.0598e-01 (1.8404e-01) 
2023-05-25 00:35:25.376075: train Epoch: [5][183/193]	Time  1.604 ( 1.420)	Data  0.544 ( 0.244)	Loss 1.5577e-01 (1.8389e-01) 
2023-05-25 00:35:26.492929: train Epoch: [5][184/193]	Time  1.117 ( 1.418)	Data  0.001 ( 0.243)	Loss 9.1351e-02 (1.8339e-01) 
2023-05-25 00:35:28.254251: train Epoch: [5][185/193]	Time  1.761 ( 1.420)	Data  0.521 ( 0.244)	Loss 2.1113e-01 (1.8354e-01) 
2023-05-25 00:35:29.340919: train Epoch: [5][186/193]	Time  1.087 ( 1.418)	Data  0.003 ( 0.243)	Loss 2.3917e-01 (1.8383e-01) 
2023-05-25 00:35:31.010531: train Epoch: [5][187/193]	Time  1.670 ( 1.419)	Data  0.335 ( 0.243)	Loss 1.3525e-01 (1.8357e-01) 
2023-05-25 00:35:32.107486: train Epoch: [5][188/193]	Time  1.097 ( 1.418)	Data  0.001 ( 0.242)	Loss 4.5301e-01 (1.8500e-01) 
2023-05-25 00:35:33.486815: train Epoch: [5][189/193]	Time  1.379 ( 1.417)	Data  0.199 ( 0.242)	Loss 2.3143e-01 (1.8524e-01) 
2023-05-25 00:35:34.596471: train Epoch: [5][190/193]	Time  1.110 ( 1.416)	Data  0.001 ( 0.241)	Loss 1.4309e-01 (1.8502e-01) 
2023-05-25 00:35:36.113511: train Epoch: [5][191/193]	Time  1.517 ( 1.416)	Data  0.446 ( 0.242)	Loss 1.2824e-01 (1.8473e-01) 
2023-05-25 00:35:37.295013: train Epoch: [5][192/193]	Time  1.181 ( 1.415)	Data  0.001 ( 0.240)	Loss 1.3225e-01 (1.8446e-01) 
2023-05-25 00:35:37.364724: Train Epoch done in 273.1943532790756 s 
2023-05-25 00:35:40.674716: val Epoch: [5][ 0/72]	Time  2.268 ( 2.268)	Data  1.845 ( 1.845)	Loss 1.0188e-01 (1.0188e-01) 
2023-05-25 00:35:40.937835: val Epoch: [5][ 1/72]	Time  0.263 ( 1.266)	Data  0.002 ( 0.924)	Loss 1.8829e-01 (1.4509e-01) 
2023-05-25 00:35:41.956792: val Epoch: [5][ 2/72]	Time  1.019 ( 1.184)	Data  0.801 ( 0.883)	Loss 1.1971e-01 (1.3663e-01) 
2023-05-25 00:35:42.264993: val Epoch: [5][ 3/72]	Time  0.308 ( 0.965)	Data  0.001 ( 0.662)	Loss 8.6432e-02 (1.2408e-01) 
2023-05-25 00:35:43.604484: val Epoch: [5][ 4/72]	Time  1.340 ( 1.040)	Data  0.954 ( 0.721)	Loss 2.6458e-01 (1.5218e-01) 
2023-05-25 00:35:43.805157: val Epoch: [5][ 5/72]	Time  0.201 ( 0.900)	Data  0.001 ( 0.601)	Loss 4.9422e-01 (2.0919e-01) 
2023-05-25 00:35:45.364170: val Epoch: [5][ 6/72]	Time  1.559 ( 0.994)	Data  0.964 ( 0.653)	Loss 4.2865e-01 (2.4054e-01) 
2023-05-25 00:35:45.719227: val Epoch: [5][ 7/72]	Time  0.355 ( 0.914)	Data  0.008 ( 0.572)	Loss 1.1202e-01 (2.2447e-01) 
2023-05-25 00:35:46.611594: val Epoch: [5][ 8/72]	Time  0.892 ( 0.912)	Data  0.507 ( 0.565)	Loss 1.8635e-01 (2.2024e-01) 
2023-05-25 00:35:46.817451: val Epoch: [5][ 9/72]	Time  0.206 ( 0.841)	Data  0.001 ( 0.508)	Loss 9.2856e-02 (2.0750e-01) 
2023-05-25 00:35:48.196480: val Epoch: [5][10/72]	Time  1.379 ( 0.890)	Data  1.000 ( 0.553)	Loss 1.1431e-01 (1.9903e-01) 
2023-05-25 00:35:48.553604: val Epoch: [5][11/72]	Time  0.357 ( 0.846)	Data  0.001 ( 0.507)	Loss 2.0007e-01 (1.9911e-01) 
2023-05-25 00:35:49.887640: val Epoch: [5][12/72]	Time  1.334 ( 0.883)	Data  0.813 ( 0.531)	Loss 4.5535e-01 (2.1883e-01) 
2023-05-25 00:35:50.110462: val Epoch: [5][13/72]	Time  0.223 ( 0.836)	Data  0.001 ( 0.493)	Loss 8.2929e-02 (2.0912e-01) 
2023-05-25 00:35:50.907793: val Epoch: [5][14/72]	Time  0.797 ( 0.833)	Data  0.407 ( 0.487)	Loss 1.1444e-01 (2.0281e-01) 
2023-05-25 00:35:51.336447: val Epoch: [5][15/72]	Time  0.429 ( 0.808)	Data  0.001 ( 0.457)	Loss 2.2148e-01 (2.0397e-01) 
2023-05-25 00:35:52.298239: val Epoch: [5][16/72]	Time  0.962 ( 0.817)	Data  0.615 ( 0.466)	Loss 4.0901e-01 (2.1603e-01) 
2023-05-25 00:35:52.634252: val Epoch: [5][17/72]	Time  0.336 ( 0.790)	Data  0.001 ( 0.440)	Loss 2.3083e-01 (2.1686e-01) 
2023-05-25 00:35:53.888642: val Epoch: [5][18/72]	Time  1.254 ( 0.815)	Data  0.748 ( 0.456)	Loss 1.4308e-01 (2.1297e-01) 
2023-05-25 00:35:54.091066: val Epoch: [5][19/72]	Time  0.202 ( 0.784)	Data  0.001 ( 0.434)	Loss 1.7002e-01 (2.1083e-01) 
2023-05-25 00:35:55.036642: val Epoch: [5][20/72]	Time  0.946 ( 0.792)	Data  0.691 ( 0.446)	Loss 4.1029e-01 (2.2032e-01) 
2023-05-25 00:35:55.327082: val Epoch: [5][21/72]	Time  0.290 ( 0.769)	Data  0.001 ( 0.426)	Loss 1.2535e-01 (2.1601e-01) 
2023-05-25 00:35:56.663145: val Epoch: [5][22/72]	Time  1.336 ( 0.794)	Data  0.816 ( 0.443)	Loss 1.4436e-01 (2.1289e-01) 
2023-05-25 00:35:57.001842: val Epoch: [5][23/72]	Time  0.339 ( 0.775)	Data  0.001 ( 0.424)	Loss 3.6263e-01 (2.1913e-01) 
2023-05-25 00:35:57.990515: val Epoch: [5][24/72]	Time  0.989 ( 0.783)	Data  0.609 ( 0.432)	Loss 2.3168e-01 (2.1963e-01) 
2023-05-25 00:35:58.177633: val Epoch: [5][25/72]	Time  0.187 ( 0.760)	Data  0.001 ( 0.415)	Loss 1.3557e-01 (2.1640e-01) 
2023-05-25 00:35:59.315759: val Epoch: [5][26/72]	Time  1.138 ( 0.774)	Data  0.897 ( 0.433)	Loss 4.2683e-01 (2.2419e-01) 
2023-05-25 00:35:59.637156: val Epoch: [5][27/72]	Time  0.321 ( 0.758)	Data  0.001 ( 0.417)	Loss 1.1894e-01 (2.2043e-01) 
2023-05-25 00:36:00.738004: val Epoch: [5][28/72]	Time  1.101 ( 0.770)	Data  0.860 ( 0.433)	Loss 4.0561e-01 (2.2682e-01) 
2023-05-25 00:36:01.095375: val Epoch: [5][29/72]	Time  0.357 ( 0.756)	Data  0.001 ( 0.418)	Loss 2.2268e-01 (2.2668e-01) 
2023-05-25 00:36:02.180035: val Epoch: [5][30/72]	Time  1.085 ( 0.767)	Data  0.769 ( 0.430)	Loss 1.1394e-01 (2.2304e-01) 
2023-05-25 00:36:02.523044: val Epoch: [5][31/72]	Time  0.343 ( 0.754)	Data  0.001 ( 0.416)	Loss 1.2230e-01 (2.1990e-01) 
2023-05-25 00:36:03.798432: val Epoch: [5][32/72]	Time  1.275 ( 0.769)	Data  0.741 ( 0.426)	Loss 1.0101e-01 (2.1629e-01) 
2023-05-25 00:36:04.016034: val Epoch: [5][33/72]	Time  0.218 ( 0.753)	Data  0.001 ( 0.414)	Loss 9.3693e-02 (2.1269e-01) 
2023-05-25 00:36:04.902806: val Epoch: [5][34/72]	Time  0.887 ( 0.757)	Data  0.635 ( 0.420)	Loss 1.7183e-01 (2.1152e-01) 
2023-05-25 00:36:05.205397: val Epoch: [5][35/72]	Time  0.303 ( 0.744)	Data  0.001 ( 0.408)	Loss 1.6493e-01 (2.1023e-01) 
2023-05-25 00:36:06.448774: val Epoch: [5][36/72]	Time  1.243 ( 0.758)	Data  0.905 ( 0.422)	Loss 2.6863e-01 (2.1180e-01) 
2023-05-25 00:36:06.848190: val Epoch: [5][37/72]	Time  0.399 ( 0.748)	Data  0.001 ( 0.411)	Loss 1.3492e-01 (2.0978e-01) 
2023-05-25 00:36:07.862039: val Epoch: [5][38/72]	Time  1.014 ( 0.755)	Data  0.795 ( 0.420)	Loss 2.8767e-01 (2.1178e-01) 
2023-05-25 00:36:08.089434: val Epoch: [5][39/72]	Time  0.227 ( 0.742)	Data  0.001 ( 0.410)	Loss 2.6597e-01 (2.1313e-01) 
2023-05-25 00:36:09.355778: val Epoch: [5][40/72]	Time  1.266 ( 0.755)	Data  1.037 ( 0.425)	Loss 1.7285e-01 (2.1215e-01) 
2023-05-25 00:36:09.672906: val Epoch: [5][41/72]	Time  0.317 ( 0.744)	Data  0.001 ( 0.415)	Loss 2.2750e-01 (2.1252e-01) 
2023-05-25 00:36:10.933009: val Epoch: [5][42/72]	Time  1.260 ( 0.756)	Data  0.877 ( 0.426)	Loss 9.2757e-02 (2.0973e-01) 
2023-05-25 00:36:11.127390: val Epoch: [5][43/72]	Time  0.194 ( 0.744)	Data  0.001 ( 0.416)	Loss 2.4393e-01 (2.1051e-01) 
2023-05-25 00:36:12.168569: val Epoch: [5][44/72]	Time  1.041 ( 0.750)	Data  0.693 ( 0.422)	Loss 1.6421e-01 (2.0948e-01) 
2023-05-25 00:36:12.554819: val Epoch: [5][45/72]	Time  0.386 ( 0.742)	Data  0.002 ( 0.413)	Loss 8.6409e-02 (2.0680e-01) 
2023-05-25 00:36:13.489337: val Epoch: [5][46/72]	Time  0.934 ( 0.746)	Data  0.585 ( 0.417)	Loss 1.2956e-01 (2.0516e-01) 
2023-05-25 00:36:13.897073: val Epoch: [5][47/72]	Time  0.408 ( 0.739)	Data  0.001 ( 0.408)	Loss 1.8449e-01 (2.0473e-01) 
2023-05-25 00:36:14.693475: val Epoch: [5][48/72]	Time  0.796 ( 0.741)	Data  0.603 ( 0.412)	Loss 1.0088e-01 (2.0261e-01) 
2023-05-25 00:36:14.975483: val Epoch: [5][49/72]	Time  0.282 ( 0.731)	Data  0.001 ( 0.404)	Loss 1.1485e-01 (2.0085e-01) 
2023-05-25 00:36:16.320902: val Epoch: [5][50/72]	Time  1.345 ( 0.743)	Data  0.921 ( 0.414)	Loss 2.4848e-01 (2.0179e-01) 
2023-05-25 00:36:16.810094: val Epoch: [5][51/72]	Time  0.489 ( 0.739)	Data  0.001 ( 0.406)	Loss 5.2363e-01 (2.0798e-01) 
2023-05-25 00:36:17.581493: val Epoch: [5][52/72]	Time  0.771 ( 0.739)	Data  0.462 ( 0.407)	Loss 1.1733e-01 (2.0627e-01) 
2023-05-25 00:36:18.009748: val Epoch: [5][53/72]	Time  0.428 ( 0.733)	Data  0.001 ( 0.400)	Loss 8.7485e-02 (2.0407e-01) 
2023-05-25 00:36:18.878113: val Epoch: [5][54/72]	Time  0.868 ( 0.736)	Data  0.568 ( 0.403)	Loss 2.4442e-01 (2.0480e-01) 
2023-05-25 00:36:19.190011: val Epoch: [5][55/72]	Time  0.312 ( 0.728)	Data  0.001 ( 0.396)	Loss 1.4447e-01 (2.0372e-01) 
2023-05-25 00:36:20.392001: val Epoch: [5][56/72]	Time  1.202 ( 0.737)	Data  0.909 ( 0.405)	Loss 1.1590e-01 (2.0218e-01) 
2023-05-25 00:36:20.748159: val Epoch: [5][57/72]	Time  0.356 ( 0.730)	Data  0.001 ( 0.398)	Loss 1.8759e-01 (2.0193e-01) 
2023-05-25 00:36:21.865418: val Epoch: [5][58/72]	Time  1.117 ( 0.737)	Data  0.756 ( 0.404)	Loss 8.9315e-02 (2.0002e-01) 
2023-05-25 00:36:22.057462: val Epoch: [5][59/72]	Time  0.192 ( 0.728)	Data  0.001 ( 0.397)	Loss 1.0347e-01 (1.9841e-01) 
2023-05-25 00:36:23.252369: val Epoch: [5][60/72]	Time  1.195 ( 0.735)	Data  0.920 ( 0.406)	Loss 1.9047e-01 (1.9828e-01) 
2023-05-25 00:36:23.463934: val Epoch: [5][61/72]	Time  0.212 ( 0.727)	Data  0.001 ( 0.399)	Loss 2.0864e-01 (1.9845e-01) 
2023-05-25 00:36:24.792639: val Epoch: [5][62/72]	Time  1.329 ( 0.736)	Data  0.909 ( 0.407)	Loss 1.3731e-01 (1.9748e-01) 
2023-05-25 00:36:25.098527: val Epoch: [5][63/72]	Time  0.306 ( 0.730)	Data  0.001 ( 0.401)	Loss 1.9201e-01 (1.9739e-01) 
2023-05-25 00:36:26.127237: val Epoch: [5][64/72]	Time  1.029 ( 0.734)	Data  0.618 ( 0.404)	Loss 1.1563e-01 (1.9614e-01) 
2023-05-25 00:36:26.422803: val Epoch: [5][65/72]	Time  0.296 ( 0.728)	Data  0.001 ( 0.398)	Loss 9.0127e-02 (1.9453e-01) 
2023-05-25 00:36:27.654057: val Epoch: [5][66/72]	Time  1.231 ( 0.735)	Data  0.693 ( 0.402)	Loss 4.9029e-01 (1.9895e-01) 
2023-05-25 00:36:28.233538: val Epoch: [5][67/72]	Time  0.579 ( 0.733)	Data  0.004 ( 0.397)	Loss 1.7042e-01 (1.9853e-01) 
2023-05-25 00:36:28.953398: val Epoch: [5][68/72]	Time  0.720 ( 0.733)	Data  0.317 ( 0.395)	Loss 3.6781e-01 (2.0098e-01) 
2023-05-25 00:36:29.281306: val Epoch: [5][69/72]	Time  0.328 ( 0.727)	Data  0.001 ( 0.390)	Loss 1.9932e-01 (2.0096e-01) 
2023-05-25 00:36:30.174680: val Epoch: [5][70/72]	Time  0.893 ( 0.729)	Data  0.635 ( 0.393)	Loss 1.9676e-01 (2.0090e-01) 
2023-05-25 00:36:30.657295: val Epoch: [5][71/72]	Time  0.483 ( 0.726)	Data  0.132 ( 0.390)	Loss 1.4549e-01 (2.0013e-01) 
2023-05-25 00:36:30.946586: Epoch 5 :Val : ['ET : 0.6462194919586182', 'TC : 0.649189829826355', 'WT : 0.7989470958709717'] 
2023-05-25 00:36:30.951864: Epoch 5 :Val : ['ET : 0.6462194919586182', 'TC : 0.649189829826355', 'WT : 0.7989470958709717'] 
2023-05-25 00:36:30.955214: Saving the model with DSC 0.69105464220047 
2023-05-25 00:36:31.906783: Val epoch done in 54.54205153894145 s 
2023-05-25 00:36:31.913442: Batches per epoch:  193 
2023-05-25 00:36:36.474233: train Epoch: [6][  0/193]	Time  4.560 ( 4.560)	Data  3.168 ( 3.168)	Loss 1.4962e-01 (1.4962e-01) 
2023-05-25 00:36:37.729684: train Epoch: [6][  1/193]	Time  1.256 ( 2.908)	Data  0.002 ( 1.585)	Loss 1.6368e-01 (1.5665e-01) 
2023-05-25 00:36:39.366347: train Epoch: [6][  2/193]	Time  1.637 ( 2.484)	Data  0.314 ( 1.161)	Loss 1.6384e-01 (1.5904e-01) 
2023-05-25 00:36:40.415308: train Epoch: [6][  3/193]	Time  1.049 ( 2.125)	Data  0.001 ( 0.871)	Loss 1.0592e-01 (1.4576e-01) 
2023-05-25 00:36:42.124960: train Epoch: [6][  4/193]	Time  1.710 ( 2.042)	Data  0.468 ( 0.791)	Loss 5.5433e-02 (1.2770e-01) 
2023-05-25 00:36:43.107296: train Epoch: [6][  5/193]	Time  0.982 ( 1.866)	Data  0.001 ( 0.659)	Loss 1.4395e-01 (1.3041e-01) 
2023-05-25 00:36:44.862919: train Epoch: [6][  6/193]	Time  1.756 ( 1.850)	Data  0.653 ( 0.658)	Loss 2.1573e-01 (1.4259e-01) 
2023-05-25 00:36:46.040520: train Epoch: [6][  7/193]	Time  1.178 ( 1.766)	Data  0.001 ( 0.576)	Loss 1.1765e-01 (1.3948e-01) 
2023-05-25 00:36:47.826971: train Epoch: [6][  8/193]	Time  1.786 ( 1.768)	Data  0.570 ( 0.575)	Loss 8.3379e-02 (1.3324e-01) 
2023-05-25 00:36:48.962631: train Epoch: [6][  9/193]	Time  1.136 ( 1.705)	Data  0.001 ( 0.518)	Loss 2.3273e-01 (1.4319e-01) 
2023-05-25 00:36:50.572839: train Epoch: [6][ 10/193]	Time  1.610 ( 1.696)	Data  0.520 ( 0.518)	Loss 1.4987e-01 (1.4380e-01) 
2023-05-25 00:36:51.724858: train Epoch: [6][ 11/193]	Time  1.152 ( 1.651)	Data  0.001 ( 0.475)	Loss 3.4413e-01 (1.6049e-01) 
2023-05-25 00:36:53.407823: train Epoch: [6][ 12/193]	Time  1.683 ( 1.653)	Data  0.554 ( 0.481)	Loss 8.1181e-02 (1.5439e-01) 
2023-05-25 00:36:54.497531: train Epoch: [6][ 13/193]	Time  1.090 ( 1.613)	Data  0.001 ( 0.447)	Loss 1.6620e-01 (1.5524e-01) 
2023-05-25 00:36:56.521211: train Epoch: [6][ 14/193]	Time  2.024 ( 1.640)	Data  0.892 ( 0.476)	Loss 1.4503e-01 (1.5455e-01) 
2023-05-25 00:36:57.635560: train Epoch: [6][ 15/193]	Time  1.114 ( 1.608)	Data  0.001 ( 0.447)	Loss 1.1589e-01 (1.5214e-01) 
2023-05-25 00:36:59.237006: train Epoch: [6][ 16/193]	Time  1.601 ( 1.607)	Data  0.542 ( 0.452)	Loss 1.8322e-01 (1.5397e-01) 
2023-05-25 00:37:00.400495: train Epoch: [6][ 17/193]	Time  1.164 ( 1.583)	Data  0.001 ( 0.427)	Loss 1.3532e-01 (1.5293e-01) 
2023-05-25 00:37:02.242679: train Epoch: [6][ 18/193]	Time  1.842 ( 1.596)	Data  0.562 ( 0.434)	Loss 1.2263e-01 (1.5134e-01) 
2023-05-25 00:37:03.191014: train Epoch: [6][ 19/193]	Time  0.948 ( 1.564)	Data  0.001 ( 0.413)	Loss 1.3905e-01 (1.5072e-01) 
2023-05-25 00:37:05.094259: train Epoch: [6][ 20/193]	Time  1.903 ( 1.580)	Data  0.634 ( 0.423)	Loss 1.0916e-01 (1.4874e-01) 
2023-05-25 00:37:06.158109: train Epoch: [6][ 21/193]	Time  1.064 ( 1.557)	Data  0.001 ( 0.404)	Loss 1.5560e-01 (1.4905e-01) 
2023-05-25 00:37:07.945591: train Epoch: [6][ 22/193]	Time  1.788 ( 1.567)	Data  0.561 ( 0.411)	Loss 1.8585e-01 (1.5065e-01) 
2023-05-25 00:37:08.878910: train Epoch: [6][ 23/193]	Time  0.933 ( 1.540)	Data  0.001 ( 0.394)	Loss 2.2844e-01 (1.5390e-01) 
2023-05-25 00:37:10.612061: train Epoch: [6][ 24/193]	Time  1.733 ( 1.548)	Data  0.620 ( 0.403)	Loss 3.3418e-01 (1.6111e-01) 
2023-05-25 00:37:11.548769: train Epoch: [6][ 25/193]	Time  0.937 ( 1.524)	Data  0.001 ( 0.387)	Loss 1.5632e-01 (1.6092e-01) 
2023-05-25 00:37:13.800179: train Epoch: [6][ 26/193]	Time  2.251 ( 1.551)	Data  0.980 ( 0.409)	Loss 2.1947e-01 (1.6309e-01) 
2023-05-25 00:37:14.945795: train Epoch: [6][ 27/193]	Time  1.146 ( 1.537)	Data  0.001 ( 0.395)	Loss 1.0658e-01 (1.6107e-01) 
2023-05-25 00:37:16.538066: train Epoch: [6][ 28/193]	Time  1.592 ( 1.539)	Data  0.562 ( 0.400)	Loss 2.0103e-01 (1.6245e-01) 
2023-05-25 00:37:17.537146: train Epoch: [6][ 29/193]	Time  0.999 ( 1.521)	Data  0.001 ( 0.387)	Loss 2.3271e-01 (1.6479e-01) 
2023-05-25 00:37:19.604171: train Epoch: [6][ 30/193]	Time  2.067 ( 1.538)	Data  0.799 ( 0.400)	Loss 1.3139e-01 (1.6372e-01) 
2023-05-25 00:37:20.704431: train Epoch: [6][ 31/193]	Time  1.100 ( 1.525)	Data  0.001 ( 0.388)	Loss 2.0085e-01 (1.6488e-01) 
2023-05-25 00:37:22.090903: train Epoch: [6][ 32/193]	Time  1.386 ( 1.521)	Data  0.260 ( 0.384)	Loss 1.4834e-01 (1.6437e-01) 
2023-05-25 00:37:23.146341: train Epoch: [6][ 33/193]	Time  1.055 ( 1.507)	Data  0.001 ( 0.373)	Loss 1.0846e-01 (1.6273e-01) 
2023-05-25 00:37:24.694464: train Epoch: [6][ 34/193]	Time  1.548 ( 1.508)	Data  0.550 ( 0.378)	Loss 1.9423e-01 (1.6363e-01) 
2023-05-25 00:37:25.800995: train Epoch: [6][ 35/193]	Time  1.107 ( 1.497)	Data  0.001 ( 0.367)	Loss 1.4598e-01 (1.6314e-01) 
2023-05-25 00:37:27.451907: train Epoch: [6][ 36/193]	Time  1.651 ( 1.501)	Data  0.513 ( 0.371)	Loss 1.2359e-01 (1.6207e-01) 
2023-05-25 00:37:28.465949: train Epoch: [6][ 37/193]	Time  1.014 ( 1.488)	Data  0.001 ( 0.362)	Loss 1.8391e-01 (1.6265e-01) 
2023-05-25 00:37:30.249065: train Epoch: [6][ 38/193]	Time  1.783 ( 1.496)	Data  0.476 ( 0.365)	Loss 1.9325e-01 (1.6343e-01) 
2023-05-25 00:37:31.201080: train Epoch: [6][ 39/193]	Time  0.952 ( 1.482)	Data  0.001 ( 0.355)	Loss 1.6257e-01 (1.6341e-01) 
2023-05-25 00:37:32.928635: train Epoch: [6][ 40/193]	Time  1.728 ( 1.488)	Data  0.437 ( 0.357)	Loss 1.1396e-01 (1.6220e-01) 
2023-05-25 00:37:34.005144: train Epoch: [6][ 41/193]	Time  1.076 ( 1.478)	Data  0.001 ( 0.349)	Loss 1.3148e-01 (1.6147e-01) 
2023-05-25 00:37:35.647197: train Epoch: [6][ 42/193]	Time  1.642 ( 1.482)	Data  0.440 ( 0.351)	Loss 1.6573e-01 (1.6157e-01) 
2023-05-25 00:37:36.693852: train Epoch: [6][ 43/193]	Time  1.047 ( 1.472)	Data  0.001 ( 0.343)	Loss 1.0329e-01 (1.6025e-01) 
2023-05-25 00:37:38.367692: train Epoch: [6][ 44/193]	Time  1.674 ( 1.477)	Data  0.518 ( 0.347)	Loss 9.9259e-02 (1.5889e-01) 
2023-05-25 00:37:39.445035: train Epoch: [6][ 45/193]	Time  1.077 ( 1.468)	Data  0.001 ( 0.339)	Loss 2.0208e-01 (1.5983e-01) 
2023-05-25 00:37:40.978603: train Epoch: [6][ 46/193]	Time  1.534 ( 1.469)	Data  0.607 ( 0.345)	Loss 1.3649e-01 (1.5933e-01) 
2023-05-25 00:37:41.986343: train Epoch: [6][ 47/193]	Time  1.008 ( 1.460)	Data  0.001 ( 0.338)	Loss 2.5310e-01 (1.6129e-01) 
2023-05-25 00:37:44.206879: train Epoch: [6][ 48/193]	Time  2.221 ( 1.475)	Data  0.955 ( 0.351)	Loss 1.2487e-01 (1.6054e-01) 
2023-05-25 00:37:45.575892: train Epoch: [6][ 49/193]	Time  1.369 ( 1.473)	Data  0.001 ( 0.344)	Loss 1.8787e-01 (1.6109e-01) 
2023-05-25 00:37:46.862794: train Epoch: [6][ 50/193]	Time  1.287 ( 1.470)	Data  0.224 ( 0.341)	Loss 8.7245e-02 (1.5964e-01) 
2023-05-25 00:37:47.944848: train Epoch: [6][ 51/193]	Time  1.082 ( 1.462)	Data  0.001 ( 0.335)	Loss 1.0252e-01 (1.5854e-01) 
2023-05-25 00:37:49.618449: train Epoch: [6][ 52/193]	Time  1.674 ( 1.466)	Data  0.594 ( 0.340)	Loss 1.7100e-01 (1.5878e-01) 
2023-05-25 00:37:50.656462: train Epoch: [6][ 53/193]	Time  1.038 ( 1.458)	Data  0.001 ( 0.333)	Loss 2.9547e-01 (1.6131e-01) 
2023-05-25 00:37:52.568806: train Epoch: [6][ 54/193]	Time  1.912 ( 1.466)	Data  0.707 ( 0.340)	Loss 1.1348e-01 (1.6044e-01) 
2023-05-25 00:37:53.606096: train Epoch: [6][ 55/193]	Time  1.037 ( 1.459)	Data  0.001 ( 0.334)	Loss 9.9523e-02 (1.5935e-01) 
2023-05-25 00:37:55.344426: train Epoch: [6][ 56/193]	Time  1.738 ( 1.464)	Data  0.441 ( 0.336)	Loss 1.5038e-01 (1.5919e-01) 
2023-05-25 00:37:56.459326: train Epoch: [6][ 57/193]	Time  1.115 ( 1.458)	Data  0.001 ( 0.330)	Loss 2.0414e-01 (1.5997e-01) 
2023-05-25 00:37:58.069079: train Epoch: [6][ 58/193]	Time  1.610 ( 1.460)	Data  0.325 ( 0.330)	Loss 1.0310e-01 (1.5901e-01) 
2023-05-25 00:37:59.039227: train Epoch: [6][ 59/193]	Time  0.970 ( 1.452)	Data  0.001 ( 0.325)	Loss 1.0457e-01 (1.5810e-01) 
2023-05-25 00:38:00.874362: train Epoch: [6][ 60/193]	Time  1.835 ( 1.458)	Data  0.561 ( 0.329)	Loss 8.8450e-02 (1.5696e-01) 
2023-05-25 00:38:01.852360: train Epoch: [6][ 61/193]	Time  0.978 ( 1.451)	Data  0.001 ( 0.323)	Loss 8.9223e-02 (1.5586e-01) 
2023-05-25 00:38:03.474602: train Epoch: [6][ 62/193]	Time  1.622 ( 1.453)	Data  0.536 ( 0.327)	Loss 1.4421e-01 (1.5568e-01) 
2023-05-25 00:38:04.536115: train Epoch: [6][ 63/193]	Time  1.061 ( 1.447)	Data  0.001 ( 0.322)	Loss 1.0427e-01 (1.5488e-01) 
2023-05-25 00:38:06.014940: train Epoch: [6][ 64/193]	Time  1.479 ( 1.448)	Data  0.404 ( 0.323)	Loss 1.3868e-01 (1.5463e-01) 
2023-05-25 00:38:07.154662: train Epoch: [6][ 65/193]	Time  1.140 ( 1.443)	Data  0.001 ( 0.318)	Loss 1.5780e-01 (1.5467e-01) 
2023-05-25 00:38:08.781153: train Epoch: [6][ 66/193]	Time  1.626 ( 1.446)	Data  0.542 ( 0.321)	Loss 8.8330e-02 (1.5368e-01) 
2023-05-25 00:38:10.007194: train Epoch: [6][ 67/193]	Time  1.226 ( 1.443)	Data  0.001 ( 0.317)	Loss 1.1559e-01 (1.5312e-01) 
2023-05-25 00:38:11.315709: train Epoch: [6][ 68/193]	Time  1.309 ( 1.441)	Data  0.273 ( 0.316)	Loss 1.3775e-01 (1.5290e-01) 
2023-05-25 00:38:12.361763: train Epoch: [6][ 69/193]	Time  1.046 ( 1.435)	Data  0.001 ( 0.311)	Loss 7.5807e-02 (1.5180e-01) 
2023-05-25 00:38:14.042969: train Epoch: [6][ 70/193]	Time  1.681 ( 1.438)	Data  0.629 ( 0.316)	Loss 2.0442e-01 (1.5254e-01) 
2023-05-25 00:38:15.183071: train Epoch: [6][ 71/193]	Time  1.140 ( 1.434)	Data  0.001 ( 0.312)	Loss 1.5248e-01 (1.5254e-01) 
2023-05-25 00:38:17.050720: train Epoch: [6][ 72/193]	Time  1.868 ( 1.440)	Data  0.614 ( 0.316)	Loss 1.0284e-01 (1.5186e-01) 
2023-05-25 00:38:18.105357: train Epoch: [6][ 73/193]	Time  1.055 ( 1.435)	Data  0.001 ( 0.311)	Loss 1.2051e-01 (1.5144e-01) 
2023-05-25 00:38:20.027691: train Epoch: [6][ 74/193]	Time  1.922 ( 1.442)	Data  0.449 ( 0.313)	Loss 1.4726e-01 (1.5138e-01) 
2023-05-25 00:38:21.133862: train Epoch: [6][ 75/193]	Time  1.106 ( 1.437)	Data  0.001 ( 0.309)	Loss 2.4444e-01 (1.5260e-01) 
2023-05-25 00:38:22.593466: train Epoch: [6][ 76/193]	Time  1.460 ( 1.437)	Data  0.199 ( 0.308)	Loss 1.1056e-01 (1.5206e-01) 
2023-05-25 00:38:23.590623: train Epoch: [6][ 77/193]	Time  0.997 ( 1.432)	Data  0.001 ( 0.304)	Loss 1.9672e-01 (1.5263e-01) 
2023-05-25 00:38:25.312140: train Epoch: [6][ 78/193]	Time  1.722 ( 1.435)	Data  0.511 ( 0.306)	Loss 1.7579e-01 (1.5292e-01) 
2023-05-25 00:38:26.528567: train Epoch: [6][ 79/193]	Time  1.216 ( 1.433)	Data  0.001 ( 0.303)	Loss 1.0872e-01 (1.5237e-01) 
2023-05-25 00:38:28.125932: train Epoch: [6][ 80/193]	Time  1.597 ( 1.435)	Data  0.430 ( 0.304)	Loss 2.3723e-01 (1.5342e-01) 
2023-05-25 00:38:29.382047: train Epoch: [6][ 81/193]	Time  1.256 ( 1.433)	Data  0.001 ( 0.300)	Loss 1.7684e-01 (1.5370e-01) 
2023-05-25 00:38:30.948505: train Epoch: [6][ 82/193]	Time  1.566 ( 1.434)	Data  0.386 ( 0.302)	Loss 1.0425e-01 (1.5311e-01) 
2023-05-25 00:38:32.078139: train Epoch: [6][ 83/193]	Time  1.130 ( 1.431)	Data  0.001 ( 0.298)	Loss 1.6820e-01 (1.5329e-01) 
2023-05-25 00:38:33.818678: train Epoch: [6][ 84/193]	Time  1.741 ( 1.434)	Data  0.663 ( 0.302)	Loss 2.8968e-01 (1.5489e-01) 
2023-05-25 00:38:34.846497: train Epoch: [6][ 85/193]	Time  1.028 ( 1.429)	Data  0.001 ( 0.299)	Loss 1.3321e-01 (1.5464e-01) 
2023-05-25 00:38:36.690924: train Epoch: [6][ 86/193]	Time  1.844 ( 1.434)	Data  0.770 ( 0.304)	Loss 1.9031e-01 (1.5505e-01) 
2023-05-25 00:38:37.775992: train Epoch: [6][ 87/193]	Time  1.085 ( 1.430)	Data  0.002 ( 0.301)	Loss 2.3550e-01 (1.5597e-01) 
2023-05-25 00:38:39.356750: train Epoch: [6][ 88/193]	Time  1.581 ( 1.432)	Data  0.620 ( 0.304)	Loss 1.1262e-01 (1.5548e-01) 
2023-05-25 00:38:40.407968: train Epoch: [6][ 89/193]	Time  1.051 ( 1.428)	Data  0.001 ( 0.301)	Loss 2.0238e-01 (1.5600e-01) 
2023-05-25 00:38:42.361145: train Epoch: [6][ 90/193]	Time  1.953 ( 1.433)	Data  0.709 ( 0.305)	Loss 1.5013e-01 (1.5593e-01) 
2023-05-25 00:38:43.396130: train Epoch: [6][ 91/193]	Time  1.035 ( 1.429)	Data  0.001 ( 0.302)	Loss 9.2096e-02 (1.5524e-01) 
2023-05-25 00:38:44.909121: train Epoch: [6][ 92/193]	Time  1.513 ( 1.430)	Data  0.390 ( 0.303)	Loss 9.2420e-02 (1.5457e-01) 
2023-05-25 00:38:46.075400: train Epoch: [6][ 93/193]	Time  1.166 ( 1.427)	Data  0.001 ( 0.300)	Loss 1.3461e-01 (1.5435e-01) 
2023-05-25 00:38:47.669068: train Epoch: [6][ 94/193]	Time  1.594 ( 1.429)	Data  0.419 ( 0.301)	Loss 1.2535e-01 (1.5405e-01) 
2023-05-25 00:38:48.887616: train Epoch: [6][ 95/193]	Time  1.219 ( 1.427)	Data  0.001 ( 0.298)	Loss 1.4345e-01 (1.5394e-01) 
2023-05-25 00:38:50.368631: train Epoch: [6][ 96/193]	Time  1.481 ( 1.427)	Data  0.303 ( 0.298)	Loss 1.3404e-01 (1.5373e-01) 
2023-05-25 00:38:51.597835: train Epoch: [6][ 97/193]	Time  1.229 ( 1.425)	Data  0.001 ( 0.295)	Loss 1.7859e-01 (1.5399e-01) 
2023-05-25 00:38:52.936518: train Epoch: [6][ 98/193]	Time  1.339 ( 1.424)	Data  0.444 ( 0.296)	Loss 1.5576e-01 (1.5400e-01) 
2023-05-25 00:38:53.875371: train Epoch: [6][ 99/193]	Time  0.939 ( 1.420)	Data  0.001 ( 0.294)	Loss 1.6019e-01 (1.5407e-01) 
2023-05-25 00:38:55.914625: train Epoch: [6][100/193]	Time  2.039 ( 1.426)	Data  0.965 ( 0.300)	Loss 3.8629e-01 (1.5637e-01) 
2023-05-25 00:38:56.964525: train Epoch: [6][101/193]	Time  1.050 ( 1.422)	Data  0.001 ( 0.297)	Loss 7.5204e-02 (1.5557e-01) 
2023-05-25 00:38:58.876534: train Epoch: [6][102/193]	Time  1.912 ( 1.427)	Data  0.706 ( 0.301)	Loss 1.3607e-01 (1.5538e-01) 
2023-05-25 00:38:59.983252: train Epoch: [6][103/193]	Time  1.107 ( 1.424)	Data  0.001 ( 0.298)	Loss 1.7351e-01 (1.5555e-01) 
2023-05-25 00:39:01.600371: train Epoch: [6][104/193]	Time  1.617 ( 1.426)	Data  0.437 ( 0.300)	Loss 2.3223e-01 (1.5628e-01) 
2023-05-25 00:39:02.676879: train Epoch: [6][105/193]	Time  1.077 ( 1.422)	Data  0.001 ( 0.297)	Loss 2.3958e-01 (1.5707e-01) 
2023-05-25 00:39:04.530839: train Epoch: [6][106/193]	Time  1.854 ( 1.426)	Data  0.551 ( 0.299)	Loss 1.9793e-01 (1.5745e-01) 
2023-05-25 00:39:05.569821: train Epoch: [6][107/193]	Time  1.039 ( 1.423)	Data  0.001 ( 0.296)	Loss 9.0849e-02 (1.5684e-01) 
2023-05-25 00:39:07.111030: train Epoch: [6][108/193]	Time  1.541 ( 1.424)	Data  0.415 ( 0.298)	Loss 1.6269e-01 (1.5689e-01) 
2023-05-25 00:39:08.246870: train Epoch: [6][109/193]	Time  1.136 ( 1.421)	Data  0.001 ( 0.295)	Loss 1.2891e-01 (1.5664e-01) 
2023-05-25 00:39:09.793085: train Epoch: [6][110/193]	Time  1.546 ( 1.422)	Data  0.506 ( 0.297)	Loss 9.0192e-02 (1.5604e-01) 
2023-05-25 00:39:10.978013: train Epoch: [6][111/193]	Time  1.185 ( 1.420)	Data  0.001 ( 0.294)	Loss 1.8079e-01 (1.5626e-01) 
2023-05-25 00:39:12.817241: train Epoch: [6][112/193]	Time  1.839 ( 1.424)	Data  0.626 ( 0.297)	Loss 1.2771e-01 (1.5601e-01) 
2023-05-25 00:39:14.125382: train Epoch: [6][113/193]	Time  1.308 ( 1.423)	Data  0.001 ( 0.294)	Loss 2.1382e-01 (1.5651e-01) 
2023-05-25 00:39:15.407924: train Epoch: [6][114/193]	Time  1.283 ( 1.422)	Data  0.253 ( 0.294)	Loss 1.5006e-01 (1.5646e-01) 
2023-05-25 00:39:16.414843: train Epoch: [6][115/193]	Time  1.007 ( 1.418)	Data  0.001 ( 0.292)	Loss 3.4191e-01 (1.5805e-01) 
2023-05-25 00:39:18.038523: train Epoch: [6][116/193]	Time  1.624 ( 1.420)	Data  0.695 ( 0.295)	Loss 2.2440e-01 (1.5862e-01) 
2023-05-25 00:39:18.982790: train Epoch: [6][117/193]	Time  0.944 ( 1.416)	Data  0.001 ( 0.293)	Loss 2.5766e-01 (1.5946e-01) 
2023-05-25 00:39:21.178920: train Epoch: [6][118/193]	Time  2.196 ( 1.422)	Data  0.942 ( 0.298)	Loss 1.4902e-01 (1.5937e-01) 
2023-05-25 00:39:22.144214: train Epoch: [6][119/193]	Time  0.965 ( 1.419)	Data  0.001 ( 0.296)	Loss 1.4359e-01 (1.5924e-01) 
2023-05-25 00:39:24.076071: train Epoch: [6][120/193]	Time  1.932 ( 1.423)	Data  0.653 ( 0.298)	Loss 1.2354e-01 (1.5895e-01) 
2023-05-25 00:39:25.072998: train Epoch: [6][121/193]	Time  0.997 ( 1.419)	Data  0.001 ( 0.296)	Loss 1.2540e-01 (1.5867e-01) 
2023-05-25 00:39:26.696561: train Epoch: [6][122/193]	Time  1.624 ( 1.421)	Data  0.499 ( 0.298)	Loss 1.4695e-01 (1.5858e-01) 
2023-05-25 00:39:27.832149: train Epoch: [6][123/193]	Time  1.136 ( 1.419)	Data  0.001 ( 0.295)	Loss 9.6128e-02 (1.5807e-01) 
2023-05-25 00:39:29.709396: train Epoch: [6][124/193]	Time  1.877 ( 1.422)	Data  0.570 ( 0.297)	Loss 9.1913e-02 (1.5754e-01) 
2023-05-25 00:39:30.669982: train Epoch: [6][125/193]	Time  0.961 ( 1.419)	Data  0.001 ( 0.295)	Loss 1.6096e-01 (1.5757e-01) 
2023-05-25 00:39:32.177458: train Epoch: [6][126/193]	Time  1.507 ( 1.419)	Data  0.527 ( 0.297)	Loss 1.8025e-01 (1.5775e-01) 
2023-05-25 00:39:33.282131: train Epoch: [6][127/193]	Time  1.105 ( 1.417)	Data  0.001 ( 0.295)	Loss 1.3391e-01 (1.5756e-01) 
2023-05-25 00:39:35.002002: train Epoch: [6][128/193]	Time  1.720 ( 1.419)	Data  0.649 ( 0.297)	Loss 2.6045e-01 (1.5836e-01) 
2023-05-25 00:39:36.095432: train Epoch: [6][129/193]	Time  1.093 ( 1.417)	Data  0.001 ( 0.295)	Loss 1.2937e-01 (1.5814e-01) 
2023-05-25 00:39:37.799273: train Epoch: [6][130/193]	Time  1.704 ( 1.419)	Data  0.664 ( 0.298)	Loss 1.0630e-01 (1.5774e-01) 
2023-05-25 00:39:38.919416: train Epoch: [6][131/193]	Time  1.120 ( 1.417)	Data  0.001 ( 0.296)	Loss 2.3337e-01 (1.5831e-01) 
2023-05-25 00:39:40.656493: train Epoch: [6][132/193]	Time  1.737 ( 1.419)	Data  0.640 ( 0.298)	Loss 1.6714e-01 (1.5838e-01) 
2023-05-25 00:39:41.718748: train Epoch: [6][133/193]	Time  1.062 ( 1.416)	Data  0.001 ( 0.296)	Loss 1.7306e-01 (1.5849e-01) 
2023-05-25 00:39:43.423048: train Epoch: [6][134/193]	Time  1.704 ( 1.419)	Data  0.578 ( 0.298)	Loss 1.1285e-01 (1.5815e-01) 
2023-05-25 00:39:44.557625: train Epoch: [6][135/193]	Time  1.135 ( 1.416)	Data  0.001 ( 0.296)	Loss 1.6008e-01 (1.5817e-01) 
2023-05-25 00:39:46.368770: train Epoch: [6][136/193]	Time  1.811 ( 1.419)	Data  0.477 ( 0.297)	Loss 2.0448e-01 (1.5850e-01) 
2023-05-25 00:39:47.376578: train Epoch: [6][137/193]	Time  1.008 ( 1.416)	Data  0.001 ( 0.295)	Loss 1.5785e-01 (1.5850e-01) 
2023-05-25 00:39:49.081711: train Epoch: [6][138/193]	Time  1.705 ( 1.418)	Data  0.408 ( 0.296)	Loss 1.1001e-01 (1.5815e-01) 
2023-05-25 00:39:50.165952: train Epoch: [6][139/193]	Time  1.084 ( 1.416)	Data  0.001 ( 0.294)	Loss 1.3506e-01 (1.5799e-01) 
2023-05-25 00:39:51.757467: train Epoch: [6][140/193]	Time  1.592 ( 1.417)	Data  0.412 ( 0.295)	Loss 1.8338e-01 (1.5817e-01) 
2023-05-25 00:39:52.828690: train Epoch: [6][141/193]	Time  1.071 ( 1.415)	Data  0.001 ( 0.293)	Loss 1.5281e-01 (1.5813e-01) 
2023-05-25 00:39:54.412291: train Epoch: [6][142/193]	Time  1.584 ( 1.416)	Data  0.525 ( 0.294)	Loss 1.3581e-01 (1.5797e-01) 
2023-05-25 00:39:55.524220: train Epoch: [6][143/193]	Time  1.112 ( 1.414)	Data  0.001 ( 0.292)	Loss 1.6523e-01 (1.5802e-01) 
2023-05-25 00:39:57.570928: train Epoch: [6][144/193]	Time  2.047 ( 1.418)	Data  0.675 ( 0.295)	Loss 1.5681e-01 (1.5801e-01) 
2023-05-25 00:39:58.681151: train Epoch: [6][145/193]	Time  1.110 ( 1.416)	Data  0.001 ( 0.293)	Loss 1.1137e-01 (1.5770e-01) 
2023-05-25 00:40:00.107795: train Epoch: [6][146/193]	Time  1.427 ( 1.416)	Data  0.413 ( 0.294)	Loss 1.0663e-01 (1.5735e-01) 
2023-05-25 00:40:01.127913: train Epoch: [6][147/193]	Time  1.020 ( 1.414)	Data  0.001 ( 0.292)	Loss 1.3573e-01 (1.5720e-01) 
2023-05-25 00:40:02.934525: train Epoch: [6][148/193]	Time  1.807 ( 1.416)	Data  0.818 ( 0.295)	Loss 1.4040e-01 (1.5709e-01) 
2023-05-25 00:40:04.019541: train Epoch: [6][149/193]	Time  1.085 ( 1.414)	Data  0.001 ( 0.293)	Loss 9.0117e-02 (1.5664e-01) 
2023-05-25 00:40:05.960353: train Epoch: [6][150/193]	Time  1.941 ( 1.418)	Data  0.759 ( 0.296)	Loss 1.4842e-01 (1.5659e-01) 
2023-05-25 00:40:06.985468: train Epoch: [6][151/193]	Time  1.025 ( 1.415)	Data  0.001 ( 0.294)	Loss 1.4525e-01 (1.5651e-01) 
2023-05-25 00:40:08.822510: train Epoch: [6][152/193]	Time  1.837 ( 1.418)	Data  0.705 ( 0.297)	Loss 2.5504e-01 (1.5716e-01) 
2023-05-25 00:40:09.893183: train Epoch: [6][153/193]	Time  1.071 ( 1.415)	Data  0.001 ( 0.295)	Loss 3.8496e-01 (1.5864e-01) 
2023-05-25 00:40:11.770596: train Epoch: [6][154/193]	Time  1.877 ( 1.418)	Data  0.601 ( 0.297)	Loss 1.1283e-01 (1.5834e-01) 
2023-05-25 00:40:12.857456: train Epoch: [6][155/193]	Time  1.087 ( 1.416)	Data  0.001 ( 0.295)	Loss 1.8615e-01 (1.5852e-01) 
2023-05-25 00:40:14.299592: train Epoch: [6][156/193]	Time  1.442 ( 1.416)	Data  0.430 ( 0.296)	Loss 1.2942e-01 (1.5833e-01) 
2023-05-25 00:40:15.290085: train Epoch: [6][157/193]	Time  0.990 ( 1.414)	Data  0.001 ( 0.294)	Loss 1.8361e-01 (1.5849e-01) 
2023-05-25 00:40:17.183706: train Epoch: [6][158/193]	Time  1.894 ( 1.417)	Data  0.682 ( 0.297)	Loss 1.5931e-01 (1.5850e-01) 
2023-05-25 00:40:18.212988: train Epoch: [6][159/193]	Time  1.029 ( 1.414)	Data  0.001 ( 0.295)	Loss 1.2339e-01 (1.5828e-01) 
2023-05-25 00:40:19.936364: train Epoch: [6][160/193]	Time  1.723 ( 1.416)	Data  0.637 ( 0.297)	Loss 1.2408e-01 (1.5807e-01) 
2023-05-25 00:40:21.002663: train Epoch: [6][161/193]	Time  1.066 ( 1.414)	Data  0.002 ( 0.295)	Loss 1.7438e-01 (1.5817e-01) 
2023-05-25 00:40:22.906090: train Epoch: [6][162/193]	Time  1.903 ( 1.417)	Data  0.814 ( 0.298)	Loss 1.3467e-01 (1.5802e-01) 
2023-05-25 00:40:24.119968: train Epoch: [6][163/193]	Time  1.214 ( 1.416)	Data  0.001 ( 0.296)	Loss 1.1393e-01 (1.5776e-01) 
2023-05-25 00:40:25.634237: train Epoch: [6][164/193]	Time  1.514 ( 1.416)	Data  0.437 ( 0.297)	Loss 1.1953e-01 (1.5752e-01) 
2023-05-25 00:40:26.816644: train Epoch: [6][165/193]	Time  1.182 ( 1.415)	Data  0.001 ( 0.296)	Loss 9.0195e-02 (1.5712e-01) 
2023-05-25 00:40:28.439631: train Epoch: [6][166/193]	Time  1.623 ( 1.416)	Data  0.550 ( 0.297)	Loss 1.0384e-01 (1.5680e-01) 
2023-05-25 00:40:29.563169: train Epoch: [6][167/193]	Time  1.124 ( 1.415)	Data  0.001 ( 0.295)	Loss 2.2909e-01 (1.5723e-01) 
2023-05-25 00:40:31.364001: train Epoch: [6][168/193]	Time  1.801 ( 1.417)	Data  0.487 ( 0.296)	Loss 1.6238e-01 (1.5726e-01) 
2023-05-25 00:40:32.408941: train Epoch: [6][169/193]	Time  1.045 ( 1.415)	Data  0.001 ( 0.295)	Loss 1.5104e-01 (1.5722e-01) 
2023-05-25 00:40:33.778927: train Epoch: [6][170/193]	Time  1.370 ( 1.414)	Data  0.356 ( 0.295)	Loss 2.7033e-01 (1.5788e-01) 
2023-05-25 00:40:34.791988: train Epoch: [6][171/193]	Time  1.013 ( 1.412)	Data  0.001 ( 0.293)	Loss 1.5493e-01 (1.5787e-01) 
2023-05-25 00:40:36.759580: train Epoch: [6][172/193]	Time  1.968 ( 1.415)	Data  0.798 ( 0.296)	Loss 1.3857e-01 (1.5776e-01) 
2023-05-25 00:40:37.822344: train Epoch: [6][173/193]	Time  1.063 ( 1.413)	Data  0.001 ( 0.295)	Loss 1.3173e-01 (1.5761e-01) 
2023-05-25 00:40:39.704264: train Epoch: [6][174/193]	Time  1.882 ( 1.416)	Data  0.615 ( 0.296)	Loss 1.2380e-01 (1.5741e-01) 
2023-05-25 00:40:40.683664: train Epoch: [6][175/193]	Time  0.979 ( 1.413)	Data  0.001 ( 0.295)	Loss 1.7786e-01 (1.5753e-01) 
2023-05-25 00:40:42.167291: train Epoch: [6][176/193]	Time  1.484 ( 1.414)	Data  0.468 ( 0.296)	Loss 1.8280e-01 (1.5767e-01) 
2023-05-25 00:40:43.317697: train Epoch: [6][177/193]	Time  1.150 ( 1.412)	Data  0.001 ( 0.294)	Loss 1.5355e-01 (1.5765e-01) 
2023-05-25 00:40:45.182977: train Epoch: [6][178/193]	Time  1.865 ( 1.415)	Data  0.647 ( 0.296)	Loss 1.6664e-01 (1.5770e-01) 
2023-05-25 00:40:46.392481: train Epoch: [6][179/193]	Time  1.210 ( 1.414)	Data  0.001 ( 0.294)	Loss 2.8247e-01 (1.5839e-01) 
2023-05-25 00:40:47.924686: train Epoch: [6][180/193]	Time  1.532 ( 1.414)	Data  0.447 ( 0.295)	Loss 1.7016e-01 (1.5846e-01) 
2023-05-25 00:40:49.155149: train Epoch: [6][181/193]	Time  1.230 ( 1.413)	Data  0.001 ( 0.294)	Loss 2.1589e-01 (1.5877e-01) 
2023-05-25 00:40:50.777947: train Epoch: [6][182/193]	Time  1.623 ( 1.415)	Data  0.388 ( 0.294)	Loss 7.1785e-02 (1.5830e-01) 
2023-05-25 00:40:51.922671: train Epoch: [6][183/193]	Time  1.145 ( 1.413)	Data  0.001 ( 0.293)	Loss 1.6169e-01 (1.5832e-01) 
2023-05-25 00:40:53.342036: train Epoch: [6][184/193]	Time  1.419 ( 1.413)	Data  0.358 ( 0.293)	Loss 1.0673e-01 (1.5804e-01) 
2023-05-25 00:40:54.510180: train Epoch: [6][185/193]	Time  1.168 ( 1.412)	Data  0.001 ( 0.291)	Loss 1.7977e-01 (1.5815e-01) 
2023-05-25 00:40:56.206268: train Epoch: [6][186/193]	Time  1.696 ( 1.413)	Data  0.527 ( 0.293)	Loss 1.8123e-01 (1.5828e-01) 
2023-05-25 00:40:57.247359: train Epoch: [6][187/193]	Time  1.041 ( 1.411)	Data  0.001 ( 0.291)	Loss 1.8611e-01 (1.5843e-01) 
2023-05-25 00:40:59.182655: train Epoch: [6][188/193]	Time  1.935 ( 1.414)	Data  0.563 ( 0.292)	Loss 1.6357e-01 (1.5845e-01) 
2023-05-25 00:41:00.290488: train Epoch: [6][189/193]	Time  1.108 ( 1.413)	Data  0.001 ( 0.291)	Loss 1.6106e-01 (1.5847e-01) 
2023-05-25 00:41:01.802217: train Epoch: [6][190/193]	Time  1.512 ( 1.413)	Data  0.221 ( 0.291)	Loss 1.3499e-01 (1.5834e-01) 
2023-05-25 00:41:02.873924: train Epoch: [6][191/193]	Time  1.072 ( 1.411)	Data  0.001 ( 0.289)	Loss 1.4384e-01 (1.5827e-01) 
2023-05-25 00:41:03.878521: train Epoch: [6][192/193]	Time  1.005 ( 1.409)	Data  0.001 ( 0.288)	Loss 1.4613e-01 (1.5820e-01) 
2023-05-25 00:41:03.943356: Train Epoch done in 272.02997449901886 s 
2023-05-25 00:41:07.227920: val Epoch: [6][ 0/72]	Time  2.378 ( 2.378)	Data  1.809 ( 1.809)	Loss 9.3101e-02 (9.3101e-02) 
2023-05-25 00:41:07.555149: val Epoch: [6][ 1/72]	Time  0.327 ( 1.353)	Data  0.002 ( 0.905)	Loss 2.1357e-01 (1.5333e-01) 
2023-05-25 00:41:08.260357: val Epoch: [6][ 2/72]	Time  0.705 ( 1.137)	Data  0.373 ( 0.728)	Loss 1.1242e-01 (1.3970e-01) 
2023-05-25 00:41:08.694475: val Epoch: [6][ 3/72]	Time  0.434 ( 0.961)	Data  0.001 ( 0.546)	Loss 1.6242e-01 (1.4538e-01) 
2023-05-25 00:41:09.880257: val Epoch: [6][ 4/72]	Time  1.186 ( 1.006)	Data  0.651 ( 0.567)	Loss 4.4654e-01 (2.0561e-01) 
2023-05-25 00:41:10.315080: val Epoch: [6][ 5/72]	Time  0.435 ( 0.911)	Data  0.001 ( 0.473)	Loss 1.5348e-01 (1.9692e-01) 
2023-05-25 00:41:11.228627: val Epoch: [6][ 6/72]	Time  0.914 ( 0.911)	Data  0.489 ( 0.475)	Loss 5.2004e-01 (2.4308e-01) 
2023-05-25 00:41:11.418014: val Epoch: [6][ 7/72]	Time  0.189 ( 0.821)	Data  0.001 ( 0.416)	Loss 2.3201e-01 (2.4170e-01) 
2023-05-25 00:41:12.672659: val Epoch: [6][ 8/72]	Time  1.255 ( 0.869)	Data  0.846 ( 0.464)	Loss 6.1831e-01 (2.8354e-01) 
2023-05-25 00:41:13.110769: val Epoch: [6][ 9/72]	Time  0.438 ( 0.826)	Data  0.005 ( 0.418)	Loss 8.0098e-02 (2.6320e-01) 
2023-05-25 00:41:14.224087: val Epoch: [6][10/72]	Time  1.113 ( 0.852)	Data  0.694 ( 0.443)	Loss 1.2198e-01 (2.5036e-01) 
2023-05-25 00:41:14.435594: val Epoch: [6][11/72]	Time  0.211 ( 0.799)	Data  0.001 ( 0.406)	Loss 8.7300e-02 (2.3677e-01) 
2023-05-25 00:41:15.527761: val Epoch: [6][12/72]	Time  1.092 ( 0.821)	Data  0.809 ( 0.437)	Loss 1.9087e-01 (2.3324e-01) 
2023-05-25 00:41:15.763274: val Epoch: [6][13/72]	Time  0.236 ( 0.780)	Data  0.001 ( 0.406)	Loss 1.0383e-01 (2.2400e-01) 
2023-05-25 00:41:17.114395: val Epoch: [6][14/72]	Time  1.351 ( 0.818)	Data  0.957 ( 0.443)	Loss 1.2563e-01 (2.1744e-01) 
2023-05-25 00:41:17.477376: val Epoch: [6][15/72]	Time  0.363 ( 0.789)	Data  0.001 ( 0.415)	Loss 2.0621e-01 (2.1674e-01) 
2023-05-25 00:41:18.593089: val Epoch: [6][16/72]	Time  1.116 ( 0.808)	Data  0.741 ( 0.434)	Loss 8.6642e-02 (2.0908e-01) 
2023-05-25 00:41:18.791906: val Epoch: [6][17/72]	Time  0.199 ( 0.775)	Data  0.001 ( 0.410)	Loss 6.0629e-01 (2.3115e-01) 
2023-05-25 00:41:20.081772: val Epoch: [6][18/72]	Time  1.290 ( 0.802)	Data  0.866 ( 0.434)	Loss 2.9539e-01 (2.3453e-01) 
2023-05-25 00:41:20.423246: val Epoch: [6][19/72]	Time  0.341 ( 0.779)	Data  0.001 ( 0.413)	Loss 1.0462e-01 (2.2804e-01) 
2023-05-25 00:41:21.587698: val Epoch: [6][20/72]	Time  1.164 ( 0.797)	Data  0.694 ( 0.426)	Loss 4.2949e-01 (2.3763e-01) 
2023-05-25 00:41:21.784670: val Epoch: [6][21/72]	Time  0.197 ( 0.770)	Data  0.001 ( 0.407)	Loss 9.8526e-02 (2.3131e-01) 
2023-05-25 00:41:22.758327: val Epoch: [6][22/72]	Time  0.974 ( 0.779)	Data  0.719 ( 0.420)	Loss 7.7547e-02 (2.2462e-01) 
2023-05-25 00:41:23.062559: val Epoch: [6][23/72]	Time  0.304 ( 0.759)	Data  0.002 ( 0.403)	Loss 2.0667e-01 (2.2387e-01) 
2023-05-25 00:41:24.257657: val Epoch: [6][24/72]	Time  1.195 ( 0.776)	Data  0.842 ( 0.420)	Loss 2.5985e-01 (2.2531e-01) 
2023-05-25 00:41:24.698883: val Epoch: [6][25/72]	Time  0.441 ( 0.763)	Data  0.001 ( 0.404)	Loss 1.2556e-01 (2.2148e-01) 
2023-05-25 00:41:25.574563: val Epoch: [6][26/72]	Time  0.876 ( 0.768)	Data  0.569 ( 0.410)	Loss 2.4761e-01 (2.2244e-01) 
2023-05-25 00:41:25.853533: val Epoch: [6][27/72]	Time  0.279 ( 0.750)	Data  0.001 ( 0.396)	Loss 9.0452e-02 (2.1773e-01) 
2023-05-25 00:41:27.067845: val Epoch: [6][28/72]	Time  1.214 ( 0.766)	Data  0.816 ( 0.410)	Loss 1.8421e-01 (2.1657e-01) 
2023-05-25 00:41:27.495384: val Epoch: [6][29/72]	Time  0.428 ( 0.755)	Data  0.005 ( 0.397)	Loss 4.2290e-01 (2.2345e-01) 
2023-05-25 00:41:28.381119: val Epoch: [6][30/72]	Time  0.886 ( 0.759)	Data  0.657 ( 0.405)	Loss 1.6029e-01 (2.2141e-01) 
2023-05-25 00:41:28.637906: val Epoch: [6][31/72]	Time  0.257 ( 0.743)	Data  0.001 ( 0.393)	Loss 9.8296e-02 (2.1757e-01) 
2023-05-25 00:41:29.912620: val Epoch: [6][32/72]	Time  1.275 ( 0.759)	Data  0.868 ( 0.407)	Loss 2.2647e-01 (2.1784e-01) 
2023-05-25 00:41:30.252401: val Epoch: [6][33/72]	Time  0.340 ( 0.747)	Data  0.001 ( 0.395)	Loss 1.3746e-01 (2.1547e-01) 
2023-05-25 00:41:31.448410: val Epoch: [6][34/72]	Time  1.196 ( 0.760)	Data  0.738 ( 0.405)	Loss 3.8201e-01 (2.2023e-01) 
2023-05-25 00:41:31.813685: val Epoch: [6][35/72]	Time  0.365 ( 0.749)	Data  0.001 ( 0.394)	Loss 1.6447e-01 (2.1868e-01) 
2023-05-25 00:41:32.945461: val Epoch: [6][36/72]	Time  1.132 ( 0.759)	Data  0.671 ( 0.401)	Loss 2.3178e-01 (2.1904e-01) 
2023-05-25 00:41:33.530354: val Epoch: [6][37/72]	Time  0.585 ( 0.755)	Data  0.001 ( 0.391)	Loss 5.4258e-01 (2.2755e-01) 
2023-05-25 00:41:34.418233: val Epoch: [6][38/72]	Time  0.888 ( 0.758)	Data  0.564 ( 0.395)	Loss 1.1206e-01 (2.2459e-01) 
2023-05-25 00:41:34.800786: val Epoch: [6][39/72]	Time  0.383 ( 0.749)	Data  0.001 ( 0.385)	Loss 1.1193e-01 (2.2177e-01) 
2023-05-25 00:41:35.887893: val Epoch: [6][40/72]	Time  1.087 ( 0.757)	Data  0.683 ( 0.392)	Loss 2.8497e-01 (2.2331e-01) 
2023-05-25 00:41:36.081633: val Epoch: [6][41/72]	Time  0.194 ( 0.744)	Data  0.001 ( 0.383)	Loss 1.0063e-01 (2.2039e-01) 
2023-05-25 00:41:37.105802: val Epoch: [6][42/72]	Time  1.024 ( 0.750)	Data  0.716 ( 0.391)	Loss 9.3987e-02 (2.1745e-01) 
2023-05-25 00:41:37.575680: val Epoch: [6][43/72]	Time  0.470 ( 0.744)	Data  0.084 ( 0.384)	Loss 1.1304e-01 (2.1508e-01) 
2023-05-25 00:41:38.920886: val Epoch: [6][44/72]	Time  1.345 ( 0.757)	Data  0.876 ( 0.395)	Loss 2.8374e-01 (2.1661e-01) 
2023-05-25 00:41:39.173723: val Epoch: [6][45/72]	Time  0.253 ( 0.746)	Data  0.001 ( 0.386)	Loss 9.3653e-02 (2.1393e-01) 
2023-05-25 00:41:40.158394: val Epoch: [6][46/72]	Time  0.985 ( 0.751)	Data  0.656 ( 0.392)	Loss 1.0432e-01 (2.1160e-01) 
2023-05-25 00:41:40.342395: val Epoch: [6][47/72]	Time  0.184 ( 0.739)	Data  0.001 ( 0.384)	Loss 1.0193e-01 (2.0932e-01) 
2023-05-25 00:41:41.609867: val Epoch: [6][48/72]	Time  1.267 ( 0.750)	Data  0.939 ( 0.395)	Loss 8.0125e-02 (2.0668e-01) 
2023-05-25 00:41:42.196983: val Epoch: [6][49/72]	Time  0.587 ( 0.747)	Data  0.001 ( 0.387)	Loss 1.0308e-01 (2.0461e-01) 
2023-05-25 00:41:43.030761: val Epoch: [6][50/72]	Time  0.834 ( 0.749)	Data  0.498 ( 0.389)	Loss 2.5477e-01 (2.0559e-01) 
2023-05-25 00:41:43.277102: val Epoch: [6][51/72]	Time  0.246 ( 0.739)	Data  0.001 ( 0.382)	Loss 4.4797e-01 (2.1025e-01) 
2023-05-25 00:41:44.329079: val Epoch: [6][52/72]	Time  1.052 ( 0.745)	Data  0.850 ( 0.391)	Loss 3.8538e-01 (2.1356e-01) 
2023-05-25 00:41:44.667547: val Epoch: [6][53/72]	Time  0.338 ( 0.737)	Data  0.075 ( 0.385)	Loss 8.2624e-02 (2.1113e-01) 
2023-05-25 00:41:45.956504: val Epoch: [6][54/72]	Time  1.289 ( 0.747)	Data  0.907 ( 0.394)	Loss 1.7538e-01 (2.1048e-01) 
2023-05-25 00:41:46.335559: val Epoch: [6][55/72]	Time  0.379 ( 0.741)	Data  0.001 ( 0.387)	Loss 2.4108e-01 (2.1103e-01) 
2023-05-25 00:41:47.320152: val Epoch: [6][56/72]	Time  0.985 ( 0.745)	Data  0.682 ( 0.393)	Loss 1.8368e-01 (2.1055e-01) 
2023-05-25 00:41:47.579910: val Epoch: [6][57/72]	Time  0.260 ( 0.737)	Data  0.001 ( 0.386)	Loss 1.1962e-01 (2.0898e-01) 
2023-05-25 00:41:48.740819: val Epoch: [6][58/72]	Time  1.161 ( 0.744)	Data  0.858 ( 0.394)	Loss 1.8291e-01 (2.0854e-01) 
2023-05-25 00:41:49.066254: val Epoch: [6][59/72]	Time  0.325 ( 0.737)	Data  0.001 ( 0.387)	Loss 1.0405e-01 (2.0680e-01) 
2023-05-25 00:41:50.202018: val Epoch: [6][60/72]	Time  1.136 ( 0.743)	Data  0.817 ( 0.394)	Loss 8.7317e-02 (2.0484e-01) 
2023-05-25 00:41:50.724219: val Epoch: [6][61/72]	Time  0.522 ( 0.740)	Data  0.001 ( 0.388)	Loss 1.9563e-01 (2.0469e-01) 
2023-05-25 00:41:51.648353: val Epoch: [6][62/72]	Time  0.924 ( 0.743)	Data  0.647 ( 0.392)	Loss 1.3910e-01 (2.0365e-01) 
2023-05-25 00:41:52.286138: val Epoch: [6][63/72]	Time  0.638 ( 0.741)	Data  0.064 ( 0.387)	Loss 2.8256e-01 (2.0488e-01) 
2023-05-25 00:41:53.152308: val Epoch: [6][64/72]	Time  0.866 ( 0.743)	Data  0.601 ( 0.390)	Loss 3.6268e-01 (2.0731e-01) 
2023-05-25 00:41:53.497463: val Epoch: [6][65/72]	Time  0.345 ( 0.737)	Data  0.055 ( 0.385)	Loss 8.8861e-02 (2.0552e-01) 
2023-05-25 00:41:54.825456: val Epoch: [6][66/72]	Time  1.328 ( 0.746)	Data  0.865 ( 0.392)	Loss 1.7720e-01 (2.0509e-01) 
2023-05-25 00:41:55.019497: val Epoch: [6][67/72]	Time  0.194 ( 0.738)	Data  0.001 ( 0.387)	Loss 8.3345e-02 (2.0330e-01) 
2023-05-25 00:41:56.282371: val Epoch: [6][68/72]	Time  1.263 ( 0.745)	Data  0.803 ( 0.393)	Loss 1.6267e-01 (2.0271e-01) 
2023-05-25 00:41:56.513427: val Epoch: [6][69/72]	Time  0.231 ( 0.738)	Data  0.001 ( 0.387)	Loss 1.3385e-01 (2.0173e-01) 
2023-05-25 00:41:57.742075: val Epoch: [6][70/72]	Time  1.229 ( 0.745)	Data  0.729 ( 0.392)	Loss 2.4063e-01 (2.0228e-01) 
2023-05-25 00:41:57.956347: val Epoch: [6][71/72]	Time  0.214 ( 0.738)	Data  0.001 ( 0.386)	Loss 1.1488e-01 (2.0106e-01) 
2023-05-25 00:41:58.156420: Epoch 6 :Val : ['ET : 0.6380913257598877', 'TC : 0.6558138728141785', 'WT : 0.7962913513183594'] 
2023-05-25 00:41:58.163962: Epoch 6 :Val : ['ET : 0.6380913257598877', 'TC : 0.6558138728141785', 'WT : 0.7962913513183594'] 
2023-05-25 00:41:58.174201: Val epoch done in 54.230843820027076 s 
2023-05-25 00:41:58.184329: Batches per epoch:  193 
2023-05-25 00:42:02.759286: train Epoch: [7][  0/193]	Time  4.574 ( 4.574)	Data  3.349 ( 3.349)	Loss 2.7170e-01 (2.7170e-01) 
2023-05-25 00:42:03.764361: train Epoch: [7][  1/193]	Time  1.005 ( 2.790)	Data  0.001 ( 1.675)	Loss 1.5647e-01 (2.1408e-01) 
2023-05-25 00:42:05.387920: train Epoch: [7][  2/193]	Time  1.624 ( 2.401)	Data  0.496 ( 1.282)	Loss 1.3721e-01 (1.8846e-01) 
2023-05-25 00:42:06.455724: train Epoch: [7][  3/193]	Time  1.068 ( 2.068)	Data  0.001 ( 0.962)	Loss 2.1563e-01 (1.9525e-01) 
2023-05-25 00:42:08.215052: train Epoch: [7][  4/193]	Time  1.759 ( 2.006)	Data  0.470 ( 0.863)	Loss 1.2805e-01 (1.8181e-01) 
2023-05-25 00:42:09.241166: train Epoch: [7][  5/193]	Time  1.026 ( 1.843)	Data  0.001 ( 0.720)	Loss 1.0513e-01 (1.6903e-01) 
2023-05-25 00:42:10.779151: train Epoch: [7][  6/193]	Time  1.538 ( 1.799)	Data  0.395 ( 0.673)	Loss 9.1903e-02 (1.5801e-01) 
2023-05-25 00:42:11.959493: train Epoch: [7][  7/193]	Time  1.180 ( 1.722)	Data  0.001 ( 0.589)	Loss 1.0870e-01 (1.5185e-01) 
2023-05-25 00:42:13.281143: train Epoch: [7][  8/193]	Time  1.322 ( 1.677)	Data  0.315 ( 0.559)	Loss 9.4242e-02 (1.4545e-01) 
2023-05-25 00:42:14.365841: train Epoch: [7][  9/193]	Time  1.085 ( 1.618)	Data  0.001 ( 0.503)	Loss 1.6023e-01 (1.4693e-01) 
2023-05-25 00:42:16.254621: train Epoch: [7][ 10/193]	Time  1.889 ( 1.643)	Data  0.617 ( 0.513)	Loss 1.7543e-01 (1.4952e-01) 
2023-05-25 00:42:17.509253: train Epoch: [7][ 11/193]	Time  1.255 ( 1.610)	Data  0.002 ( 0.471)	Loss 1.1711e-01 (1.4682e-01) 
2023-05-25 00:42:18.836894: train Epoch: [7][ 12/193]	Time  1.328 ( 1.589)	Data  0.234 ( 0.452)	Loss 9.4295e-02 (1.4278e-01) 
2023-05-25 00:42:19.937675: train Epoch: [7][ 13/193]	Time  1.101 ( 1.554)	Data  0.001 ( 0.420)	Loss 2.2274e-01 (1.4849e-01) 
2023-05-25 00:42:21.565916: train Epoch: [7][ 14/193]	Time  1.628 ( 1.559)	Data  0.561 ( 0.430)	Loss 1.2446e-01 (1.4689e-01) 
2023-05-25 00:42:22.585663: train Epoch: [7][ 15/193]	Time  1.020 ( 1.525)	Data  0.001 ( 0.403)	Loss 1.3080e-01 (1.4588e-01) 
2023-05-25 00:42:24.487701: train Epoch: [7][ 16/193]	Time  1.902 ( 1.547)	Data  0.571 ( 0.413)	Loss 2.3715e-01 (1.5125e-01) 
2023-05-25 00:42:25.534946: train Epoch: [7][ 17/193]	Time  1.047 ( 1.519)	Data  0.001 ( 0.390)	Loss 2.4619e-01 (1.5652e-01) 
2023-05-25 00:42:27.049041: train Epoch: [7][ 18/193]	Time  1.514 ( 1.519)	Data  0.284 ( 0.384)	Loss 1.7406e-01 (1.5745e-01) 
2023-05-25 00:42:28.139090: train Epoch: [7][ 19/193]	Time  1.090 ( 1.498)	Data  0.001 ( 0.365)	Loss 1.2630e-01 (1.5589e-01) 
2023-05-25 00:42:30.118862: train Epoch: [7][ 20/193]	Time  1.980 ( 1.521)	Data  0.475 ( 0.370)	Loss 1.6429e-01 (1.5629e-01) 
2023-05-25 00:42:31.245481: train Epoch: [7][ 21/193]	Time  1.127 ( 1.503)	Data  0.001 ( 0.354)	Loss 2.7760e-01 (1.6180e-01) 
2023-05-25 00:42:32.323847: train Epoch: [7][ 22/193]	Time  1.078 ( 1.484)	Data  0.094 ( 0.342)	Loss 1.0170e-01 (1.5919e-01) 
2023-05-25 00:42:33.582755: train Epoch: [7][ 23/193]	Time  1.259 ( 1.475)	Data  0.001 ( 0.328)	Loss 1.3358e-01 (1.5812e-01) 
2023-05-25 00:42:35.307706: train Epoch: [7][ 24/193]	Time  1.725 ( 1.485)	Data  0.509 ( 0.335)	Loss 1.2888e-01 (1.5695e-01) 
2023-05-25 00:42:36.556073: train Epoch: [7][ 25/193]	Time  1.248 ( 1.476)	Data  0.001 ( 0.322)	Loss 7.8174e-02 (1.5392e-01) 
2023-05-25 00:42:37.924908: train Epoch: [7][ 26/193]	Time  1.369 ( 1.472)	Data  0.313 ( 0.322)	Loss 2.4473e-01 (1.5729e-01) 
2023-05-25 00:42:39.087722: train Epoch: [7][ 27/193]	Time  1.163 ( 1.461)	Data  0.001 ( 0.311)	Loss 1.2960e-01 (1.5630e-01) 
2023-05-25 00:42:40.644136: train Epoch: [7][ 28/193]	Time  1.556 ( 1.464)	Data  0.397 ( 0.314)	Loss 1.1428e-01 (1.5485e-01) 
2023-05-25 00:42:41.671275: train Epoch: [7][ 29/193]	Time  1.027 ( 1.450)	Data  0.001 ( 0.303)	Loss 2.2204e-01 (1.5709e-01) 
2023-05-25 00:42:43.345956: train Epoch: [7][ 30/193]	Time  1.675 ( 1.457)	Data  0.452 ( 0.308)	Loss 3.2638e-01 (1.6255e-01) 
2023-05-25 00:42:44.342957: train Epoch: [7][ 31/193]	Time  0.997 ( 1.442)	Data  0.001 ( 0.298)	Loss 1.4894e-01 (1.6212e-01) 
2023-05-25 00:42:45.790260: train Epoch: [7][ 32/193]	Time  1.447 ( 1.443)	Data  0.512 ( 0.305)	Loss 7.2384e-02 (1.5941e-01) 
2023-05-25 00:42:46.820304: train Epoch: [7][ 33/193]	Time  1.030 ( 1.430)	Data  0.001 ( 0.296)	Loss 1.9484e-01 (1.6045e-01) 
2023-05-25 00:42:48.808316: train Epoch: [7][ 34/193]	Time  1.988 ( 1.446)	Data  0.841 ( 0.312)	Loss 3.2093e-01 (1.6503e-01) 
2023-05-25 00:42:49.867661: train Epoch: [7][ 35/193]	Time  1.059 ( 1.436)	Data  0.001 ( 0.303)	Loss 1.5231e-01 (1.6468e-01) 
2023-05-25 00:42:51.658061: train Epoch: [7][ 36/193]	Time  1.790 ( 1.445)	Data  0.577 ( 0.310)	Loss 1.3320e-01 (1.6383e-01) 
2023-05-25 00:42:52.825557: train Epoch: [7][ 37/193]	Time  1.167 ( 1.438)	Data  0.001 ( 0.302)	Loss 1.1093e-01 (1.6244e-01) 
2023-05-25 00:42:54.480267: train Epoch: [7][ 38/193]	Time  1.655 ( 1.443)	Data  0.339 ( 0.303)	Loss 1.0060e-01 (1.6085e-01) 
2023-05-25 00:42:55.792413: train Epoch: [7][ 39/193]	Time  1.312 ( 1.440)	Data  0.001 ( 0.296)	Loss 1.2704e-01 (1.6001e-01) 
2023-05-25 00:42:56.993623: train Epoch: [7][ 40/193]	Time  1.201 ( 1.434)	Data  0.143 ( 0.292)	Loss 1.2030e-01 (1.5904e-01) 
2023-05-25 00:42:58.236504: train Epoch: [7][ 41/193]	Time  1.243 ( 1.430)	Data  0.001 ( 0.285)	Loss 2.1714e-01 (1.6042e-01) 
2023-05-25 00:42:59.887666: train Epoch: [7][ 42/193]	Time  1.651 ( 1.435)	Data  0.499 ( 0.290)	Loss 1.4584e-01 (1.6008e-01) 
2023-05-25 00:43:00.966159: train Epoch: [7][ 43/193]	Time  1.079 ( 1.427)	Data  0.002 ( 0.283)	Loss 1.9499e-01 (1.6087e-01) 
2023-05-25 00:43:02.512903: train Epoch: [7][ 44/193]	Time  1.547 ( 1.430)	Data  0.601 ( 0.290)	Loss 1.1941e-01 (1.5995e-01) 
2023-05-25 00:43:03.491467: train Epoch: [7][ 45/193]	Time  0.979 ( 1.420)	Data  0.001 ( 0.284)	Loss 1.3522e-01 (1.5942e-01) 
2023-05-25 00:43:05.305094: train Epoch: [7][ 46/193]	Time  1.814 ( 1.428)	Data  0.836 ( 0.296)	Loss 1.5872e-01 (1.5940e-01) 
2023-05-25 00:43:06.401167: train Epoch: [7][ 47/193]	Time  1.096 ( 1.421)	Data  0.001 ( 0.290)	Loss 1.4104e-01 (1.5902e-01) 
2023-05-25 00:43:08.142024: train Epoch: [7][ 48/193]	Time  1.741 ( 1.428)	Data  0.598 ( 0.296)	Loss 2.2706e-01 (1.6041e-01) 
2023-05-25 00:43:09.241872: train Epoch: [7][ 49/193]	Time  1.100 ( 1.421)	Data  0.001 ( 0.290)	Loss 1.8140e-01 (1.6083e-01) 
2023-05-25 00:43:11.007267: train Epoch: [7][ 50/193]	Time  1.765 ( 1.428)	Data  0.513 ( 0.295)	Loss 1.1850e-01 (1.6000e-01) 
2023-05-25 00:43:11.964096: train Epoch: [7][ 51/193]	Time  0.957 ( 1.419)	Data  0.001 ( 0.289)	Loss 1.5499e-01 (1.5990e-01) 
2023-05-25 00:43:13.519825: train Epoch: [7][ 52/193]	Time  1.556 ( 1.421)	Data  0.510 ( 0.293)	Loss 1.3027e-01 (1.5934e-01) 
2023-05-25 00:43:14.663182: train Epoch: [7][ 53/193]	Time  1.143 ( 1.416)	Data  0.001 ( 0.288)	Loss 1.5038e-01 (1.5918e-01) 
2023-05-25 00:43:16.558659: train Epoch: [7][ 54/193]	Time  1.895 ( 1.425)	Data  0.666 ( 0.295)	Loss 1.0727e-01 (1.5823e-01) 
2023-05-25 00:43:17.617530: train Epoch: [7][ 55/193]	Time  1.059 ( 1.418)	Data  0.001 ( 0.289)	Loss 1.5808e-01 (1.5823e-01) 
2023-05-25 00:43:19.066191: train Epoch: [7][ 56/193]	Time  1.449 ( 1.419)	Data  0.435 ( 0.292)	Loss 1.4927e-01 (1.5807e-01) 
2023-05-25 00:43:20.152089: train Epoch: [7][ 57/193]	Time  1.086 ( 1.413)	Data  0.001 ( 0.287)	Loss 1.5266e-01 (1.5798e-01) 
2023-05-25 00:43:22.214638: train Epoch: [7][ 58/193]	Time  2.063 ( 1.424)	Data  0.802 ( 0.296)	Loss 2.1317e-01 (1.5891e-01) 
2023-05-25 00:43:23.238806: train Epoch: [7][ 59/193]	Time  1.024 ( 1.418)	Data  0.001 ( 0.291)	Loss 1.3657e-01 (1.5854e-01) 
2023-05-25 00:43:24.696538: train Epoch: [7][ 60/193]	Time  1.458 ( 1.418)	Data  0.417 ( 0.293)	Loss 1.7659e-01 (1.5884e-01) 
2023-05-25 00:43:25.793576: train Epoch: [7][ 61/193]	Time  1.097 ( 1.413)	Data  0.001 ( 0.288)	Loss 2.0933e-01 (1.5965e-01) 
2023-05-25 00:43:27.655636: train Epoch: [7][ 62/193]	Time  1.862 ( 1.420)	Data  0.555 ( 0.292)	Loss 1.6854e-01 (1.5979e-01) 
2023-05-25 00:43:28.651690: train Epoch: [7][ 63/193]	Time  0.996 ( 1.414)	Data  0.001 ( 0.288)	Loss 1.9251e-01 (1.6030e-01) 
2023-05-25 00:43:29.986089: train Epoch: [7][ 64/193]	Time  1.334 ( 1.412)	Data  0.378 ( 0.289)	Loss 1.8847e-01 (1.6074e-01) 
2023-05-25 00:43:30.950953: train Epoch: [7][ 65/193]	Time  0.965 ( 1.406)	Data  0.002 ( 0.285)	Loss 1.0850e-01 (1.5995e-01) 
2023-05-25 00:43:32.957951: train Epoch: [7][ 66/193]	Time  2.007 ( 1.415)	Data  0.880 ( 0.294)	Loss 2.8200e-01 (1.6177e-01) 
2023-05-25 00:43:34.065240: train Epoch: [7][ 67/193]	Time  1.107 ( 1.410)	Data  0.001 ( 0.289)	Loss 2.0955e-01 (1.6247e-01) 
2023-05-25 00:43:35.707849: train Epoch: [7][ 68/193]	Time  1.643 ( 1.413)	Data  0.581 ( 0.294)	Loss 1.1709e-01 (1.6181e-01) 
2023-05-25 00:43:36.784702: train Epoch: [7][ 69/193]	Time  1.077 ( 1.409)	Data  0.001 ( 0.289)	Loss 1.9727e-01 (1.6232e-01) 
2023-05-25 00:43:38.832277: train Epoch: [7][ 70/193]	Time  2.048 ( 1.418)	Data  0.582 ( 0.293)	Loss 1.2264e-01 (1.6176e-01) 
2023-05-25 00:43:39.808488: train Epoch: [7][ 71/193]	Time  0.976 ( 1.411)	Data  0.001 ( 0.289)	Loss 1.4428e-01 (1.6152e-01) 
2023-05-25 00:43:41.137939: train Epoch: [7][ 72/193]	Time  1.329 ( 1.410)	Data  0.236 ( 0.289)	Loss 2.1070e-01 (1.6219e-01) 
2023-05-25 00:43:42.135844: train Epoch: [7][ 73/193]	Time  0.998 ( 1.405)	Data  0.001 ( 0.285)	Loss 3.9085e-01 (1.6528e-01) 
2023-05-25 00:43:43.839589: train Epoch: [7][ 74/193]	Time  1.704 ( 1.409)	Data  0.548 ( 0.288)	Loss 2.9164e-01 (1.6697e-01) 
2023-05-25 00:43:45.032521: train Epoch: [7][ 75/193]	Time  1.193 ( 1.406)	Data  0.001 ( 0.285)	Loss 2.3932e-01 (1.6792e-01) 
2023-05-25 00:43:46.607574: train Epoch: [7][ 76/193]	Time  1.575 ( 1.408)	Data  0.427 ( 0.286)	Loss 1.1786e-01 (1.6727e-01) 
2023-05-25 00:43:47.715765: train Epoch: [7][ 77/193]	Time  1.108 ( 1.404)	Data  0.001 ( 0.283)	Loss 1.1898e-01 (1.6665e-01) 
2023-05-25 00:43:49.369695: train Epoch: [7][ 78/193]	Time  1.654 ( 1.407)	Data  0.405 ( 0.284)	Loss 1.8482e-01 (1.6688e-01) 
2023-05-25 00:43:50.402615: train Epoch: [7][ 79/193]	Time  1.033 ( 1.403)	Data  0.001 ( 0.281)	Loss 1.3149e-01 (1.6644e-01) 
2023-05-25 00:43:52.168250: train Epoch: [7][ 80/193]	Time  1.766 ( 1.407)	Data  0.359 ( 0.282)	Loss 1.6765e-01 (1.6645e-01) 
2023-05-25 00:43:53.172366: train Epoch: [7][ 81/193]	Time  1.004 ( 1.402)	Data  0.001 ( 0.278)	Loss 1.3352e-01 (1.6605e-01) 
2023-05-25 00:43:54.387834: train Epoch: [7][ 82/193]	Time  1.215 ( 1.400)	Data  0.213 ( 0.277)	Loss 1.3141e-01 (1.6563e-01) 
2023-05-25 00:43:55.419575: train Epoch: [7][ 83/193]	Time  1.032 ( 1.396)	Data  0.001 ( 0.274)	Loss 1.0541e-01 (1.6492e-01) 
2023-05-25 00:43:57.250921: train Epoch: [7][ 84/193]	Time  1.831 ( 1.401)	Data  0.709 ( 0.279)	Loss 2.4291e-01 (1.6583e-01) 
2023-05-25 00:43:58.304930: train Epoch: [7][ 85/193]	Time  1.054 ( 1.397)	Data  0.001 ( 0.276)	Loss 1.5727e-01 (1.6573e-01) 
2023-05-25 00:44:00.057870: train Epoch: [7][ 86/193]	Time  1.753 ( 1.401)	Data  0.556 ( 0.279)	Loss 1.3768e-01 (1.6541e-01) 
2023-05-25 00:44:01.174567: train Epoch: [7][ 87/193]	Time  1.117 ( 1.398)	Data  0.001 ( 0.276)	Loss 1.9907e-01 (1.6579e-01) 
2023-05-25 00:44:02.836406: train Epoch: [7][ 88/193]	Time  1.662 ( 1.401)	Data  0.468 ( 0.278)	Loss 1.3501e-01 (1.6545e-01) 
2023-05-25 00:44:03.882133: train Epoch: [7][ 89/193]	Time  1.046 ( 1.397)	Data  0.001 ( 0.275)	Loss 1.8337e-01 (1.6565e-01) 
2023-05-25 00:44:05.549337: train Epoch: [7][ 90/193]	Time  1.667 ( 1.400)	Data  0.517 ( 0.278)	Loss 2.6022e-01 (1.6669e-01) 
2023-05-25 00:44:06.533824: train Epoch: [7][ 91/193]	Time  0.984 ( 1.395)	Data  0.001 ( 0.275)	Loss 1.3751e-01 (1.6637e-01) 
2023-05-25 00:44:08.368386: train Epoch: [7][ 92/193]	Time  1.835 ( 1.400)	Data  0.555 ( 0.278)	Loss 1.6285e-01 (1.6633e-01) 
2023-05-25 00:44:09.327316: train Epoch: [7][ 93/193]	Time  0.959 ( 1.395)	Data  0.001 ( 0.275)	Loss 7.9587e-02 (1.6541e-01) 
2023-05-25 00:44:11.140394: train Epoch: [7][ 94/193]	Time  1.813 ( 1.400)	Data  0.467 ( 0.277)	Loss 1.6913e-01 (1.6545e-01) 
2023-05-25 00:44:12.289519: train Epoch: [7][ 95/193]	Time  1.149 ( 1.397)	Data  0.001 ( 0.274)	Loss 2.4003e-01 (1.6622e-01) 
2023-05-25 00:44:13.922869: train Epoch: [7][ 96/193]	Time  1.633 ( 1.399)	Data  0.405 ( 0.275)	Loss 1.3990e-01 (1.6595e-01) 
2023-05-25 00:44:15.037303: train Epoch: [7][ 97/193]	Time  1.114 ( 1.396)	Data  0.001 ( 0.273)	Loss 1.3409e-01 (1.6563e-01) 
2023-05-25 00:44:16.541120: train Epoch: [7][ 98/193]	Time  1.504 ( 1.398)	Data  0.425 ( 0.274)	Loss 1.0982e-01 (1.6506e-01) 
2023-05-25 00:44:17.682887: train Epoch: [7][ 99/193]	Time  1.142 ( 1.395)	Data  0.001 ( 0.271)	Loss 1.1486e-01 (1.6456e-01) 
2023-05-25 00:44:19.281847: train Epoch: [7][100/193]	Time  1.599 ( 1.397)	Data  0.505 ( 0.274)	Loss 3.6185e-01 (1.6652e-01) 
2023-05-25 00:44:20.245281: train Epoch: [7][101/193]	Time  0.963 ( 1.393)	Data  0.001 ( 0.271)	Loss 8.3710e-02 (1.6570e-01) 
2023-05-25 00:44:21.851442: train Epoch: [7][102/193]	Time  1.606 ( 1.395)	Data  0.553 ( 0.274)	Loss 1.5469e-01 (1.6560e-01) 
2023-05-25 00:44:22.847399: train Epoch: [7][103/193]	Time  0.996 ( 1.391)	Data  0.001 ( 0.271)	Loss 1.5029e-01 (1.6545e-01) 
2023-05-25 00:44:24.681271: train Epoch: [7][104/193]	Time  1.834 ( 1.395)	Data  0.558 ( 0.274)	Loss 1.2536e-01 (1.6507e-01) 
2023-05-25 00:44:25.646114: train Epoch: [7][105/193]	Time  0.965 ( 1.391)	Data  0.001 ( 0.271)	Loss 1.2549e-01 (1.6469e-01) 
2023-05-25 00:44:27.251953: train Epoch: [7][106/193]	Time  1.606 ( 1.393)	Data  0.293 ( 0.272)	Loss 1.1972e-01 (1.6427e-01) 
2023-05-25 00:44:28.279864: train Epoch: [7][107/193]	Time  1.028 ( 1.390)	Data  0.001 ( 0.269)	Loss 6.3538e-02 (1.6334e-01) 
2023-05-25 00:44:29.738408: train Epoch: [7][108/193]	Time  1.459 ( 1.390)	Data  0.408 ( 0.270)	Loss 1.2474e-01 (1.6299e-01) 
2023-05-25 00:44:30.909184: train Epoch: [7][109/193]	Time  1.171 ( 1.388)	Data  0.001 ( 0.268)	Loss 1.7598e-01 (1.6311e-01) 
2023-05-25 00:44:32.557151: train Epoch: [7][110/193]	Time  1.648 ( 1.391)	Data  0.448 ( 0.269)	Loss 7.4935e-02 (1.6231e-01) 
2023-05-25 00:44:33.559960: train Epoch: [7][111/193]	Time  1.003 ( 1.387)	Data  0.001 ( 0.267)	Loss 1.0850e-01 (1.6183e-01) 
2023-05-25 00:44:35.265373: train Epoch: [7][112/193]	Time  1.705 ( 1.390)	Data  0.513 ( 0.269)	Loss 1.6435e-01 (1.6185e-01) 
2023-05-25 00:44:36.383752: train Epoch: [7][113/193]	Time  1.118 ( 1.388)	Data  0.001 ( 0.267)	Loss 8.6426e-02 (1.6119e-01) 
2023-05-25 00:44:37.705164: train Epoch: [7][114/193]	Time  1.321 ( 1.387)	Data  0.428 ( 0.268)	Loss 9.2965e-02 (1.6060e-01) 
2023-05-25 00:44:38.791155: train Epoch: [7][115/193]	Time  1.086 ( 1.385)	Data  0.001 ( 0.266)	Loss 1.5784e-01 (1.6057e-01) 
2023-05-25 00:44:40.904154: train Epoch: [7][116/193]	Time  2.113 ( 1.391)	Data  0.773 ( 0.270)	Loss 1.5575e-01 (1.6053e-01) 
2023-05-25 00:44:41.964268: train Epoch: [7][117/193]	Time  1.060 ( 1.388)	Data  0.001 ( 0.268)	Loss 1.9591e-01 (1.6083e-01) 
2023-05-25 00:44:43.394273: train Epoch: [7][118/193]	Time  1.430 ( 1.388)	Data  0.338 ( 0.269)	Loss 1.4054e-01 (1.6066e-01) 
2023-05-25 00:44:44.405812: train Epoch: [7][119/193]	Time  1.012 ( 1.385)	Data  0.001 ( 0.266)	Loss 1.2100e-01 (1.6033e-01) 
2023-05-25 00:44:46.330947: train Epoch: [7][120/193]	Time  1.925 ( 1.390)	Data  0.861 ( 0.271)	Loss 1.3257e-01 (1.6010e-01) 
2023-05-25 00:44:47.550389: train Epoch: [7][121/193]	Time  1.219 ( 1.388)	Data  0.001 ( 0.269)	Loss 3.8308e-01 (1.6193e-01) 
2023-05-25 00:44:49.237982: train Epoch: [7][122/193]	Time  1.688 ( 1.391)	Data  0.599 ( 0.272)	Loss 1.4137e-01 (1.6176e-01) 
2023-05-25 00:44:50.346197: train Epoch: [7][123/193]	Time  1.108 ( 1.388)	Data  0.001 ( 0.270)	Loss 2.9891e-01 (1.6287e-01) 
2023-05-25 00:44:52.105189: train Epoch: [7][124/193]	Time  1.759 ( 1.391)	Data  0.589 ( 0.272)	Loss 2.4086e-01 (1.6349e-01) 
2023-05-25 00:44:53.293116: train Epoch: [7][125/193]	Time  1.188 ( 1.390)	Data  0.001 ( 0.270)	Loss 1.3668e-01 (1.6328e-01) 
2023-05-25 00:44:54.648411: train Epoch: [7][126/193]	Time  1.355 ( 1.389)	Data  0.337 ( 0.271)	Loss 2.1805e-01 (1.6371e-01) 
2023-05-25 00:44:55.769125: train Epoch: [7][127/193]	Time  1.121 ( 1.387)	Data  0.001 ( 0.268)	Loss 1.2566e-01 (1.6341e-01) 
2023-05-25 00:44:57.425829: train Epoch: [7][128/193]	Time  1.657 ( 1.389)	Data  0.519 ( 0.270)	Loss 1.7100e-01 (1.6347e-01) 
2023-05-25 00:44:58.422591: train Epoch: [7][129/193]	Time  0.997 ( 1.386)	Data  0.001 ( 0.268)	Loss 1.3482e-01 (1.6325e-01) 
2023-05-25 00:45:00.166277: train Epoch: [7][130/193]	Time  1.744 ( 1.389)	Data  0.583 ( 0.271)	Loss 1.6669e-01 (1.6328e-01) 
2023-05-25 00:45:01.147501: train Epoch: [7][131/193]	Time  0.981 ( 1.386)	Data  0.001 ( 0.269)	Loss 1.2355e-01 (1.6298e-01) 
2023-05-25 00:45:02.779836: train Epoch: [7][132/193]	Time  1.632 ( 1.388)	Data  0.441 ( 0.270)	Loss 9.2072e-02 (1.6244e-01) 
2023-05-25 00:45:03.780418: train Epoch: [7][133/193]	Time  1.001 ( 1.385)	Data  0.001 ( 0.268)	Loss 1.4617e-01 (1.6232e-01) 
2023-05-25 00:45:05.187899: train Epoch: [7][134/193]	Time  1.407 ( 1.385)	Data  0.408 ( 0.269)	Loss 1.0906e-01 (1.6193e-01) 
2023-05-25 00:45:06.435428: train Epoch: [7][135/193]	Time  1.248 ( 1.384)	Data  0.001 ( 0.267)	Loss 1.0217e-01 (1.6149e-01) 
2023-05-25 00:45:08.006130: train Epoch: [7][136/193]	Time  1.571 ( 1.386)	Data  0.372 ( 0.268)	Loss 2.8501e-01 (1.6239e-01) 
2023-05-25 00:45:09.221017: train Epoch: [7][137/193]	Time  1.215 ( 1.384)	Data  0.001 ( 0.266)	Loss 1.6288e-01 (1.6239e-01) 
2023-05-25 00:45:10.399369: train Epoch: [7][138/193]	Time  1.178 ( 1.383)	Data  0.215 ( 0.265)	Loss 1.0568e-01 (1.6199e-01) 
2023-05-25 00:45:11.459302: train Epoch: [7][139/193]	Time  1.060 ( 1.381)	Data  0.001 ( 0.264)	Loss 1.8962e-01 (1.6218e-01) 
2023-05-25 00:45:13.263703: train Epoch: [7][140/193]	Time  1.804 ( 1.384)	Data  0.646 ( 0.266)	Loss 1.8573e-01 (1.6235e-01) 
2023-05-25 00:45:14.303753: train Epoch: [7][141/193]	Time  1.040 ( 1.381)	Data  0.001 ( 0.264)	Loss 3.0202e-01 (1.6333e-01) 
2023-05-25 00:45:16.111436: train Epoch: [7][142/193]	Time  1.808 ( 1.384)	Data  0.482 ( 0.266)	Loss 1.2610e-01 (1.6307e-01) 
2023-05-25 00:45:17.211130: train Epoch: [7][143/193]	Time  1.100 ( 1.382)	Data  0.001 ( 0.264)	Loss 1.2170e-01 (1.6279e-01) 
2023-05-25 00:45:18.751427: train Epoch: [7][144/193]	Time  1.540 ( 1.383)	Data  0.291 ( 0.264)	Loss 3.4706e-01 (1.6406e-01) 
2023-05-25 00:45:19.822886: train Epoch: [7][145/193]	Time  1.071 ( 1.381)	Data  0.001 ( 0.263)	Loss 9.7774e-02 (1.6360e-01) 
2023-05-25 00:45:21.363477: train Epoch: [7][146/193]	Time  1.541 ( 1.382)	Data  0.407 ( 0.263)	Loss 1.9389e-01 (1.6381e-01) 
2023-05-25 00:45:22.542753: train Epoch: [7][147/193]	Time  1.179 ( 1.381)	Data  0.001 ( 0.262)	Loss 1.1426e-01 (1.6347e-01) 
2023-05-25 00:45:23.936321: train Epoch: [7][148/193]	Time  1.394 ( 1.381)	Data  0.315 ( 0.262)	Loss 1.2954e-01 (1.6325e-01) 
2023-05-25 00:45:25.195230: train Epoch: [7][149/193]	Time  1.259 ( 1.380)	Data  0.001 ( 0.260)	Loss 1.1668e-01 (1.6294e-01) 
2023-05-25 00:45:26.781950: train Epoch: [7][150/193]	Time  1.587 ( 1.381)	Data  0.403 ( 0.261)	Loss 1.1024e-01 (1.6259e-01) 
2023-05-25 00:45:27.869518: train Epoch: [7][151/193]	Time  1.088 ( 1.379)	Data  0.001 ( 0.260)	Loss 2.9494e-01 (1.6346e-01) 
2023-05-25 00:45:29.354351: train Epoch: [7][152/193]	Time  1.485 ( 1.380)	Data  0.440 ( 0.261)	Loss 2.7996e-01 (1.6422e-01) 
2023-05-25 00:45:30.393595: train Epoch: [7][153/193]	Time  1.039 ( 1.378)	Data  0.001 ( 0.259)	Loss 1.7118e-01 (1.6427e-01) 
2023-05-25 00:45:32.111187: train Epoch: [7][154/193]	Time  1.718 ( 1.380)	Data  0.672 ( 0.262)	Loss 1.9552e-01 (1.6447e-01) 
2023-05-25 00:45:33.149639: train Epoch: [7][155/193]	Time  1.038 ( 1.378)	Data  0.001 ( 0.260)	Loss 2.5073e-01 (1.6502e-01) 
2023-05-25 00:45:34.820723: train Epoch: [7][156/193]	Time  1.671 ( 1.380)	Data  0.579 ( 0.262)	Loss 1.4388e-01 (1.6488e-01) 
2023-05-25 00:45:35.736337: train Epoch: [7][157/193]	Time  0.916 ( 1.377)	Data  0.001 ( 0.260)	Loss 7.8137e-02 (1.6434e-01) 
2023-05-25 00:45:37.793064: train Epoch: [7][158/193]	Time  2.057 ( 1.381)	Data  0.726 ( 0.263)	Loss 1.3299e-01 (1.6414e-01) 
2023-05-25 00:45:38.795410: train Epoch: [7][159/193]	Time  1.002 ( 1.379)	Data  0.001 ( 0.262)	Loss 1.6549e-01 (1.6415e-01) 
2023-05-25 00:45:40.173772: train Epoch: [7][160/193]	Time  1.378 ( 1.379)	Data  0.402 ( 0.263)	Loss 1.0999e-01 (1.6381e-01) 
2023-05-25 00:45:41.364614: train Epoch: [7][161/193]	Time  1.191 ( 1.378)	Data  0.001 ( 0.261)	Loss 1.0619e-01 (1.6346e-01) 
2023-05-25 00:45:43.009985: train Epoch: [7][162/193]	Time  1.645 ( 1.379)	Data  0.569 ( 0.263)	Loss 1.1419e-01 (1.6315e-01) 
2023-05-25 00:45:44.167397: train Epoch: [7][163/193]	Time  1.157 ( 1.378)	Data  0.001 ( 0.261)	Loss 2.6973e-01 (1.6380e-01) 
2023-05-25 00:45:45.616052: train Epoch: [7][164/193]	Time  1.449 ( 1.378)	Data  0.407 ( 0.262)	Loss 1.9630e-01 (1.6400e-01) 
2023-05-25 00:45:46.948358: train Epoch: [7][165/193]	Time  1.332 ( 1.378)	Data  0.001 ( 0.261)	Loss 2.9569e-01 (1.6479e-01) 
2023-05-25 00:45:48.539466: train Epoch: [7][166/193]	Time  1.591 ( 1.379)	Data  0.360 ( 0.261)	Loss 1.3975e-01 (1.6464e-01) 
2023-05-25 00:45:49.645577: train Epoch: [7][167/193]	Time  1.106 ( 1.378)	Data  0.001 ( 0.260)	Loss 1.1148e-01 (1.6433e-01) 
2023-05-25 00:45:51.097467: train Epoch: [7][168/193]	Time  1.452 ( 1.378)	Data  0.427 ( 0.261)	Loss 1.2319e-01 (1.6408e-01) 
2023-05-25 00:45:52.052630: train Epoch: [7][169/193]	Time  0.955 ( 1.376)	Data  0.001 ( 0.259)	Loss 1.4045e-01 (1.6394e-01) 
2023-05-25 00:45:53.924772: train Epoch: [7][170/193]	Time  1.872 ( 1.379)	Data  0.698 ( 0.262)	Loss 1.7739e-01 (1.6402e-01) 
2023-05-25 00:45:54.902873: train Epoch: [7][171/193]	Time  0.978 ( 1.376)	Data  0.001 ( 0.260)	Loss 2.4845e-01 (1.6451e-01) 
2023-05-25 00:45:56.640627: train Epoch: [7][172/193]	Time  1.738 ( 1.378)	Data  0.515 ( 0.262)	Loss 2.0780e-01 (1.6476e-01) 
2023-05-25 00:45:57.696873: train Epoch: [7][173/193]	Time  1.056 ( 1.377)	Data  0.001 ( 0.260)	Loss 1.2371e-01 (1.6453e-01) 
2023-05-25 00:45:59.338506: train Epoch: [7][174/193]	Time  1.642 ( 1.378)	Data  0.431 ( 0.261)	Loss 1.1668e-01 (1.6425e-01) 
2023-05-25 00:46:00.383217: train Epoch: [7][175/193]	Time  1.045 ( 1.376)	Data  0.001 ( 0.260)	Loss 1.2542e-01 (1.6403e-01) 
2023-05-25 00:46:01.969226: train Epoch: [7][176/193]	Time  1.586 ( 1.377)	Data  0.487 ( 0.261)	Loss 2.9623e-01 (1.6478e-01) 
2023-05-25 00:46:03.194441: train Epoch: [7][177/193]	Time  1.225 ( 1.376)	Data  0.001 ( 0.259)	Loss 1.9572e-01 (1.6495e-01) 
2023-05-25 00:46:04.514647: train Epoch: [7][178/193]	Time  1.320 ( 1.376)	Data  0.409 ( 0.260)	Loss 1.3195e-01 (1.6477e-01) 
2023-05-25 00:46:05.575375: train Epoch: [7][179/193]	Time  1.061 ( 1.374)	Data  0.001 ( 0.259)	Loss 1.4080e-01 (1.6464e-01) 
2023-05-25 00:46:07.517615: train Epoch: [7][180/193]	Time  1.942 ( 1.378)	Data  0.802 ( 0.262)	Loss 2.9483e-01 (1.6536e-01) 
2023-05-25 00:46:08.551056: train Epoch: [7][181/193]	Time  1.033 ( 1.376)	Data  0.001 ( 0.260)	Loss 1.3666e-01 (1.6520e-01) 
2023-05-25 00:46:10.119677: train Epoch: [7][182/193]	Time  1.569 ( 1.377)	Data  0.562 ( 0.262)	Loss 1.4291e-01 (1.6508e-01) 
2023-05-25 00:46:11.084318: train Epoch: [7][183/193]	Time  0.965 ( 1.374)	Data  0.001 ( 0.261)	Loss 1.8697e-01 (1.6520e-01) 
2023-05-25 00:46:12.915632: train Epoch: [7][184/193]	Time  1.831 ( 1.377)	Data  0.732 ( 0.263)	Loss 1.0262e-01 (1.6486e-01) 
2023-05-25 00:46:13.967970: train Epoch: [7][185/193]	Time  1.052 ( 1.375)	Data  0.002 ( 0.262)	Loss 1.5563e-01 (1.6481e-01) 
2023-05-25 00:46:15.627350: train Epoch: [7][186/193]	Time  1.659 ( 1.377)	Data  0.522 ( 0.263)	Loss 1.4538e-01 (1.6470e-01) 
2023-05-25 00:46:16.742676: train Epoch: [7][187/193]	Time  1.115 ( 1.375)	Data  0.001 ( 0.262)	Loss 1.0816e-01 (1.6440e-01) 
2023-05-25 00:46:18.370735: train Epoch: [7][188/193]	Time  1.628 ( 1.377)	Data  0.540 ( 0.263)	Loss 1.5229e-01 (1.6434e-01) 
2023-05-25 00:46:19.661969: train Epoch: [7][189/193]	Time  1.291 ( 1.376)	Data  0.001 ( 0.262)	Loss 9.2856e-02 (1.6396e-01) 
2023-05-25 00:46:20.915724: train Epoch: [7][190/193]	Time  1.254 ( 1.376)	Data  0.259 ( 0.262)	Loss 1.0218e-01 (1.6364e-01) 
2023-05-25 00:46:22.088650: train Epoch: [7][191/193]	Time  1.173 ( 1.374)	Data  0.001 ( 0.261)	Loss 1.4905e-01 (1.6356e-01) 
2023-05-25 00:46:23.066522: train Epoch: [7][192/193]	Time  0.978 ( 1.372)	Data  0.001 ( 0.259)	Loss 1.7810e-01 (1.6364e-01) 
2023-05-25 00:46:23.144798: Train Epoch done in 264.9605382379377 s 
2023-05-25 00:46:26.495867: val Epoch: [7][ 0/72]	Time  2.303 ( 2.303)	Data  1.757 ( 1.757)	Loss 1.1259e-01 (1.1259e-01) 
2023-05-25 00:46:26.751386: val Epoch: [7][ 1/72]	Time  0.256 ( 1.280)	Data  0.002 ( 0.880)	Loss 8.5832e-02 (9.9213e-02) 
2023-05-25 00:46:27.804884: val Epoch: [7][ 2/72]	Time  1.054 ( 1.204)	Data  0.661 ( 0.807)	Loss 1.2998e-01 (1.0947e-01) 
2023-05-25 00:46:28.003648: val Epoch: [7][ 3/72]	Time  0.199 ( 0.953)	Data  0.001 ( 0.605)	Loss 1.3171e-01 (1.1503e-01) 
2023-05-25 00:46:29.132507: val Epoch: [7][ 4/72]	Time  1.129 ( 0.988)	Data  0.768 ( 0.638)	Loss 2.3184e-01 (1.3839e-01) 
2023-05-25 00:46:29.448304: val Epoch: [7][ 5/72]	Time  0.316 ( 0.876)	Data  0.001 ( 0.532)	Loss 9.5206e-02 (1.3119e-01) 
2023-05-25 00:46:30.437414: val Epoch: [7][ 6/72]	Time  0.989 ( 0.892)	Data  0.740 ( 0.561)	Loss 9.0501e-02 (1.2538e-01) 
2023-05-25 00:46:30.918914: val Epoch: [7][ 7/72]	Time  0.481 ( 0.841)	Data  0.001 ( 0.491)	Loss 1.4806e-01 (1.2822e-01) 
2023-05-25 00:46:31.956651: val Epoch: [7][ 8/72]	Time  1.038 ( 0.863)	Data  0.720 ( 0.517)	Loss 6.5601e-01 (1.8686e-01) 
2023-05-25 00:46:32.155611: val Epoch: [7][ 9/72]	Time  0.199 ( 0.796)	Data  0.001 ( 0.465)	Loss 1.2719e-01 (1.8089e-01) 
2023-05-25 00:46:33.441375: val Epoch: [7][10/72]	Time  1.286 ( 0.841)	Data  0.926 ( 0.507)	Loss 4.6092e-01 (2.0635e-01) 
2023-05-25 00:46:33.793316: val Epoch: [7][11/72]	Time  0.352 ( 0.800)	Data  0.001 ( 0.465)	Loss 2.0708e-01 (2.0641e-01) 
2023-05-25 00:46:35.012732: val Epoch: [7][12/72]	Time  1.219 ( 0.832)	Data  0.687 ( 0.482)	Loss 1.8029e-01 (2.0440e-01) 
2023-05-25 00:46:35.331492: val Epoch: [7][13/72]	Time  0.319 ( 0.796)	Data  0.001 ( 0.448)	Loss 1.1060e-01 (1.9770e-01) 
2023-05-25 00:46:36.253019: val Epoch: [7][14/72]	Time  0.922 ( 0.804)	Data  0.597 ( 0.458)	Loss 2.2533e-01 (1.9954e-01) 
2023-05-25 00:46:36.516059: val Epoch: [7][15/72]	Time  0.263 ( 0.770)	Data  0.001 ( 0.429)	Loss 1.8337e-01 (1.9853e-01) 
2023-05-25 00:46:37.680490: val Epoch: [7][16/72]	Time  1.164 ( 0.793)	Data  0.862 ( 0.455)	Loss 4.4751e-01 (2.1318e-01) 
2023-05-25 00:46:38.171468: val Epoch: [7][17/72]	Time  0.491 ( 0.777)	Data  0.001 ( 0.429)	Loss 7.9768e-02 (2.0577e-01) 
2023-05-25 00:46:39.162306: val Epoch: [7][18/72]	Time  0.991 ( 0.788)	Data  0.632 ( 0.440)	Loss 1.0464e-01 (2.0044e-01) 
2023-05-25 00:46:39.523548: val Epoch: [7][19/72]	Time  0.361 ( 0.767)	Data  0.001 ( 0.418)	Loss 1.0279e-01 (1.9556e-01) 
2023-05-25 00:46:40.495824: val Epoch: [7][20/72]	Time  0.972 ( 0.776)	Data  0.688 ( 0.431)	Loss 1.6398e-01 (1.9406e-01) 
2023-05-25 00:46:40.784629: val Epoch: [7][21/72]	Time  0.289 ( 0.754)	Data  0.001 ( 0.411)	Loss 1.1135e-01 (1.9030e-01) 
2023-05-25 00:46:41.787416: val Epoch: [7][22/72]	Time  1.003 ( 0.765)	Data  0.803 ( 0.428)	Loss 1.8732e-01 (1.9017e-01) 
2023-05-25 00:46:42.187762: val Epoch: [7][23/72]	Time  0.400 ( 0.750)	Data  0.001 ( 0.411)	Loss 1.2530e-01 (1.8747e-01) 
2023-05-25 00:46:43.301151: val Epoch: [7][24/72]	Time  1.113 ( 0.764)	Data  0.834 ( 0.428)	Loss 4.3130e-01 (1.9722e-01) 
2023-05-25 00:46:43.561600: val Epoch: [7][25/72]	Time  0.260 ( 0.745)	Data  0.001 ( 0.411)	Loss 1.1034e-01 (1.9388e-01) 
2023-05-25 00:46:44.926800: val Epoch: [7][26/72]	Time  1.365 ( 0.768)	Data  0.911 ( 0.430)	Loss 7.8605e-02 (1.8961e-01) 
2023-05-25 00:46:45.278080: val Epoch: [7][27/72]	Time  0.351 ( 0.753)	Data  0.001 ( 0.414)	Loss 7.9527e-02 (1.8568e-01) 
2023-05-25 00:46:46.214094: val Epoch: [7][28/72]	Time  0.936 ( 0.759)	Data  0.554 ( 0.419)	Loss 2.1817e-01 (1.8680e-01) 
2023-05-25 00:46:46.403541: val Epoch: [7][29/72]	Time  0.189 ( 0.740)	Data  0.001 ( 0.405)	Loss 2.1198e-01 (1.8764e-01) 
2023-05-25 00:46:47.677294: val Epoch: [7][30/72]	Time  1.274 ( 0.758)	Data  0.934 ( 0.422)	Loss 1.3184e-01 (1.8584e-01) 
2023-05-25 00:46:48.163281: val Epoch: [7][31/72]	Time  0.486 ( 0.749)	Data  0.001 ( 0.409)	Loss 8.5038e-02 (1.8269e-01) 
2023-05-25 00:46:49.143690: val Epoch: [7][32/72]	Time  0.980 ( 0.756)	Data  0.591 ( 0.415)	Loss 3.8914e-01 (1.8894e-01) 
2023-05-25 00:46:49.341349: val Epoch: [7][33/72]	Time  0.198 ( 0.740)	Data  0.001 ( 0.402)	Loss 3.7978e-01 (1.9456e-01) 
2023-05-25 00:46:50.435900: val Epoch: [7][34/72]	Time  1.095 ( 0.750)	Data  0.861 ( 0.416)	Loss 2.1646e-01 (1.9518e-01) 
2023-05-25 00:46:50.654282: val Epoch: [7][35/72]	Time  0.218 ( 0.735)	Data  0.001 ( 0.404)	Loss 1.0272e-01 (1.9261e-01) 
2023-05-25 00:46:51.883902: val Epoch: [7][36/72]	Time  1.230 ( 0.748)	Data  0.963 ( 0.419)	Loss 2.6912e-01 (1.9468e-01) 
2023-05-25 00:46:52.406249: val Epoch: [7][37/72]	Time  0.522 ( 0.742)	Data  0.001 ( 0.408)	Loss 1.1494e-01 (1.9258e-01) 
2023-05-25 00:46:53.334005: val Epoch: [7][38/72]	Time  0.928 ( 0.747)	Data  0.604 ( 0.413)	Loss 1.8812e-01 (1.9247e-01) 
2023-05-25 00:46:53.588084: val Epoch: [7][39/72]	Time  0.254 ( 0.735)	Data  0.001 ( 0.403)	Loss 1.6635e-01 (1.9182e-01) 
2023-05-25 00:46:54.589313: val Epoch: [7][40/72]	Time  1.001 ( 0.741)	Data  0.802 ( 0.413)	Loss 9.8105e-02 (1.8953e-01) 
2023-05-25 00:46:54.862360: val Epoch: [7][41/72]	Time  0.273 ( 0.730)	Data  0.001 ( 0.403)	Loss 1.7242e-01 (1.8912e-01) 
2023-05-25 00:46:56.265882: val Epoch: [7][42/72]	Time  1.404 ( 0.746)	Data  0.963 ( 0.416)	Loss 1.3146e-01 (1.8778e-01) 
2023-05-25 00:46:56.639104: val Epoch: [7][43/72]	Time  0.373 ( 0.737)	Data  0.001 ( 0.406)	Loss 1.4364e-01 (1.8678e-01) 
2023-05-25 00:46:57.700204: val Epoch: [7][44/72]	Time  1.061 ( 0.745)	Data  0.678 ( 0.412)	Loss 4.2771e-01 (1.9213e-01) 
2023-05-25 00:46:58.042745: val Epoch: [7][45/72]	Time  0.343 ( 0.736)	Data  0.001 ( 0.403)	Loss 1.1468e-01 (1.9045e-01) 
2023-05-25 00:46:59.066471: val Epoch: [7][46/72]	Time  1.024 ( 0.742)	Data  0.713 ( 0.410)	Loss 2.7778e-01 (1.9231e-01) 
2023-05-25 00:46:59.494307: val Epoch: [7][47/72]	Time  0.428 ( 0.735)	Data  0.001 ( 0.402)	Loss 1.1147e-01 (1.9062e-01) 
2023-05-25 00:47:00.530975: val Epoch: [7][48/72]	Time  1.037 ( 0.742)	Data  0.733 ( 0.408)	Loss 1.2488e-01 (1.8928e-01) 
2023-05-25 00:47:00.713439: val Epoch: [7][49/72]	Time  0.182 ( 0.730)	Data  0.001 ( 0.400)	Loss 8.8301e-02 (1.8726e-01) 
2023-05-25 00:47:02.067888: val Epoch: [7][50/72]	Time  1.354 ( 0.743)	Data  0.952 ( 0.411)	Loss 4.6225e-01 (1.9265e-01) 
2023-05-25 00:47:02.385724: val Epoch: [7][51/72]	Time  0.318 ( 0.734)	Data  0.001 ( 0.403)	Loss 1.3569e-01 (1.9156e-01) 
2023-05-25 00:47:03.590001: val Epoch: [7][52/72]	Time  1.204 ( 0.743)	Data  0.720 ( 0.409)	Loss 2.1532e-01 (1.9201e-01) 
2023-05-25 00:47:03.777613: val Epoch: [7][53/72]	Time  0.188 ( 0.733)	Data  0.001 ( 0.402)	Loss 2.4878e-01 (1.9306e-01) 
2023-05-25 00:47:04.896482: val Epoch: [7][54/72]	Time  1.119 ( 0.740)	Data  0.773 ( 0.408)	Loss 1.3050e-01 (1.9192e-01) 
2023-05-25 00:47:05.213699: val Epoch: [7][55/72]	Time  0.317 ( 0.733)	Data  0.001 ( 0.401)	Loss 5.5531e-01 (1.9841e-01) 
2023-05-25 00:47:06.408405: val Epoch: [7][56/72]	Time  1.195 ( 0.741)	Data  0.818 ( 0.408)	Loss 2.1891e-01 (1.9877e-01) 
2023-05-25 00:47:06.909743: val Epoch: [7][57/72]	Time  0.501 ( 0.736)	Data  0.001 ( 0.401)	Loss 1.7227e-01 (1.9831e-01) 
2023-05-25 00:47:07.712575: val Epoch: [7][58/72]	Time  0.803 ( 0.738)	Data  0.494 ( 0.403)	Loss 1.2944e-01 (1.9714e-01) 
2023-05-25 00:47:08.133281: val Epoch: [7][59/72]	Time  0.421 ( 0.732)	Data  0.001 ( 0.396)	Loss 9.2976e-02 (1.9541e-01) 
2023-05-25 00:47:09.212656: val Epoch: [7][60/72]	Time  1.079 ( 0.738)	Data  0.705 ( 0.401)	Loss 8.5867e-02 (1.9361e-01) 
2023-05-25 00:47:09.513658: val Epoch: [7][61/72]	Time  0.301 ( 0.731)	Data  0.001 ( 0.395)	Loss 2.3867e-01 (1.9434e-01) 
2023-05-25 00:47:10.773908: val Epoch: [7][62/72]	Time  1.260 ( 0.739)	Data  0.745 ( 0.400)	Loss 1.2883e-01 (1.9330e-01) 
2023-05-25 00:47:10.968548: val Epoch: [7][63/72]	Time  0.195 ( 0.731)	Data  0.001 ( 0.394)	Loss 8.7308e-02 (1.9164e-01) 
2023-05-25 00:47:12.099561: val Epoch: [7][64/72]	Time  1.131 ( 0.737)	Data  0.719 ( 0.399)	Loss 1.9459e-01 (1.9169e-01) 
2023-05-25 00:47:12.510967: val Epoch: [7][65/72]	Time  0.411 ( 0.732)	Data  0.001 ( 0.393)	Loss 1.1039e-01 (1.9046e-01) 
2023-05-25 00:47:13.342870: val Epoch: [7][66/72]	Time  0.832 ( 0.734)	Data  0.585 ( 0.396)	Loss 1.8906e-01 (1.9044e-01) 
2023-05-25 00:47:13.558719: val Epoch: [7][67/72]	Time  0.216 ( 0.726)	Data  0.003 ( 0.390)	Loss 3.9343e-01 (1.9342e-01) 
2023-05-25 00:47:14.913950: val Epoch: [7][68/72]	Time  1.355 ( 0.735)	Data  0.902 ( 0.398)	Loss 9.9527e-02 (1.9206e-01) 
2023-05-25 00:47:15.246548: val Epoch: [7][69/72]	Time  0.333 ( 0.729)	Data  0.001 ( 0.392)	Loss 3.5875e-01 (1.9444e-01) 
2023-05-25 00:47:16.129830: val Epoch: [7][70/72]	Time  0.883 ( 0.732)	Data  0.553 ( 0.394)	Loss 2.5578e-01 (1.9531e-01) 
2023-05-25 00:47:16.366700: val Epoch: [7][71/72]	Time  0.237 ( 0.725)	Data  0.001 ( 0.389)	Loss 8.8257e-02 (1.9382e-01) 
2023-05-25 00:47:16.928046: Epoch 7 :Val : ['ET : 0.6393664479255676', 'TC : 0.6632168292999268', 'WT : 0.8037685751914978'] 
2023-05-25 00:47:16.928867: Epoch 7 :Val : ['ET : 0.6393664479255676', 'TC : 0.6632168292999268', 'WT : 0.8037685751914978'] 
2023-05-25 00:47:16.936102: Saving the model with DSC 0.6997082233428955 
2023-05-25 00:47:17.861412: Val epoch done in 54.716605529072694 s 
2023-05-25 00:47:17.867697: Batches per epoch:  193 
2023-05-25 00:47:22.255911: train Epoch: [8][  0/193]	Time  4.388 ( 4.388)	Data  3.262 ( 3.262)	Loss 2.8043e-01 (2.8043e-01) 
2023-05-25 00:47:23.309763: train Epoch: [8][  1/193]	Time  1.054 ( 2.721)	Data  0.001 ( 1.631)	Loss 1.4915e-01 (2.1479e-01) 
2023-05-25 00:47:25.232574: train Epoch: [8][  2/193]	Time  1.923 ( 2.455)	Data  0.587 ( 1.283)	Loss 1.1926e-01 (1.8295e-01) 
2023-05-25 00:47:26.236646: train Epoch: [8][  3/193]	Time  1.004 ( 2.092)	Data  0.001 ( 0.963)	Loss 1.8816e-01 (1.8425e-01) 
2023-05-25 00:47:27.674952: train Epoch: [8][  4/193]	Time  1.438 ( 1.961)	Data  0.270 ( 0.824)	Loss 1.6054e-01 (1.7951e-01) 
2023-05-25 00:47:28.726646: train Epoch: [8][  5/193]	Time  1.052 ( 1.810)	Data  0.001 ( 0.687)	Loss 1.5493e-01 (1.7541e-01) 
2023-05-25 00:47:30.665073: train Epoch: [8][  6/193]	Time  1.938 ( 1.828)	Data  0.623 ( 0.678)	Loss 1.3828e-01 (1.7011e-01) 
2023-05-25 00:47:31.689217: train Epoch: [8][  7/193]	Time  1.024 ( 1.728)	Data  0.001 ( 0.593)	Loss 1.7966e-01 (1.7130e-01) 
2023-05-25 00:47:33.172639: train Epoch: [8][  8/193]	Time  1.483 ( 1.700)	Data  0.426 ( 0.575)	Loss 1.6602e-01 (1.7071e-01) 
2023-05-25 00:47:34.344792: train Epoch: [8][  9/193]	Time  1.172 ( 1.648)	Data  0.001 ( 0.517)	Loss 2.8761e-01 (1.8240e-01) 
2023-05-25 00:47:35.969006: train Epoch: [8][ 10/193]	Time  1.624 ( 1.646)	Data  0.506 ( 0.516)	Loss 2.2144e-01 (1.8595e-01) 
2023-05-25 00:47:37.022028: train Epoch: [8][ 11/193]	Time  1.053 ( 1.596)	Data  0.001 ( 0.473)	Loss 1.1269e-01 (1.7985e-01) 
2023-05-25 00:47:38.789655: train Epoch: [8][ 12/193]	Time  1.768 ( 1.609)	Data  0.669 ( 0.488)	Loss 1.6820e-01 (1.7895e-01) 
2023-05-25 00:47:39.791079: train Epoch: [8][ 13/193]	Time  1.001 ( 1.566)	Data  0.001 ( 0.454)	Loss 1.8178e-01 (1.7915e-01) 
2023-05-25 00:47:41.709484: train Epoch: [8][ 14/193]	Time  1.918 ( 1.589)	Data  0.642 ( 0.466)	Loss 3.3465e-01 (1.8952e-01) 
2023-05-25 00:47:42.817648: train Epoch: [8][ 15/193]	Time  1.108 ( 1.559)	Data  0.002 ( 0.437)	Loss 1.8444e-01 (1.8920e-01) 
2023-05-25 00:47:44.348147: train Epoch: [8][ 16/193]	Time  1.530 ( 1.558)	Data  0.337 ( 0.431)	Loss 1.2022e-01 (1.8514e-01) 
2023-05-25 00:47:45.443518: train Epoch: [8][ 17/193]	Time  1.095 ( 1.532)	Data  0.002 ( 0.407)	Loss 1.6710e-01 (1.8414e-01) 
2023-05-25 00:47:47.140461: train Epoch: [8][ 18/193]	Time  1.697 ( 1.541)	Data  0.434 ( 0.409)	Loss 7.6066e-02 (1.7845e-01) 
2023-05-25 00:47:48.242095: train Epoch: [8][ 19/193]	Time  1.102 ( 1.519)	Data  0.001 ( 0.388)	Loss 9.4605e-02 (1.7426e-01) 
2023-05-25 00:47:49.868585: train Epoch: [8][ 20/193]	Time  1.626 ( 1.524)	Data  0.414 ( 0.390)	Loss 1.1472e-01 (1.7143e-01) 
2023-05-25 00:47:51.098288: train Epoch: [8][ 21/193]	Time  1.230 ( 1.510)	Data  0.001 ( 0.372)	Loss 1.0842e-01 (1.6856e-01) 
2023-05-25 00:47:52.325909: train Epoch: [8][ 22/193]	Time  1.228 ( 1.498)	Data  0.233 ( 0.366)	Loss 9.3817e-02 (1.6531e-01) 
2023-05-25 00:47:53.366330: train Epoch: [8][ 23/193]	Time  1.040 ( 1.479)	Data  0.001 ( 0.351)	Loss 1.0589e-01 (1.6284e-01) 
2023-05-25 00:47:55.263024: train Epoch: [8][ 24/193]	Time  1.897 ( 1.496)	Data  0.694 ( 0.364)	Loss 1.0100e-01 (1.6036e-01) 
2023-05-25 00:47:56.344728: train Epoch: [8][ 25/193]	Time  1.082 ( 1.480)	Data  0.001 ( 0.350)	Loss 1.2957e-01 (1.5918e-01) 
2023-05-25 00:47:57.966058: train Epoch: [8][ 26/193]	Time  1.621 ( 1.485)	Data  0.477 ( 0.355)	Loss 1.1798e-01 (1.5765e-01) 
2023-05-25 00:47:58.941446: train Epoch: [8][ 27/193]	Time  0.975 ( 1.467)	Data  0.001 ( 0.342)	Loss 9.1230e-02 (1.5528e-01) 
2023-05-25 00:48:00.657968: train Epoch: [8][ 28/193]	Time  1.717 ( 1.476)	Data  0.662 ( 0.353)	Loss 2.7218e-01 (1.5931e-01) 
2023-05-25 00:48:01.655992: train Epoch: [8][ 29/193]	Time  0.998 ( 1.460)	Data  0.001 ( 0.342)	Loss 1.7600e-01 (1.5987e-01) 
2023-05-25 00:48:03.647022: train Epoch: [8][ 30/193]	Time  1.991 ( 1.477)	Data  0.722 ( 0.354)	Loss 1.1947e-01 (1.5856e-01) 
2023-05-25 00:48:04.622443: train Epoch: [8][ 31/193]	Time  0.975 ( 1.461)	Data  0.001 ( 0.343)	Loss 1.7087e-01 (1.5895e-01) 
2023-05-25 00:48:06.376510: train Epoch: [8][ 32/193]	Time  1.754 ( 1.470)	Data  0.579 ( 0.350)	Loss 1.3620e-01 (1.5826e-01) 
2023-05-25 00:48:07.484649: train Epoch: [8][ 33/193]	Time  1.108 ( 1.459)	Data  0.001 ( 0.340)	Loss 1.0405e-01 (1.5667e-01) 
2023-05-25 00:48:09.513154: train Epoch: [8][ 34/193]	Time  2.028 ( 1.476)	Data  0.626 ( 0.348)	Loss 2.4638e-01 (1.5923e-01) 
2023-05-25 00:48:10.628795: train Epoch: [8][ 35/193]	Time  1.116 ( 1.466)	Data  0.001 ( 0.338)	Loss 9.4663e-02 (1.5744e-01) 
2023-05-25 00:48:12.103579: train Epoch: [8][ 36/193]	Time  1.475 ( 1.466)	Data  0.306 ( 0.337)	Loss 1.8277e-01 (1.5812e-01) 
2023-05-25 00:48:13.164435: train Epoch: [8][ 37/193]	Time  1.061 ( 1.455)	Data  0.002 ( 0.329)	Loss 1.3314e-01 (1.5746e-01) 
2023-05-25 00:48:14.850643: train Epoch: [8][ 38/193]	Time  1.686 ( 1.461)	Data  0.621 ( 0.336)	Loss 1.2915e-01 (1.5674e-01) 
2023-05-25 00:48:15.985165: train Epoch: [8][ 39/193]	Time  1.135 ( 1.453)	Data  0.001 ( 0.328)	Loss 9.5278e-02 (1.5520e-01) 
2023-05-25 00:48:17.677928: train Epoch: [8][ 40/193]	Time  1.693 ( 1.459)	Data  0.653 ( 0.336)	Loss 9.5833e-02 (1.5375e-01) 
2023-05-25 00:48:18.859358: train Epoch: [8][ 41/193]	Time  1.181 ( 1.452)	Data  0.001 ( 0.328)	Loss 2.3882e-01 (1.5578e-01) 
2023-05-25 00:48:20.698530: train Epoch: [8][ 42/193]	Time  1.839 ( 1.461)	Data  0.671 ( 0.336)	Loss 8.7355e-02 (1.5419e-01) 
2023-05-25 00:48:21.960860: train Epoch: [8][ 43/193]	Time  1.262 ( 1.457)	Data  0.001 ( 0.328)	Loss 1.5486e-01 (1.5420e-01) 
2023-05-25 00:48:23.363846: train Epoch: [8][ 44/193]	Time  1.403 ( 1.455)	Data  0.380 ( 0.329)	Loss 1.1072e-01 (1.5324e-01) 
2023-05-25 00:48:24.493879: train Epoch: [8][ 45/193]	Time  1.130 ( 1.448)	Data  0.001 ( 0.322)	Loss 1.3533e-01 (1.5285e-01) 
2023-05-25 00:48:26.221139: train Epoch: [8][ 46/193]	Time  1.727 ( 1.454)	Data  0.718 ( 0.331)	Loss 1.5261e-01 (1.5284e-01) 
2023-05-25 00:48:27.321774: train Epoch: [8][ 47/193]	Time  1.101 ( 1.447)	Data  0.001 ( 0.324)	Loss 2.6471e-01 (1.5517e-01) 
2023-05-25 00:48:29.374756: train Epoch: [8][ 48/193]	Time  2.053 ( 1.459)	Data  0.856 ( 0.335)	Loss 1.8485e-01 (1.5578e-01) 
2023-05-25 00:48:30.442550: train Epoch: [8][ 49/193]	Time  1.068 ( 1.451)	Data  0.001 ( 0.328)	Loss 1.2230e-01 (1.5511e-01) 
2023-05-25 00:48:32.051454: train Epoch: [8][ 50/193]	Time  1.609 ( 1.455)	Data  0.565 ( 0.333)	Loss 1.5501e-01 (1.5511e-01) 
2023-05-25 00:48:33.034951: train Epoch: [8][ 51/193]	Time  0.983 ( 1.446)	Data  0.001 ( 0.326)	Loss 1.1001e-01 (1.5424e-01) 
2023-05-25 00:48:34.960778: train Epoch: [8][ 52/193]	Time  1.926 ( 1.455)	Data  0.698 ( 0.333)	Loss 2.1450e-01 (1.5538e-01) 
2023-05-25 00:48:35.936281: train Epoch: [8][ 53/193]	Time  0.975 ( 1.446)	Data  0.001 ( 0.327)	Loss 1.2387e-01 (1.5479e-01) 
2023-05-25 00:48:37.717930: train Epoch: [8][ 54/193]	Time  1.782 ( 1.452)	Data  0.530 ( 0.331)	Loss 1.4557e-01 (1.5462e-01) 
2023-05-25 00:48:38.678587: train Epoch: [8][ 55/193]	Time  0.961 ( 1.443)	Data  0.001 ( 0.325)	Loss 2.7723e-01 (1.5681e-01) 
2023-05-25 00:48:40.447945: train Epoch: [8][ 56/193]	Time  1.769 ( 1.449)	Data  0.604 ( 0.330)	Loss 1.1046e-01 (1.5600e-01) 
2023-05-25 00:48:41.493654: train Epoch: [8][ 57/193]	Time  1.046 ( 1.442)	Data  0.001 ( 0.324)	Loss 7.8301e-02 (1.5466e-01) 
2023-05-25 00:48:43.194086: train Epoch: [8][ 58/193]	Time  1.700 ( 1.446)	Data  0.617 ( 0.329)	Loss 1.1808e-01 (1.5404e-01) 
2023-05-25 00:48:44.253638: train Epoch: [8][ 59/193]	Time  1.060 ( 1.440)	Data  0.001 ( 0.324)	Loss 1.3846e-01 (1.5378e-01) 
2023-05-25 00:48:46.207465: train Epoch: [8][ 60/193]	Time  1.954 ( 1.448)	Data  0.681 ( 0.329)	Loss 7.7805e-02 (1.5254e-01) 
2023-05-25 00:48:47.562435: train Epoch: [8][ 61/193]	Time  1.355 ( 1.447)	Data  0.001 ( 0.324)	Loss 1.0901e-01 (1.5183e-01) 
2023-05-25 00:48:48.619245: train Epoch: [8][ 62/193]	Time  1.057 ( 1.440)	Data  0.060 ( 0.320)	Loss 1.2067e-01 (1.5134e-01) 
2023-05-25 00:48:49.655374: train Epoch: [8][ 63/193]	Time  1.036 ( 1.434)	Data  0.001 ( 0.315)	Loss 1.2030e-01 (1.5085e-01) 
2023-05-25 00:48:51.306618: train Epoch: [8][ 64/193]	Time  1.651 ( 1.438)	Data  0.462 ( 0.317)	Loss 1.3688e-01 (1.5064e-01) 
2023-05-25 00:48:52.500522: train Epoch: [8][ 65/193]	Time  1.194 ( 1.434)	Data  0.001 ( 0.312)	Loss 9.1411e-02 (1.4974e-01) 
2023-05-25 00:48:54.042312: train Epoch: [8][ 66/193]	Time  1.542 ( 1.435)	Data  0.271 ( 0.312)	Loss 1.4244e-01 (1.4963e-01) 
2023-05-25 00:48:55.040136: train Epoch: [8][ 67/193]	Time  0.998 ( 1.429)	Data  0.001 ( 0.307)	Loss 1.0790e-01 (1.4902e-01) 
2023-05-25 00:48:56.363493: train Epoch: [8][ 68/193]	Time  1.323 ( 1.427)	Data  0.283 ( 0.307)	Loss 1.0527e-01 (1.4838e-01) 
2023-05-25 00:48:57.313159: train Epoch: [8][ 69/193]	Time  0.950 ( 1.421)	Data  0.001 ( 0.303)	Loss 8.5882e-02 (1.4749e-01) 
2023-05-25 00:48:59.144728: train Epoch: [8][ 70/193]	Time  1.832 ( 1.426)	Data  0.733 ( 0.309)	Loss 4.4047e-01 (1.5162e-01) 
2023-05-25 00:49:00.103140: train Epoch: [8][ 71/193]	Time  0.958 ( 1.420)	Data  0.002 ( 0.304)	Loss 7.1087e-02 (1.5050e-01) 
2023-05-25 00:49:02.155154: train Epoch: [8][ 72/193]	Time  2.052 ( 1.429)	Data  0.832 ( 0.312)	Loss 1.2980e-01 (1.5022e-01) 
2023-05-25 00:49:03.247334: train Epoch: [8][ 73/193]	Time  1.092 ( 1.424)	Data  0.001 ( 0.307)	Loss 1.6611e-01 (1.5043e-01) 
2023-05-25 00:49:04.837776: train Epoch: [8][ 74/193]	Time  1.590 ( 1.426)	Data  0.463 ( 0.309)	Loss 1.8268e-01 (1.5086e-01) 
2023-05-25 00:49:05.934119: train Epoch: [8][ 75/193]	Time  1.096 ( 1.422)	Data  0.001 ( 0.305)	Loss 1.2216e-01 (1.5048e-01) 
2023-05-25 00:49:07.596296: train Epoch: [8][ 76/193]	Time  1.662 ( 1.425)	Data  0.489 ( 0.308)	Loss 2.1135e-01 (1.5127e-01) 
2023-05-25 00:49:08.655569: train Epoch: [8][ 77/193]	Time  1.059 ( 1.420)	Data  0.001 ( 0.304)	Loss 1.6961e-01 (1.5151e-01) 
2023-05-25 00:49:10.338619: train Epoch: [8][ 78/193]	Time  1.683 ( 1.424)	Data  0.545 ( 0.307)	Loss 1.9186e-01 (1.5202e-01) 
2023-05-25 00:49:11.409179: train Epoch: [8][ 79/193]	Time  1.071 ( 1.419)	Data  0.001 ( 0.303)	Loss 1.1305e-01 (1.5153e-01) 
2023-05-25 00:49:13.145280: train Epoch: [8][ 80/193]	Time  1.736 ( 1.423)	Data  0.556 ( 0.306)	Loss 1.3765e-01 (1.5136e-01) 
2023-05-25 00:49:14.154292: train Epoch: [8][ 81/193]	Time  1.009 ( 1.418)	Data  0.001 ( 0.302)	Loss 1.2581e-01 (1.5105e-01) 
2023-05-25 00:49:16.046360: train Epoch: [8][ 82/193]	Time  1.892 ( 1.424)	Data  0.494 ( 0.305)	Loss 1.1512e-01 (1.5062e-01) 
2023-05-25 00:49:17.105834: train Epoch: [8][ 83/193]	Time  1.059 ( 1.419)	Data  0.001 ( 0.301)	Loss 2.5198e-01 (1.5182e-01) 
2023-05-25 00:49:18.767606: train Epoch: [8][ 84/193]	Time  1.662 ( 1.422)	Data  0.374 ( 0.302)	Loss 7.2724e-02 (1.5089e-01) 
2023-05-25 00:49:19.764874: train Epoch: [8][ 85/193]	Time  0.997 ( 1.417)	Data  0.001 ( 0.298)	Loss 1.5312e-01 (1.5092e-01) 
2023-05-25 00:49:21.302766: train Epoch: [8][ 86/193]	Time  1.538 ( 1.419)	Data  0.529 ( 0.301)	Loss 1.4597e-01 (1.5086e-01) 
2023-05-25 00:49:22.357955: train Epoch: [8][ 87/193]	Time  1.055 ( 1.415)	Data  0.001 ( 0.298)	Loss 1.0111e-01 (1.5030e-01) 
2023-05-25 00:49:24.225418: train Epoch: [8][ 88/193]	Time  1.867 ( 1.420)	Data  0.708 ( 0.302)	Loss 1.5602e-01 (1.5036e-01) 
2023-05-25 00:49:25.228623: train Epoch: [8][ 89/193]	Time  1.003 ( 1.415)	Data  0.001 ( 0.299)	Loss 4.3983e-01 (1.5358e-01) 
2023-05-25 00:49:27.218321: train Epoch: [8][ 90/193]	Time  1.990 ( 1.421)	Data  0.695 ( 0.303)	Loss 1.7539e-01 (1.5382e-01) 
2023-05-25 00:49:28.248132: train Epoch: [8][ 91/193]	Time  1.030 ( 1.417)	Data  0.001 ( 0.300)	Loss 1.1079e-01 (1.5335e-01) 
2023-05-25 00:49:30.106189: train Epoch: [8][ 92/193]	Time  1.858 ( 1.422)	Data  0.599 ( 0.303)	Loss 2.3785e-01 (1.5426e-01) 
2023-05-25 00:49:31.246188: train Epoch: [8][ 93/193]	Time  1.140 ( 1.419)	Data  0.001 ( 0.300)	Loss 7.6863e-02 (1.5343e-01) 
2023-05-25 00:49:33.001420: train Epoch: [8][ 94/193]	Time  1.755 ( 1.422)	Data  0.509 ( 0.302)	Loss 2.1160e-01 (1.5405e-01) 
2023-05-25 00:49:34.086011: train Epoch: [8][ 95/193]	Time  1.085 ( 1.419)	Data  0.001 ( 0.299)	Loss 1.3128e-01 (1.5381e-01) 
2023-05-25 00:49:35.758851: train Epoch: [8][ 96/193]	Time  1.673 ( 1.422)	Data  0.480 ( 0.301)	Loss 1.5379e-01 (1.5381e-01) 
2023-05-25 00:49:36.906251: train Epoch: [8][ 97/193]	Time  1.147 ( 1.419)	Data  0.001 ( 0.298)	Loss 1.2902e-01 (1.5356e-01) 
2023-05-25 00:49:38.469766: train Epoch: [8][ 98/193]	Time  1.564 ( 1.420)	Data  0.360 ( 0.299)	Loss 1.1225e-01 (1.5314e-01) 
2023-05-25 00:49:39.508352: train Epoch: [8][ 99/193]	Time  1.039 ( 1.416)	Data  0.001 ( 0.296)	Loss 6.3185e-02 (1.5224e-01) 
2023-05-25 00:49:40.962892: train Epoch: [8][100/193]	Time  1.455 ( 1.417)	Data  0.436 ( 0.297)	Loss 1.6055e-01 (1.5232e-01) 
2023-05-25 00:49:41.968012: train Epoch: [8][101/193]	Time  1.005 ( 1.413)	Data  0.001 ( 0.294)	Loss 1.5975e-01 (1.5239e-01) 
2023-05-25 00:49:43.972151: train Epoch: [8][102/193]	Time  2.004 ( 1.418)	Data  0.766 ( 0.299)	Loss 1.3467e-01 (1.5222e-01) 
2023-05-25 00:49:44.956235: train Epoch: [8][103/193]	Time  0.984 ( 1.414)	Data  0.001 ( 0.296)	Loss 1.2043e-01 (1.5192e-01) 
2023-05-25 00:49:46.859049: train Epoch: [8][104/193]	Time  1.903 ( 1.419)	Data  0.578 ( 0.298)	Loss 2.9344e-01 (1.5326e-01) 
2023-05-25 00:49:47.970737: train Epoch: [8][105/193]	Time  1.112 ( 1.416)	Data  0.001 ( 0.296)	Loss 1.9929e-01 (1.5370e-01) 
2023-05-25 00:49:49.204465: train Epoch: [8][106/193]	Time  1.234 ( 1.414)	Data  0.226 ( 0.295)	Loss 1.4240e-01 (1.5359e-01) 
2023-05-25 00:49:50.418721: train Epoch: [8][107/193]	Time  1.214 ( 1.412)	Data  0.001 ( 0.292)	Loss 2.1282e-01 (1.5414e-01) 
2023-05-25 00:49:51.877021: train Epoch: [8][108/193]	Time  1.458 ( 1.413)	Data  0.431 ( 0.294)	Loss 1.5128e-01 (1.5412e-01) 
2023-05-25 00:49:53.181170: train Epoch: [8][109/193]	Time  1.304 ( 1.412)	Data  0.001 ( 0.291)	Loss 9.4866e-02 (1.5358e-01) 
2023-05-25 00:49:54.706794: train Epoch: [8][110/193]	Time  1.526 ( 1.413)	Data  0.399 ( 0.292)	Loss 9.4260e-02 (1.5304e-01) 
2023-05-25 00:49:55.855136: train Epoch: [8][111/193]	Time  1.148 ( 1.411)	Data  0.001 ( 0.289)	Loss 1.2295e-01 (1.5277e-01) 
2023-05-25 00:49:57.512667: train Epoch: [8][112/193]	Time  1.658 ( 1.413)	Data  0.435 ( 0.291)	Loss 1.2169e-01 (1.5250e-01) 
2023-05-25 00:49:58.482105: train Epoch: [8][113/193]	Time  0.969 ( 1.409)	Data  0.001 ( 0.288)	Loss 1.8189e-01 (1.5276e-01) 
2023-05-25 00:50:00.147441: train Epoch: [8][114/193]	Time  1.665 ( 1.411)	Data  0.508 ( 0.290)	Loss 2.7821e-01 (1.5385e-01) 
2023-05-25 00:50:01.221483: train Epoch: [8][115/193]	Time  1.074 ( 1.408)	Data  0.033 ( 0.288)	Loss 1.0680e-01 (1.5344e-01) 
2023-05-25 00:50:02.942287: train Epoch: [8][116/193]	Time  1.721 ( 1.411)	Data  0.469 ( 0.289)	Loss 1.5079e-01 (1.5342e-01) 
2023-05-25 00:50:04.105620: train Epoch: [8][117/193]	Time  1.163 ( 1.409)	Data  0.076 ( 0.287)	Loss 1.5942e-01 (1.5347e-01) 
2023-05-25 00:50:05.336738: train Epoch: [8][118/193]	Time  1.231 ( 1.407)	Data  0.142 ( 0.286)	Loss 1.0384e-01 (1.5305e-01) 
2023-05-25 00:50:06.898603: train Epoch: [8][119/193]	Time  1.562 ( 1.409)	Data  0.508 ( 0.288)	Loss 1.4177e-01 (1.5296e-01) 
2023-05-25 00:50:08.019537: train Epoch: [8][120/193]	Time  1.121 ( 1.406)	Data  0.001 ( 0.286)	Loss 9.2776e-02 (1.5246e-01) 
2023-05-25 00:50:09.885382: train Epoch: [8][121/193]	Time  1.866 ( 1.410)	Data  0.675 ( 0.289)	Loss 1.2888e-01 (1.5227e-01) 
2023-05-25 00:50:10.953948: train Epoch: [8][122/193]	Time  1.069 ( 1.407)	Data  0.001 ( 0.287)	Loss 4.2041e-01 (1.5445e-01) 
2023-05-25 00:50:12.837120: train Epoch: [8][123/193]	Time  1.883 ( 1.411)	Data  0.495 ( 0.288)	Loss 1.3639e-01 (1.5430e-01) 
2023-05-25 00:50:13.868100: train Epoch: [8][124/193]	Time  1.031 ( 1.408)	Data  0.001 ( 0.286)	Loss 1.0967e-01 (1.5395e-01) 
2023-05-25 00:50:15.412741: train Epoch: [8][125/193]	Time  1.545 ( 1.409)	Data  0.282 ( 0.286)	Loss 1.4782e-01 (1.5390e-01) 
2023-05-25 00:50:16.524726: train Epoch: [8][126/193]	Time  1.112 ( 1.407)	Data  0.001 ( 0.284)	Loss 1.2130e-01 (1.5364e-01) 
2023-05-25 00:50:18.317366: train Epoch: [8][127/193]	Time  1.793 ( 1.410)	Data  0.378 ( 0.284)	Loss 9.3146e-02 (1.5317e-01) 
2023-05-25 00:50:19.304986: train Epoch: [8][128/193]	Time  0.988 ( 1.406)	Data  0.001 ( 0.282)	Loss 1.1134e-01 (1.5284e-01) 
2023-05-25 00:50:20.882472: train Epoch: [8][129/193]	Time  1.577 ( 1.408)	Data  0.384 ( 0.283)	Loss 1.1404e-01 (1.5254e-01) 
2023-05-25 00:50:21.980252: train Epoch: [8][130/193]	Time  1.098 ( 1.405)	Data  0.001 ( 0.281)	Loss 9.1709e-02 (1.5208e-01) 
2023-05-25 00:50:23.744363: train Epoch: [8][131/193]	Time  1.764 ( 1.408)	Data  0.525 ( 0.283)	Loss 7.9649e-02 (1.5153e-01) 
2023-05-25 00:50:24.781910: train Epoch: [8][132/193]	Time  1.038 ( 1.405)	Data  0.001 ( 0.281)	Loss 7.1949e-02 (1.5093e-01) 
2023-05-25 00:50:26.591593: train Epoch: [8][133/193]	Time  1.810 ( 1.408)	Data  0.669 ( 0.284)	Loss 1.8560e-01 (1.5119e-01) 
2023-05-25 00:50:27.571902: train Epoch: [8][134/193]	Time  0.980 ( 1.405)	Data  0.001 ( 0.281)	Loss 1.1741e-01 (1.5094e-01) 
2023-05-25 00:50:29.297593: train Epoch: [8][135/193]	Time  1.726 ( 1.408)	Data  0.598 ( 0.284)	Loss 1.8978e-01 (1.5123e-01) 
2023-05-25 00:50:30.293193: train Epoch: [8][136/193]	Time  0.996 ( 1.405)	Data  0.001 ( 0.282)	Loss 1.8528e-01 (1.5148e-01) 
2023-05-25 00:50:32.086143: train Epoch: [8][137/193]	Time  1.793 ( 1.407)	Data  0.693 ( 0.285)	Loss 1.7778e-01 (1.5167e-01) 
2023-05-25 00:50:33.171906: train Epoch: [8][138/193]	Time  1.086 ( 1.405)	Data  0.001 ( 0.283)	Loss 1.0607e-01 (1.5134e-01) 
2023-05-25 00:50:34.773208: train Epoch: [8][139/193]	Time  1.601 ( 1.406)	Data  0.600 ( 0.285)	Loss 2.9272e-01 (1.5235e-01) 
2023-05-25 00:50:35.834288: train Epoch: [8][140/193]	Time  1.061 ( 1.404)	Data  0.001 ( 0.283)	Loss 1.3614e-01 (1.5223e-01) 
2023-05-25 00:50:37.776039: train Epoch: [8][141/193]	Time  1.942 ( 1.408)	Data  0.662 ( 0.286)	Loss 1.4757e-01 (1.5220e-01) 
2023-05-25 00:50:38.730949: train Epoch: [8][142/193]	Time  0.955 ( 1.405)	Data  0.001 ( 0.284)	Loss 8.2762e-02 (1.5172e-01) 
2023-05-25 00:50:40.462638: train Epoch: [8][143/193]	Time  1.732 ( 1.407)	Data  0.490 ( 0.285)	Loss 1.2088e-01 (1.5150e-01) 
2023-05-25 00:50:41.437922: train Epoch: [8][144/193]	Time  0.975 ( 1.404)	Data  0.001 ( 0.283)	Loss 8.7073e-02 (1.5106e-01) 
2023-05-25 00:50:43.238723: train Epoch: [8][145/193]	Time  1.801 ( 1.407)	Data  0.518 ( 0.285)	Loss 1.6667e-01 (1.5116e-01) 
2023-05-25 00:50:44.229010: train Epoch: [8][146/193]	Time  0.990 ( 1.404)	Data  0.001 ( 0.283)	Loss 9.8688e-02 (1.5081e-01) 
2023-05-25 00:50:45.856483: train Epoch: [8][147/193]	Time  1.627 ( 1.405)	Data  0.533 ( 0.284)	Loss 1.2845e-01 (1.5066e-01) 
2023-05-25 00:50:46.979313: train Epoch: [8][148/193]	Time  1.123 ( 1.403)	Data  0.001 ( 0.283)	Loss 9.3039e-02 (1.5027e-01) 
2023-05-25 00:50:48.765794: train Epoch: [8][149/193]	Time  1.786 ( 1.406)	Data  0.680 ( 0.285)	Loss 1.8596e-01 (1.5051e-01) 
2023-05-25 00:50:49.937845: train Epoch: [8][150/193]	Time  1.172 ( 1.404)	Data  0.001 ( 0.283)	Loss 3.7053e-01 (1.5196e-01) 
2023-05-25 00:50:51.585455: train Epoch: [8][151/193]	Time  1.648 ( 1.406)	Data  0.547 ( 0.285)	Loss 1.7299e-01 (1.5210e-01) 
2023-05-25 00:50:52.650843: train Epoch: [8][152/193]	Time  1.065 ( 1.404)	Data  0.001 ( 0.283)	Loss 1.4693e-01 (1.5207e-01) 
2023-05-25 00:50:54.402335: train Epoch: [8][153/193]	Time  1.751 ( 1.406)	Data  0.629 ( 0.285)	Loss 9.5305e-02 (1.5170e-01) 
2023-05-25 00:50:55.435730: train Epoch: [8][154/193]	Time  1.033 ( 1.404)	Data  0.001 ( 0.284)	Loss 1.4772e-01 (1.5167e-01) 
2023-05-25 00:50:57.050204: train Epoch: [8][155/193]	Time  1.614 ( 1.405)	Data  0.642 ( 0.286)	Loss 1.3543e-01 (1.5157e-01) 
2023-05-25 00:50:57.982780: train Epoch: [8][156/193]	Time  0.933 ( 1.402)	Data  0.001 ( 0.284)	Loss 2.7546e-01 (1.5236e-01) 
2023-05-25 00:51:00.195904: train Epoch: [8][157/193]	Time  2.213 ( 1.407)	Data  1.005 ( 0.289)	Loss 3.6158e-01 (1.5368e-01) 
2023-05-25 00:51:01.151663: train Epoch: [8][158/193]	Time  0.956 ( 1.404)	Data  0.001 ( 0.287)	Loss 9.0110e-02 (1.5328e-01) 
2023-05-25 00:51:02.819225: train Epoch: [8][159/193]	Time  1.668 ( 1.406)	Data  0.637 ( 0.289)	Loss 9.8046e-02 (1.5294e-01) 
2023-05-25 00:51:03.926964: train Epoch: [8][160/193]	Time  1.108 ( 1.404)	Data  0.001 ( 0.287)	Loss 1.2366e-01 (1.5276e-01) 
2023-05-25 00:51:05.470195: train Epoch: [8][161/193]	Time  1.543 ( 1.405)	Data  0.507 ( 0.289)	Loss 7.9154e-02 (1.5230e-01) 
2023-05-25 00:51:06.505055: train Epoch: [8][162/193]	Time  1.035 ( 1.403)	Data  0.001 ( 0.287)	Loss 1.3552e-01 (1.5220e-01) 
2023-05-25 00:51:08.128376: train Epoch: [8][163/193]	Time  1.623 ( 1.404)	Data  0.650 ( 0.289)	Loss 8.6269e-02 (1.5180e-01) 
2023-05-25 00:51:09.418123: train Epoch: [8][164/193]	Time  1.290 ( 1.403)	Data  0.001 ( 0.287)	Loss 1.1164e-01 (1.5155e-01) 
2023-05-25 00:51:11.142653: train Epoch: [8][165/193]	Time  1.725 ( 1.405)	Data  0.508 ( 0.289)	Loss 1.9106e-01 (1.5179e-01) 
2023-05-25 00:51:12.275599: train Epoch: [8][166/193]	Time  1.133 ( 1.404)	Data  0.001 ( 0.287)	Loss 7.4392e-02 (1.5133e-01) 
2023-05-25 00:51:14.082288: train Epoch: [8][167/193]	Time  1.807 ( 1.406)	Data  0.517 ( 0.288)	Loss 1.4115e-01 (1.5127e-01) 
2023-05-25 00:51:15.193206: train Epoch: [8][168/193]	Time  1.111 ( 1.404)	Data  0.001 ( 0.287)	Loss 1.8089e-01 (1.5144e-01) 
2023-05-25 00:51:16.655302: train Epoch: [8][169/193]	Time  1.462 ( 1.405)	Data  0.390 ( 0.287)	Loss 1.0175e-01 (1.5115e-01) 
2023-05-25 00:51:17.611995: train Epoch: [8][170/193]	Time  0.957 ( 1.402)	Data  0.001 ( 0.285)	Loss 1.7619e-01 (1.5130e-01) 
2023-05-25 00:51:19.571913: train Epoch: [8][171/193]	Time  1.960 ( 1.405)	Data  0.680 ( 0.288)	Loss 1.7605e-01 (1.5144e-01) 
2023-05-25 00:51:20.629386: train Epoch: [8][172/193]	Time  1.057 ( 1.403)	Data  0.001 ( 0.286)	Loss 4.0259e-01 (1.5289e-01) 
2023-05-25 00:51:22.361537: train Epoch: [8][173/193]	Time  1.732 ( 1.405)	Data  0.435 ( 0.287)	Loss 1.5657e-01 (1.5291e-01) 
2023-05-25 00:51:23.529052: train Epoch: [8][174/193]	Time  1.168 ( 1.404)	Data  0.001 ( 0.285)	Loss 1.6630e-01 (1.5299e-01) 
2023-05-25 00:51:25.206962: train Epoch: [8][175/193]	Time  1.678 ( 1.405)	Data  0.345 ( 0.286)	Loss 1.1717e-01 (1.5279e-01) 
2023-05-25 00:51:26.337162: train Epoch: [8][176/193]	Time  1.130 ( 1.404)	Data  0.001 ( 0.284)	Loss 1.0028e-01 (1.5249e-01) 
2023-05-25 00:51:27.718551: train Epoch: [8][177/193]	Time  1.381 ( 1.404)	Data  0.282 ( 0.284)	Loss 2.3186e-01 (1.5294e-01) 
2023-05-25 00:51:28.669001: train Epoch: [8][178/193]	Time  0.950 ( 1.401)	Data  0.002 ( 0.282)	Loss 1.8421e-01 (1.5311e-01) 
2023-05-25 00:51:30.468902: train Epoch: [8][179/193]	Time  1.800 ( 1.403)	Data  0.723 ( 0.285)	Loss 1.3520e-01 (1.5301e-01) 
2023-05-25 00:51:31.485592: train Epoch: [8][180/193]	Time  1.017 ( 1.401)	Data  0.001 ( 0.283)	Loss 1.1654e-01 (1.5281e-01) 
2023-05-25 00:51:33.160261: train Epoch: [8][181/193]	Time  1.675 ( 1.403)	Data  0.600 ( 0.285)	Loss 1.1995e-01 (1.5263e-01) 
2023-05-25 00:51:34.253950: train Epoch: [8][182/193]	Time  1.094 ( 1.401)	Data  0.001 ( 0.284)	Loss 1.6999e-01 (1.5272e-01) 
2023-05-25 00:51:36.082647: train Epoch: [8][183/193]	Time  1.829 ( 1.403)	Data  0.788 ( 0.286)	Loss 2.6030e-01 (1.5331e-01) 
2023-05-25 00:51:37.177708: train Epoch: [8][184/193]	Time  1.095 ( 1.402)	Data  0.001 ( 0.285)	Loss 2.0877e-01 (1.5361e-01) 
2023-05-25 00:51:38.982018: train Epoch: [8][185/193]	Time  1.804 ( 1.404)	Data  0.734 ( 0.287)	Loss 1.5959e-01 (1.5364e-01) 
2023-05-25 00:51:40.142714: train Epoch: [8][186/193]	Time  1.161 ( 1.403)	Data  0.001 ( 0.286)	Loss 7.7328e-02 (1.5323e-01) 
2023-05-25 00:51:41.706293: train Epoch: [8][187/193]	Time  1.564 ( 1.403)	Data  0.580 ( 0.287)	Loss 1.8305e-01 (1.5339e-01) 
2023-05-25 00:51:42.727252: train Epoch: [8][188/193]	Time  1.021 ( 1.401)	Data  0.001 ( 0.286)	Loss 1.3805e-01 (1.5331e-01) 
2023-05-25 00:51:44.671351: train Epoch: [8][189/193]	Time  1.944 ( 1.404)	Data  0.743 ( 0.288)	Loss 8.2924e-02 (1.5294e-01) 
2023-05-25 00:51:45.781963: train Epoch: [8][190/193]	Time  1.111 ( 1.403)	Data  0.001 ( 0.287)	Loss 1.0697e-01 (1.5270e-01) 
2023-05-25 00:51:47.350149: train Epoch: [8][191/193]	Time  1.568 ( 1.404)	Data  0.380 ( 0.287)	Loss 1.4413e-01 (1.5265e-01) 
2023-05-25 00:51:48.491767: train Epoch: [8][192/193]	Time  1.142 ( 1.402)	Data  0.001 ( 0.286)	Loss 1.2930e-01 (1.5253e-01) 
2023-05-25 00:51:48.562585: Train Epoch done in 270.6949359260034 s 
2023-05-25 00:51:51.637178: val Epoch: [8][ 0/72]	Time  2.072 ( 2.072)	Data  1.723 ( 1.723)	Loss 1.0029e-01 (1.0029e-01) 
2023-05-25 00:51:52.160384: val Epoch: [8][ 1/72]	Time  0.523 ( 1.298)	Data  0.002 ( 0.863)	Loss 1.5752e-01 (1.2890e-01) 
2023-05-25 00:51:53.162483: val Epoch: [8][ 2/72]	Time  1.002 ( 1.199)	Data  0.574 ( 0.766)	Loss 2.5285e-01 (1.7022e-01) 
2023-05-25 00:51:53.368638: val Epoch: [8][ 3/72]	Time  0.206 ( 0.951)	Data  0.001 ( 0.575)	Loss 2.0112e-01 (1.7795e-01) 
2023-05-25 00:51:54.496215: val Epoch: [8][ 4/72]	Time  1.128 ( 0.986)	Data  0.833 ( 0.626)	Loss 3.6133e-01 (2.1462e-01) 
2023-05-25 00:51:55.065594: val Epoch: [8][ 5/72]	Time  0.569 ( 0.917)	Data  0.001 ( 0.522)	Loss 9.7148e-02 (1.9504e-01) 
2023-05-25 00:51:55.880136: val Epoch: [8][ 6/72]	Time  0.815 ( 0.902)	Data  0.618 ( 0.536)	Loss 1.2059e-01 (1.8441e-01) 
2023-05-25 00:51:56.431846: val Epoch: [8][ 7/72]	Time  0.552 ( 0.858)	Data  0.001 ( 0.469)	Loss 1.5403e-01 (1.8061e-01) 
2023-05-25 00:51:57.251430: val Epoch: [8][ 8/72]	Time  0.820 ( 0.854)	Data  0.625 ( 0.486)	Loss 6.6493e-02 (1.6793e-01) 
2023-05-25 00:51:57.516281: val Epoch: [8][ 9/72]	Time  0.265 ( 0.795)	Data  0.001 ( 0.438)	Loss 1.1719e-01 (1.6286e-01) 
2023-05-25 00:51:58.813470: val Epoch: [8][10/72]	Time  1.297 ( 0.841)	Data  0.957 ( 0.485)	Loss 8.6584e-02 (1.5592e-01) 
2023-05-25 00:51:59.279581: val Epoch: [8][11/72]	Time  0.466 ( 0.810)	Data  0.001 ( 0.445)	Loss 1.1937e-01 (1.5288e-01) 
2023-05-25 00:52:00.377743: val Epoch: [8][12/72]	Time  1.098 ( 0.832)	Data  0.558 ( 0.453)	Loss 9.3671e-02 (1.4832e-01) 
2023-05-25 00:52:00.697811: val Epoch: [8][13/72]	Time  0.320 ( 0.795)	Data  0.001 ( 0.421)	Loss 8.1772e-02 (1.4357e-01) 
2023-05-25 00:52:01.690850: val Epoch: [8][14/72]	Time  0.993 ( 0.808)	Data  0.539 ( 0.429)	Loss 1.5768e-01 (1.4451e-01) 
2023-05-25 00:52:02.105432: val Epoch: [8][15/72]	Time  0.415 ( 0.784)	Data  0.001 ( 0.402)	Loss 7.9738e-02 (1.4046e-01) 
2023-05-25 00:52:03.027393: val Epoch: [8][16/72]	Time  0.922 ( 0.792)	Data  0.557 ( 0.411)	Loss 2.0446e-01 (1.4423e-01) 
2023-05-25 00:52:03.575780: val Epoch: [8][17/72]	Time  0.548 ( 0.778)	Data  0.001 ( 0.389)	Loss 2.0251e-01 (1.4746e-01) 
2023-05-25 00:52:04.427761: val Epoch: [8][18/72]	Time  0.852 ( 0.782)	Data  0.481 ( 0.393)	Loss 2.2793e-01 (1.5170e-01) 
2023-05-25 00:52:04.762746: val Epoch: [8][19/72]	Time  0.335 ( 0.760)	Data  0.001 ( 0.374)	Loss 9.3954e-02 (1.4881e-01) 
2023-05-25 00:52:05.843373: val Epoch: [8][20/72]	Time  1.081 ( 0.775)	Data  0.728 ( 0.391)	Loss 3.9002e-01 (1.6030e-01) 
2023-05-25 00:52:06.309555: val Epoch: [8][21/72]	Time  0.466 ( 0.761)	Data  0.001 ( 0.373)	Loss 4.4374e-01 (1.7318e-01) 
2023-05-25 00:52:07.201125: val Epoch: [8][22/72]	Time  0.892 ( 0.767)	Data  0.570 ( 0.381)	Loss 1.6560e-01 (1.7285e-01) 
2023-05-25 00:52:07.404360: val Epoch: [8][23/72]	Time  0.203 ( 0.743)	Data  0.001 ( 0.366)	Loss 1.1941e-01 (1.7063e-01) 
2023-05-25 00:52:08.539783: val Epoch: [8][24/72]	Time  1.135 ( 0.759)	Data  0.850 ( 0.385)	Loss 4.4630e-01 (1.8165e-01) 
2023-05-25 00:52:08.914566: val Epoch: [8][25/72]	Time  0.375 ( 0.744)	Data  0.001 ( 0.370)	Loss 5.3618e-01 (1.9529e-01) 
2023-05-25 00:52:09.867274: val Epoch: [8][26/72]	Time  0.953 ( 0.752)	Data  0.671 ( 0.381)	Loss 1.9334e-01 (1.9522e-01) 
2023-05-25 00:52:10.300634: val Epoch: [8][27/72]	Time  0.433 ( 0.741)	Data  0.001 ( 0.368)	Loss 1.6744e-01 (1.9422e-01) 
2023-05-25 00:52:11.120296: val Epoch: [8][28/72]	Time  0.820 ( 0.743)	Data  0.603 ( 0.376)	Loss 1.1678e-01 (1.9155e-01) 
2023-05-25 00:52:11.694597: val Epoch: [8][29/72]	Time  0.574 ( 0.738)	Data  0.069 ( 0.366)	Loss 4.4153e-01 (1.9989e-01) 
2023-05-25 00:52:12.579407: val Epoch: [8][30/72]	Time  0.885 ( 0.742)	Data  0.558 ( 0.372)	Loss 8.1307e-02 (1.9606e-01) 
2023-05-25 00:52:12.991872: val Epoch: [8][31/72]	Time  0.412 ( 0.732)	Data  0.103 ( 0.363)	Loss 2.2395e-01 (1.9693e-01) 
2023-05-25 00:52:14.046416: val Epoch: [8][32/72]	Time  1.055 ( 0.742)	Data  0.695 ( 0.374)	Loss 1.4034e-01 (1.9522e-01) 
2023-05-25 00:52:14.540697: val Epoch: [8][33/72]	Time  0.494 ( 0.735)	Data  0.090 ( 0.365)	Loss 9.0673e-02 (1.9214e-01) 
2023-05-25 00:52:15.394338: val Epoch: [8][34/72]	Time  0.854 ( 0.738)	Data  0.542 ( 0.370)	Loss 1.2029e-01 (1.9009e-01) 
2023-05-25 00:52:15.957674: val Epoch: [8][35/72]	Time  0.563 ( 0.733)	Data  0.181 ( 0.365)	Loss 7.7204e-02 (1.8695e-01) 
2023-05-25 00:52:16.874858: val Epoch: [8][36/72]	Time  0.917 ( 0.738)	Data  0.590 ( 0.371)	Loss 5.0158e-01 (1.9546e-01) 
2023-05-25 00:52:17.424400: val Epoch: [8][37/72]	Time  0.550 ( 0.733)	Data  0.111 ( 0.364)	Loss 8.2781e-02 (1.9249e-01) 
2023-05-25 00:52:18.114513: val Epoch: [8][38/72]	Time  0.690 ( 0.732)	Data  0.466 ( 0.367)	Loss 8.8791e-02 (1.8983e-01) 
2023-05-25 00:52:18.665799: val Epoch: [8][39/72]	Time  0.551 ( 0.728)	Data  0.295 ( 0.365)	Loss 8.2629e-02 (1.8715e-01) 
2023-05-25 00:52:19.594191: val Epoch: [8][40/72]	Time  0.928 ( 0.732)	Data  0.640 ( 0.372)	Loss 1.0837e-01 (1.8523e-01) 
2023-05-25 00:52:20.361561: val Epoch: [8][41/72]	Time  0.767 ( 0.733)	Data  0.324 ( 0.371)	Loss 1.5527e-01 (1.8452e-01) 
2023-05-25 00:52:21.155865: val Epoch: [8][42/72]	Time  0.794 ( 0.735)	Data  0.276 ( 0.368)	Loss 9.3087e-02 (1.8239e-01) 
2023-05-25 00:52:21.612403: val Epoch: [8][43/72]	Time  0.457 ( 0.728)	Data  0.189 ( 0.364)	Loss 9.0462e-02 (1.8030e-01) 
2023-05-25 00:52:22.202311: val Epoch: [8][44/72]	Time  0.590 ( 0.725)	Data  0.322 ( 0.363)	Loss 7.8750e-02 (1.7805e-01) 
2023-05-25 00:52:22.992076: val Epoch: [8][45/72]	Time  0.790 ( 0.727)	Data  0.504 ( 0.366)	Loss 7.7538e-02 (1.7586e-01) 
2023-05-25 00:52:23.699386: val Epoch: [8][46/72]	Time  0.707 ( 0.726)	Data  0.330 ( 0.366)	Loss 1.4682e-01 (1.7524e-01) 
2023-05-25 00:52:24.250003: val Epoch: [8][47/72]	Time  0.551 ( 0.723)	Data  0.346 ( 0.365)	Loss 9.0098e-02 (1.7347e-01) 
2023-05-25 00:52:25.036126: val Epoch: [8][48/72]	Time  0.786 ( 0.724)	Data  0.456 ( 0.367)	Loss 2.3924e-01 (1.7481e-01) 
2023-05-25 00:52:25.826227: val Epoch: [8][49/72]	Time  0.790 ( 0.725)	Data  0.483 ( 0.369)	Loss 3.5411e-01 (1.7840e-01) 
2023-05-25 00:52:26.519442: val Epoch: [8][50/72]	Time  0.693 ( 0.725)	Data  0.319 ( 0.368)	Loss 1.8352e-01 (1.7850e-01) 
2023-05-25 00:52:27.224907: val Epoch: [8][51/72]	Time  0.705 ( 0.724)	Data  0.373 ( 0.369)	Loss 1.4398e-01 (1.7783e-01) 
2023-05-25 00:52:27.878674: val Epoch: [8][52/72]	Time  0.654 ( 0.723)	Data  0.300 ( 0.367)	Loss 8.5367e-02 (1.7609e-01) 
2023-05-25 00:52:28.850350: val Epoch: [8][53/72]	Time  0.972 ( 0.728)	Data  0.483 ( 0.369)	Loss 1.2307e-01 (1.7511e-01) 
2023-05-25 00:52:29.322397: val Epoch: [8][54/72]	Time  0.472 ( 0.723)	Data  0.018 ( 0.363)	Loss 1.9203e-01 (1.7542e-01) 
2023-05-25 00:52:30.260565: val Epoch: [8][55/72]	Time  0.938 ( 0.727)	Data  0.526 ( 0.366)	Loss 1.5488e-01 (1.7505e-01) 
2023-05-25 00:52:30.711777: val Epoch: [8][56/72]	Time  0.451 ( 0.722)	Data  0.030 ( 0.360)	Loss 9.7950e-02 (1.7370e-01) 
2023-05-25 00:52:31.688685: val Epoch: [8][57/72]	Time  0.977 ( 0.726)	Data  0.603 ( 0.364)	Loss 1.0089e-01 (1.7244e-01) 
2023-05-25 00:52:32.141357: val Epoch: [8][58/72]	Time  0.453 ( 0.722)	Data  0.020 ( 0.358)	Loss 4.8842e-01 (1.7780e-01) 
2023-05-25 00:52:33.040593: val Epoch: [8][59/72]	Time  0.899 ( 0.725)	Data  0.655 ( 0.363)	Loss 4.1116e-01 (1.8169e-01) 
2023-05-25 00:52:33.334784: val Epoch: [8][60/72]	Time  0.294 ( 0.718)	Data  0.014 ( 0.358)	Loss 1.1414e-01 (1.8058e-01) 
2023-05-25 00:52:34.508768: val Epoch: [8][61/72]	Time  1.174 ( 0.725)	Data  0.836 ( 0.365)	Loss 7.2902e-02 (1.7884e-01) 
2023-05-25 00:52:34.870265: val Epoch: [8][62/72]	Time  0.361 ( 0.719)	Data  0.003 ( 0.360)	Loss 3.3995e-01 (1.8140e-01) 
2023-05-25 00:52:35.920665: val Epoch: [8][63/72]	Time  1.050 ( 0.724)	Data  0.698 ( 0.365)	Loss 1.0507e-01 (1.8021e-01) 
2023-05-25 00:52:36.384876: val Epoch: [8][64/72]	Time  0.464 ( 0.720)	Data  0.048 ( 0.360)	Loss 1.6062e-01 (1.7990e-01) 
2023-05-25 00:52:37.358736: val Epoch: [8][65/72]	Time  0.974 ( 0.724)	Data  0.654 ( 0.364)	Loss 1.9623e-01 (1.8015e-01) 
2023-05-25 00:52:37.755158: val Epoch: [8][66/72]	Time  0.396 ( 0.719)	Data  0.012 ( 0.359)	Loss 7.6997e-02 (1.7861e-01) 
2023-05-25 00:52:38.918772: val Epoch: [8][67/72]	Time  1.164 ( 0.726)	Data  0.704 ( 0.364)	Loss 1.0975e-01 (1.7760e-01) 
2023-05-25 00:52:39.347030: val Epoch: [8][68/72]	Time  0.428 ( 0.721)	Data  0.001 ( 0.359)	Loss 2.2244e-01 (1.7825e-01) 
2023-05-25 00:52:40.377018: val Epoch: [8][69/72]	Time  1.030 ( 0.726)	Data  0.651 ( 0.363)	Loss 1.5924e-01 (1.7798e-01) 
2023-05-25 00:52:40.626597: val Epoch: [8][70/72]	Time  0.250 ( 0.719)	Data  0.001 ( 0.358)	Loss 6.1492e-01 (1.8413e-01) 
2023-05-25 00:52:41.468909: val Epoch: [8][71/72]	Time  0.842 ( 0.721)	Data  0.591 ( 0.361)	Loss 2.4509e-01 (1.8498e-01) 
2023-05-25 00:52:41.733227: Epoch 8 :Val : ['ET : 0.6414446830749512', 'TC : 0.6859854459762573', 'WT : 0.8190553784370422'] 
2023-05-25 00:52:41.734375: Epoch 8 :Val : ['ET : 0.6414446830749512', 'TC : 0.6859854459762573', 'WT : 0.8190553784370422'] 
2023-05-25 00:52:41.739192: Saving the model with DSC 0.7133408188819885 
2023-05-25 00:52:42.809113: Val epoch done in 54.24651879398152 s 
2023-05-25 00:52:42.815584: Batches per epoch:  193 
2023-05-25 00:52:47.138827: train Epoch: [9][  0/193]	Time  4.323 ( 4.323)	Data  3.172 ( 3.172)	Loss 1.7163e-01 (1.7163e-01) 
2023-05-25 00:52:48.180134: train Epoch: [9][  1/193]	Time  1.041 ( 2.682)	Data  0.001 ( 1.586)	Loss 8.3278e-02 (1.2745e-01) 
2023-05-25 00:52:50.053425: train Epoch: [9][  2/193]	Time  1.873 ( 2.412)	Data  0.739 ( 1.304)	Loss 2.7694e-01 (1.7728e-01) 
2023-05-25 00:52:51.025167: train Epoch: [9][  3/193]	Time  0.972 ( 2.052)	Data  0.001 ( 0.978)	Loss 7.3850e-02 (1.5142e-01) 
2023-05-25 00:52:52.744581: train Epoch: [9][  4/193]	Time  1.719 ( 1.986)	Data  0.718 ( 0.926)	Loss 8.4266e-02 (1.3799e-01) 
2023-05-25 00:52:53.719096: train Epoch: [9][  5/193]	Time  0.974 ( 1.817)	Data  0.001 ( 0.772)	Loss 9.8883e-02 (1.3147e-01) 
2023-05-25 00:52:55.937269: train Epoch: [9][  6/193]	Time  2.218 ( 1.874)	Data  0.879 ( 0.787)	Loss 1.3562e-01 (1.3207e-01) 
2023-05-25 00:52:56.969898: train Epoch: [9][  7/193]	Time  1.033 ( 1.769)	Data  0.001 ( 0.689)	Loss 1.9768e-01 (1.4027e-01) 
2023-05-25 00:52:58.762038: train Epoch: [9][  8/193]	Time  1.792 ( 1.772)	Data  0.498 ( 0.668)	Loss 2.0363e-01 (1.4731e-01) 
2023-05-25 00:52:59.768635: train Epoch: [9][  9/193]	Time  1.007 ( 1.695)	Data  0.001 ( 0.601)	Loss 1.4170e-01 (1.4675e-01) 
2023-05-25 00:53:01.691242: train Epoch: [9][ 10/193]	Time  1.923 ( 1.716)	Data  0.617 ( 0.602)	Loss 2.8155e-01 (1.5900e-01) 
2023-05-25 00:53:02.702010: train Epoch: [9][ 11/193]	Time  1.011 ( 1.657)	Data  0.001 ( 0.552)	Loss 9.6841e-02 (1.5382e-01) 
2023-05-25 00:53:04.431477: train Epoch: [9][ 12/193]	Time  1.729 ( 1.663)	Data  0.511 ( 0.549)	Loss 1.4704e-01 (1.5330e-01) 
2023-05-25 00:53:05.393210: train Epoch: [9][ 13/193]	Time  0.962 ( 1.613)	Data  0.001 ( 0.510)	Loss 1.4531e-01 (1.5273e-01) 
2023-05-25 00:53:07.183839: train Epoch: [9][ 14/193]	Time  1.791 ( 1.625)	Data  0.612 ( 0.517)	Loss 8.1663e-02 (1.4799e-01) 
2023-05-25 00:53:08.566164: train Epoch: [9][ 15/193]	Time  1.382 ( 1.609)	Data  0.001 ( 0.485)	Loss 8.7354e-02 (1.4420e-01) 
2023-05-25 00:53:09.843357: train Epoch: [9][ 16/193]	Time  1.277 ( 1.590)	Data  0.230 ( 0.470)	Loss 2.0226e-01 (1.4762e-01) 
2023-05-25 00:53:11.080446: train Epoch: [9][ 17/193]	Time  1.237 ( 1.570)	Data  0.001 ( 0.444)	Loss 1.3908e-01 (1.4714e-01) 
2023-05-25 00:53:12.957789: train Epoch: [9][ 18/193]	Time  1.877 ( 1.586)	Data  0.615 ( 0.453)	Loss 1.3104e-01 (1.4629e-01) 
2023-05-25 00:53:14.007862: train Epoch: [9][ 19/193]	Time  1.050 ( 1.560)	Data  0.001 ( 0.430)	Loss 1.3685e-01 (1.4582e-01) 
2023-05-25 00:53:15.629663: train Epoch: [9][ 20/193]	Time  1.622 ( 1.563)	Data  0.568 ( 0.437)	Loss 1.0282e-01 (1.4377e-01) 
2023-05-25 00:53:16.708311: train Epoch: [9][ 21/193]	Time  1.079 ( 1.541)	Data  0.001 ( 0.417)	Loss 2.1632e-01 (1.4707e-01) 
2023-05-25 00:53:18.292556: train Epoch: [9][ 22/193]	Time  1.584 ( 1.542)	Data  0.589 ( 0.424)	Loss 1.0561e-01 (1.4527e-01) 
2023-05-25 00:53:19.278182: train Epoch: [9][ 23/193]	Time  0.986 ( 1.519)	Data  0.001 ( 0.407)	Loss 1.3584e-01 (1.4488e-01) 
2023-05-25 00:53:20.955043: train Epoch: [9][ 24/193]	Time  1.677 ( 1.526)	Data  0.628 ( 0.416)	Loss 1.4927e-01 (1.4505e-01) 
2023-05-25 00:53:21.928397: train Epoch: [9][ 25/193]	Time  0.973 ( 1.504)	Data  0.001 ( 0.400)	Loss 8.6702e-02 (1.4281e-01) 
2023-05-25 00:53:23.679838: train Epoch: [9][ 26/193]	Time  1.751 ( 1.513)	Data  0.681 ( 0.410)	Loss 7.0440e-02 (1.4013e-01) 
2023-05-25 00:53:24.622704: train Epoch: [9][ 27/193]	Time  0.943 ( 1.493)	Data  0.001 ( 0.395)	Loss 1.0887e-01 (1.3901e-01) 
2023-05-25 00:53:26.615240: train Epoch: [9][ 28/193]	Time  1.993 ( 1.510)	Data  0.775 ( 0.409)	Loss 1.1805e-01 (1.3829e-01) 
2023-05-25 00:53:27.569243: train Epoch: [9][ 29/193]	Time  0.954 ( 1.492)	Data  0.001 ( 0.395)	Loss 2.1848e-01 (1.4096e-01) 
2023-05-25 00:53:29.512804: train Epoch: [9][ 30/193]	Time  1.944 ( 1.506)	Data  0.566 ( 0.400)	Loss 2.1904e-01 (1.4348e-01) 
2023-05-25 00:53:30.664581: train Epoch: [9][ 31/193]	Time  1.152 ( 1.495)	Data  0.001 ( 0.388)	Loss 8.8886e-02 (1.4177e-01) 
2023-05-25 00:53:31.882354: train Epoch: [9][ 32/193]	Time  1.218 ( 1.487)	Data  0.209 ( 0.383)	Loss 1.1660e-01 (1.4101e-01) 
2023-05-25 00:53:33.065457: train Epoch: [9][ 33/193]	Time  1.183 ( 1.478)	Data  0.001 ( 0.371)	Loss 2.0109e-01 (1.4278e-01) 
2023-05-25 00:53:34.528808: train Epoch: [9][ 34/193]	Time  1.463 ( 1.477)	Data  0.414 ( 0.373)	Loss 1.2115e-01 (1.4216e-01) 
2023-05-25 00:53:35.658592: train Epoch: [9][ 35/193]	Time  1.130 ( 1.468)	Data  0.001 ( 0.362)	Loss 1.5787e-01 (1.4260e-01) 
2023-05-25 00:53:37.356986: train Epoch: [9][ 36/193]	Time  1.698 ( 1.474)	Data  0.721 ( 0.372)	Loss 1.2445e-01 (1.4211e-01) 
2023-05-25 00:53:38.327369: train Epoch: [9][ 37/193]	Time  0.970 ( 1.461)	Data  0.001 ( 0.362)	Loss 1.0801e-01 (1.4121e-01) 
2023-05-25 00:53:40.273717: train Epoch: [9][ 38/193]	Time  1.946 ( 1.473)	Data  0.826 ( 0.374)	Loss 1.6243e-01 (1.4175e-01) 
2023-05-25 00:53:41.377910: train Epoch: [9][ 39/193]	Time  1.104 ( 1.464)	Data  0.001 ( 0.365)	Loss 1.9202e-01 (1.4301e-01) 
2023-05-25 00:53:43.156723: train Epoch: [9][ 40/193]	Time  1.779 ( 1.472)	Data  0.529 ( 0.369)	Loss 8.8487e-02 (1.4168e-01) 
2023-05-25 00:53:44.274905: train Epoch: [9][ 41/193]	Time  1.118 ( 1.463)	Data  0.001 ( 0.360)	Loss 1.5639e-01 (1.4203e-01) 
2023-05-25 00:53:45.577614: train Epoch: [9][ 42/193]	Time  1.303 ( 1.460)	Data  0.222 ( 0.357)	Loss 2.2287e-01 (1.4391e-01) 
2023-05-25 00:53:46.619815: train Epoch: [9][ 43/193]	Time  1.042 ( 1.450)	Data  0.001 ( 0.349)	Loss 2.1511e-01 (1.4553e-01) 
2023-05-25 00:53:48.417367: train Epoch: [9][ 44/193]	Time  1.798 ( 1.458)	Data  0.630 ( 0.355)	Loss 9.8807e-02 (1.4449e-01) 
2023-05-25 00:53:49.449863: train Epoch: [9][ 45/193]	Time  1.032 ( 1.449)	Data  0.001 ( 0.347)	Loss 1.0001e-01 (1.4352e-01) 
2023-05-25 00:53:51.112693: train Epoch: [9][ 46/193]	Time  1.663 ( 1.453)	Data  0.657 ( 0.354)	Loss 2.4282e-01 (1.4564e-01) 
2023-05-25 00:53:52.204047: train Epoch: [9][ 47/193]	Time  1.091 ( 1.446)	Data  0.001 ( 0.347)	Loss 9.6132e-02 (1.4460e-01) 
2023-05-25 00:53:54.308238: train Epoch: [9][ 48/193]	Time  2.104 ( 1.459)	Data  0.870 ( 0.357)	Loss 1.6664e-01 (1.4505e-01) 
2023-05-25 00:53:55.679872: train Epoch: [9][ 49/193]	Time  1.372 ( 1.457)	Data  0.001 ( 0.350)	Loss 9.5140e-02 (1.4406e-01) 
2023-05-25 00:53:56.849191: train Epoch: [9][ 50/193]	Time  1.169 ( 1.452)	Data  0.205 ( 0.347)	Loss 9.2548e-02 (1.4305e-01) 
2023-05-25 00:53:57.870188: train Epoch: [9][ 51/193]	Time  1.021 ( 1.443)	Data  0.001 ( 0.341)	Loss 1.2250e-01 (1.4265e-01) 
2023-05-25 00:53:59.666183: train Epoch: [9][ 52/193]	Time  1.796 ( 1.450)	Data  0.712 ( 0.348)	Loss 1.3605e-01 (1.4253e-01) 
2023-05-25 00:54:00.635298: train Epoch: [9][ 53/193]	Time  0.969 ( 1.441)	Data  0.001 ( 0.341)	Loss 1.7829e-01 (1.4319e-01) 
2023-05-25 00:54:02.451350: train Epoch: [9][ 54/193]	Time  1.816 ( 1.448)	Data  0.601 ( 0.346)	Loss 1.8194e-01 (1.4389e-01) 
2023-05-25 00:54:03.419720: train Epoch: [9][ 55/193]	Time  0.968 ( 1.439)	Data  0.002 ( 0.340)	Loss 1.8528e-01 (1.4463e-01) 
2023-05-25 00:54:05.308734: train Epoch: [9][ 56/193]	Time  1.889 ( 1.447)	Data  0.608 ( 0.344)	Loss 1.4905e-01 (1.4471e-01) 
2023-05-25 00:54:06.468889: train Epoch: [9][ 57/193]	Time  1.160 ( 1.442)	Data  0.001 ( 0.339)	Loss 1.0742e-01 (1.4407e-01) 
2023-05-25 00:54:07.859149: train Epoch: [9][ 58/193]	Time  1.390 ( 1.441)	Data  0.331 ( 0.338)	Loss 1.1775e-01 (1.4362e-01) 
2023-05-25 00:54:08.856776: train Epoch: [9][ 59/193]	Time  0.998 ( 1.434)	Data  0.001 ( 0.333)	Loss 1.3562e-01 (1.4349e-01) 
2023-05-25 00:54:10.628215: train Epoch: [9][ 60/193]	Time  1.771 ( 1.440)	Data  0.681 ( 0.338)	Loss 1.1391e-01 (1.4300e-01) 
2023-05-25 00:54:11.845972: train Epoch: [9][ 61/193]	Time  1.218 ( 1.436)	Data  0.001 ( 0.333)	Loss 2.2248e-01 (1.4428e-01) 
2023-05-25 00:54:13.188204: train Epoch: [9][ 62/193]	Time  1.342 ( 1.434)	Data  0.411 ( 0.334)	Loss 9.6382e-02 (1.4352e-01) 
2023-05-25 00:54:14.193358: train Epoch: [9][ 63/193]	Time  1.005 ( 1.428)	Data  0.001 ( 0.329)	Loss 7.8437e-02 (1.4251e-01) 
2023-05-25 00:54:16.176036: train Epoch: [9][ 64/193]	Time  1.983 ( 1.436)	Data  0.767 ( 0.336)	Loss 7.5620e-02 (1.4148e-01) 
2023-05-25 00:54:17.278723: train Epoch: [9][ 65/193]	Time  1.103 ( 1.431)	Data  0.001 ( 0.331)	Loss 1.6603e-01 (1.4185e-01) 
2023-05-25 00:54:19.012167: train Epoch: [9][ 66/193]	Time  1.733 ( 1.436)	Data  0.416 ( 0.332)	Loss 2.0153e-01 (1.4274e-01) 
2023-05-25 00:54:20.020221: train Epoch: [9][ 67/193]	Time  1.008 ( 1.429)	Data  0.001 ( 0.327)	Loss 1.3060e-01 (1.4256e-01) 
2023-05-25 00:54:21.316632: train Epoch: [9][ 68/193]	Time  1.296 ( 1.428)	Data  0.290 ( 0.327)	Loss 1.2173e-01 (1.4226e-01) 
2023-05-25 00:54:22.341108: train Epoch: [9][ 69/193]	Time  1.024 ( 1.422)	Data  0.001 ( 0.322)	Loss 1.3002e-01 (1.4209e-01) 
2023-05-25 00:54:24.340248: train Epoch: [9][ 70/193]	Time  1.999 ( 1.430)	Data  0.892 ( 0.330)	Loss 1.3980e-01 (1.4205e-01) 
2023-05-25 00:54:25.315620: train Epoch: [9][ 71/193]	Time  0.975 ( 1.424)	Data  0.001 ( 0.325)	Loss 1.7617e-01 (1.4253e-01) 
2023-05-25 00:54:27.312718: train Epoch: [9][ 72/193]	Time  1.997 ( 1.431)	Data  0.851 ( 0.333)	Loss 1.2437e-01 (1.4228e-01) 
2023-05-25 00:54:28.486221: train Epoch: [9][ 73/193]	Time  1.174 ( 1.428)	Data  0.001 ( 0.328)	Loss 1.1308e-01 (1.4188e-01) 
2023-05-25 00:54:29.955786: train Epoch: [9][ 74/193]	Time  1.470 ( 1.429)	Data  0.404 ( 0.329)	Loss 1.1675e-01 (1.4155e-01) 
2023-05-25 00:54:31.143475: train Epoch: [9][ 75/193]	Time  1.188 ( 1.425)	Data  0.001 ( 0.325)	Loss 3.5586e-01 (1.4437e-01) 
2023-05-25 00:54:32.731761: train Epoch: [9][ 76/193]	Time  1.588 ( 1.427)	Data  0.541 ( 0.328)	Loss 1.6670e-01 (1.4466e-01) 
2023-05-25 00:54:33.950636: train Epoch: [9][ 77/193]	Time  1.219 ( 1.425)	Data  0.001 ( 0.323)	Loss 1.3352e-01 (1.4452e-01) 
2023-05-25 00:54:35.759185: train Epoch: [9][ 78/193]	Time  1.809 ( 1.430)	Data  0.567 ( 0.327)	Loss 1.6392e-01 (1.4476e-01) 
2023-05-25 00:54:36.937826: train Epoch: [9][ 79/193]	Time  1.179 ( 1.427)	Data  0.002 ( 0.322)	Loss 9.1483e-02 (1.4410e-01) 
2023-05-25 00:54:38.442155: train Epoch: [9][ 80/193]	Time  1.504 ( 1.427)	Data  0.315 ( 0.322)	Loss 1.3888e-01 (1.4403e-01) 
2023-05-25 00:54:39.575709: train Epoch: [9][ 81/193]	Time  1.134 ( 1.424)	Data  0.001 ( 0.318)	Loss 8.9406e-02 (1.4336e-01) 
2023-05-25 00:54:41.147937: train Epoch: [9][ 82/193]	Time  1.572 ( 1.426)	Data  0.450 ( 0.320)	Loss 1.6215e-01 (1.4359e-01) 
2023-05-25 00:54:42.189624: train Epoch: [9][ 83/193]	Time  1.042 ( 1.421)	Data  0.001 ( 0.316)	Loss 1.6439e-01 (1.4384e-01) 
2023-05-25 00:54:43.930833: train Epoch: [9][ 84/193]	Time  1.741 ( 1.425)	Data  0.476 ( 0.318)	Loss 7.3127e-02 (1.4301e-01) 
2023-05-25 00:54:44.989771: train Epoch: [9][ 85/193]	Time  1.059 ( 1.421)	Data  0.001 ( 0.314)	Loss 7.9876e-02 (1.4227e-01) 
2023-05-25 00:54:46.295500: train Epoch: [9][ 86/193]	Time  1.306 ( 1.419)	Data  0.255 ( 0.314)	Loss 8.5806e-02 (1.4162e-01) 
2023-05-25 00:54:47.422196: train Epoch: [9][ 87/193]	Time  1.127 ( 1.416)	Data  0.001 ( 0.310)	Loss 1.4315e-01 (1.4164e-01) 
2023-05-25 00:54:49.268015: train Epoch: [9][ 88/193]	Time  1.846 ( 1.421)	Data  0.524 ( 0.313)	Loss 9.3343e-02 (1.4110e-01) 
2023-05-25 00:54:50.362571: train Epoch: [9][ 89/193]	Time  1.095 ( 1.417)	Data  0.001 ( 0.309)	Loss 1.0929e-01 (1.4074e-01) 
2023-05-25 00:54:51.577123: train Epoch: [9][ 90/193]	Time  1.215 ( 1.415)	Data  0.197 ( 0.308)	Loss 1.2014e-01 (1.4052e-01) 
2023-05-25 00:54:52.783780: train Epoch: [9][ 91/193]	Time  1.207 ( 1.413)	Data  0.001 ( 0.305)	Loss 1.2395e-01 (1.4034e-01) 
2023-05-25 00:54:54.250488: train Epoch: [9][ 92/193]	Time  1.467 ( 1.413)	Data  0.425 ( 0.306)	Loss 1.7578e-01 (1.4072e-01) 
2023-05-25 00:54:55.212804: train Epoch: [9][ 93/193]	Time  0.962 ( 1.408)	Data  0.001 ( 0.303)	Loss 1.6167e-01 (1.4094e-01) 
2023-05-25 00:54:56.974710: train Epoch: [9][ 94/193]	Time  1.762 ( 1.412)	Data  0.645 ( 0.306)	Loss 8.7290e-02 (1.4038e-01) 
2023-05-25 00:54:58.092936: train Epoch: [9][ 95/193]	Time  1.118 ( 1.409)	Data  0.001 ( 0.303)	Loss 1.3001e-01 (1.4027e-01) 
2023-05-25 00:54:59.799389: train Epoch: [9][ 96/193]	Time  1.706 ( 1.412)	Data  0.426 ( 0.304)	Loss 1.6828e-01 (1.4056e-01) 
2023-05-25 00:55:00.989359: train Epoch: [9][ 97/193]	Time  1.190 ( 1.410)	Data  0.001 ( 0.301)	Loss 8.4373e-02 (1.3999e-01) 
2023-05-25 00:55:02.186414: train Epoch: [9][ 98/193]	Time  1.197 ( 1.408)	Data  0.149 ( 0.300)	Loss 1.1708e-01 (1.3975e-01) 
2023-05-25 00:55:03.534899: train Epoch: [9][ 99/193]	Time  1.348 ( 1.407)	Data  0.001 ( 0.297)	Loss 1.1374e-01 (1.3949e-01) 
2023-05-25 00:55:04.729437: train Epoch: [9][100/193]	Time  1.195 ( 1.405)	Data  0.166 ( 0.295)	Loss 1.3406e-01 (1.3944e-01) 
2023-05-25 00:55:05.895834: train Epoch: [9][101/193]	Time  1.166 ( 1.403)	Data  0.001 ( 0.293)	Loss 1.0261e-01 (1.3908e-01) 
2023-05-25 00:55:07.389260: train Epoch: [9][102/193]	Time  1.493 ( 1.404)	Data  0.481 ( 0.294)	Loss 1.1117e-01 (1.3881e-01) 
2023-05-25 00:55:08.407674: train Epoch: [9][103/193]	Time  1.018 ( 1.400)	Data  0.001 ( 0.292)	Loss 1.5590e-01 (1.3897e-01) 
2023-05-25 00:55:10.184216: train Epoch: [9][104/193]	Time  1.777 ( 1.404)	Data  0.656 ( 0.295)	Loss 1.1691e-01 (1.3876e-01) 
2023-05-25 00:55:11.319377: train Epoch: [9][105/193]	Time  1.135 ( 1.401)	Data  0.001 ( 0.292)	Loss 1.2072e-01 (1.3859e-01) 
2023-05-25 00:55:12.978380: train Epoch: [9][106/193]	Time  1.659 ( 1.403)	Data  0.525 ( 0.294)	Loss 1.5481e-01 (1.3874e-01) 
2023-05-25 00:55:14.029435: train Epoch: [9][107/193]	Time  1.051 ( 1.400)	Data  0.001 ( 0.292)	Loss 1.2759e-01 (1.3864e-01) 
2023-05-25 00:55:15.527112: train Epoch: [9][108/193]	Time  1.498 ( 1.401)	Data  0.486 ( 0.293)	Loss 1.1243e-01 (1.3840e-01) 
2023-05-25 00:55:16.546500: train Epoch: [9][109/193]	Time  1.019 ( 1.398)	Data  0.001 ( 0.291)	Loss 2.4032e-01 (1.3933e-01) 
2023-05-25 00:55:18.440729: train Epoch: [9][110/193]	Time  1.894 ( 1.402)	Data  0.746 ( 0.295)	Loss 1.1685e-01 (1.3912e-01) 
2023-05-25 00:55:19.740050: train Epoch: [9][111/193]	Time  1.299 ( 1.401)	Data  0.001 ( 0.292)	Loss 1.3523e-01 (1.3909e-01) 
2023-05-25 00:55:21.065632: train Epoch: [9][112/193]	Time  1.326 ( 1.400)	Data  0.272 ( 0.292)	Loss 1.2169e-01 (1.3894e-01) 
2023-05-25 00:55:22.359433: train Epoch: [9][113/193]	Time  1.294 ( 1.399)	Data  0.001 ( 0.290)	Loss 1.9893e-01 (1.3946e-01) 
2023-05-25 00:55:24.216246: train Epoch: [9][114/193]	Time  1.857 ( 1.403)	Data  0.646 ( 0.293)	Loss 1.1549e-01 (1.3925e-01) 
2023-05-25 00:55:25.483469: train Epoch: [9][115/193]	Time  1.267 ( 1.402)	Data  0.001 ( 0.290)	Loss 1.0244e-01 (1.3894e-01) 
2023-05-25 00:55:27.123403: train Epoch: [9][116/193]	Time  1.640 ( 1.404)	Data  0.457 ( 0.292)	Loss 1.6304e-01 (1.3914e-01) 
2023-05-25 00:55:28.110664: train Epoch: [9][117/193]	Time  0.987 ( 1.401)	Data  0.001 ( 0.289)	Loss 1.2310e-01 (1.3901e-01) 
2023-05-25 00:55:29.810925: train Epoch: [9][118/193]	Time  1.700 ( 1.403)	Data  0.708 ( 0.293)	Loss 1.7302e-01 (1.3929e-01) 
2023-05-25 00:55:30.825146: train Epoch: [9][119/193]	Time  1.014 ( 1.400)	Data  0.001 ( 0.290)	Loss 1.3389e-01 (1.3925e-01) 
2023-05-25 00:55:32.655789: train Epoch: [9][120/193]	Time  1.831 ( 1.404)	Data  0.853 ( 0.295)	Loss 1.0962e-01 (1.3900e-01) 
2023-05-25 00:55:33.727778: train Epoch: [9][121/193]	Time  1.072 ( 1.401)	Data  0.001 ( 0.292)	Loss 1.4827e-01 (1.3908e-01) 
2023-05-25 00:55:35.586199: train Epoch: [9][122/193]	Time  1.858 ( 1.405)	Data  0.816 ( 0.297)	Loss 2.5301e-01 (1.4000e-01) 
2023-05-25 00:55:36.696258: train Epoch: [9][123/193]	Time  1.110 ( 1.402)	Data  0.001 ( 0.294)	Loss 7.9876e-02 (1.3952e-01) 
2023-05-25 00:55:38.271950: train Epoch: [9][124/193]	Time  1.576 ( 1.404)	Data  0.569 ( 0.297)	Loss 1.1482e-01 (1.3932e-01) 
2023-05-25 00:55:39.308197: train Epoch: [9][125/193]	Time  1.036 ( 1.401)	Data  0.001 ( 0.294)	Loss 1.4166e-01 (1.3934e-01) 
2023-05-25 00:55:41.500020: train Epoch: [9][126/193]	Time  2.192 ( 1.407)	Data  0.866 ( 0.299)	Loss 1.6306e-01 (1.3953e-01) 
2023-05-25 00:55:42.480360: train Epoch: [9][127/193]	Time  0.980 ( 1.404)	Data  0.001 ( 0.296)	Loss 6.9504e-02 (1.3898e-01) 
2023-05-25 00:55:44.270960: train Epoch: [9][128/193]	Time  1.791 ( 1.407)	Data  0.460 ( 0.298)	Loss 1.0685e-01 (1.3873e-01) 
2023-05-25 00:55:45.280469: train Epoch: [9][129/193]	Time  1.010 ( 1.404)	Data  0.001 ( 0.295)	Loss 9.6592e-02 (1.3841e-01) 
2023-05-25 00:55:46.954456: train Epoch: [9][130/193]	Time  1.674 ( 1.406)	Data  0.476 ( 0.297)	Loss 1.1874e-01 (1.3826e-01) 
2023-05-25 00:55:48.149082: train Epoch: [9][131/193]	Time  1.195 ( 1.404)	Data  0.001 ( 0.294)	Loss 1.4385e-01 (1.3830e-01) 
2023-05-25 00:55:49.566324: train Epoch: [9][132/193]	Time  1.417 ( 1.404)	Data  0.381 ( 0.295)	Loss 1.9524e-01 (1.3873e-01) 
2023-05-25 00:55:50.731902: train Epoch: [9][133/193]	Time  1.166 ( 1.402)	Data  0.001 ( 0.293)	Loss 1.3121e-01 (1.3867e-01) 
2023-05-25 00:55:52.478110: train Epoch: [9][134/193]	Time  1.746 ( 1.405)	Data  0.544 ( 0.295)	Loss 1.3876e-01 (1.3867e-01) 
2023-05-25 00:55:53.896623: train Epoch: [9][135/193]	Time  1.419 ( 1.405)	Data  0.001 ( 0.293)	Loss 1.2603e-01 (1.3858e-01) 
2023-05-25 00:55:55.119121: train Epoch: [9][136/193]	Time  1.222 ( 1.404)	Data  0.207 ( 0.292)	Loss 1.1461e-01 (1.3840e-01) 
2023-05-25 00:55:56.190430: train Epoch: [9][137/193]	Time  1.071 ( 1.401)	Data  0.001 ( 0.290)	Loss 1.4512e-01 (1.3845e-01) 
2023-05-25 00:55:58.209316: train Epoch: [9][138/193]	Time  2.019 ( 1.406)	Data  0.774 ( 0.293)	Loss 1.3461e-01 (1.3842e-01) 
2023-05-25 00:55:59.310259: train Epoch: [9][139/193]	Time  1.101 ( 1.404)	Data  0.001 ( 0.291)	Loss 1.3071e-01 (1.3837e-01) 
2023-05-25 00:56:00.932707: train Epoch: [9][140/193]	Time  1.622 ( 1.405)	Data  0.484 ( 0.293)	Loss 9.4603e-02 (1.3806e-01) 
2023-05-25 00:56:02.011270: train Epoch: [9][141/193]	Time  1.079 ( 1.403)	Data  0.002 ( 0.291)	Loss 5.9430e-02 (1.3751e-01) 
2023-05-25 00:56:03.942838: train Epoch: [9][142/193]	Time  1.932 ( 1.406)	Data  0.605 ( 0.293)	Loss 8.9674e-02 (1.3717e-01) 
2023-05-25 00:56:05.068573: train Epoch: [9][143/193]	Time  1.126 ( 1.405)	Data  0.001 ( 0.291)	Loss 1.5460e-01 (1.3729e-01) 
2023-05-25 00:56:06.704297: train Epoch: [9][144/193]	Time  1.636 ( 1.406)	Data  0.338 ( 0.291)	Loss 1.4149e-01 (1.3732e-01) 
2023-05-25 00:56:07.769447: train Epoch: [9][145/193]	Time  1.065 ( 1.404)	Data  0.001 ( 0.289)	Loss 8.6316e-02 (1.3697e-01) 
2023-05-25 00:56:09.117078: train Epoch: [9][146/193]	Time  1.348 ( 1.403)	Data  0.296 ( 0.289)	Loss 9.4698e-02 (1.3668e-01) 
2023-05-25 00:56:10.125512: train Epoch: [9][147/193]	Time  1.008 ( 1.401)	Data  0.001 ( 0.287)	Loss 2.0538e-01 (1.3715e-01) 
2023-05-25 00:56:11.877516: train Epoch: [9][148/193]	Time  1.752 ( 1.403)	Data  0.544 ( 0.289)	Loss 1.5108e-01 (1.3724e-01) 
2023-05-25 00:56:13.207989: train Epoch: [9][149/193]	Time  1.330 ( 1.403)	Data  0.001 ( 0.287)	Loss 2.1284e-01 (1.3775e-01) 
2023-05-25 00:56:14.475548: train Epoch: [9][150/193]	Time  1.268 ( 1.402)	Data  0.225 ( 0.287)	Loss 7.8259e-02 (1.3735e-01) 
2023-05-25 00:56:15.631526: train Epoch: [9][151/193]	Time  1.156 ( 1.400)	Data  0.001 ( 0.285)	Loss 1.5271e-01 (1.3745e-01) 
2023-05-25 00:56:17.221423: train Epoch: [9][152/193]	Time  1.590 ( 1.401)	Data  0.446 ( 0.286)	Loss 1.0524e-01 (1.3724e-01) 
2023-05-25 00:56:18.371804: train Epoch: [9][153/193]	Time  1.150 ( 1.400)	Data  0.001 ( 0.284)	Loss 1.3519e-01 (1.3723e-01) 
2023-05-25 00:56:19.673353: train Epoch: [9][154/193]	Time  1.302 ( 1.399)	Data  0.390 ( 0.285)	Loss 1.0485e-01 (1.3702e-01) 
2023-05-25 00:56:20.655027: train Epoch: [9][155/193]	Time  0.982 ( 1.396)	Data  0.001 ( 0.283)	Loss 9.4690e-02 (1.3675e-01) 
2023-05-25 00:56:22.525736: train Epoch: [9][156/193]	Time  1.871 ( 1.399)	Data  0.744 ( 0.286)	Loss 1.2538e-01 (1.3668e-01) 
2023-05-25 00:56:23.524877: train Epoch: [9][157/193]	Time  0.999 ( 1.397)	Data  0.001 ( 0.284)	Loss 8.7171e-02 (1.3636e-01) 
2023-05-25 00:56:25.162021: train Epoch: [9][158/193]	Time  1.637 ( 1.398)	Data  0.546 ( 0.286)	Loss 1.0205e-01 (1.3615e-01) 
2023-05-25 00:56:26.275037: train Epoch: [9][159/193]	Time  1.113 ( 1.397)	Data  0.001 ( 0.284)	Loss 1.1528e-01 (1.3602e-01) 
2023-05-25 00:56:27.886788: train Epoch: [9][160/193]	Time  1.612 ( 1.398)	Data  0.520 ( 0.285)	Loss 1.9295e-01 (1.3637e-01) 
2023-05-25 00:56:29.171851: train Epoch: [9][161/193]	Time  1.285 ( 1.397)	Data  0.001 ( 0.284)	Loss 1.2422e-01 (1.3630e-01) 
2023-05-25 00:56:30.816637: train Epoch: [9][162/193]	Time  1.645 ( 1.399)	Data  0.316 ( 0.284)	Loss 1.2571e-01 (1.3623e-01) 
2023-05-25 00:56:31.824998: train Epoch: [9][163/193]	Time  1.008 ( 1.396)	Data  0.001 ( 0.282)	Loss 1.3222e-01 (1.3621e-01) 
2023-05-25 00:56:33.268197: train Epoch: [9][164/193]	Time  1.443 ( 1.397)	Data  0.384 ( 0.283)	Loss 1.5600e-01 (1.3633e-01) 
2023-05-25 00:56:34.304188: train Epoch: [9][165/193]	Time  1.036 ( 1.395)	Data  0.001 ( 0.281)	Loss 1.0885e-01 (1.3616e-01) 
2023-05-25 00:56:36.219975: train Epoch: [9][166/193]	Time  1.916 ( 1.398)	Data  0.676 ( 0.283)	Loss 1.1181e-01 (1.3601e-01) 
2023-05-25 00:56:37.238966: train Epoch: [9][167/193]	Time  1.019 ( 1.395)	Data  0.001 ( 0.282)	Loss 1.4856e-01 (1.3609e-01) 
2023-05-25 00:56:38.709857: train Epoch: [9][168/193]	Time  1.471 ( 1.396)	Data  0.388 ( 0.282)	Loss 2.0583e-01 (1.3650e-01) 
2023-05-25 00:56:39.941957: train Epoch: [9][169/193]	Time  1.232 ( 1.395)	Data  0.001 ( 0.281)	Loss 1.3608e-01 (1.3650e-01) 
2023-05-25 00:56:41.549860: train Epoch: [9][170/193]	Time  1.608 ( 1.396)	Data  0.485 ( 0.282)	Loss 1.5343e-01 (1.3660e-01) 
2023-05-25 00:56:42.855559: train Epoch: [9][171/193]	Time  1.306 ( 1.396)	Data  0.001 ( 0.280)	Loss 2.7067e-01 (1.3738e-01) 
2023-05-25 00:56:44.063439: train Epoch: [9][172/193]	Time  1.208 ( 1.394)	Data  0.246 ( 0.280)	Loss 7.8546e-02 (1.3704e-01) 
2023-05-25 00:56:45.204000: train Epoch: [9][173/193]	Time  1.141 ( 1.393)	Data  0.001 ( 0.278)	Loss 1.3157e-01 (1.3701e-01) 
2023-05-25 00:56:47.138023: train Epoch: [9][174/193]	Time  1.934 ( 1.396)	Data  0.732 ( 0.281)	Loss 2.2125e-01 (1.3749e-01) 
2023-05-25 00:56:48.221277: train Epoch: [9][175/193]	Time  1.083 ( 1.394)	Data  0.001 ( 0.279)	Loss 2.0290e-01 (1.3786e-01) 
2023-05-25 00:56:49.768591: train Epoch: [9][176/193]	Time  1.547 ( 1.395)	Data  0.558 ( 0.281)	Loss 1.1362e-01 (1.3772e-01) 
2023-05-25 00:56:50.817305: train Epoch: [9][177/193]	Time  1.049 ( 1.393)	Data  0.001 ( 0.279)	Loss 1.6080e-01 (1.3785e-01) 
2023-05-25 00:56:52.554667: train Epoch: [9][178/193]	Time  1.737 ( 1.395)	Data  0.793 ( 0.282)	Loss 8.9229e-02 (1.3758e-01) 
2023-05-25 00:56:53.596690: train Epoch: [9][179/193]	Time  1.042 ( 1.393)	Data  0.001 ( 0.281)	Loss 1.6315e-01 (1.3772e-01) 
2023-05-25 00:56:55.620662: train Epoch: [9][180/193]	Time  2.024 ( 1.397)	Data  0.822 ( 0.284)	Loss 2.0311e-01 (1.3808e-01) 
2023-05-25 00:56:56.633745: train Epoch: [9][181/193]	Time  1.013 ( 1.395)	Data  0.001 ( 0.282)	Loss 3.0863e-01 (1.3902e-01) 
2023-05-25 00:56:58.386404: train Epoch: [9][182/193]	Time  1.753 ( 1.397)	Data  0.494 ( 0.283)	Loss 6.9461e-02 (1.3864e-01) 
2023-05-25 00:56:59.398757: train Epoch: [9][183/193]	Time  1.012 ( 1.394)	Data  0.001 ( 0.282)	Loss 1.4067e-01 (1.3865e-01) 
2023-05-25 00:57:01.178636: train Epoch: [9][184/193]	Time  1.780 ( 1.397)	Data  0.452 ( 0.283)	Loss 1.0122e-01 (1.3845e-01) 
2023-05-25 00:57:02.221798: train Epoch: [9][185/193]	Time  1.043 ( 1.395)	Data  0.001 ( 0.281)	Loss 1.2262e-01 (1.3836e-01) 
2023-05-25 00:57:03.828650: train Epoch: [9][186/193]	Time  1.607 ( 1.396)	Data  0.454 ( 0.282)	Loss 1.4954e-01 (1.3842e-01) 
2023-05-25 00:57:04.819561: train Epoch: [9][187/193]	Time  0.991 ( 1.394)	Data  0.001 ( 0.281)	Loss 1.0413e-01 (1.3824e-01) 
2023-05-25 00:57:06.642441: train Epoch: [9][188/193]	Time  1.823 ( 1.396)	Data  0.648 ( 0.283)	Loss 1.4039e-01 (1.3825e-01) 
2023-05-25 00:57:07.596253: train Epoch: [9][189/193]	Time  0.954 ( 1.394)	Data  0.001 ( 0.281)	Loss 2.5637e-01 (1.3887e-01) 
2023-05-25 00:57:09.384216: train Epoch: [9][190/193]	Time  1.788 ( 1.396)	Data  0.615 ( 0.283)	Loss 1.6124e-01 (1.3899e-01) 
2023-05-25 00:57:10.527750: train Epoch: [9][191/193]	Time  1.144 ( 1.394)	Data  0.001 ( 0.281)	Loss 2.0272e-01 (1.3932e-01) 
2023-05-25 00:57:11.548301: train Epoch: [9][192/193]	Time  1.021 ( 1.392)	Data  0.001 ( 0.280)	Loss 1.2197e-01 (1.3923e-01) 
2023-05-25 00:57:11.609715: Train Epoch done in 268.7941981559852 s 
2023-05-25 00:57:14.820202: val Epoch: [9][ 0/72]	Time  2.326 ( 2.326)	Data  1.777 ( 1.777)	Loss 1.4369e-01 (1.4369e-01) 
2023-05-25 00:57:15.201166: val Epoch: [9][ 1/72]	Time  0.382 ( 1.354)	Data  0.002 ( 0.889)	Loss 1.0826e-01 (1.2597e-01) 
2023-05-25 00:57:15.940969: val Epoch: [9][ 2/72]	Time  0.740 ( 1.149)	Data  0.436 ( 0.738)	Loss 1.1153e-01 (1.2116e-01) 
2023-05-25 00:57:16.198209: val Epoch: [9][ 3/72]	Time  0.257 ( 0.926)	Data  0.001 ( 0.554)	Loss 8.5304e-02 (1.1219e-01) 
2023-05-25 00:57:17.478184: val Epoch: [9][ 4/72]	Time  1.280 ( 0.997)	Data  0.916 ( 0.626)	Loss 1.5406e-01 (1.2057e-01) 
2023-05-25 00:57:17.767745: val Epoch: [9][ 5/72]	Time  0.290 ( 0.879)	Data  0.002 ( 0.522)	Loss 2.2777e-01 (1.3843e-01) 
2023-05-25 00:57:19.030797: val Epoch: [9][ 6/72]	Time  1.263 ( 0.934)	Data  0.853 ( 0.569)	Loss 1.1284e-01 (1.3478e-01) 
2023-05-25 00:57:19.213906: val Epoch: [9][ 7/72]	Time  0.183 ( 0.840)	Data  0.001 ( 0.498)	Loss 1.9571e-01 (1.4239e-01) 
2023-05-25 00:57:20.399220: val Epoch: [9][ 8/72]	Time  1.185 ( 0.878)	Data  0.823 ( 0.534)	Loss 8.2433e-02 (1.3573e-01) 
2023-05-25 00:57:20.750842: val Epoch: [9][ 9/72]	Time  0.352 ( 0.826)	Data  0.001 ( 0.481)	Loss 5.3541e-01 (1.7570e-01) 
2023-05-25 00:57:21.909689: val Epoch: [9][10/72]	Time  1.159 ( 0.856)	Data  0.769 ( 0.507)	Loss 2.3244e-01 (1.8086e-01) 
2023-05-25 00:57:22.244316: val Epoch: [9][11/72]	Time  0.335 ( 0.813)	Data  0.001 ( 0.465)	Loss 3.9815e-01 (1.9897e-01) 
2023-05-25 00:57:23.139546: val Epoch: [9][12/72]	Time  0.895 ( 0.819)	Data  0.708 ( 0.484)	Loss 8.4497e-02 (1.9016e-01) 
2023-05-25 00:57:23.386003: val Epoch: [9][13/72]	Time  0.246 ( 0.778)	Data  0.001 ( 0.449)	Loss 1.9344e-01 (1.9039e-01) 
2023-05-25 00:57:24.725540: val Epoch: [9][14/72]	Time  1.340 ( 0.815)	Data  1.073 ( 0.491)	Loss 4.0571e-01 (2.0475e-01) 
2023-05-25 00:57:25.043171: val Epoch: [9][15/72]	Time  0.318 ( 0.784)	Data  0.001 ( 0.460)	Loss 1.1562e-01 (1.9918e-01) 
2023-05-25 00:57:26.050300: val Epoch: [9][16/72]	Time  1.007 ( 0.797)	Data  0.815 ( 0.481)	Loss 1.0695e-01 (1.9375e-01) 
2023-05-25 00:57:26.316031: val Epoch: [9][17/72]	Time  0.266 ( 0.768)	Data  0.001 ( 0.454)	Loss 1.2654e-01 (1.9002e-01) 
2023-05-25 00:57:27.789416: val Epoch: [9][18/72]	Time  1.473 ( 0.805)	Data  1.011 ( 0.484)	Loss 5.6822e-01 (2.0992e-01) 
2023-05-25 00:57:28.101137: val Epoch: [9][19/72]	Time  0.312 ( 0.780)	Data  0.001 ( 0.460)	Loss 2.7098e-01 (2.1298e-01) 
2023-05-25 00:57:29.185155: val Epoch: [9][20/72]	Time  1.084 ( 0.795)	Data  0.657 ( 0.469)	Loss 2.5556e-01 (2.1500e-01) 
2023-05-25 00:57:29.363126: val Epoch: [9][21/72]	Time  0.178 ( 0.767)	Data  0.000 ( 0.448)	Loss 7.4977e-02 (2.0864e-01) 
2023-05-25 00:57:30.522680: val Epoch: [9][22/72]	Time  1.160 ( 0.784)	Data  0.800 ( 0.463)	Loss 3.2766e-01 (2.1381e-01) 
2023-05-25 00:57:30.809396: val Epoch: [9][23/72]	Time  0.287 ( 0.763)	Data  0.003 ( 0.444)	Loss 1.5032e-01 (2.1117e-01) 
2023-05-25 00:57:32.059089: val Epoch: [9][24/72]	Time  1.250 ( 0.783)	Data  0.778 ( 0.457)	Loss 9.2881e-02 (2.0644e-01) 
2023-05-25 00:57:32.588097: val Epoch: [9][25/72]	Time  0.529 ( 0.773)	Data  0.001 ( 0.440)	Loss 1.0119e-01 (2.0239e-01) 
2023-05-25 00:57:33.434178: val Epoch: [9][26/72]	Time  0.846 ( 0.776)	Data  0.475 ( 0.441)	Loss 2.2019e-01 (2.0305e-01) 
2023-05-25 00:57:33.826369: val Epoch: [9][27/72]	Time  0.392 ( 0.762)	Data  0.001 ( 0.425)	Loss 2.8129e-01 (2.0584e-01) 
2023-05-25 00:57:34.905328: val Epoch: [9][28/72]	Time  1.079 ( 0.773)	Data  0.731 ( 0.436)	Loss 1.6569e-01 (2.0446e-01) 
2023-05-25 00:57:35.218993: val Epoch: [9][29/72]	Time  0.314 ( 0.757)	Data  0.001 ( 0.421)	Loss 2.1920e-01 (2.0495e-01) 
2023-05-25 00:57:36.369486: val Epoch: [9][30/72]	Time  1.151 ( 0.770)	Data  0.761 ( 0.432)	Loss 1.6115e-01 (2.0354e-01) 
2023-05-25 00:57:36.569893: val Epoch: [9][31/72]	Time  0.200 ( 0.752)	Data  0.001 ( 0.419)	Loss 7.8170e-02 (1.9962e-01) 
2023-05-25 00:57:37.641202: val Epoch: [9][32/72]	Time  1.071 ( 0.762)	Data  0.803 ( 0.430)	Loss 8.2044e-02 (1.9606e-01) 
2023-05-25 00:57:38.069534: val Epoch: [9][33/72]	Time  0.428 ( 0.752)	Data  0.001 ( 0.418)	Loss 5.5975e-01 (2.0675e-01) 
2023-05-25 00:57:39.290779: val Epoch: [9][34/72]	Time  1.221 ( 0.766)	Data  0.734 ( 0.427)	Loss 1.1547e-01 (2.0414e-01) 
2023-05-25 00:57:39.623520: val Epoch: [9][35/72]	Time  0.333 ( 0.754)	Data  0.001 ( 0.415)	Loss 1.2641e-01 (2.0199e-01) 
2023-05-25 00:57:40.629128: val Epoch: [9][36/72]	Time  1.006 ( 0.760)	Data  0.696 ( 0.423)	Loss 1.0787e-01 (1.9944e-01) 
2023-05-25 00:57:40.988580: val Epoch: [9][37/72]	Time  0.359 ( 0.750)	Data  0.001 ( 0.412)	Loss 8.8491e-02 (1.9652e-01) 
2023-05-25 00:57:42.208542: val Epoch: [9][38/72]	Time  1.220 ( 0.762)	Data  0.804 ( 0.422)	Loss 1.0746e-01 (1.9424e-01) 
2023-05-25 00:57:42.416692: val Epoch: [9][39/72]	Time  0.208 ( 0.748)	Data  0.001 ( 0.411)	Loss 1.3352e-01 (1.9272e-01) 
2023-05-25 00:57:43.588995: val Epoch: [9][40/72]	Time  1.172 ( 0.758)	Data  0.880 ( 0.423)	Loss 1.6184e-01 (1.9197e-01) 
2023-05-25 00:57:43.865340: val Epoch: [9][41/72]	Time  0.276 ( 0.747)	Data  0.001 ( 0.413)	Loss 4.3635e-01 (1.9779e-01) 
2023-05-25 00:57:45.050994: val Epoch: [9][42/72]	Time  1.186 ( 0.757)	Data  0.870 ( 0.423)	Loss 1.6121e-01 (1.9694e-01) 
2023-05-25 00:57:45.445404: val Epoch: [9][43/72]	Time  0.394 ( 0.749)	Data  0.001 ( 0.414)	Loss 8.1612e-02 (1.9431e-01) 
2023-05-25 00:57:46.542664: val Epoch: [9][44/72]	Time  1.097 ( 0.757)	Data  0.697 ( 0.420)	Loss 2.8860e-01 (1.9641e-01) 
2023-05-25 00:57:46.734414: val Epoch: [9][45/72]	Time  0.192 ( 0.744)	Data  0.001 ( 0.411)	Loss 1.0391e-01 (1.9440e-01) 
2023-05-25 00:57:47.755276: val Epoch: [9][46/72]	Time  1.021 ( 0.750)	Data  0.727 ( 0.417)	Loss 9.2682e-02 (1.9223e-01) 
2023-05-25 00:57:48.010168: val Epoch: [9][47/72]	Time  0.255 ( 0.740)	Data  0.001 ( 0.409)	Loss 6.1302e-01 (2.0100e-01) 
2023-05-25 00:57:49.127341: val Epoch: [9][48/72]	Time  1.117 ( 0.748)	Data  0.801 ( 0.417)	Loss 1.5257e-01 (2.0001e-01) 
2023-05-25 00:57:49.370256: val Epoch: [9][49/72]	Time  0.243 ( 0.738)	Data  0.001 ( 0.408)	Loss 3.0477e-01 (2.0211e-01) 
2023-05-25 00:57:50.584464: val Epoch: [9][50/72]	Time  1.214 ( 0.747)	Data  0.774 ( 0.416)	Loss 5.3476e-01 (2.0863e-01) 
2023-05-25 00:57:51.167444: val Epoch: [9][51/72]	Time  0.583 ( 0.744)	Data  0.004 ( 0.408)	Loss 7.8097e-02 (2.0612e-01) 
2023-05-25 00:57:51.800577: val Epoch: [9][52/72]	Time  0.633 ( 0.742)	Data  0.338 ( 0.406)	Loss 4.9702e-01 (2.1161e-01) 
2023-05-25 00:57:52.176428: val Epoch: [9][53/72]	Time  0.376 ( 0.735)	Data  0.001 ( 0.399)	Loss 4.9579e-01 (2.1687e-01) 
2023-05-25 00:57:53.227266: val Epoch: [9][54/72]	Time  1.051 ( 0.741)	Data  0.719 ( 0.405)	Loss 1.1190e-01 (2.1496e-01) 
2023-05-25 00:57:53.662170: val Epoch: [9][55/72]	Time  0.435 ( 0.735)	Data  0.001 ( 0.397)	Loss 1.0586e-01 (2.1301e-01) 
2023-05-25 00:57:54.465390: val Epoch: [9][56/72]	Time  0.803 ( 0.736)	Data  0.580 ( 0.401)	Loss 8.8644e-02 (2.1083e-01) 
2023-05-25 00:57:54.713427: val Epoch: [9][57/72]	Time  0.248 ( 0.728)	Data  0.001 ( 0.394)	Loss 1.5543e-01 (2.0988e-01) 
2023-05-25 00:57:56.157998: val Epoch: [9][58/72]	Time  1.445 ( 0.740)	Data  0.944 ( 0.403)	Loss 1.2382e-01 (2.0842e-01) 
2023-05-25 00:57:56.588815: val Epoch: [9][59/72]	Time  0.431 ( 0.735)	Data  0.001 ( 0.396)	Loss 3.0320e-01 (2.1000e-01) 
2023-05-25 00:57:57.453723: val Epoch: [9][60/72]	Time  0.865 ( 0.737)	Data  0.444 ( 0.397)	Loss 2.6981e-01 (2.1098e-01) 
2023-05-25 00:57:57.830538: val Epoch: [9][61/72]	Time  0.377 ( 0.731)	Data  0.002 ( 0.391)	Loss 9.2929e-02 (2.0907e-01) 
2023-05-25 00:57:58.786645: val Epoch: [9][62/72]	Time  0.956 ( 0.735)	Data  0.632 ( 0.395)	Loss 2.4052e-01 (2.0957e-01) 
2023-05-25 00:57:59.029641: val Epoch: [9][63/72]	Time  0.243 ( 0.727)	Data  0.001 ( 0.388)	Loss 3.9150e-01 (2.1242e-01) 
2023-05-25 00:58:00.212973: val Epoch: [9][64/72]	Time  1.183 ( 0.734)	Data  0.812 ( 0.395)	Loss 1.0565e-01 (2.1077e-01) 
2023-05-25 00:58:00.543672: val Epoch: [9][65/72]	Time  0.331 ( 0.728)	Data  0.001 ( 0.389)	Loss 2.8166e-01 (2.1185e-01) 
2023-05-25 00:58:01.596980: val Epoch: [9][66/72]	Time  1.053 ( 0.733)	Data  0.634 ( 0.393)	Loss 1.2356e-01 (2.1053e-01) 
2023-05-25 00:58:02.107440: val Epoch: [9][67/72]	Time  0.510 ( 0.730)	Data  0.002 ( 0.387)	Loss 1.3658e-01 (2.0944e-01) 
2023-05-25 00:58:03.057006: val Epoch: [9][68/72]	Time  0.950 ( 0.733)	Data  0.467 ( 0.388)	Loss 1.5190e-01 (2.0861e-01) 
2023-05-25 00:58:03.373830: val Epoch: [9][69/72]	Time  0.317 ( 0.727)	Data  0.001 ( 0.383)	Loss 1.3021e-01 (2.0749e-01) 
2023-05-25 00:58:04.209337: val Epoch: [9][70/72]	Time  0.836 ( 0.728)	Data  0.477 ( 0.384)	Loss 9.2245e-02 (2.0587e-01) 
2023-05-25 00:58:04.400558: val Epoch: [9][71/72]	Time  0.191 ( 0.721)	Data  0.001 ( 0.379)	Loss 1.7433e-01 (2.0543e-01) 
2023-05-25 00:58:04.649132: Epoch 9 :Val : ['ET : 0.6192014217376709', 'TC : 0.6354181170463562', 'WT : 0.8040733337402344'] 
2023-05-25 00:58:04.652120: Epoch 9 :Val : ['ET : 0.6192014217376709', 'TC : 0.6354181170463562', 'WT : 0.8040733337402344'] 
2023-05-25 00:58:04.655003: Val epoch done in 53.045293504954316 s 
2023-05-25 00:58:04.662072: Batches per epoch:  193 
2023-05-25 00:58:09.191395: train Epoch: [10][  0/193]	Time  4.529 ( 4.529)	Data  3.268 ( 3.268)	Loss 1.4397e-01 (1.4397e-01) 
2023-05-25 00:58:10.276509: train Epoch: [10][  1/193]	Time  1.085 ( 2.807)	Data  0.002 ( 1.635)	Loss 1.3394e-01 (1.3895e-01) 
2023-05-25 00:58:11.858869: train Epoch: [10][  2/193]	Time  1.582 ( 2.399)	Data  0.432 ( 1.234)	Loss 7.9367e-02 (1.1909e-01) 
2023-05-25 00:58:12.828392: train Epoch: [10][  3/193]	Time  0.970 ( 2.041)	Data  0.003 ( 0.926)	Loss 1.1624e-01 (1.1838e-01) 
2023-05-25 00:58:14.539551: train Epoch: [10][  4/193]	Time  1.711 ( 1.975)	Data  0.646 ( 0.870)	Loss 1.5063e-01 (1.2483e-01) 
2023-05-25 00:58:15.538413: train Epoch: [10][  5/193]	Time  0.999 ( 1.813)	Data  0.001 ( 0.725)	Loss 1.0505e-01 (1.2153e-01) 
2023-05-25 00:58:17.454518: train Epoch: [10][  6/193]	Time  1.916 ( 1.827)	Data  0.822 ( 0.739)	Loss 1.4132e-01 (1.2436e-01) 
2023-05-25 00:58:18.340004: train Epoch: [10][  7/193]	Time  0.885 ( 1.710)	Data  0.001 ( 0.647)	Loss 8.0938e-02 (1.1893e-01) 
2023-05-25 00:58:20.528466: train Epoch: [10][  8/193]	Time  2.188 ( 1.763)	Data  0.869 ( 0.672)	Loss 3.3745e-01 (1.4321e-01) 
2023-05-25 00:58:21.547634: train Epoch: [10][  9/193]	Time  1.019 ( 1.689)	Data  0.001 ( 0.604)	Loss 1.1888e-01 (1.4078e-01) 
2023-05-25 00:58:23.137041: train Epoch: [10][ 10/193]	Time  1.589 ( 1.679)	Data  0.457 ( 0.591)	Loss 1.0755e-01 (1.3776e-01) 
2023-05-25 00:58:24.182930: train Epoch: [10][ 11/193]	Time  1.046 ( 1.627)	Data  0.001 ( 0.542)	Loss 1.3166e-01 (1.3725e-01) 
2023-05-25 00:58:25.753937: train Epoch: [10][ 12/193]	Time  1.571 ( 1.622)	Data  0.488 ( 0.538)	Loss 1.0627e-01 (1.3487e-01) 
2023-05-25 00:58:27.052419: train Epoch: [10][ 13/193]	Time  1.298 ( 1.599)	Data  0.001 ( 0.499)	Loss 1.2256e-01 (1.3399e-01) 
2023-05-25 00:58:28.508017: train Epoch: [10][ 14/193]	Time  1.456 ( 1.590)	Data  0.263 ( 0.484)	Loss 1.3121e-01 (1.3380e-01) 
2023-05-25 00:58:29.721271: train Epoch: [10][ 15/193]	Time  1.213 ( 1.566)	Data  0.001 ( 0.454)	Loss 1.0035e-01 (1.3171e-01) 
2023-05-25 00:58:31.144777: train Epoch: [10][ 16/193]	Time  1.424 ( 1.558)	Data  0.418 ( 0.451)	Loss 1.7513e-01 (1.3427e-01) 
2023-05-25 00:58:32.229510: train Epoch: [10][ 17/193]	Time  1.085 ( 1.531)	Data  0.001 ( 0.426)	Loss 2.2798e-01 (1.3947e-01) 
2023-05-25 00:58:33.874374: train Epoch: [10][ 18/193]	Time  1.645 ( 1.537)	Data  0.659 ( 0.439)	Loss 7.1947e-02 (1.3592e-01) 
2023-05-25 00:58:34.897565: train Epoch: [10][ 19/193]	Time  1.023 ( 1.512)	Data  0.001 ( 0.417)	Loss 9.7594e-02 (1.3400e-01) 
2023-05-25 00:58:36.828158: train Epoch: [10][ 20/193]	Time  1.931 ( 1.532)	Data  0.789 ( 0.435)	Loss 2.1801e-01 (1.3800e-01) 
2023-05-25 00:58:37.937572: train Epoch: [10][ 21/193]	Time  1.109 ( 1.512)	Data  0.001 ( 0.415)	Loss 1.9748e-01 (1.4071e-01) 
2023-05-25 00:58:39.904123: train Epoch: [10][ 22/193]	Time  1.967 ( 1.532)	Data  0.587 ( 0.422)	Loss 1.5215e-01 (1.4120e-01) 
2023-05-25 00:58:41.001670: train Epoch: [10][ 23/193]	Time  1.098 ( 1.514)	Data  0.001 ( 0.405)	Loss 1.1578e-01 (1.4014e-01) 
2023-05-25 00:58:42.637777: train Epoch: [10][ 24/193]	Time  1.636 ( 1.519)	Data  0.418 ( 0.405)	Loss 1.1724e-01 (1.3923e-01) 
2023-05-25 00:58:43.855975: train Epoch: [10][ 25/193]	Time  1.218 ( 1.507)	Data  0.001 ( 0.390)	Loss 9.9305e-02 (1.3769e-01) 
2023-05-25 00:58:45.442775: train Epoch: [10][ 26/193]	Time  1.587 ( 1.510)	Data  0.337 ( 0.388)	Loss 1.3875e-01 (1.3773e-01) 
2023-05-25 00:58:46.655143: train Epoch: [10][ 27/193]	Time  1.212 ( 1.500)	Data  0.001 ( 0.374)	Loss 9.6971e-02 (1.3628e-01) 
2023-05-25 00:58:47.924282: train Epoch: [10][ 28/193]	Time  1.269 ( 1.492)	Data  0.208 ( 0.368)	Loss 1.2944e-01 (1.3604e-01) 
2023-05-25 00:58:48.933321: train Epoch: [10][ 29/193]	Time  1.009 ( 1.476)	Data  0.001 ( 0.356)	Loss 1.9329e-01 (1.3795e-01) 
2023-05-25 00:58:50.719725: train Epoch: [10][ 30/193]	Time  1.786 ( 1.486)	Data  0.739 ( 0.368)	Loss 1.0710e-01 (1.3695e-01) 
2023-05-25 00:58:51.720056: train Epoch: [10][ 31/193]	Time  1.000 ( 1.471)	Data  0.001 ( 0.357)	Loss 1.2891e-01 (1.3670e-01) 
2023-05-25 00:58:53.408237: train Epoch: [10][ 32/193]	Time  1.688 ( 1.477)	Data  0.679 ( 0.367)	Loss 1.5358e-01 (1.3721e-01) 
2023-05-25 00:58:54.415390: train Epoch: [10][ 33/193]	Time  1.007 ( 1.463)	Data  0.001 ( 0.356)	Loss 1.7479e-01 (1.3832e-01) 
2023-05-25 00:58:56.184025: train Epoch: [10][ 34/193]	Time  1.769 ( 1.472)	Data  0.549 ( 0.361)	Loss 1.1411e-01 (1.3763e-01) 
2023-05-25 00:58:57.142923: train Epoch: [10][ 35/193]	Time  0.959 ( 1.458)	Data  0.001 ( 0.351)	Loss 1.5669e-01 (1.3816e-01) 
2023-05-25 00:58:58.748866: train Epoch: [10][ 36/193]	Time  1.606 ( 1.462)	Data  0.520 ( 0.356)	Loss 1.6673e-01 (1.3893e-01) 
2023-05-25 00:58:59.723280: train Epoch: [10][ 37/193]	Time  0.974 ( 1.449)	Data  0.001 ( 0.347)	Loss 1.2074e-01 (1.3845e-01) 
2023-05-25 00:59:01.608231: train Epoch: [10][ 38/193]	Time  1.885 ( 1.460)	Data  0.651 ( 0.354)	Loss 1.5970e-01 (1.3899e-01) 
2023-05-25 00:59:02.633287: train Epoch: [10][ 39/193]	Time  1.025 ( 1.449)	Data  0.001 ( 0.346)	Loss 2.1790e-01 (1.4097e-01) 
2023-05-25 00:59:04.163901: train Epoch: [10][ 40/193]	Time  1.531 ( 1.451)	Data  0.484 ( 0.349)	Loss 1.3896e-01 (1.4092e-01) 
2023-05-25 00:59:05.381875: train Epoch: [10][ 41/193]	Time  1.218 ( 1.446)	Data  0.124 ( 0.344)	Loss 9.9985e-02 (1.3994e-01) 
2023-05-25 00:59:07.173567: train Epoch: [10][ 42/193]	Time  1.792 ( 1.454)	Data  0.574 ( 0.349)	Loss 1.7713e-01 (1.4081e-01) 
2023-05-25 00:59:08.186416: train Epoch: [10][ 43/193]	Time  1.013 ( 1.444)	Data  0.001 ( 0.341)	Loss 2.0466e-01 (1.4226e-01) 
2023-05-25 00:59:09.884908: train Epoch: [10][ 44/193]	Time  1.699 ( 1.449)	Data  0.604 ( 0.347)	Loss 1.5455e-01 (1.4253e-01) 
2023-05-25 00:59:11.014215: train Epoch: [10][ 45/193]	Time  1.129 ( 1.442)	Data  0.001 ( 0.339)	Loss 2.1887e-01 (1.4419e-01) 
2023-05-25 00:59:12.828211: train Epoch: [10][ 46/193]	Time  1.814 ( 1.450)	Data  0.603 ( 0.345)	Loss 1.1057e-01 (1.4348e-01) 
2023-05-25 00:59:13.930425: train Epoch: [10][ 47/193]	Time  1.102 ( 1.443)	Data  0.001 ( 0.338)	Loss 1.1531e-01 (1.4289e-01) 
2023-05-25 00:59:15.501202: train Epoch: [10][ 48/193]	Time  1.571 ( 1.446)	Data  0.483 ( 0.341)	Loss 2.1710e-01 (1.4441e-01) 
2023-05-25 00:59:16.603611: train Epoch: [10][ 49/193]	Time  1.102 ( 1.439)	Data  0.001 ( 0.334)	Loss 1.0025e-01 (1.4352e-01) 
2023-05-25 00:59:18.427253: train Epoch: [10][ 50/193]	Time  1.824 ( 1.446)	Data  0.594 ( 0.339)	Loss 1.2828e-01 (1.4322e-01) 
2023-05-25 00:59:19.458630: train Epoch: [10][ 51/193]	Time  1.031 ( 1.438)	Data  0.001 ( 0.333)	Loss 8.8563e-02 (1.4217e-01) 
2023-05-25 00:59:21.241831: train Epoch: [10][ 52/193]	Time  1.783 ( 1.445)	Data  0.467 ( 0.335)	Loss 2.3522e-01 (1.4393e-01) 
2023-05-25 00:59:22.314439: train Epoch: [10][ 53/193]	Time  1.073 ( 1.438)	Data  0.001 ( 0.329)	Loss 2.0670e-01 (1.4509e-01) 
2023-05-25 00:59:23.704002: train Epoch: [10][ 54/193]	Time  1.390 ( 1.437)	Data  0.322 ( 0.329)	Loss 1.0856e-01 (1.4443e-01) 
2023-05-25 00:59:24.768228: train Epoch: [10][ 55/193]	Time  1.064 ( 1.430)	Data  0.001 ( 0.323)	Loss 1.2385e-01 (1.4406e-01) 
2023-05-25 00:59:26.595320: train Epoch: [10][ 56/193]	Time  1.827 ( 1.437)	Data  0.627 ( 0.328)	Loss 2.4342e-01 (1.4580e-01) 
2023-05-25 00:59:27.796501: train Epoch: [10][ 57/193]	Time  1.201 ( 1.433)	Data  0.001 ( 0.323)	Loss 1.1505e-01 (1.4527e-01) 
2023-05-25 00:59:29.306452: train Epoch: [10][ 58/193]	Time  1.510 ( 1.435)	Data  0.321 ( 0.323)	Loss 2.0445e-01 (1.4627e-01) 
2023-05-25 00:59:30.538093: train Epoch: [10][ 59/193]	Time  1.232 ( 1.431)	Data  0.001 ( 0.317)	Loss 1.2599e-01 (1.4594e-01) 
2023-05-25 00:59:32.004835: train Epoch: [10][ 60/193]	Time  1.467 ( 1.432)	Data  0.312 ( 0.317)	Loss 1.0869e-01 (1.4533e-01) 
2023-05-25 00:59:33.097220: train Epoch: [10][ 61/193]	Time  1.092 ( 1.426)	Data  0.001 ( 0.312)	Loss 1.3988e-01 (1.4524e-01) 
2023-05-25 00:59:34.649398: train Epoch: [10][ 62/193]	Time  1.552 ( 1.428)	Data  0.539 ( 0.316)	Loss 9.2368e-02 (1.4440e-01) 
2023-05-25 00:59:35.684145: train Epoch: [10][ 63/193]	Time  1.035 ( 1.422)	Data  0.067 ( 0.312)	Loss 1.1186e-01 (1.4389e-01) 
2023-05-25 00:59:37.449625: train Epoch: [10][ 64/193]	Time  1.765 ( 1.427)	Data  0.660 ( 0.317)	Loss 2.1966e-01 (1.4506e-01) 
2023-05-25 00:59:38.511145: train Epoch: [10][ 65/193]	Time  1.062 ( 1.422)	Data  0.077 ( 0.314)	Loss 1.4374e-01 (1.4504e-01) 
2023-05-25 00:59:40.433078: train Epoch: [10][ 66/193]	Time  1.922 ( 1.429)	Data  0.602 ( 0.318)	Loss 1.4763e-01 (1.4508e-01) 
2023-05-25 00:59:41.407455: train Epoch: [10][ 67/193]	Time  0.974 ( 1.423)	Data  0.001 ( 0.313)	Loss 6.5151e-02 (1.4390e-01) 
2023-05-25 00:59:42.932488: train Epoch: [10][ 68/193]	Time  1.525 ( 1.424)	Data  0.473 ( 0.315)	Loss 1.6711e-01 (1.4424e-01) 
2023-05-25 00:59:44.234063: train Epoch: [10][ 69/193]	Time  1.302 ( 1.422)	Data  0.252 ( 0.315)	Loss 1.0870e-01 (1.4373e-01) 
2023-05-25 00:59:45.646048: train Epoch: [10][ 70/193]	Time  1.412 ( 1.422)	Data  0.324 ( 0.315)	Loss 2.0457e-01 (1.4459e-01) 
2023-05-25 00:59:47.337246: train Epoch: [10][ 71/193]	Time  1.691 ( 1.426)	Data  0.412 ( 0.316)	Loss 1.9371e-01 (1.4527e-01) 
2023-05-25 00:59:48.458882: train Epoch: [10][ 72/193]	Time  1.122 ( 1.422)	Data  0.057 ( 0.312)	Loss 2.0843e-01 (1.4613e-01) 
2023-05-25 00:59:50.169855: train Epoch: [10][ 73/193]	Time  1.711 ( 1.426)	Data  0.439 ( 0.314)	Loss 1.6315e-01 (1.4636e-01) 
2023-05-25 00:59:51.215882: train Epoch: [10][ 74/193]	Time  1.046 ( 1.421)	Data  0.041 ( 0.311)	Loss 1.3888e-01 (1.4626e-01) 
2023-05-25 00:59:52.969944: train Epoch: [10][ 75/193]	Time  1.754 ( 1.425)	Data  0.424 ( 0.312)	Loss 1.2462e-01 (1.4598e-01) 
2023-05-25 00:59:54.013151: train Epoch: [10][ 76/193]	Time  1.043 ( 1.420)	Data  0.001 ( 0.308)	Loss 1.1545e-01 (1.4558e-01) 
2023-05-25 00:59:55.879324: train Epoch: [10][ 77/193]	Time  1.866 ( 1.426)	Data  0.494 ( 0.310)	Loss 7.5330e-02 (1.4468e-01) 
2023-05-25 00:59:56.831974: train Epoch: [10][ 78/193]	Time  0.953 ( 1.420)	Data  0.001 ( 0.306)	Loss 1.5173e-01 (1.4477e-01) 
2023-05-25 00:59:58.605982: train Epoch: [10][ 79/193]	Time  1.774 ( 1.424)	Data  0.559 ( 0.310)	Loss 1.2983e-01 (1.4458e-01) 
2023-05-25 00:59:59.679069: train Epoch: [10][ 80/193]	Time  1.073 ( 1.420)	Data  0.001 ( 0.306)	Loss 1.0320e-01 (1.4407e-01) 
2023-05-25 01:00:01.537487: train Epoch: [10][ 81/193]	Time  1.858 ( 1.425)	Data  0.726 ( 0.311)	Loss 1.2106e-01 (1.4379e-01) 
2023-05-25 01:00:02.722459: train Epoch: [10][ 82/193]	Time  1.185 ( 1.422)	Data  0.001 ( 0.307)	Loss 2.3113e-01 (1.4484e-01) 
2023-05-25 01:00:04.347337: train Epoch: [10][ 83/193]	Time  1.625 ( 1.425)	Data  0.549 ( 0.310)	Loss 1.2991e-01 (1.4467e-01) 
2023-05-25 01:00:05.462627: train Epoch: [10][ 84/193]	Time  1.115 ( 1.421)	Data  0.001 ( 0.306)	Loss 8.6256e-02 (1.4398e-01) 
2023-05-25 01:00:07.367769: train Epoch: [10][ 85/193]	Time  1.905 ( 1.427)	Data  0.762 ( 0.312)	Loss 1.9337e-01 (1.4455e-01) 
2023-05-25 01:00:08.537162: train Epoch: [10][ 86/193]	Time  1.169 ( 1.424)	Data  0.001 ( 0.308)	Loss 1.4214e-01 (1.4453e-01) 
2023-05-25 01:00:10.251379: train Epoch: [10][ 87/193]	Time  1.714 ( 1.427)	Data  0.542 ( 0.311)	Loss 5.4309e-02 (1.4350e-01) 
2023-05-25 01:00:11.319906: train Epoch: [10][ 88/193]	Time  1.069 ( 1.423)	Data  0.001 ( 0.307)	Loss 7.5493e-02 (1.4274e-01) 
2023-05-25 01:00:12.799016: train Epoch: [10][ 89/193]	Time  1.479 ( 1.424)	Data  0.505 ( 0.310)	Loss 1.1287e-01 (1.4240e-01) 
2023-05-25 01:00:13.876495: train Epoch: [10][ 90/193]	Time  1.077 ( 1.420)	Data  0.001 ( 0.306)	Loss 2.0661e-01 (1.4311e-01) 
2023-05-25 01:00:15.854464: train Epoch: [10][ 91/193]	Time  1.978 ( 1.426)	Data  0.704 ( 0.310)	Loss 1.4609e-01 (1.4314e-01) 
2023-05-25 01:00:16.842355: train Epoch: [10][ 92/193]	Time  0.988 ( 1.421)	Data  0.001 ( 0.307)	Loss 8.9749e-02 (1.4257e-01) 
2023-05-25 01:00:18.400409: train Epoch: [10][ 93/193]	Time  1.558 ( 1.423)	Data  0.454 ( 0.309)	Loss 3.1010e-01 (1.4435e-01) 
2023-05-25 01:00:19.403008: train Epoch: [10][ 94/193]	Time  1.003 ( 1.418)	Data  0.001 ( 0.305)	Loss 8.5754e-02 (1.4373e-01) 
2023-05-25 01:00:21.288773: train Epoch: [10][ 95/193]	Time  1.886 ( 1.423)	Data  0.689 ( 0.309)	Loss 1.4948e-01 (1.4379e-01) 
2023-05-25 01:00:22.426529: train Epoch: [10][ 96/193]	Time  1.138 ( 1.420)	Data  0.001 ( 0.306)	Loss 1.6160e-01 (1.4398e-01) 
2023-05-25 01:00:24.096977: train Epoch: [10][ 97/193]	Time  1.670 ( 1.423)	Data  0.436 ( 0.308)	Loss 7.9818e-02 (1.4332e-01) 
2023-05-25 01:00:25.219603: train Epoch: [10][ 98/193]	Time  1.123 ( 1.420)	Data  0.001 ( 0.305)	Loss 1.5041e-01 (1.4339e-01) 
2023-05-25 01:00:26.869359: train Epoch: [10][ 99/193]	Time  1.650 ( 1.422)	Data  0.455 ( 0.306)	Loss 9.0849e-02 (1.4287e-01) 
2023-05-25 01:00:28.140280: train Epoch: [10][100/193]	Time  1.271 ( 1.421)	Data  0.001 ( 0.303)	Loss 2.9496e-01 (1.4437e-01) 
2023-05-25 01:00:29.730090: train Epoch: [10][101/193]	Time  1.590 ( 1.422)	Data  0.540 ( 0.305)	Loss 2.0905e-01 (1.4501e-01) 
2023-05-25 01:00:30.926286: train Epoch: [10][102/193]	Time  1.196 ( 1.420)	Data  0.001 ( 0.302)	Loss 1.1579e-01 (1.4473e-01) 
2023-05-25 01:00:32.314449: train Epoch: [10][103/193]	Time  1.388 ( 1.420)	Data  0.395 ( 0.303)	Loss 1.4666e-01 (1.4474e-01) 
2023-05-25 01:00:33.341991: train Epoch: [10][104/193]	Time  1.028 ( 1.416)	Data  0.001 ( 0.300)	Loss 2.1228e-01 (1.4539e-01) 
2023-05-25 01:00:35.402788: train Epoch: [10][105/193]	Time  2.061 ( 1.422)	Data  0.808 ( 0.305)	Loss 1.0624e-01 (1.4502e-01) 
2023-05-25 01:00:36.474414: train Epoch: [10][106/193]	Time  1.072 ( 1.419)	Data  0.001 ( 0.302)	Loss 9.9850e-02 (1.4460e-01) 
2023-05-25 01:00:38.123573: train Epoch: [10][107/193]	Time  1.649 ( 1.421)	Data  0.371 ( 0.303)	Loss 1.2555e-01 (1.4442e-01) 
2023-05-25 01:00:39.138528: train Epoch: [10][108/193]	Time  1.015 ( 1.417)	Data  0.001 ( 0.300)	Loss 1.0789e-01 (1.4408e-01) 
2023-05-25 01:00:40.858380: train Epoch: [10][109/193]	Time  1.720 ( 1.420)	Data  0.487 ( 0.302)	Loss 1.5271e-01 (1.4416e-01) 
2023-05-25 01:00:41.892408: train Epoch: [10][110/193]	Time  1.034 ( 1.416)	Data  0.002 ( 0.299)	Loss 2.5426e-01 (1.4515e-01) 
2023-05-25 01:00:43.609541: train Epoch: [10][111/193]	Time  1.717 ( 1.419)	Data  0.423 ( 0.300)	Loss 1.7312e-01 (1.4540e-01) 
2023-05-25 01:00:44.669982: train Epoch: [10][112/193]	Time  1.060 ( 1.416)	Data  0.001 ( 0.298)	Loss 1.8493e-01 (1.4575e-01) 
2023-05-25 01:00:46.514721: train Epoch: [10][113/193]	Time  1.845 ( 1.420)	Data  0.577 ( 0.300)	Loss 1.5976e-01 (1.4588e-01) 
2023-05-25 01:00:47.566161: train Epoch: [10][114/193]	Time  1.051 ( 1.417)	Data  0.001 ( 0.298)	Loss 9.4286e-02 (1.4543e-01) 
2023-05-25 01:00:49.134683: train Epoch: [10][115/193]	Time  1.569 ( 1.418)	Data  0.465 ( 0.299)	Loss 1.7784e-01 (1.4571e-01) 
2023-05-25 01:00:50.189043: train Epoch: [10][116/193]	Time  1.054 ( 1.415)	Data  0.001 ( 0.296)	Loss 1.7323e-01 (1.4594e-01) 
2023-05-25 01:00:52.084531: train Epoch: [10][117/193]	Time  1.895 ( 1.419)	Data  0.672 ( 0.300)	Loss 2.0246e-01 (1.4642e-01) 
2023-05-25 01:00:53.028520: train Epoch: [10][118/193]	Time  0.944 ( 1.415)	Data  0.001 ( 0.297)	Loss 1.3857e-01 (1.4636e-01) 
2023-05-25 01:00:54.779105: train Epoch: [10][119/193]	Time  1.751 ( 1.418)	Data  0.672 ( 0.300)	Loss 1.7776e-01 (1.4662e-01) 
2023-05-25 01:00:55.802312: train Epoch: [10][120/193]	Time  1.023 ( 1.414)	Data  0.001 ( 0.298)	Loss 1.2625e-01 (1.4645e-01) 
2023-05-25 01:00:57.481868: train Epoch: [10][121/193]	Time  1.680 ( 1.417)	Data  0.662 ( 0.301)	Loss 1.4850e-01 (1.4647e-01) 
2023-05-25 01:00:58.643434: train Epoch: [10][122/193]	Time  1.162 ( 1.414)	Data  0.001 ( 0.298)	Loss 1.0151e-01 (1.4610e-01) 
2023-05-25 01:01:00.336904: train Epoch: [10][123/193]	Time  1.693 ( 1.417)	Data  0.604 ( 0.301)	Loss 9.5909e-02 (1.4570e-01) 
2023-05-25 01:01:01.380943: train Epoch: [10][124/193]	Time  1.044 ( 1.414)	Data  0.001 ( 0.298)	Loss 1.0461e-01 (1.4537e-01) 
2023-05-25 01:01:02.953977: train Epoch: [10][125/193]	Time  1.573 ( 1.415)	Data  0.499 ( 0.300)	Loss 1.6299e-01 (1.4551e-01) 
2023-05-25 01:01:04.104661: train Epoch: [10][126/193]	Time  1.151 ( 1.413)	Data  0.001 ( 0.298)	Loss 8.9040e-02 (1.4506e-01) 
2023-05-25 01:01:06.005658: train Epoch: [10][127/193]	Time  1.901 ( 1.417)	Data  0.524 ( 0.299)	Loss 7.7470e-02 (1.4453e-01) 
2023-05-25 01:01:07.060187: train Epoch: [10][128/193]	Time  1.055 ( 1.414)	Data  0.001 ( 0.297)	Loss 9.1268e-02 (1.4412e-01) 
2023-05-25 01:01:08.547975: train Epoch: [10][129/193]	Time  1.488 ( 1.414)	Data  0.345 ( 0.297)	Loss 1.5645e-01 (1.4422e-01) 
2023-05-25 01:01:09.646837: train Epoch: [10][130/193]	Time  1.099 ( 1.412)	Data  0.001 ( 0.295)	Loss 1.4230e-01 (1.4420e-01) 
2023-05-25 01:01:11.635291: train Epoch: [10][131/193]	Time  1.988 ( 1.416)	Data  0.630 ( 0.298)	Loss 1.1520e-01 (1.4398e-01) 
2023-05-25 01:01:12.604115: train Epoch: [10][132/193]	Time  0.969 ( 1.413)	Data  0.001 ( 0.295)	Loss 8.2122e-02 (1.4352e-01) 
2023-05-25 01:01:14.321775: train Epoch: [10][133/193]	Time  1.718 ( 1.415)	Data  0.523 ( 0.297)	Loss 1.9567e-01 (1.4391e-01) 
2023-05-25 01:01:15.388981: train Epoch: [10][134/193]	Time  1.067 ( 1.413)	Data  0.001 ( 0.295)	Loss 1.1112e-01 (1.4366e-01) 
2023-05-25 01:01:17.206603: train Epoch: [10][135/193]	Time  1.818 ( 1.416)	Data  0.716 ( 0.298)	Loss 8.3254e-02 (1.4322e-01) 
2023-05-25 01:01:18.279891: train Epoch: [10][136/193]	Time  1.073 ( 1.413)	Data  0.001 ( 0.296)	Loss 2.1962e-01 (1.4378e-01) 
2023-05-25 01:01:20.038322: train Epoch: [10][137/193]	Time  1.758 ( 1.416)	Data  0.663 ( 0.299)	Loss 1.3888e-01 (1.4374e-01) 
2023-05-25 01:01:21.227182: train Epoch: [10][138/193]	Time  1.189 ( 1.414)	Data  0.001 ( 0.296)	Loss 8.5201e-02 (1.4332e-01) 
2023-05-25 01:01:22.789770: train Epoch: [10][139/193]	Time  1.563 ( 1.415)	Data  0.470 ( 0.298)	Loss 1.5073e-01 (1.4337e-01) 
2023-05-25 01:01:24.037013: train Epoch: [10][140/193]	Time  1.247 ( 1.414)	Data  0.001 ( 0.296)	Loss 1.0603e-01 (1.4311e-01) 
2023-05-25 01:01:25.746120: train Epoch: [10][141/193]	Time  1.709 ( 1.416)	Data  0.496 ( 0.297)	Loss 3.2207e-01 (1.4437e-01) 
2023-05-25 01:01:27.029521: train Epoch: [10][142/193]	Time  1.283 ( 1.415)	Data  0.001 ( 0.295)	Loss 3.5298e-01 (1.4583e-01) 
2023-05-25 01:01:28.442709: train Epoch: [10][143/193]	Time  1.413 ( 1.415)	Data  0.356 ( 0.295)	Loss 2.3071e-01 (1.4642e-01) 
2023-05-25 01:01:29.535109: train Epoch: [10][144/193]	Time  1.092 ( 1.413)	Data  0.001 ( 0.293)	Loss 1.7688e-01 (1.4663e-01) 
2023-05-25 01:01:31.238070: train Epoch: [10][145/193]	Time  1.703 ( 1.415)	Data  0.690 ( 0.296)	Loss 1.6609e-01 (1.4676e-01) 
2023-05-25 01:01:32.202730: train Epoch: [10][146/193]	Time  0.965 ( 1.412)	Data  0.001 ( 0.294)	Loss 1.1217e-01 (1.4652e-01) 
2023-05-25 01:01:34.273241: train Epoch: [10][147/193]	Time  2.071 ( 1.416)	Data  0.672 ( 0.297)	Loss 1.9427e-01 (1.4685e-01) 
2023-05-25 01:01:35.330920: train Epoch: [10][148/193]	Time  1.058 ( 1.414)	Data  0.001 ( 0.295)	Loss 4.0746e-01 (1.4860e-01) 
2023-05-25 01:01:36.615018: train Epoch: [10][149/193]	Time  1.284 ( 1.413)	Data  0.244 ( 0.294)	Loss 1.9817e-01 (1.4893e-01) 
2023-05-25 01:01:37.791589: train Epoch: [10][150/193]	Time  1.177 ( 1.411)	Data  0.001 ( 0.292)	Loss 1.0936e-01 (1.4867e-01) 
2023-05-25 01:01:39.323749: train Epoch: [10][151/193]	Time  1.532 ( 1.412)	Data  0.461 ( 0.293)	Loss 1.1207e-01 (1.4842e-01) 
2023-05-25 01:01:40.539228: train Epoch: [10][152/193]	Time  1.215 ( 1.411)	Data  0.001 ( 0.291)	Loss 1.5877e-01 (1.4849e-01) 
2023-05-25 01:01:42.028732: train Epoch: [10][153/193]	Time  1.490 ( 1.411)	Data  0.291 ( 0.291)	Loss 1.1895e-01 (1.4830e-01) 
2023-05-25 01:01:43.275259: train Epoch: [10][154/193]	Time  1.247 ( 1.410)	Data  0.001 ( 0.290)	Loss 1.0162e-01 (1.4800e-01) 
2023-05-25 01:01:44.680500: train Epoch: [10][155/193]	Time  1.405 ( 1.410)	Data  0.260 ( 0.289)	Loss 1.1629e-01 (1.4780e-01) 
2023-05-25 01:01:45.784407: train Epoch: [10][156/193]	Time  1.104 ( 1.408)	Data  0.001 ( 0.288)	Loss 1.2144e-01 (1.4763e-01) 
2023-05-25 01:01:47.525023: train Epoch: [10][157/193]	Time  1.741 ( 1.411)	Data  0.427 ( 0.288)	Loss 1.5467e-01 (1.4767e-01) 
2023-05-25 01:01:48.572204: train Epoch: [10][158/193]	Time  1.047 ( 1.408)	Data  0.001 ( 0.287)	Loss 7.3624e-02 (1.4721e-01) 
2023-05-25 01:01:50.101871: train Epoch: [10][159/193]	Time  1.530 ( 1.409)	Data  0.311 ( 0.287)	Loss 2.2455e-01 (1.4769e-01) 
2023-05-25 01:01:51.068352: train Epoch: [10][160/193]	Time  0.967 ( 1.406)	Data  0.001 ( 0.285)	Loss 8.6051e-02 (1.4731e-01) 
2023-05-25 01:01:52.954534: train Epoch: [10][161/193]	Time  1.886 ( 1.409)	Data  0.607 ( 0.287)	Loss 1.8077e-01 (1.4751e-01) 
2023-05-25 01:01:54.011712: train Epoch: [10][162/193]	Time  1.057 ( 1.407)	Data  0.001 ( 0.285)	Loss 1.4482e-01 (1.4750e-01) 
2023-05-25 01:01:55.702161: train Epoch: [10][163/193]	Time  1.690 ( 1.409)	Data  0.494 ( 0.287)	Loss 1.2348e-01 (1.4735e-01) 
2023-05-25 01:01:56.883545: train Epoch: [10][164/193]	Time  1.181 ( 1.407)	Data  0.001 ( 0.285)	Loss 1.5483e-01 (1.4740e-01) 
2023-05-25 01:01:58.495585: train Epoch: [10][165/193]	Time  1.612 ( 1.409)	Data  0.481 ( 0.286)	Loss 7.0615e-02 (1.4693e-01) 
2023-05-25 01:01:59.684029: train Epoch: [10][166/193]	Time  1.188 ( 1.407)	Data  0.001 ( 0.284)	Loss 3.9150e-01 (1.4840e-01) 
2023-05-25 01:02:01.282245: train Epoch: [10][167/193]	Time  1.598 ( 1.408)	Data  0.531 ( 0.286)	Loss 1.2800e-01 (1.4828e-01) 
2023-05-25 01:02:02.241930: train Epoch: [10][168/193]	Time  0.960 ( 1.406)	Data  0.001 ( 0.284)	Loss 9.7675e-02 (1.4798e-01) 
2023-05-25 01:02:03.897491: train Epoch: [10][169/193]	Time  1.656 ( 1.407)	Data  0.721 ( 0.287)	Loss 1.2931e-01 (1.4787e-01) 
2023-05-25 01:02:04.916591: train Epoch: [10][170/193]	Time  1.019 ( 1.405)	Data  0.010 ( 0.285)	Loss 9.4265e-02 (1.4755e-01) 
2023-05-25 01:02:06.885570: train Epoch: [10][171/193]	Time  1.969 ( 1.408)	Data  0.893 ( 0.289)	Loss 1.3542e-01 (1.4748e-01) 
2023-05-25 01:02:07.891205: train Epoch: [10][172/193]	Time  1.006 ( 1.406)	Data  0.001 ( 0.287)	Loss 1.5198e-01 (1.4751e-01) 
2023-05-25 01:02:09.929327: train Epoch: [10][173/193]	Time  2.038 ( 1.410)	Data  0.670 ( 0.289)	Loss 2.0102e-01 (1.4782e-01) 
2023-05-25 01:02:11.037357: train Epoch: [10][174/193]	Time  1.108 ( 1.408)	Data  0.001 ( 0.287)	Loss 1.4577e-01 (1.4781e-01) 
2023-05-25 01:02:12.424557: train Epoch: [10][175/193]	Time  1.387 ( 1.408)	Data  0.179 ( 0.287)	Loss 2.9212e-01 (1.4863e-01) 
2023-05-25 01:02:13.509185: train Epoch: [10][176/193]	Time  1.085 ( 1.406)	Data  0.001 ( 0.285)	Loss 2.0629e-01 (1.4895e-01) 
2023-05-25 01:02:15.145204: train Epoch: [10][177/193]	Time  1.636 ( 1.407)	Data  0.422 ( 0.286)	Loss 1.6179e-01 (1.4902e-01) 
2023-05-25 01:02:16.257364: train Epoch: [10][178/193]	Time  1.112 ( 1.406)	Data  0.001 ( 0.284)	Loss 1.3426e-01 (1.4894e-01) 
2023-05-25 01:02:17.836028: train Epoch: [10][179/193]	Time  1.579 ( 1.407)	Data  0.465 ( 0.285)	Loss 9.3338e-02 (1.4863e-01) 
2023-05-25 01:02:19.061932: train Epoch: [10][180/193]	Time  1.226 ( 1.406)	Data  0.001 ( 0.284)	Loss 1.7682e-01 (1.4879e-01) 
2023-05-25 01:02:20.553074: train Epoch: [10][181/193]	Time  1.491 ( 1.406)	Data  0.352 ( 0.284)	Loss 1.9646e-01 (1.4905e-01) 
2023-05-25 01:02:21.789197: train Epoch: [10][182/193]	Time  1.236 ( 1.405)	Data  0.001 ( 0.283)	Loss 2.1380e-01 (1.4940e-01) 
2023-05-25 01:02:23.244689: train Epoch: [10][183/193]	Time  1.456 ( 1.405)	Data  0.439 ( 0.284)	Loss 2.2473e-01 (1.4981e-01) 
2023-05-25 01:02:24.341484: train Epoch: [10][184/193]	Time  1.097 ( 1.404)	Data  0.001 ( 0.282)	Loss 1.2134e-01 (1.4966e-01) 
2023-05-25 01:02:26.163036: train Epoch: [10][185/193]	Time  1.822 ( 1.406)	Data  0.730 ( 0.284)	Loss 1.6782e-01 (1.4976e-01) 
2023-05-25 01:02:27.309449: train Epoch: [10][186/193]	Time  1.146 ( 1.405)	Data  0.001 ( 0.283)	Loss 1.3383e-01 (1.4967e-01) 
2023-05-25 01:02:28.995706: train Epoch: [10][187/193]	Time  1.686 ( 1.406)	Data  0.470 ( 0.284)	Loss 9.0823e-02 (1.4936e-01) 
2023-05-25 01:02:29.998435: train Epoch: [10][188/193]	Time  1.003 ( 1.404)	Data  0.001 ( 0.282)	Loss 2.5798e-01 (1.4993e-01) 
2023-05-25 01:02:31.692144: train Epoch: [10][189/193]	Time  1.694 ( 1.405)	Data  0.409 ( 0.283)	Loss 1.7781e-01 (1.5008e-01) 
2023-05-25 01:02:32.669053: train Epoch: [10][190/193]	Time  0.977 ( 1.403)	Data  0.001 ( 0.282)	Loss 1.2653e-01 (1.4996e-01) 
2023-05-25 01:02:34.467645: train Epoch: [10][191/193]	Time  1.799 ( 1.405)	Data  0.460 ( 0.283)	Loss 1.4724e-01 (1.4994e-01) 
2023-05-25 01:02:35.434161: train Epoch: [10][192/193]	Time  0.966 ( 1.403)	Data  0.001 ( 0.281)	Loss 1.5161e-01 (1.4995e-01) 
2023-05-25 01:02:35.498584: Train Epoch done in 270.83656198799144 s 
2023-05-25 01:02:38.886220: val Epoch: [10][ 0/72]	Time  2.240 ( 2.240)	Data  1.739 ( 1.739)	Loss 1.7951e-01 (1.7951e-01) 
2023-05-25 01:02:39.414001: val Epoch: [10][ 1/72]	Time  0.528 ( 1.384)	Data  0.002 ( 0.870)	Loss 1.2731e-01 (1.5341e-01) 
2023-05-25 01:02:39.981061: val Epoch: [10][ 2/72]	Time  0.567 ( 1.112)	Data  0.326 ( 0.689)	Loss 4.7497e-01 (2.6060e-01) 
2023-05-25 01:02:40.241627: val Epoch: [10][ 3/72]	Time  0.261 ( 0.899)	Data  0.001 ( 0.517)	Loss 1.4276e-01 (2.3114e-01) 
2023-05-25 01:02:41.547157: val Epoch: [10][ 4/72]	Time  1.306 ( 0.980)	Data  0.915 ( 0.597)	Loss 1.6325e-01 (2.1756e-01) 
2023-05-25 01:02:42.055322: val Epoch: [10][ 5/72]	Time  0.508 ( 0.902)	Data  0.001 ( 0.497)	Loss 6.5067e-02 (1.9214e-01) 
2023-05-25 01:02:43.029841: val Epoch: [10][ 6/72]	Time  0.975 ( 0.912)	Data  0.456 ( 0.491)	Loss 1.2368e-01 (1.8236e-01) 
2023-05-25 01:02:43.378558: val Epoch: [10][ 7/72]	Time  0.349 ( 0.842)	Data  0.001 ( 0.430)	Loss 2.3356e-01 (1.8876e-01) 
2023-05-25 01:02:44.287051: val Epoch: [10][ 8/72]	Time  0.908 ( 0.849)	Data  0.508 ( 0.439)	Loss 2.2670e-01 (1.9298e-01) 
2023-05-25 01:02:44.595770: val Epoch: [10][ 9/72]	Time  0.309 ( 0.795)	Data  0.001 ( 0.395)	Loss 7.8461e-02 (1.8153e-01) 
2023-05-25 01:02:45.568156: val Epoch: [10][10/72]	Time  0.972 ( 0.811)	Data  0.683 ( 0.421)	Loss 1.3354e-01 (1.7716e-01) 
2023-05-25 01:02:45.876167: val Epoch: [10][11/72]	Time  0.308 ( 0.769)	Data  0.001 ( 0.386)	Loss 7.1524e-02 (1.6836e-01) 
2023-05-25 01:02:46.851728: val Epoch: [10][12/72]	Time  0.976 ( 0.785)	Data  0.788 ( 0.417)	Loss 3.6374e-01 (1.8339e-01) 
2023-05-25 01:02:47.193447: val Epoch: [10][13/72]	Time  0.342 ( 0.753)	Data  0.105 ( 0.395)	Loss 4.3977e-01 (2.0170e-01) 
2023-05-25 01:02:48.233295: val Epoch: [10][14/72]	Time  1.040 ( 0.772)	Data  0.799 ( 0.422)	Loss 8.9179e-02 (1.9420e-01) 
2023-05-25 01:02:48.783738: val Epoch: [10][15/72]	Time  0.550 ( 0.759)	Data  0.164 ( 0.406)	Loss 2.2268e-01 (1.9598e-01) 
2023-05-25 01:02:49.703374: val Epoch: [10][16/72]	Time  0.920 ( 0.768)	Data  0.621 ( 0.418)	Loss 7.9314e-02 (1.8912e-01) 
2023-05-25 01:02:50.166528: val Epoch: [10][17/72]	Time  0.463 ( 0.751)	Data  0.194 ( 0.406)	Loss 2.4648e-01 (1.9231e-01) 
2023-05-25 01:02:50.976794: val Epoch: [10][18/72]	Time  0.810 ( 0.754)	Data  0.580 ( 0.415)	Loss 8.7039e-02 (1.8677e-01) 
2023-05-25 01:02:51.655070: val Epoch: [10][19/72]	Time  0.678 ( 0.750)	Data  0.353 ( 0.412)	Loss 1.0046e-01 (1.8245e-01) 
2023-05-25 01:02:52.526006: val Epoch: [10][20/72]	Time  0.871 ( 0.756)	Data  0.487 ( 0.415)	Loss 1.8404e-01 (1.8253e-01) 
2023-05-25 01:02:53.301339: val Epoch: [10][21/72]	Time  0.775 ( 0.757)	Data  0.304 ( 0.410)	Loss 4.6298e-01 (1.9527e-01) 
2023-05-25 01:02:53.878498: val Epoch: [10][22/72]	Time  0.577 ( 0.749)	Data  0.203 ( 0.401)	Loss 1.0041e-01 (1.9115e-01) 
2023-05-25 01:02:54.680265: val Epoch: [10][23/72]	Time  0.802 ( 0.751)	Data  0.447 ( 0.403)	Loss 1.6900e-01 (1.9023e-01) 
2023-05-25 01:02:55.138473: val Epoch: [10][24/72]	Time  0.458 ( 0.740)	Data  0.102 ( 0.391)	Loss 2.0813e-01 (1.9094e-01) 
2023-05-25 01:02:56.292506: val Epoch: [10][25/72]	Time  1.154 ( 0.756)	Data  0.763 ( 0.406)	Loss 2.0484e-01 (1.9148e-01) 
2023-05-25 01:02:56.647841: val Epoch: [10][26/72]	Time  0.355 ( 0.741)	Data  0.001 ( 0.391)	Loss 8.0850e-02 (1.8738e-01) 
2023-05-25 01:02:57.558142: val Epoch: [10][27/72]	Time  0.910 ( 0.747)	Data  0.699 ( 0.402)	Loss 9.8166e-02 (1.8419e-01) 
2023-05-25 01:02:57.956318: val Epoch: [10][28/72]	Time  0.398 ( 0.735)	Data  0.073 ( 0.390)	Loss 9.4897e-02 (1.8111e-01) 
2023-05-25 01:02:59.271848: val Epoch: [10][29/72]	Time  1.316 ( 0.754)	Data  0.879 ( 0.407)	Loss 6.0593e-02 (1.7710e-01) 
2023-05-25 01:02:59.661643: val Epoch: [10][30/72]	Time  0.390 ( 0.742)	Data  0.001 ( 0.393)	Loss 1.9946e-01 (1.7782e-01) 
2023-05-25 01:03:00.734469: val Epoch: [10][31/72]	Time  1.073 ( 0.753)	Data  0.662 ( 0.402)	Loss 1.9695e-01 (1.7842e-01) 
2023-05-25 01:03:01.222736: val Epoch: [10][32/72]	Time  0.488 ( 0.745)	Data  0.001 ( 0.390)	Loss 1.0823e-01 (1.7629e-01) 
2023-05-25 01:03:02.322388: val Epoch: [10][33/72]	Time  1.100 ( 0.755)	Data  0.685 ( 0.398)	Loss 1.3962e-01 (1.7521e-01) 
2023-05-25 01:03:02.693298: val Epoch: [10][34/72]	Time  0.371 ( 0.744)	Data  0.001 ( 0.387)	Loss 1.7402e-01 (1.7518e-01) 
2023-05-25 01:03:03.975065: val Epoch: [10][35/72]	Time  1.282 ( 0.759)	Data  0.755 ( 0.397)	Loss 1.3371e-01 (1.7403e-01) 
2023-05-25 01:03:04.261750: val Epoch: [10][36/72]	Time  0.287 ( 0.746)	Data  0.001 ( 0.387)	Loss 3.5644e-01 (1.7896e-01) 
2023-05-25 01:03:05.320585: val Epoch: [10][37/72]	Time  1.059 ( 0.755)	Data  0.701 ( 0.395)	Loss 3.5103e-01 (1.8348e-01) 
2023-05-25 01:03:05.647409: val Epoch: [10][38/72]	Time  0.327 ( 0.744)	Data  0.001 ( 0.385)	Loss 1.7476e-01 (1.8326e-01) 
2023-05-25 01:03:06.790128: val Epoch: [10][39/72]	Time  1.143 ( 0.754)	Data  0.756 ( 0.394)	Loss 1.2348e-01 (1.8177e-01) 
2023-05-25 01:03:07.308066: val Epoch: [10][40/72]	Time  0.518 ( 0.748)	Data  0.001 ( 0.384)	Loss 1.4402e-01 (1.8085e-01) 
2023-05-25 01:03:08.240462: val Epoch: [10][41/72]	Time  0.932 ( 0.752)	Data  0.686 ( 0.392)	Loss 4.3232e-01 (1.8683e-01) 
2023-05-25 01:03:08.666254: val Epoch: [10][42/72]	Time  0.426 ( 0.745)	Data  0.001 ( 0.383)	Loss 1.0421e-01 (1.8491e-01) 
2023-05-25 01:03:09.711716: val Epoch: [10][43/72]	Time  1.045 ( 0.751)	Data  0.809 ( 0.392)	Loss 1.2143e-01 (1.8347e-01) 
2023-05-25 01:03:09.998111: val Epoch: [10][44/72]	Time  0.286 ( 0.741)	Data  0.001 ( 0.384)	Loss 6.4899e-02 (1.8083e-01) 
2023-05-25 01:03:11.398997: val Epoch: [10][45/72]	Time  1.401 ( 0.755)	Data  0.999 ( 0.397)	Loss 8.7494e-02 (1.7880e-01) 
2023-05-25 01:03:11.892722: val Epoch: [10][46/72]	Time  0.494 ( 0.750)	Data  0.006 ( 0.389)	Loss 1.5191e-01 (1.7823e-01) 
2023-05-25 01:03:12.670829: val Epoch: [10][47/72]	Time  0.778 ( 0.751)	Data  0.585 ( 0.393)	Loss 4.3110e-01 (1.8350e-01) 
2023-05-25 01:03:12.920163: val Epoch: [10][48/72]	Time  0.249 ( 0.740)	Data  0.001 ( 0.385)	Loss 7.7703e-02 (1.8134e-01) 
2023-05-25 01:03:14.220073: val Epoch: [10][49/72]	Time  1.300 ( 0.751)	Data  0.967 ( 0.396)	Loss 2.5785e-01 (1.8287e-01) 
2023-05-25 01:03:14.756421: val Epoch: [10][50/72]	Time  0.536 ( 0.747)	Data  0.018 ( 0.389)	Loss 9.2652e-02 (1.8110e-01) 
2023-05-25 01:03:15.725228: val Epoch: [10][51/72]	Time  0.969 ( 0.752)	Data  0.646 ( 0.394)	Loss 1.9131e-01 (1.8130e-01) 
2023-05-25 01:03:15.905740: val Epoch: [10][52/72]	Time  0.181 ( 0.741)	Data  0.001 ( 0.386)	Loss 8.4260e-02 (1.7947e-01) 
2023-05-25 01:03:17.009663: val Epoch: [10][53/72]	Time  1.104 ( 0.747)	Data  0.833 ( 0.395)	Loss 3.3864e-01 (1.8242e-01) 
2023-05-25 01:03:17.417277: val Epoch: [10][54/72]	Time  0.408 ( 0.741)	Data  0.001 ( 0.388)	Loss 1.9801e-01 (1.8270e-01) 
2023-05-25 01:03:18.310746: val Epoch: [10][55/72]	Time  0.893 ( 0.744)	Data  0.609 ( 0.392)	Loss 2.6236e-01 (1.8412e-01) 
2023-05-25 01:03:18.689227: val Epoch: [10][56/72]	Time  0.378 ( 0.738)	Data  0.001 ( 0.385)	Loss 8.6530e-02 (1.8241e-01) 
2023-05-25 01:03:19.552609: val Epoch: [10][57/72]	Time  0.863 ( 0.740)	Data  0.629 ( 0.389)	Loss 2.3903e-01 (1.8339e-01) 
2023-05-25 01:03:19.874496: val Epoch: [10][58/72]	Time  0.322 ( 0.733)	Data  0.001 ( 0.382)	Loss 1.3727e-01 (1.8260e-01) 
2023-05-25 01:03:20.914723: val Epoch: [10][59/72]	Time  1.040 ( 0.738)	Data  0.766 ( 0.389)	Loss 1.3015e-01 (1.8173e-01) 
2023-05-25 01:03:21.160824: val Epoch: [10][60/72]	Time  0.246 ( 0.730)	Data  0.002 ( 0.382)	Loss 3.1260e-01 (1.8388e-01) 
2023-05-25 01:03:22.460579: val Epoch: [10][61/72]	Time  1.300 ( 0.739)	Data  0.891 ( 0.391)	Loss 3.7441e-01 (1.8695e-01) 
2023-05-25 01:03:22.808026: val Epoch: [10][62/72]	Time  0.347 ( 0.733)	Data  0.001 ( 0.384)	Loss 5.8867e-01 (1.9332e-01) 
2023-05-25 01:03:23.791878: val Epoch: [10][63/72]	Time  0.984 ( 0.737)	Data  0.587 ( 0.388)	Loss 9.1633e-02 (1.9174e-01) 
2023-05-25 01:03:24.111285: val Epoch: [10][64/72]	Time  0.319 ( 0.730)	Data  0.001 ( 0.382)	Loss 1.5263e-01 (1.9113e-01) 
2023-05-25 01:03:25.267648: val Epoch: [10][65/72]	Time  1.156 ( 0.737)	Data  0.726 ( 0.387)	Loss 5.0776e-01 (1.9593e-01) 
2023-05-25 01:03:25.644591: val Epoch: [10][66/72]	Time  0.377 ( 0.731)	Data  0.001 ( 0.381)	Loss 2.7771e-01 (1.9715e-01) 
2023-05-25 01:03:26.684813: val Epoch: [10][67/72]	Time  1.040 ( 0.736)	Data  0.546 ( 0.383)	Loss 8.0468e-02 (1.9544e-01) 
2023-05-25 01:03:26.888298: val Epoch: [10][68/72]	Time  0.203 ( 0.728)	Data  0.001 ( 0.378)	Loss 1.0691e-01 (1.9415e-01) 
2023-05-25 01:03:27.890848: val Epoch: [10][69/72]	Time  1.003 ( 0.732)	Data  0.644 ( 0.382)	Loss 1.7048e-01 (1.9382e-01) 
2023-05-25 01:03:28.315286: val Epoch: [10][70/72]	Time  0.424 ( 0.728)	Data  0.001 ( 0.376)	Loss 8.7632e-02 (1.9232e-01) 
2023-05-25 01:03:29.170637: val Epoch: [10][71/72]	Time  0.855 ( 0.729)	Data  0.384 ( 0.377)	Loss 1.3534e-01 (1.9153e-01) 
2023-05-25 01:03:29.423033: Epoch 10 :Val : ['ET : 0.6117498874664307', 'TC : 0.6880789995193481', 'WT : 0.8134366273880005'] 
2023-05-25 01:03:29.427974: Epoch 10 :Val : ['ET : 0.6117498874664307', 'TC : 0.6880789995193481', 'WT : 0.8134366273880005'] 
2023-05-25 01:03:29.430526: Val epoch done in 53.9319522830192 s 
2023-05-25 01:03:29.440526: Batches per epoch:  193 
2023-05-25 01:03:33.905367: train Epoch: [11][  0/193]	Time  4.464 ( 4.464)	Data  3.151 ( 3.151)	Loss 1.0296e-01 (1.0296e-01) 
2023-05-25 01:03:34.972281: train Epoch: [11][  1/193]	Time  1.067 ( 2.766)	Data  0.001 ( 1.576)	Loss 1.2429e-01 (1.1363e-01) 
2023-05-25 01:03:36.371960: train Epoch: [11][  2/193]	Time  1.400 ( 2.310)	Data  0.402 ( 1.184)	Loss 2.8202e-01 (1.6976e-01) 
2023-05-25 01:03:37.361547: train Epoch: [11][  3/193]	Time  0.990 ( 1.980)	Data  0.001 ( 0.889)	Loss 1.4666e-01 (1.6398e-01) 
2023-05-25 01:03:39.150749: train Epoch: [11][  4/193]	Time  1.789 ( 1.942)	Data  0.733 ( 0.858)	Loss 7.6868e-02 (1.4656e-01) 
2023-05-25 01:03:40.216699: train Epoch: [11][  5/193]	Time  1.066 ( 1.796)	Data  0.001 ( 0.715)	Loss 2.1711e-01 (1.5832e-01) 
2023-05-25 01:03:42.439070: train Epoch: [11][  6/193]	Time  2.222 ( 1.857)	Data  0.673 ( 0.709)	Loss 1.2194e-01 (1.5312e-01) 
2023-05-25 01:03:43.455908: train Epoch: [11][  7/193]	Time  1.017 ( 1.752)	Data  0.001 ( 0.620)	Loss 1.1576e-01 (1.4845e-01) 
2023-05-25 01:03:44.717520: train Epoch: [11][  8/193]	Time  1.262 ( 1.697)	Data  0.231 ( 0.577)	Loss 1.7620e-01 (1.5154e-01) 
2023-05-25 01:03:45.962254: train Epoch: [11][  9/193]	Time  1.245 ( 1.652)	Data  0.001 ( 0.519)	Loss 2.8300e-01 (1.6468e-01) 
2023-05-25 01:03:47.760589: train Epoch: [11][ 10/193]	Time  1.798 ( 1.665)	Data  0.486 ( 0.516)	Loss 1.5337e-01 (1.6365e-01) 
2023-05-25 01:03:48.983974: train Epoch: [11][ 11/193]	Time  1.223 ( 1.629)	Data  0.001 ( 0.474)	Loss 1.9119e-01 (1.6595e-01) 
2023-05-25 01:03:50.084161: train Epoch: [11][ 12/193]	Time  1.100 ( 1.588)	Data  0.195 ( 0.452)	Loss 1.2544e-01 (1.6283e-01) 
2023-05-25 01:03:51.037715: train Epoch: [11][ 13/193]	Time  0.954 ( 1.543)	Data  0.001 ( 0.420)	Loss 1.1158e-01 (1.5917e-01) 
2023-05-25 01:03:52.918857: train Epoch: [11][ 14/193]	Time  1.881 ( 1.565)	Data  0.929 ( 0.454)	Loss 1.0136e-01 (1.5532e-01) 
2023-05-25 01:03:53.850075: train Epoch: [11][ 15/193]	Time  0.931 ( 1.526)	Data  0.001 ( 0.426)	Loss 9.8593e-02 (1.5177e-01) 
2023-05-25 01:03:56.011422: train Epoch: [11][ 16/193]	Time  2.161 ( 1.563)	Data  0.890 ( 0.453)	Loss 1.8040e-01 (1.5345e-01) 
2023-05-25 01:03:57.044746: train Epoch: [11][ 17/193]	Time  1.033 ( 1.534)	Data  0.001 ( 0.428)	Loss 1.5488e-01 (1.5353e-01) 
2023-05-25 01:03:58.902040: train Epoch: [11][ 18/193]	Time  1.857 ( 1.551)	Data  0.555 ( 0.434)	Loss 1.6102e-01 (1.5393e-01) 
2023-05-25 01:03:59.977514: train Epoch: [11][ 19/193]	Time  1.075 ( 1.527)	Data  0.001 ( 0.413)	Loss 2.0778e-01 (1.5662e-01) 
2023-05-25 01:04:01.467075: train Epoch: [11][ 20/193]	Time  1.490 ( 1.525)	Data  0.298 ( 0.407)	Loss 1.4287e-01 (1.5597e-01) 
2023-05-25 01:04:02.483211: train Epoch: [11][ 21/193]	Time  1.016 ( 1.502)	Data  0.001 ( 0.389)	Loss 1.2355e-01 (1.5449e-01) 
2023-05-25 01:04:04.354049: train Epoch: [11][ 22/193]	Time  1.871 ( 1.518)	Data  0.497 ( 0.394)	Loss 1.4019e-01 (1.5387e-01) 
2023-05-25 01:04:05.341909: train Epoch: [11][ 23/193]	Time  0.988 ( 1.496)	Data  0.001 ( 0.377)	Loss 6.7979e-02 (1.5029e-01) 
2023-05-25 01:04:06.728693: train Epoch: [11][ 24/193]	Time  1.387 ( 1.491)	Data  0.386 ( 0.378)	Loss 8.8239e-02 (1.4781e-01) 
2023-05-25 01:04:07.824864: train Epoch: [11][ 25/193]	Time  1.096 ( 1.476)	Data  0.001 ( 0.363)	Loss 1.4510e-01 (1.4771e-01) 
2023-05-25 01:04:09.547766: train Epoch: [11][ 26/193]	Time  1.723 ( 1.485)	Data  0.648 ( 0.374)	Loss 1.4787e-01 (1.4771e-01) 
2023-05-25 01:04:10.726571: train Epoch: [11][ 27/193]	Time  1.179 ( 1.474)	Data  0.002 ( 0.360)	Loss 1.2993e-01 (1.4708e-01) 
2023-05-25 01:04:12.179574: train Epoch: [11][ 28/193]	Time  1.453 ( 1.474)	Data  0.417 ( 0.362)	Loss 8.5270e-02 (1.4495e-01) 
2023-05-25 01:04:13.264943: train Epoch: [11][ 29/193]	Time  1.085 ( 1.461)	Data  0.001 ( 0.350)	Loss 8.3156e-02 (1.4289e-01) 
2023-05-25 01:04:14.887507: train Epoch: [11][ 30/193]	Time  1.623 ( 1.466)	Data  0.540 ( 0.356)	Loss 1.4824e-01 (1.4306e-01) 
2023-05-25 01:04:16.037592: train Epoch: [11][ 31/193]	Time  1.150 ( 1.456)	Data  0.001 ( 0.345)	Loss 1.4372e-01 (1.4308e-01) 
2023-05-25 01:04:17.624285: train Epoch: [11][ 32/193]	Time  1.587 ( 1.460)	Data  0.529 ( 0.351)	Loss 7.5617e-02 (1.4103e-01) 
2023-05-25 01:04:18.624534: train Epoch: [11][ 33/193]	Time  1.000 ( 1.447)	Data  0.013 ( 0.341)	Loss 2.0777e-01 (1.4300e-01) 
2023-05-25 01:04:20.591632: train Epoch: [11][ 34/193]	Time  1.967 ( 1.461)	Data  0.596 ( 0.348)	Loss 1.0251e-01 (1.4184e-01) 
2023-05-25 01:04:21.614177: train Epoch: [11][ 35/193]	Time  1.023 ( 1.449)	Data  0.001 ( 0.339)	Loss 9.5796e-02 (1.4056e-01) 
2023-05-25 01:04:23.197814: train Epoch: [11][ 36/193]	Time  1.584 ( 1.453)	Data  0.293 ( 0.337)	Loss 1.5694e-01 (1.4100e-01) 
2023-05-25 01:04:24.195848: train Epoch: [11][ 37/193]	Time  0.998 ( 1.441)	Data  0.044 ( 0.330)	Loss 8.3200e-02 (1.3948e-01) 
2023-05-25 01:04:25.966902: train Epoch: [11][ 38/193]	Time  1.771 ( 1.449)	Data  0.420 ( 0.332)	Loss 1.3049e-01 (1.3925e-01) 
2023-05-25 01:04:27.162423: train Epoch: [11][ 39/193]	Time  1.195 ( 1.443)	Data  0.192 ( 0.328)	Loss 7.4184e-02 (1.3763e-01) 
2023-05-25 01:04:28.338069: train Epoch: [11][ 40/193]	Time  1.176 ( 1.437)	Data  0.141 ( 0.324)	Loss 9.4265e-02 (1.3657e-01) 
2023-05-25 01:04:30.127011: train Epoch: [11][ 41/193]	Time  1.789 ( 1.445)	Data  0.634 ( 0.331)	Loss 1.5873e-01 (1.3710e-01) 
2023-05-25 01:04:31.245159: train Epoch: [11][ 42/193]	Time  1.118 ( 1.437)	Data  0.001 ( 0.324)	Loss 1.6521e-01 (1.3775e-01) 
2023-05-25 01:04:33.129201: train Epoch: [11][ 43/193]	Time  1.884 ( 1.447)	Data  0.517 ( 0.328)	Loss 1.6421e-01 (1.3835e-01) 
2023-05-25 01:04:34.166955: train Epoch: [11][ 44/193]	Time  1.038 ( 1.438)	Data  0.001 ( 0.321)	Loss 1.3357e-01 (1.3824e-01) 
2023-05-25 01:04:35.703775: train Epoch: [11][ 45/193]	Time  1.537 ( 1.440)	Data  0.415 ( 0.323)	Loss 1.3081e-01 (1.3808e-01) 
2023-05-25 01:04:36.789114: train Epoch: [11][ 46/193]	Time  1.085 ( 1.433)	Data  0.001 ( 0.316)	Loss 9.2865e-02 (1.3712e-01) 
2023-05-25 01:04:38.545541: train Epoch: [11][ 47/193]	Time  1.756 ( 1.440)	Data  0.534 ( 0.320)	Loss 1.1483e-01 (1.3666e-01) 
2023-05-25 01:04:39.746326: train Epoch: [11][ 48/193]	Time  1.201 ( 1.435)	Data  0.001 ( 0.314)	Loss 1.2091e-01 (1.3634e-01) 
2023-05-25 01:04:41.073522: train Epoch: [11][ 49/193]	Time  1.327 ( 1.433)	Data  0.244 ( 0.313)	Loss 9.8749e-02 (1.3558e-01) 
2023-05-25 01:04:42.345936: train Epoch: [11][ 50/193]	Time  1.272 ( 1.430)	Data  0.001 ( 0.306)	Loss 7.7997e-02 (1.3445e-01) 
2023-05-25 01:04:43.882907: train Epoch: [11][ 51/193]	Time  1.537 ( 1.432)	Data  0.465 ( 0.309)	Loss 1.5321e-01 (1.3482e-01) 
2023-05-25 01:04:45.138863: train Epoch: [11][ 52/193]	Time  1.256 ( 1.428)	Data  0.001 ( 0.304)	Loss 1.2424e-01 (1.3462e-01) 
2023-05-25 01:04:46.771749: train Epoch: [11][ 53/193]	Time  1.633 ( 1.432)	Data  0.437 ( 0.306)	Loss 1.1555e-01 (1.3426e-01) 
2023-05-25 01:04:48.089642: train Epoch: [11][ 54/193]	Time  1.318 ( 1.430)	Data  0.001 ( 0.301)	Loss 1.4343e-01 (1.3443e-01) 
2023-05-25 01:04:49.310946: train Epoch: [11][ 55/193]	Time  1.221 ( 1.426)	Data  0.218 ( 0.299)	Loss 1.4634e-01 (1.3464e-01) 
2023-05-25 01:04:50.433551: train Epoch: [11][ 56/193]	Time  1.123 ( 1.421)	Data  0.090 ( 0.295)	Loss 9.6069e-02 (1.3397e-01) 
2023-05-25 01:04:52.093508: train Epoch: [11][ 57/193]	Time  1.660 ( 1.425)	Data  0.576 ( 0.300)	Loss 1.5146e-01 (1.3427e-01) 
2023-05-25 01:04:53.312267: train Epoch: [11][ 58/193]	Time  1.219 ( 1.422)	Data  0.157 ( 0.298)	Loss 1.2561e-01 (1.3412e-01) 
2023-05-25 01:04:55.164665: train Epoch: [11][ 59/193]	Time  1.852 ( 1.429)	Data  0.520 ( 0.302)	Loss 1.0221e-01 (1.3359e-01) 
2023-05-25 01:04:56.261268: train Epoch: [11][ 60/193]	Time  1.097 ( 1.423)	Data  0.001 ( 0.297)	Loss 7.3305e-02 (1.3260e-01) 
2023-05-25 01:04:57.903949: train Epoch: [11][ 61/193]	Time  1.643 ( 1.427)	Data  0.242 ( 0.296)	Loss 1.4502e-01 (1.3280e-01) 
2023-05-25 01:04:58.927949: train Epoch: [11][ 62/193]	Time  1.024 ( 1.420)	Data  0.001 ( 0.291)	Loss 1.0636e-01 (1.3238e-01) 
2023-05-25 01:05:00.323002: train Epoch: [11][ 63/193]	Time  1.395 ( 1.420)	Data  0.282 ( 0.291)	Loss 9.5730e-02 (1.3181e-01) 
2023-05-25 01:05:01.480486: train Epoch: [11][ 64/193]	Time  1.157 ( 1.416)	Data  0.116 ( 0.288)	Loss 1.1024e-01 (1.3148e-01) 
2023-05-25 01:05:03.104677: train Epoch: [11][ 65/193]	Time  1.624 ( 1.419)	Data  0.477 ( 0.291)	Loss 1.0830e-01 (1.3112e-01) 
2023-05-25 01:05:04.351641: train Epoch: [11][ 66/193]	Time  1.247 ( 1.417)	Data  0.077 ( 0.288)	Loss 1.1804e-01 (1.3093e-01) 
2023-05-25 01:05:05.929486: train Epoch: [11][ 67/193]	Time  1.578 ( 1.419)	Data  0.403 ( 0.290)	Loss 8.6741e-02 (1.3028e-01) 
2023-05-25 01:05:07.069098: train Epoch: [11][ 68/193]	Time  1.140 ( 1.415)	Data  0.001 ( 0.285)	Loss 1.7383e-01 (1.3091e-01) 
2023-05-25 01:05:08.638809: train Epoch: [11][ 69/193]	Time  1.570 ( 1.417)	Data  0.517 ( 0.289)	Loss 1.7777e-01 (1.3158e-01) 
2023-05-25 01:05:09.809012: train Epoch: [11][ 70/193]	Time  1.170 ( 1.414)	Data  0.001 ( 0.285)	Loss 1.1455e-01 (1.3134e-01) 
2023-05-25 01:05:11.467389: train Epoch: [11][ 71/193]	Time  1.658 ( 1.417)	Data  0.646 ( 0.290)	Loss 1.1647e-01 (1.3113e-01) 
2023-05-25 01:05:12.547884: train Epoch: [11][ 72/193]	Time  1.081 ( 1.412)	Data  0.001 ( 0.286)	Loss 1.2384e-01 (1.3103e-01) 
2023-05-25 01:05:14.331863: train Epoch: [11][ 73/193]	Time  1.784 ( 1.417)	Data  0.736 ( 0.292)	Loss 3.7146e-01 (1.3428e-01) 
2023-05-25 01:05:15.313840: train Epoch: [11][ 74/193]	Time  0.982 ( 1.412)	Data  0.001 ( 0.288)	Loss 9.3469e-02 (1.3374e-01) 
2023-05-25 01:05:17.306978: train Epoch: [11][ 75/193]	Time  1.993 ( 1.419)	Data  0.917 ( 0.296)	Loss 1.1614e-01 (1.3351e-01) 
2023-05-25 01:05:18.269945: train Epoch: [11][ 76/193]	Time  0.963 ( 1.413)	Data  0.001 ( 0.292)	Loss 9.3805e-02 (1.3299e-01) 
2023-05-25 01:05:20.088495: train Epoch: [11][ 77/193]	Time  1.819 ( 1.419)	Data  0.814 ( 0.299)	Loss 8.4120e-02 (1.3237e-01) 
2023-05-25 01:05:21.201512: train Epoch: [11][ 78/193]	Time  1.113 ( 1.415)	Data  0.001 ( 0.295)	Loss 1.0832e-01 (1.3206e-01) 
2023-05-25 01:05:23.164637: train Epoch: [11][ 79/193]	Time  1.963 ( 1.422)	Data  0.675 ( 0.300)	Loss 9.0323e-02 (1.3154e-01) 
2023-05-25 01:05:24.192090: train Epoch: [11][ 80/193]	Time  1.027 ( 1.417)	Data  0.001 ( 0.296)	Loss 1.1152e-01 (1.3129e-01) 
2023-05-25 01:05:25.704000: train Epoch: [11][ 81/193]	Time  1.512 ( 1.418)	Data  0.365 ( 0.297)	Loss 1.2031e-01 (1.3116e-01) 
2023-05-25 01:05:26.718268: train Epoch: [11][ 82/193]	Time  1.014 ( 1.413)	Data  0.001 ( 0.294)	Loss 9.7998e-02 (1.3076e-01) 
2023-05-25 01:05:28.524150: train Epoch: [11][ 83/193]	Time  1.806 ( 1.418)	Data  0.735 ( 0.299)	Loss 1.3357e-01 (1.3079e-01) 
2023-05-25 01:05:29.724707: train Epoch: [11][ 84/193]	Time  1.201 ( 1.415)	Data  0.001 ( 0.295)	Loss 6.1854e-02 (1.2998e-01) 
2023-05-25 01:05:31.251934: train Epoch: [11][ 85/193]	Time  1.527 ( 1.416)	Data  0.447 ( 0.297)	Loss 9.8496e-02 (1.2961e-01) 
2023-05-25 01:05:32.582666: train Epoch: [11][ 86/193]	Time  1.331 ( 1.415)	Data  0.001 ( 0.294)	Loss 1.6926e-01 (1.3007e-01) 
2023-05-25 01:05:33.838840: train Epoch: [11][ 87/193]	Time  1.256 ( 1.414)	Data  0.132 ( 0.292)	Loss 1.2885e-01 (1.3006e-01) 
2023-05-25 01:05:34.865133: train Epoch: [11][ 88/193]	Time  1.026 ( 1.409)	Data  0.001 ( 0.289)	Loss 1.0944e-01 (1.2982e-01) 
2023-05-25 01:05:36.460448: train Epoch: [11][ 89/193]	Time  1.595 ( 1.411)	Data  0.538 ( 0.291)	Loss 1.3500e-01 (1.2988e-01) 
2023-05-25 01:05:37.421926: train Epoch: [11][ 90/193]	Time  0.961 ( 1.406)	Data  0.001 ( 0.288)	Loss 1.8791e-01 (1.3052e-01) 
2023-05-25 01:05:39.248013: train Epoch: [11][ 91/193]	Time  1.826 ( 1.411)	Data  0.867 ( 0.294)	Loss 1.5807e-01 (1.3082e-01) 
2023-05-25 01:05:40.335888: train Epoch: [11][ 92/193]	Time  1.088 ( 1.407)	Data  0.001 ( 0.291)	Loss 1.9147e-01 (1.3147e-01) 
2023-05-25 01:05:42.183810: train Epoch: [11][ 93/193]	Time  1.848 ( 1.412)	Data  0.534 ( 0.294)	Loss 1.3078e-01 (1.3146e-01) 
2023-05-25 01:05:43.166709: train Epoch: [11][ 94/193]	Time  0.983 ( 1.408)	Data  0.001 ( 0.291)	Loss 2.5586e-01 (1.3277e-01) 
2023-05-25 01:05:44.643630: train Epoch: [11][ 95/193]	Time  1.477 ( 1.408)	Data  0.388 ( 0.292)	Loss 1.2835e-01 (1.3273e-01) 
2023-05-25 01:05:46.133631: train Epoch: [11][ 96/193]	Time  1.490 ( 1.409)	Data  0.374 ( 0.293)	Loss 2.6193e-01 (1.3406e-01) 
2023-05-25 01:05:47.336143: train Epoch: [11][ 97/193]	Time  1.203 ( 1.407)	Data  0.165 ( 0.291)	Loss 9.9452e-02 (1.3371e-01) 
2023-05-25 01:05:49.166604: train Epoch: [11][ 98/193]	Time  1.830 ( 1.411)	Data  0.608 ( 0.295)	Loss 1.3287e-01 (1.3370e-01) 
2023-05-25 01:05:50.163216: train Epoch: [11][ 99/193]	Time  0.997 ( 1.407)	Data  0.001 ( 0.292)	Loss 2.6273e-01 (1.3499e-01) 
2023-05-25 01:05:52.069085: train Epoch: [11][100/193]	Time  1.906 ( 1.412)	Data  0.594 ( 0.295)	Loss 1.0358e-01 (1.3468e-01) 
2023-05-25 01:05:53.085248: train Epoch: [11][101/193]	Time  1.016 ( 1.408)	Data  0.001 ( 0.292)	Loss 2.0021e-01 (1.3532e-01) 
2023-05-25 01:05:54.774746: train Epoch: [11][102/193]	Time  1.690 ( 1.411)	Data  0.426 ( 0.293)	Loss 1.1468e-01 (1.3512e-01) 
2023-05-25 01:05:55.831987: train Epoch: [11][103/193]	Time  1.057 ( 1.408)	Data  0.001 ( 0.290)	Loss 1.0987e-01 (1.3488e-01) 
2023-05-25 01:05:57.580654: train Epoch: [11][104/193]	Time  1.749 ( 1.411)	Data  0.481 ( 0.292)	Loss 4.3461e-02 (1.3401e-01) 
2023-05-25 01:05:58.604283: train Epoch: [11][105/193]	Time  1.024 ( 1.407)	Data  0.001 ( 0.289)	Loss 1.2431e-01 (1.3391e-01) 
2023-05-25 01:06:00.153900: train Epoch: [11][106/193]	Time  1.550 ( 1.409)	Data  0.497 ( 0.291)	Loss 1.1126e-01 (1.3370e-01) 
2023-05-25 01:06:01.188805: train Epoch: [11][107/193]	Time  1.035 ( 1.405)	Data  0.056 ( 0.289)	Loss 2.0742e-01 (1.3439e-01) 
2023-05-25 01:06:03.020813: train Epoch: [11][108/193]	Time  1.832 ( 1.409)	Data  0.747 ( 0.293)	Loss 1.0911e-01 (1.3415e-01) 
2023-05-25 01:06:04.115537: train Epoch: [11][109/193]	Time  1.095 ( 1.406)	Data  0.091 ( 0.291)	Loss 1.0381e-01 (1.3388e-01) 
2023-05-25 01:06:05.709286: train Epoch: [11][110/193]	Time  1.594 ( 1.408)	Data  0.549 ( 0.294)	Loss 1.1653e-01 (1.3372e-01) 
2023-05-25 01:06:06.930282: train Epoch: [11][111/193]	Time  1.221 ( 1.406)	Data  0.165 ( 0.293)	Loss 1.2295e-01 (1.3363e-01) 
2023-05-25 01:06:08.536285: train Epoch: [11][112/193]	Time  1.606 ( 1.408)	Data  0.490 ( 0.294)	Loss 1.1144e-01 (1.3343e-01) 
2023-05-25 01:06:09.692830: train Epoch: [11][113/193]	Time  1.157 ( 1.406)	Data  0.175 ( 0.293)	Loss 8.1167e-02 (1.3297e-01) 
2023-05-25 01:06:11.496309: train Epoch: [11][114/193]	Time  1.803 ( 1.409)	Data  0.488 ( 0.295)	Loss 9.8721e-02 (1.3267e-01) 
2023-05-25 01:06:12.731143: train Epoch: [11][115/193]	Time  1.235 ( 1.408)	Data  0.228 ( 0.294)	Loss 8.3233e-02 (1.3225e-01) 
2023-05-25 01:06:13.967301: train Epoch: [11][116/193]	Time  1.236 ( 1.406)	Data  0.114 ( 0.293)	Loss 2.2785e-01 (1.3306e-01) 
2023-05-25 01:06:15.909957: train Epoch: [11][117/193]	Time  1.943 ( 1.411)	Data  0.654 ( 0.296)	Loss 9.6195e-02 (1.3275e-01) 
2023-05-25 01:06:16.979042: train Epoch: [11][118/193]	Time  1.069 ( 1.408)	Data  0.001 ( 0.293)	Loss 1.5314e-01 (1.3292e-01) 
2023-05-25 01:06:18.489685: train Epoch: [11][119/193]	Time  1.511 ( 1.409)	Data  0.490 ( 0.295)	Loss 8.9826e-02 (1.3256e-01) 
2023-05-25 01:06:19.582020: train Epoch: [11][120/193]	Time  1.092 ( 1.406)	Data  0.001 ( 0.293)	Loss 1.8174e-01 (1.3297e-01) 
2023-05-25 01:06:21.472809: train Epoch: [11][121/193]	Time  1.891 ( 1.410)	Data  0.642 ( 0.296)	Loss 1.4572e-01 (1.3307e-01) 
2023-05-25 01:06:22.431897: train Epoch: [11][122/193]	Time  0.959 ( 1.406)	Data  0.001 ( 0.293)	Loss 3.6850e-01 (1.3499e-01) 
2023-05-25 01:06:24.160081: train Epoch: [11][123/193]	Time  1.728 ( 1.409)	Data  0.635 ( 0.296)	Loss 1.2393e-01 (1.3490e-01) 
2023-05-25 01:06:25.119643: train Epoch: [11][124/193]	Time  0.960 ( 1.405)	Data  0.001 ( 0.294)	Loss 1.0659e-01 (1.3467e-01) 
2023-05-25 01:06:27.236205: train Epoch: [11][125/193]	Time  2.117 ( 1.411)	Data  0.974 ( 0.299)	Loss 1.0918e-01 (1.3447e-01) 
2023-05-25 01:06:28.202500: train Epoch: [11][126/193]	Time  0.966 ( 1.408)	Data  0.001 ( 0.297)	Loss 7.7860e-02 (1.3402e-01) 
2023-05-25 01:06:29.910012: train Epoch: [11][127/193]	Time  1.707 ( 1.410)	Data  0.714 ( 0.300)	Loss 8.0389e-02 (1.3361e-01) 
2023-05-25 01:06:30.848309: train Epoch: [11][128/193]	Time  0.938 ( 1.406)	Data  0.001 ( 0.298)	Loss 2.3315e-01 (1.3438e-01) 
2023-05-25 01:06:32.880906: train Epoch: [11][129/193]	Time  2.033 ( 1.411)	Data  0.881 ( 0.302)	Loss 8.1632e-02 (1.3397e-01) 
2023-05-25 01:06:33.956906: train Epoch: [11][130/193]	Time  1.076 ( 1.409)	Data  0.001 ( 0.300)	Loss 2.2993e-01 (1.3470e-01) 
2023-05-25 01:06:35.920304: train Epoch: [11][131/193]	Time  1.963 ( 1.413)	Data  0.673 ( 0.303)	Loss 7.6243e-02 (1.3426e-01) 
2023-05-25 01:06:36.946544: train Epoch: [11][132/193]	Time  1.026 ( 1.410)	Data  0.001 ( 0.300)	Loss 1.2083e-01 (1.3416e-01) 
2023-05-25 01:06:38.652097: train Epoch: [11][133/193]	Time  1.706 ( 1.412)	Data  0.478 ( 0.302)	Loss 1.0314e-01 (1.3393e-01) 
2023-05-25 01:06:39.774328: train Epoch: [11][134/193]	Time  1.122 ( 1.410)	Data  0.001 ( 0.299)	Loss 9.8653e-02 (1.3367e-01) 
2023-05-25 01:06:41.551310: train Epoch: [11][135/193]	Time  1.777 ( 1.413)	Data  0.484 ( 0.301)	Loss 9.4763e-02 (1.3338e-01) 
2023-05-25 01:06:42.617954: train Epoch: [11][136/193]	Time  1.067 ( 1.410)	Data  0.001 ( 0.299)	Loss 8.4821e-02 (1.3303e-01) 
2023-05-25 01:06:44.197929: train Epoch: [11][137/193]	Time  1.580 ( 1.411)	Data  0.521 ( 0.300)	Loss 1.2795e-01 (1.3299e-01) 
2023-05-25 01:06:45.466000: train Epoch: [11][138/193]	Time  1.268 ( 1.410)	Data  0.001 ( 0.298)	Loss 1.1652e-01 (1.3287e-01) 
2023-05-25 01:06:46.939588: train Epoch: [11][139/193]	Time  1.474 ( 1.411)	Data  0.436 ( 0.299)	Loss 1.0586e-01 (1.3268e-01) 
2023-05-25 01:06:47.970497: train Epoch: [11][140/193]	Time  1.031 ( 1.408)	Data  0.001 ( 0.297)	Loss 7.4360e-02 (1.3226e-01) 
2023-05-25 01:06:50.032801: train Epoch: [11][141/193]	Time  2.062 ( 1.413)	Data  0.601 ( 0.299)	Loss 1.5447e-01 (1.3242e-01) 
2023-05-25 01:06:50.988794: train Epoch: [11][142/193]	Time  0.956 ( 1.409)	Data  0.001 ( 0.297)	Loss 1.2279e-01 (1.3235e-01) 
2023-05-25 01:06:52.260890: train Epoch: [11][143/193]	Time  1.272 ( 1.408)	Data  0.315 ( 0.297)	Loss 1.1649e-01 (1.3224e-01) 
2023-05-25 01:06:53.200338: train Epoch: [11][144/193]	Time  0.939 ( 1.405)	Data  0.001 ( 0.295)	Loss 1.1720e-01 (1.3214e-01) 
2023-05-25 01:06:54.852973: train Epoch: [11][145/193]	Time  1.653 ( 1.407)	Data  0.710 ( 0.298)	Loss 9.4181e-02 (1.3188e-01) 
2023-05-25 01:06:55.813623: train Epoch: [11][146/193]	Time  0.961 ( 1.404)	Data  0.001 ( 0.296)	Loss 1.2598e-01 (1.3184e-01) 
2023-05-25 01:06:57.598239: train Epoch: [11][147/193]	Time  1.785 ( 1.406)	Data  0.801 ( 0.299)	Loss 1.1252e-01 (1.3171e-01) 
2023-05-25 01:06:58.559114: train Epoch: [11][148/193]	Time  0.961 ( 1.403)	Data  0.001 ( 0.297)	Loss 7.1298e-02 (1.3130e-01) 
2023-05-25 01:07:00.170328: train Epoch: [11][149/193]	Time  1.611 ( 1.405)	Data  0.650 ( 0.300)	Loss 1.5136e-01 (1.3144e-01) 
2023-05-25 01:07:01.131259: train Epoch: [11][150/193]	Time  0.961 ( 1.402)	Data  0.001 ( 0.298)	Loss 1.2515e-01 (1.3140e-01) 
2023-05-25 01:07:02.795714: train Epoch: [11][151/193]	Time  1.664 ( 1.404)	Data  0.706 ( 0.300)	Loss 9.0593e-02 (1.3113e-01) 
2023-05-25 01:07:03.742527: train Epoch: [11][152/193]	Time  0.947 ( 1.401)	Data  0.001 ( 0.298)	Loss 1.0368e-01 (1.3095e-01) 
2023-05-25 01:07:05.418124: train Epoch: [11][153/193]	Time  1.676 ( 1.402)	Data  0.752 ( 0.301)	Loss 1.4052e-01 (1.3101e-01) 
2023-05-25 01:07:06.372249: train Epoch: [11][154/193]	Time  0.954 ( 1.400)	Data  0.001 ( 0.299)	Loss 1.2228e-01 (1.3095e-01) 
2023-05-25 01:07:08.421181: train Epoch: [11][155/193]	Time  2.049 ( 1.404)	Data  0.878 ( 0.303)	Loss 1.6979e-01 (1.3120e-01) 
2023-05-25 01:07:10.372441: train Epoch: [11][156/193]	Time  1.951 ( 1.407)	Data  0.001 ( 0.301)	Loss 1.0841e-01 (1.3106e-01) 
2023-05-25 01:07:12.314543: train Epoch: [11][157/193]	Time  1.942 ( 1.411)	Data  0.001 ( 0.299)	Loss 1.3141e-01 (1.3106e-01) 
2023-05-25 01:07:14.265914: train Epoch: [11][158/193]	Time  1.951 ( 1.414)	Data  0.001 ( 0.297)	Loss 7.3083e-02 (1.3070e-01) 
2023-05-25 01:07:16.232462: train Epoch: [11][159/193]	Time  1.967 ( 1.417)	Data  0.001 ( 0.296)	Loss 1.3603e-01 (1.3073e-01) 
2023-05-25 01:07:18.192558: train Epoch: [11][160/193]	Time  1.960 ( 1.421)	Data  0.001 ( 0.294)	Loss 1.4073e-01 (1.3079e-01) 
2023-05-25 01:07:20.149934: train Epoch: [11][161/193]	Time  1.957 ( 1.424)	Data  0.001 ( 0.292)	Loss 1.0736e-01 (1.3065e-01) 
2023-05-25 01:07:22.098846: train Epoch: [11][162/193]	Time  1.949 ( 1.427)	Data  0.001 ( 0.290)	Loss 6.8119e-02 (1.3026e-01) 
2023-05-25 01:07:24.053131: train Epoch: [11][163/193]	Time  1.954 ( 1.431)	Data  0.001 ( 0.288)	Loss 1.0965e-01 (1.3014e-01) 
2023-05-25 01:07:25.995100: train Epoch: [11][164/193]	Time  1.942 ( 1.434)	Data  0.001 ( 0.287)	Loss 1.5956e-01 (1.3032e-01) 
2023-05-25 01:07:27.957515: train Epoch: [11][165/193]	Time  1.962 ( 1.437)	Data  0.001 ( 0.285)	Loss 1.3679e-01 (1.3035e-01) 
2023-05-25 01:07:29.904738: train Epoch: [11][166/193]	Time  1.947 ( 1.440)	Data  0.001 ( 0.283)	Loss 9.5852e-02 (1.3015e-01) 
2023-05-25 01:07:31.854866: train Epoch: [11][167/193]	Time  1.950 ( 1.443)	Data  0.001 ( 0.282)	Loss 1.0677e-01 (1.3001e-01) 
2023-05-25 01:07:33.811456: train Epoch: [11][168/193]	Time  1.957 ( 1.446)	Data  0.001 ( 0.280)	Loss 1.2433e-01 (1.2997e-01) 
2023-05-25 01:07:35.760201: train Epoch: [11][169/193]	Time  1.949 ( 1.449)	Data  0.001 ( 0.278)	Loss 8.1816e-02 (1.2969e-01) 
2023-05-25 01:07:37.549240: train Epoch: [11][170/193]	Time  1.789 ( 1.451)	Data  0.001 ( 0.277)	Loss 1.1458e-01 (1.2960e-01) 
2023-05-25 01:07:38.426562: train Epoch: [11][171/193]	Time  0.877 ( 1.448)	Data  0.001 ( 0.275)	Loss 1.5862e-01 (1.2977e-01) 
2023-05-25 01:07:39.673970: train Epoch: [11][172/193]	Time  1.247 ( 1.446)	Data  0.001 ( 0.273)	Loss 6.9750e-02 (1.2942e-01) 
2023-05-25 01:07:40.890553: train Epoch: [11][173/193]	Time  1.217 ( 1.445)	Data  0.001 ( 0.272)	Loss 1.7852e-01 (1.2971e-01) 
2023-05-25 01:07:42.153758: train Epoch: [11][174/193]	Time  1.263 ( 1.444)	Data  0.002 ( 0.270)	Loss 1.7881e-01 (1.2999e-01) 
2023-05-25 01:07:43.184458: train Epoch: [11][175/193]	Time  1.031 ( 1.442)	Data  0.001 ( 0.269)	Loss 1.4263e-01 (1.3006e-01) 
2023-05-25 01:07:44.282850: train Epoch: [11][176/193]	Time  1.098 ( 1.440)	Data  0.001 ( 0.267)	Loss 1.5688e-01 (1.3021e-01) 
2023-05-25 01:07:45.495038: train Epoch: [11][177/193]	Time  1.212 ( 1.439)	Data  0.001 ( 0.266)	Loss 1.0896e-01 (1.3009e-01) 
2023-05-25 01:07:46.609331: train Epoch: [11][178/193]	Time  1.114 ( 1.437)	Data  0.001 ( 0.264)	Loss 8.1242e-02 (1.2982e-01) 
2023-05-25 01:07:47.633900: train Epoch: [11][179/193]	Time  1.025 ( 1.434)	Data  0.033 ( 0.263)	Loss 8.2664e-02 (1.2956e-01) 
2023-05-25 01:07:48.604526: train Epoch: [11][180/193]	Time  0.971 ( 1.432)	Data  0.001 ( 0.262)	Loss 1.6635e-01 (1.2976e-01) 
2023-05-25 01:07:50.861238: train Epoch: [11][181/193]	Time  2.257 ( 1.436)	Data  1.051 ( 0.266)	Loss 9.4967e-02 (1.2957e-01) 
2023-05-25 01:07:51.856908: train Epoch: [11][182/193]	Time  0.996 ( 1.434)	Data  0.001 ( 0.264)	Loss 1.7803e-01 (1.2983e-01) 
2023-05-25 01:07:53.683729: train Epoch: [11][183/193]	Time  1.827 ( 1.436)	Data  0.751 ( 0.267)	Loss 6.9331e-02 (1.2950e-01) 
2023-05-25 01:07:54.782601: train Epoch: [11][184/193]	Time  1.099 ( 1.434)	Data  0.001 ( 0.266)	Loss 8.0222e-02 (1.2924e-01) 
2023-05-25 01:07:56.535730: train Epoch: [11][185/193]	Time  1.753 ( 1.436)	Data  0.681 ( 0.268)	Loss 8.8304e-02 (1.2902e-01) 
2023-05-25 01:07:57.915510: train Epoch: [11][186/193]	Time  1.380 ( 1.436)	Data  0.002 ( 0.266)	Loss 1.8066e-01 (1.2929e-01) 
2023-05-25 01:07:59.192352: train Epoch: [11][187/193]	Time  1.277 ( 1.435)	Data  0.327 ( 0.267)	Loss 2.7402e-01 (1.3006e-01) 
2023-05-25 01:08:00.102129: train Epoch: [11][188/193]	Time  0.910 ( 1.432)	Data  0.001 ( 0.265)	Loss 1.0813e-01 (1.2995e-01) 
2023-05-25 01:08:02.223479: train Epoch: [11][189/193]	Time  2.121 ( 1.436)	Data  0.967 ( 0.269)	Loss 1.0535e-01 (1.2982e-01) 
2023-05-25 01:08:03.278225: train Epoch: [11][190/193]	Time  1.055 ( 1.434)	Data  0.001 ( 0.268)	Loss 1.7793e-01 (1.3007e-01) 
2023-05-25 01:08:04.716336: train Epoch: [11][191/193]	Time  1.438 ( 1.434)	Data  0.313 ( 0.268)	Loss 1.2537e-01 (1.3005e-01) 
2023-05-25 01:08:05.674486: train Epoch: [11][192/193]	Time  0.958 ( 1.431)	Data  0.001 ( 0.267)	Loss 1.2677e-01 (1.3003e-01) 
2023-05-25 01:08:05.739674: Train Epoch done in 276.29923113202676 s 
2023-05-25 01:08:09.099238: val Epoch: [11][ 0/72]	Time  2.307 ( 2.307)	Data  1.827 ( 1.827)	Loss 8.4362e-02 (8.4362e-02) 
2023-05-25 01:08:09.362001: val Epoch: [11][ 1/72]	Time  0.263 ( 1.285)	Data  0.002 ( 0.914)	Loss 1.4159e-01 (1.1298e-01) 
2023-05-25 01:08:10.192147: val Epoch: [11][ 2/72]	Time  0.830 ( 1.133)	Data  0.507 ( 0.779)	Loss 7.3595e-02 (9.9849e-02) 
2023-05-25 01:08:10.595279: val Epoch: [11][ 3/72]	Time  0.403 ( 0.951)	Data  0.001 ( 0.584)	Loss 3.3406e-01 (1.5840e-01) 
2023-05-25 01:08:11.874883: val Epoch: [11][ 4/72]	Time  1.280 ( 1.017)	Data  0.639 ( 0.595)	Loss 6.1094e-02 (1.3894e-01) 
2023-05-25 01:08:12.287993: val Epoch: [11][ 5/72]	Time  0.413 ( 0.916)	Data  0.001 ( 0.496)	Loss 2.1825e-01 (1.5216e-01) 
2023-05-25 01:08:13.187429: val Epoch: [11][ 6/72]	Time  0.899 ( 0.914)	Data  0.356 ( 0.476)	Loss 1.0259e-01 (1.4508e-01) 
2023-05-25 01:08:13.404749: val Epoch: [11][ 7/72]	Time  0.217 ( 0.827)	Data  0.001 ( 0.417)	Loss 6.9394e-02 (1.3562e-01) 
2023-05-25 01:08:14.468412: val Epoch: [11][ 8/72]	Time  1.064 ( 0.853)	Data  0.625 ( 0.440)	Loss 5.3600e-01 (1.8010e-01) 
2023-05-25 01:08:14.961658: val Epoch: [11][ 9/72]	Time  0.493 ( 0.817)	Data  0.010 ( 0.397)	Loss 5.3808e-01 (2.1590e-01) 
2023-05-25 01:08:15.726478: val Epoch: [11][10/72]	Time  0.765 ( 0.812)	Data  0.399 ( 0.397)	Loss 7.0021e-02 (2.0264e-01) 
2023-05-25 01:08:16.441003: val Epoch: [11][11/72]	Time  0.715 ( 0.804)	Data  0.259 ( 0.385)	Loss 2.5159e-01 (2.0672e-01) 
2023-05-25 01:08:17.024271: val Epoch: [11][12/72]	Time  0.583 ( 0.787)	Data  0.297 ( 0.379)	Loss 3.0031e-01 (2.1392e-01) 
2023-05-25 01:08:17.705464: val Epoch: [11][13/72]	Time  0.681 ( 0.780)	Data  0.353 ( 0.377)	Loss 1.1051e-01 (2.0653e-01) 
2023-05-25 01:08:18.564415: val Epoch: [11][14/72]	Time  0.859 ( 0.785)	Data  0.446 ( 0.381)	Loss 1.4309e-01 (2.0230e-01) 
2023-05-25 01:08:19.157585: val Epoch: [11][15/72]	Time  0.593 ( 0.773)	Data  0.177 ( 0.369)	Loss 8.9276e-02 (1.9524e-01) 
2023-05-25 01:08:19.857279: val Epoch: [11][16/72]	Time  0.700 ( 0.769)	Data  0.418 ( 0.372)	Loss 2.9303e-01 (2.0099e-01) 
2023-05-25 01:08:20.617893: val Epoch: [11][17/72]	Time  0.761 ( 0.768)	Data  0.283 ( 0.367)	Loss 1.8321e-01 (2.0000e-01) 
2023-05-25 01:08:21.219476: val Epoch: [11][18/72]	Time  0.602 ( 0.759)	Data  0.342 ( 0.365)	Loss 2.2790e-01 (2.0147e-01) 
2023-05-25 01:08:21.695430: val Epoch: [11][19/72]	Time  0.476 ( 0.745)	Data  0.259 ( 0.360)	Loss 8.9544e-02 (1.9587e-01) 
2023-05-25 01:08:22.737969: val Epoch: [11][20/72]	Time  1.043 ( 0.759)	Data  0.631 ( 0.373)	Loss 1.0631e-01 (1.9161e-01) 
2023-05-25 01:08:23.244145: val Epoch: [11][21/72]	Time  0.506 ( 0.748)	Data  0.106 ( 0.361)	Loss 1.7612e-01 (1.9091e-01) 
2023-05-25 01:08:24.355153: val Epoch: [11][22/72]	Time  1.111 ( 0.764)	Data  0.581 ( 0.370)	Loss 1.6073e-01 (1.8959e-01) 
2023-05-25 01:08:24.711920: val Epoch: [11][23/72]	Time  0.357 ( 0.747)	Data  0.001 ( 0.355)	Loss 7.2001e-02 (1.8469e-01) 
2023-05-25 01:08:25.523396: val Epoch: [11][24/72]	Time  0.811 ( 0.749)	Data  0.597 ( 0.365)	Loss 6.5319e-02 (1.7992e-01) 
2023-05-25 01:08:25.952631: val Epoch: [11][25/72]	Time  0.429 ( 0.737)	Data  0.092 ( 0.354)	Loss 6.6957e-02 (1.7557e-01) 
2023-05-25 01:08:27.012503: val Epoch: [11][26/72]	Time  1.060 ( 0.749)	Data  0.758 ( 0.369)	Loss 8.9421e-02 (1.7238e-01) 
2023-05-25 01:08:27.595710: val Epoch: [11][27/72]	Time  0.583 ( 0.743)	Data  0.049 ( 0.358)	Loss 1.0548e-01 (1.6999e-01) 
2023-05-25 01:08:28.537368: val Epoch: [11][28/72]	Time  0.942 ( 0.750)	Data  0.663 ( 0.368)	Loss 2.0736e-01 (1.7128e-01) 
2023-05-25 01:08:28.959801: val Epoch: [11][29/72]	Time  0.422 ( 0.739)	Data  0.047 ( 0.358)	Loss 1.1879e-01 (1.6953e-01) 
2023-05-25 01:08:30.254924: val Epoch: [11][30/72]	Time  1.295 ( 0.757)	Data  0.797 ( 0.372)	Loss 1.4237e-01 (1.6866e-01) 
2023-05-25 01:08:30.516475: val Epoch: [11][31/72]	Time  0.262 ( 0.741)	Data  0.001 ( 0.360)	Loss 8.6467e-02 (1.6609e-01) 
2023-05-25 01:08:31.749676: val Epoch: [11][32/72]	Time  1.233 ( 0.756)	Data  0.765 ( 0.372)	Loss 5.6400e-01 (1.7815e-01) 
2023-05-25 01:08:32.083986: val Epoch: [11][33/72]	Time  0.334 ( 0.744)	Data  0.001 ( 0.361)	Loss 1.6139e-01 (1.7765e-01) 
2023-05-25 01:08:32.952235: val Epoch: [11][34/72]	Time  0.868 ( 0.747)	Data  0.629 ( 0.369)	Loss 7.1032e-02 (1.7461e-01) 
2023-05-25 01:08:33.325011: val Epoch: [11][35/72]	Time  0.373 ( 0.737)	Data  0.001 ( 0.359)	Loss 8.0213e-02 (1.7198e-01) 
2023-05-25 01:08:34.398723: val Epoch: [11][36/72]	Time  1.074 ( 0.746)	Data  0.841 ( 0.372)	Loss 1.5102e-01 (1.7142e-01) 
2023-05-25 01:08:34.639445: val Epoch: [11][37/72]	Time  0.241 ( 0.733)	Data  0.001 ( 0.362)	Loss 1.4980e-01 (1.7085e-01) 
2023-05-25 01:08:35.888032: val Epoch: [11][38/72]	Time  1.249 ( 0.746)	Data  0.954 ( 0.377)	Loss 8.9585e-02 (1.6877e-01) 
2023-05-25 01:08:36.250784: val Epoch: [11][39/72]	Time  0.363 ( 0.736)	Data  0.001 ( 0.368)	Loss 6.4570e-02 (1.6616e-01) 
2023-05-25 01:08:37.441771: val Epoch: [11][40/72]	Time  1.191 ( 0.748)	Data  0.866 ( 0.380)	Loss 2.0497e-01 (1.6711e-01) 
2023-05-25 01:08:37.847138: val Epoch: [11][41/72]	Time  0.405 ( 0.739)	Data  0.001 ( 0.371)	Loss 2.2226e-01 (1.6842e-01) 
2023-05-25 01:08:39.040489: val Epoch: [11][42/72]	Time  1.193 ( 0.750)	Data  0.656 ( 0.378)	Loss 7.9895e-02 (1.6636e-01) 
2023-05-25 01:08:39.295188: val Epoch: [11][43/72]	Time  0.255 ( 0.739)	Data  0.001 ( 0.369)	Loss 1.1944e-01 (1.6529e-01) 
2023-05-25 01:08:40.582668: val Epoch: [11][44/72]	Time  1.287 ( 0.751)	Data  0.718 ( 0.377)	Loss 8.7710e-02 (1.6357e-01) 
2023-05-25 01:08:40.766911: val Epoch: [11][45/72]	Time  0.184 ( 0.739)	Data  0.001 ( 0.369)	Loss 2.3163e-01 (1.6505e-01) 
2023-05-25 01:08:41.554707: val Epoch: [11][46/72]	Time  0.788 ( 0.740)	Data  0.606 ( 0.374)	Loss 6.7086e-02 (1.6297e-01) 
2023-05-25 01:08:41.954917: val Epoch: [11][47/72]	Time  0.400 ( 0.733)	Data  0.001 ( 0.366)	Loss 9.0449e-02 (1.6146e-01) 
2023-05-25 01:08:43.186115: val Epoch: [11][48/72]	Time  1.231 ( 0.743)	Data  0.879 ( 0.376)	Loss 1.1262e-01 (1.6046e-01) 
2023-05-25 01:08:43.444989: val Epoch: [11][49/72]	Time  0.259 ( 0.733)	Data  0.001 ( 0.369)	Loss 9.2770e-02 (1.5910e-01) 
2023-05-25 01:08:44.497629: val Epoch: [11][50/72]	Time  1.053 ( 0.739)	Data  0.856 ( 0.378)	Loss 4.9521e-01 (1.6570e-01) 
2023-05-25 01:08:44.882343: val Epoch: [11][51/72]	Time  0.385 ( 0.732)	Data  0.001 ( 0.371)	Loss 2.2400e-01 (1.6682e-01) 
2023-05-25 01:08:46.143364: val Epoch: [11][52/72]	Time  1.261 ( 0.742)	Data  0.931 ( 0.382)	Loss 1.2404e-01 (1.6601e-01) 
2023-05-25 01:08:46.476806: val Epoch: [11][53/72]	Time  0.333 ( 0.735)	Data  0.001 ( 0.375)	Loss 1.4848e-01 (1.6568e-01) 
2023-05-25 01:08:47.798993: val Epoch: [11][54/72]	Time  1.322 ( 0.746)	Data  0.820 ( 0.383)	Loss 3.9727e-01 (1.6990e-01) 
2023-05-25 01:08:48.318926: val Epoch: [11][55/72]	Time  0.520 ( 0.742)	Data  0.001 ( 0.376)	Loss 8.9869e-02 (1.6847e-01) 
2023-05-25 01:08:49.005148: val Epoch: [11][56/72]	Time  0.686 ( 0.741)	Data  0.431 ( 0.377)	Loss 4.3221e-01 (1.7309e-01) 
2023-05-25 01:08:49.423277: val Epoch: [11][57/72]	Time  0.418 ( 0.735)	Data  0.001 ( 0.370)	Loss 3.9110e-01 (1.7685e-01) 
2023-05-25 01:08:50.579263: val Epoch: [11][58/72]	Time  1.156 ( 0.742)	Data  0.888 ( 0.379)	Loss 3.0444e-01 (1.7901e-01) 
2023-05-25 01:08:50.923000: val Epoch: [11][59/72]	Time  0.344 ( 0.736)	Data  0.001 ( 0.373)	Loss 1.1612e-01 (1.7797e-01) 
2023-05-25 01:08:52.037750: val Epoch: [11][60/72]	Time  1.115 ( 0.742)	Data  0.788 ( 0.380)	Loss 2.3626e-01 (1.7892e-01) 
2023-05-25 01:08:52.207096: val Epoch: [11][61/72]	Time  0.169 ( 0.732)	Data  0.001 ( 0.374)	Loss 7.4482e-02 (1.7724e-01) 
2023-05-25 01:08:53.484545: val Epoch: [11][62/72]	Time  1.277 ( 0.741)	Data  0.970 ( 0.383)	Loss 1.4010e-01 (1.7665e-01) 
2023-05-25 01:08:53.779474: val Epoch: [11][63/72]	Time  0.295 ( 0.734)	Data  0.001 ( 0.377)	Loss 1.3707e-01 (1.7603e-01) 
2023-05-25 01:08:55.152892: val Epoch: [11][64/72]	Time  1.373 ( 0.744)	Data  0.823 ( 0.384)	Loss 7.0090e-02 (1.7440e-01) 
2023-05-25 01:08:55.448566: val Epoch: [11][65/72]	Time  0.296 ( 0.737)	Data  0.001 ( 0.378)	Loss 1.0180e-01 (1.7330e-01) 
2023-05-25 01:08:56.313567: val Epoch: [11][66/72]	Time  0.865 ( 0.739)	Data  0.616 ( 0.382)	Loss 1.6344e-01 (1.7315e-01) 
2023-05-25 01:08:56.693913: val Epoch: [11][67/72]	Time  0.380 ( 0.734)	Data  0.004 ( 0.376)	Loss 6.5874e-02 (1.7157e-01) 
2023-05-25 01:08:57.872157: val Epoch: [11][68/72]	Time  1.178 ( 0.740)	Data  0.834 ( 0.383)	Loss 3.8537e-01 (1.7467e-01) 
2023-05-25 01:08:58.319530: val Epoch: [11][69/72]	Time  0.447 ( 0.736)	Data  0.001 ( 0.377)	Loss 1.3268e-01 (1.7407e-01) 
2023-05-25 01:08:59.003462: val Epoch: [11][70/72]	Time  0.684 ( 0.735)	Data  0.495 ( 0.379)	Loss 1.4749e-01 (1.7370e-01) 
2023-05-25 01:08:59.268549: val Epoch: [11][71/72]	Time  0.265 ( 0.729)	Data  0.001 ( 0.374)	Loss 7.8774e-02 (1.7238e-01) 
2023-05-25 01:08:59.530633: Epoch 11 :Val : ['ET : 0.6688342690467834', 'TC : 0.7173157930374146', 'WT : 0.8231913447380066'] 
2023-05-25 01:08:59.535066: Epoch 11 :Val : ['ET : 0.6688342690467834', 'TC : 0.7173157930374146', 'WT : 0.8231913447380066'] 
2023-05-25 01:08:59.538546: Saving the model with DSC 0.7357866764068604 
2023-05-25 01:09:00.600591: Val epoch done in 54.86090226797387 s 
2023-05-25 01:09:00.610055: Batches per epoch:  193 
2023-05-25 01:09:05.257673: train Epoch: [12][  0/193]	Time  4.647 ( 4.647)	Data  3.299 ( 3.299)	Loss 2.1981e-01 (2.1981e-01) 
2023-05-25 01:09:06.349961: train Epoch: [12][  1/193]	Time  1.092 ( 2.870)	Data  0.001 ( 1.650)	Loss 1.1379e-01 (1.6680e-01) 
2023-05-25 01:09:07.898351: train Epoch: [12][  2/193]	Time  1.548 ( 2.429)	Data  0.366 ( 1.222)	Loss 1.6168e-01 (1.6509e-01) 
2023-05-25 01:09:09.091580: train Epoch: [12][  3/193]	Time  1.193 ( 2.120)	Data  0.001 ( 0.917)	Loss 6.0734e-02 (1.3900e-01) 
2023-05-25 01:09:10.631974: train Epoch: [12][  4/193]	Time  1.540 ( 2.004)	Data  0.327 ( 0.799)	Loss 1.0327e-01 (1.3186e-01) 
2023-05-25 01:09:11.738805: train Epoch: [12][  5/193]	Time  1.107 ( 1.855)	Data  0.001 ( 0.666)	Loss 8.3369e-02 (1.2378e-01) 
2023-05-25 01:09:13.138568: train Epoch: [12][  6/193]	Time  1.400 ( 1.790)	Data  0.423 ( 0.631)	Loss 1.5787e-01 (1.2865e-01) 
2023-05-25 01:09:14.182902: train Epoch: [12][  7/193]	Time  1.044 ( 1.697)	Data  0.001 ( 0.552)	Loss 2.2557e-01 (1.4076e-01) 
2023-05-25 01:09:16.061808: train Epoch: [12][  8/193]	Time  1.879 ( 1.717)	Data  0.769 ( 0.577)	Loss 8.6053e-02 (1.3468e-01) 
2023-05-25 01:09:17.175153: train Epoch: [12][  9/193]	Time  1.113 ( 1.656)	Data  0.001 ( 0.519)	Loss 1.1015e-01 (1.3223e-01) 
2023-05-25 01:09:18.987124: train Epoch: [12][ 10/193]	Time  1.812 ( 1.671)	Data  0.500 ( 0.517)	Loss 9.7966e-02 (1.2912e-01) 
2023-05-25 01:09:20.041972: train Epoch: [12][ 11/193]	Time  1.055 ( 1.619)	Data  0.001 ( 0.474)	Loss 1.1100e-01 (1.2761e-01) 
2023-05-25 01:09:21.517504: train Epoch: [12][ 12/193]	Time  1.476 ( 1.608)	Data  0.372 ( 0.466)	Loss 1.0976e-01 (1.2623e-01) 
2023-05-25 01:09:22.557784: train Epoch: [12][ 13/193]	Time  1.040 ( 1.568)	Data  0.001 ( 0.433)	Loss 9.0885e-02 (1.2371e-01) 
2023-05-25 01:09:24.329745: train Epoch: [12][ 14/193]	Time  1.772 ( 1.581)	Data  0.628 ( 0.446)	Loss 1.7603e-01 (1.2720e-01) 
2023-05-25 01:09:25.609347: train Epoch: [12][ 15/193]	Time  1.280 ( 1.562)	Data  0.001 ( 0.418)	Loss 1.6709e-01 (1.2969e-01) 
2023-05-25 01:09:26.927392: train Epoch: [12][ 16/193]	Time  1.318 ( 1.548)	Data  0.337 ( 0.413)	Loss 9.9478e-02 (1.2791e-01) 
2023-05-25 01:09:27.946246: train Epoch: [12][ 17/193]	Time  1.019 ( 1.519)	Data  0.001 ( 0.391)	Loss 1.6575e-01 (1.3001e-01) 
2023-05-25 01:09:29.789189: train Epoch: [12][ 18/193]	Time  1.843 ( 1.536)	Data  0.724 ( 0.408)	Loss 1.0294e-01 (1.2859e-01) 
2023-05-25 01:09:30.887173: train Epoch: [12][ 19/193]	Time  1.098 ( 1.514)	Data  0.001 ( 0.388)	Loss 8.1315e-02 (1.2623e-01) 
2023-05-25 01:09:32.654892: train Epoch: [12][ 20/193]	Time  1.768 ( 1.526)	Data  0.422 ( 0.389)	Loss 9.3518e-02 (1.2467e-01) 
2023-05-25 01:09:33.729899: train Epoch: [12][ 21/193]	Time  1.075 ( 1.505)	Data  0.001 ( 0.372)	Loss 1.1138e-01 (1.2406e-01) 
2023-05-25 01:09:35.038660: train Epoch: [12][ 22/193]	Time  1.309 ( 1.497)	Data  0.276 ( 0.368)	Loss 8.0158e-02 (1.2215e-01) 
2023-05-25 01:09:36.061100: train Epoch: [12][ 23/193]	Time  1.022 ( 1.477)	Data  0.001 ( 0.352)	Loss 1.0507e-01 (1.2144e-01) 
2023-05-25 01:09:37.577685: train Epoch: [12][ 24/193]	Time  1.517 ( 1.479)	Data  0.523 ( 0.359)	Loss 9.7746e-02 (1.2050e-01) 
2023-05-25 01:09:38.709021: train Epoch: [12][ 25/193]	Time  1.131 ( 1.465)	Data  0.001 ( 0.345)	Loss 2.2940e-01 (1.2468e-01) 
2023-05-25 01:09:40.731421: train Epoch: [12][ 26/193]	Time  2.022 ( 1.486)	Data  0.765 ( 0.361)	Loss 1.7239e-01 (1.2645e-01) 
2023-05-25 01:09:41.741464: train Epoch: [12][ 27/193]	Time  1.010 ( 1.469)	Data  0.001 ( 0.348)	Loss 1.0531e-01 (1.2570e-01) 
2023-05-25 01:09:43.499157: train Epoch: [12][ 28/193]	Time  1.758 ( 1.479)	Data  0.498 ( 0.353)	Loss 8.0042e-02 (1.2412e-01) 
2023-05-25 01:09:44.769050: train Epoch: [12][ 29/193]	Time  1.270 ( 1.472)	Data  0.001 ( 0.342)	Loss 8.3239e-02 (1.2276e-01) 
2023-05-25 01:09:46.068967: train Epoch: [12][ 30/193]	Time  1.300 ( 1.466)	Data  0.274 ( 0.339)	Loss 3.9620e-01 (1.3158e-01) 
2023-05-25 01:09:47.294110: train Epoch: [12][ 31/193]	Time  1.225 ( 1.459)	Data  0.001 ( 0.329)	Loss 8.2763e-02 (1.3005e-01) 
2023-05-25 01:09:48.931979: train Epoch: [12][ 32/193]	Time  1.638 ( 1.464)	Data  0.538 ( 0.335)	Loss 8.9745e-02 (1.2883e-01) 
2023-05-25 01:09:50.239804: train Epoch: [12][ 33/193]	Time  1.308 ( 1.460)	Data  0.001 ( 0.325)	Loss 8.0818e-02 (1.2742e-01) 
2023-05-25 01:09:51.831539: train Epoch: [12][ 34/193]	Time  1.592 ( 1.463)	Data  0.364 ( 0.326)	Loss 1.3436e-01 (1.2762e-01) 
2023-05-25 01:09:52.980713: train Epoch: [12][ 35/193]	Time  1.149 ( 1.455)	Data  0.001 ( 0.317)	Loss 1.5499e-01 (1.2838e-01) 
2023-05-25 01:09:54.541479: train Epoch: [12][ 36/193]	Time  1.561 ( 1.458)	Data  0.403 ( 0.320)	Loss 1.6293e-01 (1.2931e-01) 
2023-05-25 01:09:55.635160: train Epoch: [12][ 37/193]	Time  1.094 ( 1.448)	Data  0.001 ( 0.311)	Loss 1.4247e-01 (1.2966e-01) 
2023-05-25 01:09:57.292165: train Epoch: [12][ 38/193]	Time  1.657 ( 1.453)	Data  0.592 ( 0.319)	Loss 6.1613e-02 (1.2791e-01) 
2023-05-25 01:09:58.358012: train Epoch: [12][ 39/193]	Time  1.066 ( 1.444)	Data  0.001 ( 0.311)	Loss 1.2894e-01 (1.2794e-01) 
2023-05-25 01:10:00.190764: train Epoch: [12][ 40/193]	Time  1.833 ( 1.453)	Data  0.721 ( 0.321)	Loss 1.0589e-01 (1.2740e-01) 
2023-05-25 01:10:01.280320: train Epoch: [12][ 41/193]	Time  1.090 ( 1.445)	Data  0.001 ( 0.313)	Loss 7.8542e-02 (1.2624e-01) 
2023-05-25 01:10:02.993400: train Epoch: [12][ 42/193]	Time  1.713 ( 1.451)	Data  0.543 ( 0.318)	Loss 1.3134e-01 (1.2636e-01) 
2023-05-25 01:10:04.107328: train Epoch: [12][ 43/193]	Time  1.114 ( 1.443)	Data  0.001 ( 0.311)	Loss 1.2551e-01 (1.2634e-01) 
2023-05-25 01:10:06.012010: train Epoch: [12][ 44/193]	Time  1.905 ( 1.453)	Data  0.456 ( 0.314)	Loss 8.4574e-02 (1.2541e-01) 
2023-05-25 01:10:07.086414: train Epoch: [12][ 45/193]	Time  1.074 ( 1.445)	Data  0.001 ( 0.308)	Loss 1.2597e-01 (1.2542e-01) 
2023-05-25 01:10:08.365567: train Epoch: [12][ 46/193]	Time  1.279 ( 1.442)	Data  0.255 ( 0.306)	Loss 1.3023e-01 (1.2552e-01) 
2023-05-25 01:10:09.634429: train Epoch: [12][ 47/193]	Time  1.269 ( 1.438)	Data  0.001 ( 0.300)	Loss 1.0095e-01 (1.2501e-01) 
2023-05-25 01:10:11.188870: train Epoch: [12][ 48/193]	Time  1.554 ( 1.440)	Data  0.423 ( 0.303)	Loss 7.3603e-02 (1.2396e-01) 
2023-05-25 01:10:12.387481: train Epoch: [12][ 49/193]	Time  1.199 ( 1.436)	Data  0.001 ( 0.297)	Loss 1.2308e-01 (1.2395e-01) 
2023-05-25 01:10:14.038475: train Epoch: [12][ 50/193]	Time  1.651 ( 1.440)	Data  0.510 ( 0.301)	Loss 1.0951e-01 (1.2366e-01) 
2023-05-25 01:10:15.303662: train Epoch: [12][ 51/193]	Time  1.265 ( 1.436)	Data  0.001 ( 0.295)	Loss 1.1496e-01 (1.2349e-01) 
2023-05-25 01:10:16.903934: train Epoch: [12][ 52/193]	Time  1.600 ( 1.439)	Data  0.373 ( 0.296)	Loss 2.2568e-01 (1.2542e-01) 
2023-05-25 01:10:18.232522: train Epoch: [12][ 53/193]	Time  1.329 ( 1.437)	Data  0.001 ( 0.291)	Loss 9.2863e-02 (1.2482e-01) 
2023-05-25 01:10:19.628541: train Epoch: [12][ 54/193]	Time  1.396 ( 1.437)	Data  0.340 ( 0.292)	Loss 1.3113e-01 (1.2493e-01) 
2023-05-25 01:10:20.689583: train Epoch: [12][ 55/193]	Time  1.061 ( 1.430)	Data  0.001 ( 0.287)	Loss 1.2372e-01 (1.2491e-01) 
2023-05-25 01:10:22.549249: train Epoch: [12][ 56/193]	Time  1.860 ( 1.438)	Data  0.714 ( 0.294)	Loss 9.3409e-02 (1.2436e-01) 
2023-05-25 01:10:23.599113: train Epoch: [12][ 57/193]	Time  1.050 ( 1.431)	Data  0.001 ( 0.289)	Loss 8.2904e-02 (1.2365e-01) 
2023-05-25 01:10:25.211085: train Epoch: [12][ 58/193]	Time  1.612 ( 1.434)	Data  0.589 ( 0.294)	Loss 1.2072e-01 (1.2360e-01) 
2023-05-25 01:10:26.234318: train Epoch: [12][ 59/193]	Time  1.023 ( 1.427)	Data  0.001 ( 0.289)	Loss 1.0088e-01 (1.2322e-01) 
2023-05-25 01:10:28.181890: train Epoch: [12][ 60/193]	Time  1.948 ( 1.436)	Data  0.664 ( 0.295)	Loss 7.6749e-02 (1.2246e-01) 
2023-05-25 01:10:29.241955: train Epoch: [12][ 61/193]	Time  1.060 ( 1.430)	Data  0.001 ( 0.291)	Loss 1.5895e-01 (1.2304e-01) 
2023-05-25 01:10:30.931098: train Epoch: [12][ 62/193]	Time  1.689 ( 1.434)	Data  0.499 ( 0.294)	Loss 1.5723e-01 (1.2359e-01) 
2023-05-25 01:10:31.956120: train Epoch: [12][ 63/193]	Time  1.025 ( 1.427)	Data  0.001 ( 0.289)	Loss 2.2394e-01 (1.2515e-01) 
2023-05-25 01:10:33.994634: train Epoch: [12][ 64/193]	Time  2.039 ( 1.437)	Data  0.654 ( 0.295)	Loss 1.3182e-01 (1.2526e-01) 
2023-05-25 01:10:35.088251: train Epoch: [12][ 65/193]	Time  1.094 ( 1.431)	Data  0.001 ( 0.291)	Loss 1.7643e-01 (1.2603e-01) 
2023-05-25 01:10:36.356107: train Epoch: [12][ 66/193]	Time  1.268 ( 1.429)	Data  0.276 ( 0.290)	Loss 9.8487e-02 (1.2562e-01) 
2023-05-25 01:10:37.374462: train Epoch: [12][ 67/193]	Time  1.018 ( 1.423)	Data  0.001 ( 0.286)	Loss 1.5694e-01 (1.2608e-01) 
2023-05-25 01:10:39.356204: train Epoch: [12][ 68/193]	Time  1.982 ( 1.431)	Data  0.824 ( 0.294)	Loss 8.0559e-02 (1.2542e-01) 
2023-05-25 01:10:40.501232: train Epoch: [12][ 69/193]	Time  1.145 ( 1.427)	Data  0.001 ( 0.290)	Loss 1.5323e-01 (1.2582e-01) 
2023-05-25 01:10:42.174400: train Epoch: [12][ 70/193]	Time  1.673 ( 1.430)	Data  0.538 ( 0.293)	Loss 7.2755e-02 (1.2507e-01) 
2023-05-25 01:10:43.333238: train Epoch: [12][ 71/193]	Time  1.159 ( 1.427)	Data  0.001 ( 0.289)	Loss 8.9256e-02 (1.2457e-01) 
2023-05-25 01:10:44.934211: train Epoch: [12][ 72/193]	Time  1.601 ( 1.429)	Data  0.450 ( 0.291)	Loss 1.0145e-01 (1.2426e-01) 
2023-05-25 01:10:46.021706: train Epoch: [12][ 73/193]	Time  1.088 ( 1.424)	Data  0.002 ( 0.287)	Loss 1.0369e-01 (1.2398e-01) 
2023-05-25 01:10:47.427418: train Epoch: [12][ 74/193]	Time  1.406 ( 1.424)	Data  0.543 ( 0.291)	Loss 2.0940e-01 (1.2512e-01) 
2023-05-25 01:10:48.479488: train Epoch: [12][ 75/193]	Time  1.052 ( 1.419)	Data  0.001 ( 0.287)	Loss 1.1539e-01 (1.2499e-01) 
2023-05-25 01:10:50.465652: train Epoch: [12][ 76/193]	Time  1.986 ( 1.427)	Data  0.892 ( 0.295)	Loss 1.5720e-01 (1.2541e-01) 
2023-05-25 01:10:51.518355: train Epoch: [12][ 77/193]	Time  1.053 ( 1.422)	Data  0.001 ( 0.291)	Loss 9.1283e-02 (1.2497e-01) 
2023-05-25 01:10:53.123276: train Epoch: [12][ 78/193]	Time  1.605 ( 1.424)	Data  0.641 ( 0.296)	Loss 1.3256e-01 (1.2507e-01) 
2023-05-25 01:10:54.115816: train Epoch: [12][ 79/193]	Time  0.993 ( 1.419)	Data  0.001 ( 0.292)	Loss 9.1799e-02 (1.2465e-01) 
2023-05-25 01:10:56.312011: train Epoch: [12][ 80/193]	Time  2.196 ( 1.428)	Data  0.819 ( 0.298)	Loss 1.1218e-01 (1.2450e-01) 
2023-05-25 01:10:57.426775: train Epoch: [12][ 81/193]	Time  1.115 ( 1.425)	Data  0.001 ( 0.295)	Loss 1.0534e-01 (1.2426e-01) 
2023-05-25 01:10:58.828798: train Epoch: [12][ 82/193]	Time  1.402 ( 1.424)	Data  0.237 ( 0.294)	Loss 8.2343e-02 (1.2376e-01) 
2023-05-25 01:10:59.808979: train Epoch: [12][ 83/193]	Time  0.980 ( 1.419)	Data  0.001 ( 0.291)	Loss 1.2812e-01 (1.2381e-01) 
2023-05-25 01:11:01.655651: train Epoch: [12][ 84/193]	Time  1.847 ( 1.424)	Data  0.740 ( 0.296)	Loss 1.3599e-01 (1.2395e-01) 
2023-05-25 01:11:02.935318: train Epoch: [12][ 85/193]	Time  1.280 ( 1.422)	Data  0.001 ( 0.292)	Loss 1.4088e-01 (1.2415e-01) 
2023-05-25 01:11:04.438141: train Epoch: [12][ 86/193]	Time  1.503 ( 1.423)	Data  0.450 ( 0.294)	Loss 1.2031e-01 (1.2411e-01) 
2023-05-25 01:11:05.636679: train Epoch: [12][ 87/193]	Time  1.199 ( 1.421)	Data  0.001 ( 0.291)	Loss 1.1980e-01 (1.2406e-01) 
2023-05-25 01:11:07.600935: train Epoch: [12][ 88/193]	Time  1.964 ( 1.427)	Data  0.647 ( 0.295)	Loss 8.0831e-02 (1.2357e-01) 
2023-05-25 01:11:08.794509: train Epoch: [12][ 89/193]	Time  1.194 ( 1.424)	Data  0.001 ( 0.292)	Loss 1.2848e-01 (1.2363e-01) 
2023-05-25 01:11:10.176309: train Epoch: [12][ 90/193]	Time  1.382 ( 1.424)	Data  0.284 ( 0.292)	Loss 1.0974e-01 (1.2347e-01) 
2023-05-25 01:11:11.193078: train Epoch: [12][ 91/193]	Time  1.017 ( 1.419)	Data  0.001 ( 0.288)	Loss 2.6512e-01 (1.2501e-01) 
2023-05-25 01:11:13.042961: train Epoch: [12][ 92/193]	Time  1.850 ( 1.424)	Data  0.645 ( 0.292)	Loss 4.3601e-01 (1.2836e-01) 
2023-05-25 01:11:14.084030: train Epoch: [12][ 93/193]	Time  1.041 ( 1.420)	Data  0.001 ( 0.289)	Loss 1.1136e-01 (1.2818e-01) 
2023-05-25 01:11:15.648269: train Epoch: [12][ 94/193]	Time  1.564 ( 1.421)	Data  0.540 ( 0.292)	Loss 1.3216e-01 (1.2822e-01) 
2023-05-25 01:11:16.762070: train Epoch: [12][ 95/193]	Time  1.114 ( 1.418)	Data  0.001 ( 0.289)	Loss 1.5255e-01 (1.2847e-01) 
2023-05-25 01:11:18.352453: train Epoch: [12][ 96/193]	Time  1.590 ( 1.420)	Data  0.601 ( 0.292)	Loss 9.1669e-02 (1.2809e-01) 
2023-05-25 01:11:19.376658: train Epoch: [12][ 97/193]	Time  1.024 ( 1.416)	Data  0.001 ( 0.289)	Loss 1.2724e-01 (1.2808e-01) 
2023-05-25 01:11:21.665124: train Epoch: [12][ 98/193]	Time  2.288 ( 1.425)	Data  0.824 ( 0.294)	Loss 8.3548e-02 (1.2763e-01) 
2023-05-25 01:11:22.743881: train Epoch: [12][ 99/193]	Time  1.079 ( 1.421)	Data  0.001 ( 0.291)	Loss 1.1652e-01 (1.2752e-01) 
2023-05-25 01:11:23.940315: train Epoch: [12][100/193]	Time  1.196 ( 1.419)	Data  0.191 ( 0.290)	Loss 1.8112e-01 (1.2805e-01) 
2023-05-25 01:11:25.019063: train Epoch: [12][101/193]	Time  1.079 ( 1.416)	Data  0.001 ( 0.288)	Loss 1.7661e-01 (1.2853e-01) 
2023-05-25 01:11:26.862707: train Epoch: [12][102/193]	Time  1.844 ( 1.420)	Data  0.652 ( 0.291)	Loss 2.1201e-01 (1.2934e-01) 
2023-05-25 01:11:27.870823: train Epoch: [12][103/193]	Time  1.008 ( 1.416)	Data  0.001 ( 0.288)	Loss 4.1272e-01 (1.3207e-01) 
2023-05-25 01:11:29.396496: train Epoch: [12][104/193]	Time  1.526 ( 1.417)	Data  0.509 ( 0.290)	Loss 1.2667e-01 (1.3201e-01) 
2023-05-25 01:11:30.430255: train Epoch: [12][105/193]	Time  1.034 ( 1.413)	Data  0.001 ( 0.288)	Loss 1.0779e-01 (1.3179e-01) 
2023-05-25 01:11:32.305552: train Epoch: [12][106/193]	Time  1.875 ( 1.418)	Data  0.670 ( 0.291)	Loss 1.8882e-01 (1.3232e-01) 
2023-05-25 01:11:33.254746: train Epoch: [12][107/193]	Time  0.949 ( 1.413)	Data  0.001 ( 0.289)	Loss 1.2504e-01 (1.3225e-01) 
2023-05-25 01:11:34.786939: train Epoch: [12][108/193]	Time  1.532 ( 1.414)	Data  0.614 ( 0.292)	Loss 1.1298e-01 (1.3207e-01) 
2023-05-25 01:11:35.762250: train Epoch: [12][109/193]	Time  0.975 ( 1.410)	Data  0.001 ( 0.289)	Loss 9.5326e-02 (1.3174e-01) 
2023-05-25 01:11:37.685383: train Epoch: [12][110/193]	Time  1.923 ( 1.415)	Data  0.763 ( 0.293)	Loss 9.8974e-02 (1.3144e-01) 
2023-05-25 01:11:38.676677: train Epoch: [12][111/193]	Time  0.991 ( 1.411)	Data  0.001 ( 0.291)	Loss 1.0065e-01 (1.3117e-01) 
2023-05-25 01:11:40.762043: train Epoch: [12][112/193]	Time  2.085 ( 1.417)	Data  0.666 ( 0.294)	Loss 1.4156e-01 (1.3126e-01) 
2023-05-25 01:11:41.802748: train Epoch: [12][113/193]	Time  1.041 ( 1.414)	Data  0.001 ( 0.291)	Loss 3.0535e-01 (1.3279e-01) 
2023-05-25 01:11:43.040010: train Epoch: [12][114/193]	Time  1.237 ( 1.412)	Data  0.214 ( 0.291)	Loss 1.9056e-01 (1.3329e-01) 
2023-05-25 01:11:44.250852: train Epoch: [12][115/193]	Time  1.211 ( 1.411)	Data  0.001 ( 0.288)	Loss 1.9056e-01 (1.3379e-01) 
2023-05-25 01:11:45.720134: train Epoch: [12][116/193]	Time  1.469 ( 1.411)	Data  0.430 ( 0.289)	Loss 1.2877e-01 (1.3374e-01) 
2023-05-25 01:11:47.007223: train Epoch: [12][117/193]	Time  1.287 ( 1.410)	Data  0.001 ( 0.287)	Loss 1.1861e-01 (1.3361e-01) 
2023-05-25 01:11:48.465839: train Epoch: [12][118/193]	Time  1.459 ( 1.411)	Data  0.243 ( 0.287)	Loss 7.9959e-02 (1.3316e-01) 
2023-05-25 01:11:49.534876: train Epoch: [12][119/193]	Time  1.069 ( 1.408)	Data  0.002 ( 0.284)	Loss 2.3308e-01 (1.3400e-01) 
2023-05-25 01:11:50.971431: train Epoch: [12][120/193]	Time  1.437 ( 1.408)	Data  0.402 ( 0.285)	Loss 6.5612e-02 (1.3343e-01) 
2023-05-25 01:11:51.950130: train Epoch: [12][121/193]	Time  0.979 ( 1.404)	Data  0.001 ( 0.283)	Loss 1.2604e-01 (1.3337e-01) 
2023-05-25 01:11:53.686539: train Epoch: [12][122/193]	Time  1.736 ( 1.407)	Data  0.655 ( 0.286)	Loss 1.2576e-01 (1.3331e-01) 
2023-05-25 01:11:54.788643: train Epoch: [12][123/193]	Time  1.102 ( 1.405)	Data  0.064 ( 0.284)	Loss 8.9923e-02 (1.3296e-01) 
2023-05-25 01:11:56.657397: train Epoch: [12][124/193]	Time  1.869 ( 1.408)	Data  0.583 ( 0.287)	Loss 1.0294e-01 (1.3272e-01) 
2023-05-25 01:11:57.687889: train Epoch: [12][125/193]	Time  1.030 ( 1.405)	Data  0.001 ( 0.284)	Loss 1.9312e-01 (1.3320e-01) 
2023-05-25 01:11:59.384907: train Epoch: [12][126/193]	Time  1.697 ( 1.408)	Data  0.447 ( 0.286)	Loss 2.6914e-01 (1.3427e-01) 
2023-05-25 01:12:00.425614: train Epoch: [12][127/193]	Time  1.041 ( 1.405)	Data  0.001 ( 0.283)	Loss 8.1584e-02 (1.3386e-01) 
2023-05-25 01:12:02.023610: train Epoch: [12][128/193]	Time  1.598 ( 1.406)	Data  0.499 ( 0.285)	Loss 7.7728e-02 (1.3342e-01) 
2023-05-25 01:12:03.262599: train Epoch: [12][129/193]	Time  1.239 ( 1.405)	Data  0.001 ( 0.283)	Loss 1.0738e-01 (1.3322e-01) 
2023-05-25 01:12:04.831529: train Epoch: [12][130/193]	Time  1.569 ( 1.406)	Data  0.427 ( 0.284)	Loss 2.7530e-01 (1.3431e-01) 
2023-05-25 01:12:05.833799: train Epoch: [12][131/193]	Time  1.002 ( 1.403)	Data  0.001 ( 0.282)	Loss 8.7356e-02 (1.3395e-01) 
2023-05-25 01:12:07.706841: train Epoch: [12][132/193]	Time  1.873 ( 1.407)	Data  0.787 ( 0.286)	Loss 1.4982e-01 (1.3407e-01) 
2023-05-25 01:12:08.886127: train Epoch: [12][133/193]	Time  1.179 ( 1.405)	Data  0.020 ( 0.284)	Loss 1.3983e-01 (1.3411e-01) 
2023-05-25 01:12:10.474021: train Epoch: [12][134/193]	Time  1.588 ( 1.406)	Data  0.527 ( 0.285)	Loss 1.4978e-01 (1.3423e-01) 
2023-05-25 01:12:11.552650: train Epoch: [12][135/193]	Time  1.079 ( 1.404)	Data  0.069 ( 0.284)	Loss 9.7336e-02 (1.3396e-01) 
2023-05-25 01:12:13.533193: train Epoch: [12][136/193]	Time  1.981 ( 1.408)	Data  0.899 ( 0.288)	Loss 1.1899e-01 (1.3385e-01) 
2023-05-25 01:12:14.647855: train Epoch: [12][137/193]	Time  1.115 ( 1.406)	Data  0.001 ( 0.286)	Loss 1.7204e-01 (1.3412e-01) 
2023-05-25 01:12:16.560607: train Epoch: [12][138/193]	Time  1.913 ( 1.410)	Data  0.759 ( 0.290)	Loss 2.0165e-01 (1.3461e-01) 
2023-05-25 01:12:17.698598: train Epoch: [12][139/193]	Time  1.138 ( 1.408)	Data  0.001 ( 0.288)	Loss 1.5383e-01 (1.3475e-01) 
2023-05-25 01:12:19.410478: train Epoch: [12][140/193]	Time  1.712 ( 1.410)	Data  0.654 ( 0.290)	Loss 9.7522e-02 (1.3448e-01) 
2023-05-25 01:12:20.439428: train Epoch: [12][141/193]	Time  1.029 ( 1.407)	Data  0.001 ( 0.288)	Loss 1.3451e-01 (1.3448e-01) 
2023-05-25 01:12:22.258145: train Epoch: [12][142/193]	Time  1.819 ( 1.410)	Data  0.743 ( 0.291)	Loss 1.6385e-01 (1.3469e-01) 
2023-05-25 01:12:23.345122: train Epoch: [12][143/193]	Time  1.087 ( 1.408)	Data  0.001 ( 0.289)	Loss 2.2072e-01 (1.3529e-01) 
2023-05-25 01:12:24.979152: train Epoch: [12][144/193]	Time  1.634 ( 1.409)	Data  0.539 ( 0.291)	Loss 8.6476e-02 (1.3495e-01) 
2023-05-25 01:12:26.024522: train Epoch: [12][145/193]	Time  1.045 ( 1.407)	Data  0.001 ( 0.289)	Loss 2.0466e-01 (1.3543e-01) 
2023-05-25 01:12:28.002791: train Epoch: [12][146/193]	Time  1.978 ( 1.411)	Data  0.718 ( 0.292)	Loss 1.4344e-01 (1.3548e-01) 
2023-05-25 01:12:28.976326: train Epoch: [12][147/193]	Time  0.974 ( 1.408)	Data  0.001 ( 0.290)	Loss 1.4387e-01 (1.3554e-01) 
2023-05-25 01:12:30.943375: train Epoch: [12][148/193]	Time  1.967 ( 1.412)	Data  0.683 ( 0.293)	Loss 1.9557e-01 (1.3594e-01) 
2023-05-25 01:12:31.895097: train Epoch: [12][149/193]	Time  0.952 ( 1.409)	Data  0.001 ( 0.291)	Loss 1.9527e-01 (1.3634e-01) 
2023-05-25 01:12:33.758783: train Epoch: [12][150/193]	Time  1.864 ( 1.412)	Data  0.611 ( 0.293)	Loss 1.3171e-01 (1.3631e-01) 
2023-05-25 01:12:34.736915: train Epoch: [12][151/193]	Time  0.978 ( 1.409)	Data  0.001 ( 0.291)	Loss 9.6200e-02 (1.3604e-01) 
2023-05-25 01:12:36.669709: train Epoch: [12][152/193]	Time  1.933 ( 1.412)	Data  0.609 ( 0.293)	Loss 1.2647e-01 (1.3598e-01) 
2023-05-25 01:12:37.766696: train Epoch: [12][153/193]	Time  1.097 ( 1.410)	Data  0.001 ( 0.291)	Loss 1.3302e-01 (1.3596e-01) 
2023-05-25 01:12:39.463177: train Epoch: [12][154/193]	Time  1.696 ( 1.412)	Data  0.396 ( 0.292)	Loss 1.4077e-01 (1.3599e-01) 
2023-05-25 01:12:40.569951: train Epoch: [12][155/193]	Time  1.107 ( 1.410)	Data  0.001 ( 0.290)	Loss 2.7989e-01 (1.3691e-01) 
2023-05-25 01:12:42.127412: train Epoch: [12][156/193]	Time  1.557 ( 1.411)	Data  0.330 ( 0.290)	Loss 2.2651e-01 (1.3748e-01) 
2023-05-25 01:12:43.440827: train Epoch: [12][157/193]	Time  1.313 ( 1.410)	Data  0.001 ( 0.288)	Loss 8.1833e-02 (1.3713e-01) 
2023-05-25 01:12:44.658162: train Epoch: [12][158/193]	Time  1.217 ( 1.409)	Data  0.207 ( 0.288)	Loss 1.1174e-01 (1.3697e-01) 
2023-05-25 01:12:45.714327: train Epoch: [12][159/193]	Time  1.056 ( 1.407)	Data  0.001 ( 0.286)	Loss 1.8003e-01 (1.3724e-01) 
2023-05-25 01:12:47.476051: train Epoch: [12][160/193]	Time  1.762 ( 1.409)	Data  0.734 ( 0.289)	Loss 1.6068e-01 (1.3739e-01) 
2023-05-25 01:12:48.579763: train Epoch: [12][161/193]	Time  1.104 ( 1.407)	Data  0.001 ( 0.287)	Loss 1.4250e-01 (1.3742e-01) 
2023-05-25 01:12:50.322898: train Epoch: [12][162/193]	Time  1.743 ( 1.409)	Data  0.650 ( 0.289)	Loss 1.2671e-01 (1.3735e-01) 
2023-05-25 01:12:51.355065: train Epoch: [12][163/193]	Time  1.032 ( 1.407)	Data  0.001 ( 0.287)	Loss 5.2535e-02 (1.3684e-01) 
2023-05-25 01:12:53.525583: train Epoch: [12][164/193]	Time  2.171 ( 1.412)	Data  0.719 ( 0.290)	Loss 1.8067e-01 (1.3710e-01) 
2023-05-25 01:12:54.634457: train Epoch: [12][165/193]	Time  1.109 ( 1.410)	Data  0.001 ( 0.288)	Loss 1.1636e-01 (1.3698e-01) 
2023-05-25 01:12:55.800577: train Epoch: [12][166/193]	Time  1.166 ( 1.408)	Data  0.192 ( 0.288)	Loss 4.0138e-01 (1.3856e-01) 
2023-05-25 01:12:56.845986: train Epoch: [12][167/193]	Time  1.045 ( 1.406)	Data  0.001 ( 0.286)	Loss 2.2234e-01 (1.3906e-01) 
2023-05-25 01:12:58.659531: train Epoch: [12][168/193]	Time  1.814 ( 1.409)	Data  0.737 ( 0.289)	Loss 6.8926e-02 (1.3864e-01) 
2023-05-25 01:12:59.661173: train Epoch: [12][169/193]	Time  1.002 ( 1.406)	Data  0.001 ( 0.287)	Loss 7.6185e-02 (1.3828e-01) 
2023-05-25 01:13:01.716162: train Epoch: [12][170/193]	Time  2.055 ( 1.410)	Data  0.772 ( 0.290)	Loss 1.0792e-01 (1.3810e-01) 
2023-05-25 01:13:02.964047: train Epoch: [12][171/193]	Time  1.248 ( 1.409)	Data  0.001 ( 0.288)	Loss 1.4347e-01 (1.3813e-01) 
2023-05-25 01:13:04.271072: train Epoch: [12][172/193]	Time  1.307 ( 1.408)	Data  0.231 ( 0.288)	Loss 1.5032e-01 (1.3820e-01) 
2023-05-25 01:13:05.481538: train Epoch: [12][173/193]	Time  1.210 ( 1.407)	Data  0.001 ( 0.286)	Loss 1.0125e-01 (1.3799e-01) 
2023-05-25 01:13:07.104196: train Epoch: [12][174/193]	Time  1.623 ( 1.409)	Data  0.530 ( 0.288)	Loss 1.1137e-01 (1.3784e-01) 
2023-05-25 01:13:08.171026: train Epoch: [12][175/193]	Time  1.067 ( 1.407)	Data  0.001 ( 0.286)	Loss 1.2533e-01 (1.3777e-01) 
2023-05-25 01:13:10.079617: train Epoch: [12][176/193]	Time  1.909 ( 1.409)	Data  0.809 ( 0.289)	Loss 9.8862e-02 (1.3755e-01) 
2023-05-25 01:13:11.124538: train Epoch: [12][177/193]	Time  1.045 ( 1.407)	Data  0.001 ( 0.287)	Loss 7.3317e-02 (1.3718e-01) 
2023-05-25 01:13:12.975561: train Epoch: [12][178/193]	Time  1.851 ( 1.410)	Data  0.711 ( 0.290)	Loss 1.3363e-01 (1.3716e-01) 
2023-05-25 01:13:13.928383: train Epoch: [12][179/193]	Time  0.953 ( 1.407)	Data  0.001 ( 0.288)	Loss 1.0104e-01 (1.3696e-01) 
2023-05-25 01:13:15.968134: train Epoch: [12][180/193]	Time  2.040 ( 1.411)	Data  0.732 ( 0.291)	Loss 1.4268e-01 (1.3700e-01) 
2023-05-25 01:13:16.930459: train Epoch: [12][181/193]	Time  0.962 ( 1.408)	Data  0.001 ( 0.289)	Loss 1.1689e-01 (1.3689e-01) 
2023-05-25 01:13:18.717376: train Epoch: [12][182/193]	Time  1.787 ( 1.410)	Data  0.537 ( 0.290)	Loss 1.2220e-01 (1.3680e-01) 
2023-05-25 01:13:19.795184: train Epoch: [12][183/193]	Time  1.078 ( 1.409)	Data  0.001 ( 0.289)	Loss 1.9850e-01 (1.3714e-01) 
2023-05-25 01:13:21.688809: train Epoch: [12][184/193]	Time  1.894 ( 1.411)	Data  0.614 ( 0.290)	Loss 9.2385e-02 (1.3690e-01) 
2023-05-25 01:13:22.672129: train Epoch: [12][185/193]	Time  0.983 ( 1.409)	Data  0.001 ( 0.289)	Loss 1.8855e-01 (1.3718e-01) 
2023-05-25 01:13:24.547184: train Epoch: [12][186/193]	Time  1.875 ( 1.411)	Data  0.596 ( 0.291)	Loss 2.4666e-01 (1.3776e-01) 
2023-05-25 01:13:25.660434: train Epoch: [12][187/193]	Time  1.113 ( 1.410)	Data  0.001 ( 0.289)	Loss 2.1315e-01 (1.3816e-01) 
2023-05-25 01:13:27.129586: train Epoch: [12][188/193]	Time  1.469 ( 1.410)	Data  0.285 ( 0.289)	Loss 1.1912e-01 (1.3806e-01) 
2023-05-25 01:13:28.290975: train Epoch: [12][189/193]	Time  1.161 ( 1.409)	Data  0.001 ( 0.287)	Loss 1.0473e-01 (1.3789e-01) 
2023-05-25 01:13:29.360301: train Epoch: [12][190/193]	Time  1.069 ( 1.407)	Data  0.090 ( 0.286)	Loss 1.2298e-01 (1.3781e-01) 
2023-05-25 01:13:30.423080: train Epoch: [12][191/193]	Time  1.063 ( 1.405)	Data  0.001 ( 0.285)	Loss 6.4341e-02 (1.3743e-01) 
2023-05-25 01:13:31.488356: train Epoch: [12][192/193]	Time  1.065 ( 1.404)	Data  0.079 ( 0.284)	Loss 1.1481e-01 (1.3731e-01) 
2023-05-25 01:13:31.552883: Train Epoch done in 270.94291024899576 s 
2023-05-25 01:13:34.613506: val Epoch: [12][ 0/72]	Time  2.006 ( 2.006)	Data  1.624 ( 1.624)	Loss 6.1079e-02 (6.1079e-02) 
2023-05-25 01:13:34.874438: val Epoch: [12][ 1/72]	Time  0.261 ( 1.134)	Data  0.002 ( 0.813)	Loss 1.3011e-01 (9.5592e-02) 
2023-05-25 01:13:36.119407: val Epoch: [12][ 2/72]	Time  1.245 ( 1.171)	Data  0.786 ( 0.804)	Loss 2.4629e-01 (1.4582e-01) 
2023-05-25 01:13:36.541262: val Epoch: [12][ 3/72]	Time  0.422 ( 0.984)	Data  0.001 ( 0.603)	Loss 3.7577e-01 (2.0331e-01) 
2023-05-25 01:13:37.422692: val Epoch: [12][ 4/72]	Time  0.881 ( 0.963)	Data  0.576 ( 0.598)	Loss 7.8315e-02 (1.7831e-01) 
2023-05-25 01:13:37.791172: val Epoch: [12][ 5/72]	Time  0.368 ( 0.864)	Data  0.002 ( 0.499)	Loss 1.2514e-01 (1.6945e-01) 
2023-05-25 01:13:38.857583: val Epoch: [12][ 6/72]	Time  1.066 ( 0.893)	Data  0.769 ( 0.537)	Loss 1.6033e-01 (1.6815e-01) 
2023-05-25 01:13:39.135517: val Epoch: [12][ 7/72]	Time  0.278 ( 0.816)	Data  0.001 ( 0.470)	Loss 1.0445e-01 (1.6019e-01) 
2023-05-25 01:13:40.362484: val Epoch: [12][ 8/72]	Time  1.227 ( 0.862)	Data  0.900 ( 0.518)	Loss 1.5551e-01 (1.5967e-01) 
2023-05-25 01:13:40.547128: val Epoch: [12][ 9/72]	Time  0.185 ( 0.794)	Data  0.001 ( 0.466)	Loss 2.3154e-01 (1.6685e-01) 
2023-05-25 01:13:41.835073: val Epoch: [12][10/72]	Time  1.288 ( 0.839)	Data  0.933 ( 0.509)	Loss 1.8675e-01 (1.6866e-01) 
2023-05-25 01:13:42.126933: val Epoch: [12][11/72]	Time  0.292 ( 0.793)	Data  0.001 ( 0.466)	Loss 7.3055e-02 (1.6069e-01) 
2023-05-25 01:13:43.308142: val Epoch: [12][12/72]	Time  1.181 ( 0.823)	Data  0.768 ( 0.490)	Loss 1.6524e-01 (1.6104e-01) 
2023-05-25 01:13:43.507410: val Epoch: [12][13/72]	Time  0.199 ( 0.779)	Data  0.001 ( 0.455)	Loss 1.6222e-01 (1.6113e-01) 
2023-05-25 01:13:44.780578: val Epoch: [12][14/72]	Time  1.273 ( 0.812)	Data  0.797 ( 0.478)	Loss 7.4647e-02 (1.5536e-01) 
2023-05-25 01:13:45.222491: val Epoch: [12][15/72]	Time  0.442 ( 0.788)	Data  0.001 ( 0.448)	Loss 4.7837e-01 (1.7555e-01) 
2023-05-25 01:13:46.037010: val Epoch: [12][16/72]	Time  0.815 ( 0.790)	Data  0.422 ( 0.446)	Loss 2.0585e-01 (1.7733e-01) 
2023-05-25 01:13:46.551161: val Epoch: [12][17/72]	Time  0.514 ( 0.775)	Data  0.002 ( 0.422)	Loss 1.0532e-01 (1.7333e-01) 
2023-05-25 01:13:47.333501: val Epoch: [12][18/72]	Time  0.782 ( 0.775)	Data  0.463 ( 0.424)	Loss 8.5544e-02 (1.6871e-01) 
2023-05-25 01:13:47.597177: val Epoch: [12][19/72]	Time  0.264 ( 0.750)	Data  0.001 ( 0.403)	Loss 1.0319e-01 (1.6544e-01) 
2023-05-25 01:13:48.688946: val Epoch: [12][20/72]	Time  1.092 ( 0.766)	Data  0.751 ( 0.419)	Loss 1.0149e-01 (1.6239e-01) 
2023-05-25 01:13:49.108465: val Epoch: [12][21/72]	Time  0.419 ( 0.750)	Data  0.001 ( 0.400)	Loss 7.7166e-02 (1.5852e-01) 
2023-05-25 01:13:50.041872: val Epoch: [12][22/72]	Time  0.933 ( 0.758)	Data  0.644 ( 0.411)	Loss 7.2838e-02 (1.5479e-01) 
2023-05-25 01:13:50.422942: val Epoch: [12][23/72]	Time  0.381 ( 0.742)	Data  0.017 ( 0.394)	Loss 9.8283e-02 (1.5244e-01) 
2023-05-25 01:13:51.632683: val Epoch: [12][24/72]	Time  1.210 ( 0.761)	Data  0.694 ( 0.406)	Loss 7.2939e-02 (1.4926e-01) 
2023-05-25 01:13:51.858865: val Epoch: [12][25/72]	Time  0.226 ( 0.740)	Data  0.001 ( 0.391)	Loss 8.4411e-02 (1.4676e-01) 
2023-05-25 01:13:52.663016: val Epoch: [12][26/72]	Time  0.804 ( 0.743)	Data  0.591 ( 0.398)	Loss 8.7229e-02 (1.4456e-01) 
2023-05-25 01:13:53.276598: val Epoch: [12][27/72]	Time  0.614 ( 0.738)	Data  0.285 ( 0.394)	Loss 2.6866e-01 (1.4899e-01) 
2023-05-25 01:13:54.427253: val Epoch: [12][28/72]	Time  1.151 ( 0.752)	Data  0.676 ( 0.404)	Loss 8.1190e-02 (1.4665e-01) 
2023-05-25 01:13:54.906103: val Epoch: [12][29/72]	Time  0.479 ( 0.743)	Data  0.001 ( 0.390)	Loss 1.1774e-01 (1.4569e-01) 
2023-05-25 01:13:55.827864: val Epoch: [12][30/72]	Time  0.922 ( 0.749)	Data  0.523 ( 0.395)	Loss 4.2173e-01 (1.5459e-01) 
2023-05-25 01:13:56.106539: val Epoch: [12][31/72]	Time  0.279 ( 0.734)	Data  0.001 ( 0.382)	Loss 1.8519e-01 (1.5555e-01) 
2023-05-25 01:13:57.398916: val Epoch: [12][32/72]	Time  1.292 ( 0.751)	Data  0.744 ( 0.393)	Loss 9.0473e-02 (1.5358e-01) 
2023-05-25 01:13:57.778620: val Epoch: [12][33/72]	Time  0.380 ( 0.740)	Data  0.002 ( 0.382)	Loss 1.9290e-01 (1.5473e-01) 
2023-05-25 01:13:58.807828: val Epoch: [12][34/72]	Time  1.029 ( 0.749)	Data  0.500 ( 0.385)	Loss 9.9334e-02 (1.5315e-01) 
2023-05-25 01:13:59.083133: val Epoch: [12][35/72]	Time  0.275 ( 0.735)	Data  0.001 ( 0.374)	Loss 8.0187e-02 (1.5112e-01) 
2023-05-25 01:13:59.966656: val Epoch: [12][36/72]	Time  0.883 ( 0.739)	Data  0.552 ( 0.379)	Loss 2.5267e-01 (1.5387e-01) 
2023-05-25 01:14:00.211771: val Epoch: [12][37/72]	Time  0.245 ( 0.726)	Data  0.001 ( 0.369)	Loss 7.7767e-02 (1.5187e-01) 
2023-05-25 01:14:01.632857: val Epoch: [12][38/72]	Time  1.421 ( 0.744)	Data  0.878 ( 0.382)	Loss 5.7472e-01 (1.6271e-01) 
2023-05-25 01:14:02.029927: val Epoch: [12][39/72]	Time  0.397 ( 0.736)	Data  0.001 ( 0.373)	Loss 1.9539e-01 (1.6352e-01) 
2023-05-25 01:14:02.707973: val Epoch: [12][40/72]	Time  0.678 ( 0.734)	Data  0.419 ( 0.374)	Loss 7.2671e-02 (1.6131e-01) 
2023-05-25 01:14:03.308905: val Epoch: [12][41/72]	Time  0.601 ( 0.731)	Data  0.078 ( 0.367)	Loss 3.4708e-01 (1.6573e-01) 
2023-05-25 01:14:04.166039: val Epoch: [12][42/72]	Time  0.857 ( 0.734)	Data  0.561 ( 0.371)	Loss 3.5513e-01 (1.7014e-01) 
2023-05-25 01:14:04.565096: val Epoch: [12][43/72]	Time  0.399 ( 0.726)	Data  0.100 ( 0.365)	Loss 1.7541e-01 (1.7026e-01) 
2023-05-25 01:14:05.748161: val Epoch: [12][44/72]	Time  1.183 ( 0.736)	Data  0.733 ( 0.373)	Loss 1.0476e-01 (1.6880e-01) 
2023-05-25 01:14:05.964020: val Epoch: [12][45/72]	Time  0.216 ( 0.725)	Data  0.001 ( 0.365)	Loss 2.4147e-01 (1.7038e-01) 
2023-05-25 01:14:07.259625: val Epoch: [12][46/72]	Time  1.296 ( 0.737)	Data  0.772 ( 0.374)	Loss 1.5961e-01 (1.7015e-01) 
2023-05-25 01:14:07.687581: val Epoch: [12][47/72]	Time  0.428 ( 0.731)	Data  0.002 ( 0.366)	Loss 2.1038e-01 (1.7099e-01) 
2023-05-25 01:14:08.604734: val Epoch: [12][48/72]	Time  0.917 ( 0.735)	Data  0.535 ( 0.370)	Loss 1.2630e-01 (1.7008e-01) 
2023-05-25 01:14:08.817210: val Epoch: [12][49/72]	Time  0.212 ( 0.724)	Data  0.001 ( 0.362)	Loss 9.5703e-02 (1.6859e-01) 
2023-05-25 01:14:09.803576: val Epoch: [12][50/72]	Time  0.986 ( 0.729)	Data  0.762 ( 0.370)	Loss 1.1649e-01 (1.6757e-01) 
2023-05-25 01:14:10.193845: val Epoch: [12][51/72]	Time  0.390 ( 0.723)	Data  0.153 ( 0.366)	Loss 1.7499e-01 (1.6771e-01) 
2023-05-25 01:14:11.327542: val Epoch: [12][52/72]	Time  1.134 ( 0.731)	Data  0.849 ( 0.375)	Loss 1.2968e-01 (1.6699e-01) 
2023-05-25 01:14:11.852354: val Epoch: [12][53/72]	Time  0.525 ( 0.727)	Data  0.031 ( 0.369)	Loss 1.6836e-01 (1.6702e-01) 
2023-05-25 01:14:12.761251: val Epoch: [12][54/72]	Time  0.909 ( 0.730)	Data  0.561 ( 0.372)	Loss 1.4543e-01 (1.6663e-01) 
2023-05-25 01:14:13.124786: val Epoch: [12][55/72]	Time  0.364 ( 0.724)	Data  0.048 ( 0.366)	Loss 3.8663e-01 (1.7056e-01) 
2023-05-25 01:14:14.098342: val Epoch: [12][56/72]	Time  0.974 ( 0.728)	Data  0.666 ( 0.372)	Loss 1.1300e-01 (1.6955e-01) 
2023-05-25 01:14:14.612492: val Epoch: [12][57/72]	Time  0.514 ( 0.724)	Data  0.135 ( 0.368)	Loss 8.7172e-02 (1.6813e-01) 
2023-05-25 01:14:15.672113: val Epoch: [12][58/72]	Time  1.060 ( 0.730)	Data  0.700 ( 0.373)	Loss 1.7657e-01 (1.6827e-01) 
2023-05-25 01:14:15.871881: val Epoch: [12][59/72]	Time  0.200 ( 0.721)	Data  0.001 ( 0.367)	Loss 1.1333e-01 (1.6735e-01) 
2023-05-25 01:14:17.191333: val Epoch: [12][60/72]	Time  1.319 ( 0.731)	Data  0.868 ( 0.375)	Loss 8.9075e-02 (1.6607e-01) 
2023-05-25 01:14:17.417146: val Epoch: [12][61/72]	Time  0.226 ( 0.723)	Data  0.001 ( 0.369)	Loss 1.9214e-01 (1.6649e-01) 
2023-05-25 01:14:18.635193: val Epoch: [12][62/72]	Time  1.218 ( 0.731)	Data  0.868 ( 0.377)	Loss 1.5885e-01 (1.6637e-01) 
2023-05-25 01:14:19.163505: val Epoch: [12][63/72]	Time  0.528 ( 0.727)	Data  0.001 ( 0.371)	Loss 6.8931e-02 (1.6485e-01) 
2023-05-25 01:14:19.894948: val Epoch: [12][64/72]	Time  0.731 ( 0.728)	Data  0.495 ( 0.373)	Loss 1.6502e-01 (1.6485e-01) 
2023-05-25 01:14:20.269937: val Epoch: [12][65/72]	Time  0.375 ( 0.722)	Data  0.001 ( 0.367)	Loss 1.9456e-01 (1.6530e-01) 
2023-05-25 01:14:21.619530: val Epoch: [12][66/72]	Time  1.350 ( 0.732)	Data  0.848 ( 0.375)	Loss 6.8951e-02 (1.6386e-01) 
2023-05-25 01:14:22.048509: val Epoch: [12][67/72]	Time  0.429 ( 0.727)	Data  0.004 ( 0.369)	Loss 4.5660e-01 (1.6817e-01) 
2023-05-25 01:14:22.811424: val Epoch: [12][68/72]	Time  0.763 ( 0.728)	Data  0.548 ( 0.372)	Loss 4.5237e-01 (1.7229e-01) 
2023-05-25 01:14:23.057988: val Epoch: [12][69/72]	Time  0.247 ( 0.721)	Data  0.001 ( 0.366)	Loss 6.2761e-01 (1.7879e-01) 
2023-05-25 01:14:24.313481: val Epoch: [12][70/72]	Time  1.255 ( 0.728)	Data  0.894 ( 0.374)	Loss 8.5276e-02 (1.7747e-01) 
2023-05-25 01:14:24.544109: val Epoch: [12][71/72]	Time  0.231 ( 0.721)	Data  0.001 ( 0.369)	Loss 6.9121e-01 (1.8461e-01) 
2023-05-25 01:14:24.810847: Epoch 12 :Val : ['ET : 0.6713693141937256', 'TC : 0.6912034153938293', 'WT : 0.7953202724456787'] 
2023-05-25 01:14:24.811999: Epoch 12 :Val : ['ET : 0.6713693141937256', 'TC : 0.6912034153938293', 'WT : 0.7953202724456787'] 
2023-05-25 01:14:24.815255: Val epoch done in 53.26237232692074 s 
2023-05-25 01:14:24.834075: Batches per epoch:  193 
2023-05-25 01:14:29.321172: train Epoch: [13][  0/193]	Time  4.487 ( 4.487)	Data  3.248 ( 3.248)	Loss 9.2344e-02 (9.2344e-02) 
2023-05-25 01:14:30.505583: train Epoch: [13][  1/193]	Time  1.184 ( 2.836)	Data  0.001 ( 1.625)	Loss 1.6230e-01 (1.2732e-01) 
2023-05-25 01:14:32.276882: train Epoch: [13][  2/193]	Time  1.771 ( 2.481)	Data  0.478 ( 1.243)	Loss 2.0273e-01 (1.5246e-01) 
2023-05-25 01:14:33.302845: train Epoch: [13][  3/193]	Time  1.026 ( 2.117)	Data  0.001 ( 0.932)	Loss 1.5363e-01 (1.5275e-01) 
2023-05-25 01:14:35.057889: train Epoch: [13][  4/193]	Time  1.755 ( 2.045)	Data  0.430 ( 0.832)	Loss 1.0439e-01 (1.4308e-01) 
2023-05-25 01:14:36.107455: train Epoch: [13][  5/193]	Time  1.050 ( 1.879)	Data  0.001 ( 0.693)	Loss 1.8868e-01 (1.5068e-01) 
2023-05-25 01:14:37.921666: train Epoch: [13][  6/193]	Time  1.814 ( 1.870)	Data  0.507 ( 0.667)	Loss 2.2269e-01 (1.6097e-01) 
2023-05-25 01:14:38.913058: train Epoch: [13][  7/193]	Time  0.991 ( 1.760)	Data  0.001 ( 0.584)	Loss 1.1453e-01 (1.5516e-01) 
2023-05-25 01:14:40.688572: train Epoch: [13][  8/193]	Time  1.776 ( 1.762)	Data  0.726 ( 0.599)	Loss 1.7065e-01 (1.5688e-01) 
2023-05-25 01:14:41.727856: train Epoch: [13][  9/193]	Time  1.039 ( 1.689)	Data  0.001 ( 0.540)	Loss 1.5428e-01 (1.5662e-01) 
2023-05-25 01:14:43.613860: train Epoch: [13][ 10/193]	Time  1.886 ( 1.707)	Data  0.756 ( 0.559)	Loss 1.1412e-01 (1.5276e-01) 
2023-05-25 01:14:44.737535: train Epoch: [13][ 11/193]	Time  1.124 ( 1.659)	Data  0.002 ( 0.513)	Loss 2.5106e-01 (1.6095e-01) 
2023-05-25 01:14:46.437682: train Epoch: [13][ 12/193]	Time  1.700 ( 1.662)	Data  0.714 ( 0.528)	Loss 1.3161e-01 (1.5869e-01) 
2023-05-25 01:14:47.452263: train Epoch: [13][ 13/193]	Time  1.015 ( 1.616)	Data  0.001 ( 0.491)	Loss 1.0277e-01 (1.5470e-01) 
2023-05-25 01:14:49.442394: train Epoch: [13][ 14/193]	Time  1.990 ( 1.641)	Data  0.947 ( 0.521)	Loss 1.0908e-01 (1.5166e-01) 
2023-05-25 01:14:50.518337: train Epoch: [13][ 15/193]	Time  1.076 ( 1.605)	Data  0.001 ( 0.489)	Loss 1.2396e-01 (1.4993e-01) 
2023-05-25 01:14:52.467932: train Epoch: [13][ 16/193]	Time  1.950 ( 1.625)	Data  0.818 ( 0.508)	Loss 1.0200e-01 (1.4711e-01) 
2023-05-25 01:14:53.692965: train Epoch: [13][ 17/193]	Time  1.225 ( 1.603)	Data  0.001 ( 0.480)	Loss 1.6210e-01 (1.4794e-01) 
2023-05-25 01:14:55.118447: train Epoch: [13][ 18/193]	Time  1.425 ( 1.594)	Data  0.401 ( 0.476)	Loss 1.2814e-01 (1.4690e-01) 
2023-05-25 01:14:56.198740: train Epoch: [13][ 19/193]	Time  1.080 ( 1.568)	Data  0.001 ( 0.452)	Loss 8.1153e-02 (1.4361e-01) 
2023-05-25 01:14:57.958122: train Epoch: [13][ 20/193]	Time  1.759 ( 1.577)	Data  0.582 ( 0.458)	Loss 1.5278e-01 (1.4405e-01) 
2023-05-25 01:14:58.971380: train Epoch: [13][ 21/193]	Time  1.013 ( 1.552)	Data  0.001 ( 0.437)	Loss 2.3505e-01 (1.4818e-01) 
2023-05-25 01:15:00.757324: train Epoch: [13][ 22/193]	Time  1.786 ( 1.562)	Data  0.536 ( 0.442)	Loss 1.1223e-01 (1.4662e-01) 
2023-05-25 01:15:01.742103: train Epoch: [13][ 23/193]	Time  0.985 ( 1.538)	Data  0.001 ( 0.423)	Loss 8.8034e-02 (1.4418e-01) 
2023-05-25 01:15:03.323885: train Epoch: [13][ 24/193]	Time  1.582 ( 1.540)	Data  0.501 ( 0.426)	Loss 8.6484e-02 (1.4187e-01) 
2023-05-25 01:15:04.381904: train Epoch: [13][ 25/193]	Time  1.058 ( 1.521)	Data  0.001 ( 0.410)	Loss 1.6667e-01 (1.4283e-01) 
2023-05-25 01:15:06.442144: train Epoch: [13][ 26/193]	Time  2.060 ( 1.541)	Data  0.671 ( 0.420)	Loss 9.7634e-02 (1.4115e-01) 
2023-05-25 01:15:07.561656: train Epoch: [13][ 27/193]	Time  1.119 ( 1.526)	Data  0.001 ( 0.405)	Loss 2.3434e-01 (1.4448e-01) 
2023-05-25 01:15:08.878806: train Epoch: [13][ 28/193]	Time  1.317 ( 1.519)	Data  0.290 ( 0.401)	Loss 1.3727e-01 (1.4423e-01) 
2023-05-25 01:15:10.036728: train Epoch: [13][ 29/193]	Time  1.158 ( 1.507)	Data  0.001 ( 0.387)	Loss 1.3590e-01 (1.4395e-01) 
2023-05-25 01:15:11.779294: train Epoch: [13][ 30/193]	Time  1.743 ( 1.514)	Data  0.658 ( 0.396)	Loss 8.7721e-02 (1.4214e-01) 
2023-05-25 01:15:13.105384: train Epoch: [13][ 31/193]	Time  1.326 ( 1.508)	Data  0.001 ( 0.384)	Loss 7.4104e-02 (1.4001e-01) 
2023-05-25 01:15:14.459785: train Epoch: [13][ 32/193]	Time  1.354 ( 1.504)	Data  0.260 ( 0.380)	Loss 1.9855e-01 (1.4179e-01) 
2023-05-25 01:15:15.630294: train Epoch: [13][ 33/193]	Time  1.171 ( 1.494)	Data  0.001 ( 0.369)	Loss 1.0423e-01 (1.4068e-01) 
2023-05-25 01:15:17.356046: train Epoch: [13][ 34/193]	Time  1.726 ( 1.501)	Data  0.620 ( 0.376)	Loss 9.7728e-02 (1.3946e-01) 
2023-05-25 01:15:18.542921: train Epoch: [13][ 35/193]	Time  1.187 ( 1.492)	Data  0.001 ( 0.366)	Loss 1.3892e-01 (1.3944e-01) 
2023-05-25 01:15:20.171095: train Epoch: [13][ 36/193]	Time  1.628 ( 1.496)	Data  0.545 ( 0.370)	Loss 1.3514e-01 (1.3933e-01) 
2023-05-25 01:15:21.246799: train Epoch: [13][ 37/193]	Time  1.076 ( 1.485)	Data  0.001 ( 0.361)	Loss 1.0323e-01 (1.3838e-01) 
2023-05-25 01:15:22.929607: train Epoch: [13][ 38/193]	Time  1.683 ( 1.490)	Data  0.692 ( 0.369)	Loss 1.2781e-01 (1.3810e-01) 
2023-05-25 01:15:24.010942: train Epoch: [13][ 39/193]	Time  1.081 ( 1.479)	Data  0.001 ( 0.360)	Loss 1.6627e-01 (1.3881e-01) 
2023-05-25 01:15:26.079818: train Epoch: [13][ 40/193]	Time  2.069 ( 1.494)	Data  0.766 ( 0.370)	Loss 1.1027e-01 (1.3811e-01) 
2023-05-25 01:15:27.102748: train Epoch: [13][ 41/193]	Time  1.023 ( 1.483)	Data  0.001 ( 0.361)	Loss 1.4010e-01 (1.3816e-01) 
2023-05-25 01:15:28.735613: train Epoch: [13][ 42/193]	Time  1.633 ( 1.486)	Data  0.491 ( 0.364)	Loss 1.9304e-01 (1.3944e-01) 
2023-05-25 01:15:29.692714: train Epoch: [13][ 43/193]	Time  0.957 ( 1.474)	Data  0.001 ( 0.356)	Loss 1.6558e-01 (1.4003e-01) 
2023-05-25 01:15:31.380605: train Epoch: [13][ 44/193]	Time  1.688 ( 1.479)	Data  0.571 ( 0.361)	Loss 8.1960e-02 (1.3874e-01) 
2023-05-25 01:15:32.426959: train Epoch: [13][ 45/193]	Time  1.046 ( 1.469)	Data  0.001 ( 0.353)	Loss 9.0332e-02 (1.3769e-01) 
2023-05-25 01:15:34.201056: train Epoch: [13][ 46/193]	Time  1.774 ( 1.476)	Data  0.654 ( 0.359)	Loss 1.5303e-01 (1.3801e-01) 
2023-05-25 01:15:35.229082: train Epoch: [13][ 47/193]	Time  1.028 ( 1.467)	Data  0.001 ( 0.352)	Loss 7.7206e-02 (1.3675e-01) 
2023-05-25 01:15:36.744644: train Epoch: [13][ 48/193]	Time  1.516 ( 1.468)	Data  0.576 ( 0.356)	Loss 1.2690e-01 (1.3655e-01) 
2023-05-25 01:15:37.681360: train Epoch: [13][ 49/193]	Time  0.937 ( 1.457)	Data  0.001 ( 0.349)	Loss 1.9290e-01 (1.3767e-01) 
2023-05-25 01:15:39.654098: train Epoch: [13][ 50/193]	Time  1.973 ( 1.467)	Data  0.886 ( 0.360)	Loss 2.3153e-01 (1.3951e-01) 
2023-05-25 01:15:40.710527: train Epoch: [13][ 51/193]	Time  1.056 ( 1.459)	Data  0.001 ( 0.353)	Loss 2.5032e-01 (1.4164e-01) 
2023-05-25 01:15:42.346997: train Epoch: [13][ 52/193]	Time  1.636 ( 1.462)	Data  0.561 ( 0.357)	Loss 8.0409e-02 (1.4049e-01) 
2023-05-25 01:15:43.409684: train Epoch: [13][ 53/193]	Time  1.063 ( 1.455)	Data  0.001 ( 0.350)	Loss 8.9948e-02 (1.3955e-01) 
2023-05-25 01:15:45.169492: train Epoch: [13][ 54/193]	Time  1.760 ( 1.461)	Data  0.595 ( 0.355)	Loss 1.8507e-01 (1.4038e-01) 
2023-05-25 01:15:46.335788: train Epoch: [13][ 55/193]	Time  1.166 ( 1.455)	Data  0.002 ( 0.348)	Loss 1.0989e-01 (1.3984e-01) 
2023-05-25 01:15:48.121034: train Epoch: [13][ 56/193]	Time  1.785 ( 1.461)	Data  0.474 ( 0.351)	Loss 2.7899e-01 (1.4228e-01) 
2023-05-25 01:15:49.142717: train Epoch: [13][ 57/193]	Time  1.022 ( 1.454)	Data  0.001 ( 0.345)	Loss 1.3779e-01 (1.4220e-01) 
2023-05-25 01:15:50.413658: train Epoch: [13][ 58/193]	Time  1.271 ( 1.450)	Data  0.267 ( 0.343)	Loss 1.3190e-01 (1.4203e-01) 
2023-05-25 01:15:51.412996: train Epoch: [13][ 59/193]	Time  0.999 ( 1.443)	Data  0.001 ( 0.338)	Loss 1.4043e-01 (1.4200e-01) 
2023-05-25 01:15:53.437601: train Epoch: [13][ 60/193]	Time  2.025 ( 1.453)	Data  0.818 ( 0.345)	Loss 9.3979e-02 (1.4121e-01) 
2023-05-25 01:15:54.590660: train Epoch: [13][ 61/193]	Time  1.153 ( 1.448)	Data  0.001 ( 0.340)	Loss 9.3346e-02 (1.4044e-01) 
2023-05-25 01:15:56.055004: train Epoch: [13][ 62/193]	Time  1.464 ( 1.448)	Data  0.332 ( 0.340)	Loss 1.3997e-01 (1.4043e-01) 
2023-05-25 01:15:57.139859: train Epoch: [13][ 63/193]	Time  1.085 ( 1.442)	Data  0.001 ( 0.334)	Loss 1.0288e-01 (1.3985e-01) 
2023-05-25 01:15:59.050646: train Epoch: [13][ 64/193]	Time  1.911 ( 1.449)	Data  0.552 ( 0.338)	Loss 2.0979e-01 (1.4092e-01) 
2023-05-25 01:16:00.181921: train Epoch: [13][ 65/193]	Time  1.131 ( 1.445)	Data  0.001 ( 0.333)	Loss 1.0059e-01 (1.4031e-01) 
2023-05-25 01:16:01.447114: train Epoch: [13][ 66/193]	Time  1.265 ( 1.442)	Data  0.239 ( 0.331)	Loss 1.3983e-01 (1.4030e-01) 
2023-05-25 01:16:02.370136: train Epoch: [13][ 67/193]	Time  0.923 ( 1.434)	Data  0.001 ( 0.326)	Loss 1.6168e-01 (1.4062e-01) 
2023-05-25 01:16:04.353787: train Epoch: [13][ 68/193]	Time  1.984 ( 1.442)	Data  0.766 ( 0.333)	Loss 1.7812e-01 (1.4116e-01) 
2023-05-25 01:16:05.321845: train Epoch: [13][ 69/193]	Time  0.968 ( 1.436)	Data  0.001 ( 0.328)	Loss 1.0659e-01 (1.4067e-01) 
2023-05-25 01:16:07.052989: train Epoch: [13][ 70/193]	Time  1.731 ( 1.440)	Data  0.511 ( 0.331)	Loss 1.3279e-01 (1.4056e-01) 
2023-05-25 01:16:08.166413: train Epoch: [13][ 71/193]	Time  1.113 ( 1.435)	Data  0.001 ( 0.326)	Loss 1.0116e-01 (1.4001e-01) 
2023-05-25 01:16:09.910993: train Epoch: [13][ 72/193]	Time  1.745 ( 1.439)	Data  0.489 ( 0.328)	Loss 1.6405e-01 (1.4034e-01) 
2023-05-25 01:16:10.902317: train Epoch: [13][ 73/193]	Time  0.991 ( 1.433)	Data  0.001 ( 0.324)	Loss 4.5604e-02 (1.3906e-01) 
2023-05-25 01:16:12.723695: train Epoch: [13][ 74/193]	Time  1.821 ( 1.439)	Data  0.540 ( 0.327)	Loss 1.1364e-01 (1.3872e-01) 
2023-05-25 01:16:13.893139: train Epoch: [13][ 75/193]	Time  1.169 ( 1.435)	Data  0.001 ( 0.322)	Loss 2.1425e-01 (1.3971e-01) 
2023-05-25 01:16:15.445410: train Epoch: [13][ 76/193]	Time  1.552 ( 1.436)	Data  0.492 ( 0.325)	Loss 8.9798e-02 (1.3906e-01) 
2023-05-25 01:16:16.539939: train Epoch: [13][ 77/193]	Time  1.095 ( 1.432)	Data  0.001 ( 0.321)	Loss 1.9306e-01 (1.3976e-01) 
2023-05-25 01:16:18.668526: train Epoch: [13][ 78/193]	Time  2.129 ( 1.441)	Data  0.806 ( 0.327)	Loss 7.0602e-02 (1.3888e-01) 
2023-05-25 01:16:19.824061: train Epoch: [13][ 79/193]	Time  1.155 ( 1.437)	Data  0.001 ( 0.323)	Loss 1.0756e-01 (1.3849e-01) 
2023-05-25 01:16:21.339915: train Epoch: [13][ 80/193]	Time  1.516 ( 1.438)	Data  0.430 ( 0.324)	Loss 1.2370e-01 (1.3831e-01) 
2023-05-25 01:16:22.591521: train Epoch: [13][ 81/193]	Time  1.252 ( 1.436)	Data  0.001 ( 0.320)	Loss 1.1739e-01 (1.3805e-01) 
2023-05-25 01:16:24.235877: train Epoch: [13][ 82/193]	Time  1.644 ( 1.439)	Data  0.592 ( 0.323)	Loss 9.2926e-02 (1.3751e-01) 
2023-05-25 01:16:25.436291: train Epoch: [13][ 83/193]	Time  1.200 ( 1.436)	Data  0.001 ( 0.319)	Loss 1.7494e-01 (1.3795e-01) 
2023-05-25 01:16:27.041780: train Epoch: [13][ 84/193]	Time  1.605 ( 1.438)	Data  0.583 ( 0.323)	Loss 1.0954e-01 (1.3762e-01) 
2023-05-25 01:16:28.152132: train Epoch: [13][ 85/193]	Time  1.110 ( 1.434)	Data  0.001 ( 0.319)	Loss 8.9229e-02 (1.3706e-01) 
2023-05-25 01:16:30.196135: train Epoch: [13][ 86/193]	Time  2.044 ( 1.441)	Data  0.603 ( 0.322)	Loss 1.1148e-01 (1.3676e-01) 
2023-05-25 01:16:31.304559: train Epoch: [13][ 87/193]	Time  1.108 ( 1.437)	Data  0.001 ( 0.318)	Loss 1.0569e-01 (1.3641e-01) 
2023-05-25 01:16:32.408773: train Epoch: [13][ 88/193]	Time  1.104 ( 1.433)	Data  0.090 ( 0.316)	Loss 9.2632e-02 (1.3592e-01) 
2023-05-25 01:16:33.481730: train Epoch: [13][ 89/193]	Time  1.073 ( 1.429)	Data  0.001 ( 0.312)	Loss 1.5394e-01 (1.3612e-01) 
2023-05-25 01:16:35.046195: train Epoch: [13][ 90/193]	Time  1.564 ( 1.431)	Data  0.550 ( 0.315)	Loss 1.0755e-01 (1.3580e-01) 
2023-05-25 01:16:36.031229: train Epoch: [13][ 91/193]	Time  0.985 ( 1.426)	Data  0.001 ( 0.312)	Loss 2.0170e-01 (1.3652e-01) 
2023-05-25 01:16:38.082146: train Epoch: [13][ 92/193]	Time  2.051 ( 1.433)	Data  0.810 ( 0.317)	Loss 1.1611e-01 (1.3630e-01) 
2023-05-25 01:16:39.056775: train Epoch: [13][ 93/193]	Time  0.975 ( 1.428)	Data  0.001 ( 0.314)	Loss 1.0739e-01 (1.3599e-01) 
2023-05-25 01:16:40.602853: train Epoch: [13][ 94/193]	Time  1.546 ( 1.429)	Data  0.342 ( 0.314)	Loss 5.8721e-02 (1.3518e-01) 
2023-05-25 01:16:41.558428: train Epoch: [13][ 95/193]	Time  0.956 ( 1.424)	Data  0.001 ( 0.311)	Loss 1.2505e-01 (1.3508e-01) 
2023-05-25 01:16:43.558043: train Epoch: [13][ 96/193]	Time  2.000 ( 1.430)	Data  0.484 ( 0.312)	Loss 1.4528e-01 (1.3518e-01) 
2023-05-25 01:16:44.602644: train Epoch: [13][ 97/193]	Time  1.045 ( 1.426)	Data  0.001 ( 0.309)	Loss 1.6354e-01 (1.3547e-01) 
2023-05-25 01:16:45.808118: train Epoch: [13][ 98/193]	Time  1.205 ( 1.424)	Data  0.177 ( 0.308)	Loss 1.8578e-01 (1.3598e-01) 
2023-05-25 01:16:46.937707: train Epoch: [13][ 99/193]	Time  1.130 ( 1.421)	Data  0.001 ( 0.305)	Loss 1.8380e-01 (1.3646e-01) 
2023-05-25 01:16:48.720976: train Epoch: [13][100/193]	Time  1.783 ( 1.425)	Data  0.515 ( 0.307)	Loss 1.0042e-01 (1.3610e-01) 
2023-05-25 01:16:49.846096: train Epoch: [13][101/193]	Time  1.125 ( 1.422)	Data  0.001 ( 0.304)	Loss 9.1060e-02 (1.3566e-01) 
2023-05-25 01:16:51.173094: train Epoch: [13][102/193]	Time  1.327 ( 1.421)	Data  0.193 ( 0.303)	Loss 1.9363e-01 (1.3622e-01) 
2023-05-25 01:16:52.246083: train Epoch: [13][103/193]	Time  1.073 ( 1.417)	Data  0.001 ( 0.300)	Loss 1.6803e-01 (1.3653e-01) 
2023-05-25 01:16:53.783568: train Epoch: [13][104/193]	Time  1.537 ( 1.419)	Data  0.463 ( 0.301)	Loss 7.3196e-02 (1.3592e-01) 
2023-05-25 01:16:54.873625: train Epoch: [13][105/193]	Time  1.090 ( 1.415)	Data  0.001 ( 0.299)	Loss 7.5499e-02 (1.3535e-01) 
2023-05-25 01:16:56.492784: train Epoch: [13][106/193]	Time  1.619 ( 1.417)	Data  0.525 ( 0.301)	Loss 1.1780e-01 (1.3519e-01) 
2023-05-25 01:16:57.455026: train Epoch: [13][107/193]	Time  0.962 ( 1.413)	Data  0.070 ( 0.299)	Loss 6.7581e-02 (1.3456e-01) 
2023-05-25 01:16:59.306896: train Epoch: [13][108/193]	Time  1.852 ( 1.417)	Data  0.629 ( 0.302)	Loss 2.1207e-01 (1.3527e-01) 
2023-05-25 01:17:00.406184: train Epoch: [13][109/193]	Time  1.099 ( 1.414)	Data  0.155 ( 0.300)	Loss 9.1306e-02 (1.3487e-01) 
2023-05-25 01:17:02.173331: train Epoch: [13][110/193]	Time  1.767 ( 1.417)	Data  0.506 ( 0.302)	Loss 1.2313e-01 (1.3477e-01) 
2023-05-25 01:17:03.286713: train Epoch: [13][111/193]	Time  1.113 ( 1.415)	Data  0.165 ( 0.301)	Loss 6.2540e-02 (1.3412e-01) 
2023-05-25 01:17:05.005641: train Epoch: [13][112/193]	Time  1.719 ( 1.417)	Data  0.626 ( 0.304)	Loss 1.2198e-01 (1.3402e-01) 
2023-05-25 01:17:06.176669: train Epoch: [13][113/193]	Time  1.171 ( 1.415)	Data  0.192 ( 0.303)	Loss 1.0940e-01 (1.3380e-01) 
2023-05-25 01:17:07.957746: train Epoch: [13][114/193]	Time  1.781 ( 1.418)	Data  0.625 ( 0.306)	Loss 1.1859e-01 (1.3367e-01) 
2023-05-25 01:17:09.053684: train Epoch: [13][115/193]	Time  1.096 ( 1.416)	Data  0.018 ( 0.303)	Loss 1.1450e-01 (1.3350e-01) 
2023-05-25 01:17:10.581289: train Epoch: [13][116/193]	Time  1.528 ( 1.417)	Data  0.540 ( 0.305)	Loss 9.2502e-02 (1.3315e-01) 
2023-05-25 01:17:11.806597: train Epoch: [13][117/193]	Time  1.225 ( 1.415)	Data  0.104 ( 0.303)	Loss 7.3040e-02 (1.3264e-01) 
2023-05-25 01:17:13.431047: train Epoch: [13][118/193]	Time  1.624 ( 1.417)	Data  0.632 ( 0.306)	Loss 1.9304e-01 (1.3315e-01) 
2023-05-25 01:17:14.608341: train Epoch: [13][119/193]	Time  1.177 ( 1.415)	Data  0.054 ( 0.304)	Loss 1.1242e-01 (1.3298e-01) 
2023-05-25 01:17:16.571287: train Epoch: [13][120/193]	Time  1.963 ( 1.419)	Data  0.682 ( 0.307)	Loss 8.7758e-02 (1.3260e-01) 
2023-05-25 01:17:17.655412: train Epoch: [13][121/193]	Time  1.084 ( 1.417)	Data  0.001 ( 0.305)	Loss 1.1273e-01 (1.3244e-01) 
2023-05-25 01:17:19.214345: train Epoch: [13][122/193]	Time  1.559 ( 1.418)	Data  0.363 ( 0.305)	Loss 3.4660e-01 (1.3418e-01) 
2023-05-25 01:17:20.368545: train Epoch: [13][123/193]	Time  1.154 ( 1.416)	Data  0.001 ( 0.303)	Loss 9.2480e-02 (1.3385e-01) 
2023-05-25 01:17:22.045239: train Epoch: [13][124/193]	Time  1.677 ( 1.418)	Data  0.435 ( 0.304)	Loss 7.1318e-02 (1.3335e-01) 
2023-05-25 01:17:23.082134: train Epoch: [13][125/193]	Time  1.037 ( 1.415)	Data  0.001 ( 0.301)	Loss 1.1087e-01 (1.3317e-01) 
2023-05-25 01:17:24.893510: train Epoch: [13][126/193]	Time  1.811 ( 1.418)	Data  0.573 ( 0.304)	Loss 1.7795e-01 (1.3352e-01) 
2023-05-25 01:17:26.119685: train Epoch: [13][127/193]	Time  1.226 ( 1.416)	Data  0.001 ( 0.301)	Loss 9.2075e-02 (1.3320e-01) 
2023-05-25 01:17:27.505357: train Epoch: [13][128/193]	Time  1.386 ( 1.416)	Data  0.272 ( 0.301)	Loss 1.7977e-01 (1.3356e-01) 
2023-05-25 01:17:28.674129: train Epoch: [13][129/193]	Time  1.169 ( 1.414)	Data  0.001 ( 0.299)	Loss 2.1637e-01 (1.3419e-01) 
2023-05-25 01:17:30.212546: train Epoch: [13][130/193]	Time  1.538 ( 1.415)	Data  0.468 ( 0.300)	Loss 8.1056e-02 (1.3379e-01) 
2023-05-25 01:17:31.213547: train Epoch: [13][131/193]	Time  1.001 ( 1.412)	Data  0.001 ( 0.298)	Loss 1.9263e-01 (1.3423e-01) 
2023-05-25 01:17:33.137962: train Epoch: [13][132/193]	Time  1.924 ( 1.416)	Data  0.669 ( 0.300)	Loss 1.7968e-01 (1.3458e-01) 
2023-05-25 01:17:34.319774: train Epoch: [13][133/193]	Time  1.182 ( 1.414)	Data  0.001 ( 0.298)	Loss 5.8970e-02 (1.3401e-01) 
2023-05-25 01:17:35.996496: train Epoch: [13][134/193]	Time  1.677 ( 1.416)	Data  0.433 ( 0.299)	Loss 1.8022e-01 (1.3435e-01) 
2023-05-25 01:17:37.076196: train Epoch: [13][135/193]	Time  1.080 ( 1.414)	Data  0.001 ( 0.297)	Loss 1.3457e-01 (1.3436e-01) 
2023-05-25 01:17:38.942477: train Epoch: [13][136/193]	Time  1.866 ( 1.417)	Data  0.483 ( 0.298)	Loss 1.6696e-01 (1.3459e-01) 
2023-05-25 01:17:40.069621: train Epoch: [13][137/193]	Time  1.127 ( 1.415)	Data  0.001 ( 0.296)	Loss 1.0893e-01 (1.3441e-01) 
2023-05-25 01:17:41.450212: train Epoch: [13][138/193]	Time  1.381 ( 1.414)	Data  0.247 ( 0.296)	Loss 6.1491e-02 (1.3388e-01) 
2023-05-25 01:17:42.436654: train Epoch: [13][139/193]	Time  0.986 ( 1.411)	Data  0.001 ( 0.294)	Loss 1.2395e-01 (1.3381e-01) 
2023-05-25 01:17:44.376379: train Epoch: [13][140/193]	Time  1.940 ( 1.415)	Data  0.703 ( 0.297)	Loss 1.0875e-01 (1.3363e-01) 
2023-05-25 01:17:45.449005: train Epoch: [13][141/193]	Time  1.073 ( 1.413)	Data  0.001 ( 0.295)	Loss 1.0346e-01 (1.3342e-01) 
2023-05-25 01:17:47.075776: train Epoch: [13][142/193]	Time  1.627 ( 1.414)	Data  0.520 ( 0.296)	Loss 1.0665e-01 (1.3323e-01) 
2023-05-25 01:17:48.410813: train Epoch: [13][143/193]	Time  1.335 ( 1.414)	Data  0.001 ( 0.294)	Loss 6.6611e-02 (1.3277e-01) 
2023-05-25 01:17:49.877626: train Epoch: [13][144/193]	Time  1.467 ( 1.414)	Data  0.322 ( 0.294)	Loss 1.0388e-01 (1.3257e-01) 
2023-05-25 01:17:50.927860: train Epoch: [13][145/193]	Time  1.050 ( 1.412)	Data  0.001 ( 0.292)	Loss 1.9645e-01 (1.3301e-01) 
2023-05-25 01:17:52.465080: train Epoch: [13][146/193]	Time  1.537 ( 1.412)	Data  0.553 ( 0.294)	Loss 1.1968e-01 (1.3292e-01) 
2023-05-25 01:17:53.471901: train Epoch: [13][147/193]	Time  1.007 ( 1.410)	Data  0.001 ( 0.292)	Loss 7.4594e-02 (1.3253e-01) 
2023-05-25 01:17:55.308203: train Epoch: [13][148/193]	Time  1.836 ( 1.413)	Data  0.836 ( 0.296)	Loss 1.1588e-01 (1.3241e-01) 
2023-05-25 01:17:56.348343: train Epoch: [13][149/193]	Time  1.040 ( 1.410)	Data  0.001 ( 0.294)	Loss 7.7649e-02 (1.3205e-01) 
2023-05-25 01:17:58.308822: train Epoch: [13][150/193]	Time  1.960 ( 1.414)	Data  0.693 ( 0.296)	Loss 1.1735e-01 (1.3195e-01) 
2023-05-25 01:17:59.318728: train Epoch: [13][151/193]	Time  1.010 ( 1.411)	Data  0.001 ( 0.295)	Loss 9.0719e-02 (1.3168e-01) 
2023-05-25 01:18:01.121853: train Epoch: [13][152/193]	Time  1.803 ( 1.414)	Data  0.565 ( 0.296)	Loss 8.5897e-02 (1.3138e-01) 
2023-05-25 01:18:02.286019: train Epoch: [13][153/193]	Time  1.164 ( 1.412)	Data  0.001 ( 0.294)	Loss 1.9214e-01 (1.3178e-01) 
2023-05-25 01:18:03.974438: train Epoch: [13][154/193]	Time  1.688 ( 1.414)	Data  0.451 ( 0.295)	Loss 1.2275e-01 (1.3172e-01) 
2023-05-25 01:18:04.979148: train Epoch: [13][155/193]	Time  1.005 ( 1.411)	Data  0.001 ( 0.293)	Loss 1.0494e-01 (1.3155e-01) 
2023-05-25 01:18:06.529897: train Epoch: [13][156/193]	Time  1.551 ( 1.412)	Data  0.457 ( 0.295)	Loss 1.1792e-01 (1.3146e-01) 
2023-05-25 01:18:07.761636: train Epoch: [13][157/193]	Time  1.232 ( 1.411)	Data  0.001 ( 0.293)	Loss 1.0472e-01 (1.3129e-01) 
2023-05-25 01:18:09.247532: train Epoch: [13][158/193]	Time  1.486 ( 1.411)	Data  0.428 ( 0.294)	Loss 1.6418e-01 (1.3150e-01) 
2023-05-25 01:18:10.435759: train Epoch: [13][159/193]	Time  1.188 ( 1.410)	Data  0.001 ( 0.292)	Loss 1.5297e-01 (1.3163e-01) 
2023-05-25 01:18:12.119436: train Epoch: [13][160/193]	Time  1.684 ( 1.412)	Data  0.558 ( 0.293)	Loss 1.5585e-01 (1.3178e-01) 
2023-05-25 01:18:13.366117: train Epoch: [13][161/193]	Time  1.247 ( 1.411)	Data  0.001 ( 0.292)	Loss 1.0917e-01 (1.3164e-01) 
2023-05-25 01:18:14.678778: train Epoch: [13][162/193]	Time  1.313 ( 1.410)	Data  0.284 ( 0.291)	Loss 1.3374e-01 (1.3165e-01) 
2023-05-25 01:18:15.703182: train Epoch: [13][163/193]	Time  1.024 ( 1.408)	Data  0.001 ( 0.290)	Loss 9.2244e-02 (1.3141e-01) 
2023-05-25 01:18:17.311318: train Epoch: [13][164/193]	Time  1.608 ( 1.409)	Data  0.672 ( 0.292)	Loss 1.7639e-01 (1.3169e-01) 
2023-05-25 01:18:18.356507: train Epoch: [13][165/193]	Time  1.045 ( 1.407)	Data  0.001 ( 0.290)	Loss 1.9361e-01 (1.3206e-01) 
2023-05-25 01:18:20.195448: train Epoch: [13][166/193]	Time  1.839 ( 1.409)	Data  0.571 ( 0.292)	Loss 7.5963e-02 (1.3172e-01) 
2023-05-25 01:18:21.182955: train Epoch: [13][167/193]	Time  0.988 ( 1.407)	Data  0.001 ( 0.290)	Loss 9.5373e-02 (1.3151e-01) 
2023-05-25 01:18:22.513139: train Epoch: [13][168/193]	Time  1.330 ( 1.406)	Data  0.347 ( 0.291)	Loss 8.7494e-02 (1.3125e-01) 
2023-05-25 01:18:23.870296: train Epoch: [13][169/193]	Time  1.357 ( 1.406)	Data  0.301 ( 0.291)	Loss 9.9364e-02 (1.3106e-01) 
2023-05-25 01:18:25.430810: train Epoch: [13][170/193]	Time  1.561 ( 1.407)	Data  0.359 ( 0.291)	Loss 9.6690e-02 (1.3086e-01) 
2023-05-25 01:18:26.926440: train Epoch: [13][171/193]	Time  1.496 ( 1.408)	Data  0.366 ( 0.291)	Loss 1.3536e-01 (1.3088e-01) 
2023-05-25 01:18:28.013161: train Epoch: [13][172/193]	Time  1.087 ( 1.406)	Data  0.001 ( 0.290)	Loss 1.3538e-01 (1.3091e-01) 
2023-05-25 01:18:29.730916: train Epoch: [13][173/193]	Time  1.718 ( 1.407)	Data  0.694 ( 0.292)	Loss 1.0379e-01 (1.3075e-01) 
2023-05-25 01:18:30.643567: train Epoch: [13][174/193]	Time  0.913 ( 1.405)	Data  0.001 ( 0.290)	Loss 1.7628e-01 (1.3101e-01) 
2023-05-25 01:18:32.603967: train Epoch: [13][175/193]	Time  1.960 ( 1.408)	Data  1.002 ( 0.294)	Loss 2.8658e-01 (1.3190e-01) 
2023-05-25 01:18:33.711117: train Epoch: [13][176/193]	Time  1.107 ( 1.406)	Data  0.001 ( 0.293)	Loss 1.3403e-01 (1.3191e-01) 
2023-05-25 01:18:35.813310: train Epoch: [13][177/193]	Time  2.102 ( 1.410)	Data  0.709 ( 0.295)	Loss 8.3287e-02 (1.3164e-01) 
2023-05-25 01:18:36.822932: train Epoch: [13][178/193]	Time  1.010 ( 1.408)	Data  0.001 ( 0.294)	Loss 1.4095e-01 (1.3169e-01) 
2023-05-25 01:18:38.285512: train Epoch: [13][179/193]	Time  1.463 ( 1.408)	Data  0.245 ( 0.293)	Loss 1.0997e-01 (1.3157e-01) 
2023-05-25 01:18:39.280766: train Epoch: [13][180/193]	Time  0.995 ( 1.406)	Data  0.001 ( 0.292)	Loss 9.5944e-02 (1.3137e-01) 
2023-05-25 01:18:40.865159: train Epoch: [13][181/193]	Time  1.584 ( 1.407)	Data  0.570 ( 0.293)	Loss 8.6741e-02 (1.3113e-01) 
2023-05-25 01:18:41.946980: train Epoch: [13][182/193]	Time  1.082 ( 1.405)	Data  0.001 ( 0.292)	Loss 1.8786e-01 (1.3144e-01) 
2023-05-25 01:18:43.650445: train Epoch: [13][183/193]	Time  1.703 ( 1.407)	Data  0.661 ( 0.294)	Loss 9.1177e-02 (1.3122e-01) 
2023-05-25 01:18:44.745302: train Epoch: [13][184/193]	Time  1.095 ( 1.405)	Data  0.001 ( 0.292)	Loss 9.2265e-02 (1.3101e-01) 
2023-05-25 01:18:46.573426: train Epoch: [13][185/193]	Time  1.828 ( 1.407)	Data  0.702 ( 0.294)	Loss 2.2398e-01 (1.3151e-01) 
2023-05-25 01:18:47.848989: train Epoch: [13][186/193]	Time  1.276 ( 1.406)	Data  0.001 ( 0.293)	Loss 9.6806e-02 (1.3132e-01) 
2023-05-25 01:18:49.379761: train Epoch: [13][187/193]	Time  1.531 ( 1.407)	Data  0.452 ( 0.293)	Loss 1.4349e-01 (1.3139e-01) 
2023-05-25 01:18:50.412369: train Epoch: [13][188/193]	Time  1.033 ( 1.405)	Data  0.001 ( 0.292)	Loss 1.0006e-01 (1.3122e-01) 
2023-05-25 01:18:52.174963: train Epoch: [13][189/193]	Time  1.763 ( 1.407)	Data  0.744 ( 0.294)	Loss 9.1114e-02 (1.3101e-01) 
2023-05-25 01:18:53.390800: train Epoch: [13][190/193]	Time  1.216 ( 1.406)	Data  0.001 ( 0.293)	Loss 8.0247e-02 (1.3074e-01) 
2023-05-25 01:18:55.080835: train Epoch: [13][191/193]	Time  1.690 ( 1.408)	Data  0.630 ( 0.295)	Loss 7.7005e-02 (1.3046e-01) 
2023-05-25 01:18:56.176707: train Epoch: [13][192/193]	Time  1.096 ( 1.406)	Data  0.001 ( 0.293)	Loss 1.0510e-01 (1.3033e-01) 
2023-05-25 01:18:56.244090: Train Epoch done in 271.4101023749681 s 
2023-05-25 01:18:59.264728: val Epoch: [13][ 0/72]	Time  2.127 ( 2.127)	Data  1.750 ( 1.750)	Loss 2.6981e-01 (2.6981e-01) 
2023-05-25 01:18:59.598184: val Epoch: [13][ 1/72]	Time  0.334 ( 1.230)	Data  0.006 ( 0.878)	Loss 1.4494e-01 (2.0738e-01) 
2023-05-25 01:19:00.710483: val Epoch: [13][ 2/72]	Time  1.112 ( 1.191)	Data  0.740 ( 0.832)	Loss 2.7762e-01 (2.3079e-01) 
2023-05-25 01:19:00.931720: val Epoch: [13][ 3/72]	Time  0.221 ( 0.949)	Data  0.001 ( 0.624)	Loss 5.9038e-02 (1.8785e-01) 
2023-05-25 01:19:02.088693: val Epoch: [13][ 4/72]	Time  1.157 ( 0.990)	Data  0.817 ( 0.663)	Loss 2.3526e-01 (1.9734e-01) 
2023-05-25 01:19:02.518363: val Epoch: [13][ 5/72]	Time  0.430 ( 0.897)	Data  0.001 ( 0.553)	Loss 3.5403e-01 (2.2345e-01) 
2023-05-25 01:19:03.532106: val Epoch: [13][ 6/72]	Time  1.014 ( 0.913)	Data  0.657 ( 0.568)	Loss 9.4875e-02 (2.0508e-01) 
2023-05-25 01:19:03.767973: val Epoch: [13][ 7/72]	Time  0.236 ( 0.829)	Data  0.001 ( 0.497)	Loss 9.3089e-02 (1.9108e-01) 
2023-05-25 01:19:04.826010: val Epoch: [13][ 8/72]	Time  1.058 ( 0.854)	Data  0.837 ( 0.534)	Loss 6.1365e-02 (1.7667e-01) 
2023-05-25 01:19:05.110614: val Epoch: [13][ 9/72]	Time  0.285 ( 0.797)	Data  0.001 ( 0.481)	Loss 1.6638e-01 (1.7564e-01) 
2023-05-25 01:19:06.437989: val Epoch: [13][10/72]	Time  1.327 ( 0.845)	Data  0.947 ( 0.523)	Loss 4.7083e-01 (2.0248e-01) 
2023-05-25 01:19:06.788401: val Epoch: [13][11/72]	Time  0.350 ( 0.804)	Data  0.001 ( 0.480)	Loss 6.2462e-02 (1.9081e-01) 
2023-05-25 01:19:07.789542: val Epoch: [13][12/72]	Time  1.001 ( 0.819)	Data  0.634 ( 0.492)	Loss 1.4377e-01 (1.8719e-01) 
2023-05-25 01:19:08.023944: val Epoch: [13][13/72]	Time  0.234 ( 0.778)	Data  0.001 ( 0.457)	Loss 7.9264e-02 (1.7948e-01) 
2023-05-25 01:19:09.250152: val Epoch: [13][14/72]	Time  1.226 ( 0.807)	Data  0.783 ( 0.479)	Loss 5.9122e-02 (1.7146e-01) 
2023-05-25 01:19:09.619449: val Epoch: [13][15/72]	Time  0.369 ( 0.780)	Data  0.001 ( 0.449)	Loss 3.9294e-01 (1.8530e-01) 
2023-05-25 01:19:10.648233: val Epoch: [13][16/72]	Time  1.029 ( 0.795)	Data  0.663 ( 0.461)	Loss 8.1121e-02 (1.7917e-01) 
2023-05-25 01:19:11.136600: val Epoch: [13][17/72]	Time  0.488 ( 0.778)	Data  0.001 ( 0.436)	Loss 1.0456e-01 (1.7503e-01) 
2023-05-25 01:19:11.937902: val Epoch: [13][18/72]	Time  0.801 ( 0.779)	Data  0.614 ( 0.445)	Loss 6.5529e-02 (1.6926e-01) 
2023-05-25 01:19:12.282728: val Epoch: [13][19/72]	Time  0.345 ( 0.757)	Data  0.001 ( 0.423)	Loss 7.3271e-02 (1.6446e-01) 
2023-05-25 01:19:13.505087: val Epoch: [13][20/72]	Time  1.222 ( 0.779)	Data  0.896 ( 0.445)	Loss 1.8033e-01 (1.6522e-01) 
2023-05-25 01:19:13.882374: val Epoch: [13][21/72]	Time  0.377 ( 0.761)	Data  0.001 ( 0.425)	Loss 7.0186e-02 (1.6090e-01) 
2023-05-25 01:19:15.145616: val Epoch: [13][22/72]	Time  1.263 ( 0.783)	Data  0.745 ( 0.439)	Loss 1.1156e-01 (1.5875e-01) 
2023-05-25 01:19:15.352891: val Epoch: [13][23/72]	Time  0.207 ( 0.759)	Data  0.001 ( 0.421)	Loss 8.0621e-02 (1.5550e-01) 
2023-05-25 01:19:16.378315: val Epoch: [13][24/72]	Time  1.025 ( 0.770)	Data  0.701 ( 0.432)	Loss 1.2472e-01 (1.5427e-01) 
2023-05-25 01:19:16.919520: val Epoch: [13][25/72]	Time  0.541 ( 0.761)	Data  0.001 ( 0.416)	Loss 9.7994e-02 (1.5210e-01) 
2023-05-25 01:19:18.000311: val Epoch: [13][26/72]	Time  1.081 ( 0.773)	Data  0.598 ( 0.422)	Loss 1.3200e-01 (1.5136e-01) 
2023-05-25 01:19:18.228769: val Epoch: [13][27/72]	Time  0.228 ( 0.753)	Data  0.001 ( 0.407)	Loss 7.8401e-02 (1.4875e-01) 
2023-05-25 01:19:19.164581: val Epoch: [13][28/72]	Time  0.936 ( 0.760)	Data  0.699 ( 0.417)	Loss 1.4794e-01 (1.4873e-01) 
2023-05-25 01:19:19.534292: val Epoch: [13][29/72]	Time  0.370 ( 0.747)	Data  0.001 ( 0.403)	Loss 2.1547e-01 (1.5095e-01) 
2023-05-25 01:19:20.578291: val Epoch: [13][30/72]	Time  1.044 ( 0.756)	Data  0.774 ( 0.415)	Loss 2.2576e-01 (1.5336e-01) 
2023-05-25 01:19:20.894564: val Epoch: [13][31/72]	Time  0.316 ( 0.742)	Data  0.001 ( 0.402)	Loss 1.4364e-01 (1.5306e-01) 
2023-05-25 01:19:21.930435: val Epoch: [13][32/72]	Time  1.036 ( 0.751)	Data  0.849 ( 0.416)	Loss 7.1165e-02 (1.5058e-01) 
2023-05-25 01:19:22.196255: val Epoch: [13][33/72]	Time  0.266 ( 0.737)	Data  0.001 ( 0.404)	Loss 1.0822e-01 (1.4933e-01) 
2023-05-25 01:19:23.361026: val Epoch: [13][34/72]	Time  1.165 ( 0.749)	Data  0.865 ( 0.417)	Loss 1.1247e-01 (1.4828e-01) 
2023-05-25 01:19:23.711080: val Epoch: [13][35/72]	Time  0.350 ( 0.738)	Data  0.001 ( 0.405)	Loss 5.4045e-02 (1.4566e-01) 
2023-05-25 01:19:24.889843: val Epoch: [13][36/72]	Time  1.179 ( 0.750)	Data  0.747 ( 0.415)	Loss 7.8040e-02 (1.4383e-01) 
2023-05-25 01:19:25.120235: val Epoch: [13][37/72]	Time  0.230 ( 0.736)	Data  0.000 ( 0.404)	Loss 3.1926e-01 (1.4845e-01) 
2023-05-25 01:19:26.196764: val Epoch: [13][38/72]	Time  1.077 ( 0.745)	Data  0.747 ( 0.413)	Loss 5.3820e-01 (1.5844e-01) 
2023-05-25 01:19:26.568576: val Epoch: [13][39/72]	Time  0.372 ( 0.736)	Data  0.002 ( 0.402)	Loss 3.9405e-01 (1.6433e-01) 
2023-05-25 01:19:27.784007: val Epoch: [13][40/72]	Time  1.215 ( 0.747)	Data  0.732 ( 0.410)	Loss 6.6111e-01 (1.7645e-01) 
2023-05-25 01:19:27.978026: val Epoch: [13][41/72]	Time  0.194 ( 0.734)	Data  0.004 ( 0.401)	Loss 6.5383e-02 (1.7381e-01) 
2023-05-25 01:19:29.046024: val Epoch: [13][42/72]	Time  1.068 ( 0.742)	Data  0.724 ( 0.408)	Loss 2.0771e-01 (1.7459e-01) 
2023-05-25 01:19:29.281996: val Epoch: [13][43/72]	Time  0.236 ( 0.731)	Data  0.001 ( 0.399)	Loss 8.3764e-02 (1.7253e-01) 
2023-05-25 01:19:30.458252: val Epoch: [13][44/72]	Time  1.176 ( 0.740)	Data  0.802 ( 0.408)	Loss 1.2774e-01 (1.7153e-01) 
2023-05-25 01:19:30.786535: val Epoch: [13][45/72]	Time  0.328 ( 0.731)	Data  0.002 ( 0.399)	Loss 2.0511e-01 (1.7226e-01) 
2023-05-25 01:19:31.666256: val Epoch: [13][46/72]	Time  0.880 ( 0.735)	Data  0.621 ( 0.404)	Loss 6.6076e-02 (1.7001e-01) 
2023-05-25 01:19:32.306285: val Epoch: [13][47/72]	Time  0.640 ( 0.733)	Data  0.137 ( 0.398)	Loss 3.0706e-01 (1.7286e-01) 
2023-05-25 01:19:32.925805: val Epoch: [13][48/72]	Time  0.619 ( 0.730)	Data  0.389 ( 0.398)	Loss 6.6780e-02 (1.7070e-01) 
2023-05-25 01:19:33.551374: val Epoch: [13][49/72]	Time  0.626 ( 0.728)	Data  0.274 ( 0.396)	Loss 1.1351e-01 (1.6955e-01) 
2023-05-25 01:19:34.575195: val Epoch: [13][50/72]	Time  1.024 ( 0.734)	Data  0.638 ( 0.400)	Loss 1.7617e-01 (1.6968e-01) 
2023-05-25 01:19:35.031207: val Epoch: [13][51/72]	Time  0.456 ( 0.729)	Data  0.121 ( 0.395)	Loss 3.3280e-01 (1.7282e-01) 
2023-05-25 01:19:35.917022: val Epoch: [13][52/72]	Time  0.886 ( 0.732)	Data  0.679 ( 0.400)	Loss 1.4502e-01 (1.7229e-01) 
2023-05-25 01:19:36.397432: val Epoch: [13][53/72]	Time  0.480 ( 0.727)	Data  0.166 ( 0.396)	Loss 9.9569e-02 (1.7095e-01) 
2023-05-25 01:19:37.365659: val Epoch: [13][54/72]	Time  0.968 ( 0.731)	Data  0.752 ( 0.402)	Loss 1.2548e-01 (1.7012e-01) 
2023-05-25 01:19:37.712734: val Epoch: [13][55/72]	Time  0.347 ( 0.725)	Data  0.093 ( 0.397)	Loss 5.2808e-01 (1.7651e-01) 
2023-05-25 01:19:39.035403: val Epoch: [13][56/72]	Time  1.323 ( 0.735)	Data  0.925 ( 0.406)	Loss 1.3422e-01 (1.7577e-01) 
2023-05-25 01:19:39.392136: val Epoch: [13][57/72]	Time  0.357 ( 0.729)	Data  0.001 ( 0.399)	Loss 9.2976e-02 (1.7434e-01) 
2023-05-25 01:19:40.436793: val Epoch: [13][58/72]	Time  1.045 ( 0.734)	Data  0.695 ( 0.404)	Loss 6.6682e-02 (1.7252e-01) 
2023-05-25 01:19:40.821356: val Epoch: [13][59/72]	Time  0.385 ( 0.728)	Data  0.001 ( 0.397)	Loss 8.0236e-02 (1.7098e-01) 
2023-05-25 01:19:41.999051: val Epoch: [13][60/72]	Time  1.178 ( 0.735)	Data  0.806 ( 0.404)	Loss 9.4614e-02 (1.6973e-01) 
2023-05-25 01:19:42.296682: val Epoch: [13][61/72]	Time  0.298 ( 0.728)	Data  0.001 ( 0.398)	Loss 1.8628e-01 (1.7000e-01) 
2023-05-25 01:19:43.569133: val Epoch: [13][62/72]	Time  1.272 ( 0.737)	Data  0.881 ( 0.405)	Loss 2.9266e-01 (1.7194e-01) 
2023-05-25 01:19:44.100621: val Epoch: [13][63/72]	Time  0.531 ( 0.734)	Data  0.001 ( 0.399)	Loss 5.7970e-02 (1.7016e-01) 
2023-05-25 01:19:44.919601: val Epoch: [13][64/72]	Time  0.819 ( 0.735)	Data  0.547 ( 0.401)	Loss 1.6534e-01 (1.7009e-01) 
2023-05-25 01:19:45.207756: val Epoch: [13][65/72]	Time  0.288 ( 0.728)	Data  0.001 ( 0.395)	Loss 8.8218e-02 (1.6885e-01) 
2023-05-25 01:19:46.505791: val Epoch: [13][66/72]	Time  1.298 ( 0.737)	Data  0.865 ( 0.402)	Loss 7.3090e-02 (1.6742e-01) 
2023-05-25 01:19:46.920009: val Epoch: [13][67/72]	Time  0.414 ( 0.732)	Data  0.002 ( 0.396)	Loss 1.5691e-01 (1.6726e-01) 
2023-05-25 01:19:47.970127: val Epoch: [13][68/72]	Time  1.050 ( 0.737)	Data  0.620 ( 0.400)	Loss 1.1774e-01 (1.6655e-01) 
2023-05-25 01:19:48.154408: val Epoch: [13][69/72]	Time  0.184 ( 0.729)	Data  0.001 ( 0.394)	Loss 1.8890e-01 (1.6687e-01) 
2023-05-25 01:19:49.122874: val Epoch: [13][70/72]	Time  0.968 ( 0.732)	Data  0.689 ( 0.398)	Loss 1.0619e-01 (1.6601e-01) 
2023-05-25 01:19:49.433287: val Epoch: [13][71/72]	Time  0.310 ( 0.726)	Data  0.001 ( 0.393)	Loss 1.6941e-01 (1.6606e-01) 
2023-05-25 01:19:49.719620: Epoch 13 :Val : ['ET : 0.6807893514633179', 'TC : 0.73207688331604', 'WT : 0.8262484669685364'] 
2023-05-25 01:19:49.725576: Epoch 13 :Val : ['ET : 0.6807893514633179', 'TC : 0.73207688331604', 'WT : 0.8262484669685364'] 
2023-05-25 01:19:49.730265: Saving the model with DSC 0.7455924153327942 
2023-05-25 01:19:50.804198: Val epoch done in 54.56009644898586 s 
2023-05-25 01:19:50.810882: Batches per epoch:  193 
2023-05-25 01:19:55.162072: train Epoch: [14][  0/193]	Time  4.351 ( 4.351)	Data  3.011 ( 3.011)	Loss 1.4272e-01 (1.4272e-01) 
2023-05-25 01:19:56.164909: train Epoch: [14][  1/193]	Time  1.003 ( 2.677)	Data  0.001 ( 1.506)	Loss 7.0831e-02 (1.0678e-01) 
2023-05-25 01:19:57.448687: train Epoch: [14][  2/193]	Time  1.284 ( 2.212)	Data  0.266 ( 1.093)	Loss 8.2949e-02 (9.8834e-02) 
2023-05-25 01:19:58.620021: train Epoch: [14][  3/193]	Time  1.171 ( 1.952)	Data  0.002 ( 0.820)	Loss 1.3506e-01 (1.0789e-01) 
2023-05-25 01:20:00.128528: train Epoch: [14][  4/193]	Time  1.509 ( 1.863)	Data  0.389 ( 0.734)	Loss 9.3805e-02 (1.0507e-01) 
2023-05-25 01:20:01.171889: train Epoch: [14][  5/193]	Time  1.043 ( 1.727)	Data  0.001 ( 0.612)	Loss 1.9905e-01 (1.2074e-01) 
2023-05-25 01:20:02.748468: train Epoch: [14][  6/193]	Time  1.577 ( 1.705)	Data  0.490 ( 0.595)	Loss 1.0798e-01 (1.1891e-01) 
2023-05-25 01:20:03.886344: train Epoch: [14][  7/193]	Time  1.138 ( 1.634)	Data  0.051 ( 0.527)	Loss 1.1496e-01 (1.1842e-01) 
2023-05-25 01:20:05.447615: train Epoch: [14][  8/193]	Time  1.561 ( 1.626)	Data  0.474 ( 0.521)	Loss 6.1362e-02 (1.1208e-01) 
2023-05-25 01:20:06.870724: train Epoch: [14][  9/193]	Time  1.423 ( 1.606)	Data  0.325 ( 0.501)	Loss 1.1085e-01 (1.1196e-01) 
2023-05-25 01:20:07.993042: train Epoch: [14][ 10/193]	Time  1.122 ( 1.562)	Data  0.146 ( 0.469)	Loss 1.1290e-01 (1.1204e-01) 
2023-05-25 01:20:09.625548: train Epoch: [14][ 11/193]	Time  1.633 ( 1.568)	Data  0.597 ( 0.480)	Loss 1.1750e-01 (1.1250e-01) 
2023-05-25 01:20:10.810091: train Epoch: [14][ 12/193]	Time  1.185 ( 1.538)	Data  0.157 ( 0.455)	Loss 1.2921e-01 (1.1378e-01) 
2023-05-25 01:20:12.459957: train Epoch: [14][ 13/193]	Time  1.650 ( 1.546)	Data  0.626 ( 0.467)	Loss 8.7890e-02 (1.1193e-01) 
2023-05-25 01:20:13.517390: train Epoch: [14][ 14/193]	Time  1.057 ( 1.514)	Data  0.001 ( 0.436)	Loss 1.0493e-01 (1.1147e-01) 
2023-05-25 01:20:15.598854: train Epoch: [14][ 15/193]	Time  2.081 ( 1.549)	Data  0.797 ( 0.459)	Loss 1.0736e-01 (1.1121e-01) 
2023-05-25 01:20:16.603997: train Epoch: [14][ 16/193]	Time  1.005 ( 1.517)	Data  0.001 ( 0.432)	Loss 7.1455e-02 (1.0887e-01) 
2023-05-25 01:20:18.453252: train Epoch: [14][ 17/193]	Time  1.849 ( 1.536)	Data  0.478 ( 0.434)	Loss 5.5098e-02 (1.0588e-01) 
2023-05-25 01:20:19.558877: train Epoch: [14][ 18/193]	Time  1.106 ( 1.513)	Data  0.001 ( 0.411)	Loss 2.4719e-01 (1.1332e-01) 
2023-05-25 01:20:21.012167: train Epoch: [14][ 19/193]	Time  1.453 ( 1.510)	Data  0.352 ( 0.408)	Loss 8.2007e-02 (1.1176e-01) 
2023-05-25 01:20:22.051771: train Epoch: [14][ 20/193]	Time  1.040 ( 1.488)	Data  0.001 ( 0.389)	Loss 8.6233e-02 (1.1054e-01) 
2023-05-25 01:20:23.818384: train Epoch: [14][ 21/193]	Time  1.767 ( 1.500)	Data  0.564 ( 0.397)	Loss 6.2664e-02 (1.0836e-01) 
2023-05-25 01:20:25.035657: train Epoch: [14][ 22/193]	Time  1.217 ( 1.488)	Data  0.001 ( 0.380)	Loss 1.6875e-01 (1.1099e-01) 
2023-05-25 01:20:26.550693: train Epoch: [14][ 23/193]	Time  1.515 ( 1.489)	Data  0.327 ( 0.378)	Loss 9.8437e-02 (1.1047e-01) 
2023-05-25 01:20:27.614448: train Epoch: [14][ 24/193]	Time  1.064 ( 1.472)	Data  0.001 ( 0.363)	Loss 1.1818e-01 (1.1077e-01) 
2023-05-25 01:20:29.128368: train Epoch: [14][ 25/193]	Time  1.514 ( 1.474)	Data  0.522 ( 0.369)	Loss 1.2583e-01 (1.1135e-01) 
2023-05-25 01:20:30.149266: train Epoch: [14][ 26/193]	Time  1.021 ( 1.457)	Data  0.001 ( 0.355)	Loss 1.0190e-01 (1.1100e-01) 
2023-05-25 01:20:32.069065: train Epoch: [14][ 27/193]	Time  1.920 ( 1.473)	Data  0.806 ( 0.371)	Loss 8.6051e-02 (1.1011e-01) 
2023-05-25 01:20:33.069178: train Epoch: [14][ 28/193]	Time  1.000 ( 1.457)	Data  0.001 ( 0.358)	Loss 1.6495e-01 (1.1200e-01) 
2023-05-25 01:20:35.059210: train Epoch: [14][ 29/193]	Time  1.990 ( 1.475)	Data  0.852 ( 0.375)	Loss 1.2352e-01 (1.1239e-01) 
2023-05-25 01:20:35.998180: train Epoch: [14][ 30/193]	Time  0.939 ( 1.458)	Data  0.001 ( 0.363)	Loss 8.1348e-02 (1.1139e-01) 
2023-05-25 01:20:37.936844: train Epoch: [14][ 31/193]	Time  1.939 ( 1.473)	Data  0.756 ( 0.375)	Loss 1.0356e-01 (1.1114e-01) 
2023-05-25 01:20:38.936260: train Epoch: [14][ 32/193]	Time  0.999 ( 1.458)	Data  0.001 ( 0.364)	Loss 6.2273e-02 (1.0966e-01) 
2023-05-25 01:20:40.855775: train Epoch: [14][ 33/193]	Time  1.919 ( 1.472)	Data  0.656 ( 0.372)	Loss 1.0775e-01 (1.0960e-01) 
2023-05-25 01:20:41.948301: train Epoch: [14][ 34/193]	Time  1.093 ( 1.461)	Data  0.001 ( 0.362)	Loss 1.5554e-01 (1.1092e-01) 
2023-05-25 01:20:43.574100: train Epoch: [14][ 35/193]	Time  1.626 ( 1.466)	Data  0.507 ( 0.366)	Loss 8.2956e-02 (1.1014e-01) 
2023-05-25 01:20:44.580130: train Epoch: [14][ 36/193]	Time  1.006 ( 1.453)	Data  0.001 ( 0.356)	Loss 9.4172e-02 (1.0971e-01) 
2023-05-25 01:20:46.452420: train Epoch: [14][ 37/193]	Time  1.872 ( 1.464)	Data  0.740 ( 0.366)	Loss 2.0041e-01 (1.1210e-01) 
2023-05-25 01:20:47.454892: train Epoch: [14][ 38/193]	Time  1.002 ( 1.452)	Data  0.001 ( 0.357)	Loss 2.1658e-01 (1.1478e-01) 
2023-05-25 01:20:49.383939: train Epoch: [14][ 39/193]	Time  1.929 ( 1.464)	Data  0.680 ( 0.365)	Loss 1.1870e-01 (1.1487e-01) 
2023-05-25 01:20:50.414251: train Epoch: [14][ 40/193]	Time  1.030 ( 1.454)	Data  0.001 ( 0.356)	Loss 1.1991e-01 (1.1500e-01) 
2023-05-25 01:20:52.132308: train Epoch: [14][ 41/193]	Time  1.718 ( 1.460)	Data  0.483 ( 0.359)	Loss 1.0866e-01 (1.1485e-01) 
2023-05-25 01:20:53.135318: train Epoch: [14][ 42/193]	Time  1.003 ( 1.449)	Data  0.001 ( 0.351)	Loss 1.5760e-01 (1.1584e-01) 
2023-05-25 01:20:54.948136: train Epoch: [14][ 43/193]	Time  1.813 ( 1.458)	Data  0.571 ( 0.356)	Loss 9.6185e-02 (1.1539e-01) 
2023-05-25 01:20:55.929900: train Epoch: [14][ 44/193]	Time  0.982 ( 1.447)	Data  0.001 ( 0.348)	Loss 7.7495e-02 (1.1455e-01) 
2023-05-25 01:20:57.548883: train Epoch: [14][ 45/193]	Time  1.619 ( 1.451)	Data  0.504 ( 0.351)	Loss 7.5640e-02 (1.1370e-01) 
2023-05-25 01:20:58.654514: train Epoch: [14][ 46/193]	Time  1.106 ( 1.443)	Data  0.001 ( 0.344)	Loss 8.3197e-02 (1.1306e-01) 
2023-05-25 01:21:00.361526: train Epoch: [14][ 47/193]	Time  1.707 ( 1.449)	Data  0.527 ( 0.348)	Loss 1.3530e-01 (1.1352e-01) 
2023-05-25 01:21:01.601762: train Epoch: [14][ 48/193]	Time  1.240 ( 1.445)	Data  0.001 ( 0.340)	Loss 1.0440e-01 (1.1333e-01) 
2023-05-25 01:21:03.149507: train Epoch: [14][ 49/193]	Time  1.548 ( 1.447)	Data  0.433 ( 0.342)	Loss 1.7183e-01 (1.1450e-01) 
2023-05-25 01:21:04.197801: train Epoch: [14][ 50/193]	Time  1.048 ( 1.439)	Data  0.001 ( 0.336)	Loss 2.2812e-01 (1.1673e-01) 
2023-05-25 01:21:05.954800: train Epoch: [14][ 51/193]	Time  1.757 ( 1.445)	Data  0.643 ( 0.342)	Loss 1.5713e-01 (1.1751e-01) 
2023-05-25 01:21:07.195032: train Epoch: [14][ 52/193]	Time  1.240 ( 1.441)	Data  0.001 ( 0.335)	Loss 1.1777e-01 (1.1751e-01) 
2023-05-25 01:21:08.762000: train Epoch: [14][ 53/193]	Time  1.567 ( 1.444)	Data  0.448 ( 0.337)	Loss 7.9246e-02 (1.1680e-01) 
2023-05-25 01:21:09.950553: train Epoch: [14][ 54/193]	Time  1.189 ( 1.439)	Data  0.001 ( 0.331)	Loss 1.1447e-01 (1.1676e-01) 
2023-05-25 01:21:11.525879: train Epoch: [14][ 55/193]	Time  1.575 ( 1.441)	Data  0.583 ( 0.336)	Loss 1.6323e-01 (1.1759e-01) 
2023-05-25 01:21:12.549499: train Epoch: [14][ 56/193]	Time  1.024 ( 1.434)	Data  0.001 ( 0.330)	Loss 8.0548e-02 (1.1694e-01) 
2023-05-25 01:21:14.521818: train Epoch: [14][ 57/193]	Time  1.972 ( 1.443)	Data  0.828 ( 0.338)	Loss 1.0369e-01 (1.1671e-01) 
2023-05-25 01:21:15.538018: train Epoch: [14][ 58/193]	Time  1.016 ( 1.436)	Data  0.001 ( 0.333)	Loss 1.5548e-01 (1.1737e-01) 
2023-05-25 01:21:17.398353: train Epoch: [14][ 59/193]	Time  1.860 ( 1.443)	Data  0.595 ( 0.337)	Loss 1.9058e-01 (1.1859e-01) 
2023-05-25 01:21:18.431134: train Epoch: [14][ 60/193]	Time  1.033 ( 1.436)	Data  0.001 ( 0.331)	Loss 1.2809e-01 (1.1875e-01) 
2023-05-25 01:21:20.379417: train Epoch: [14][ 61/193]	Time  1.948 ( 1.445)	Data  0.605 ( 0.336)	Loss 2.0019e-01 (1.2006e-01) 
2023-05-25 01:21:21.398449: train Epoch: [14][ 62/193]	Time  1.019 ( 1.438)	Data  0.001 ( 0.331)	Loss 1.3153e-01 (1.2024e-01) 
2023-05-25 01:21:23.018160: train Epoch: [14][ 63/193]	Time  1.620 ( 1.441)	Data  0.463 ( 0.333)	Loss 8.8296e-02 (1.1974e-01) 
2023-05-25 01:21:24.069874: train Epoch: [14][ 64/193]	Time  1.052 ( 1.435)	Data  0.001 ( 0.328)	Loss 8.2670e-02 (1.1917e-01) 
2023-05-25 01:21:25.895505: train Epoch: [14][ 65/193]	Time  1.826 ( 1.441)	Data  0.598 ( 0.332)	Loss 8.2364e-02 (1.1861e-01) 
2023-05-25 01:21:26.937679: train Epoch: [14][ 66/193]	Time  1.042 ( 1.435)	Data  0.001 ( 0.327)	Loss 7.6038e-02 (1.1798e-01) 
2023-05-25 01:21:28.516052: train Epoch: [14][ 67/193]	Time  1.578 ( 1.437)	Data  0.526 ( 0.330)	Loss 2.4369e-01 (1.1983e-01) 
2023-05-25 01:21:29.607595: train Epoch: [14][ 68/193]	Time  1.092 ( 1.432)	Data  0.001 ( 0.325)	Loss 5.4790e-02 (1.1888e-01) 
2023-05-25 01:21:31.519305: train Epoch: [14][ 69/193]	Time  1.912 ( 1.439)	Data  0.720 ( 0.331)	Loss 1.3839e-01 (1.1916e-01) 
2023-05-25 01:21:32.682596: train Epoch: [14][ 70/193]	Time  1.163 ( 1.435)	Data  0.001 ( 0.326)	Loss 8.5810e-02 (1.1869e-01) 
2023-05-25 01:21:34.366507: train Epoch: [14][ 71/193]	Time  1.684 ( 1.438)	Data  0.507 ( 0.328)	Loss 1.4203e-01 (1.1902e-01) 
2023-05-25 01:21:35.659885: train Epoch: [14][ 72/193]	Time  1.293 ( 1.436)	Data  0.001 ( 0.324)	Loss 1.0230e-01 (1.1879e-01) 
2023-05-25 01:21:36.974120: train Epoch: [14][ 73/193]	Time  1.314 ( 1.435)	Data  0.295 ( 0.324)	Loss 1.1875e-01 (1.1879e-01) 
2023-05-25 01:21:38.002553: train Epoch: [14][ 74/193]	Time  1.028 ( 1.429)	Data  0.001 ( 0.319)	Loss 8.9767e-02 (1.1840e-01) 
2023-05-25 01:21:39.680276: train Epoch: [14][ 75/193]	Time  1.678 ( 1.432)	Data  0.668 ( 0.324)	Loss 1.2456e-01 (1.1848e-01) 
2023-05-25 01:21:40.752356: train Epoch: [14][ 76/193]	Time  1.072 ( 1.428)	Data  0.001 ( 0.320)	Loss 1.3201e-01 (1.1866e-01) 
2023-05-25 01:21:42.440101: train Epoch: [14][ 77/193]	Time  1.688 ( 1.431)	Data  0.616 ( 0.323)	Loss 2.0261e-01 (1.1973e-01) 
2023-05-25 01:21:43.411611: train Epoch: [14][ 78/193]	Time  0.972 ( 1.425)	Data  0.001 ( 0.319)	Loss 1.1808e-01 (1.1971e-01) 
2023-05-25 01:21:45.305830: train Epoch: [14][ 79/193]	Time  1.894 ( 1.431)	Data  0.692 ( 0.324)	Loss 1.8096e-01 (1.2048e-01) 
2023-05-25 01:21:46.280187: train Epoch: [14][ 80/193]	Time  0.974 ( 1.426)	Data  0.001 ( 0.320)	Loss 7.7974e-02 (1.1995e-01) 
2023-05-25 01:21:48.066193: train Epoch: [14][ 81/193]	Time  1.786 ( 1.430)	Data  0.508 ( 0.322)	Loss 1.0955e-01 (1.1983e-01) 
2023-05-25 01:21:49.018686: train Epoch: [14][ 82/193]	Time  0.952 ( 1.424)	Data  0.001 ( 0.318)	Loss 1.2185e-01 (1.1985e-01) 
2023-05-25 01:21:50.850101: train Epoch: [14][ 83/193]	Time  1.831 ( 1.429)	Data  0.549 ( 0.321)	Loss 1.0294e-01 (1.1965e-01) 
2023-05-25 01:21:51.909181: train Epoch: [14][ 84/193]	Time  1.059 ( 1.425)	Data  0.001 ( 0.317)	Loss 1.0072e-01 (1.1943e-01) 
2023-05-25 01:21:53.370003: train Epoch: [14][ 85/193]	Time  1.461 ( 1.425)	Data  0.443 ( 0.319)	Loss 1.2564e-01 (1.1950e-01) 
2023-05-25 01:21:54.455495: train Epoch: [14][ 86/193]	Time  1.085 ( 1.421)	Data  0.001 ( 0.315)	Loss 9.7437e-02 (1.1925e-01) 
2023-05-25 01:21:56.484212: train Epoch: [14][ 87/193]	Time  2.029 ( 1.428)	Data  0.860 ( 0.321)	Loss 6.7699e-02 (1.1866e-01) 
2023-05-25 01:21:57.620286: train Epoch: [14][ 88/193]	Time  1.136 ( 1.425)	Data  0.001 ( 0.318)	Loss 8.5128e-02 (1.1828e-01) 
2023-05-25 01:21:59.200131: train Epoch: [14][ 89/193]	Time  1.580 ( 1.427)	Data  0.499 ( 0.320)	Loss 8.2675e-02 (1.1789e-01) 
2023-05-25 01:22:00.182413: train Epoch: [14][ 90/193]	Time  0.982 ( 1.422)	Data  0.001 ( 0.316)	Loss 8.4148e-02 (1.1752e-01) 
2023-05-25 01:22:01.803194: train Epoch: [14][ 91/193]	Time  1.621 ( 1.424)	Data  0.695 ( 0.320)	Loss 1.8460e-01 (1.1825e-01) 
2023-05-25 01:22:02.806554: train Epoch: [14][ 92/193]	Time  1.003 ( 1.419)	Data  0.001 ( 0.317)	Loss 7.0524e-02 (1.1773e-01) 
2023-05-25 01:22:04.979098: train Epoch: [14][ 93/193]	Time  2.173 ( 1.427)	Data  0.928 ( 0.324)	Loss 9.9990e-02 (1.1754e-01) 
2023-05-25 01:22:06.004311: train Epoch: [14][ 94/193]	Time  1.025 ( 1.423)	Data  0.001 ( 0.320)	Loss 8.0809e-02 (1.1716e-01) 
2023-05-25 01:22:07.793205: train Epoch: [14][ 95/193]	Time  1.789 ( 1.427)	Data  0.530 ( 0.322)	Loss 9.3415e-02 (1.1691e-01) 
2023-05-25 01:22:08.774330: train Epoch: [14][ 96/193]	Time  0.981 ( 1.422)	Data  0.001 ( 0.319)	Loss 1.6324e-01 (1.1739e-01) 
2023-05-25 01:22:10.637607: train Epoch: [14][ 97/193]	Time  1.863 ( 1.427)	Data  0.548 ( 0.321)	Loss 9.3808e-02 (1.1715e-01) 
2023-05-25 01:22:11.615066: train Epoch: [14][ 98/193]	Time  0.977 ( 1.422)	Data  0.001 ( 0.318)	Loss 1.2727e-01 (1.1725e-01) 
2023-05-25 01:22:13.491624: train Epoch: [14][ 99/193]	Time  1.877 ( 1.427)	Data  0.466 ( 0.320)	Loss 1.1820e-01 (1.1726e-01) 
2023-05-25 01:22:14.470766: train Epoch: [14][100/193]	Time  0.979 ( 1.422)	Data  0.001 ( 0.316)	Loss 1.9110e-01 (1.1799e-01) 
2023-05-25 01:22:15.873528: train Epoch: [14][101/193]	Time  1.403 ( 1.422)	Data  0.274 ( 0.316)	Loss 9.0972e-02 (1.1773e-01) 
2023-05-25 01:22:16.986682: train Epoch: [14][102/193]	Time  1.113 ( 1.419)	Data  0.001 ( 0.313)	Loss 1.2880e-01 (1.1783e-01) 
2023-05-25 01:22:18.563619: train Epoch: [14][103/193]	Time  1.577 ( 1.421)	Data  0.487 ( 0.315)	Loss 1.0449e-01 (1.1770e-01) 
2023-05-25 01:22:19.685098: train Epoch: [14][104/193]	Time  1.122 ( 1.418)	Data  0.002 ( 0.312)	Loss 8.6318e-02 (1.1741e-01) 
2023-05-25 01:22:21.285087: train Epoch: [14][105/193]	Time  1.600 ( 1.420)	Data  0.405 ( 0.313)	Loss 9.5154e-02 (1.1720e-01) 
2023-05-25 01:22:22.283388: train Epoch: [14][106/193]	Time  0.998 ( 1.416)	Data  0.001 ( 0.310)	Loss 1.2802e-01 (1.1730e-01) 
2023-05-25 01:22:23.760487: train Epoch: [14][107/193]	Time  1.477 ( 1.416)	Data  0.450 ( 0.311)	Loss 7.9533e-02 (1.1695e-01) 
2023-05-25 01:22:24.797936: train Epoch: [14][108/193]	Time  1.037 ( 1.413)	Data  0.001 ( 0.308)	Loss 8.3569e-02 (1.1664e-01) 
2023-05-25 01:22:26.674343: train Epoch: [14][109/193]	Time  1.876 ( 1.417)	Data  0.732 ( 0.312)	Loss 1.5757e-01 (1.1701e-01) 
2023-05-25 01:22:27.908821: train Epoch: [14][110/193]	Time  1.234 ( 1.415)	Data  0.001 ( 0.309)	Loss 1.7848e-01 (1.1757e-01) 
2023-05-25 01:22:29.277302: train Epoch: [14][111/193]	Time  1.368 ( 1.415)	Data  0.343 ( 0.309)	Loss 1.1413e-01 (1.1754e-01) 
2023-05-25 01:22:30.461468: train Epoch: [14][112/193]	Time  1.184 ( 1.413)	Data  0.001 ( 0.307)	Loss 1.1499e-01 (1.1751e-01) 
2023-05-25 01:22:32.099637: train Epoch: [14][113/193]	Time  1.638 ( 1.415)	Data  0.569 ( 0.309)	Loss 6.1685e-02 (1.1702e-01) 
2023-05-25 01:22:33.144237: train Epoch: [14][114/193]	Time  1.045 ( 1.412)	Data  0.001 ( 0.306)	Loss 9.8325e-02 (1.1686e-01) 
2023-05-25 01:22:34.808075: train Epoch: [14][115/193]	Time  1.664 ( 1.414)	Data  0.687 ( 0.310)	Loss 4.2169e-02 (1.1622e-01) 
2023-05-25 01:22:35.843380: train Epoch: [14][116/193]	Time  1.035 ( 1.411)	Data  0.001 ( 0.307)	Loss 6.6786e-02 (1.1580e-01) 
2023-05-25 01:22:37.638937: train Epoch: [14][117/193]	Time  1.796 ( 1.414)	Data  0.803 ( 0.311)	Loss 1.1758e-01 (1.1581e-01) 
2023-05-25 01:22:38.585793: train Epoch: [14][118/193]	Time  0.947 ( 1.410)	Data  0.001 ( 0.309)	Loss 9.7475e-02 (1.1566e-01) 
2023-05-25 01:22:40.812067: train Epoch: [14][119/193]	Time  2.226 ( 1.417)	Data  0.943 ( 0.314)	Loss 1.3315e-01 (1.1580e-01) 
2023-05-25 01:22:41.884232: train Epoch: [14][120/193]	Time  1.072 ( 1.414)	Data  0.001 ( 0.311)	Loss 8.4214e-02 (1.1554e-01) 
2023-05-25 01:22:43.591075: train Epoch: [14][121/193]	Time  1.707 ( 1.416)	Data  0.478 ( 0.313)	Loss 9.3368e-02 (1.1536e-01) 
2023-05-25 01:22:44.581678: train Epoch: [14][122/193]	Time  0.991 ( 1.413)	Data  0.001 ( 0.310)	Loss 2.0855e-01 (1.1612e-01) 
2023-05-25 01:22:46.728217: train Epoch: [14][123/193]	Time  2.147 ( 1.419)	Data  0.643 ( 0.313)	Loss 2.0844e-01 (1.1686e-01) 
2023-05-25 01:22:47.787267: train Epoch: [14][124/193]	Time  1.059 ( 1.416)	Data  0.001 ( 0.310)	Loss 1.6955e-01 (1.1728e-01) 
2023-05-25 01:22:49.078382: train Epoch: [14][125/193]	Time  1.291 ( 1.415)	Data  0.231 ( 0.310)	Loss 9.1057e-02 (1.1707e-01) 
2023-05-25 01:22:50.194799: train Epoch: [14][126/193]	Time  1.116 ( 1.412)	Data  0.001 ( 0.307)	Loss 1.4670e-01 (1.1731e-01) 
2023-05-25 01:22:52.092169: train Epoch: [14][127/193]	Time  1.897 ( 1.416)	Data  0.603 ( 0.310)	Loss 2.4640e-01 (1.1832e-01) 
2023-05-25 01:22:53.042741: train Epoch: [14][128/193]	Time  0.951 ( 1.413)	Data  0.001 ( 0.307)	Loss 8.8768e-02 (1.1809e-01) 
2023-05-25 01:22:54.794510: train Epoch: [14][129/193]	Time  1.752 ( 1.415)	Data  0.622 ( 0.310)	Loss 1.6073e-01 (1.1842e-01) 
2023-05-25 01:22:55.940709: train Epoch: [14][130/193]	Time  1.146 ( 1.413)	Data  0.001 ( 0.307)	Loss 8.7900e-02 (1.1818e-01) 
2023-05-25 01:22:57.554053: train Epoch: [14][131/193]	Time  1.613 ( 1.415)	Data  0.515 ( 0.309)	Loss 6.9261e-02 (1.1781e-01) 
2023-05-25 01:22:58.669410: train Epoch: [14][132/193]	Time  1.115 ( 1.412)	Data  0.001 ( 0.306)	Loss 9.4787e-02 (1.1764e-01) 
2023-05-25 01:23:00.442387: train Epoch: [14][133/193]	Time  1.773 ( 1.415)	Data  0.722 ( 0.310)	Loss 9.5499e-02 (1.1747e-01) 
2023-05-25 01:23:01.587466: train Epoch: [14][134/193]	Time  1.145 ( 1.413)	Data  0.001 ( 0.307)	Loss 9.2739e-02 (1.1729e-01) 
2023-05-25 01:23:03.555677: train Epoch: [14][135/193]	Time  1.968 ( 1.417)	Data  0.611 ( 0.310)	Loss 1.4151e-01 (1.1747e-01) 
2023-05-25 01:23:04.607296: train Epoch: [14][136/193]	Time  1.052 ( 1.415)	Data  0.001 ( 0.307)	Loss 9.1535e-02 (1.1728e-01) 
2023-05-25 01:23:06.259382: train Epoch: [14][137/193]	Time  1.652 ( 1.416)	Data  0.437 ( 0.308)	Loss 1.3009e-01 (1.1737e-01) 
2023-05-25 01:23:07.370352: train Epoch: [14][138/193]	Time  1.111 ( 1.414)	Data  0.001 ( 0.306)	Loss 9.2990e-02 (1.1720e-01) 
2023-05-25 01:23:09.266184: train Epoch: [14][139/193]	Time  1.896 ( 1.418)	Data  0.609 ( 0.308)	Loss 1.3615e-01 (1.1733e-01) 
2023-05-25 01:23:10.274764: train Epoch: [14][140/193]	Time  1.009 ( 1.415)	Data  0.001 ( 0.306)	Loss 9.8731e-02 (1.1720e-01) 
2023-05-25 01:23:12.141573: train Epoch: [14][141/193]	Time  1.867 ( 1.418)	Data  0.608 ( 0.308)	Loss 9.1709e-02 (1.1702e-01) 
2023-05-25 01:23:13.208769: train Epoch: [14][142/193]	Time  1.067 ( 1.415)	Data  0.001 ( 0.306)	Loss 1.6939e-01 (1.1739e-01) 
2023-05-25 01:23:15.073592: train Epoch: [14][143/193]	Time  1.865 ( 1.418)	Data  0.614 ( 0.308)	Loss 9.6385e-02 (1.1724e-01) 
2023-05-25 01:23:16.219466: train Epoch: [14][144/193]	Time  1.146 ( 1.417)	Data  0.001 ( 0.306)	Loss 1.0551e-01 (1.1716e-01) 
2023-05-25 01:23:17.710040: train Epoch: [14][145/193]	Time  1.491 ( 1.417)	Data  0.445 ( 0.307)	Loss 8.8243e-02 (1.1696e-01) 
2023-05-25 01:23:18.844779: train Epoch: [14][146/193]	Time  1.135 ( 1.415)	Data  0.001 ( 0.305)	Loss 8.8753e-02 (1.1677e-01) 
2023-05-25 01:23:20.647477: train Epoch: [14][147/193]	Time  1.803 ( 1.418)	Data  0.679 ( 0.307)	Loss 1.0640e-01 (1.1670e-01) 
2023-05-25 01:23:21.752155: train Epoch: [14][148/193]	Time  1.105 ( 1.416)	Data  0.001 ( 0.305)	Loss 1.4748e-01 (1.1691e-01) 
2023-05-25 01:23:23.431186: train Epoch: [14][149/193]	Time  1.679 ( 1.417)	Data  0.589 ( 0.307)	Loss 1.7071e-01 (1.1727e-01) 
2023-05-25 01:23:24.475492: train Epoch: [14][150/193]	Time  1.044 ( 1.415)	Data  0.001 ( 0.305)	Loss 1.2677e-01 (1.1733e-01) 
2023-05-25 01:23:26.000496: train Epoch: [14][151/193]	Time  1.525 ( 1.416)	Data  0.624 ( 0.307)	Loss 1.0449e-01 (1.1724e-01) 
2023-05-25 01:23:26.960604: train Epoch: [14][152/193]	Time  0.960 ( 1.413)	Data  0.001 ( 0.305)	Loss 6.8189e-02 (1.1692e-01) 
2023-05-25 01:23:29.041839: train Epoch: [14][153/193]	Time  2.081 ( 1.417)	Data  0.873 ( 0.309)	Loss 1.0098e-01 (1.1682e-01) 
2023-05-25 01:23:30.075179: train Epoch: [14][154/193]	Time  1.033 ( 1.415)	Data  0.001 ( 0.307)	Loss 1.3285e-01 (1.1692e-01) 
2023-05-25 01:23:31.856239: train Epoch: [14][155/193]	Time  1.781 ( 1.417)	Data  0.437 ( 0.308)	Loss 1.1256e-01 (1.1690e-01) 
2023-05-25 01:23:32.988016: train Epoch: [14][156/193]	Time  1.132 ( 1.415)	Data  0.001 ( 0.306)	Loss 1.1529e-01 (1.1688e-01) 
2023-05-25 01:23:34.310695: train Epoch: [14][157/193]	Time  1.323 ( 1.415)	Data  0.180 ( 0.305)	Loss 1.7234e-01 (1.1724e-01) 
2023-05-25 01:23:35.364821: train Epoch: [14][158/193]	Time  1.054 ( 1.412)	Data  0.001 ( 0.303)	Loss 1.2610e-01 (1.1729e-01) 
2023-05-25 01:23:37.310295: train Epoch: [14][159/193]	Time  1.945 ( 1.416)	Data  0.603 ( 0.305)	Loss 1.5091e-01 (1.1750e-01) 
2023-05-25 01:23:38.347265: train Epoch: [14][160/193]	Time  1.037 ( 1.413)	Data  0.001 ( 0.303)	Loss 8.6202e-02 (1.1731e-01) 
2023-05-25 01:23:40.220724: train Epoch: [14][161/193]	Time  1.873 ( 1.416)	Data  0.486 ( 0.304)	Loss 8.6918e-02 (1.1712e-01) 
2023-05-25 01:23:41.347816: train Epoch: [14][162/193]	Time  1.127 ( 1.414)	Data  0.001 ( 0.302)	Loss 1.1566e-01 (1.1711e-01) 
2023-05-25 01:23:42.697820: train Epoch: [14][163/193]	Time  1.350 ( 1.414)	Data  0.332 ( 0.303)	Loss 1.2144e-01 (1.1714e-01) 
2023-05-25 01:23:43.736198: train Epoch: [14][164/193]	Time  1.038 ( 1.412)	Data  0.001 ( 0.301)	Loss 1.0523e-01 (1.1707e-01) 
2023-05-25 01:23:45.457332: train Epoch: [14][165/193]	Time  1.721 ( 1.414)	Data  0.659 ( 0.303)	Loss 1.1499e-01 (1.1705e-01) 
2023-05-25 01:23:46.631258: train Epoch: [14][166/193]	Time  1.174 ( 1.412)	Data  0.001 ( 0.301)	Loss 6.8696e-02 (1.1676e-01) 
2023-05-25 01:23:48.581678: train Epoch: [14][167/193]	Time  1.950 ( 1.415)	Data  0.762 ( 0.304)	Loss 1.0627e-01 (1.1670e-01) 
2023-05-25 01:23:49.804916: train Epoch: [14][168/193]	Time  1.223 ( 1.414)	Data  0.001 ( 0.302)	Loss 8.7890e-02 (1.1653e-01) 
2023-05-25 01:23:51.301703: train Epoch: [14][169/193]	Time  1.497 ( 1.415)	Data  0.388 ( 0.303)	Loss 1.0990e-01 (1.1649e-01) 
2023-05-25 01:23:52.497379: train Epoch: [14][170/193]	Time  1.196 ( 1.413)	Data  0.001 ( 0.301)	Loss 1.0854e-01 (1.1644e-01) 
2023-05-25 01:23:54.285841: train Epoch: [14][171/193]	Time  1.788 ( 1.416)	Data  0.591 ( 0.302)	Loss 2.7886e-01 (1.1739e-01) 
2023-05-25 01:23:55.316533: train Epoch: [14][172/193]	Time  1.031 ( 1.413)	Data  0.001 ( 0.301)	Loss 1.1290e-01 (1.1736e-01) 
2023-05-25 01:23:56.902764: train Epoch: [14][173/193]	Time  1.586 ( 1.414)	Data  0.617 ( 0.303)	Loss 6.4768e-02 (1.1706e-01) 
2023-05-25 01:23:57.946438: train Epoch: [14][174/193]	Time  1.044 ( 1.412)	Data  0.001 ( 0.301)	Loss 1.1985e-01 (1.1708e-01) 
2023-05-25 01:23:59.975253: train Epoch: [14][175/193]	Time  2.029 ( 1.416)	Data  0.828 ( 0.304)	Loss 5.1163e-02 (1.1670e-01) 
2023-05-25 01:24:01.029720: train Epoch: [14][176/193]	Time  1.054 ( 1.414)	Data  0.001 ( 0.302)	Loss 7.2272e-02 (1.1645e-01) 
2023-05-25 01:24:02.708517: train Epoch: [14][177/193]	Time  1.679 ( 1.415)	Data  0.490 ( 0.303)	Loss 1.0659e-01 (1.1640e-01) 
2023-05-25 01:24:03.745604: train Epoch: [14][178/193]	Time  1.037 ( 1.413)	Data  0.001 ( 0.301)	Loss 1.6908e-01 (1.1669e-01) 
2023-05-25 01:24:05.646042: train Epoch: [14][179/193]	Time  1.900 ( 1.416)	Data  0.493 ( 0.303)	Loss 1.0837e-01 (1.1664e-01) 
2023-05-25 01:24:06.683000: train Epoch: [14][180/193]	Time  1.037 ( 1.414)	Data  0.001 ( 0.301)	Loss 2.3512e-01 (1.1730e-01) 
2023-05-25 01:24:08.131153: train Epoch: [14][181/193]	Time  1.448 ( 1.414)	Data  0.182 ( 0.300)	Loss 9.2656e-02 (1.1716e-01) 
2023-05-25 01:24:09.221401: train Epoch: [14][182/193]	Time  1.090 ( 1.412)	Data  0.001 ( 0.299)	Loss 1.0692e-01 (1.1711e-01) 
2023-05-25 01:24:11.014407: train Epoch: [14][183/193]	Time  1.793 ( 1.414)	Data  0.474 ( 0.300)	Loss 8.3474e-02 (1.1692e-01) 
2023-05-25 01:24:12.137863: train Epoch: [14][184/193]	Time  1.123 ( 1.413)	Data  0.001 ( 0.298)	Loss 1.7242e-01 (1.1722e-01) 
2023-05-25 01:24:13.767778: train Epoch: [14][185/193]	Time  1.630 ( 1.414)	Data  0.424 ( 0.299)	Loss 1.1494e-01 (1.1721e-01) 
2023-05-25 01:24:14.925889: train Epoch: [14][186/193]	Time  1.158 ( 1.412)	Data  0.001 ( 0.297)	Loss 7.1566e-02 (1.1697e-01) 
2023-05-25 01:24:16.755373: train Epoch: [14][187/193]	Time  1.829 ( 1.415)	Data  0.449 ( 0.298)	Loss 7.4506e-02 (1.1674e-01) 
2023-05-25 01:24:17.899115: train Epoch: [14][188/193]	Time  1.144 ( 1.413)	Data  0.001 ( 0.296)	Loss 1.6719e-01 (1.1701e-01) 
2023-05-25 01:24:19.420759: train Epoch: [14][189/193]	Time  1.522 ( 1.414)	Data  0.275 ( 0.296)	Loss 2.8839e-01 (1.1791e-01) 
2023-05-25 01:24:20.647917: train Epoch: [14][190/193]	Time  1.227 ( 1.413)	Data  0.001 ( 0.295)	Loss 1.2973e-01 (1.1797e-01) 
2023-05-25 01:24:21.905445: train Epoch: [14][191/193]	Time  1.258 ( 1.412)	Data  0.218 ( 0.294)	Loss 2.1816e-01 (1.1849e-01) 
2023-05-25 01:24:23.220258: train Epoch: [14][192/193]	Time  1.315 ( 1.411)	Data  0.001 ( 0.293)	Loss 1.0539e-01 (1.1843e-01) 
2023-05-25 01:24:23.371442: Train Epoch done in 272.56063903996255 s 
2023-05-25 01:24:26.862886: val Epoch: [14][ 0/72]	Time  2.395 ( 2.395)	Data  1.874 ( 1.874)	Loss 1.6669e-01 (1.6669e-01) 
2023-05-25 01:24:27.259115: val Epoch: [14][ 1/72]	Time  0.397 ( 1.396)	Data  0.008 ( 0.941)	Loss 1.1182e-01 (1.3925e-01) 
2023-05-25 01:24:28.193221: val Epoch: [14][ 2/72]	Time  0.934 ( 1.242)	Data  0.531 ( 0.805)	Loss 3.4786e-01 (2.0879e-01) 
2023-05-25 01:24:28.611252: val Epoch: [14][ 3/72]	Time  0.418 ( 1.036)	Data  0.001 ( 0.604)	Loss 6.4850e-02 (1.7280e-01) 
2023-05-25 01:24:29.542495: val Epoch: [14][ 4/72]	Time  0.931 ( 1.015)	Data  0.742 ( 0.631)	Loss 1.0845e-01 (1.5993e-01) 
2023-05-25 01:24:29.809083: val Epoch: [14][ 5/72]	Time  0.267 ( 0.890)	Data  0.001 ( 0.526)	Loss 1.9394e-01 (1.6560e-01) 
2023-05-25 01:24:31.361732: val Epoch: [14][ 6/72]	Time  1.553 ( 0.985)	Data  1.081 ( 0.606)	Loss 5.7950e-02 (1.5022e-01) 
2023-05-25 01:24:31.791908: val Epoch: [14][ 7/72]	Time  0.430 ( 0.916)	Data  0.002 ( 0.530)	Loss 8.0058e-02 (1.4145e-01) 
2023-05-25 01:24:32.715551: val Epoch: [14][ 8/72]	Time  0.924 ( 0.916)	Data  0.632 ( 0.541)	Loss 3.6639e-01 (1.6644e-01) 
2023-05-25 01:24:32.972644: val Epoch: [14][ 9/72]	Time  0.257 ( 0.850)	Data  0.001 ( 0.487)	Loss 8.6347e-02 (1.5843e-01) 
2023-05-25 01:24:34.261971: val Epoch: [14][10/72]	Time  1.289 ( 0.890)	Data  0.911 ( 0.526)	Loss 1.1588e-01 (1.5457e-01) 
2023-05-25 01:24:34.577939: val Epoch: [14][11/72]	Time  0.316 ( 0.843)	Data  0.001 ( 0.482)	Loss 1.5870e-01 (1.5491e-01) 
2023-05-25 01:24:35.813878: val Epoch: [14][12/72]	Time  1.236 ( 0.873)	Data  0.846 ( 0.510)	Loss 6.6005e-02 (1.4807e-01) 
2023-05-25 01:24:36.248833: val Epoch: [14][13/72]	Time  0.435 ( 0.842)	Data  0.001 ( 0.474)	Loss 1.9802e-01 (1.5164e-01) 
2023-05-25 01:24:37.303976: val Epoch: [14][14/72]	Time  1.055 ( 0.856)	Data  0.734 ( 0.491)	Loss 1.1497e-01 (1.4919e-01) 
2023-05-25 01:24:37.923705: val Epoch: [14][15/72]	Time  0.620 ( 0.841)	Data  0.001 ( 0.460)	Loss 1.4526e-01 (1.4895e-01) 
2023-05-25 01:24:38.828595: val Epoch: [14][16/72]	Time  0.905 ( 0.845)	Data  0.552 ( 0.466)	Loss 8.8900e-02 (1.4542e-01) 
2023-05-25 01:24:39.164235: val Epoch: [14][17/72]	Time  0.336 ( 0.816)	Data  0.001 ( 0.440)	Loss 9.0911e-02 (1.4239e-01) 
2023-05-25 01:24:40.139774: val Epoch: [14][18/72]	Time  0.976 ( 0.825)	Data  0.779 ( 0.458)	Loss 8.3074e-02 (1.3927e-01) 
2023-05-25 01:24:40.422804: val Epoch: [14][19/72]	Time  0.283 ( 0.798)	Data  0.001 ( 0.435)	Loss 5.7950e-02 (1.3520e-01) 
2023-05-25 01:24:41.627028: val Epoch: [14][20/72]	Time  1.204 ( 0.817)	Data  0.904 ( 0.457)	Loss 9.5614e-02 (1.3331e-01) 
2023-05-25 01:24:42.182682: val Epoch: [14][21/72]	Time  0.556 ( 0.805)	Data  0.001 ( 0.437)	Loss 2.9043e-01 (1.4046e-01) 
2023-05-25 01:24:43.188073: val Epoch: [14][22/72]	Time  1.005 ( 0.814)	Data  0.535 ( 0.441)	Loss 2.4264e-01 (1.4490e-01) 
2023-05-25 01:24:43.440596: val Epoch: [14][23/72]	Time  0.252 ( 0.791)	Data  0.001 ( 0.423)	Loss 1.0878e-01 (1.4339e-01) 
2023-05-25 01:24:44.441705: val Epoch: [14][24/72]	Time  1.001 ( 0.799)	Data  0.701 ( 0.434)	Loss 3.9384e-01 (1.5341e-01) 
2023-05-25 01:24:44.855135: val Epoch: [14][25/72]	Time  0.413 ( 0.784)	Data  0.002 ( 0.417)	Loss 1.6299e-01 (1.5378e-01) 
2023-05-25 01:24:45.788508: val Epoch: [14][26/72]	Time  0.933 ( 0.790)	Data  0.705 ( 0.428)	Loss 7.6327e-02 (1.5091e-01) 
2023-05-25 01:24:46.113222: val Epoch: [14][27/72]	Time  0.325 ( 0.773)	Data  0.003 ( 0.413)	Loss 2.0388e-01 (1.5280e-01) 
2023-05-25 01:24:47.413989: val Epoch: [14][28/72]	Time  1.301 ( 0.791)	Data  0.853 ( 0.428)	Loss 6.7134e-02 (1.4985e-01) 
2023-05-25 01:24:47.619103: val Epoch: [14][29/72]	Time  0.205 ( 0.772)	Data  0.001 ( 0.414)	Loss 8.8130e-02 (1.4779e-01) 
2023-05-25 01:24:48.647721: val Epoch: [14][30/72]	Time  1.029 ( 0.780)	Data  0.684 ( 0.422)	Loss 1.0084e-01 (1.4628e-01) 
2023-05-25 01:24:49.013152: val Epoch: [14][31/72]	Time  0.365 ( 0.767)	Data  0.003 ( 0.409)	Loss 6.4268e-02 (1.4371e-01) 
2023-05-25 01:24:50.065748: val Epoch: [14][32/72]	Time  1.053 ( 0.776)	Data  0.689 ( 0.418)	Loss 3.9745e-01 (1.5140e-01) 
2023-05-25 01:24:50.544422: val Epoch: [14][33/72]	Time  0.479 ( 0.767)	Data  0.001 ( 0.405)	Loss 7.1824e-02 (1.4906e-01) 
2023-05-25 01:24:51.414418: val Epoch: [14][34/72]	Time  0.870 ( 0.770)	Data  0.658 ( 0.413)	Loss 5.3762e-01 (1.6017e-01) 
2023-05-25 01:24:51.712225: val Epoch: [14][35/72]	Time  0.298 ( 0.757)	Data  0.003 ( 0.401)	Loss 6.8984e-02 (1.5763e-01) 
2023-05-25 01:24:53.192508: val Epoch: [14][36/72]	Time  1.480 ( 0.776)	Data  1.069 ( 0.419)	Loss 1.0433e-01 (1.5619e-01) 
2023-05-25 01:24:53.581891: val Epoch: [14][37/72]	Time  0.389 ( 0.766)	Data  0.001 ( 0.408)	Loss 2.1040e-01 (1.5762e-01) 
2023-05-25 01:24:54.523897: val Epoch: [14][38/72]	Time  0.942 ( 0.771)	Data  0.622 ( 0.414)	Loss 9.9570e-02 (1.5613e-01) 
2023-05-25 01:24:54.795446: val Epoch: [14][39/72]	Time  0.272 ( 0.758)	Data  0.001 ( 0.403)	Loss 7.6869e-02 (1.5415e-01) 
2023-05-25 01:24:56.028986: val Epoch: [14][40/72]	Time  1.233 ( 0.770)	Data  0.892 ( 0.415)	Loss 2.1638e-01 (1.5567e-01) 
2023-05-25 01:24:56.375462: val Epoch: [14][41/72]	Time  0.346 ( 0.760)	Data  0.001 ( 0.405)	Loss 1.1794e-01 (1.5477e-01) 
2023-05-25 01:24:57.532155: val Epoch: [14][42/72]	Time  1.157 ( 0.769)	Data  0.846 ( 0.416)	Loss 6.7342e-02 (1.5273e-01) 
2023-05-25 01:24:57.746340: val Epoch: [14][43/72]	Time  0.214 ( 0.756)	Data  0.001 ( 0.406)	Loss 8.8131e-02 (1.5127e-01) 
2023-05-25 01:24:59.150392: val Epoch: [14][44/72]	Time  1.404 ( 0.771)	Data  0.983 ( 0.419)	Loss 3.6005e-01 (1.5591e-01) 
2023-05-25 01:24:59.388211: val Epoch: [14][45/72]	Time  0.238 ( 0.759)	Data  0.001 ( 0.410)	Loss 1.5528e-01 (1.5589e-01) 
2023-05-25 01:25:00.497146: val Epoch: [14][46/72]	Time  1.109 ( 0.767)	Data  0.639 ( 0.415)	Loss 6.5630e-02 (1.5397e-01) 
2023-05-25 01:25:00.746038: val Epoch: [14][47/72]	Time  0.249 ( 0.756)	Data  0.001 ( 0.406)	Loss 8.5085e-02 (1.5254e-01) 
2023-05-25 01:25:01.790108: val Epoch: [14][48/72]	Time  1.044 ( 0.762)	Data  0.748 ( 0.413)	Loss 7.5711e-02 (1.5097e-01) 
2023-05-25 01:25:02.060174: val Epoch: [14][49/72]	Time  0.270 ( 0.752)	Data  0.001 ( 0.405)	Loss 1.6421e-01 (1.5123e-01) 
2023-05-25 01:25:03.360335: val Epoch: [14][50/72]	Time  1.300 ( 0.763)	Data  0.882 ( 0.414)	Loss 1.3841e-01 (1.5098e-01) 
2023-05-25 01:25:03.715848: val Epoch: [14][51/72]	Time  0.355 ( 0.755)	Data  0.001 ( 0.406)	Loss 1.6893e-01 (1.5133e-01) 
2023-05-25 01:25:04.748062: val Epoch: [14][52/72]	Time  1.032 ( 0.760)	Data  0.616 ( 0.410)	Loss 9.2529e-02 (1.5022e-01) 
2023-05-25 01:25:04.930167: val Epoch: [14][53/72]	Time  0.182 ( 0.749)	Data  0.001 ( 0.403)	Loss 1.6272e-01 (1.5045e-01) 
2023-05-25 01:25:05.986817: val Epoch: [14][54/72]	Time  1.057 ( 0.755)	Data  0.762 ( 0.409)	Loss 5.0236e-01 (1.5685e-01) 
2023-05-25 01:25:06.189902: val Epoch: [14][55/72]	Time  0.203 ( 0.745)	Data  0.001 ( 0.402)	Loss 7.0683e-02 (1.5531e-01) 
2023-05-25 01:25:07.327273: val Epoch: [14][56/72]	Time  1.137 ( 0.752)	Data  0.932 ( 0.411)	Loss 2.2678e-01 (1.5656e-01) 
2023-05-25 01:25:07.640755: val Epoch: [14][57/72]	Time  0.313 ( 0.744)	Data  0.001 ( 0.404)	Loss 1.2599e-01 (1.5604e-01) 
2023-05-25 01:25:09.004142: val Epoch: [14][58/72]	Time  1.363 ( 0.755)	Data  0.915 ( 0.413)	Loss 1.5895e-01 (1.5609e-01) 
2023-05-25 01:25:09.323486: val Epoch: [14][59/72]	Time  0.319 ( 0.748)	Data  0.001 ( 0.406)	Loss 1.6486e-01 (1.5623e-01) 
2023-05-25 01:25:10.298865: val Epoch: [14][60/72]	Time  0.975 ( 0.751)	Data  0.699 ( 0.411)	Loss 1.8292e-01 (1.5667e-01) 
2023-05-25 01:25:10.696577: val Epoch: [14][61/72]	Time  0.398 ( 0.746)	Data  0.008 ( 0.404)	Loss 7.2044e-02 (1.5530e-01) 
2023-05-25 01:25:11.626606: val Epoch: [14][62/72]	Time  0.930 ( 0.749)	Data  0.680 ( 0.409)	Loss 5.8390e-02 (1.5377e-01) 
2023-05-25 01:25:12.160627: val Epoch: [14][63/72]	Time  0.534 ( 0.745)	Data  0.002 ( 0.402)	Loss 1.7160e-01 (1.5404e-01) 
2023-05-25 01:25:13.012941: val Epoch: [14][64/72]	Time  0.852 ( 0.747)	Data  0.593 ( 0.405)	Loss 4.2855e-01 (1.5827e-01) 
2023-05-25 01:25:13.341524: val Epoch: [14][65/72]	Time  0.329 ( 0.741)	Data  0.005 ( 0.399)	Loss 1.7819e-01 (1.5857e-01) 
2023-05-25 01:25:14.544598: val Epoch: [14][66/72]	Time  1.203 ( 0.747)	Data  0.826 ( 0.406)	Loss 9.2331e-02 (1.5758e-01) 
2023-05-25 01:25:14.938035: val Epoch: [14][67/72]	Time  0.393 ( 0.742)	Data  0.003 ( 0.400)	Loss 1.3922e-01 (1.5731e-01) 
2023-05-25 01:25:15.882694: val Epoch: [14][68/72]	Time  0.945 ( 0.745)	Data  0.613 ( 0.403)	Loss 1.4786e-01 (1.5717e-01) 
2023-05-25 01:25:16.159093: val Epoch: [14][69/72]	Time  0.276 ( 0.738)	Data  0.001 ( 0.397)	Loss 1.9640e-01 (1.5773e-01) 
2023-05-25 01:25:17.108919: val Epoch: [14][70/72]	Time  0.950 ( 0.741)	Data  0.602 ( 0.400)	Loss 8.8834e-02 (1.5676e-01) 
2023-05-25 01:25:17.437273: val Epoch: [14][71/72]	Time  0.328 ( 0.736)	Data  0.001 ( 0.394)	Loss 3.1725e-01 (1.5899e-01) 
2023-05-25 01:25:17.709444: Epoch 14 :Val : ['ET : 0.7131083011627197', 'TC : 0.74037766456604', 'WT : 0.8213756680488586'] 
2023-05-25 01:25:17.715329: Epoch 14 :Val : ['ET : 0.7131083011627197', 'TC : 0.74037766456604', 'WT : 0.8213756680488586'] 
2023-05-25 01:25:17.719322: Saving the model with DSC 0.7530187964439392 
2023-05-25 01:25:18.616091: Val epoch done in 55.24462786805816 s 
2023-05-25 01:25:18.625738: Batches per epoch:  193 
2023-05-25 01:25:23.127326: train Epoch: [15][  0/193]	Time  4.501 ( 4.501)	Data  3.390 ( 3.390)	Loss 1.0765e-01 (1.0765e-01) 
2023-05-25 01:25:24.177727: train Epoch: [15][  1/193]	Time  1.050 ( 2.776)	Data  0.001 ( 1.695)	Loss 9.8948e-02 (1.0330e-01) 
2023-05-25 01:25:26.128710: train Epoch: [15][  2/193]	Time  1.951 ( 2.501)	Data  0.687 ( 1.359)	Loss 1.0208e-01 (1.0290e-01) 
2023-05-25 01:25:27.131472: train Epoch: [15][  3/193]	Time  1.003 ( 2.126)	Data  0.001 ( 1.020)	Loss 2.2115e-01 (1.3246e-01) 
2023-05-25 01:25:28.992322: train Epoch: [15][  4/193]	Time  1.861 ( 2.073)	Data  0.542 ( 0.924)	Loss 1.7114e-01 (1.4020e-01) 
2023-05-25 01:25:29.959723: train Epoch: [15][  5/193]	Time  0.967 ( 1.889)	Data  0.001 ( 0.770)	Loss 7.9463e-02 (1.3007e-01) 
2023-05-25 01:25:31.493145: train Epoch: [15][  6/193]	Time  1.533 ( 1.838)	Data  0.442 ( 0.724)	Loss 9.2375e-02 (1.2469e-01) 
2023-05-25 01:25:32.540136: train Epoch: [15][  7/193]	Time  1.047 ( 1.739)	Data  0.001 ( 0.633)	Loss 1.1834e-01 (1.2390e-01) 
2023-05-25 01:25:34.524249: train Epoch: [15][  8/193]	Time  1.984 ( 1.766)	Data  0.681 ( 0.639)	Loss 1.3579e-01 (1.2522e-01) 
2023-05-25 01:25:35.776890: train Epoch: [15][  9/193]	Time  1.253 ( 1.715)	Data  0.001 ( 0.575)	Loss 1.1750e-01 (1.2445e-01) 
2023-05-25 01:25:36.937574: train Epoch: [15][ 10/193]	Time  1.161 ( 1.665)	Data  0.136 ( 0.535)	Loss 6.3590e-02 (1.1891e-01) 
2023-05-25 01:25:38.080518: train Epoch: [15][ 11/193]	Time  1.143 ( 1.621)	Data  0.001 ( 0.490)	Loss 1.0516e-01 (1.1777e-01) 
2023-05-25 01:25:39.677602: train Epoch: [15][ 12/193]	Time  1.597 ( 1.619)	Data  0.568 ( 0.496)	Loss 1.1437e-01 (1.1751e-01) 
2023-05-25 01:25:40.745595: train Epoch: [15][ 13/193]	Time  1.068 ( 1.580)	Data  0.001 ( 0.461)	Loss 2.2927e-01 (1.2549e-01) 
2023-05-25 01:25:42.663423: train Epoch: [15][ 14/193]	Time  1.918 ( 1.602)	Data  0.672 ( 0.475)	Loss 1.1605e-01 (1.2486e-01) 
2023-05-25 01:25:43.622653: train Epoch: [15][ 15/193]	Time  0.959 ( 1.562)	Data  0.001 ( 0.445)	Loss 1.0031e-01 (1.2333e-01) 
2023-05-25 01:25:45.393467: train Epoch: [15][ 16/193]	Time  1.771 ( 1.575)	Data  0.603 ( 0.455)	Loss 7.7106e-02 (1.2061e-01) 
2023-05-25 01:25:46.379783: train Epoch: [15][ 17/193]	Time  0.986 ( 1.542)	Data  0.001 ( 0.430)	Loss 1.3626e-01 (1.2148e-01) 
2023-05-25 01:25:48.399040: train Epoch: [15][ 18/193]	Time  2.019 ( 1.567)	Data  0.528 ( 0.435)	Loss 1.7470e-01 (1.2428e-01) 
2023-05-25 01:25:49.531874: train Epoch: [15][ 19/193]	Time  1.133 ( 1.545)	Data  0.001 ( 0.413)	Loss 1.4630e-01 (1.2538e-01) 
2023-05-25 01:25:50.663064: train Epoch: [15][ 20/193]	Time  1.131 ( 1.526)	Data  0.084 ( 0.397)	Loss 6.7571e-02 (1.2263e-01) 
2023-05-25 01:25:51.945884: train Epoch: [15][ 21/193]	Time  1.283 ( 1.515)	Data  0.001 ( 0.379)	Loss 1.7381e-01 (1.2495e-01) 
2023-05-25 01:25:53.429399: train Epoch: [15][ 22/193]	Time  1.484 ( 1.513)	Data  0.400 ( 0.380)	Loss 1.1641e-01 (1.2458e-01) 
2023-05-25 01:25:54.416749: train Epoch: [15][ 23/193]	Time  0.987 ( 1.491)	Data  0.001 ( 0.364)	Loss 1.2056e-01 (1.2441e-01) 
2023-05-25 01:25:56.216150: train Epoch: [15][ 24/193]	Time  1.799 ( 1.504)	Data  0.686 ( 0.377)	Loss 1.3842e-01 (1.2497e-01) 
2023-05-25 01:25:57.330982: train Epoch: [15][ 25/193]	Time  1.115 ( 1.489)	Data  0.001 ( 0.363)	Loss 1.7483e-01 (1.2689e-01) 
2023-05-25 01:25:58.979268: train Epoch: [15][ 26/193]	Time  1.648 ( 1.495)	Data  0.462 ( 0.367)	Loss 9.4690e-02 (1.2570e-01) 
2023-05-25 01:26:00.159789: train Epoch: [15][ 27/193]	Time  1.181 ( 1.483)	Data  0.001 ( 0.353)	Loss 1.3094e-01 (1.2589e-01) 
2023-05-25 01:26:01.814999: train Epoch: [15][ 28/193]	Time  1.655 ( 1.489)	Data  0.446 ( 0.357)	Loss 9.7220e-02 (1.2490e-01) 
2023-05-25 01:26:02.869353: train Epoch: [15][ 29/193]	Time  1.054 ( 1.475)	Data  0.001 ( 0.345)	Loss 8.0889e-02 (1.2343e-01) 
2023-05-25 01:26:04.411462: train Epoch: [15][ 30/193]	Time  1.542 ( 1.477)	Data  0.405 ( 0.347)	Loss 9.4587e-02 (1.2250e-01) 
2023-05-25 01:26:05.337811: train Epoch: [15][ 31/193]	Time  0.926 ( 1.460)	Data  0.001 ( 0.336)	Loss 2.3778e-01 (1.2610e-01) 
2023-05-25 01:26:06.920509: train Epoch: [15][ 32/193]	Time  1.583 ( 1.463)	Data  0.613 ( 0.344)	Loss 1.1952e-01 (1.2590e-01) 
2023-05-25 01:26:08.079735: train Epoch: [15][ 33/193]	Time  1.159 ( 1.455)	Data  0.001 ( 0.334)	Loss 9.8837e-02 (1.2511e-01) 
2023-05-25 01:26:09.769086: train Epoch: [15][ 34/193]	Time  1.689 ( 1.461)	Data  0.586 ( 0.341)	Loss 8.1175e-02 (1.2385e-01) 
2023-05-25 01:26:10.868613: train Epoch: [15][ 35/193]	Time  1.100 ( 1.451)	Data  0.002 ( 0.332)	Loss 7.9605e-02 (1.2262e-01) 
2023-05-25 01:26:12.387135: train Epoch: [15][ 36/193]	Time  1.519 ( 1.453)	Data  0.527 ( 0.337)	Loss 7.3014e-02 (1.2128e-01) 
2023-05-25 01:26:13.505906: train Epoch: [15][ 37/193]	Time  1.119 ( 1.444)	Data  0.001 ( 0.328)	Loss 7.4248e-02 (1.2004e-01) 
2023-05-25 01:26:15.103409: train Epoch: [15][ 38/193]	Time  1.597 ( 1.448)	Data  0.614 ( 0.336)	Loss 1.1399e-01 (1.1989e-01) 
2023-05-25 01:26:16.088777: train Epoch: [15][ 39/193]	Time  0.985 ( 1.437)	Data  0.001 ( 0.327)	Loss 1.2799e-01 (1.2009e-01) 
2023-05-25 01:26:17.965320: train Epoch: [15][ 40/193]	Time  1.877 ( 1.447)	Data  0.786 ( 0.339)	Loss 1.4812e-01 (1.2078e-01) 
2023-05-25 01:26:18.937665: train Epoch: [15][ 41/193]	Time  0.972 ( 1.436)	Data  0.001 ( 0.331)	Loss 2.0073e-01 (1.2268e-01) 
2023-05-25 01:26:20.860989: train Epoch: [15][ 42/193]	Time  1.923 ( 1.447)	Data  0.793 ( 0.341)	Loss 1.2094e-01 (1.2264e-01) 
2023-05-25 01:26:21.893518: train Epoch: [15][ 43/193]	Time  1.033 ( 1.438)	Data  0.001 ( 0.334)	Loss 8.5806e-02 (1.2180e-01) 
2023-05-25 01:26:23.612659: train Epoch: [15][ 44/193]	Time  1.719 ( 1.444)	Data  0.614 ( 0.340)	Loss 6.3070e-02 (1.2050e-01) 
2023-05-25 01:26:24.650375: train Epoch: [15][ 45/193]	Time  1.038 ( 1.435)	Data  0.003 ( 0.332)	Loss 9.8701e-02 (1.2002e-01) 
2023-05-25 01:26:26.306818: train Epoch: [15][ 46/193]	Time  1.656 ( 1.440)	Data  0.473 ( 0.335)	Loss 6.0549e-02 (1.1876e-01) 
2023-05-25 01:26:27.270907: train Epoch: [15][ 47/193]	Time  0.964 ( 1.430)	Data  0.001 ( 0.328)	Loss 7.6153e-02 (1.1787e-01) 
2023-05-25 01:26:28.966927: train Epoch: [15][ 48/193]	Time  1.696 ( 1.436)	Data  0.515 ( 0.332)	Loss 6.8907e-02 (1.1687e-01) 
2023-05-25 01:26:30.039832: train Epoch: [15][ 49/193]	Time  1.073 ( 1.428)	Data  0.001 ( 0.326)	Loss 6.9147e-02 (1.1592e-01) 
2023-05-25 01:26:31.756259: train Epoch: [15][ 50/193]	Time  1.716 ( 1.434)	Data  0.548 ( 0.330)	Loss 1.3203e-01 (1.1623e-01) 
2023-05-25 01:26:32.701476: train Epoch: [15][ 51/193]	Time  0.945 ( 1.425)	Data  0.001 ( 0.324)	Loss 1.0151e-01 (1.1595e-01) 
2023-05-25 01:26:34.700392: train Epoch: [15][ 52/193]	Time  1.999 ( 1.435)	Data  0.647 ( 0.330)	Loss 7.2300e-02 (1.1512e-01) 
2023-05-25 01:26:35.683245: train Epoch: [15][ 53/193]	Time  0.983 ( 1.427)	Data  0.002 ( 0.324)	Loss 1.2436e-01 (1.1530e-01) 
2023-05-25 01:26:37.385028: train Epoch: [15][ 54/193]	Time  1.702 ( 1.432)	Data  0.469 ( 0.326)	Loss 1.3835e-01 (1.1572e-01) 
2023-05-25 01:26:38.534970: train Epoch: [15][ 55/193]	Time  1.150 ( 1.427)	Data  0.001 ( 0.321)	Loss 1.3165e-01 (1.1600e-01) 
2023-05-25 01:26:40.020603: train Epoch: [15][ 56/193]	Time  1.486 ( 1.428)	Data  0.302 ( 0.320)	Loss 7.7404e-02 (1.1532e-01) 
2023-05-25 01:26:41.074399: train Epoch: [15][ 57/193]	Time  1.054 ( 1.422)	Data  0.001 ( 0.315)	Loss 1.4001e-01 (1.1575e-01) 
2023-05-25 01:26:42.597939: train Epoch: [15][ 58/193]	Time  1.524 ( 1.423)	Data  0.526 ( 0.318)	Loss 1.6696e-01 (1.1662e-01) 
2023-05-25 01:26:43.716873: train Epoch: [15][ 59/193]	Time  1.119 ( 1.418)	Data  0.001 ( 0.313)	Loss 1.3064e-01 (1.1685e-01) 
2023-05-25 01:26:45.412348: train Epoch: [15][ 60/193]	Time  1.695 ( 1.423)	Data  0.687 ( 0.319)	Loss 1.9027e-01 (1.1805e-01) 
2023-05-25 01:26:46.413208: train Epoch: [15][ 61/193]	Time  1.001 ( 1.416)	Data  0.002 ( 0.314)	Loss 5.8987e-02 (1.1710e-01) 
2023-05-25 01:26:48.069835: train Epoch: [15][ 62/193]	Time  1.657 ( 1.420)	Data  0.680 ( 0.320)	Loss 7.7771e-02 (1.1648e-01) 
2023-05-25 01:26:49.034150: train Epoch: [15][ 63/193]	Time  0.964 ( 1.413)	Data  0.001 ( 0.315)	Loss 3.3787e-01 (1.1994e-01) 
2023-05-25 01:26:50.963511: train Epoch: [15][ 64/193]	Time  1.929 ( 1.421)	Data  0.652 ( 0.320)	Loss 1.0417e-01 (1.1969e-01) 
2023-05-25 01:26:51.955690: train Epoch: [15][ 65/193]	Time  0.992 ( 1.414)	Data  0.001 ( 0.315)	Loss 1.5389e-01 (1.2021e-01) 
2023-05-25 01:26:53.602698: train Epoch: [15][ 66/193]	Time  1.647 ( 1.418)	Data  0.480 ( 0.318)	Loss 3.8528e-01 (1.2417e-01) 
2023-05-25 01:26:54.701053: train Epoch: [15][ 67/193]	Time  1.098 ( 1.413)	Data  0.001 ( 0.313)	Loss 7.5428e-02 (1.2345e-01) 
2023-05-25 01:26:56.493127: train Epoch: [15][ 68/193]	Time  1.792 ( 1.418)	Data  0.526 ( 0.316)	Loss 1.8281e-01 (1.2431e-01) 
2023-05-25 01:26:57.581988: train Epoch: [15][ 69/193]	Time  1.089 ( 1.414)	Data  0.001 ( 0.312)	Loss 1.0079e-01 (1.2398e-01) 
2023-05-25 01:26:59.429374: train Epoch: [15][ 70/193]	Time  1.847 ( 1.420)	Data  0.618 ( 0.316)	Loss 2.3020e-01 (1.2547e-01) 
2023-05-25 01:27:00.607575: train Epoch: [15][ 71/193]	Time  1.178 ( 1.416)	Data  0.001 ( 0.312)	Loss 1.0503e-01 (1.2519e-01) 
2023-05-25 01:27:02.070224: train Epoch: [15][ 72/193]	Time  1.463 ( 1.417)	Data  0.425 ( 0.313)	Loss 1.4409e-01 (1.2545e-01) 
2023-05-25 01:27:03.134725: train Epoch: [15][ 73/193]	Time  1.065 ( 1.412)	Data  0.001 ( 0.309)	Loss 1.3458e-01 (1.2557e-01) 
2023-05-25 01:27:04.839868: train Epoch: [15][ 74/193]	Time  1.705 ( 1.416)	Data  0.646 ( 0.313)	Loss 1.2022e-01 (1.2550e-01) 
2023-05-25 01:27:05.934682: train Epoch: [15][ 75/193]	Time  1.095 ( 1.412)	Data  0.001 ( 0.309)	Loss 1.7383e-01 (1.2613e-01) 
2023-05-25 01:27:07.703474: train Epoch: [15][ 76/193]	Time  1.769 ( 1.417)	Data  0.706 ( 0.314)	Loss 1.3925e-01 (1.2630e-01) 
2023-05-25 01:27:08.775826: train Epoch: [15][ 77/193]	Time  1.072 ( 1.412)	Data  0.001 ( 0.310)	Loss 9.1499e-02 (1.2586e-01) 
2023-05-25 01:27:10.572871: train Epoch: [15][ 78/193]	Time  1.797 ( 1.417)	Data  0.641 ( 0.315)	Loss 1.6488e-01 (1.2635e-01) 
2023-05-25 01:27:11.551477: train Epoch: [15][ 79/193]	Time  0.979 ( 1.412)	Data  0.001 ( 0.311)	Loss 1.7570e-01 (1.2697e-01) 
2023-05-25 01:27:13.661397: train Epoch: [15][ 80/193]	Time  2.110 ( 1.420)	Data  0.793 ( 0.317)	Loss 1.1991e-01 (1.2688e-01) 
2023-05-25 01:27:14.651781: train Epoch: [15][ 81/193]	Time  0.990 ( 1.415)	Data  0.001 ( 0.313)	Loss 9.3501e-02 (1.2647e-01) 
2023-05-25 01:27:16.238173: train Epoch: [15][ 82/193]	Time  1.586 ( 1.417)	Data  0.458 ( 0.315)	Loss 1.1195e-01 (1.2630e-01) 
2023-05-25 01:27:17.336175: train Epoch: [15][ 83/193]	Time  1.098 ( 1.413)	Data  0.001 ( 0.311)	Loss 9.2579e-02 (1.2590e-01) 
2023-05-25 01:27:19.174731: train Epoch: [15][ 84/193]	Time  1.839 ( 1.418)	Data  0.645 ( 0.315)	Loss 9.6734e-02 (1.2556e-01) 
2023-05-25 01:27:20.283815: train Epoch: [15][ 85/193]	Time  1.109 ( 1.415)	Data  0.001 ( 0.311)	Loss 1.7533e-01 (1.2613e-01) 
2023-05-25 01:27:21.928535: train Epoch: [15][ 86/193]	Time  1.645 ( 1.417)	Data  0.409 ( 0.312)	Loss 3.3482e-01 (1.2853e-01) 
2023-05-25 01:27:23.160562: train Epoch: [15][ 87/193]	Time  1.232 ( 1.415)	Data  0.001 ( 0.309)	Loss 1.5163e-01 (1.2880e-01) 
2023-05-25 01:27:24.741954: train Epoch: [15][ 88/193]	Time  1.581 ( 1.417)	Data  0.391 ( 0.310)	Loss 1.0249e-01 (1.2850e-01) 
2023-05-25 01:27:25.809360: train Epoch: [15][ 89/193]	Time  1.067 ( 1.413)	Data  0.001 ( 0.306)	Loss 1.5740e-01 (1.2882e-01) 
2023-05-25 01:27:27.410381: train Epoch: [15][ 90/193]	Time  1.601 ( 1.415)	Data  0.584 ( 0.309)	Loss 1.1783e-01 (1.2870e-01) 
2023-05-25 01:27:28.497065: train Epoch: [15][ 91/193]	Time  1.087 ( 1.412)	Data  0.001 ( 0.306)	Loss 1.4649e-01 (1.2889e-01) 
2023-05-25 01:27:30.133728: train Epoch: [15][ 92/193]	Time  1.637 ( 1.414)	Data  0.658 ( 0.310)	Loss 1.0943e-01 (1.2868e-01) 
2023-05-25 01:27:31.142745: train Epoch: [15][ 93/193]	Time  1.009 ( 1.410)	Data  0.001 ( 0.306)	Loss 1.2657e-01 (1.2866e-01) 
2023-05-25 01:27:33.135960: train Epoch: [15][ 94/193]	Time  1.993 ( 1.416)	Data  0.712 ( 0.311)	Loss 1.5111e-01 (1.2890e-01) 
2023-05-25 01:27:34.148201: train Epoch: [15][ 95/193]	Time  1.012 ( 1.412)	Data  0.001 ( 0.307)	Loss 2.2290e-01 (1.2988e-01) 
2023-05-25 01:27:35.835274: train Epoch: [15][ 96/193]	Time  1.687 ( 1.415)	Data  0.367 ( 0.308)	Loss 7.5168e-02 (1.2931e-01) 
2023-05-25 01:27:36.863482: train Epoch: [15][ 97/193]	Time  1.028 ( 1.411)	Data  0.001 ( 0.305)	Loss 7.3159e-02 (1.2874e-01) 
2023-05-25 01:27:38.531224: train Epoch: [15][ 98/193]	Time  1.668 ( 1.413)	Data  0.498 ( 0.307)	Loss 3.8016e-01 (1.3128e-01) 
2023-05-25 01:27:39.599700: train Epoch: [15][ 99/193]	Time  1.068 ( 1.410)	Data  0.001 ( 0.304)	Loss 9.9271e-02 (1.3096e-01) 
2023-05-25 01:27:41.432285: train Epoch: [15][100/193]	Time  1.833 ( 1.414)	Data  0.649 ( 0.307)	Loss 9.9474e-02 (1.3065e-01) 
2023-05-25 01:27:42.551878: train Epoch: [15][101/193]	Time  1.120 ( 1.411)	Data  0.001 ( 0.304)	Loss 1.6986e-01 (1.3103e-01) 
2023-05-25 01:27:44.315909: train Epoch: [15][102/193]	Time  1.764 ( 1.414)	Data  0.550 ( 0.307)	Loss 1.6830e-01 (1.3139e-01) 
2023-05-25 01:27:45.553483: train Epoch: [15][103/193]	Time  1.238 ( 1.413)	Data  0.001 ( 0.304)	Loss 1.6126e-01 (1.3168e-01) 
2023-05-25 01:27:46.971576: train Epoch: [15][104/193]	Time  1.418 ( 1.413)	Data  0.353 ( 0.304)	Loss 1.2105e-01 (1.3158e-01) 
2023-05-25 01:27:48.235351: train Epoch: [15][105/193]	Time  1.264 ( 1.411)	Data  0.001 ( 0.301)	Loss 1.5615e-01 (1.3181e-01) 
2023-05-25 01:27:49.689257: train Epoch: [15][106/193]	Time  1.454 ( 1.412)	Data  0.446 ( 0.303)	Loss 1.0253e-01 (1.3154e-01) 
2023-05-25 01:27:50.733960: train Epoch: [15][107/193]	Time  1.045 ( 1.408)	Data  0.001 ( 0.300)	Loss 1.0854e-01 (1.3133e-01) 
2023-05-25 01:27:52.517024: train Epoch: [15][108/193]	Time  1.783 ( 1.412)	Data  0.680 ( 0.303)	Loss 1.1042e-01 (1.3113e-01) 
2023-05-25 01:27:53.639076: train Epoch: [15][109/193]	Time  1.122 ( 1.409)	Data  0.001 ( 0.301)	Loss 1.6795e-01 (1.3147e-01) 
2023-05-25 01:27:55.525825: train Epoch: [15][110/193]	Time  1.887 ( 1.414)	Data  0.605 ( 0.303)	Loss 1.2849e-01 (1.3144e-01) 
2023-05-25 01:27:56.574397: train Epoch: [15][111/193]	Time  1.049 ( 1.410)	Data  0.001 ( 0.301)	Loss 6.8369e-02 (1.3088e-01) 
2023-05-25 01:27:58.359463: train Epoch: [15][112/193]	Time  1.785 ( 1.414)	Data  0.444 ( 0.302)	Loss 5.2531e-02 (1.3019e-01) 
2023-05-25 01:27:59.619794: train Epoch: [15][113/193]	Time  1.260 ( 1.412)	Data  0.001 ( 0.299)	Loss 6.7932e-02 (1.2964e-01) 
2023-05-25 01:28:00.814223: train Epoch: [15][114/193]	Time  1.194 ( 1.410)	Data  0.160 ( 0.298)	Loss 5.4589e-02 (1.2899e-01) 
2023-05-25 01:28:01.853616: train Epoch: [15][115/193]	Time  1.039 ( 1.407)	Data  0.001 ( 0.295)	Loss 1.7570e-01 (1.2939e-01) 
2023-05-25 01:28:03.695096: train Epoch: [15][116/193]	Time  1.841 ( 1.411)	Data  0.687 ( 0.299)	Loss 1.1882e-01 (1.2930e-01) 
2023-05-25 01:28:04.830640: train Epoch: [15][117/193]	Time  1.136 ( 1.409)	Data  0.001 ( 0.296)	Loss 1.2814e-01 (1.2929e-01) 
2023-05-25 01:28:06.603914: train Epoch: [15][118/193]	Time  1.773 ( 1.412)	Data  0.477 ( 0.298)	Loss 9.5862e-02 (1.2901e-01) 
2023-05-25 01:28:07.864141: train Epoch: [15][119/193]	Time  1.260 ( 1.410)	Data  0.001 ( 0.295)	Loss 1.6619e-01 (1.2932e-01) 
2023-05-25 01:28:09.487303: train Epoch: [15][120/193]	Time  1.623 ( 1.412)	Data  0.410 ( 0.296)	Loss 1.2863e-01 (1.2931e-01) 
2023-05-25 01:28:10.718453: train Epoch: [15][121/193]	Time  1.231 ( 1.411)	Data  0.001 ( 0.294)	Loss 1.1765e-01 (1.2922e-01) 
2023-05-25 01:28:12.090767: train Epoch: [15][122/193]	Time  1.372 ( 1.410)	Data  0.335 ( 0.294)	Loss 8.2748e-02 (1.2884e-01) 
2023-05-25 01:28:13.236614: train Epoch: [15][123/193]	Time  1.146 ( 1.408)	Data  0.001 ( 0.292)	Loss 1.8925e-01 (1.2933e-01) 
2023-05-25 01:28:14.778975: train Epoch: [15][124/193]	Time  1.542 ( 1.409)	Data  0.615 ( 0.294)	Loss 1.2961e-01 (1.2933e-01) 
2023-05-25 01:28:15.782128: train Epoch: [15][125/193]	Time  1.003 ( 1.406)	Data  0.001 ( 0.292)	Loss 1.0527e-01 (1.2914e-01) 
2023-05-25 01:28:17.752812: train Epoch: [15][126/193]	Time  1.971 ( 1.410)	Data  0.828 ( 0.296)	Loss 1.9563e-01 (1.2966e-01) 
2023-05-25 01:28:18.795628: train Epoch: [15][127/193]	Time  1.043 ( 1.408)	Data  0.001 ( 0.294)	Loss 1.8584e-01 (1.3010e-01) 
2023-05-25 01:28:20.578982: train Epoch: [15][128/193]	Time  1.783 ( 1.410)	Data  0.559 ( 0.296)	Loss 1.5914e-01 (1.3032e-01) 
2023-05-25 01:28:21.753321: train Epoch: [15][129/193]	Time  1.174 ( 1.409)	Data  0.001 ( 0.294)	Loss 1.5953e-01 (1.3055e-01) 
2023-05-25 01:28:23.325388: train Epoch: [15][130/193]	Time  1.572 ( 1.410)	Data  0.454 ( 0.295)	Loss 1.3488e-01 (1.3058e-01) 
2023-05-25 01:28:24.578993: train Epoch: [15][131/193]	Time  1.254 ( 1.409)	Data  0.001 ( 0.293)	Loss 1.1384e-01 (1.3046e-01) 
2023-05-25 01:28:26.084412: train Epoch: [15][132/193]	Time  1.505 ( 1.409)	Data  0.458 ( 0.294)	Loss 1.5380e-01 (1.3063e-01) 
2023-05-25 01:28:27.256269: train Epoch: [15][133/193]	Time  1.172 ( 1.408)	Data  0.001 ( 0.292)	Loss 1.0506e-01 (1.3044e-01) 
2023-05-25 01:28:28.875458: train Epoch: [15][134/193]	Time  1.619 ( 1.409)	Data  0.529 ( 0.294)	Loss 1.9172e-01 (1.3089e-01) 
2023-05-25 01:28:29.987564: train Epoch: [15][135/193]	Time  1.112 ( 1.407)	Data  0.001 ( 0.291)	Loss 6.7727e-02 (1.3043e-01) 
2023-05-25 01:28:31.419572: train Epoch: [15][136/193]	Time  1.432 ( 1.407)	Data  0.467 ( 0.293)	Loss 8.7854e-02 (1.3012e-01) 
2023-05-25 01:28:32.381573: train Epoch: [15][137/193]	Time  0.962 ( 1.404)	Data  0.001 ( 0.291)	Loss 1.0577e-01 (1.2994e-01) 
2023-05-25 01:28:34.544925: train Epoch: [15][138/193]	Time  2.163 ( 1.409)	Data  0.951 ( 0.295)	Loss 9.9950e-02 (1.2973e-01) 
2023-05-25 01:28:35.601481: train Epoch: [15][139/193]	Time  1.057 ( 1.407)	Data  0.001 ( 0.293)	Loss 2.0691e-01 (1.3028e-01) 
2023-05-25 01:28:37.308664: train Epoch: [15][140/193]	Time  1.707 ( 1.409)	Data  0.479 ( 0.295)	Loss 1.0280e-01 (1.3008e-01) 
2023-05-25 01:28:38.317604: train Epoch: [15][141/193]	Time  1.009 ( 1.406)	Data  0.001 ( 0.293)	Loss 9.1307e-02 (1.2981e-01) 
2023-05-25 01:28:40.205958: train Epoch: [15][142/193]	Time  1.888 ( 1.410)	Data  0.525 ( 0.294)	Loss 9.4271e-02 (1.2956e-01) 
2023-05-25 01:28:41.213058: train Epoch: [15][143/193]	Time  1.007 ( 1.407)	Data  0.001 ( 0.292)	Loss 7.8640e-02 (1.2921e-01) 
2023-05-25 01:28:42.716973: train Epoch: [15][144/193]	Time  1.504 ( 1.408)	Data  0.476 ( 0.293)	Loss 7.9588e-02 (1.2887e-01) 
2023-05-25 01:28:44.005543: train Epoch: [15][145/193]	Time  1.289 ( 1.407)	Data  0.001 ( 0.291)	Loss 1.2189e-01 (1.2882e-01) 
2023-05-25 01:28:45.586039: train Epoch: [15][146/193]	Time  1.580 ( 1.408)	Data  0.489 ( 0.293)	Loss 1.3067e-01 (1.2883e-01) 
2023-05-25 01:28:46.833459: train Epoch: [15][147/193]	Time  1.247 ( 1.407)	Data  0.001 ( 0.291)	Loss 1.9432e-01 (1.2927e-01) 
2023-05-25 01:28:48.258286: train Epoch: [15][148/193]	Time  1.425 ( 1.407)	Data  0.361 ( 0.291)	Loss 1.7100e-01 (1.2955e-01) 
2023-05-25 01:28:49.623839: train Epoch: [15][149/193]	Time  1.366 ( 1.407)	Data  0.001 ( 0.289)	Loss 1.5007e-01 (1.2969e-01) 
2023-05-25 01:28:51.289081: train Epoch: [15][150/193]	Time  1.665 ( 1.408)	Data  0.368 ( 0.290)	Loss 9.8737e-02 (1.2949e-01) 
2023-05-25 01:28:52.543201: train Epoch: [15][151/193]	Time  1.254 ( 1.407)	Data  0.001 ( 0.288)	Loss 1.2101e-01 (1.2943e-01) 
2023-05-25 01:28:54.134674: train Epoch: [15][152/193]	Time  1.591 ( 1.409)	Data  0.263 ( 0.288)	Loss 1.6149e-01 (1.2964e-01) 
2023-05-25 01:28:55.362865: train Epoch: [15][153/193]	Time  1.228 ( 1.407)	Data  0.001 ( 0.286)	Loss 1.7073e-01 (1.2991e-01) 
2023-05-25 01:28:57.070022: train Epoch: [15][154/193]	Time  1.707 ( 1.409)	Data  0.395 ( 0.287)	Loss 8.8516e-02 (1.2964e-01) 
2023-05-25 01:28:58.274172: train Epoch: [15][155/193]	Time  1.204 ( 1.408)	Data  0.002 ( 0.285)	Loss 9.2525e-02 (1.2940e-01) 
2023-05-25 01:28:59.823150: train Epoch: [15][156/193]	Time  1.549 ( 1.409)	Data  0.298 ( 0.285)	Loss 1.1372e-01 (1.2930e-01) 
2023-05-25 01:29:01.054195: train Epoch: [15][157/193]	Time  1.231 ( 1.408)	Data  0.001 ( 0.283)	Loss 7.7616e-02 (1.2897e-01) 
2023-05-25 01:29:02.505989: train Epoch: [15][158/193]	Time  1.452 ( 1.408)	Data  0.236 ( 0.283)	Loss 9.4903e-02 (1.2876e-01) 
2023-05-25 01:29:03.734174: train Epoch: [15][159/193]	Time  1.228 ( 1.407)	Data  0.001 ( 0.281)	Loss 1.2188e-01 (1.2872e-01) 
2023-05-25 01:29:05.046212: train Epoch: [15][160/193]	Time  1.312 ( 1.406)	Data  0.132 ( 0.280)	Loss 6.8017e-02 (1.2834e-01) 
2023-05-25 01:29:06.078249: train Epoch: [15][161/193]	Time  1.032 ( 1.404)	Data  0.002 ( 0.278)	Loss 9.6702e-02 (1.2814e-01) 
2023-05-25 01:29:07.865976: train Epoch: [15][162/193]	Time  1.788 ( 1.406)	Data  0.448 ( 0.279)	Loss 8.3267e-02 (1.2787e-01) 
2023-05-25 01:29:09.074693: train Epoch: [15][163/193]	Time  1.209 ( 1.405)	Data  0.003 ( 0.278)	Loss 1.1245e-01 (1.2777e-01) 
2023-05-25 01:29:10.266948: train Epoch: [15][164/193]	Time  1.192 ( 1.404)	Data  0.157 ( 0.277)	Loss 1.2680e-01 (1.2777e-01) 
2023-05-25 01:29:11.612815: train Epoch: [15][165/193]	Time  1.346 ( 1.404)	Data  0.330 ( 0.277)	Loss 6.9163e-02 (1.2742e-01) 
2023-05-25 01:29:12.945971: train Epoch: [15][166/193]	Time  1.333 ( 1.403)	Data  0.298 ( 0.277)	Loss 8.4288e-02 (1.2716e-01) 
2023-05-25 01:29:14.577596: train Epoch: [15][167/193]	Time  1.632 ( 1.404)	Data  0.500 ( 0.279)	Loss 1.0071e-01 (1.2700e-01) 
2023-05-25 01:29:15.509492: train Epoch: [15][168/193]	Time  0.932 ( 1.402)	Data  0.001 ( 0.277)	Loss 6.9443e-02 (1.2666e-01) 
2023-05-25 01:29:17.284787: train Epoch: [15][169/193]	Time  1.775 ( 1.404)	Data  0.846 ( 0.280)	Loss 1.2347e-01 (1.2664e-01) 
2023-05-25 01:29:18.283429: train Epoch: [15][170/193]	Time  0.999 ( 1.401)	Data  0.002 ( 0.279)	Loss 3.6499e-01 (1.2803e-01) 
2023-05-25 01:29:20.416098: train Epoch: [15][171/193]	Time  2.133 ( 1.406)	Data  0.966 ( 0.283)	Loss 9.1663e-02 (1.2782e-01) 
2023-05-25 01:29:21.375589: train Epoch: [15][172/193]	Time  0.959 ( 1.403)	Data  0.001 ( 0.281)	Loss 1.6796e-01 (1.2806e-01) 
2023-05-25 01:29:23.299166: train Epoch: [15][173/193]	Time  1.924 ( 1.406)	Data  0.762 ( 0.284)	Loss 2.4111e-01 (1.2870e-01) 
2023-05-25 01:29:24.298965: train Epoch: [15][174/193]	Time  1.000 ( 1.404)	Data  0.001 ( 0.282)	Loss 1.0872e-01 (1.2859e-01) 
2023-05-25 01:29:26.125286: train Epoch: [15][175/193]	Time  1.826 ( 1.406)	Data  0.593 ( 0.284)	Loss 1.8659e-01 (1.2892e-01) 
2023-05-25 01:29:27.148034: train Epoch: [15][176/193]	Time  1.023 ( 1.404)	Data  0.001 ( 0.283)	Loss 4.0953e-01 (1.3051e-01) 
2023-05-25 01:29:28.686612: train Epoch: [15][177/193]	Time  1.539 ( 1.405)	Data  0.439 ( 0.283)	Loss 1.3748e-01 (1.3054e-01) 
2023-05-25 01:29:29.673746: train Epoch: [15][178/193]	Time  0.987 ( 1.402)	Data  0.001 ( 0.282)	Loss 1.2449e-01 (1.3051e-01) 
2023-05-25 01:29:31.714568: train Epoch: [15][179/193]	Time  2.041 ( 1.406)	Data  0.733 ( 0.284)	Loss 1.0352e-01 (1.3036e-01) 
2023-05-25 01:29:32.746187: train Epoch: [15][180/193]	Time  1.032 ( 1.404)	Data  0.001 ( 0.283)	Loss 1.1392e-01 (1.3027e-01) 
2023-05-25 01:29:34.205073: train Epoch: [15][181/193]	Time  1.459 ( 1.404)	Data  0.372 ( 0.283)	Loss 1.0005e-01 (1.3010e-01) 
2023-05-25 01:29:35.302327: train Epoch: [15][182/193]	Time  1.097 ( 1.403)	Data  0.001 ( 0.282)	Loss 9.2879e-02 (1.2990e-01) 
2023-05-25 01:29:36.784847: train Epoch: [15][183/193]	Time  1.482 ( 1.403)	Data  0.499 ( 0.283)	Loss 1.0800e-01 (1.2978e-01) 
2023-05-25 01:29:37.853784: train Epoch: [15][184/193]	Time  1.069 ( 1.401)	Data  0.011 ( 0.281)	Loss 1.3308e-01 (1.2980e-01) 
2023-05-25 01:29:39.741187: train Epoch: [15][185/193]	Time  1.887 ( 1.404)	Data  0.704 ( 0.284)	Loss 9.9693e-02 (1.2964e-01) 
2023-05-25 01:29:40.696428: train Epoch: [15][186/193]	Time  0.955 ( 1.401)	Data  0.001 ( 0.282)	Loss 8.2654e-02 (1.2939e-01) 
2023-05-25 01:29:42.395698: train Epoch: [15][187/193]	Time  1.699 ( 1.403)	Data  0.606 ( 0.284)	Loss 9.7789e-02 (1.2922e-01) 
2023-05-25 01:29:43.365770: train Epoch: [15][188/193]	Time  0.970 ( 1.401)	Data  0.001 ( 0.282)	Loss 1.5487e-01 (1.2935e-01) 
2023-05-25 01:29:45.310696: train Epoch: [15][189/193]	Time  1.945 ( 1.404)	Data  0.709 ( 0.285)	Loss 6.2455e-02 (1.2900e-01) 
2023-05-25 01:29:46.263635: train Epoch: [15][190/193]	Time  0.953 ( 1.401)	Data  0.001 ( 0.283)	Loss 1.1549e-01 (1.2893e-01) 
2023-05-25 01:29:48.098134: train Epoch: [15][191/193]	Time  1.835 ( 1.403)	Data  0.622 ( 0.285)	Loss 1.7354e-01 (1.2916e-01) 
2023-05-25 01:29:49.014471: train Epoch: [15][192/193]	Time  0.916 ( 1.401)	Data  0.001 ( 0.283)	Loss 7.3370e-02 (1.2887e-01) 
2023-05-25 01:29:49.082130: Train Epoch done in 270.4564653849229 s 
2023-05-25 01:29:52.523201: val Epoch: [15][ 0/72]	Time  2.277 ( 2.277)	Data  1.829 ( 1.829)	Loss 6.3005e-02 (6.3005e-02) 
2023-05-25 01:29:52.858808: val Epoch: [15][ 1/72]	Time  0.336 ( 1.306)	Data  0.002 ( 0.915)	Loss 3.5778e-01 (2.1039e-01) 
2023-05-25 01:29:53.822888: val Epoch: [15][ 2/72]	Time  0.964 ( 1.192)	Data  0.544 ( 0.792)	Loss 7.3302e-02 (1.6469e-01) 
2023-05-25 01:29:54.206988: val Epoch: [15][ 3/72]	Time  0.384 ( 0.990)	Data  0.002 ( 0.594)	Loss 6.8082e-02 (1.4054e-01) 
2023-05-25 01:29:55.094159: val Epoch: [15][ 4/72]	Time  0.887 ( 0.970)	Data  0.703 ( 0.616)	Loss 3.2997e-01 (1.7843e-01) 
2023-05-25 01:29:55.388223: val Epoch: [15][ 5/72]	Time  0.294 ( 0.857)	Data  0.001 ( 0.513)	Loss 5.3735e-02 (1.5764e-01) 
2023-05-25 01:29:56.721571: val Epoch: [15][ 6/72]	Time  1.333 ( 0.925)	Data  1.023 ( 0.586)	Loss 2.6205e-01 (1.7256e-01) 
2023-05-25 01:29:57.114709: val Epoch: [15][ 7/72]	Time  0.393 ( 0.859)	Data  0.001 ( 0.513)	Loss 5.8165e-01 (2.2370e-01) 
2023-05-25 01:29:58.118390: val Epoch: [15][ 8/72]	Time  1.004 ( 0.875)	Data  0.773 ( 0.542)	Loss 1.3154e-01 (2.1346e-01) 
2023-05-25 01:29:58.514812: val Epoch: [15][ 9/72]	Time  0.396 ( 0.827)	Data  0.002 ( 0.488)	Loss 5.8418e-02 (1.9795e-01) 
2023-05-25 01:29:59.479026: val Epoch: [15][10/72]	Time  0.964 ( 0.839)	Data  0.782 ( 0.514)	Loss 1.4188e-01 (1.9285e-01) 
2023-05-25 01:30:00.058176: val Epoch: [15][11/72]	Time  0.579 ( 0.818)	Data  0.001 ( 0.472)	Loss 1.4536e-01 (1.8890e-01) 
2023-05-25 01:30:01.036474: val Epoch: [15][12/72]	Time  0.978 ( 0.830)	Data  0.592 ( 0.481)	Loss 6.6298e-02 (1.7947e-01) 
2023-05-25 01:30:01.340491: val Epoch: [15][13/72]	Time  0.304 ( 0.792)	Data  0.001 ( 0.447)	Loss 6.7024e-02 (1.7143e-01) 
2023-05-25 01:30:02.532777: val Epoch: [15][14/72]	Time  1.192 ( 0.819)	Data  0.791 ( 0.470)	Loss 3.2723e-01 (1.8182e-01) 
2023-05-25 01:30:02.757225: val Epoch: [15][15/72]	Time  0.224 ( 0.782)	Data  0.001 ( 0.440)	Loss 1.2085e-01 (1.7801e-01) 
2023-05-25 01:30:03.725979: val Epoch: [15][16/72]	Time  0.969 ( 0.793)	Data  0.771 ( 0.460)	Loss 6.2876e-02 (1.7124e-01) 
2023-05-25 01:30:03.891263: val Epoch: [15][17/72]	Time  0.165 ( 0.758)	Data  0.001 ( 0.434)	Loss 9.9293e-02 (1.6724e-01) 
2023-05-25 01:30:05.273790: val Epoch: [15][18/72]	Time  1.383 ( 0.791)	Data  1.039 ( 0.466)	Loss 1.1574e-01 (1.6453e-01) 
2023-05-25 01:30:05.629590: val Epoch: [15][19/72]	Time  0.356 ( 0.769)	Data  0.001 ( 0.443)	Loss 6.9646e-01 (1.9113e-01) 
2023-05-25 01:30:06.734329: val Epoch: [15][20/72]	Time  1.105 ( 0.785)	Data  0.750 ( 0.457)	Loss 5.7146e-01 (2.0924e-01) 
2023-05-25 01:30:07.028696: val Epoch: [15][21/72]	Time  0.294 ( 0.763)	Data  0.001 ( 0.437)	Loss 3.7637e-01 (2.1683e-01) 
2023-05-25 01:30:08.285508: val Epoch: [15][22/72]	Time  1.257 ( 0.784)	Data  0.844 ( 0.454)	Loss 5.7406e-01 (2.3237e-01) 
2023-05-25 01:30:08.711756: val Epoch: [15][23/72]	Time  0.426 ( 0.769)	Data  0.002 ( 0.436)	Loss 1.0217e-01 (2.2694e-01) 
2023-05-25 01:30:09.629971: val Epoch: [15][24/72]	Time  0.918 ( 0.775)	Data  0.581 ( 0.441)	Loss 1.5481e-01 (2.2406e-01) 
2023-05-25 01:30:09.901661: val Epoch: [15][25/72]	Time  0.272 ( 0.756)	Data  0.001 ( 0.424)	Loss 3.5818e-01 (2.2922e-01) 
2023-05-25 01:30:11.113722: val Epoch: [15][26/72]	Time  1.212 ( 0.773)	Data  0.770 ( 0.437)	Loss 6.6402e-02 (2.2319e-01) 
2023-05-25 01:30:11.588695: val Epoch: [15][27/72]	Time  0.475 ( 0.762)	Data  0.001 ( 0.422)	Loss 6.0574e-02 (2.1738e-01) 
2023-05-25 01:30:12.576222: val Epoch: [15][28/72]	Time  0.987 ( 0.770)	Data  0.521 ( 0.425)	Loss 1.3388e-01 (2.1450e-01) 
2023-05-25 01:30:12.847375: val Epoch: [15][29/72]	Time  0.271 ( 0.753)	Data  0.002 ( 0.411)	Loss 7.0481e-02 (2.0970e-01) 
2023-05-25 01:30:13.796812: val Epoch: [15][30/72]	Time  0.949 ( 0.760)	Data  0.680 ( 0.420)	Loss 1.7565e-01 (2.0860e-01) 
2023-05-25 01:30:13.972166: val Epoch: [15][31/72]	Time  0.175 ( 0.741)	Data  0.001 ( 0.407)	Loss 7.6901e-02 (2.0448e-01) 
2023-05-25 01:30:15.295184: val Epoch: [15][32/72]	Time  1.323 ( 0.759)	Data  1.008 ( 0.425)	Loss 5.8803e-02 (2.0007e-01) 
2023-05-25 01:30:15.586196: val Epoch: [15][33/72]	Time  0.291 ( 0.745)	Data  0.002 ( 0.412)	Loss 1.1774e-01 (1.9765e-01) 
2023-05-25 01:30:16.923792: val Epoch: [15][34/72]	Time  1.338 ( 0.762)	Data  0.896 ( 0.426)	Loss 3.8668e-01 (2.0305e-01) 
2023-05-25 01:30:17.111373: val Epoch: [15][35/72]	Time  0.188 ( 0.746)	Data  0.001 ( 0.414)	Loss 1.0684e-01 (2.0038e-01) 
2023-05-25 01:30:18.192364: val Epoch: [15][36/72]	Time  1.081 ( 0.755)	Data  0.800 ( 0.425)	Loss 4.1268e-01 (2.0611e-01) 
2023-05-25 01:30:18.586646: val Epoch: [15][37/72]	Time  0.394 ( 0.746)	Data  0.001 ( 0.414)	Loss 1.6775e-01 (2.0510e-01) 
2023-05-25 01:30:19.699557: val Epoch: [15][38/72]	Time  1.113 ( 0.755)	Data  0.727 ( 0.422)	Loss 6.5328e-02 (2.0152e-01) 
2023-05-25 01:30:20.085575: val Epoch: [15][39/72]	Time  0.386 ( 0.746)	Data  0.001 ( 0.411)	Loss 7.2296e-02 (1.9829e-01) 
2023-05-25 01:30:21.073876: val Epoch: [15][40/72]	Time  0.988 ( 0.752)	Data  0.693 ( 0.418)	Loss 1.3925e-01 (1.9685e-01) 
2023-05-25 01:30:21.431767: val Epoch: [15][41/72]	Time  0.358 ( 0.743)	Data  0.001 ( 0.408)	Loss 1.0250e-01 (1.9460e-01) 
2023-05-25 01:30:22.739901: val Epoch: [15][42/72]	Time  1.308 ( 0.756)	Data  0.818 ( 0.418)	Loss 1.2340e-01 (1.9295e-01) 
2023-05-25 01:30:23.199260: val Epoch: [15][43/72]	Time  0.459 ( 0.749)	Data  0.009 ( 0.408)	Loss 1.4053e-01 (1.9176e-01) 
2023-05-25 01:30:23.911885: val Epoch: [15][44/72]	Time  0.713 ( 0.748)	Data  0.473 ( 0.410)	Loss 7.1852e-02 (1.8909e-01) 
2023-05-25 01:30:24.120706: val Epoch: [15][45/72]	Time  0.209 ( 0.736)	Data  0.001 ( 0.401)	Loss 1.4317e-01 (1.8809e-01) 
2023-05-25 01:30:25.362215: val Epoch: [15][46/72]	Time  1.241 ( 0.747)	Data  0.955 ( 0.413)	Loss 9.1644e-02 (1.8604e-01) 
2023-05-25 01:30:25.666676: val Epoch: [15][47/72]	Time  0.304 ( 0.738)	Data  0.003 ( 0.404)	Loss 1.3608e-01 (1.8500e-01) 
2023-05-25 01:30:26.985095: val Epoch: [15][48/72]	Time  1.318 ( 0.750)	Data  0.833 ( 0.413)	Loss 9.0729e-02 (1.8308e-01) 
2023-05-25 01:30:27.191075: val Epoch: [15][49/72]	Time  0.206 ( 0.739)	Data  0.001 ( 0.405)	Loss 7.4464e-02 (1.8090e-01) 
2023-05-25 01:30:28.152467: val Epoch: [15][50/72]	Time  0.961 ( 0.743)	Data  0.715 ( 0.411)	Loss 7.6661e-02 (1.7886e-01) 
2023-05-25 01:30:28.541593: val Epoch: [15][51/72]	Time  0.389 ( 0.736)	Data  0.001 ( 0.403)	Loss 5.9097e-02 (1.7656e-01) 
2023-05-25 01:30:29.959270: val Epoch: [15][52/72]	Time  1.418 ( 0.749)	Data  0.858 ( 0.411)	Loss 1.1239e-01 (1.7535e-01) 
2023-05-25 01:30:30.163071: val Epoch: [15][53/72]	Time  0.204 ( 0.739)	Data  0.001 ( 0.404)	Loss 1.3288e-01 (1.7456e-01) 
2023-05-25 01:30:31.117173: val Epoch: [15][54/72]	Time  0.954 ( 0.743)	Data  0.618 ( 0.408)	Loss 6.8600e-02 (1.7263e-01) 
2023-05-25 01:30:31.434784: val Epoch: [15][55/72]	Time  0.318 ( 0.736)	Data  0.001 ( 0.400)	Loss 1.0080e-01 (1.7135e-01) 
2023-05-25 01:30:32.502228: val Epoch: [15][56/72]	Time  1.067 ( 0.741)	Data  0.748 ( 0.407)	Loss 1.1223e-01 (1.7031e-01) 
2023-05-25 01:30:32.843484: val Epoch: [15][57/72]	Time  0.341 ( 0.734)	Data  0.001 ( 0.400)	Loss 1.4008e-01 (1.6979e-01) 
2023-05-25 01:30:33.910028: val Epoch: [15][58/72]	Time  1.067 ( 0.740)	Data  0.783 ( 0.406)	Loss 9.0216e-02 (1.6844e-01) 
2023-05-25 01:30:34.135644: val Epoch: [15][59/72]	Time  0.226 ( 0.731)	Data  0.001 ( 0.399)	Loss 7.0668e-02 (1.6681e-01) 
2023-05-25 01:30:35.528835: val Epoch: [15][60/72]	Time  1.393 ( 0.742)	Data  0.914 ( 0.408)	Loss 5.7872e-01 (1.7357e-01) 
2023-05-25 01:30:36.102679: val Epoch: [15][61/72]	Time  0.574 ( 0.740)	Data  0.001 ( 0.401)	Loss 1.6532e-01 (1.7343e-01) 
2023-05-25 01:30:36.960294: val Epoch: [15][62/72]	Time  0.858 ( 0.741)	Data  0.337 ( 0.400)	Loss 6.6640e-02 (1.7174e-01) 
2023-05-25 01:30:37.164219: val Epoch: [15][63/72]	Time  0.204 ( 0.733)	Data  0.001 ( 0.394)	Loss 2.2972e-01 (1.7264e-01) 
2023-05-25 01:30:38.183723: val Epoch: [15][64/72]	Time  1.019 ( 0.737)	Data  0.693 ( 0.399)	Loss 2.3672e-01 (1.7363e-01) 
2023-05-25 01:30:38.378853: val Epoch: [15][65/72]	Time  0.195 ( 0.729)	Data  0.001 ( 0.393)	Loss 7.1415e-02 (1.7208e-01) 
2023-05-25 01:30:39.564051: val Epoch: [15][66/72]	Time  1.185 ( 0.736)	Data  0.906 ( 0.400)	Loss 1.7672e-01 (1.7215e-01) 
2023-05-25 01:30:39.926584: val Epoch: [15][67/72]	Time  0.363 ( 0.731)	Data  0.003 ( 0.394)	Loss 7.5317e-02 (1.7073e-01) 
2023-05-25 01:30:41.232652: val Epoch: [15][68/72]	Time  1.306 ( 0.739)	Data  0.840 ( 0.401)	Loss 1.8370e-01 (1.7091e-01) 
2023-05-25 01:30:41.537752: val Epoch: [15][69/72]	Time  0.305 ( 0.733)	Data  0.001 ( 0.395)	Loss 1.2110e-01 (1.7020e-01) 
2023-05-25 01:30:42.518425: val Epoch: [15][70/72]	Time  0.981 ( 0.736)	Data  0.618 ( 0.398)	Loss 8.3707e-02 (1.6898e-01) 
2023-05-25 01:30:42.760455: val Epoch: [15][71/72]	Time  0.242 ( 0.729)	Data  0.001 ( 0.393)	Loss 2.4015e-01 (1.6997e-01) 
2023-05-25 01:30:43.003697: Epoch 15 :Val : ['ET : 0.6937745213508606', 'TC : 0.7179312705993652', 'WT : 0.8040751218795776'] 
2023-05-25 01:30:43.004981: Epoch 15 :Val : ['ET : 0.6937745213508606', 'TC : 0.7179312705993652', 'WT : 0.8040751218795776'] 
2023-05-25 01:30:43.011089: Val epoch done in 53.9289596270537 s 
2023-05-25 01:30:43.022097: Batches per epoch:  193 
2023-05-25 01:30:47.934401: train Epoch: [16][  0/193]	Time  4.911 ( 4.911)	Data  3.493 ( 3.493)	Loss 9.9177e-02 (9.9177e-02) 
2023-05-25 01:30:49.158789: train Epoch: [16][  1/193]	Time  1.224 ( 3.068)	Data  0.002 ( 1.747)	Loss 1.3312e-01 (1.1615e-01) 
2023-05-25 01:30:50.757382: train Epoch: [16][  2/193]	Time  1.599 ( 2.578)	Data  0.219 ( 1.238)	Loss 1.0050e-01 (1.1093e-01) 
2023-05-25 01:30:51.937350: train Epoch: [16][  3/193]	Time  1.180 ( 2.229)	Data  0.001 ( 0.929)	Loss 7.8379e-02 (1.0279e-01) 
2023-05-25 01:30:53.615060: train Epoch: [16][  4/193]	Time  1.678 ( 2.118)	Data  0.398 ( 0.823)	Loss 1.5013e-01 (1.1226e-01) 
2023-05-25 01:30:54.570142: train Epoch: [16][  5/193]	Time  0.955 ( 1.925)	Data  0.001 ( 0.686)	Loss 1.0260e-01 (1.1065e-01) 
2023-05-25 01:30:56.380974: train Epoch: [16][  6/193]	Time  1.811 ( 1.908)	Data  0.666 ( 0.683)	Loss 1.1250e-01 (1.1092e-01) 
2023-05-25 01:30:57.375541: train Epoch: [16][  7/193]	Time  0.995 ( 1.794)	Data  0.002 ( 0.598)	Loss 1.3672e-01 (1.1414e-01) 
2023-05-25 01:30:59.384986: train Epoch: [16][  8/193]	Time  2.009 ( 1.818)	Data  0.736 ( 0.613)	Loss 1.2391e-01 (1.1523e-01) 
2023-05-25 01:31:00.548477: train Epoch: [16][  9/193]	Time  1.163 ( 1.753)	Data  0.001 ( 0.552)	Loss 1.1956e-01 (1.1566e-01) 
2023-05-25 01:31:01.971671: train Epoch: [16][ 10/193]	Time  1.423 ( 1.723)	Data  0.360 ( 0.534)	Loss 9.0828e-02 (1.1340e-01) 
2023-05-25 01:31:03.108005: train Epoch: [16][ 11/193]	Time  1.136 ( 1.674)	Data  0.004 ( 0.490)	Loss 9.5628e-02 (1.1192e-01) 
2023-05-25 01:31:04.950037: train Epoch: [16][ 12/193]	Time  1.842 ( 1.687)	Data  0.694 ( 0.506)	Loss 2.7247e-01 (1.2427e-01) 
2023-05-25 01:31:06.222632: train Epoch: [16][ 13/193]	Time  1.273 ( 1.657)	Data  0.001 ( 0.470)	Loss 1.1958e-01 (1.2394e-01) 
2023-05-25 01:31:07.842228: train Epoch: [16][ 14/193]	Time  1.620 ( 1.655)	Data  0.429 ( 0.467)	Loss 7.1985e-02 (1.2047e-01) 
2023-05-25 01:31:08.975543: train Epoch: [16][ 15/193]	Time  1.133 ( 1.622)	Data  0.001 ( 0.438)	Loss 1.6437e-01 (1.2322e-01) 
2023-05-25 01:31:10.350394: train Epoch: [16][ 16/193]	Time  1.375 ( 1.607)	Data  0.429 ( 0.437)	Loss 1.2749e-01 (1.2347e-01) 
2023-05-25 01:31:11.325491: train Epoch: [16][ 17/193]	Time  0.975 ( 1.572)	Data  0.001 ( 0.413)	Loss 1.1113e-01 (1.2278e-01) 
2023-05-25 01:31:13.175114: train Epoch: [16][ 18/193]	Time  1.850 ( 1.587)	Data  0.838 ( 0.436)	Loss 1.8571e-01 (1.2609e-01) 
2023-05-25 01:31:14.151432: train Epoch: [16][ 19/193]	Time  0.976 ( 1.556)	Data  0.001 ( 0.414)	Loss 1.0138e-01 (1.2486e-01) 
2023-05-25 01:31:15.989716: train Epoch: [16][ 20/193]	Time  1.838 ( 1.570)	Data  0.873 ( 0.436)	Loss 8.6108e-02 (1.2301e-01) 
2023-05-25 01:31:17.034798: train Epoch: [16][ 21/193]	Time  1.045 ( 1.546)	Data  0.001 ( 0.416)	Loss 6.5281e-02 (1.2039e-01) 
2023-05-25 01:31:19.215799: train Epoch: [16][ 22/193]	Time  2.181 ( 1.574)	Data  0.865 ( 0.435)	Loss 1.6813e-01 (1.2246e-01) 
2023-05-25 01:31:20.199200: train Epoch: [16][ 23/193]	Time  0.983 ( 1.549)	Data  0.001 ( 0.417)	Loss 1.5694e-01 (1.2390e-01) 
2023-05-25 01:31:21.672424: train Epoch: [16][ 24/193]	Time  1.473 ( 1.546)	Data  0.247 ( 0.411)	Loss 1.1684e-01 (1.2362e-01) 
2023-05-25 01:31:22.773855: train Epoch: [16][ 25/193]	Time  1.101 ( 1.529)	Data  0.001 ( 0.395)	Loss 1.3869e-01 (1.2420e-01) 
2023-05-25 01:31:24.878887: train Epoch: [16][ 26/193]	Time  2.105 ( 1.550)	Data  0.620 ( 0.403)	Loss 1.1413e-01 (1.2383e-01) 
2023-05-25 01:31:25.887930: train Epoch: [16][ 27/193]	Time  1.009 ( 1.531)	Data  0.001 ( 0.389)	Loss 8.1947e-02 (1.2233e-01) 
2023-05-25 01:31:27.246720: train Epoch: [16][ 28/193]	Time  1.359 ( 1.525)	Data  0.297 ( 0.386)	Loss 1.6444e-01 (1.2378e-01) 
2023-05-25 01:31:28.262141: train Epoch: [16][ 29/193]	Time  1.015 ( 1.508)	Data  0.001 ( 0.373)	Loss 1.0717e-01 (1.2323e-01) 
2023-05-25 01:31:30.253447: train Epoch: [16][ 30/193]	Time  1.991 ( 1.524)	Data  0.757 ( 0.385)	Loss 8.9404e-02 (1.2214e-01) 
2023-05-25 01:31:31.564301: train Epoch: [16][ 31/193]	Time  1.311 ( 1.517)	Data  0.001 ( 0.373)	Loss 8.5488e-02 (1.2099e-01) 
2023-05-25 01:31:32.999609: train Epoch: [16][ 32/193]	Time  1.435 ( 1.514)	Data  0.342 ( 0.372)	Loss 7.6874e-02 (1.1965e-01) 
2023-05-25 01:31:34.186073: train Epoch: [16][ 33/193]	Time  1.186 ( 1.505)	Data  0.001 ( 0.361)	Loss 1.1620e-01 (1.1955e-01) 
2023-05-25 01:31:35.798189: train Epoch: [16][ 34/193]	Time  1.612 ( 1.508)	Data  0.475 ( 0.365)	Loss 8.8750e-02 (1.1867e-01) 
2023-05-25 01:31:37.195522: train Epoch: [16][ 35/193]	Time  1.397 ( 1.505)	Data  0.001 ( 0.354)	Loss 1.3066e-01 (1.1901e-01) 
2023-05-25 01:31:38.524237: train Epoch: [16][ 36/193]	Time  1.329 ( 1.500)	Data  0.235 ( 0.351)	Loss 8.3842e-02 (1.1806e-01) 
2023-05-25 01:31:39.512452: train Epoch: [16][ 37/193]	Time  0.988 ( 1.487)	Data  0.001 ( 0.342)	Loss 6.2635e-02 (1.1660e-01) 
2023-05-25 01:31:41.244306: train Epoch: [16][ 38/193]	Time  1.732 ( 1.493)	Data  0.694 ( 0.351)	Loss 1.2540e-01 (1.1682e-01) 
2023-05-25 01:31:42.211997: train Epoch: [16][ 39/193]	Time  0.968 ( 1.480)	Data  0.001 ( 0.342)	Loss 9.7330e-02 (1.1634e-01) 
2023-05-25 01:31:44.048609: train Epoch: [16][ 40/193]	Time  1.837 ( 1.488)	Data  0.752 ( 0.352)	Loss 1.2694e-01 (1.1659e-01) 
2023-05-25 01:31:44.991358: train Epoch: [16][ 41/193]	Time  0.943 ( 1.475)	Data  0.001 ( 0.344)	Loss 7.6743e-02 (1.1565e-01) 
2023-05-25 01:31:47.014401: train Epoch: [16][ 42/193]	Time  2.023 ( 1.488)	Data  0.779 ( 0.354)	Loss 8.8102e-02 (1.1500e-01) 
2023-05-25 01:31:48.107606: train Epoch: [16][ 43/193]	Time  1.093 ( 1.479)	Data  0.001 ( 0.346)	Loss 1.1941e-01 (1.1511e-01) 
2023-05-25 01:31:49.718668: train Epoch: [16][ 44/193]	Time  1.611 ( 1.482)	Data  0.393 ( 0.347)	Loss 8.6783e-02 (1.1448e-01) 
2023-05-25 01:31:50.838195: train Epoch: [16][ 45/193]	Time  1.120 ( 1.474)	Data  0.001 ( 0.340)	Loss 8.1295e-02 (1.1375e-01) 
2023-05-25 01:31:52.551638: train Epoch: [16][ 46/193]	Time  1.713 ( 1.479)	Data  0.509 ( 0.343)	Loss 8.2820e-02 (1.1310e-01) 
2023-05-25 01:31:53.670631: train Epoch: [16][ 47/193]	Time  1.119 ( 1.472)	Data  0.001 ( 0.336)	Loss 2.2144e-01 (1.1535e-01) 
2023-05-25 01:31:55.432491: train Epoch: [16][ 48/193]	Time  1.762 ( 1.478)	Data  0.561 ( 0.341)	Loss 2.8780e-01 (1.1887e-01) 
2023-05-25 01:31:56.724427: train Epoch: [16][ 49/193]	Time  1.292 ( 1.474)	Data  0.001 ( 0.334)	Loss 9.0736e-02 (1.1831e-01) 
2023-05-25 01:31:58.015914: train Epoch: [16][ 50/193]	Time  1.291 ( 1.470)	Data  0.268 ( 0.333)	Loss 6.9785e-02 (1.1736e-01) 
2023-05-25 01:31:59.049498: train Epoch: [16][ 51/193]	Time  1.034 ( 1.462)	Data  0.001 ( 0.326)	Loss 7.7105e-02 (1.1658e-01) 
2023-05-25 01:32:00.756830: train Epoch: [16][ 52/193]	Time  1.707 ( 1.467)	Data  0.640 ( 0.332)	Loss 2.8596e-01 (1.1978e-01) 
2023-05-25 01:32:01.812689: train Epoch: [16][ 53/193]	Time  1.056 ( 1.459)	Data  0.001 ( 0.326)	Loss 8.2070e-02 (1.1908e-01) 
2023-05-25 01:32:03.383373: train Epoch: [16][ 54/193]	Time  1.571 ( 1.461)	Data  0.469 ( 0.329)	Loss 1.7296e-01 (1.2006e-01) 
2023-05-25 01:32:04.368660: train Epoch: [16][ 55/193]	Time  0.985 ( 1.453)	Data  0.001 ( 0.323)	Loss 1.4388e-01 (1.2049e-01) 
2023-05-25 01:32:06.286717: train Epoch: [16][ 56/193]	Time  1.918 ( 1.461)	Data  0.586 ( 0.327)	Loss 1.3168e-01 (1.2068e-01) 
2023-05-25 01:32:07.319771: train Epoch: [16][ 57/193]	Time  1.033 ( 1.453)	Data  0.001 ( 0.322)	Loss 1.4859e-01 (1.2116e-01) 
2023-05-25 01:32:08.984384: train Epoch: [16][ 58/193]	Time  1.665 ( 1.457)	Data  0.361 ( 0.322)	Loss 1.0329e-01 (1.2086e-01) 
2023-05-25 01:32:09.949382: train Epoch: [16][ 59/193]	Time  0.965 ( 1.449)	Data  0.001 ( 0.317)	Loss 1.0594e-01 (1.2061e-01) 
2023-05-25 01:32:11.610762: train Epoch: [16][ 60/193]	Time  1.661 ( 1.452)	Data  0.402 ( 0.318)	Loss 1.5601e-01 (1.2119e-01) 
2023-05-25 01:32:12.671780: train Epoch: [16][ 61/193]	Time  1.061 ( 1.446)	Data  0.001 ( 0.313)	Loss 9.0119e-02 (1.2069e-01) 
2023-05-25 01:32:14.393895: train Epoch: [16][ 62/193]	Time  1.722 ( 1.450)	Data  0.578 ( 0.318)	Loss 1.2571e-01 (1.2077e-01) 
2023-05-25 01:32:15.459914: train Epoch: [16][ 63/193]	Time  1.066 ( 1.444)	Data  0.001 ( 0.313)	Loss 2.6277e-01 (1.2299e-01) 
2023-05-25 01:32:17.065448: train Epoch: [16][ 64/193]	Time  1.606 ( 1.447)	Data  0.580 ( 0.317)	Loss 1.8621e-01 (1.2396e-01) 
2023-05-25 01:32:18.146350: train Epoch: [16][ 65/193]	Time  1.081 ( 1.441)	Data  0.001 ( 0.312)	Loss 1.0589e-01 (1.2369e-01) 
2023-05-25 01:32:19.879319: train Epoch: [16][ 66/193]	Time  1.733 ( 1.446)	Data  0.693 ( 0.318)	Loss 1.3914e-01 (1.2392e-01) 
2023-05-25 01:32:21.158457: train Epoch: [16][ 67/193]	Time  1.279 ( 1.443)	Data  0.001 ( 0.313)	Loss 7.7169e-02 (1.2323e-01) 
2023-05-25 01:32:22.694375: train Epoch: [16][ 68/193]	Time  1.536 ( 1.445)	Data  0.445 ( 0.315)	Loss 9.7900e-02 (1.2286e-01) 
2023-05-25 01:32:23.850910: train Epoch: [16][ 69/193]	Time  1.157 ( 1.440)	Data  0.001 ( 0.310)	Loss 1.3967e-01 (1.2311e-01) 
2023-05-25 01:32:25.474335: train Epoch: [16][ 70/193]	Time  1.623 ( 1.443)	Data  0.619 ( 0.315)	Loss 1.3000e-01 (1.2320e-01) 
2023-05-25 01:32:26.575716: train Epoch: [16][ 71/193]	Time  1.101 ( 1.438)	Data  0.001 ( 0.310)	Loss 5.5425e-02 (1.2226e-01) 
2023-05-25 01:32:28.252868: train Epoch: [16][ 72/193]	Time  1.677 ( 1.442)	Data  0.538 ( 0.313)	Loss 1.2518e-01 (1.2230e-01) 
2023-05-25 01:32:29.286247: train Epoch: [16][ 73/193]	Time  1.033 ( 1.436)	Data  0.001 ( 0.309)	Loss 7.4899e-02 (1.2166e-01) 
2023-05-25 01:32:31.294004: train Epoch: [16][ 74/193]	Time  2.008 ( 1.444)	Data  0.567 ( 0.313)	Loss 8.8318e-02 (1.2122e-01) 
2023-05-25 01:32:32.392561: train Epoch: [16][ 75/193]	Time  1.099 ( 1.439)	Data  0.001 ( 0.309)	Loss 9.4445e-02 (1.2086e-01) 
2023-05-25 01:32:33.561981: train Epoch: [16][ 76/193]	Time  1.169 ( 1.436)	Data  0.177 ( 0.307)	Loss 1.1676e-01 (1.2081e-01) 
2023-05-25 01:32:34.634840: train Epoch: [16][ 77/193]	Time  1.073 ( 1.431)	Data  0.001 ( 0.303)	Loss 1.1701e-01 (1.2076e-01) 
2023-05-25 01:32:36.398502: train Epoch: [16][ 78/193]	Time  1.764 ( 1.435)	Data  0.741 ( 0.309)	Loss 1.1382e-01 (1.2067e-01) 
2023-05-25 01:32:37.531982: train Epoch: [16][ 79/193]	Time  1.133 ( 1.431)	Data  0.001 ( 0.305)	Loss 1.0455e-01 (1.2047e-01) 
2023-05-25 01:32:39.344652: train Epoch: [16][ 80/193]	Time  1.813 ( 1.436)	Data  0.640 ( 0.309)	Loss 1.4755e-01 (1.2081e-01) 
2023-05-25 01:32:40.556131: train Epoch: [16][ 81/193]	Time  1.211 ( 1.433)	Data  0.001 ( 0.305)	Loss 7.2601e-02 (1.2022e-01) 
2023-05-25 01:32:42.067883: train Epoch: [16][ 82/193]	Time  1.512 ( 1.434)	Data  0.298 ( 0.305)	Loss 1.0176e-01 (1.2000e-01) 
2023-05-25 01:32:43.070247: train Epoch: [16][ 83/193]	Time  1.002 ( 1.429)	Data  0.001 ( 0.301)	Loss 1.7088e-01 (1.2060e-01) 
2023-05-25 01:32:44.782618: train Epoch: [16][ 84/193]	Time  1.712 ( 1.432)	Data  0.573 ( 0.305)	Loss 1.6155e-01 (1.2108e-01) 
2023-05-25 01:32:46.057127: train Epoch: [16][ 85/193]	Time  1.275 ( 1.431)	Data  0.001 ( 0.301)	Loss 1.8982e-01 (1.2188e-01) 
2023-05-25 01:32:47.749899: train Epoch: [16][ 86/193]	Time  1.693 ( 1.434)	Data  0.418 ( 0.302)	Loss 6.2739e-02 (1.2120e-01) 
2023-05-25 01:32:48.913612: train Epoch: [16][ 87/193]	Time  1.164 ( 1.431)	Data  0.001 ( 0.299)	Loss 8.6704e-02 (1.2081e-01) 
2023-05-25 01:32:50.374478: train Epoch: [16][ 88/193]	Time  1.461 ( 1.431)	Data  0.454 ( 0.301)	Loss 1.1977e-01 (1.2080e-01) 
2023-05-25 01:32:51.390203: train Epoch: [16][ 89/193]	Time  1.016 ( 1.426)	Data  0.001 ( 0.297)	Loss 5.1611e-02 (1.2003e-01) 
2023-05-25 01:32:53.464936: train Epoch: [16][ 90/193]	Time  2.075 ( 1.433)	Data  0.815 ( 0.303)	Loss 9.9814e-02 (1.1981e-01) 
2023-05-25 01:32:54.512908: train Epoch: [16][ 91/193]	Time  1.048 ( 1.429)	Data  0.001 ( 0.300)	Loss 1.2989e-01 (1.1992e-01) 
2023-05-25 01:32:56.149371: train Epoch: [16][ 92/193]	Time  1.636 ( 1.431)	Data  0.466 ( 0.302)	Loss 1.4633e-01 (1.2020e-01) 
2023-05-25 01:32:57.209887: train Epoch: [16][ 93/193]	Time  1.061 ( 1.428)	Data  0.001 ( 0.298)	Loss 6.4919e-02 (1.1961e-01) 
2023-05-25 01:32:59.024479: train Epoch: [16][ 94/193]	Time  1.815 ( 1.432)	Data  0.515 ( 0.301)	Loss 7.8568e-02 (1.1918e-01) 
2023-05-25 01:33:00.094593: train Epoch: [16][ 95/193]	Time  1.070 ( 1.428)	Data  0.001 ( 0.298)	Loss 8.1012e-02 (1.1878e-01) 
2023-05-25 01:33:01.914716: train Epoch: [16][ 96/193]	Time  1.820 ( 1.432)	Data  0.611 ( 0.301)	Loss 5.2851e-02 (1.1810e-01) 
2023-05-25 01:33:02.855575: train Epoch: [16][ 97/193]	Time  0.941 ( 1.427)	Data  0.001 ( 0.298)	Loss 1.0055e-01 (1.1793e-01) 
2023-05-25 01:33:04.661348: train Epoch: [16][ 98/193]	Time  1.806 ( 1.431)	Data  0.663 ( 0.301)	Loss 7.0908e-02 (1.1745e-01) 
2023-05-25 01:33:05.670687: train Epoch: [16][ 99/193]	Time  1.009 ( 1.426)	Data  0.001 ( 0.298)	Loss 1.1732e-01 (1.1745e-01) 
2023-05-25 01:33:07.500164: train Epoch: [16][100/193]	Time  1.829 ( 1.430)	Data  0.714 ( 0.302)	Loss 1.2512e-01 (1.1752e-01) 
2023-05-25 01:33:08.709790: train Epoch: [16][101/193]	Time  1.210 ( 1.428)	Data  0.001 ( 0.300)	Loss 1.2166e-01 (1.1757e-01) 
2023-05-25 01:33:10.318490: train Epoch: [16][102/193]	Time  1.609 ( 1.430)	Data  0.534 ( 0.302)	Loss 1.0719e-01 (1.1746e-01) 
2023-05-25 01:33:11.609318: train Epoch: [16][103/193]	Time  1.291 ( 1.429)	Data  0.001 ( 0.299)	Loss 1.0186e-01 (1.1731e-01) 
2023-05-25 01:33:13.307609: train Epoch: [16][104/193]	Time  1.698 ( 1.431)	Data  0.498 ( 0.301)	Loss 1.0509e-01 (1.1720e-01) 
2023-05-25 01:33:14.382977: train Epoch: [16][105/193]	Time  1.075 ( 1.428)	Data  0.001 ( 0.298)	Loss 1.0132e-01 (1.1705e-01) 
2023-05-25 01:33:16.146365: train Epoch: [16][106/193]	Time  1.763 ( 1.431)	Data  0.590 ( 0.301)	Loss 1.0722e-01 (1.1696e-01) 
2023-05-25 01:33:17.267914: train Epoch: [16][107/193]	Time  1.122 ( 1.428)	Data  0.001 ( 0.298)	Loss 1.4485e-01 (1.1721e-01) 
2023-05-25 01:33:18.745800: train Epoch: [16][108/193]	Time  1.478 ( 1.429)	Data  0.517 ( 0.300)	Loss 6.6258e-02 (1.1675e-01) 
2023-05-25 01:33:19.723980: train Epoch: [16][109/193]	Time  0.978 ( 1.425)	Data  0.001 ( 0.297)	Loss 9.5452e-02 (1.1655e-01) 
2023-05-25 01:33:21.746012: train Epoch: [16][110/193]	Time  2.022 ( 1.430)	Data  0.858 ( 0.302)	Loss 1.0093e-01 (1.1641e-01) 
2023-05-25 01:33:22.792901: train Epoch: [16][111/193]	Time  1.047 ( 1.427)	Data  0.001 ( 0.300)	Loss 5.4516e-02 (1.1586e-01) 
2023-05-25 01:33:24.512240: train Epoch: [16][112/193]	Time  1.719 ( 1.429)	Data  0.576 ( 0.302)	Loss 1.1467e-01 (1.1585e-01) 
2023-05-25 01:33:25.452109: train Epoch: [16][113/193]	Time  0.940 ( 1.425)	Data  0.001 ( 0.299)	Loss 9.3762e-02 (1.1566e-01) 
2023-05-25 01:33:27.405677: train Epoch: [16][114/193]	Time  1.954 ( 1.429)	Data  0.817 ( 0.304)	Loss 6.9064e-02 (1.1525e-01) 
2023-05-25 01:33:28.384579: train Epoch: [16][115/193]	Time  0.979 ( 1.426)	Data  0.001 ( 0.301)	Loss 1.3990e-01 (1.1546e-01) 
2023-05-25 01:33:30.566561: train Epoch: [16][116/193]	Time  2.182 ( 1.432)	Data  0.897 ( 0.306)	Loss 1.7292e-01 (1.1595e-01) 
2023-05-25 01:33:31.597392: train Epoch: [16][117/193]	Time  1.031 ( 1.429)	Data  0.001 ( 0.304)	Loss 8.7764e-02 (1.1572e-01) 
2023-05-25 01:33:33.416738: train Epoch: [16][118/193]	Time  1.819 ( 1.432)	Data  0.416 ( 0.305)	Loss 6.4560e-02 (1.1529e-01) 
2023-05-25 01:33:34.506731: train Epoch: [16][119/193]	Time  1.090 ( 1.429)	Data  0.001 ( 0.302)	Loss 7.8614e-02 (1.1498e-01) 
2023-05-25 01:33:35.908671: train Epoch: [16][120/193]	Time  1.402 ( 1.429)	Data  0.250 ( 0.302)	Loss 1.5764e-01 (1.1533e-01) 
2023-05-25 01:33:36.935026: train Epoch: [16][121/193]	Time  1.026 ( 1.426)	Data  0.001 ( 0.299)	Loss 9.0644e-02 (1.1513e-01) 
2023-05-25 01:33:38.960317: train Epoch: [16][122/193]	Time  2.025 ( 1.430)	Data  0.744 ( 0.303)	Loss 1.0636e-01 (1.1506e-01) 
2023-05-25 01:33:40.057168: train Epoch: [16][123/193]	Time  1.097 ( 1.428)	Data  0.001 ( 0.300)	Loss 1.0966e-01 (1.1502e-01) 
2023-05-25 01:33:41.686913: train Epoch: [16][124/193]	Time  1.630 ( 1.429)	Data  0.544 ( 0.302)	Loss 1.2786e-01 (1.1512e-01) 
2023-05-25 01:33:42.772088: train Epoch: [16][125/193]	Time  1.085 ( 1.427)	Data  0.001 ( 0.300)	Loss 1.4290e-01 (1.1534e-01) 
2023-05-25 01:33:44.948926: train Epoch: [16][126/193]	Time  2.177 ( 1.432)	Data  0.683 ( 0.303)	Loss 1.1072e-01 (1.1530e-01) 
2023-05-25 01:33:46.038275: train Epoch: [16][127/193]	Time  1.089 ( 1.430)	Data  0.001 ( 0.301)	Loss 3.4994e-01 (1.1714e-01) 
2023-05-25 01:33:47.203533: train Epoch: [16][128/193]	Time  1.165 ( 1.428)	Data  0.001 ( 0.298)	Loss 1.2467e-01 (1.1719e-01) 
2023-05-25 01:33:48.407647: train Epoch: [16][129/193]	Time  1.204 ( 1.426)	Data  0.001 ( 0.296)	Loss 7.3412e-02 (1.1686e-01) 
2023-05-25 01:33:49.562217: train Epoch: [16][130/193]	Time  1.155 ( 1.424)	Data  0.057 ( 0.294)	Loss 9.3009e-02 (1.1668e-01) 
2023-05-25 01:33:50.611127: train Epoch: [16][131/193]	Time  1.049 ( 1.421)	Data  0.001 ( 0.292)	Loss 6.8193e-02 (1.1631e-01) 
2023-05-25 01:33:51.988463: train Epoch: [16][132/193]	Time  1.377 ( 1.421)	Data  0.384 ( 0.293)	Loss 6.7875e-02 (1.1594e-01) 
2023-05-25 01:33:53.013781: train Epoch: [16][133/193]	Time  1.025 ( 1.418)	Data  0.001 ( 0.291)	Loss 1.3092e-01 (1.1606e-01) 
2023-05-25 01:33:55.063145: train Epoch: [16][134/193]	Time  2.049 ( 1.423)	Data  0.775 ( 0.294)	Loss 1.3897e-01 (1.1623e-01) 
2023-05-25 01:33:56.067017: train Epoch: [16][135/193]	Time  1.004 ( 1.419)	Data  0.001 ( 0.292)	Loss 8.7484e-02 (1.1601e-01) 
2023-05-25 01:33:57.594287: train Epoch: [16][136/193]	Time  1.527 ( 1.420)	Data  0.348 ( 0.292)	Loss 9.4781e-02 (1.1586e-01) 
2023-05-25 01:33:58.645889: train Epoch: [16][137/193]	Time  1.052 ( 1.418)	Data  0.001 ( 0.290)	Loss 9.4755e-02 (1.1571e-01) 
2023-05-25 01:34:00.340744: train Epoch: [16][138/193]	Time  1.695 ( 1.420)	Data  0.534 ( 0.292)	Loss 1.8660e-01 (1.1622e-01) 
2023-05-25 01:34:01.613441: train Epoch: [16][139/193]	Time  1.273 ( 1.418)	Data  0.001 ( 0.290)	Loss 6.9080e-02 (1.1588e-01) 
2023-05-25 01:34:02.752877: train Epoch: [16][140/193]	Time  1.139 ( 1.417)	Data  0.094 ( 0.289)	Loss 6.0583e-02 (1.1549e-01) 
2023-05-25 01:34:03.730051: train Epoch: [16][141/193]	Time  0.977 ( 1.413)	Data  0.001 ( 0.287)	Loss 1.4575e-01 (1.1570e-01) 
2023-05-25 01:34:05.393805: train Epoch: [16][142/193]	Time  1.664 ( 1.415)	Data  0.666 ( 0.289)	Loss 7.7468e-02 (1.1543e-01) 
2023-05-25 01:34:06.491170: train Epoch: [16][143/193]	Time  1.097 ( 1.413)	Data  0.001 ( 0.287)	Loss 1.2064e-01 (1.1547e-01) 
2023-05-25 01:34:08.418578: train Epoch: [16][144/193]	Time  1.927 ( 1.417)	Data  0.628 ( 0.290)	Loss 8.8057e-02 (1.1528e-01) 
2023-05-25 01:34:09.382964: train Epoch: [16][145/193]	Time  0.964 ( 1.413)	Data  0.001 ( 0.288)	Loss 8.1910e-02 (1.1505e-01) 
2023-05-25 01:34:11.092188: train Epoch: [16][146/193]	Time  1.709 ( 1.415)	Data  0.507 ( 0.289)	Loss 1.0337e-01 (1.1497e-01) 
2023-05-25 01:34:12.101988: train Epoch: [16][147/193]	Time  1.010 ( 1.413)	Data  0.002 ( 0.287)	Loss 1.0785e-01 (1.1492e-01) 
2023-05-25 01:34:13.807081: train Epoch: [16][148/193]	Time  1.705 ( 1.415)	Data  0.569 ( 0.289)	Loss 1.0794e-01 (1.1488e-01) 
2023-05-25 01:34:14.906656: train Epoch: [16][149/193]	Time  1.100 ( 1.413)	Data  0.086 ( 0.288)	Loss 1.2597e-01 (1.1495e-01) 
2023-05-25 01:34:16.600295: train Epoch: [16][150/193]	Time  1.694 ( 1.414)	Data  0.480 ( 0.289)	Loss 1.1688e-01 (1.1496e-01) 
2023-05-25 01:34:17.865440: train Epoch: [16][151/193]	Time  1.265 ( 1.413)	Data  0.233 ( 0.289)	Loss 1.3312e-01 (1.1508e-01) 
2023-05-25 01:34:18.915568: train Epoch: [16][152/193]	Time  1.050 ( 1.411)	Data  0.164 ( 0.288)	Loss 1.5358e-01 (1.1533e-01) 
2023-05-25 01:34:21.123616: train Epoch: [16][153/193]	Time  2.208 ( 1.416)	Data  0.755 ( 0.291)	Loss 1.1493e-01 (1.1533e-01) 
2023-05-25 01:34:22.253488: train Epoch: [16][154/193]	Time  1.130 ( 1.414)	Data  0.001 ( 0.289)	Loss 8.2705e-02 (1.1512e-01) 
2023-05-25 01:34:23.690129: train Epoch: [16][155/193]	Time  1.437 ( 1.415)	Data  0.155 ( 0.288)	Loss 9.8377e-02 (1.1501e-01) 
2023-05-25 01:34:24.681372: train Epoch: [16][156/193]	Time  0.991 ( 1.412)	Data  0.001 ( 0.286)	Loss 1.3878e-01 (1.1517e-01) 
2023-05-25 01:34:26.475129: train Epoch: [16][157/193]	Time  1.794 ( 1.414)	Data  0.473 ( 0.287)	Loss 7.1442e-02 (1.1489e-01) 
2023-05-25 01:34:27.575624: train Epoch: [16][158/193]	Time  1.100 ( 1.412)	Data  0.001 ( 0.286)	Loss 8.7360e-02 (1.1472e-01) 
2023-05-25 01:34:29.108900: train Epoch: [16][159/193]	Time  1.533 ( 1.413)	Data  0.345 ( 0.286)	Loss 5.8995e-02 (1.1437e-01) 
2023-05-25 01:34:30.212399: train Epoch: [16][160/193]	Time  1.103 ( 1.411)	Data  0.015 ( 0.284)	Loss 9.4755e-02 (1.1425e-01) 
2023-05-25 01:34:32.061410: train Epoch: [16][161/193]	Time  1.849 ( 1.414)	Data  0.523 ( 0.286)	Loss 9.6878e-02 (1.1414e-01) 
2023-05-25 01:34:33.199620: train Epoch: [16][162/193]	Time  1.138 ( 1.412)	Data  0.001 ( 0.284)	Loss 8.3380e-02 (1.1395e-01) 
2023-05-25 01:34:34.764339: train Epoch: [16][163/193]	Time  1.565 ( 1.413)	Data  0.389 ( 0.285)	Loss 6.9780e-02 (1.1368e-01) 
2023-05-25 01:34:36.003016: train Epoch: [16][164/193]	Time  1.239 ( 1.412)	Data  0.001 ( 0.283)	Loss 1.8141e-01 (1.1409e-01) 
2023-05-25 01:34:37.466585: train Epoch: [16][165/193]	Time  1.464 ( 1.412)	Data  0.432 ( 0.284)	Loss 1.4677e-01 (1.1429e-01) 
2023-05-25 01:34:38.527859: train Epoch: [16][166/193]	Time  1.061 ( 1.410)	Data  0.001 ( 0.282)	Loss 9.3449e-02 (1.1416e-01) 
2023-05-25 01:34:40.410074: train Epoch: [16][167/193]	Time  1.882 ( 1.413)	Data  0.790 ( 0.285)	Loss 9.0494e-02 (1.1402e-01) 
2023-05-25 01:34:41.391172: train Epoch: [16][168/193]	Time  0.981 ( 1.410)	Data  0.001 ( 0.283)	Loss 7.4365e-02 (1.1379e-01) 
2023-05-25 01:34:43.063719: train Epoch: [16][169/193]	Time  1.673 ( 1.412)	Data  0.638 ( 0.286)	Loss 2.6094e-01 (1.1465e-01) 
2023-05-25 01:34:44.178674: train Epoch: [16][170/193]	Time  1.115 ( 1.410)	Data  0.001 ( 0.284)	Loss 8.4010e-02 (1.1447e-01) 
2023-05-25 01:34:45.878395: train Epoch: [16][171/193]	Time  1.700 ( 1.412)	Data  0.660 ( 0.286)	Loss 7.8300e-02 (1.1426e-01) 
2023-05-25 01:34:46.952401: train Epoch: [16][172/193]	Time  1.074 ( 1.410)	Data  0.087 ( 0.285)	Loss 6.9490e-02 (1.1400e-01) 
2023-05-25 01:34:48.780887: train Epoch: [16][173/193]	Time  1.828 ( 1.412)	Data  0.646 ( 0.287)	Loss 1.3509e-01 (1.1413e-01) 
2023-05-25 01:34:49.812230: train Epoch: [16][174/193]	Time  1.031 ( 1.410)	Data  0.015 ( 0.285)	Loss 1.3433e-01 (1.1424e-01) 
2023-05-25 01:34:51.552414: train Epoch: [16][175/193]	Time  1.740 ( 1.412)	Data  0.534 ( 0.287)	Loss 8.6711e-02 (1.1408e-01) 
2023-05-25 01:34:52.594192: train Epoch: [16][176/193]	Time  1.042 ( 1.410)	Data  0.001 ( 0.285)	Loss 6.9134e-02 (1.1383e-01) 
2023-05-25 01:34:54.152373: train Epoch: [16][177/193]	Time  1.558 ( 1.411)	Data  0.517 ( 0.287)	Loss 1.9015e-01 (1.1426e-01) 
2023-05-25 01:34:55.322562: train Epoch: [16][178/193]	Time  1.170 ( 1.409)	Data  0.176 ( 0.286)	Loss 1.1680e-01 (1.1427e-01) 
2023-05-25 01:34:57.080721: train Epoch: [16][179/193]	Time  1.758 ( 1.411)	Data  0.595 ( 0.288)	Loss 9.0320e-02 (1.1414e-01) 
2023-05-25 01:34:58.279809: train Epoch: [16][180/193]	Time  1.199 ( 1.410)	Data  0.020 ( 0.286)	Loss 1.3225e-01 (1.1424e-01) 
2023-05-25 01:34:59.751636: train Epoch: [16][181/193]	Time  1.472 ( 1.411)	Data  0.439 ( 0.287)	Loss 4.7336e-02 (1.1387e-01) 
2023-05-25 01:35:00.826657: train Epoch: [16][182/193]	Time  1.075 ( 1.409)	Data  0.099 ( 0.286)	Loss 8.1700e-02 (1.1370e-01) 
2023-05-25 01:35:02.542260: train Epoch: [16][183/193]	Time  1.716 ( 1.410)	Data  0.681 ( 0.288)	Loss 5.5336e-02 (1.1338e-01) 
2023-05-25 01:35:03.661826: train Epoch: [16][184/193]	Time  1.120 ( 1.409)	Data  0.171 ( 0.288)	Loss 9.6715e-02 (1.1329e-01) 
2023-05-25 01:35:05.298084: train Epoch: [16][185/193]	Time  1.636 ( 1.410)	Data  0.648 ( 0.289)	Loss 6.6901e-02 (1.1304e-01) 
2023-05-25 01:35:06.567388: train Epoch: [16][186/193]	Time  1.269 ( 1.409)	Data  0.241 ( 0.289)	Loss 1.1395e-01 (1.1305e-01) 
2023-05-25 01:35:08.376649: train Epoch: [16][187/193]	Time  1.809 ( 1.411)	Data  0.598 ( 0.291)	Loss 1.8214e-01 (1.1341e-01) 
2023-05-25 01:35:09.385217: train Epoch: [16][188/193]	Time  1.009 ( 1.409)	Data  0.001 ( 0.289)	Loss 1.2620e-01 (1.1348e-01) 
2023-05-25 01:35:11.166005: train Epoch: [16][189/193]	Time  1.781 ( 1.411)	Data  0.554 ( 0.291)	Loss 1.2719e-01 (1.1355e-01) 
2023-05-25 01:35:12.326167: train Epoch: [16][190/193]	Time  1.160 ( 1.410)	Data  0.179 ( 0.290)	Loss 7.6859e-02 (1.1336e-01) 
2023-05-25 01:35:13.930915: train Epoch: [16][191/193]	Time  1.605 ( 1.411)	Data  0.372 ( 0.291)	Loss 1.2728e-01 (1.1343e-01) 
2023-05-25 01:35:14.993858: train Epoch: [16][192/193]	Time  1.063 ( 1.409)	Data  0.001 ( 0.289)	Loss 6.6657e-02 (1.1319e-01) 
2023-05-25 01:35:15.059428: Train Epoch done in 272.0374291429762 s 
2023-05-25 01:35:18.590390: val Epoch: [16][ 0/72]	Time  2.252 ( 2.252)	Data  1.866 ( 1.866)	Loss 1.2994e-01 (1.2994e-01) 
2023-05-25 01:35:18.973323: val Epoch: [16][ 1/72]	Time  0.383 ( 1.318)	Data  0.002 ( 0.934)	Loss 1.2926e-01 (1.2960e-01) 
2023-05-25 01:35:19.935307: val Epoch: [16][ 2/72]	Time  0.962 ( 1.199)	Data  0.731 ( 0.866)	Loss 1.2749e-01 (1.2890e-01) 
2023-05-25 01:35:20.457039: val Epoch: [16][ 3/72]	Time  0.522 ( 1.030)	Data  0.001 ( 0.650)	Loss 8.3749e-02 (1.1761e-01) 
2023-05-25 01:35:21.539867: val Epoch: [16][ 4/72]	Time  1.083 ( 1.040)	Data  0.732 ( 0.666)	Loss 1.2587e-01 (1.1926e-01) 
2023-05-25 01:35:21.809472: val Epoch: [16][ 5/72]	Time  0.270 ( 0.912)	Data  0.001 ( 0.555)	Loss 1.5937e-01 (1.2595e-01) 
2023-05-25 01:35:22.935369: val Epoch: [16][ 6/72]	Time  1.126 ( 0.943)	Data  0.897 ( 0.604)	Loss 1.7782e-01 (1.3336e-01) 
2023-05-25 01:35:23.323894: val Epoch: [16][ 7/72]	Time  0.389 ( 0.873)	Data  0.001 ( 0.529)	Loss 5.5580e-02 (1.2363e-01) 
2023-05-25 01:35:24.336575: val Epoch: [16][ 8/72]	Time  1.013 ( 0.889)	Data  0.801 ( 0.559)	Loss 5.7134e-02 (1.1625e-01) 
2023-05-25 01:35:24.666658: val Epoch: [16][ 9/72]	Time  0.330 ( 0.833)	Data  0.001 ( 0.503)	Loss 1.9439e-01 (1.2406e-01) 
2023-05-25 01:35:25.834917: val Epoch: [16][10/72]	Time  1.168 ( 0.863)	Data  0.892 ( 0.539)	Loss 6.7723e-02 (1.1894e-01) 
2023-05-25 01:35:26.190590: val Epoch: [16][11/72]	Time  0.356 ( 0.821)	Data  0.001 ( 0.494)	Loss 1.0414e-01 (1.1771e-01) 
2023-05-25 01:35:27.369645: val Epoch: [16][12/72]	Time  1.179 ( 0.849)	Data  0.874 ( 0.523)	Loss 1.1037e-01 (1.1714e-01) 
2023-05-25 01:35:27.596442: val Epoch: [16][13/72]	Time  0.227 ( 0.804)	Data  0.001 ( 0.486)	Loss 3.8829e-01 (1.3651e-01) 
2023-05-25 01:35:29.073027: val Epoch: [16][14/72]	Time  1.477 ( 0.849)	Data  1.012 ( 0.521)	Loss 1.4417e-01 (1.3702e-01) 
2023-05-25 01:35:29.441837: val Epoch: [16][15/72]	Time  0.369 ( 0.819)	Data  0.001 ( 0.488)	Loss 5.0010e-02 (1.3158e-01) 
2023-05-25 01:35:30.592393: val Epoch: [16][16/72]	Time  1.151 ( 0.839)	Data  0.685 ( 0.500)	Loss 1.5653e-01 (1.3305e-01) 
2023-05-25 01:35:30.790498: val Epoch: [16][17/72]	Time  0.198 ( 0.803)	Data  0.001 ( 0.472)	Loss 1.6074e-01 (1.3459e-01) 
2023-05-25 01:35:31.750724: val Epoch: [16][18/72]	Time  0.960 ( 0.811)	Data  0.638 ( 0.481)	Loss 5.9242e-02 (1.3062e-01) 
2023-05-25 01:35:32.095104: val Epoch: [16][19/72]	Time  0.344 ( 0.788)	Data  0.002 ( 0.457)	Loss 3.2068e-01 (1.4013e-01) 
2023-05-25 01:35:33.288660: val Epoch: [16][20/72]	Time  1.194 ( 0.807)	Data  0.714 ( 0.469)	Loss 7.8226e-02 (1.3718e-01) 
2023-05-25 01:35:33.833395: val Epoch: [16][21/72]	Time  0.545 ( 0.795)	Data  0.001 ( 0.448)	Loss 3.5994e-01 (1.4730e-01) 
2023-05-25 01:35:34.671488: val Epoch: [16][22/72]	Time  0.838 ( 0.797)	Data  0.300 ( 0.442)	Loss 1.4412e-01 (1.4716e-01) 
2023-05-25 01:35:34.895336: val Epoch: [16][23/72]	Time  0.224 ( 0.773)	Data  0.005 ( 0.423)	Loss 5.2245e-01 (1.6280e-01) 
2023-05-25 01:35:35.854641: val Epoch: [16][24/72]	Time  0.959 ( 0.781)	Data  0.586 ( 0.430)	Loss 2.0002e-01 (1.6429e-01) 
2023-05-25 01:35:36.184244: val Epoch: [16][25/72]	Time  0.330 ( 0.763)	Data  0.001 ( 0.413)	Loss 3.7102e-01 (1.7224e-01) 
2023-05-25 01:35:37.062129: val Epoch: [16][26/72]	Time  0.878 ( 0.768)	Data  0.670 ( 0.423)	Loss 5.4175e-02 (1.6787e-01) 
2023-05-25 01:35:37.385996: val Epoch: [16][27/72]	Time  0.324 ( 0.752)	Data  0.001 ( 0.408)	Loss 3.0924e-01 (1.7292e-01) 
2023-05-25 01:35:38.431116: val Epoch: [16][28/72]	Time  1.045 ( 0.762)	Data  0.849 ( 0.423)	Loss 6.1151e-02 (1.6906e-01) 
2023-05-25 01:35:38.741083: val Epoch: [16][29/72]	Time  0.310 ( 0.747)	Data  0.001 ( 0.409)	Loss 6.1532e-02 (1.6548e-01) 
2023-05-25 01:35:40.304302: val Epoch: [16][30/72]	Time  1.563 ( 0.773)	Data  1.020 ( 0.429)	Loss 1.2994e-01 (1.6433e-01) 
2023-05-25 01:35:40.765147: val Epoch: [16][31/72]	Time  0.461 ( 0.763)	Data  0.001 ( 0.415)	Loss 1.2359e-01 (1.6306e-01) 
2023-05-25 01:35:41.546559: val Epoch: [16][32/72]	Time  0.781 ( 0.764)	Data  0.431 ( 0.416)	Loss 5.8726e-02 (1.5990e-01) 
2023-05-25 01:35:41.760358: val Epoch: [16][33/72]	Time  0.214 ( 0.748)	Data  0.001 ( 0.404)	Loss 1.1841e-01 (1.5868e-01) 
2023-05-25 01:35:42.979715: val Epoch: [16][34/72]	Time  1.219 ( 0.761)	Data  0.890 ( 0.417)	Loss 8.5337e-02 (1.5658e-01) 
2023-05-25 01:35:43.387406: val Epoch: [16][35/72]	Time  0.408 ( 0.751)	Data  0.001 ( 0.406)	Loss 6.8400e-02 (1.5413e-01) 
2023-05-25 01:35:44.265606: val Epoch: [16][36/72]	Time  0.878 ( 0.755)	Data  0.659 ( 0.413)	Loss 8.1030e-02 (1.5216e-01) 
2023-05-25 01:35:44.613439: val Epoch: [16][37/72]	Time  0.348 ( 0.744)	Data  0.001 ( 0.402)	Loss 5.3487e-02 (1.4956e-01) 
2023-05-25 01:35:45.775987: val Epoch: [16][38/72]	Time  1.163 ( 0.755)	Data  0.842 ( 0.413)	Loss 1.4640e-01 (1.4948e-01) 
2023-05-25 01:35:45.942108: val Epoch: [16][39/72]	Time  0.166 ( 0.740)	Data  0.001 ( 0.403)	Loss 6.2416e-02 (1.4730e-01) 
2023-05-25 01:35:47.407357: val Epoch: [16][40/72]	Time  1.465 ( 0.758)	Data  0.949 ( 0.416)	Loss 1.1545e-01 (1.4653e-01) 
2023-05-25 01:35:47.634480: val Epoch: [16][41/72]	Time  0.227 ( 0.745)	Data  0.001 ( 0.406)	Loss 6.5576e-01 (1.5865e-01) 
2023-05-25 01:35:48.562263: val Epoch: [16][42/72]	Time  0.928 ( 0.749)	Data  0.694 ( 0.413)	Loss 5.2338e-02 (1.5618e-01) 
2023-05-25 01:35:48.855602: val Epoch: [16][43/72]	Time  0.293 ( 0.739)	Data  0.001 ( 0.404)	Loss 7.4339e-02 (1.5432e-01) 
2023-05-25 01:35:50.198098: val Epoch: [16][44/72]	Time  1.342 ( 0.752)	Data  0.954 ( 0.416)	Loss 1.0187e-01 (1.5315e-01) 
2023-05-25 01:35:50.491521: val Epoch: [16][45/72]	Time  0.293 ( 0.742)	Data  0.001 ( 0.407)	Loss 6.3530e-02 (1.5120e-01) 
2023-05-25 01:35:51.496866: val Epoch: [16][46/72]	Time  1.005 ( 0.748)	Data  0.731 ( 0.414)	Loss 7.8057e-02 (1.4965e-01) 
2023-05-25 01:35:51.696882: val Epoch: [16][47/72]	Time  0.200 ( 0.737)	Data  0.001 ( 0.405)	Loss 5.4418e-02 (1.4766e-01) 
2023-05-25 01:35:53.175105: val Epoch: [16][48/72]	Time  1.478 ( 0.752)	Data  1.027 ( 0.418)	Loss 5.1268e-01 (1.5511e-01) 
2023-05-25 01:35:53.630888: val Epoch: [16][49/72]	Time  0.456 ( 0.746)	Data  0.001 ( 0.409)	Loss 6.7042e-02 (1.5335e-01) 
2023-05-25 01:35:54.730745: val Epoch: [16][50/72]	Time  1.100 ( 0.753)	Data  0.560 ( 0.412)	Loss 6.7275e-02 (1.5166e-01) 
2023-05-25 01:35:55.157269: val Epoch: [16][51/72]	Time  0.427 ( 0.747)	Data  0.001 ( 0.405)	Loss 6.9006e-02 (1.5007e-01) 
2023-05-25 01:35:55.905099: val Epoch: [16][52/72]	Time  0.748 ( 0.747)	Data  0.463 ( 0.406)	Loss 3.8889e-01 (1.5458e-01) 
2023-05-25 01:35:56.235851: val Epoch: [16][53/72]	Time  0.331 ( 0.739)	Data  0.002 ( 0.398)	Loss 9.1858e-02 (1.5342e-01) 
2023-05-25 01:35:57.487300: val Epoch: [16][54/72]	Time  1.251 ( 0.748)	Data  0.854 ( 0.406)	Loss 9.9140e-02 (1.5243e-01) 
2023-05-25 01:35:57.849317: val Epoch: [16][55/72]	Time  0.362 ( 0.741)	Data  0.002 ( 0.399)	Loss 9.9573e-02 (1.5149e-01) 
2023-05-25 01:35:58.659035: val Epoch: [16][56/72]	Time  0.810 ( 0.742)	Data  0.598 ( 0.403)	Loss 9.9628e-02 (1.5058e-01) 
2023-05-25 01:35:58.917183: val Epoch: [16][57/72]	Time  0.258 ( 0.734)	Data  0.001 ( 0.396)	Loss 6.9604e-02 (1.4918e-01) 
2023-05-25 01:36:00.334932: val Epoch: [16][58/72]	Time  1.418 ( 0.746)	Data  0.999 ( 0.406)	Loss 3.4374e-01 (1.5248e-01) 
2023-05-25 01:36:00.663652: val Epoch: [16][59/72]	Time  0.329 ( 0.739)	Data  0.001 ( 0.399)	Loss 2.0461e-01 (1.5335e-01) 
2023-05-25 01:36:01.694622: val Epoch: [16][60/72]	Time  1.031 ( 0.744)	Data  0.673 ( 0.404)	Loss 1.5218e-01 (1.5333e-01) 
2023-05-25 01:36:01.930408: val Epoch: [16][61/72]	Time  0.236 ( 0.735)	Data  0.001 ( 0.397)	Loss 7.5460e-02 (1.5207e-01) 
2023-05-25 01:36:02.969684: val Epoch: [16][62/72]	Time  1.039 ( 0.740)	Data  0.772 ( 0.403)	Loss 6.9151e-02 (1.5076e-01) 
2023-05-25 01:36:03.179150: val Epoch: [16][63/72]	Time  0.209 ( 0.732)	Data  0.001 ( 0.397)	Loss 1.0338e-01 (1.5002e-01) 
2023-05-25 01:36:04.312698: val Epoch: [16][64/72]	Time  1.134 ( 0.738)	Data  0.940 ( 0.405)	Loss 1.5145e-01 (1.5004e-01) 
2023-05-25 01:36:04.849125: val Epoch: [16][65/72]	Time  0.536 ( 0.735)	Data  0.001 ( 0.399)	Loss 7.3110e-02 (1.4887e-01) 
2023-05-25 01:36:06.034847: val Epoch: [16][66/72]	Time  1.186 ( 0.742)	Data  0.708 ( 0.404)	Loss 3.5259e-01 (1.5191e-01) 
2023-05-25 01:36:06.423081: val Epoch: [16][67/72]	Time  0.388 ( 0.737)	Data  0.002 ( 0.398)	Loss 2.6682e-01 (1.5360e-01) 
2023-05-25 01:36:07.358389: val Epoch: [16][68/72]	Time  0.935 ( 0.739)	Data  0.552 ( 0.400)	Loss 2.4415e-01 (1.5492e-01) 
2023-05-25 01:36:07.612332: val Epoch: [16][69/72]	Time  0.254 ( 0.732)	Data  0.001 ( 0.394)	Loss 1.0924e-01 (1.5426e-01) 
2023-05-25 01:36:08.810713: val Epoch: [16][70/72]	Time  1.198 ( 0.739)	Data  0.729 ( 0.399)	Loss 1.2620e-01 (1.5387e-01) 
2023-05-25 01:36:09.009698: val Epoch: [16][71/72]	Time  0.199 ( 0.732)	Data  0.001 ( 0.394)	Loss 7.3897e-02 (1.5276e-01) 
2023-05-25 01:36:09.258940: Epoch 16 :Val : ['ET : 0.7198535799980164', 'TC : 0.7512874603271484', 'WT : 0.8358287811279297'] 
2023-05-25 01:36:09.262028: Epoch 16 :Val : ['ET : 0.7198535799980164', 'TC : 0.7512874603271484', 'WT : 0.8358287811279297'] 
2023-05-25 01:36:09.265912: Saving the model with DSC 0.7637650370597839 
2023-05-25 01:36:10.321483: Val epoch done in 55.26204361405689 s 
2023-05-25 01:36:10.334665: Batches per epoch:  193 
2023-05-25 01:36:14.565228: train Epoch: [17][  0/193]	Time  4.230 ( 4.230)	Data  2.981 ( 2.981)	Loss 6.5548e-02 (6.5548e-02) 
2023-05-25 01:36:15.834269: train Epoch: [17][  1/193]	Time  1.269 ( 2.749)	Data  0.001 ( 1.491)	Loss 9.5623e-02 (8.0586e-02) 
2023-05-25 01:36:16.957046: train Epoch: [17][  2/193]	Time  1.123 ( 2.207)	Data  0.077 ( 1.020)	Loss 5.9055e-02 (7.3409e-02) 
2023-05-25 01:36:18.038443: train Epoch: [17][  3/193]	Time  1.081 ( 1.926)	Data  0.001 ( 0.765)	Loss 1.4344e-01 (9.0917e-02) 
2023-05-25 01:36:19.673328: train Epoch: [17][  4/193]	Time  1.635 ( 1.868)	Data  0.672 ( 0.746)	Loss 9.5943e-02 (9.1922e-02) 
2023-05-25 01:36:20.673202: train Epoch: [17][  5/193]	Time  1.000 ( 1.723)	Data  0.001 ( 0.622)	Loss 9.6194e-02 (9.2634e-02) 
2023-05-25 01:36:22.775507: train Epoch: [17][  6/193]	Time  2.102 ( 1.777)	Data  0.691 ( 0.632)	Loss 7.8954e-02 (9.0680e-02) 
2023-05-25 01:36:23.837822: train Epoch: [17][  7/193]	Time  1.062 ( 1.688)	Data  0.001 ( 0.553)	Loss 1.5160e-01 (9.8294e-02) 
2023-05-25 01:36:25.188039: train Epoch: [17][  8/193]	Time  1.350 ( 1.650)	Data  0.140 ( 0.507)	Loss 6.8337e-02 (9.4966e-02) 
2023-05-25 01:36:26.329278: train Epoch: [17][  9/193]	Time  1.141 ( 1.599)	Data  0.113 ( 0.468)	Loss 1.1138e-01 (9.6607e-02) 
2023-05-25 01:36:27.910884: train Epoch: [17][ 10/193]	Time  1.582 ( 1.598)	Data  0.468 ( 0.468)	Loss 1.0754e-01 (9.7601e-02) 
2023-05-25 01:36:29.309821: train Epoch: [17][ 11/193]	Time  1.399 ( 1.581)	Data  0.277 ( 0.452)	Loss 6.8198e-02 (9.5151e-02) 
2023-05-25 01:36:30.661623: train Epoch: [17][ 12/193]	Time  1.352 ( 1.564)	Data  0.268 ( 0.438)	Loss 9.1356e-02 (9.4859e-02) 
2023-05-25 01:36:32.276242: train Epoch: [17][ 13/193]	Time  1.615 ( 1.567)	Data  0.412 ( 0.436)	Loss 7.0917e-02 (9.3149e-02) 
2023-05-25 01:36:33.312609: train Epoch: [17][ 14/193]	Time  1.036 ( 1.532)	Data  0.070 ( 0.411)	Loss 5.6155e-02 (9.0683e-02) 
2023-05-25 01:36:35.290969: train Epoch: [17][ 15/193]	Time  1.978 ( 1.560)	Data  0.653 ( 0.427)	Loss 1.0331e-01 (9.1472e-02) 
2023-05-25 01:36:36.355083: train Epoch: [17][ 16/193]	Time  1.064 ( 1.531)	Data  0.001 ( 0.402)	Loss 1.9279e-01 (9.7432e-02) 
2023-05-25 01:36:38.048248: train Epoch: [17][ 17/193]	Time  1.693 ( 1.540)	Data  0.381 ( 0.400)	Loss 8.8235e-02 (9.6921e-02) 
2023-05-25 01:36:39.093755: train Epoch: [17][ 18/193]	Time  1.045 ( 1.514)	Data  0.001 ( 0.379)	Loss 9.3560e-02 (9.6744e-02) 
2023-05-25 01:36:40.490757: train Epoch: [17][ 19/193]	Time  1.397 ( 1.508)	Data  0.381 ( 0.379)	Loss 1.7711e-01 (1.0076e-01) 
2023-05-25 01:36:41.607341: train Epoch: [17][ 20/193]	Time  1.117 ( 1.489)	Data  0.121 ( 0.367)	Loss 1.6028e-01 (1.0360e-01) 
2023-05-25 01:36:43.414837: train Epoch: [17][ 21/193]	Time  1.808 ( 1.504)	Data  0.749 ( 0.385)	Loss 9.4068e-02 (1.0316e-01) 
2023-05-25 01:36:44.630087: train Epoch: [17][ 22/193]	Time  1.215 ( 1.491)	Data  0.001 ( 0.368)	Loss 8.1950e-02 (1.0224e-01) 
2023-05-25 01:36:46.333535: train Epoch: [17][ 23/193]	Time  1.703 ( 1.500)	Data  0.516 ( 0.374)	Loss 1.4736e-01 (1.0412e-01) 
2023-05-25 01:36:47.638846: train Epoch: [17][ 24/193]	Time  1.305 ( 1.492)	Data  0.001 ( 0.359)	Loss 9.9920e-02 (1.0395e-01) 
2023-05-25 01:36:48.871874: train Epoch: [17][ 25/193]	Time  1.233 ( 1.482)	Data  0.186 ( 0.352)	Loss 1.2283e-01 (1.0468e-01) 
2023-05-25 01:36:50.116718: train Epoch: [17][ 26/193]	Time  1.245 ( 1.473)	Data  0.195 ( 0.347)	Loss 7.7700e-02 (1.0368e-01) 
2023-05-25 01:36:51.796046: train Epoch: [17][ 27/193]	Time  1.679 ( 1.481)	Data  0.523 ( 0.353)	Loss 1.2195e-01 (1.0433e-01) 
2023-05-25 01:36:52.975174: train Epoch: [17][ 28/193]	Time  1.179 ( 1.470)	Data  0.001 ( 0.341)	Loss 1.5101e-01 (1.0594e-01) 
2023-05-25 01:36:54.677482: train Epoch: [17][ 29/193]	Time  1.702 ( 1.478)	Data  0.514 ( 0.347)	Loss 7.0425e-02 (1.0476e-01) 
2023-05-25 01:36:55.657511: train Epoch: [17][ 30/193]	Time  0.980 ( 1.462)	Data  0.001 ( 0.335)	Loss 1.6756e-01 (1.0678e-01) 
2023-05-25 01:36:57.452694: train Epoch: [17][ 31/193]	Time  1.795 ( 1.472)	Data  0.592 ( 0.343)	Loss 9.8447e-02 (1.0652e-01) 
2023-05-25 01:36:58.562855: train Epoch: [17][ 32/193]	Time  1.110 ( 1.461)	Data  0.001 ( 0.333)	Loss 1.0514e-01 (1.0648e-01) 
2023-05-25 01:37:00.332549: train Epoch: [17][ 33/193]	Time  1.770 ( 1.470)	Data  0.479 ( 0.337)	Loss 1.0159e-01 (1.0634e-01) 
2023-05-25 01:37:01.320412: train Epoch: [17][ 34/193]	Time  0.988 ( 1.457)	Data  0.001 ( 0.328)	Loss 1.0111e-01 (1.0619e-01) 
2023-05-25 01:37:03.134339: train Epoch: [17][ 35/193]	Time  1.814 ( 1.467)	Data  0.592 ( 0.335)	Loss 8.6252e-02 (1.0563e-01) 
2023-05-25 01:37:04.129170: train Epoch: [17][ 36/193]	Time  0.995 ( 1.454)	Data  0.001 ( 0.326)	Loss 1.2606e-01 (1.0619e-01) 
2023-05-25 01:37:05.794498: train Epoch: [17][ 37/193]	Time  1.665 ( 1.459)	Data  0.573 ( 0.333)	Loss 1.4802e-01 (1.0729e-01) 
2023-05-25 01:37:06.911453: train Epoch: [17][ 38/193]	Time  1.117 ( 1.451)	Data  0.017 ( 0.325)	Loss 2.2128e-01 (1.1021e-01) 
2023-05-25 01:37:08.657387: train Epoch: [17][ 39/193]	Time  1.746 ( 1.458)	Data  0.598 ( 0.331)	Loss 5.5691e-02 (1.0885e-01) 
2023-05-25 01:37:09.863032: train Epoch: [17][ 40/193]	Time  1.206 ( 1.452)	Data  0.001 ( 0.323)	Loss 5.6517e-02 (1.0757e-01) 
2023-05-25 01:37:11.330009: train Epoch: [17][ 41/193]	Time  1.467 ( 1.452)	Data  0.472 ( 0.327)	Loss 8.6272e-02 (1.0706e-01) 
2023-05-25 01:37:12.481962: train Epoch: [17][ 42/193]	Time  1.152 ( 1.445)	Data  0.001 ( 0.319)	Loss 1.2121e-01 (1.0739e-01) 
2023-05-25 01:37:14.202756: train Epoch: [17][ 43/193]	Time  1.721 ( 1.452)	Data  0.682 ( 0.328)	Loss 1.5145e-01 (1.0839e-01) 
2023-05-25 01:37:15.332477: train Epoch: [17][ 44/193]	Time  1.130 ( 1.444)	Data  0.145 ( 0.323)	Loss 1.0978e-01 (1.0842e-01) 
2023-05-25 01:37:16.977260: train Epoch: [17][ 45/193]	Time  1.645 ( 1.449)	Data  0.646 ( 0.330)	Loss 5.3428e-02 (1.0723e-01) 
2023-05-25 01:37:18.153125: train Epoch: [17][ 46/193]	Time  1.176 ( 1.443)	Data  0.158 ( 0.327)	Loss 6.7721e-02 (1.0639e-01) 
2023-05-25 01:37:19.986008: train Epoch: [17][ 47/193]	Time  1.833 ( 1.451)	Data  0.625 ( 0.333)	Loss 8.6640e-02 (1.0598e-01) 
2023-05-25 01:37:21.017371: train Epoch: [17][ 48/193]	Time  1.031 ( 1.442)	Data  0.001 ( 0.326)	Loss 7.0881e-02 (1.0526e-01) 
2023-05-25 01:37:22.730474: train Epoch: [17][ 49/193]	Time  1.713 ( 1.448)	Data  0.511 ( 0.330)	Loss 9.5746e-02 (1.0507e-01) 
2023-05-25 01:37:23.706399: train Epoch: [17][ 50/193]	Time  0.976 ( 1.439)	Data  0.001 ( 0.323)	Loss 9.7108e-02 (1.0491e-01) 
2023-05-25 01:37:25.259052: train Epoch: [17][ 51/193]	Time  1.553 ( 1.441)	Data  0.567 ( 0.328)	Loss 8.1023e-02 (1.0446e-01) 
2023-05-25 01:37:26.401153: train Epoch: [17][ 52/193]	Time  1.142 ( 1.435)	Data  0.146 ( 0.325)	Loss 1.2088e-01 (1.0477e-01) 
2023-05-25 01:37:28.431834: train Epoch: [17][ 53/193]	Time  2.031 ( 1.446)	Data  0.689 ( 0.331)	Loss 9.4309e-02 (1.0457e-01) 
2023-05-25 01:37:29.381369: train Epoch: [17][ 54/193]	Time  0.950 ( 1.437)	Data  0.001 ( 0.325)	Loss 1.1947e-01 (1.0484e-01) 
2023-05-25 01:37:31.255281: train Epoch: [17][ 55/193]	Time  1.874 ( 1.445)	Data  0.511 ( 0.329)	Loss 1.1247e-01 (1.0498e-01) 
2023-05-25 01:37:32.340808: train Epoch: [17][ 56/193]	Time  1.086 ( 1.439)	Data  0.001 ( 0.323)	Loss 6.3023e-02 (1.0424e-01) 
2023-05-25 01:37:33.814984: train Epoch: [17][ 57/193]	Time  1.474 ( 1.439)	Data  0.442 ( 0.325)	Loss 9.9797e-02 (1.0417e-01) 
2023-05-25 01:37:34.922187: train Epoch: [17][ 58/193]	Time  1.107 ( 1.434)	Data  0.001 ( 0.320)	Loss 9.4136e-02 (1.0400e-01) 
2023-05-25 01:37:36.749439: train Epoch: [17][ 59/193]	Time  1.827 ( 1.440)	Data  0.721 ( 0.326)	Loss 1.4232e-01 (1.0463e-01) 
2023-05-25 01:37:37.944738: train Epoch: [17][ 60/193]	Time  1.195 ( 1.436)	Data  0.001 ( 0.321)	Loss 6.4670e-02 (1.0398e-01) 
2023-05-25 01:37:39.478338: train Epoch: [17][ 61/193]	Time  1.534 ( 1.438)	Data  0.469 ( 0.323)	Loss 8.5409e-02 (1.0368e-01) 
2023-05-25 01:37:40.977462: train Epoch: [17][ 62/193]	Time  1.499 ( 1.439)	Data  0.052 ( 0.319)	Loss 1.1784e-01 (1.0390e-01) 
2023-05-25 01:37:42.192179: train Epoch: [17][ 63/193]	Time  1.215 ( 1.435)	Data  0.188 ( 0.317)	Loss 1.1302e-01 (1.0405e-01) 
2023-05-25 01:37:43.464397: train Epoch: [17][ 64/193]	Time  1.272 ( 1.433)	Data  0.131 ( 0.314)	Loss 1.1818e-01 (1.0426e-01) 
2023-05-25 01:37:45.077193: train Epoch: [17][ 65/193]	Time  1.613 ( 1.435)	Data  0.449 ( 0.316)	Loss 1.6947e-01 (1.0525e-01) 
2023-05-25 01:37:46.215112: train Epoch: [17][ 66/193]	Time  1.138 ( 1.431)	Data  0.065 ( 0.312)	Loss 7.6978e-02 (1.0483e-01) 
2023-05-25 01:37:47.635464: train Epoch: [17][ 67/193]	Time  1.420 ( 1.431)	Data  0.492 ( 0.315)	Loss 9.8972e-02 (1.0474e-01) 
2023-05-25 01:37:48.937433: train Epoch: [17][ 68/193]	Time  1.302 ( 1.429)	Data  0.268 ( 0.314)	Loss 5.0976e-02 (1.0397e-01) 
2023-05-25 01:37:50.651216: train Epoch: [17][ 69/193]	Time  1.714 ( 1.433)	Data  0.529 ( 0.317)	Loss 7.4249e-02 (1.0354e-01) 
2023-05-25 01:37:51.673230: train Epoch: [17][ 70/193]	Time  1.022 ( 1.427)	Data  0.046 ( 0.314)	Loss 7.7994e-02 (1.0318e-01) 
2023-05-25 01:37:53.637487: train Epoch: [17][ 71/193]	Time  1.964 ( 1.435)	Data  0.635 ( 0.318)	Loss 1.2378e-01 (1.0347e-01) 
2023-05-25 01:37:54.598341: train Epoch: [17][ 72/193]	Time  0.961 ( 1.428)	Data  0.001 ( 0.314)	Loss 1.1096e-01 (1.0357e-01) 
2023-05-25 01:37:56.345857: train Epoch: [17][ 73/193]	Time  1.748 ( 1.433)	Data  0.495 ( 0.316)	Loss 1.1655e-01 (1.0375e-01) 
2023-05-25 01:37:57.318846: train Epoch: [17][ 74/193]	Time  0.973 ( 1.426)	Data  0.001 ( 0.312)	Loss 1.4222e-01 (1.0426e-01) 
2023-05-25 01:37:59.152349: train Epoch: [17][ 75/193]	Time  1.834 ( 1.432)	Data  0.530 ( 0.315)	Loss 2.8722e-01 (1.0667e-01) 
2023-05-25 01:38:00.131698: train Epoch: [17][ 76/193]	Time  0.979 ( 1.426)	Data  0.001 ( 0.311)	Loss 7.5381e-02 (1.0626e-01) 
2023-05-25 01:38:02.019836: train Epoch: [17][ 77/193]	Time  1.888 ( 1.432)	Data  0.555 ( 0.314)	Loss 1.0334e-01 (1.0622e-01) 
2023-05-25 01:38:03.037589: train Epoch: [17][ 78/193]	Time  1.018 ( 1.427)	Data  0.001 ( 0.310)	Loss 1.6367e-01 (1.0695e-01) 
2023-05-25 01:38:04.635282: train Epoch: [17][ 79/193]	Time  1.598 ( 1.429)	Data  0.487 ( 0.312)	Loss 1.2329e-01 (1.0715e-01) 
2023-05-25 01:38:05.598172: train Epoch: [17][ 80/193]	Time  0.963 ( 1.423)	Data  0.001 ( 0.308)	Loss 9.3072e-02 (1.0698e-01) 
2023-05-25 01:38:07.589026: train Epoch: [17][ 81/193]	Time  1.991 ( 1.430)	Data  0.844 ( 0.315)	Loss 1.5922e-01 (1.0762e-01) 
2023-05-25 01:38:08.638888: train Epoch: [17][ 82/193]	Time  1.050 ( 1.425)	Data  0.001 ( 0.311)	Loss 8.5454e-02 (1.0735e-01) 
2023-05-25 01:38:10.405434: train Epoch: [17][ 83/193]	Time  1.767 ( 1.429)	Data  0.545 ( 0.314)	Loss 8.6754e-02 (1.0710e-01) 
2023-05-25 01:38:11.594222: train Epoch: [17][ 84/193]	Time  1.189 ( 1.427)	Data  0.001 ( 0.310)	Loss 1.8601e-01 (1.0803e-01) 
2023-05-25 01:38:13.070335: train Epoch: [17][ 85/193]	Time  1.476 ( 1.427)	Data  0.441 ( 0.312)	Loss 1.1612e-01 (1.0813e-01) 
2023-05-25 01:38:14.218552: train Epoch: [17][ 86/193]	Time  1.148 ( 1.424)	Data  0.001 ( 0.308)	Loss 1.0195e-01 (1.0806e-01) 
2023-05-25 01:38:16.072124: train Epoch: [17][ 87/193]	Time  1.854 ( 1.429)	Data  0.788 ( 0.314)	Loss 7.5617e-02 (1.0769e-01) 
2023-05-25 01:38:17.236261: train Epoch: [17][ 88/193]	Time  1.164 ( 1.426)	Data  0.001 ( 0.310)	Loss 9.8686e-02 (1.0759e-01) 
2023-05-25 01:38:19.102702: train Epoch: [17][ 89/193]	Time  1.866 ( 1.431)	Data  0.649 ( 0.314)	Loss 8.6417e-02 (1.0735e-01) 
2023-05-25 01:38:20.348974: train Epoch: [17][ 90/193]	Time  1.246 ( 1.429)	Data  0.001 ( 0.310)	Loss 9.3176e-02 (1.0719e-01) 
2023-05-25 01:38:21.872536: train Epoch: [17][ 91/193]	Time  1.524 ( 1.430)	Data  0.358 ( 0.311)	Loss 8.6720e-02 (1.0697e-01) 
2023-05-25 01:38:23.004620: train Epoch: [17][ 92/193]	Time  1.132 ( 1.427)	Data  0.001 ( 0.308)	Loss 7.0962e-02 (1.0659e-01) 
2023-05-25 01:38:24.478225: train Epoch: [17][ 93/193]	Time  1.474 ( 1.427)	Data  0.455 ( 0.309)	Loss 6.0892e-02 (1.0610e-01) 
2023-05-25 01:38:25.502994: train Epoch: [17][ 94/193]	Time  1.025 ( 1.423)	Data  0.001 ( 0.306)	Loss 1.0314e-01 (1.0607e-01) 
2023-05-25 01:38:27.229466: train Epoch: [17][ 95/193]	Time  1.726 ( 1.426)	Data  0.771 ( 0.311)	Loss 1.4197e-01 (1.0644e-01) 
2023-05-25 01:38:28.212236: train Epoch: [17][ 96/193]	Time  0.983 ( 1.421)	Data  0.001 ( 0.308)	Loss 7.0961e-02 (1.0608e-01) 
2023-05-25 01:38:30.368443: train Epoch: [17][ 97/193]	Time  2.156 ( 1.429)	Data  0.941 ( 0.314)	Loss 1.5125e-01 (1.0654e-01) 
2023-05-25 01:38:31.372629: train Epoch: [17][ 98/193]	Time  1.004 ( 1.425)	Data  0.001 ( 0.311)	Loss 7.5380e-02 (1.0622e-01) 
2023-05-25 01:38:33.268636: train Epoch: [17][ 99/193]	Time  1.896 ( 1.429)	Data  0.656 ( 0.314)	Loss 1.1457e-01 (1.0631e-01) 
2023-05-25 01:38:34.254935: train Epoch: [17][100/193]	Time  0.986 ( 1.425)	Data  0.001 ( 0.311)	Loss 1.5223e-01 (1.0676e-01) 
2023-05-25 01:38:36.054631: train Epoch: [17][101/193]	Time  1.800 ( 1.429)	Data  0.624 ( 0.314)	Loss 1.3853e-01 (1.0707e-01) 
2023-05-25 01:38:37.023230: train Epoch: [17][102/193]	Time  0.969 ( 1.424)	Data  0.001 ( 0.311)	Loss 8.1293e-02 (1.0682e-01) 
2023-05-25 01:38:38.603810: train Epoch: [17][103/193]	Time  1.581 ( 1.426)	Data  0.595 ( 0.314)	Loss 7.4109e-02 (1.0651e-01) 
2023-05-25 01:38:39.636970: train Epoch: [17][104/193]	Time  1.033 ( 1.422)	Data  0.001 ( 0.311)	Loss 5.9853e-02 (1.0606e-01) 
2023-05-25 01:38:41.651539: train Epoch: [17][105/193]	Time  2.015 ( 1.428)	Data  0.862 ( 0.316)	Loss 1.5180e-01 (1.0649e-01) 
2023-05-25 01:38:42.658103: train Epoch: [17][106/193]	Time  1.007 ( 1.424)	Data  0.001 ( 0.313)	Loss 1.5444e-01 (1.0694e-01) 
2023-05-25 01:38:44.341020: train Epoch: [17][107/193]	Time  1.683 ( 1.426)	Data  0.632 ( 0.316)	Loss 1.0566e-01 (1.0693e-01) 
2023-05-25 01:38:45.399152: train Epoch: [17][108/193]	Time  1.058 ( 1.423)	Data  0.001 ( 0.313)	Loss 1.2015e-01 (1.0705e-01) 
2023-05-25 01:38:47.516247: train Epoch: [17][109/193]	Time  2.117 ( 1.429)	Data  0.809 ( 0.318)	Loss 1.4360e-01 (1.0738e-01) 
2023-05-25 01:38:48.564723: train Epoch: [17][110/193]	Time  1.048 ( 1.425)	Data  0.001 ( 0.315)	Loss 8.3148e-02 (1.0717e-01) 
2023-05-25 01:38:50.071484: train Epoch: [17][111/193]	Time  1.507 ( 1.426)	Data  0.487 ( 0.317)	Loss 9.3744e-02 (1.0705e-01) 
2023-05-25 01:38:51.194724: train Epoch: [17][112/193]	Time  1.123 ( 1.424)	Data  0.001 ( 0.314)	Loss 8.4689e-02 (1.0685e-01) 
2023-05-25 01:38:53.038277: train Epoch: [17][113/193]	Time  1.844 ( 1.427)	Data  0.700 ( 0.317)	Loss 1.1993e-01 (1.0696e-01) 
2023-05-25 01:38:54.246494: train Epoch: [17][114/193]	Time  1.208 ( 1.425)	Data  0.001 ( 0.314)	Loss 1.3371e-01 (1.0720e-01) 
2023-05-25 01:38:55.920244: train Epoch: [17][115/193]	Time  1.674 ( 1.427)	Data  0.518 ( 0.316)	Loss 1.0821e-01 (1.0720e-01) 
2023-05-25 01:38:56.909146: train Epoch: [17][116/193]	Time  0.989 ( 1.424)	Data  0.002 ( 0.313)	Loss 7.8889e-02 (1.0696e-01) 
2023-05-25 01:38:58.586875: train Epoch: [17][117/193]	Time  1.678 ( 1.426)	Data  0.677 ( 0.317)	Loss 4.7792e-02 (1.0646e-01) 
2023-05-25 01:38:59.635345: train Epoch: [17][118/193]	Time  1.048 ( 1.423)	Data  0.001 ( 0.314)	Loss 8.1355e-02 (1.0625e-01) 
2023-05-25 01:39:03.361898: train Epoch: [17][119/193]	Time  3.727 ( 1.442)	Data  0.755 ( 0.318)	Loss 8.9895e-02 (1.0611e-01) 
2023-05-25 01:39:04.609144: train Epoch: [17][120/193]	Time  1.247 ( 1.440)	Data  0.001 ( 0.315)	Loss 1.4492e-01 (1.0643e-01) 
2023-05-25 01:39:06.011018: train Epoch: [17][121/193]	Time  1.402 ( 1.440)	Data  0.381 ( 0.316)	Loss 5.7750e-02 (1.0603e-01) 
2023-05-25 01:39:07.249271: train Epoch: [17][122/193]	Time  1.238 ( 1.438)	Data  0.001 ( 0.313)	Loss 2.3758e-01 (1.0710e-01) 
2023-05-25 01:39:08.856912: train Epoch: [17][123/193]	Time  1.608 ( 1.440)	Data  0.444 ( 0.314)	Loss 8.3517e-02 (1.0691e-01) 
2023-05-25 01:39:10.047348: train Epoch: [17][124/193]	Time  1.190 ( 1.438)	Data  0.001 ( 0.311)	Loss 1.5840e-01 (1.0733e-01) 
2023-05-25 01:39:11.471766: train Epoch: [17][125/193]	Time  1.424 ( 1.438)	Data  0.442 ( 0.313)	Loss 1.0099e-01 (1.0728e-01) 
2023-05-25 01:39:12.478977: train Epoch: [17][126/193]	Time  1.007 ( 1.434)	Data  0.001 ( 0.310)	Loss 9.1010e-02 (1.0715e-01) 
2023-05-25 01:39:14.382449: train Epoch: [17][127/193]	Time  1.903 ( 1.438)	Data  0.622 ( 0.313)	Loss 7.2283e-02 (1.0688e-01) 
2023-05-25 01:39:15.377634: train Epoch: [17][128/193]	Time  0.995 ( 1.434)	Data  0.001 ( 0.310)	Loss 1.2336e-01 (1.0700e-01) 
2023-05-25 01:39:17.169554: train Epoch: [17][129/193]	Time  1.792 ( 1.437)	Data  0.476 ( 0.311)	Loss 7.8477e-02 (1.0678e-01) 
2023-05-25 01:39:18.191608: train Epoch: [17][130/193]	Time  1.022 ( 1.434)	Data  0.001 ( 0.309)	Loss 1.8658e-01 (1.0739e-01) 
2023-05-25 01:39:19.603760: train Epoch: [17][131/193]	Time  1.412 ( 1.434)	Data  0.378 ( 0.310)	Loss 6.1863e-02 (1.0705e-01) 
2023-05-25 01:39:20.561747: train Epoch: [17][132/193]	Time  0.958 ( 1.430)	Data  0.001 ( 0.307)	Loss 9.5927e-02 (1.0696e-01) 
2023-05-25 01:39:22.597833: train Epoch: [17][133/193]	Time  2.036 ( 1.435)	Data  0.930 ( 0.312)	Loss 1.2093e-01 (1.0707e-01) 
2023-05-25 01:39:23.746087: train Epoch: [17][134/193]	Time  1.148 ( 1.433)	Data  0.001 ( 0.310)	Loss 1.5859e-01 (1.0745e-01) 
2023-05-25 01:39:25.504697: train Epoch: [17][135/193]	Time  1.759 ( 1.435)	Data  0.549 ( 0.311)	Loss 2.0547e-01 (1.0817e-01) 
2023-05-25 01:39:26.781705: train Epoch: [17][136/193]	Time  1.277 ( 1.434)	Data  0.001 ( 0.309)	Loss 1.0424e-01 (1.0814e-01) 
2023-05-25 01:39:28.084840: train Epoch: [17][137/193]	Time  1.303 ( 1.433)	Data  0.315 ( 0.309)	Loss 1.8230e-01 (1.0868e-01) 
2023-05-25 01:39:29.198144: train Epoch: [17][138/193]	Time  1.113 ( 1.431)	Data  0.001 ( 0.307)	Loss 1.2591e-01 (1.0880e-01) 
2023-05-25 01:39:31.001902: train Epoch: [17][139/193]	Time  1.804 ( 1.433)	Data  0.653 ( 0.309)	Loss 5.7484e-02 (1.0844e-01) 
2023-05-25 01:39:32.144320: train Epoch: [17][140/193]	Time  1.142 ( 1.431)	Data  0.001 ( 0.307)	Loss 1.2983e-01 (1.0859e-01) 
2023-05-25 01:39:33.546134: train Epoch: [17][141/193]	Time  1.402 ( 1.431)	Data  0.352 ( 0.307)	Loss 9.1544e-02 (1.0847e-01) 
2023-05-25 01:39:34.657802: train Epoch: [17][142/193]	Time  1.112 ( 1.429)	Data  0.001 ( 0.305)	Loss 6.3657e-02 (1.0816e-01) 
2023-05-25 01:39:36.345662: train Epoch: [17][143/193]	Time  1.688 ( 1.431)	Data  0.586 ( 0.307)	Loss 1.3494e-01 (1.0834e-01) 
2023-05-25 01:39:37.323796: train Epoch: [17][144/193]	Time  0.978 ( 1.427)	Data  0.001 ( 0.305)	Loss 1.6669e-01 (1.0874e-01) 
2023-05-25 01:39:39.301813: train Epoch: [17][145/193]	Time  1.978 ( 1.431)	Data  0.772 ( 0.308)	Loss 1.0708e-01 (1.0873e-01) 
2023-05-25 01:39:40.295024: train Epoch: [17][146/193]	Time  0.993 ( 1.428)	Data  0.001 ( 0.306)	Loss 9.3511e-02 (1.0863e-01) 
2023-05-25 01:39:42.253004: train Epoch: [17][147/193]	Time  1.958 ( 1.432)	Data  0.676 ( 0.309)	Loss 1.0355e-01 (1.0859e-01) 
2023-05-25 01:39:43.260108: train Epoch: [17][148/193]	Time  1.007 ( 1.429)	Data  0.001 ( 0.307)	Loss 2.1560e-01 (1.0931e-01) 
2023-05-25 01:39:44.852623: train Epoch: [17][149/193]	Time  1.593 ( 1.430)	Data  0.530 ( 0.308)	Loss 8.2967e-02 (1.0914e-01) 
2023-05-25 01:39:45.884655: train Epoch: [17][150/193]	Time  1.032 ( 1.427)	Data  0.001 ( 0.306)	Loss 6.5678e-02 (1.0885e-01) 
2023-05-25 01:39:47.623471: train Epoch: [17][151/193]	Time  1.739 ( 1.430)	Data  0.670 ( 0.309)	Loss 1.0979e-01 (1.0886e-01) 
2023-05-25 01:39:48.656051: train Epoch: [17][152/193]	Time  1.033 ( 1.427)	Data  0.002 ( 0.307)	Loss 2.7490e-01 (1.0994e-01) 
2023-05-25 01:39:50.546529: train Epoch: [17][153/193]	Time  1.890 ( 1.430)	Data  0.752 ( 0.309)	Loss 1.7530e-01 (1.1036e-01) 
2023-05-25 01:39:51.635741: train Epoch: [17][154/193]	Time  1.089 ( 1.428)	Data  0.001 ( 0.307)	Loss 7.8462e-02 (1.1016e-01) 
2023-05-25 01:39:53.508192: train Epoch: [17][155/193]	Time  1.872 ( 1.431)	Data  0.746 ( 0.310)	Loss 1.1305e-01 (1.1018e-01) 
2023-05-25 01:39:54.622171: train Epoch: [17][156/193]	Time  1.114 ( 1.429)	Data  0.001 ( 0.308)	Loss 8.5825e-02 (1.1002e-01) 
2023-05-25 01:39:56.184860: train Epoch: [17][157/193]	Time  1.563 ( 1.429)	Data  0.523 ( 0.310)	Loss 5.9033e-02 (1.0970e-01) 
2023-05-25 01:39:57.361009: train Epoch: [17][158/193]	Time  1.176 ( 1.428)	Data  0.001 ( 0.308)	Loss 7.2874e-02 (1.0947e-01) 
2023-05-25 01:39:59.094483: train Epoch: [17][159/193]	Time  1.733 ( 1.430)	Data  0.633 ( 0.310)	Loss 8.1088e-02 (1.0929e-01) 
2023-05-25 01:40:00.307053: train Epoch: [17][160/193]	Time  1.213 ( 1.428)	Data  0.001 ( 0.308)	Loss 1.6786e-01 (1.0965e-01) 
2023-05-25 01:40:01.824101: train Epoch: [17][161/193]	Time  1.517 ( 1.429)	Data  0.508 ( 0.309)	Loss 8.4081e-02 (1.0950e-01) 
2023-05-25 01:40:02.840749: train Epoch: [17][162/193]	Time  1.017 ( 1.426)	Data  0.001 ( 0.307)	Loss 1.3539e-01 (1.0966e-01) 
2023-05-25 01:40:04.449828: train Epoch: [17][163/193]	Time  1.609 ( 1.428)	Data  0.667 ( 0.309)	Loss 1.3564e-01 (1.0981e-01) 
2023-05-25 01:40:05.415579: train Epoch: [17][164/193]	Time  0.966 ( 1.425)	Data  0.001 ( 0.308)	Loss 7.2086e-02 (1.0959e-01) 
2023-05-25 01:40:07.272771: train Epoch: [17][165/193]	Time  1.857 ( 1.427)	Data  0.913 ( 0.311)	Loss 1.1912e-01 (1.0964e-01) 
2023-05-25 01:40:08.242709: train Epoch: [17][166/193]	Time  0.970 ( 1.425)	Data  0.001 ( 0.309)	Loss 9.7493e-02 (1.0957e-01) 
2023-05-25 01:40:10.116339: train Epoch: [17][167/193]	Time  1.874 ( 1.427)	Data  0.793 ( 0.312)	Loss 8.1290e-02 (1.0940e-01) 
2023-05-25 01:40:11.168524: train Epoch: [17][168/193]	Time  1.052 ( 1.425)	Data  0.001 ( 0.310)	Loss 2.7645e-01 (1.1039e-01) 
2023-05-25 01:40:12.883007: train Epoch: [17][169/193]	Time  1.714 ( 1.427)	Data  0.741 ( 0.313)	Loss 1.1306e-01 (1.1041e-01) 
2023-05-25 01:40:13.954339: train Epoch: [17][170/193]	Time  1.071 ( 1.425)	Data  0.001 ( 0.311)	Loss 1.1558e-01 (1.1044e-01) 
2023-05-25 01:40:15.953211: train Epoch: [17][171/193]	Time  1.999 ( 1.428)	Data  0.751 ( 0.314)	Loss 5.3800e-02 (1.1011e-01) 
2023-05-25 01:40:16.961234: train Epoch: [17][172/193]	Time  1.008 ( 1.426)	Data  0.001 ( 0.312)	Loss 1.5352e-01 (1.1036e-01) 
2023-05-25 01:40:18.810348: train Epoch: [17][173/193]	Time  1.849 ( 1.428)	Data  0.532 ( 0.313)	Loss 1.5050e-01 (1.1059e-01) 
2023-05-25 01:40:19.819486: train Epoch: [17][174/193]	Time  1.009 ( 1.426)	Data  0.001 ( 0.311)	Loss 1.2568e-01 (1.1067e-01) 
2023-05-25 01:40:21.427753: train Epoch: [17][175/193]	Time  1.608 ( 1.427)	Data  0.493 ( 0.312)	Loss 7.8071e-02 (1.1049e-01) 
2023-05-25 01:40:22.448567: train Epoch: [17][176/193]	Time  1.021 ( 1.424)	Data  0.001 ( 0.311)	Loss 1.1799e-01 (1.1053e-01) 
2023-05-25 01:40:24.283103: train Epoch: [17][177/193]	Time  1.835 ( 1.427)	Data  0.680 ( 0.313)	Loss 9.0107e-02 (1.1042e-01) 
2023-05-25 01:40:25.349257: train Epoch: [17][178/193]	Time  1.066 ( 1.425)	Data  0.001 ( 0.311)	Loss 7.9714e-02 (1.1025e-01) 
2023-05-25 01:40:27.031592: train Epoch: [17][179/193]	Time  1.682 ( 1.426)	Data  0.538 ( 0.312)	Loss 9.8695e-02 (1.1018e-01) 
2023-05-25 01:40:28.067771: train Epoch: [17][180/193]	Time  1.036 ( 1.424)	Data  0.001 ( 0.310)	Loss 1.7407e-01 (1.1053e-01) 
2023-05-25 01:40:29.912127: train Epoch: [17][181/193]	Time  1.844 ( 1.426)	Data  0.661 ( 0.312)	Loss 1.4936e-01 (1.1075e-01) 
2023-05-25 01:40:30.970779: train Epoch: [17][182/193]	Time  1.059 ( 1.424)	Data  0.001 ( 0.311)	Loss 1.0774e-01 (1.1073e-01) 
2023-05-25 01:40:32.795616: train Epoch: [17][183/193]	Time  1.825 ( 1.426)	Data  0.768 ( 0.313)	Loss 1.4303e-01 (1.1091e-01) 
2023-05-25 01:40:33.741680: train Epoch: [17][184/193]	Time  0.946 ( 1.424)	Data  0.001 ( 0.311)	Loss 3.1439e-01 (1.1201e-01) 
2023-05-25 01:40:35.645393: train Epoch: [17][185/193]	Time  1.904 ( 1.426)	Data  0.837 ( 0.314)	Loss 1.8727e-01 (1.1241e-01) 
2023-05-25 01:40:36.751750: train Epoch: [17][186/193]	Time  1.106 ( 1.425)	Data  0.001 ( 0.313)	Loss 1.6080e-01 (1.1267e-01) 
2023-05-25 01:40:38.414799: train Epoch: [17][187/193]	Time  1.663 ( 1.426)	Data  0.585 ( 0.314)	Loss 1.0034e-01 (1.1260e-01) 
2023-05-25 01:40:39.729536: train Epoch: [17][188/193]	Time  1.315 ( 1.425)	Data  0.001 ( 0.312)	Loss 1.4913e-01 (1.1280e-01) 
2023-05-25 01:40:41.418085: train Epoch: [17][189/193]	Time  1.689 ( 1.427)	Data  0.419 ( 0.313)	Loss 8.0929e-02 (1.1263e-01) 
2023-05-25 01:40:42.649773: train Epoch: [17][190/193]	Time  1.232 ( 1.426)	Data  0.001 ( 0.311)	Loss 1.2220e-01 (1.1268e-01) 
2023-05-25 01:40:43.808556: train Epoch: [17][191/193]	Time  1.159 ( 1.424)	Data  0.045 ( 0.310)	Loss 1.3864e-01 (1.1282e-01) 
2023-05-25 01:40:44.784122: train Epoch: [17][192/193]	Time  0.976 ( 1.422)	Data  0.001 ( 0.308)	Loss 2.2822e-01 (1.1341e-01) 
2023-05-25 01:40:44.846990: Train Epoch done in 274.5124166990863 s 
2023-05-25 01:40:48.012020: val Epoch: [17][ 0/72]	Time  2.168 ( 2.168)	Data  1.847 ( 1.847)	Loss 6.7877e-02 (6.7877e-02) 
2023-05-25 01:40:48.530834: val Epoch: [17][ 1/72]	Time  0.519 ( 1.344)	Data  0.002 ( 0.925)	Loss 6.6498e-02 (6.7187e-02) 
2023-05-25 01:40:49.529514: val Epoch: [17][ 2/72]	Time  0.999 ( 1.229)	Data  0.611 ( 0.820)	Loss 9.1470e-02 (7.5282e-02) 
2023-05-25 01:40:49.942902: val Epoch: [17][ 3/72]	Time  0.413 ( 1.025)	Data  0.001 ( 0.616)	Loss 1.1104e-01 (8.4221e-02) 
2023-05-25 01:40:50.964525: val Epoch: [17][ 4/72]	Time  1.022 ( 1.024)	Data  0.709 ( 0.634)	Loss 1.1532e-01 (9.0441e-02) 
2023-05-25 01:40:51.326956: val Epoch: [17][ 5/72]	Time  0.362 ( 0.914)	Data  0.001 ( 0.529)	Loss 6.3180e-02 (8.5897e-02) 
2023-05-25 01:40:52.282911: val Epoch: [17][ 6/72]	Time  0.956 ( 0.920)	Data  0.754 ( 0.561)	Loss 1.4556e-01 (9.4421e-02) 
2023-05-25 01:40:52.586344: val Epoch: [17][ 7/72]	Time  0.303 ( 0.843)	Data  0.001 ( 0.491)	Loss 4.9441e-02 (8.8798e-02) 
2023-05-25 01:40:53.961510: val Epoch: [17][ 8/72]	Time  1.375 ( 0.902)	Data  0.969 ( 0.544)	Loss 2.1076e-01 (1.0235e-01) 
2023-05-25 01:40:54.284918: val Epoch: [17][ 9/72]	Time  0.323 ( 0.844)	Data  0.001 ( 0.490)	Loss 1.8676e-01 (1.1079e-01) 
2023-05-25 01:40:55.241361: val Epoch: [17][10/72]	Time  0.956 ( 0.854)	Data  0.712 ( 0.510)	Loss 8.5844e-02 (1.0852e-01) 
2023-05-25 01:40:55.637291: val Epoch: [17][11/72]	Time  0.396 ( 0.816)	Data  0.001 ( 0.467)	Loss 1.0063e-01 (1.0787e-01) 
2023-05-25 01:40:56.855312: val Epoch: [17][12/72]	Time  1.218 ( 0.847)	Data  0.848 ( 0.497)	Loss 3.5915e-01 (1.2720e-01) 
2023-05-25 01:40:57.290734: val Epoch: [17][13/72]	Time  0.435 ( 0.818)	Data  0.001 ( 0.461)	Loss 4.9992e-01 (1.5382e-01) 
2023-05-25 01:40:58.353715: val Epoch: [17][14/72]	Time  1.063 ( 0.834)	Data  0.663 ( 0.475)	Loss 1.0338e-01 (1.5046e-01) 
2023-05-25 01:40:58.577341: val Epoch: [17][15/72]	Time  0.224 ( 0.796)	Data  0.001 ( 0.445)	Loss 1.0776e-01 (1.4779e-01) 
2023-05-25 01:40:59.622111: val Epoch: [17][16/72]	Time  1.045 ( 0.810)	Data  0.799 ( 0.466)	Loss 7.0843e-02 (1.4326e-01) 
2023-05-25 01:40:59.874328: val Epoch: [17][17/72]	Time  0.252 ( 0.779)	Data  0.001 ( 0.440)	Loss 1.0791e-01 (1.4130e-01) 
2023-05-25 01:41:01.491824: val Epoch: [17][18/72]	Time  1.617 ( 0.824)	Data  1.114 ( 0.476)	Loss 1.0150e-01 (1.3920e-01) 
2023-05-25 01:41:01.963098: val Epoch: [17][19/72]	Time  0.471 ( 0.806)	Data  0.001 ( 0.452)	Loss 1.3603e-01 (1.3904e-01) 
2023-05-25 01:41:02.988167: val Epoch: [17][20/72]	Time  1.025 ( 0.816)	Data  0.564 ( 0.457)	Loss 5.0074e-01 (1.5627e-01) 
2023-05-25 01:41:03.340024: val Epoch: [17][21/72]	Time  0.352 ( 0.795)	Data  0.002 ( 0.437)	Loss 1.2505e-01 (1.5485e-01) 
2023-05-25 01:41:04.454831: val Epoch: [17][22/72]	Time  1.115 ( 0.809)	Data  0.714 ( 0.449)	Loss 4.9459e-01 (1.6962e-01) 
2023-05-25 01:41:04.835788: val Epoch: [17][23/72]	Time  0.381 ( 0.791)	Data  0.003 ( 0.430)	Loss 9.7384e-02 (1.6661e-01) 
2023-05-25 01:41:06.053132: val Epoch: [17][24/72]	Time  1.217 ( 0.808)	Data  0.730 ( 0.442)	Loss 3.4204e-01 (1.7363e-01) 
2023-05-25 01:41:06.242176: val Epoch: [17][25/72]	Time  0.189 ( 0.785)	Data  0.001 ( 0.425)	Loss 1.1874e-01 (1.7152e-01) 
2023-05-25 01:41:07.091613: val Epoch: [17][26/72]	Time  0.849 ( 0.787)	Data  0.610 ( 0.432)	Loss 9.3371e-02 (1.6862e-01) 
2023-05-25 01:41:07.562571: val Epoch: [17][27/72]	Time  0.471 ( 0.776)	Data  0.001 ( 0.417)	Loss 7.6817e-02 (1.6534e-01) 
2023-05-25 01:41:08.393208: val Epoch: [17][28/72]	Time  0.831 ( 0.778)	Data  0.577 ( 0.422)	Loss 8.2962e-02 (1.6250e-01) 
2023-05-25 01:41:08.920518: val Epoch: [17][29/72]	Time  0.527 ( 0.769)	Data  0.001 ( 0.408)	Loss 4.4089e-02 (1.5856e-01) 
2023-05-25 01:41:09.720141: val Epoch: [17][30/72]	Time  0.800 ( 0.770)	Data  0.517 ( 0.412)	Loss 6.6711e-02 (1.5559e-01) 
2023-05-25 01:41:10.029924: val Epoch: [17][31/72]	Time  0.310 ( 0.756)	Data  0.001 ( 0.399)	Loss 6.5768e-02 (1.5279e-01) 
2023-05-25 01:41:11.074447: val Epoch: [17][32/72]	Time  1.044 ( 0.765)	Data  0.764 ( 0.410)	Loss 1.2335e-01 (1.5189e-01) 
2023-05-25 01:41:11.410235: val Epoch: [17][33/72]	Time  0.336 ( 0.752)	Data  0.001 ( 0.398)	Loss 2.1082e-01 (1.5363e-01) 
2023-05-25 01:41:12.471640: val Epoch: [17][34/72]	Time  1.061 ( 0.761)	Data  0.744 ( 0.408)	Loss 2.0268e-01 (1.5503e-01) 
2023-05-25 01:41:12.967139: val Epoch: [17][35/72]	Time  0.496 ( 0.753)	Data  0.001 ( 0.396)	Loss 8.8876e-02 (1.5319e-01) 
2023-05-25 01:41:13.669686: val Epoch: [17][36/72]	Time  0.703 ( 0.752)	Data  0.513 ( 0.399)	Loss 1.8803e-01 (1.5413e-01) 
2023-05-25 01:41:13.927260: val Epoch: [17][37/72]	Time  0.258 ( 0.739)	Data  0.001 ( 0.389)	Loss 5.9304e-02 (1.5164e-01) 
2023-05-25 01:41:15.345130: val Epoch: [17][38/72]	Time  1.418 ( 0.756)	Data  0.865 ( 0.401)	Loss 1.8084e-01 (1.5239e-01) 
2023-05-25 01:41:15.901759: val Epoch: [17][39/72]	Time  0.557 ( 0.751)	Data  0.001 ( 0.391)	Loss 3.6479e-01 (1.5770e-01) 
2023-05-25 01:41:16.622386: val Epoch: [17][40/72]	Time  0.721 ( 0.751)	Data  0.168 ( 0.386)	Loss 1.6446e-01 (1.5786e-01) 
2023-05-25 01:41:16.971661: val Epoch: [17][41/72]	Time  0.349 ( 0.741)	Data  0.001 ( 0.377)	Loss 4.2666e-01 (1.6426e-01) 
2023-05-25 01:41:17.510669: val Epoch: [17][42/72]	Time  0.539 ( 0.736)	Data  0.316 ( 0.375)	Loss 5.5680e-02 (1.6174e-01) 
2023-05-25 01:41:17.820316: val Epoch: [17][43/72]	Time  0.310 ( 0.727)	Data  0.099 ( 0.369)	Loss 7.3198e-02 (1.5972e-01) 
2023-05-25 01:41:18.892854: val Epoch: [17][44/72]	Time  1.073 ( 0.734)	Data  0.851 ( 0.380)	Loss 1.4744e-01 (1.5945e-01) 
2023-05-25 01:41:19.233631: val Epoch: [17][45/72]	Time  0.341 ( 0.726)	Data  0.140 ( 0.374)	Loss 1.7581e-01 (1.5981e-01) 
2023-05-25 01:41:20.237542: val Epoch: [17][46/72]	Time  1.004 ( 0.732)	Data  0.788 ( 0.383)	Loss 2.4077e-01 (1.6153e-01) 
2023-05-25 01:41:20.625007: val Epoch: [17][47/72]	Time  0.387 ( 0.725)	Data  0.169 ( 0.379)	Loss 1.7486e-01 (1.6181e-01) 
2023-05-25 01:41:21.553711: val Epoch: [17][48/72]	Time  0.929 ( 0.729)	Data  0.716 ( 0.386)	Loss 5.5239e-02 (1.5963e-01) 
2023-05-25 01:41:21.976352: val Epoch: [17][49/72]	Time  0.423 ( 0.723)	Data  0.209 ( 0.382)	Loss 6.8516e-02 (1.5781e-01) 
2023-05-25 01:41:22.924538: val Epoch: [17][50/72]	Time  0.948 ( 0.727)	Data  0.720 ( 0.389)	Loss 4.8347e-02 (1.5566e-01) 
2023-05-25 01:41:23.388390: val Epoch: [17][51/72]	Time  0.464 ( 0.722)	Data  0.257 ( 0.386)	Loss 4.4665e-01 (1.6126e-01) 
2023-05-25 01:41:24.245874: val Epoch: [17][52/72]	Time  0.857 ( 0.725)	Data  0.640 ( 0.391)	Loss 5.8285e-02 (1.5932e-01) 
2023-05-25 01:41:24.766985: val Epoch: [17][53/72]	Time  0.521 ( 0.721)	Data  0.302 ( 0.389)	Loss 1.6720e-01 (1.5946e-01) 
2023-05-25 01:41:25.555388: val Epoch: [17][54/72]	Time  0.788 ( 0.722)	Data  0.576 ( 0.393)	Loss 9.0430e-02 (1.5821e-01) 
2023-05-25 01:41:26.108230: val Epoch: [17][55/72]	Time  0.553 ( 0.719)	Data  0.354 ( 0.392)	Loss 5.9913e-02 (1.5645e-01) 
2023-05-25 01:41:26.883304: val Epoch: [17][56/72]	Time  0.775 ( 0.720)	Data  0.560 ( 0.395)	Loss 3.7552e-01 (1.6030e-01) 
2023-05-25 01:41:27.543719: val Epoch: [17][57/72]	Time  0.660 ( 0.719)	Data  0.434 ( 0.396)	Loss 8.5793e-02 (1.5901e-01) 
2023-05-25 01:41:28.057281: val Epoch: [17][58/72]	Time  0.514 ( 0.715)	Data  0.332 ( 0.395)	Loss 1.0162e-01 (1.5804e-01) 
2023-05-25 01:41:29.192330: val Epoch: [17][59/72]	Time  1.135 ( 0.722)	Data  0.592 ( 0.398)	Loss 9.4519e-02 (1.5698e-01) 
2023-05-25 01:41:29.699929: val Epoch: [17][60/72]	Time  0.508 ( 0.719)	Data  0.001 ( 0.391)	Loss 4.5491e-01 (1.6186e-01) 
2023-05-25 01:41:30.684310: val Epoch: [17][61/72]	Time  0.984 ( 0.723)	Data  0.436 ( 0.392)	Loss 2.6222e-01 (1.6348e-01) 
2023-05-25 01:41:31.229774: val Epoch: [17][62/72]	Time  0.545 ( 0.720)	Data  0.001 ( 0.386)	Loss 1.3960e-01 (1.6310e-01) 
2023-05-25 01:41:32.060531: val Epoch: [17][63/72]	Time  0.831 ( 0.722)	Data  0.283 ( 0.384)	Loss 3.2559e-01 (1.6564e-01) 
2023-05-25 01:41:32.606374: val Epoch: [17][64/72]	Time  0.546 ( 0.719)	Data  0.001 ( 0.378)	Loss 7.9932e-02 (1.6432e-01) 
2023-05-25 01:41:33.465962: val Epoch: [17][65/72]	Time  0.860 ( 0.722)	Data  0.315 ( 0.377)	Loss 1.0621e-01 (1.6344e-01) 
2023-05-25 01:41:34.009132: val Epoch: [17][66/72]	Time  0.543 ( 0.719)	Data  0.001 ( 0.372)	Loss 1.4658e-01 (1.6319e-01) 
2023-05-25 01:41:34.890212: val Epoch: [17][67/72]	Time  0.881 ( 0.721)	Data  0.333 ( 0.371)	Loss 6.8952e-02 (1.6181e-01) 
2023-05-25 01:41:35.437616: val Epoch: [17][68/72]	Time  0.547 ( 0.719)	Data  0.001 ( 0.366)	Loss 1.4358e-01 (1.6154e-01) 
2023-05-25 01:41:36.239141: val Epoch: [17][69/72]	Time  0.802 ( 0.720)	Data  0.257 ( 0.364)	Loss 2.6944e-01 (1.6308e-01) 
2023-05-25 01:41:36.788346: val Epoch: [17][70/72]	Time  0.549 ( 0.718)	Data  0.001 ( 0.359)	Loss 4.7224e-01 (1.6744e-01) 
2023-05-25 01:41:37.333316: val Epoch: [17][71/72]	Time  0.545 ( 0.715)	Data  0.001 ( 0.354)	Loss 1.1201e-01 (1.6667e-01) 
2023-05-25 01:41:37.524687: Epoch 17 :Val : ['ET : 0.6609773635864258', 'TC : 0.724295437335968', 'WT : 0.8234224319458008'] 
2023-05-25 01:41:37.526006: Epoch 17 :Val : ['ET : 0.6609773635864258', 'TC : 0.724295437335968', 'WT : 0.8234224319458008'] 
2023-05-25 01:41:37.534327: Val epoch done in 52.687337941955775 s 
2023-05-25 01:41:37.541747: Batches per epoch:  193 
2023-05-25 01:41:42.315629: train Epoch: [18][  0/193]	Time  4.773 ( 4.773)	Data  2.786 ( 2.786)	Loss 9.8773e-02 (9.8773e-02) 
2023-05-25 01:41:44.300635: train Epoch: [18][  1/193]	Time  1.985 ( 3.379)	Data  0.001 ( 1.394)	Loss 3.1917e-01 (2.0897e-01) 
2023-05-25 01:41:46.257885: train Epoch: [18][  2/193]	Time  1.957 ( 2.905)	Data  0.001 ( 0.929)	Loss 1.1795e-01 (1.7863e-01) 
2023-05-25 01:41:48.211038: train Epoch: [18][  3/193]	Time  1.953 ( 2.667)	Data  0.001 ( 0.697)	Loss 1.4275e-01 (1.6966e-01) 
2023-05-25 01:41:50.153218: train Epoch: [18][  4/193]	Time  1.942 ( 2.522)	Data  0.001 ( 0.558)	Loss 9.3217e-02 (1.5437e-01) 
2023-05-25 01:41:52.106949: train Epoch: [18][  5/193]	Time  1.954 ( 2.427)	Data  0.001 ( 0.465)	Loss 1.0999e-01 (1.4697e-01) 
2023-05-25 01:41:54.048261: train Epoch: [18][  6/193]	Time  1.941 ( 2.358)	Data  0.001 ( 0.399)	Loss 1.5234e-01 (1.4774e-01) 
2023-05-25 01:41:55.997303: train Epoch: [18][  7/193]	Time  1.949 ( 2.307)	Data  0.001 ( 0.349)	Loss 1.0415e-01 (1.4229e-01) 
2023-05-25 01:41:57.940902: train Epoch: [18][  8/193]	Time  1.944 ( 2.267)	Data  0.001 ( 0.310)	Loss 1.0248e-01 (1.3787e-01) 
2023-05-25 01:41:59.895652: train Epoch: [18][  9/193]	Time  1.955 ( 2.235)	Data  0.001 ( 0.280)	Loss 7.8320e-02 (1.3191e-01) 
2023-05-25 01:42:01.294767: train Epoch: [18][ 10/193]	Time  1.399 ( 2.159)	Data  0.001 ( 0.254)	Loss 1.4626e-01 (1.3322e-01) 
2023-05-25 01:42:02.081723: train Epoch: [18][ 11/193]	Time  0.787 ( 2.045)	Data  0.001 ( 0.233)	Loss 1.3968e-01 (1.3376e-01) 
2023-05-25 01:42:03.974173: train Epoch: [18][ 12/193]	Time  1.892 ( 2.033)	Data  0.001 ( 0.215)	Loss 2.9977e-01 (1.4653e-01) 
2023-05-25 01:42:05.349382: train Epoch: [18][ 13/193]	Time  1.375 ( 1.986)	Data  0.001 ( 0.200)	Loss 9.1128e-02 (1.4257e-01) 
2023-05-25 01:42:06.513826: train Epoch: [18][ 14/193]	Time  1.164 ( 1.931)	Data  0.001 ( 0.187)	Loss 6.5478e-02 (1.3743e-01) 
2023-05-25 01:42:07.670043: train Epoch: [18][ 15/193]	Time  1.156 ( 1.883)	Data  0.001 ( 0.175)	Loss 1.5040e-01 (1.3824e-01) 
2023-05-25 01:42:08.897509: train Epoch: [18][ 16/193]	Time  1.227 ( 1.844)	Data  0.001 ( 0.165)	Loss 9.3285e-02 (1.3560e-01) 
2023-05-25 01:42:10.034817: train Epoch: [18][ 17/193]	Time  1.137 ( 1.805)	Data  0.001 ( 0.156)	Loss 6.0039e-02 (1.3140e-01) 
2023-05-25 01:42:11.021481: train Epoch: [18][ 18/193]	Time  0.987 ( 1.762)	Data  0.002 ( 0.148)	Loss 6.1677e-02 (1.2773e-01) 
2023-05-25 01:42:12.267031: train Epoch: [18][ 19/193]	Time  1.246 ( 1.736)	Data  0.001 ( 0.140)	Loss 1.2657e-01 (1.2767e-01) 
2023-05-25 01:42:13.291196: train Epoch: [18][ 20/193]	Time  1.024 ( 1.702)	Data  0.001 ( 0.134)	Loss 1.4412e-01 (1.2845e-01) 
2023-05-25 01:42:14.363009: train Epoch: [18][ 21/193]	Time  1.072 ( 1.674)	Data  0.001 ( 0.128)	Loss 1.5309e-01 (1.2957e-01) 
2023-05-25 01:42:15.701121: train Epoch: [18][ 22/193]	Time  1.338 ( 1.659)	Data  0.001 ( 0.122)	Loss 1.4156e-01 (1.3010e-01) 
2023-05-25 01:42:16.683145: train Epoch: [18][ 23/193]	Time  0.982 ( 1.631)	Data  0.001 ( 0.117)	Loss 1.3849e-01 (1.3045e-01) 
2023-05-25 01:42:17.674712: train Epoch: [18][ 24/193]	Time  0.992 ( 1.605)	Data  0.002 ( 0.113)	Loss 1.2951e-01 (1.3041e-01) 
2023-05-25 01:42:19.116892: train Epoch: [18][ 25/193]	Time  1.442 ( 1.599)	Data  0.189 ( 0.115)	Loss 7.7185e-02 (1.2836e-01) 
2023-05-25 01:42:20.319040: train Epoch: [18][ 26/193]	Time  1.202 ( 1.584)	Data  0.190 ( 0.118)	Loss 8.4103e-02 (1.2672e-01) 
2023-05-25 01:42:21.937873: train Epoch: [18][ 27/193]	Time  1.619 ( 1.586)	Data  0.404 ( 0.128)	Loss 1.4767e-01 (1.2747e-01) 
2023-05-25 01:42:23.082891: train Epoch: [18][ 28/193]	Time  1.145 ( 1.570)	Data  0.141 ( 0.129)	Loss 1.2862e-01 (1.2751e-01) 
2023-05-25 01:42:24.874639: train Epoch: [18][ 29/193]	Time  1.792 ( 1.578)	Data  0.508 ( 0.141)	Loss 1.0185e-01 (1.2665e-01) 
2023-05-25 01:42:26.014799: train Epoch: [18][ 30/193]	Time  1.140 ( 1.564)	Data  0.111 ( 0.140)	Loss 1.2208e-01 (1.2651e-01) 
2023-05-25 01:42:27.609361: train Epoch: [18][ 31/193]	Time  1.595 ( 1.565)	Data  0.469 ( 0.151)	Loss 1.1979e-01 (1.2630e-01) 
2023-05-25 01:42:28.703417: train Epoch: [18][ 32/193]	Time  1.094 ( 1.550)	Data  0.111 ( 0.150)	Loss 8.6683e-02 (1.2510e-01) 
2023-05-25 01:42:30.604130: train Epoch: [18][ 33/193]	Time  1.901 ( 1.561)	Data  0.676 ( 0.165)	Loss 8.8773e-02 (1.2403e-01) 
2023-05-25 01:42:31.580407: train Epoch: [18][ 34/193]	Time  0.976 ( 1.544)	Data  0.001 ( 0.160)	Loss 1.2266e-01 (1.2399e-01) 
2023-05-25 01:42:33.361001: train Epoch: [18][ 35/193]	Time  1.781 ( 1.551)	Data  0.513 ( 0.170)	Loss 3.3227e-01 (1.2977e-01) 
2023-05-25 01:42:34.541021: train Epoch: [18][ 36/193]	Time  1.180 ( 1.541)	Data  0.001 ( 0.166)	Loss 1.1845e-01 (1.2947e-01) 
2023-05-25 01:42:35.934470: train Epoch: [18][ 37/193]	Time  1.393 ( 1.537)	Data  0.388 ( 0.171)	Loss 1.1842e-01 (1.2918e-01) 
2023-05-25 01:42:36.988567: train Epoch: [18][ 38/193]	Time  1.054 ( 1.524)	Data  0.147 ( 0.171)	Loss 4.9001e-02 (1.2712e-01) 
2023-05-25 01:42:38.722492: train Epoch: [18][ 39/193]	Time  1.734 ( 1.530)	Data  0.744 ( 0.185)	Loss 7.6847e-02 (1.2586e-01) 
2023-05-25 01:42:39.844449: train Epoch: [18][ 40/193]	Time  1.122 ( 1.520)	Data  0.151 ( 0.184)	Loss 1.2401e-01 (1.2582e-01) 
2023-05-25 01:42:41.470112: train Epoch: [18][ 41/193]	Time  1.626 ( 1.522)	Data  0.672 ( 0.196)	Loss 1.9730e-01 (1.2752e-01) 
2023-05-25 01:42:42.597482: train Epoch: [18][ 42/193]	Time  1.127 ( 1.513)	Data  0.155 ( 0.195)	Loss 1.9336e-01 (1.2905e-01) 
2023-05-25 01:42:44.190184: train Epoch: [18][ 43/193]	Time  1.593 ( 1.515)	Data  0.672 ( 0.206)	Loss 8.1437e-02 (1.2797e-01) 
2023-05-25 01:42:45.519922: train Epoch: [18][ 44/193]	Time  1.330 ( 1.511)	Data  0.205 ( 0.206)	Loss 1.3543e-01 (1.2814e-01) 
2023-05-25 01:42:47.490684: train Epoch: [18][ 45/193]	Time  1.971 ( 1.521)	Data  0.558 ( 0.213)	Loss 9.8506e-02 (1.2749e-01) 
2023-05-25 01:42:48.561207: train Epoch: [18][ 46/193]	Time  1.071 ( 1.511)	Data  0.001 ( 0.209)	Loss 8.6809e-02 (1.2663e-01) 
2023-05-25 01:42:49.905152: train Epoch: [18][ 47/193]	Time  1.344 ( 1.508)	Data  0.288 ( 0.211)	Loss 7.2631e-02 (1.2550e-01) 
2023-05-25 01:42:51.160532: train Epoch: [18][ 48/193]	Time  1.255 ( 1.502)	Data  0.201 ( 0.210)	Loss 1.6129e-01 (1.2623e-01) 
2023-05-25 01:42:52.676491: train Epoch: [18][ 49/193]	Time  1.516 ( 1.503)	Data  0.480 ( 0.216)	Loss 1.5443e-01 (1.2680e-01) 
2023-05-25 01:42:54.230588: train Epoch: [18][ 50/193]	Time  1.554 ( 1.504)	Data  0.123 ( 0.214)	Loss 2.7306e-01 (1.2966e-01) 
2023-05-25 01:42:55.409202: train Epoch: [18][ 51/193]	Time  1.179 ( 1.497)	Data  0.158 ( 0.213)	Loss 6.3735e-02 (1.2840e-01) 
2023-05-25 01:42:56.825615: train Epoch: [18][ 52/193]	Time  1.416 ( 1.496)	Data  0.101 ( 0.211)	Loss 5.0065e-02 (1.2692e-01) 
2023-05-25 01:42:58.229214: train Epoch: [18][ 53/193]	Time  1.404 ( 1.494)	Data  0.312 ( 0.213)	Loss 8.9452e-02 (1.2622e-01) 
2023-05-25 01:42:59.205518: train Epoch: [18][ 54/193]	Time  0.976 ( 1.485)	Data  0.001 ( 0.209)	Loss 6.5677e-02 (1.2512e-01) 
2023-05-25 01:43:00.905833: train Epoch: [18][ 55/193]	Time  1.700 ( 1.489)	Data  0.725 ( 0.218)	Loss 9.5177e-02 (1.2459e-01) 
2023-05-25 01:43:02.040893: train Epoch: [18][ 56/193]	Time  1.135 ( 1.482)	Data  0.135 ( 0.217)	Loss 1.4640e-01 (1.2497e-01) 
2023-05-25 01:43:03.837886: train Epoch: [18][ 57/193]	Time  1.797 ( 1.488)	Data  0.797 ( 0.227)	Loss 8.8128e-02 (1.2434e-01) 
2023-05-25 01:43:04.802613: train Epoch: [18][ 58/193]	Time  0.965 ( 1.479)	Data  0.001 ( 0.223)	Loss 2.0973e-01 (1.2578e-01) 
2023-05-25 01:43:06.650550: train Epoch: [18][ 59/193]	Time  1.848 ( 1.485)	Data  0.870 ( 0.234)	Loss 1.0405e-01 (1.2542e-01) 
2023-05-25 01:43:07.619170: train Epoch: [18][ 60/193]	Time  0.969 ( 1.477)	Data  0.002 ( 0.230)	Loss 9.7221e-02 (1.2496e-01) 
2023-05-25 01:43:09.569970: train Epoch: [18][ 61/193]	Time  1.951 ( 1.484)	Data  0.820 ( 0.239)	Loss 1.8899e-01 (1.2599e-01) 
2023-05-25 01:43:10.599322: train Epoch: [18][ 62/193]	Time  1.029 ( 1.477)	Data  0.001 ( 0.235)	Loss 1.7268e-01 (1.2673e-01) 
2023-05-25 01:43:12.493862: train Epoch: [18][ 63/193]	Time  1.895 ( 1.484)	Data  0.557 ( 0.240)	Loss 8.7067e-02 (1.2611e-01) 
2023-05-25 01:43:13.497264: train Epoch: [18][ 64/193]	Time  1.003 ( 1.476)	Data  0.002 ( 0.237)	Loss 1.0633e-01 (1.2581e-01) 
2023-05-25 01:43:14.930361: train Epoch: [18][ 65/193]	Time  1.433 ( 1.476)	Data  0.330 ( 0.238)	Loss 8.7275e-02 (1.2522e-01) 
2023-05-25 01:43:16.170375: train Epoch: [18][ 66/193]	Time  1.240 ( 1.472)	Data  0.001 ( 0.235)	Loss 1.1518e-01 (1.2507e-01) 
2023-05-25 01:43:17.896067: train Epoch: [18][ 67/193]	Time  1.726 ( 1.476)	Data  0.381 ( 0.237)	Loss 1.3594e-01 (1.2523e-01) 
2023-05-25 01:43:19.026853: train Epoch: [18][ 68/193]	Time  1.131 ( 1.471)	Data  0.001 ( 0.233)	Loss 1.3720e-01 (1.2541e-01) 
2023-05-25 01:43:20.397044: train Epoch: [18][ 69/193]	Time  1.370 ( 1.469)	Data  0.343 ( 0.235)	Loss 1.4389e-01 (1.2567e-01) 
2023-05-25 01:43:21.397034: train Epoch: [18][ 70/193]	Time  1.000 ( 1.463)	Data  0.001 ( 0.232)	Loss 7.7937e-02 (1.2500e-01) 
2023-05-25 01:43:23.079769: train Epoch: [18][ 71/193]	Time  1.683 ( 1.466)	Data  0.697 ( 0.238)	Loss 2.1935e-01 (1.2631e-01) 
2023-05-25 01:43:24.108102: train Epoch: [18][ 72/193]	Time  1.028 ( 1.460)	Data  0.001 ( 0.235)	Loss 7.4157e-02 (1.2560e-01) 
2023-05-25 01:43:25.819143: train Epoch: [18][ 73/193]	Time  1.711 ( 1.463)	Data  0.755 ( 0.242)	Loss 1.1172e-01 (1.2541e-01) 
2023-05-25 01:43:26.870609: train Epoch: [18][ 74/193]	Time  1.051 ( 1.458)	Data  0.001 ( 0.239)	Loss 2.6979e-01 (1.2733e-01) 
2023-05-25 01:43:29.060928: train Epoch: [18][ 75/193]	Time  2.190 ( 1.467)	Data  0.876 ( 0.247)	Loss 7.8615e-02 (1.2669e-01) 
2023-05-25 01:43:30.137912: train Epoch: [18][ 76/193]	Time  1.077 ( 1.462)	Data  0.001 ( 0.244)	Loss 1.2349e-01 (1.2665e-01) 
2023-05-25 01:43:31.830546: train Epoch: [18][ 77/193]	Time  1.693 ( 1.465)	Data  0.474 ( 0.247)	Loss 6.9159e-02 (1.2591e-01) 
2023-05-25 01:43:32.853161: train Epoch: [18][ 78/193]	Time  1.023 ( 1.460)	Data  0.001 ( 0.244)	Loss 8.4637e-02 (1.2539e-01) 
2023-05-25 01:43:34.678976: train Epoch: [18][ 79/193]	Time  1.826 ( 1.464)	Data  0.560 ( 0.248)	Loss 2.9653e-01 (1.2753e-01) 
2023-05-25 01:43:35.793473: train Epoch: [18][ 80/193]	Time  1.115 ( 1.460)	Data  0.001 ( 0.245)	Loss 1.0934e-01 (1.2731e-01) 
2023-05-25 01:43:37.548424: train Epoch: [18][ 81/193]	Time  1.755 ( 1.463)	Data  0.474 ( 0.247)	Loss 7.3775e-02 (1.2665e-01) 
2023-05-25 01:43:38.583863: train Epoch: [18][ 82/193]	Time  1.035 ( 1.458)	Data  0.001 ( 0.244)	Loss 9.1039e-02 (1.2622e-01) 
2023-05-25 01:43:40.432619: train Epoch: [18][ 83/193]	Time  1.849 ( 1.463)	Data  0.530 ( 0.248)	Loss 2.2484e-01 (1.2740e-01) 
2023-05-25 01:43:41.627379: train Epoch: [18][ 84/193]	Time  1.195 ( 1.460)	Data  0.002 ( 0.245)	Loss 1.1630e-01 (1.2727e-01) 
2023-05-25 01:43:43.137443: train Epoch: [18][ 85/193]	Time  1.510 ( 1.460)	Data  0.314 ( 0.246)	Loss 1.3648e-01 (1.2737e-01) 
2023-05-25 01:43:44.276679: train Epoch: [18][ 86/193]	Time  1.139 ( 1.457)	Data  0.001 ( 0.243)	Loss 1.0185e-01 (1.2708e-01) 
2023-05-25 01:43:46.077257: train Epoch: [18][ 87/193]	Time  1.801 ( 1.461)	Data  0.539 ( 0.246)	Loss 1.4386e-01 (1.2727e-01) 
2023-05-25 01:43:47.343763: train Epoch: [18][ 88/193]	Time  1.267 ( 1.458)	Data  0.001 ( 0.244)	Loss 1.2408e-01 (1.2724e-01) 
2023-05-25 01:43:48.585395: train Epoch: [18][ 89/193]	Time  1.242 ( 1.456)	Data  0.255 ( 0.244)	Loss 1.6810e-01 (1.2769e-01) 
2023-05-25 01:43:49.667206: train Epoch: [18][ 90/193]	Time  1.082 ( 1.452)	Data  0.001 ( 0.241)	Loss 1.0853e-01 (1.2748e-01) 
2023-05-25 01:43:51.605509: train Epoch: [18][ 91/193]	Time  1.938 ( 1.457)	Data  0.784 ( 0.247)	Loss 1.2394e-01 (1.2744e-01) 
2023-05-25 01:43:52.615293: train Epoch: [18][ 92/193]	Time  1.010 ( 1.452)	Data  0.001 ( 0.244)	Loss 1.2430e-01 (1.2741e-01) 
2023-05-25 01:43:54.263407: train Epoch: [18][ 93/193]	Time  1.648 ( 1.454)	Data  0.657 ( 0.249)	Loss 1.8073e-01 (1.2797e-01) 
2023-05-25 01:43:55.234901: train Epoch: [18][ 94/193]	Time  0.971 ( 1.449)	Data  0.001 ( 0.246)	Loss 1.5810e-01 (1.2829e-01) 
2023-05-25 01:43:57.188306: train Epoch: [18][ 95/193]	Time  1.953 ( 1.455)	Data  0.911 ( 0.253)	Loss 1.8288e-01 (1.2886e-01) 
2023-05-25 01:43:58.316350: train Epoch: [18][ 96/193]	Time  1.128 ( 1.451)	Data  0.001 ( 0.250)	Loss 2.4470e-01 (1.3005e-01) 
2023-05-25 01:44:00.075418: train Epoch: [18][ 97/193]	Time  1.759 ( 1.454)	Data  0.674 ( 0.255)	Loss 1.1274e-01 (1.2988e-01) 
2023-05-25 01:44:01.087001: train Epoch: [18][ 98/193]	Time  1.012 ( 1.450)	Data  0.001 ( 0.252)	Loss 2.5671e-01 (1.3116e-01) 
2023-05-25 01:44:03.012716: train Epoch: [18][ 99/193]	Time  1.926 ( 1.455)	Data  0.720 ( 0.257)	Loss 8.0471e-02 (1.3065e-01) 
2023-05-25 01:44:03.989551: train Epoch: [18][100/193]	Time  0.977 ( 1.450)	Data  0.001 ( 0.254)	Loss 9.9166e-02 (1.3034e-01) 
2023-05-25 01:44:05.578414: train Epoch: [18][101/193]	Time  1.589 ( 1.451)	Data  0.649 ( 0.258)	Loss 1.2259e-01 (1.3026e-01) 
2023-05-25 01:44:06.557299: train Epoch: [18][102/193]	Time  0.979 ( 1.447)	Data  0.001 ( 0.256)	Loss 9.2104e-02 (1.2989e-01) 
2023-05-25 01:44:08.535035: train Epoch: [18][103/193]	Time  1.978 ( 1.452)	Data  0.907 ( 0.262)	Loss 1.1572e-01 (1.2976e-01) 
2023-05-25 01:44:09.602733: train Epoch: [18][104/193]	Time  1.068 ( 1.448)	Data  0.001 ( 0.259)	Loss 1.3411e-01 (1.2980e-01) 
2023-05-25 01:44:11.343791: train Epoch: [18][105/193]	Time  1.741 ( 1.451)	Data  0.687 ( 0.263)	Loss 7.1830e-02 (1.2925e-01) 
2023-05-25 01:44:12.652525: train Epoch: [18][106/193]	Time  1.309 ( 1.450)	Data  0.001 ( 0.261)	Loss 1.4128e-01 (1.2936e-01) 
2023-05-25 01:44:14.262677: train Epoch: [18][107/193]	Time  1.610 ( 1.451)	Data  0.384 ( 0.262)	Loss 2.3849e-01 (1.3037e-01) 
2023-05-25 01:44:15.604803: train Epoch: [18][108/193]	Time  1.342 ( 1.450)	Data  0.001 ( 0.260)	Loss 1.3530e-01 (1.3042e-01) 
2023-05-25 01:44:16.879587: train Epoch: [18][109/193]	Time  1.275 ( 1.449)	Data  0.223 ( 0.259)	Loss 2.5551e-01 (1.3156e-01) 
2023-05-25 01:44:17.912930: train Epoch: [18][110/193]	Time  1.033 ( 1.445)	Data  0.001 ( 0.257)	Loss 9.7609e-02 (1.3125e-01) 
2023-05-25 01:44:19.620921: train Epoch: [18][111/193]	Time  1.708 ( 1.447)	Data  0.707 ( 0.261)	Loss 1.6015e-01 (1.3151e-01) 
2023-05-25 01:44:20.652746: train Epoch: [18][112/193]	Time  1.032 ( 1.443)	Data  0.001 ( 0.259)	Loss 7.6630e-02 (1.3102e-01) 
2023-05-25 01:44:22.550292: train Epoch: [18][113/193]	Time  1.898 ( 1.447)	Data  0.757 ( 0.263)	Loss 8.7184e-02 (1.3064e-01) 
2023-05-25 01:44:23.635782: train Epoch: [18][114/193]	Time  1.085 ( 1.444)	Data  0.001 ( 0.261)	Loss 1.1196e-01 (1.3048e-01) 
2023-05-25 01:44:25.264780: train Epoch: [18][115/193]	Time  1.629 ( 1.446)	Data  0.573 ( 0.264)	Loss 1.9112e-01 (1.3100e-01) 
2023-05-25 01:44:26.324402: train Epoch: [18][116/193]	Time  1.060 ( 1.443)	Data  0.001 ( 0.261)	Loss 1.6902e-01 (1.3132e-01) 
2023-05-25 01:44:28.082737: train Epoch: [18][117/193]	Time  1.758 ( 1.445)	Data  0.646 ( 0.265)	Loss 2.1269e-01 (1.3201e-01) 
2023-05-25 01:44:29.150234: train Epoch: [18][118/193]	Time  1.068 ( 1.442)	Data  0.001 ( 0.262)	Loss 9.0827e-02 (1.3167e-01) 
2023-05-25 01:44:31.237068: train Epoch: [18][119/193]	Time  2.087 ( 1.447)	Data  0.615 ( 0.265)	Loss 1.2732e-01 (1.3163e-01) 
2023-05-25 01:44:32.335019: train Epoch: [18][120/193]	Time  1.098 ( 1.445)	Data  0.001 ( 0.263)	Loss 1.2071e-01 (1.3154e-01) 
2023-05-25 01:44:33.852698: train Epoch: [18][121/193]	Time  1.518 ( 1.445)	Data  0.136 ( 0.262)	Loss 9.6582e-02 (1.3125e-01) 
2023-05-25 01:44:34.983664: train Epoch: [18][122/193]	Time  1.131 ( 1.443)	Data  0.002 ( 0.260)	Loss 8.7767e-02 (1.3090e-01) 
2023-05-25 01:44:36.741202: train Epoch: [18][123/193]	Time  1.758 ( 1.445)	Data  0.292 ( 0.260)	Loss 1.3686e-01 (1.3095e-01) 
2023-05-25 01:44:37.820465: train Epoch: [18][124/193]	Time  1.079 ( 1.442)	Data  0.001 ( 0.258)	Loss 2.0195e-01 (1.3152e-01) 
2023-05-25 01:44:39.290598: train Epoch: [18][125/193]	Time  1.470 ( 1.442)	Data  0.247 ( 0.258)	Loss 1.3799e-01 (1.3157e-01) 
2023-05-25 01:44:40.377656: train Epoch: [18][126/193]	Time  1.087 ( 1.440)	Data  0.001 ( 0.256)	Loss 1.1938e-01 (1.3147e-01) 
2023-05-25 01:44:42.105994: train Epoch: [18][127/193]	Time  1.728 ( 1.442)	Data  0.476 ( 0.258)	Loss 7.6594e-02 (1.3104e-01) 
2023-05-25 01:44:43.118962: train Epoch: [18][128/193]	Time  1.013 ( 1.439)	Data  0.001 ( 0.256)	Loss 1.0823e-01 (1.3087e-01) 
2023-05-25 01:44:44.725288: train Epoch: [18][129/193]	Time  1.606 ( 1.440)	Data  0.486 ( 0.258)	Loss 8.9369e-02 (1.3055e-01) 
2023-05-25 01:44:45.816994: train Epoch: [18][130/193]	Time  1.092 ( 1.437)	Data  0.001 ( 0.256)	Loss 9.1829e-02 (1.3025e-01) 
2023-05-25 01:44:47.549029: train Epoch: [18][131/193]	Time  1.732 ( 1.439)	Data  0.742 ( 0.259)	Loss 1.7340e-01 (1.3058e-01) 
2023-05-25 01:44:48.710401: train Epoch: [18][132/193]	Time  1.161 ( 1.437)	Data  0.001 ( 0.257)	Loss 2.1742e-01 (1.3123e-01) 
2023-05-25 01:44:50.433097: train Epoch: [18][133/193]	Time  1.723 ( 1.439)	Data  0.678 ( 0.261)	Loss 1.5591e-01 (1.3142e-01) 
2023-05-25 01:44:51.548246: train Epoch: [18][134/193]	Time  1.115 ( 1.437)	Data  0.001 ( 0.259)	Loss 1.0365e-01 (1.3121e-01) 
2023-05-25 01:44:53.222535: train Epoch: [18][135/193]	Time  1.674 ( 1.439)	Data  0.574 ( 0.261)	Loss 2.2159e-01 (1.3188e-01) 
2023-05-25 01:44:54.263450: train Epoch: [18][136/193]	Time  1.041 ( 1.436)	Data  0.001 ( 0.259)	Loss 9.5168e-02 (1.3161e-01) 
2023-05-25 01:44:55.778751: train Epoch: [18][137/193]	Time  1.515 ( 1.436)	Data  0.490 ( 0.261)	Loss 6.7625e-02 (1.3114e-01) 
2023-05-25 01:44:56.851059: train Epoch: [18][138/193]	Time  1.072 ( 1.434)	Data  0.001 ( 0.259)	Loss 1.1757e-01 (1.3105e-01) 
2023-05-25 01:44:58.731560: train Epoch: [18][139/193]	Time  1.880 ( 1.437)	Data  0.721 ( 0.262)	Loss 8.8072e-02 (1.3074e-01) 
2023-05-25 01:44:59.715362: train Epoch: [18][140/193]	Time  0.984 ( 1.434)	Data  0.001 ( 0.260)	Loss 1.0475e-01 (1.3055e-01) 
2023-05-25 01:45:01.363188: train Epoch: [18][141/193]	Time  1.648 ( 1.435)	Data  0.515 ( 0.262)	Loss 6.5086e-02 (1.3009e-01) 
2023-05-25 01:45:02.445744: train Epoch: [18][142/193]	Time  1.083 ( 1.433)	Data  0.001 ( 0.260)	Loss 8.7514e-02 (1.2980e-01) 
2023-05-25 01:45:03.979041: train Epoch: [18][143/193]	Time  1.533 ( 1.434)	Data  0.559 ( 0.262)	Loss 6.6850e-02 (1.2936e-01) 
2023-05-25 01:45:04.977989: train Epoch: [18][144/193]	Time  0.999 ( 1.431)	Data  0.001 ( 0.261)	Loss 8.5892e-02 (1.2906e-01) 
2023-05-25 01:45:06.932943: train Epoch: [18][145/193]	Time  1.955 ( 1.434)	Data  0.763 ( 0.264)	Loss 9.9367e-02 (1.2886e-01) 
2023-05-25 01:45:08.008454: train Epoch: [18][146/193]	Time  1.076 ( 1.432)	Data  0.001 ( 0.262)	Loss 9.1682e-02 (1.2860e-01) 
2023-05-25 01:45:09.736905: train Epoch: [18][147/193]	Time  1.728 ( 1.434)	Data  0.480 ( 0.264)	Loss 1.5688e-01 (1.2879e-01) 
2023-05-25 01:45:10.996665: train Epoch: [18][148/193]	Time  1.260 ( 1.433)	Data  0.001 ( 0.262)	Loss 8.4670e-02 (1.2850e-01) 
2023-05-25 01:45:12.173311: train Epoch: [18][149/193]	Time  1.177 ( 1.431)	Data  0.184 ( 0.261)	Loss 1.5174e-01 (1.2865e-01) 
2023-05-25 01:45:13.308304: train Epoch: [18][150/193]	Time  1.135 ( 1.429)	Data  0.001 ( 0.260)	Loss 1.7846e-01 (1.2898e-01) 
2023-05-25 01:45:14.864543: train Epoch: [18][151/193]	Time  1.556 ( 1.430)	Data  0.579 ( 0.262)	Loss 3.3084e-01 (1.3031e-01) 
2023-05-25 01:45:15.865612: train Epoch: [18][152/193]	Time  1.001 ( 1.427)	Data  0.001 ( 0.260)	Loss 1.1186e-01 (1.3019e-01) 
2023-05-25 01:45:17.731123: train Epoch: [18][153/193]	Time  1.866 ( 1.430)	Data  0.759 ( 0.263)	Loss 1.3666e-01 (1.3023e-01) 
2023-05-25 01:45:18.830001: train Epoch: [18][154/193]	Time  1.099 ( 1.428)	Data  0.001 ( 0.262)	Loss 1.0090e-01 (1.3004e-01) 
2023-05-25 01:45:20.622245: train Epoch: [18][155/193]	Time  1.792 ( 1.430)	Data  0.519 ( 0.263)	Loss 1.2552e-01 (1.3001e-01) 
2023-05-25 01:45:21.597224: train Epoch: [18][156/193]	Time  0.975 ( 1.427)	Data  0.001 ( 0.262)	Loss 6.0083e-02 (1.2957e-01) 
2023-05-25 01:45:23.001107: train Epoch: [18][157/193]	Time  1.404 ( 1.427)	Data  0.346 ( 0.262)	Loss 8.5894e-02 (1.2929e-01) 
2023-05-25 01:45:24.013058: train Epoch: [18][158/193]	Time  1.012 ( 1.424)	Data  0.001 ( 0.260)	Loss 1.5151e-01 (1.2943e-01) 
2023-05-25 01:45:25.791829: train Epoch: [18][159/193]	Time  1.779 ( 1.427)	Data  0.652 ( 0.263)	Loss 1.0051e-01 (1.2925e-01) 
2023-05-25 01:45:27.123611: train Epoch: [18][160/193]	Time  1.332 ( 1.426)	Data  0.001 ( 0.261)	Loss 1.6496e-01 (1.2947e-01) 
2023-05-25 01:45:28.629773: train Epoch: [18][161/193]	Time  1.506 ( 1.426)	Data  0.243 ( 0.261)	Loss 7.2215e-02 (1.2912e-01) 
2023-05-25 01:45:29.920511: train Epoch: [18][162/193]	Time  1.291 ( 1.426)	Data  0.001 ( 0.260)	Loss 1.0789e-01 (1.2899e-01) 
2023-05-25 01:45:31.152385: train Epoch: [18][163/193]	Time  1.232 ( 1.424)	Data  0.096 ( 0.259)	Loss 1.4344e-01 (1.2908e-01) 
2023-05-25 01:45:32.181431: train Epoch: [18][164/193]	Time  1.029 ( 1.422)	Data  0.001 ( 0.257)	Loss 1.1621e-01 (1.2900e-01) 
2023-05-25 01:45:33.915372: train Epoch: [18][165/193]	Time  1.734 ( 1.424)	Data  0.488 ( 0.258)	Loss 9.0982e-02 (1.2877e-01) 
2023-05-25 01:45:34.955308: train Epoch: [18][166/193]	Time  1.040 ( 1.422)	Data  0.001 ( 0.257)	Loss 5.4164e-02 (1.2832e-01) 
2023-05-25 01:45:36.360079: train Epoch: [18][167/193]	Time  1.405 ( 1.422)	Data  0.339 ( 0.257)	Loss 1.1789e-01 (1.2826e-01) 
2023-05-25 01:45:37.316681: train Epoch: [18][168/193]	Time  0.957 ( 1.419)	Data  0.001 ( 0.256)	Loss 8.0952e-02 (1.2798e-01) 
2023-05-25 01:45:39.336864: train Epoch: [18][169/193]	Time  2.020 ( 1.422)	Data  0.676 ( 0.258)	Loss 1.0446e-01 (1.2784e-01) 
2023-05-25 01:45:40.377592: train Epoch: [18][170/193]	Time  1.041 ( 1.420)	Data  0.001 ( 0.257)	Loss 1.0367e-01 (1.2770e-01) 
2023-05-25 01:45:41.812897: train Epoch: [18][171/193]	Time  1.435 ( 1.420)	Data  0.326 ( 0.257)	Loss 1.2419e-01 (1.2768e-01) 
2023-05-25 01:45:42.935865: train Epoch: [18][172/193]	Time  1.123 ( 1.418)	Data  0.001 ( 0.256)	Loss 1.6850e-01 (1.2792e-01) 
2023-05-25 01:45:44.445320: train Epoch: [18][173/193]	Time  1.509 ( 1.419)	Data  0.416 ( 0.257)	Loss 1.8784e-01 (1.2826e-01) 
2023-05-25 01:45:45.722160: train Epoch: [18][174/193]	Time  1.277 ( 1.418)	Data  0.001 ( 0.255)	Loss 1.3017e-01 (1.2827e-01) 
2023-05-25 01:45:47.054271: train Epoch: [18][175/193]	Time  1.332 ( 1.418)	Data  0.305 ( 0.255)	Loss 1.6713e-01 (1.2849e-01) 
2023-05-25 01:45:48.059360: train Epoch: [18][176/193]	Time  1.005 ( 1.415)	Data  0.001 ( 0.254)	Loss 7.2380e-02 (1.2818e-01) 
2023-05-25 01:45:49.794805: train Epoch: [18][177/193]	Time  1.735 ( 1.417)	Data  0.712 ( 0.257)	Loss 9.4003e-02 (1.2798e-01) 
2023-05-25 01:45:50.850671: train Epoch: [18][178/193]	Time  1.056 ( 1.415)	Data  0.001 ( 0.255)	Loss 5.0606e-02 (1.2755e-01) 
2023-05-25 01:45:52.463300: train Epoch: [18][179/193]	Time  1.613 ( 1.416)	Data  0.615 ( 0.257)	Loss 9.7491e-02 (1.2739e-01) 
2023-05-25 01:45:53.490852: train Epoch: [18][180/193]	Time  1.028 ( 1.414)	Data  0.001 ( 0.256)	Loss 1.0712e-01 (1.2727e-01) 
2023-05-25 01:45:55.420559: train Epoch: [18][181/193]	Time  1.930 ( 1.417)	Data  0.615 ( 0.258)	Loss 8.2079e-02 (1.2702e-01) 
2023-05-25 01:45:56.509446: train Epoch: [18][182/193]	Time  1.089 ( 1.415)	Data  0.001 ( 0.256)	Loss 3.8309e-01 (1.2842e-01) 
2023-05-25 01:45:58.075876: train Epoch: [18][183/193]	Time  1.566 ( 1.416)	Data  0.236 ( 0.256)	Loss 1.4806e-01 (1.2853e-01) 
2023-05-25 01:45:59.099404: train Epoch: [18][184/193]	Time  1.024 ( 1.414)	Data  0.001 ( 0.255)	Loss 5.8715e-02 (1.2815e-01) 
2023-05-25 01:46:00.521952: train Epoch: [18][185/193]	Time  1.423 ( 1.414)	Data  0.263 ( 0.255)	Loss 7.2415e-02 (1.2785e-01) 
2023-05-25 01:46:01.640486: train Epoch: [18][186/193]	Time  1.119 ( 1.412)	Data  0.001 ( 0.254)	Loss 6.4814e-02 (1.2752e-01) 
2023-05-25 01:46:03.149702: train Epoch: [18][187/193]	Time  1.509 ( 1.413)	Data  0.432 ( 0.254)	Loss 1.0664e-01 (1.2741e-01) 
2023-05-25 01:46:04.471415: train Epoch: [18][188/193]	Time  1.322 ( 1.412)	Data  0.001 ( 0.253)	Loss 1.8072e-01 (1.2769e-01) 
2023-05-25 01:46:05.645999: train Epoch: [18][189/193]	Time  1.175 ( 1.411)	Data  0.175 ( 0.253)	Loss 9.7789e-02 (1.2753e-01) 
2023-05-25 01:46:06.603315: train Epoch: [18][190/193]	Time  0.957 ( 1.409)	Data  0.001 ( 0.251)	Loss 1.1257e-01 (1.2745e-01) 
2023-05-25 01:46:08.285403: train Epoch: [18][191/193]	Time  1.682 ( 1.410)	Data  0.702 ( 0.254)	Loss 1.1452e-01 (1.2738e-01) 
2023-05-25 01:46:09.269245: train Epoch: [18][192/193]	Time  0.984 ( 1.408)	Data  0.001 ( 0.252)	Loss 6.9199e-02 (1.2708e-01) 
2023-05-25 01:46:09.354958: Train Epoch done in 271.81327824899927 s 
2023-05-25 01:46:12.344792: val Epoch: [18][ 0/72]	Time  2.071 ( 2.071)	Data  1.621 ( 1.621)	Loss 7.2811e-02 (7.2811e-02) 
2023-05-25 01:46:12.738824: val Epoch: [18][ 1/72]	Time  0.394 ( 1.232)	Data  0.003 ( 0.812)	Loss 9.3208e-02 (8.3009e-02) 
2023-05-25 01:46:13.586801: val Epoch: [18][ 2/72]	Time  0.848 ( 1.104)	Data  0.462 ( 0.695)	Loss 5.4950e-02 (7.3656e-02) 
2023-05-25 01:46:13.867089: val Epoch: [18][ 3/72]	Time  0.280 ( 0.898)	Data  0.001 ( 0.522)	Loss 5.6474e-02 (6.9361e-02) 
2023-05-25 01:46:14.902118: val Epoch: [18][ 4/72]	Time  1.035 ( 0.926)	Data  0.654 ( 0.548)	Loss 5.5540e-02 (6.6596e-02) 
2023-05-25 01:46:15.182019: val Epoch: [18][ 5/72]	Time  0.280 ( 0.818)	Data  0.001 ( 0.457)	Loss 5.6922e-02 (6.4984e-02) 
2023-05-25 01:46:16.319398: val Epoch: [18][ 6/72]	Time  1.137 ( 0.864)	Data  0.818 ( 0.509)	Loss 1.2702e-01 (7.3847e-02) 
2023-05-25 01:46:16.652346: val Epoch: [18][ 7/72]	Time  0.333 ( 0.797)	Data  0.002 ( 0.445)	Loss 6.7677e-01 (1.4921e-01) 
2023-05-25 01:46:17.758582: val Epoch: [18][ 8/72]	Time  1.106 ( 0.832)	Data  0.784 ( 0.483)	Loss 7.9719e-02 (1.4149e-01) 
2023-05-25 01:46:18.574991: val Epoch: [18][ 9/72]	Time  0.816 ( 0.830)	Data  0.001 ( 0.435)	Loss 1.4405e-01 (1.4175e-01) 
2023-05-25 01:46:19.353813: val Epoch: [18][10/72]	Time  0.779 ( 0.825)	Data  0.348 ( 0.427)	Loss 3.9649e-01 (1.6491e-01) 
2023-05-25 01:46:19.649625: val Epoch: [18][11/72]	Time  0.296 ( 0.781)	Data  0.001 ( 0.391)	Loss 1.1071e-01 (1.6039e-01) 
2023-05-25 01:46:20.935384: val Epoch: [18][12/72]	Time  1.286 ( 0.820)	Data  0.841 ( 0.426)	Loss 7.5096e-02 (1.5383e-01) 
2023-05-25 01:46:21.149181: val Epoch: [18][13/72]	Time  0.214 ( 0.777)	Data  0.001 ( 0.396)	Loss 1.2144e-01 (1.5151e-01) 
2023-05-25 01:46:22.165447: val Epoch: [18][14/72]	Time  1.016 ( 0.793)	Data  0.723 ( 0.417)	Loss 7.6663e-02 (1.4652e-01) 
2023-05-25 01:46:22.491140: val Epoch: [18][15/72]	Time  0.326 ( 0.764)	Data  0.001 ( 0.391)	Loss 1.3123e-01 (1.4557e-01) 
2023-05-25 01:46:23.531675: val Epoch: [18][16/72]	Time  1.041 ( 0.780)	Data  0.749 ( 0.412)	Loss 6.1584e-01 (1.7323e-01) 
2023-05-25 01:46:23.960191: val Epoch: [18][17/72]	Time  0.429 ( 0.760)	Data  0.002 ( 0.390)	Loss 7.0115e-02 (1.6750e-01) 
2023-05-25 01:46:24.938894: val Epoch: [18][18/72]	Time  0.979 ( 0.772)	Data  0.677 ( 0.405)	Loss 7.9347e-02 (1.6286e-01) 
2023-05-25 01:46:25.179040: val Epoch: [18][19/72]	Time  0.240 ( 0.745)	Data  0.001 ( 0.385)	Loss 1.4650e-01 (1.6204e-01) 
2023-05-25 01:46:26.276733: val Epoch: [18][20/72]	Time  1.098 ( 0.762)	Data  0.822 ( 0.405)	Loss 1.2013e-01 (1.6005e-01) 
2023-05-25 01:46:26.555861: val Epoch: [18][21/72]	Time  0.279 ( 0.740)	Data  0.002 ( 0.387)	Loss 9.4952e-02 (1.5709e-01) 
2023-05-25 01:46:27.768915: val Epoch: [18][22/72]	Time  1.213 ( 0.761)	Data  0.851 ( 0.407)	Loss 1.1728e-01 (1.5536e-01) 
2023-05-25 01:46:28.102757: val Epoch: [18][23/72]	Time  0.334 ( 0.743)	Data  0.001 ( 0.390)	Loss 1.0115e-01 (1.5310e-01) 
2023-05-25 01:46:29.114448: val Epoch: [18][24/72]	Time  1.012 ( 0.754)	Data  0.687 ( 0.402)	Loss 4.9579e-02 (1.4896e-01) 
2023-05-25 01:46:29.501771: val Epoch: [18][25/72]	Time  0.387 ( 0.740)	Data  0.001 ( 0.387)	Loss 5.2408e-02 (1.4525e-01) 
2023-05-25 01:46:30.529210: val Epoch: [18][26/72]	Time  1.027 ( 0.750)	Data  0.726 ( 0.399)	Loss 6.6331e-02 (1.4232e-01) 
2023-05-25 01:46:30.884340: val Epoch: [18][27/72]	Time  0.355 ( 0.736)	Data  0.001 ( 0.385)	Loss 3.3526e-01 (1.4921e-01) 
2023-05-25 01:46:31.881609: val Epoch: [18][28/72]	Time  0.997 ( 0.745)	Data  0.702 ( 0.396)	Loss 5.8590e-02 (1.4609e-01) 
2023-05-25 01:46:32.166903: val Epoch: [18][29/72]	Time  0.285 ( 0.730)	Data  0.001 ( 0.383)	Loss 5.4687e-01 (1.5945e-01) 
2023-05-25 01:46:33.436784: val Epoch: [18][30/72]	Time  1.270 ( 0.747)	Data  0.813 ( 0.397)	Loss 1.2243e-01 (1.5825e-01) 
2023-05-25 01:46:33.976267: val Epoch: [18][31/72]	Time  0.539 ( 0.741)	Data  0.001 ( 0.384)	Loss 3.7339e-01 (1.6498e-01) 
2023-05-25 01:46:34.500177: val Epoch: [18][32/72]	Time  0.524 ( 0.734)	Data  0.320 ( 0.382)	Loss 9.2093e-02 (1.6277e-01) 
2023-05-25 01:46:34.815626: val Epoch: [18][33/72]	Time  0.315 ( 0.722)	Data  0.002 ( 0.371)	Loss 4.2085e-02 (1.5922e-01) 
2023-05-25 01:46:35.933154: val Epoch: [18][34/72]	Time  1.118 ( 0.733)	Data  0.866 ( 0.385)	Loss 1.9671e-01 (1.6029e-01) 
2023-05-25 01:46:36.308040: val Epoch: [18][35/72]	Time  0.375 ( 0.723)	Data  0.001 ( 0.375)	Loss 1.2741e-01 (1.5938e-01) 
2023-05-25 01:46:37.389496: val Epoch: [18][36/72]	Time  1.081 ( 0.733)	Data  0.749 ( 0.385)	Loss 3.6754e-01 (1.6500e-01) 
2023-05-25 01:46:37.652431: val Epoch: [18][37/72]	Time  0.263 ( 0.720)	Data  0.001 ( 0.375)	Loss 1.4138e-01 (1.6438e-01) 
2023-05-25 01:46:38.945556: val Epoch: [18][38/72]	Time  1.293 ( 0.735)	Data  0.774 ( 0.385)	Loss 5.3823e-02 (1.6155e-01) 
2023-05-25 01:46:39.184749: val Epoch: [18][39/72]	Time  0.239 ( 0.723)	Data  0.001 ( 0.375)	Loss 1.2647e-01 (1.6067e-01) 
2023-05-25 01:46:40.155632: val Epoch: [18][40/72]	Time  0.971 ( 0.729)	Data  0.609 ( 0.381)	Loss 7.8394e-02 (1.5866e-01) 
2023-05-25 01:46:40.618623: val Epoch: [18][41/72]	Time  0.463 ( 0.722)	Data  0.001 ( 0.372)	Loss 1.5211e-01 (1.5851e-01) 
2023-05-25 01:46:41.683138: val Epoch: [18][42/72]	Time  1.064 ( 0.730)	Data  0.575 ( 0.377)	Loss 6.4117e-02 (1.5631e-01) 
2023-05-25 01:46:42.049718: val Epoch: [18][43/72]	Time  0.367 ( 0.722)	Data  0.001 ( 0.368)	Loss 9.0546e-02 (1.5482e-01) 
2023-05-25 01:46:42.945097: val Epoch: [18][44/72]	Time  0.895 ( 0.726)	Data  0.501 ( 0.371)	Loss 5.9100e-02 (1.5269e-01) 
2023-05-25 01:46:43.159749: val Epoch: [18][45/72]	Time  0.215 ( 0.715)	Data  0.001 ( 0.363)	Loss 3.1311e-01 (1.5618e-01) 
2023-05-25 01:46:44.159645: val Epoch: [18][46/72]	Time  1.000 ( 0.721)	Data  0.717 ( 0.371)	Loss 6.4548e-02 (1.5423e-01) 
2023-05-25 01:46:44.546489: val Epoch: [18][47/72]	Time  0.387 ( 0.714)	Data  0.002 ( 0.363)	Loss 2.0083e-01 (1.5520e-01) 
2023-05-25 01:46:45.505952: val Epoch: [18][48/72]	Time  0.959 ( 0.719)	Data  0.744 ( 0.371)	Loss 6.3547e-02 (1.5333e-01) 
2023-05-25 01:46:45.897404: val Epoch: [18][49/72]	Time  0.391 ( 0.712)	Data  0.001 ( 0.363)	Loss 5.7006e-01 (1.6166e-01) 
2023-05-25 01:46:46.955483: val Epoch: [18][50/72]	Time  1.058 ( 0.719)	Data  0.843 ( 0.373)	Loss 7.5563e-02 (1.5997e-01) 
2023-05-25 01:46:47.155227: val Epoch: [18][51/72]	Time  0.200 ( 0.709)	Data  0.003 ( 0.366)	Loss 3.4104e-01 (1.6346e-01) 
2023-05-25 01:46:48.773806: val Epoch: [18][52/72]	Time  1.619 ( 0.726)	Data  1.134 ( 0.380)	Loss 7.3755e-02 (1.6176e-01) 
2023-05-25 01:46:49.172189: val Epoch: [18][53/72]	Time  0.398 ( 0.720)	Data  0.001 ( 0.373)	Loss 1.9710e-01 (1.6242e-01) 
2023-05-25 01:46:50.036838: val Epoch: [18][54/72]	Time  0.865 ( 0.723)	Data  0.454 ( 0.375)	Loss 2.0078e-01 (1.6312e-01) 
2023-05-25 01:46:50.248492: val Epoch: [18][55/72]	Time  0.212 ( 0.714)	Data  0.001 ( 0.368)	Loss 4.7091e-01 (1.6861e-01) 
2023-05-25 01:46:51.358605: val Epoch: [18][56/72]	Time  1.110 ( 0.721)	Data  0.724 ( 0.374)	Loss 4.9523e-02 (1.6652e-01) 
2023-05-25 01:46:51.848257: val Epoch: [18][57/72]	Time  0.490 ( 0.717)	Data  0.001 ( 0.368)	Loss 1.0419e-01 (1.6545e-01) 
2023-05-25 01:46:52.653478: val Epoch: [18][58/72]	Time  0.805 ( 0.718)	Data  0.504 ( 0.370)	Loss 9.0530e-02 (1.6418e-01) 
2023-05-25 01:46:52.898745: val Epoch: [18][59/72]	Time  0.245 ( 0.710)	Data  0.001 ( 0.364)	Loss 7.0624e-02 (1.6262e-01) 
2023-05-25 01:46:54.154714: val Epoch: [18][60/72]	Time  1.256 ( 0.719)	Data  0.872 ( 0.372)	Loss 1.7005e-01 (1.6274e-01) 
2023-05-25 01:46:54.571392: val Epoch: [18][61/72]	Time  0.417 ( 0.714)	Data  0.001 ( 0.366)	Loss 1.7048e-01 (1.6287e-01) 
2023-05-25 01:46:55.616297: val Epoch: [18][62/72]	Time  1.045 ( 0.720)	Data  0.554 ( 0.369)	Loss 6.3837e-02 (1.6129e-01) 
2023-05-25 01:46:55.897197: val Epoch: [18][63/72]	Time  0.281 ( 0.713)	Data  0.001 ( 0.363)	Loss 1.1333e-01 (1.6054e-01) 
2023-05-25 01:46:56.837991: val Epoch: [18][64/72]	Time  0.941 ( 0.716)	Data  0.633 ( 0.368)	Loss 5.7384e-02 (1.5896e-01) 
2023-05-25 01:46:57.297290: val Epoch: [18][65/72]	Time  0.459 ( 0.712)	Data  0.001 ( 0.362)	Loss 1.3018e-01 (1.5852e-01) 
2023-05-25 01:46:58.238679: val Epoch: [18][66/72]	Time  0.941 ( 0.716)	Data  0.589 ( 0.365)	Loss 1.2034e-01 (1.5795e-01) 
2023-05-25 01:46:58.553650: val Epoch: [18][67/72]	Time  0.315 ( 0.710)	Data  0.003 ( 0.360)	Loss 7.8102e-02 (1.5678e-01) 
2023-05-25 01:46:59.646318: val Epoch: [18][68/72]	Time  1.093 ( 0.716)	Data  0.729 ( 0.365)	Loss 2.2899e-01 (1.5782e-01) 
2023-05-25 01:47:00.052057: val Epoch: [18][69/72]	Time  0.406 ( 0.711)	Data  0.001 ( 0.360)	Loss 1.4651e-01 (1.5766e-01) 
2023-05-25 01:47:00.878308: val Epoch: [18][70/72]	Time  0.826 ( 0.713)	Data  0.489 ( 0.362)	Loss 5.6985e-02 (1.5624e-01) 
2023-05-25 01:47:01.107285: val Epoch: [18][71/72]	Time  0.229 ( 0.706)	Data  0.001 ( 0.357)	Loss 2.2608e-01 (1.5721e-01) 
2023-05-25 01:47:01.399220: Epoch 18 :Val : ['ET : 0.728155791759491', 'TC : 0.7440101504325867', 'WT : 0.8165045976638794'] 
2023-05-25 01:47:01.402746: Epoch 18 :Val : ['ET : 0.728155791759491', 'TC : 0.7440101504325867', 'WT : 0.8165045976638794'] 
2023-05-25 01:47:01.408677: Val epoch done in 52.05371608596761 s 
2023-05-25 01:47:01.418814: Batches per epoch:  193 
2023-05-25 01:47:05.668916: train Epoch: [19][  0/193]	Time  4.249 ( 4.249)	Data  3.237 ( 3.237)	Loss 9.0434e-02 (9.0434e-02) 
2023-05-25 01:47:06.725474: train Epoch: [19][  1/193]	Time  1.057 ( 2.653)	Data  0.001 ( 1.619)	Loss 9.9836e-02 (9.5135e-02) 
2023-05-25 01:47:08.591397: train Epoch: [19][  2/193]	Time  1.866 ( 2.391)	Data  0.663 ( 1.300)	Loss 7.0380e-02 (8.6883e-02) 
2023-05-25 01:47:09.576362: train Epoch: [19][  3/193]	Time  0.985 ( 2.039)	Data  0.001 ( 0.976)	Loss 8.5555e-02 (8.6551e-02) 
2023-05-25 01:47:11.357553: train Epoch: [19][  4/193]	Time  1.781 ( 1.988)	Data  0.530 ( 0.886)	Loss 1.9440e-01 (1.0812e-01) 
2023-05-25 01:47:12.398270: train Epoch: [19][  5/193]	Time  1.041 ( 1.830)	Data  0.002 ( 0.739)	Loss 7.0197e-02 (1.0180e-01) 
2023-05-25 01:47:13.944336: train Epoch: [19][  6/193]	Time  1.546 ( 1.789)	Data  0.351 ( 0.684)	Loss 5.0932e-02 (9.4534e-02) 
2023-05-25 01:47:15.053566: train Epoch: [19][  7/193]	Time  1.109 ( 1.704)	Data  0.001 ( 0.598)	Loss 1.4403e-01 (1.0072e-01) 
2023-05-25 01:47:16.667131: train Epoch: [19][  8/193]	Time  1.614 ( 1.694)	Data  0.459 ( 0.583)	Loss 9.5401e-02 (1.0013e-01) 
2023-05-25 01:47:17.808703: train Epoch: [19][  9/193]	Time  1.142 ( 1.639)	Data  0.001 ( 0.525)	Loss 6.6654e-02 (9.6782e-02) 
2023-05-25 01:47:19.103185: train Epoch: [19][ 10/193]	Time  1.295 ( 1.608)	Data  0.362 ( 0.510)	Loss 6.0218e-02 (9.3458e-02) 
2023-05-25 01:47:20.133950: train Epoch: [19][ 11/193]	Time  1.031 ( 1.560)	Data  0.001 ( 0.467)	Loss 8.2548e-02 (9.2549e-02) 
2023-05-25 01:47:22.122373: train Epoch: [19][ 12/193]	Time  1.988 ( 1.593)	Data  0.787 ( 0.492)	Loss 8.5537e-02 (9.2010e-02) 
2023-05-25 01:47:23.257950: train Epoch: [19][ 13/193]	Time  1.136 ( 1.560)	Data  0.001 ( 0.457)	Loss 9.3959e-02 (9.2149e-02) 
2023-05-25 01:47:24.750911: train Epoch: [19][ 14/193]	Time  1.493 ( 1.555)	Data  0.357 ( 0.450)	Loss 9.4522e-02 (9.2307e-02) 
2023-05-25 01:47:25.792117: train Epoch: [19][ 15/193]	Time  1.041 ( 1.523)	Data  0.001 ( 0.422)	Loss 1.0490e-01 (9.3094e-02) 
2023-05-25 01:47:27.361548: train Epoch: [19][ 16/193]	Time  1.569 ( 1.526)	Data  0.506 ( 0.427)	Loss 2.5890e-01 (1.0285e-01) 
2023-05-25 01:47:28.359335: train Epoch: [19][ 17/193]	Time  0.998 ( 1.497)	Data  0.001 ( 0.403)	Loss 9.6737e-02 (1.0251e-01) 
2023-05-25 01:47:30.153072: train Epoch: [19][ 18/193]	Time  1.794 ( 1.512)	Data  0.678 ( 0.418)	Loss 1.6029e-01 (1.0555e-01) 
2023-05-25 01:47:31.176488: train Epoch: [19][ 19/193]	Time  1.023 ( 1.488)	Data  0.001 ( 0.397)	Loss 1.1096e-01 (1.0582e-01) 
2023-05-25 01:47:32.991385: train Epoch: [19][ 20/193]	Time  1.815 ( 1.503)	Data  0.556 ( 0.405)	Loss 1.1842e-01 (1.0642e-01) 
2023-05-25 01:47:34.017364: train Epoch: [19][ 21/193]	Time  1.026 ( 1.482)	Data  0.001 ( 0.386)	Loss 7.6529e-02 (1.0506e-01) 
2023-05-25 01:47:35.678572: train Epoch: [19][ 22/193]	Time  1.661 ( 1.490)	Data  0.426 ( 0.388)	Loss 6.1413e-02 (1.0316e-01) 
2023-05-25 01:47:36.723939: train Epoch: [19][ 23/193]	Time  1.045 ( 1.471)	Data  0.001 ( 0.372)	Loss 9.1017e-02 (1.0266e-01) 
2023-05-25 01:47:38.241168: train Epoch: [19][ 24/193]	Time  1.517 ( 1.473)	Data  0.358 ( 0.371)	Loss 1.8190e-01 (1.0583e-01) 
2023-05-25 01:47:39.222367: train Epoch: [19][ 25/193]	Time  0.981 ( 1.454)	Data  0.001 ( 0.357)	Loss 1.0141e-01 (1.0566e-01) 
2023-05-25 01:47:40.868227: train Epoch: [19][ 26/193]	Time  1.646 ( 1.461)	Data  0.570 ( 0.365)	Loss 7.9027e-02 (1.0467e-01) 
2023-05-25 01:47:41.895911: train Epoch: [19][ 27/193]	Time  1.028 ( 1.446)	Data  0.001 ( 0.352)	Loss 1.3179e-01 (1.0564e-01) 
2023-05-25 01:47:43.917957: train Epoch: [19][ 28/193]	Time  2.022 ( 1.465)	Data  0.663 ( 0.363)	Loss 1.4318e-01 (1.0693e-01) 
2023-05-25 01:47:45.133888: train Epoch: [19][ 29/193]	Time  1.216 ( 1.457)	Data  0.001 ( 0.351)	Loss 9.9433e-02 (1.0668e-01) 
2023-05-25 01:47:46.258657: train Epoch: [19][ 30/193]	Time  1.125 ( 1.446)	Data  0.130 ( 0.344)	Loss 1.3454e-01 (1.0758e-01) 
2023-05-25 01:47:47.362313: train Epoch: [19][ 31/193]	Time  1.104 ( 1.436)	Data  0.001 ( 0.333)	Loss 2.2656e-01 (1.1130e-01) 
2023-05-25 01:47:49.085141: train Epoch: [19][ 32/193]	Time  1.723 ( 1.444)	Data  0.652 ( 0.343)	Loss 1.2398e-01 (1.1168e-01) 
2023-05-25 01:47:50.105165: train Epoch: [19][ 33/193]	Time  1.020 ( 1.432)	Data  0.001 ( 0.332)	Loss 7.7933e-02 (1.1069e-01) 
2023-05-25 01:47:51.832983: train Epoch: [19][ 34/193]	Time  1.728 ( 1.440)	Data  0.550 ( 0.339)	Loss 1.2581e-01 (1.1112e-01) 
2023-05-25 01:47:52.877862: train Epoch: [19][ 35/193]	Time  1.045 ( 1.429)	Data  0.001 ( 0.329)	Loss 9.7726e-02 (1.1075e-01) 
2023-05-25 01:47:54.643974: train Epoch: [19][ 36/193]	Time  1.766 ( 1.438)	Data  0.485 ( 0.334)	Loss 1.4504e-01 (1.1168e-01) 
2023-05-25 01:47:55.670431: train Epoch: [19][ 37/193]	Time  1.026 ( 1.428)	Data  0.001 ( 0.325)	Loss 1.0589e-01 (1.1153e-01) 
2023-05-25 01:47:57.119781: train Epoch: [19][ 38/193]	Time  1.449 ( 1.428)	Data  0.387 ( 0.326)	Loss 7.5713e-02 (1.1061e-01) 
2023-05-25 01:47:58.049188: train Epoch: [19][ 39/193]	Time  0.929 ( 1.416)	Data  0.001 ( 0.318)	Loss 1.4636e-01 (1.1150e-01) 
2023-05-25 01:48:00.136816: train Epoch: [19][ 40/193]	Time  2.088 ( 1.432)	Data  0.746 ( 0.329)	Loss 1.4681e-01 (1.1236e-01) 
2023-05-25 01:48:01.248847: train Epoch: [19][ 41/193]	Time  1.112 ( 1.425)	Data  0.001 ( 0.321)	Loss 7.1686e-02 (1.1139e-01) 
2023-05-25 01:48:02.482487: train Epoch: [19][ 42/193]	Time  1.234 ( 1.420)	Data  0.236 ( 0.319)	Loss 1.6799e-01 (1.1271e-01) 
2023-05-25 01:48:03.765804: train Epoch: [19][ 43/193]	Time  1.283 ( 1.417)	Data  0.001 ( 0.312)	Loss 7.0785e-02 (1.1176e-01) 
2023-05-25 01:48:05.233202: train Epoch: [19][ 44/193]	Time  1.467 ( 1.418)	Data  0.396 ( 0.314)	Loss 5.4928e-02 (1.1049e-01) 
2023-05-25 01:48:06.333697: train Epoch: [19][ 45/193]	Time  1.100 ( 1.411)	Data  0.001 ( 0.307)	Loss 1.6444e-01 (1.1167e-01) 
2023-05-25 01:48:07.774970: train Epoch: [19][ 46/193]	Time  1.441 ( 1.412)	Data  0.498 ( 0.311)	Loss 7.7496e-02 (1.1094e-01) 
2023-05-25 01:48:08.752707: train Epoch: [19][ 47/193]	Time  0.978 ( 1.403)	Data  0.001 ( 0.304)	Loss 1.7997e-01 (1.1238e-01) 
2023-05-25 01:48:10.697734: train Epoch: [19][ 48/193]	Time  1.945 ( 1.414)	Data  0.745 ( 0.313)	Loss 1.4837e-01 (1.1311e-01) 
2023-05-25 01:48:11.699045: train Epoch: [19][ 49/193]	Time  1.001 ( 1.406)	Data  0.001 ( 0.307)	Loss 7.8849e-02 (1.1243e-01) 
2023-05-25 01:48:13.339051: train Epoch: [19][ 50/193]	Time  1.640 ( 1.410)	Data  0.457 ( 0.310)	Loss 1.2399e-01 (1.1265e-01) 
2023-05-25 01:48:14.340429: train Epoch: [19][ 51/193]	Time  1.001 ( 1.402)	Data  0.001 ( 0.304)	Loss 8.4528e-02 (1.1211e-01) 
2023-05-25 01:48:16.016539: train Epoch: [19][ 52/193]	Time  1.676 ( 1.407)	Data  0.500 ( 0.308)	Loss 8.0509e-02 (1.1152e-01) 
2023-05-25 01:48:17.160009: train Epoch: [19][ 53/193]	Time  1.143 ( 1.403)	Data  0.001 ( 0.302)	Loss 8.8930e-02 (1.1110e-01) 
2023-05-25 01:48:18.585083: train Epoch: [19][ 54/193]	Time  1.425 ( 1.403)	Data  0.364 ( 0.303)	Loss 1.3352e-01 (1.1151e-01) 
2023-05-25 01:48:19.803059: train Epoch: [19][ 55/193]	Time  1.218 ( 1.400)	Data  0.001 ( 0.298)	Loss 1.5770e-01 (1.1233e-01) 
2023-05-25 01:48:21.469837: train Epoch: [19][ 56/193]	Time  1.667 ( 1.404)	Data  0.519 ( 0.302)	Loss 1.7284e-01 (1.1339e-01) 
2023-05-25 01:48:22.544626: train Epoch: [19][ 57/193]	Time  1.075 ( 1.399)	Data  0.001 ( 0.297)	Loss 9.6856e-02 (1.1311e-01) 
2023-05-25 01:48:24.050995: train Epoch: [19][ 58/193]	Time  1.506 ( 1.401)	Data  0.481 ( 0.300)	Loss 1.9761e-01 (1.1454e-01) 
2023-05-25 01:48:25.026120: train Epoch: [19][ 59/193]	Time  0.975 ( 1.393)	Data  0.001 ( 0.295)	Loss 1.1353e-01 (1.1452e-01) 
2023-05-25 01:48:26.960336: train Epoch: [19][ 60/193]	Time  1.934 ( 1.402)	Data  0.718 ( 0.302)	Loss 7.2017e-02 (1.1383e-01) 
2023-05-25 01:48:27.966688: train Epoch: [19][ 61/193]	Time  1.006 ( 1.396)	Data  0.001 ( 0.297)	Loss 1.4000e-01 (1.1425e-01) 
2023-05-25 01:48:29.645194: train Epoch: [19][ 62/193]	Time  1.679 ( 1.400)	Data  0.458 ( 0.299)	Loss 6.3644e-02 (1.1345e-01) 
2023-05-25 01:48:30.701220: train Epoch: [19][ 63/193]	Time  1.056 ( 1.395)	Data  0.001 ( 0.295)	Loss 6.5919e-02 (1.1270e-01) 
2023-05-25 01:48:32.349909: train Epoch: [19][ 64/193]	Time  1.649 ( 1.399)	Data  0.406 ( 0.296)	Loss 1.5855e-01 (1.1341e-01) 
2023-05-25 01:48:33.624473: train Epoch: [19][ 65/193]	Time  1.275 ( 1.397)	Data  0.001 ( 0.292)	Loss 9.6619e-02 (1.1315e-01) 
2023-05-25 01:48:34.866079: train Epoch: [19][ 66/193]	Time  1.242 ( 1.395)	Data  0.169 ( 0.290)	Loss 1.7833e-01 (1.1413e-01) 
2023-05-25 01:48:36.047741: train Epoch: [19][ 67/193]	Time  1.182 ( 1.392)	Data  0.001 ( 0.286)	Loss 6.0030e-02 (1.1333e-01) 
2023-05-25 01:48:37.502368: train Epoch: [19][ 68/193]	Time  1.455 ( 1.393)	Data  0.384 ( 0.287)	Loss 6.7716e-02 (1.1267e-01) 
2023-05-25 01:48:38.755698: train Epoch: [19][ 69/193]	Time  1.253 ( 1.391)	Data  0.002 ( 0.283)	Loss 1.0813e-01 (1.1260e-01) 
2023-05-25 01:48:40.127784: train Epoch: [19][ 70/193]	Time  1.372 ( 1.390)	Data  0.362 ( 0.284)	Loss 8.8024e-02 (1.1226e-01) 
2023-05-25 01:48:41.187289: train Epoch: [19][ 71/193]	Time  1.060 ( 1.386)	Data  0.001 ( 0.280)	Loss 7.9049e-02 (1.1180e-01) 
2023-05-25 01:48:42.960630: train Epoch: [19][ 72/193]	Time  1.773 ( 1.391)	Data  0.616 ( 0.285)	Loss 5.7811e-02 (1.1106e-01) 
2023-05-25 01:48:43.986728: train Epoch: [19][ 73/193]	Time  1.026 ( 1.386)	Data  0.001 ( 0.281)	Loss 7.8016e-02 (1.1061e-01) 
2023-05-25 01:48:45.580644: train Epoch: [19][ 74/193]	Time  1.594 ( 1.389)	Data  0.439 ( 0.283)	Loss 8.7900e-02 (1.1031e-01) 
2023-05-25 01:48:46.508962: train Epoch: [19][ 75/193]	Time  0.928 ( 1.383)	Data  0.001 ( 0.280)	Loss 6.1046e-02 (1.0966e-01) 
2023-05-25 01:48:48.298526: train Epoch: [19][ 76/193]	Time  1.790 ( 1.388)	Data  0.559 ( 0.283)	Loss 6.6213e-02 (1.0910e-01) 
2023-05-25 01:48:49.447740: train Epoch: [19][ 77/193]	Time  1.149 ( 1.385)	Data  0.001 ( 0.280)	Loss 6.1978e-02 (1.0849e-01) 
2023-05-25 01:48:51.029079: train Epoch: [19][ 78/193]	Time  1.581 ( 1.387)	Data  0.335 ( 0.280)	Loss 1.8950e-01 (1.0952e-01) 
2023-05-25 01:48:52.320035: train Epoch: [19][ 79/193]	Time  1.291 ( 1.386)	Data  0.001 ( 0.277)	Loss 7.5992e-02 (1.0910e-01) 
2023-05-25 01:48:53.567411: train Epoch: [19][ 80/193]	Time  1.247 ( 1.385)	Data  0.224 ( 0.276)	Loss 1.9956e-01 (1.1022e-01) 
2023-05-25 01:48:54.674624: train Epoch: [19][ 81/193]	Time  1.107 ( 1.381)	Data  0.001 ( 0.273)	Loss 8.2092e-02 (1.0987e-01) 
2023-05-25 01:48:56.231815: train Epoch: [19][ 82/193]	Time  1.557 ( 1.383)	Data  0.573 ( 0.276)	Loss 1.6676e-01 (1.1056e-01) 
2023-05-25 01:48:57.319535: train Epoch: [19][ 83/193]	Time  1.088 ( 1.380)	Data  0.001 ( 0.273)	Loss 1.3743e-01 (1.1088e-01) 
2023-05-25 01:48:58.994353: train Epoch: [19][ 84/193]	Time  1.675 ( 1.383)	Data  0.588 ( 0.277)	Loss 8.5611e-02 (1.1058e-01) 
2023-05-25 01:48:59.937466: train Epoch: [19][ 85/193]	Time  0.943 ( 1.378)	Data  0.001 ( 0.274)	Loss 8.2568e-02 (1.1025e-01) 
2023-05-25 01:49:01.756313: train Epoch: [19][ 86/193]	Time  1.819 ( 1.383)	Data  0.619 ( 0.278)	Loss 1.7571e-01 (1.1101e-01) 
2023-05-25 01:49:02.816704: train Epoch: [19][ 87/193]	Time  1.060 ( 1.380)	Data  0.001 ( 0.274)	Loss 2.1267e-01 (1.1216e-01) 
2023-05-25 01:49:04.550545: train Epoch: [19][ 88/193]	Time  1.734 ( 1.383)	Data  0.471 ( 0.277)	Loss 9.6379e-02 (1.1198e-01) 
2023-05-25 01:49:05.645219: train Epoch: [19][ 89/193]	Time  1.095 ( 1.380)	Data  0.001 ( 0.274)	Loss 5.2371e-02 (1.1132e-01) 
2023-05-25 01:49:07.126804: train Epoch: [19][ 90/193]	Time  1.482 ( 1.381)	Data  0.346 ( 0.274)	Loss 9.7794e-02 (1.1117e-01) 
2023-05-25 01:49:08.273224: train Epoch: [19][ 91/193]	Time  1.146 ( 1.379)	Data  0.001 ( 0.271)	Loss 7.9121e-02 (1.1083e-01) 
2023-05-25 01:49:09.572354: train Epoch: [19][ 92/193]	Time  1.299 ( 1.378)	Data  0.330 ( 0.272)	Loss 1.1127e-01 (1.1083e-01) 
2023-05-25 01:49:10.634820: train Epoch: [19][ 93/193]	Time  1.062 ( 1.375)	Data  0.001 ( 0.269)	Loss 9.0349e-02 (1.1061e-01) 
2023-05-25 01:49:12.249797: train Epoch: [19][ 94/193]	Time  1.615 ( 1.377)	Data  0.632 ( 0.273)	Loss 7.0495e-02 (1.1019e-01) 
2023-05-25 01:49:13.313237: train Epoch: [19][ 95/193]	Time  1.063 ( 1.374)	Data  0.001 ( 0.270)	Loss 5.8180e-02 (1.0965e-01) 
2023-05-25 01:49:15.119382: train Epoch: [19][ 96/193]	Time  1.806 ( 1.378)	Data  0.599 ( 0.273)	Loss 7.1247e-02 (1.0925e-01) 
2023-05-25 01:49:16.087663: train Epoch: [19][ 97/193]	Time  0.968 ( 1.374)	Data  0.001 ( 0.271)	Loss 9.3710e-02 (1.0909e-01) 
2023-05-25 01:49:17.895648: train Epoch: [19][ 98/193]	Time  1.808 ( 1.379)	Data  0.519 ( 0.273)	Loss 6.8055e-02 (1.0868e-01) 
2023-05-25 01:49:18.968412: train Epoch: [19][ 99/193]	Time  1.073 ( 1.375)	Data  0.001 ( 0.271)	Loss 1.0345e-01 (1.0863e-01) 
2023-05-25 01:49:20.341428: train Epoch: [19][100/193]	Time  1.373 ( 1.375)	Data  0.356 ( 0.271)	Loss 1.2413e-01 (1.0878e-01) 
2023-05-25 01:49:21.233539: train Epoch: [19][101/193]	Time  0.892 ( 1.371)	Data  0.001 ( 0.269)	Loss 1.2359e-01 (1.0893e-01) 
2023-05-25 01:49:23.047157: train Epoch: [19][102/193]	Time  1.814 ( 1.375)	Data  0.810 ( 0.274)	Loss 1.3244e-01 (1.0915e-01) 
2023-05-25 01:49:24.111514: train Epoch: [19][103/193]	Time  1.064 ( 1.372)	Data  0.002 ( 0.271)	Loss 1.4062e-01 (1.0946e-01) 
2023-05-25 01:49:25.937284: train Epoch: [19][104/193]	Time  1.826 ( 1.376)	Data  0.632 ( 0.275)	Loss 1.1439e-01 (1.0950e-01) 
2023-05-25 01:49:27.251301: train Epoch: [19][105/193]	Time  1.314 ( 1.376)	Data  0.001 ( 0.272)	Loss 1.3758e-01 (1.0977e-01) 
2023-05-25 01:49:28.345367: train Epoch: [19][106/193]	Time  1.094 ( 1.373)	Data  0.127 ( 0.271)	Loss 7.9685e-02 (1.0949e-01) 
2023-05-25 01:49:29.382552: train Epoch: [19][107/193]	Time  1.037 ( 1.370)	Data  0.001 ( 0.268)	Loss 7.8899e-02 (1.0920e-01) 
2023-05-25 01:49:31.071602: train Epoch: [19][108/193]	Time  1.689 ( 1.373)	Data  0.621 ( 0.272)	Loss 1.4675e-01 (1.0955e-01) 
2023-05-25 01:49:32.175679: train Epoch: [19][109/193]	Time  1.104 ( 1.371)	Data  0.002 ( 0.269)	Loss 9.1403e-02 (1.0938e-01) 
2023-05-25 01:49:34.112253: train Epoch: [19][110/193]	Time  1.937 ( 1.376)	Data  0.464 ( 0.271)	Loss 8.9602e-02 (1.0921e-01) 
2023-05-25 01:49:35.249804: train Epoch: [19][111/193]	Time  1.138 ( 1.373)	Data  0.001 ( 0.268)	Loss 2.5142e-01 (1.1047e-01) 
2023-05-25 01:49:36.298158: train Epoch: [19][112/193]	Time  1.048 ( 1.371)	Data  0.001 ( 0.266)	Loss 8.9360e-02 (1.1029e-01) 
2023-05-25 01:49:37.458583: train Epoch: [19][113/193]	Time  1.160 ( 1.369)	Data  0.002 ( 0.264)	Loss 5.8932e-02 (1.0984e-01) 
2023-05-25 01:49:39.085621: train Epoch: [19][114/193]	Time  1.627 ( 1.371)	Data  0.498 ( 0.266)	Loss 1.5472e-01 (1.1023e-01) 
2023-05-25 01:49:40.419411: train Epoch: [19][115/193]	Time  1.334 ( 1.371)	Data  0.001 ( 0.264)	Loss 1.4204e-01 (1.1050e-01) 
2023-05-25 01:49:41.790747: train Epoch: [19][116/193]	Time  1.371 ( 1.371)	Data  0.264 ( 0.264)	Loss 9.3342e-02 (1.1036e-01) 
2023-05-25 01:49:42.848076: train Epoch: [19][117/193]	Time  1.057 ( 1.368)	Data  0.001 ( 0.261)	Loss 6.0797e-02 (1.0994e-01) 
2023-05-25 01:49:44.360796: train Epoch: [19][118/193]	Time  1.513 ( 1.369)	Data  0.468 ( 0.263)	Loss 1.0579e-01 (1.0990e-01) 
2023-05-25 01:49:45.427678: train Epoch: [19][119/193]	Time  1.067 ( 1.367)	Data  0.001 ( 0.261)	Loss 1.2223e-01 (1.1000e-01) 
2023-05-25 01:49:47.121195: train Epoch: [19][120/193]	Time  1.694 ( 1.369)	Data  0.597 ( 0.264)	Loss 1.2394e-01 (1.1012e-01) 
2023-05-25 01:49:48.126145: train Epoch: [19][121/193]	Time  1.005 ( 1.366)	Data  0.001 ( 0.261)	Loss 7.5574e-02 (1.0984e-01) 
2023-05-25 01:49:50.014113: train Epoch: [19][122/193]	Time  1.888 ( 1.371)	Data  0.586 ( 0.264)	Loss 1.4622e-01 (1.1013e-01) 
2023-05-25 01:49:50.994441: train Epoch: [19][123/193]	Time  0.980 ( 1.368)	Data  0.001 ( 0.262)	Loss 1.4457e-01 (1.1041e-01) 
2023-05-25 01:49:52.737027: train Epoch: [19][124/193]	Time  1.743 ( 1.371)	Data  0.382 ( 0.263)	Loss 1.0652e-01 (1.1038e-01) 
2023-05-25 01:49:53.689048: train Epoch: [19][125/193]	Time  0.952 ( 1.367)	Data  0.001 ( 0.261)	Loss 1.1316e-01 (1.1040e-01) 
2023-05-25 01:49:55.377955: train Epoch: [19][126/193]	Time  1.689 ( 1.370)	Data  0.407 ( 0.262)	Loss 1.2258e-01 (1.1050e-01) 
2023-05-25 01:49:56.436292: train Epoch: [19][127/193]	Time  1.058 ( 1.367)	Data  0.001 ( 0.260)	Loss 1.2913e-01 (1.1064e-01) 
2023-05-25 01:49:57.936203: train Epoch: [19][128/193]	Time  1.500 ( 1.368)	Data  0.413 ( 0.261)	Loss 6.3881e-02 (1.1028e-01) 
2023-05-25 01:49:59.201118: train Epoch: [19][129/193]	Time  1.265 ( 1.368)	Data  0.001 ( 0.259)	Loss 6.3976e-02 (1.0992e-01) 
2023-05-25 01:50:00.617140: train Epoch: [19][130/193]	Time  1.416 ( 1.368)	Data  0.343 ( 0.260)	Loss 9.2919e-02 (1.0979e-01) 
2023-05-25 01:50:01.866754: train Epoch: [19][131/193]	Time  1.250 ( 1.367)	Data  0.001 ( 0.258)	Loss 9.9082e-02 (1.0971e-01) 
2023-05-25 01:50:03.238137: train Epoch: [19][132/193]	Time  1.371 ( 1.367)	Data  0.322 ( 0.258)	Loss 1.7661e-01 (1.1021e-01) 
2023-05-25 01:50:04.358739: train Epoch: [19][133/193]	Time  1.121 ( 1.365)	Data  0.001 ( 0.256)	Loss 6.4256e-02 (1.0987e-01) 
2023-05-25 01:50:05.989928: train Epoch: [19][134/193]	Time  1.631 ( 1.367)	Data  0.462 ( 0.258)	Loss 9.6707e-02 (1.0977e-01) 
2023-05-25 01:50:07.012719: train Epoch: [19][135/193]	Time  1.023 ( 1.365)	Data  0.001 ( 0.256)	Loss 1.2837e-01 (1.0991e-01) 
2023-05-25 01:50:08.861563: train Epoch: [19][136/193]	Time  1.849 ( 1.368)	Data  0.490 ( 0.258)	Loss 6.2053e-02 (1.0956e-01) 
2023-05-25 01:50:09.932515: train Epoch: [19][137/193]	Time  1.071 ( 1.366)	Data  0.001 ( 0.256)	Loss 8.3700e-02 (1.0937e-01) 
2023-05-25 01:50:11.382813: train Epoch: [19][138/193]	Time  1.450 ( 1.367)	Data  0.298 ( 0.256)	Loss 9.4446e-02 (1.0927e-01) 
2023-05-25 01:50:12.545727: train Epoch: [19][139/193]	Time  1.163 ( 1.365)	Data  0.001 ( 0.254)	Loss 1.2133e-01 (1.0935e-01) 
2023-05-25 01:50:14.246962: train Epoch: [19][140/193]	Time  1.701 ( 1.368)	Data  0.381 ( 0.255)	Loss 8.9364e-02 (1.0921e-01) 
2023-05-25 01:50:15.484827: train Epoch: [19][141/193]	Time  1.238 ( 1.367)	Data  0.001 ( 0.253)	Loss 2.2623e-01 (1.1004e-01) 
2023-05-25 01:50:16.648926: train Epoch: [19][142/193]	Time  1.164 ( 1.365)	Data  0.137 ( 0.253)	Loss 8.5974e-02 (1.0987e-01) 
2023-05-25 01:50:17.675186: train Epoch: [19][143/193]	Time  1.026 ( 1.363)	Data  0.001 ( 0.251)	Loss 1.4026e-01 (1.1008e-01) 
2023-05-25 01:50:19.319370: train Epoch: [19][144/193]	Time  1.644 ( 1.365)	Data  0.644 ( 0.254)	Loss 2.4273e-01 (1.1099e-01) 
2023-05-25 01:50:20.291376: train Epoch: [19][145/193]	Time  0.972 ( 1.362)	Data  0.001 ( 0.252)	Loss 8.9053e-02 (1.1084e-01) 
2023-05-25 01:50:22.062996: train Epoch: [19][146/193]	Time  1.772 ( 1.365)	Data  0.688 ( 0.255)	Loss 7.6329e-02 (1.1061e-01) 
2023-05-25 01:50:23.043587: train Epoch: [19][147/193]	Time  0.981 ( 1.362)	Data  0.001 ( 0.253)	Loss 9.5275e-02 (1.1050e-01) 
2023-05-25 01:50:24.688780: train Epoch: [19][148/193]	Time  1.645 ( 1.364)	Data  0.575 ( 0.255)	Loss 6.6072e-02 (1.1021e-01) 
2023-05-25 01:50:25.803895: train Epoch: [19][149/193]	Time  1.115 ( 1.363)	Data  0.001 ( 0.254)	Loss 6.9733e-02 (1.0994e-01) 
2023-05-25 01:50:27.525960: train Epoch: [19][150/193]	Time  1.722 ( 1.365)	Data  0.528 ( 0.255)	Loss 1.0639e-01 (1.0991e-01) 
2023-05-25 01:50:28.703632: train Epoch: [19][151/193]	Time  1.178 ( 1.364)	Data  0.001 ( 0.254)	Loss 2.1428e-01 (1.1060e-01) 
2023-05-25 01:50:30.110455: train Epoch: [19][152/193]	Time  1.407 ( 1.364)	Data  0.342 ( 0.254)	Loss 7.6597e-02 (1.1038e-01) 
2023-05-25 01:50:31.383018: train Epoch: [19][153/193]	Time  1.273 ( 1.363)	Data  0.001 ( 0.253)	Loss 8.7995e-02 (1.1023e-01) 
2023-05-25 01:50:32.805264: train Epoch: [19][154/193]	Time  1.422 ( 1.364)	Data  0.309 ( 0.253)	Loss 5.2666e-02 (1.0986e-01) 
2023-05-25 01:50:34.037576: train Epoch: [19][155/193]	Time  1.232 ( 1.363)	Data  0.001 ( 0.251)	Loss 9.4105e-02 (1.0976e-01) 
2023-05-25 01:50:35.448536: train Epoch: [19][156/193]	Time  1.411 ( 1.363)	Data  0.375 ( 0.252)	Loss 9.6168e-02 (1.0967e-01) 
2023-05-25 01:50:36.605061: train Epoch: [19][157/193]	Time  1.157 ( 1.362)	Data  0.002 ( 0.251)	Loss 1.5724e-01 (1.0997e-01) 
2023-05-25 01:50:38.122497: train Epoch: [19][158/193]	Time  1.517 ( 1.363)	Data  0.537 ( 0.252)	Loss 1.4375e-01 (1.1019e-01) 
2023-05-25 01:50:39.142440: train Epoch: [19][159/193]	Time  1.020 ( 1.361)	Data  0.001 ( 0.251)	Loss 8.5368e-02 (1.1003e-01) 
2023-05-25 01:50:41.022280: train Epoch: [19][160/193]	Time  1.880 ( 1.364)	Data  0.763 ( 0.254)	Loss 1.5428e-01 (1.1031e-01) 
2023-05-25 01:50:41.990704: train Epoch: [19][161/193]	Time  0.968 ( 1.362)	Data  0.001 ( 0.252)	Loss 8.4999e-02 (1.1015e-01) 
2023-05-25 01:50:43.888007: train Epoch: [19][162/193]	Time  1.897 ( 1.365)	Data  0.668 ( 0.255)	Loss 9.6858e-02 (1.1007e-01) 
2023-05-25 01:50:44.868523: train Epoch: [19][163/193]	Time  0.980 ( 1.362)	Data  0.001 ( 0.253)	Loss 1.2023e-01 (1.1013e-01) 
2023-05-25 01:50:46.626178: train Epoch: [19][164/193]	Time  1.758 ( 1.365)	Data  0.520 ( 0.255)	Loss 7.7827e-02 (1.0993e-01) 
2023-05-25 01:50:47.589278: train Epoch: [19][165/193]	Time  0.963 ( 1.362)	Data  0.001 ( 0.254)	Loss 6.2343e-02 (1.0965e-01) 
2023-05-25 01:50:49.239280: train Epoch: [19][166/193]	Time  1.650 ( 1.364)	Data  0.508 ( 0.255)	Loss 8.9724e-02 (1.0953e-01) 
2023-05-25 01:50:50.259867: train Epoch: [19][167/193]	Time  1.021 ( 1.362)	Data  0.001 ( 0.254)	Loss 8.2618e-02 (1.0937e-01) 
2023-05-25 01:50:52.015123: train Epoch: [19][168/193]	Time  1.755 ( 1.364)	Data  0.655 ( 0.256)	Loss 8.3906e-02 (1.0922e-01) 
2023-05-25 01:50:53.087069: train Epoch: [19][169/193]	Time  1.072 ( 1.363)	Data  0.001 ( 0.254)	Loss 8.5331e-02 (1.0908e-01) 
2023-05-25 01:50:54.703186: train Epoch: [19][170/193]	Time  1.616 ( 1.364)	Data  0.523 ( 0.256)	Loss 1.3712e-01 (1.0924e-01) 
2023-05-25 01:50:55.845162: train Epoch: [19][171/193]	Time  1.142 ( 1.363)	Data  0.002 ( 0.255)	Loss 1.1183e-01 (1.0926e-01) 
2023-05-25 01:50:57.601281: train Epoch: [19][172/193]	Time  1.756 ( 1.365)	Data  0.569 ( 0.256)	Loss 9.5781e-02 (1.0918e-01) 
2023-05-25 01:50:58.614830: train Epoch: [19][173/193]	Time  1.014 ( 1.363)	Data  0.001 ( 0.255)	Loss 9.3688e-02 (1.0909e-01) 
2023-05-25 01:51:00.352065: train Epoch: [19][174/193]	Time  1.737 ( 1.365)	Data  0.546 ( 0.257)	Loss 8.0075e-02 (1.0892e-01) 
2023-05-25 01:51:01.423399: train Epoch: [19][175/193]	Time  1.071 ( 1.364)	Data  0.001 ( 0.255)	Loss 1.2820e-01 (1.0903e-01) 
2023-05-25 01:51:03.258854: train Epoch: [19][176/193]	Time  1.835 ( 1.366)	Data  0.487 ( 0.256)	Loss 7.2469e-02 (1.0883e-01) 
2023-05-25 01:51:04.254200: train Epoch: [19][177/193]	Time  0.995 ( 1.364)	Data  0.001 ( 0.255)	Loss 5.1769e-02 (1.0851e-01) 
2023-05-25 01:51:05.759354: train Epoch: [19][178/193]	Time  1.505 ( 1.365)	Data  0.392 ( 0.256)	Loss 7.0690e-02 (1.0829e-01) 
2023-05-25 01:51:06.710829: train Epoch: [19][179/193]	Time  0.951 ( 1.363)	Data  0.001 ( 0.254)	Loss 7.1531e-02 (1.0809e-01) 
2023-05-25 01:51:08.911076: train Epoch: [19][180/193]	Time  2.200 ( 1.367)	Data  0.842 ( 0.258)	Loss 1.1019e-01 (1.0810e-01) 
2023-05-25 01:51:09.871117: train Epoch: [19][181/193]	Time  0.960 ( 1.365)	Data  0.001 ( 0.256)	Loss 9.1160e-02 (1.0801e-01) 
2023-05-25 01:51:11.291577: train Epoch: [19][182/193]	Time  1.420 ( 1.365)	Data  0.377 ( 0.257)	Loss 8.3739e-02 (1.0788e-01) 
2023-05-25 01:51:12.638134: train Epoch: [19][183/193]	Time  1.347 ( 1.365)	Data  0.001 ( 0.255)	Loss 1.2193e-01 (1.0795e-01) 
2023-05-25 01:51:13.973166: train Epoch: [19][184/193]	Time  1.335 ( 1.365)	Data  0.322 ( 0.256)	Loss 7.7980e-02 (1.0779e-01) 
2023-05-25 01:51:15.000720: train Epoch: [19][185/193]	Time  1.028 ( 1.363)	Data  0.001 ( 0.254)	Loss 1.0855e-01 (1.0779e-01) 
2023-05-25 01:51:16.731586: train Epoch: [19][186/193]	Time  1.731 ( 1.365)	Data  0.702 ( 0.257)	Loss 1.0950e-01 (1.0780e-01) 
2023-05-25 01:51:17.754519: train Epoch: [19][187/193]	Time  1.023 ( 1.363)	Data  0.001 ( 0.255)	Loss 3.2448e-01 (1.0896e-01) 
2023-05-25 01:51:19.403124: train Epoch: [19][188/193]	Time  1.649 ( 1.365)	Data  0.643 ( 0.258)	Loss 1.5073e-01 (1.0918e-01) 
2023-05-25 01:51:20.363948: train Epoch: [19][189/193]	Time  0.961 ( 1.363)	Data  0.001 ( 0.256)	Loss 1.1146e-01 (1.0919e-01) 
2023-05-25 01:51:22.193637: train Epoch: [19][190/193]	Time  1.830 ( 1.365)	Data  0.603 ( 0.258)	Loss 8.9408e-02 (1.0909e-01) 
2023-05-25 01:51:23.166460: train Epoch: [19][191/193]	Time  0.973 ( 1.363)	Data  0.001 ( 0.257)	Loss 5.3473e-02 (1.0880e-01) 
2023-05-25 01:51:24.212284: train Epoch: [19][192/193]	Time  1.046 ( 1.362)	Data  0.001 ( 0.255)	Loss 9.3620e-02 (1.0872e-01) 
2023-05-25 01:51:24.276418: Train Epoch done in 262.85767534701154 s 
2023-05-25 01:51:27.685048: val Epoch: [19][ 0/72]	Time  2.304 ( 2.304)	Data  1.759 ( 1.759)	Loss 3.5662e-01 (3.5662e-01) 
2023-05-25 01:51:27.882027: val Epoch: [19][ 1/72]	Time  0.197 ( 1.250)	Data  0.002 ( 0.880)	Loss 1.2136e-01 (2.3899e-01) 
2023-05-25 01:51:28.785276: val Epoch: [19][ 2/72]	Time  0.903 ( 1.135)	Data  0.600 ( 0.787)	Loss 1.2794e-01 (2.0197e-01) 
2023-05-25 01:51:29.082769: val Epoch: [19][ 3/72]	Time  0.297 ( 0.925)	Data  0.001 ( 0.591)	Loss 5.3377e-02 (1.6483e-01) 
2023-05-25 01:51:30.654309: val Epoch: [19][ 4/72]	Time  1.572 ( 1.055)	Data  0.809 ( 0.634)	Loss 6.6615e-02 (1.4518e-01) 
2023-05-25 01:51:30.973063: val Epoch: [19][ 5/72]	Time  0.319 ( 0.932)	Data  0.001 ( 0.529)	Loss 2.8836e-01 (1.6905e-01) 
2023-05-25 01:51:31.597033: val Epoch: [19][ 6/72]	Time  0.624 ( 0.888)	Data  0.311 ( 0.498)	Loss 1.2421e-01 (1.6264e-01) 
2023-05-25 01:51:31.849675: val Epoch: [19][ 7/72]	Time  0.253 ( 0.809)	Data  0.001 ( 0.436)	Loss 1.2027e-01 (1.5734e-01) 
2023-05-25 01:51:33.006240: val Epoch: [19][ 8/72]	Time  1.157 ( 0.847)	Data  0.842 ( 0.481)	Loss 1.4428e-01 (1.5589e-01) 
2023-05-25 01:51:33.304789: val Epoch: [19][ 9/72]	Time  0.299 ( 0.792)	Data  0.001 ( 0.433)	Loss 1.5159e-01 (1.5546e-01) 
2023-05-25 01:51:34.479617: val Epoch: [19][10/72]	Time  1.175 ( 0.827)	Data  0.814 ( 0.467)	Loss 1.6487e-01 (1.5632e-01) 
2023-05-25 01:51:35.001505: val Epoch: [19][11/72]	Time  0.522 ( 0.802)	Data  0.001 ( 0.429)	Loss 3.0433e-01 (1.6865e-01) 
2023-05-25 01:51:35.814214: val Epoch: [19][12/72]	Time  0.813 ( 0.803)	Data  0.449 ( 0.430)	Loss 6.4411e-02 (1.6063e-01) 
2023-05-25 01:51:36.155819: val Epoch: [19][13/72]	Time  0.342 ( 0.770)	Data  0.011 ( 0.400)	Loss 1.5960e-01 (1.6056e-01) 
2023-05-25 01:51:37.195917: val Epoch: [19][14/72]	Time  1.040 ( 0.788)	Data  0.633 ( 0.416)	Loss 6.6343e-02 (1.5428e-01) 
2023-05-25 01:51:37.617565: val Epoch: [19][15/72]	Time  0.422 ( 0.765)	Data  0.001 ( 0.390)	Loss 5.6536e-02 (1.4817e-01) 
2023-05-25 01:51:38.377357: val Epoch: [19][16/72]	Time  0.760 ( 0.764)	Data  0.521 ( 0.398)	Loss 6.2412e-02 (1.4313e-01) 
2023-05-25 01:51:38.679363: val Epoch: [19][17/72]	Time  0.302 ( 0.739)	Data  0.001 ( 0.376)	Loss 6.7819e-02 (1.3894e-01) 
2023-05-25 01:51:40.107418: val Epoch: [19][18/72]	Time  1.428 ( 0.775)	Data  0.875 ( 0.402)	Loss 5.7768e-02 (1.3467e-01) 
2023-05-25 01:51:40.424792: val Epoch: [19][19/72]	Time  0.317 ( 0.752)	Data  0.003 ( 0.382)	Loss 5.0585e-02 (1.3047e-01) 
2023-05-25 01:51:41.118903: val Epoch: [19][20/72]	Time  0.694 ( 0.749)	Data  0.462 ( 0.386)	Loss 9.4873e-02 (1.2877e-01) 
2023-05-25 01:51:41.512943: val Epoch: [19][21/72]	Time  0.394 ( 0.733)	Data  0.001 ( 0.368)	Loss 9.4487e-02 (1.2721e-01) 
2023-05-25 01:51:42.630890: val Epoch: [19][22/72]	Time  1.118 ( 0.750)	Data  0.687 ( 0.382)	Loss 1.0388e-01 (1.2620e-01) 
2023-05-25 01:51:42.821944: val Epoch: [19][23/72]	Time  0.191 ( 0.727)	Data  0.001 ( 0.366)	Loss 1.9855e-01 (1.2921e-01) 
2023-05-25 01:51:44.062204: val Epoch: [19][24/72]	Time  1.240 ( 0.747)	Data  0.760 ( 0.382)	Loss 1.2578e-01 (1.2907e-01) 
2023-05-25 01:51:44.411005: val Epoch: [19][25/72]	Time  0.349 ( 0.732)	Data  0.001 ( 0.367)	Loss 9.9315e-02 (1.2793e-01) 
2023-05-25 01:51:45.228365: val Epoch: [19][26/72]	Time  0.817 ( 0.735)	Data  0.560 ( 0.374)	Loss 5.0887e-02 (1.2508e-01) 
2023-05-25 01:51:45.486991: val Epoch: [19][27/72]	Time  0.259 ( 0.718)	Data  0.001 ( 0.361)	Loss 9.4776e-02 (1.2399e-01) 
2023-05-25 01:51:46.686556: val Epoch: [19][28/72]	Time  1.200 ( 0.735)	Data  0.877 ( 0.379)	Loss 1.2491e-01 (1.2403e-01) 
2023-05-25 01:51:46.878499: val Epoch: [19][29/72]	Time  0.192 ( 0.717)	Data  0.001 ( 0.366)	Loss 1.2190e-01 (1.2396e-01) 
2023-05-25 01:51:48.020605: val Epoch: [19][30/72]	Time  1.142 ( 0.730)	Data  0.841 ( 0.382)	Loss 7.0895e-02 (1.2224e-01) 
2023-05-25 01:51:48.631377: val Epoch: [19][31/72]	Time  0.611 ( 0.727)	Data  0.001 ( 0.370)	Loss 2.0664e-01 (1.2488e-01) 
2023-05-25 01:51:49.636901: val Epoch: [19][32/72]	Time  1.006 ( 0.735)	Data  0.471 ( 0.373)	Loss 1.0997e-01 (1.2443e-01) 
2023-05-25 01:51:49.977290: val Epoch: [19][33/72]	Time  0.340 ( 0.723)	Data  0.001 ( 0.362)	Loss 6.7632e-02 (1.2276e-01) 
2023-05-25 01:51:50.714035: val Epoch: [19][34/72]	Time  0.736 ( 0.724)	Data  0.481 ( 0.365)	Loss 5.5488e-02 (1.2084e-01) 
2023-05-25 01:51:51.080568: val Epoch: [19][35/72]	Time  0.368 ( 0.714)	Data  0.002 ( 0.355)	Loss 3.4298e-01 (1.2701e-01) 
2023-05-25 01:51:52.270081: val Epoch: [19][36/72]	Time  1.189 ( 0.727)	Data  0.789 ( 0.367)	Loss 2.9127e-01 (1.3145e-01) 
2023-05-25 01:51:52.689407: val Epoch: [19][37/72]	Time  0.419 ( 0.719)	Data  0.001 ( 0.357)	Loss 1.7895e-01 (1.3270e-01) 
2023-05-25 01:51:53.600421: val Epoch: [19][38/72]	Time  0.911 ( 0.724)	Data  0.527 ( 0.362)	Loss 9.5901e-02 (1.3175e-01) 
2023-05-25 01:51:53.799800: val Epoch: [19][39/72]	Time  0.199 ( 0.710)	Data  0.001 ( 0.353)	Loss 1.1627e-01 (1.3137e-01) 
2023-05-25 01:51:54.808394: val Epoch: [19][40/72]	Time  1.009 ( 0.718)	Data  0.765 ( 0.363)	Loss 7.2712e-02 (1.2994e-01) 
2023-05-25 01:51:55.135048: val Epoch: [19][41/72]	Time  0.327 ( 0.708)	Data  0.001 ( 0.354)	Loss 4.3201e-01 (1.3713e-01) 
2023-05-25 01:51:56.320211: val Epoch: [19][42/72]	Time  1.185 ( 0.720)	Data  0.854 ( 0.366)	Loss 8.0498e-02 (1.3581e-01) 
2023-05-25 01:51:56.736935: val Epoch: [19][43/72]	Time  0.417 ( 0.713)	Data  0.001 ( 0.357)	Loss 1.0120e-01 (1.3502e-01) 
2023-05-25 01:51:57.788159: val Epoch: [19][44/72]	Time  1.051 ( 0.720)	Data  0.680 ( 0.365)	Loss 7.2113e-02 (1.3363e-01) 
2023-05-25 01:51:58.240286: val Epoch: [19][45/72]	Time  0.452 ( 0.714)	Data  0.001 ( 0.357)	Loss 1.8607e-01 (1.3477e-01) 
2023-05-25 01:51:59.534323: val Epoch: [19][46/72]	Time  1.294 ( 0.727)	Data  0.725 ( 0.365)	Loss 7.7384e-02 (1.3355e-01) 
2023-05-25 01:51:59.966485: val Epoch: [19][47/72]	Time  0.432 ( 0.721)	Data  0.001 ( 0.357)	Loss 1.4619e-01 (1.3381e-01) 
2023-05-25 01:52:00.606679: val Epoch: [19][48/72]	Time  0.640 ( 0.719)	Data  0.365 ( 0.357)	Loss 7.2435e-02 (1.3256e-01) 
2023-05-25 01:52:00.896094: val Epoch: [19][49/72]	Time  0.289 ( 0.710)	Data  0.001 ( 0.350)	Loss 5.2265e-02 (1.3095e-01) 
2023-05-25 01:52:02.279940: val Epoch: [19][50/72]	Time  1.384 ( 0.723)	Data  0.804 ( 0.359)	Loss 5.0507e-02 (1.2937e-01) 
2023-05-25 01:52:02.483656: val Epoch: [19][51/72]	Time  0.204 ( 0.714)	Data  0.002 ( 0.352)	Loss 3.1904e-01 (1.3302e-01) 
2023-05-25 01:52:03.385129: val Epoch: [19][52/72]	Time  0.901 ( 0.717)	Data  0.635 ( 0.357)	Loss 3.9834e-01 (1.3803e-01) 
2023-05-25 01:52:03.772213: val Epoch: [19][53/72]	Time  0.387 ( 0.711)	Data  0.005 ( 0.351)	Loss 4.5914e-01 (1.4397e-01) 
2023-05-25 01:52:04.767356: val Epoch: [19][54/72]	Time  0.995 ( 0.716)	Data  0.703 ( 0.357)	Loss 5.7952e-02 (1.4241e-01) 
2023-05-25 01:52:04.996780: val Epoch: [19][55/72]	Time  0.229 ( 0.707)	Data  0.001 ( 0.351)	Loss 1.5152e-01 (1.4257e-01) 
2023-05-25 01:52:06.417421: val Epoch: [19][56/72]	Time  1.421 ( 0.720)	Data  0.846 ( 0.360)	Loss 6.8962e-02 (1.4128e-01) 
2023-05-25 01:52:06.669434: val Epoch: [19][57/72]	Time  0.252 ( 0.712)	Data  0.002 ( 0.353)	Loss 4.5831e-02 (1.3963e-01) 
2023-05-25 01:52:07.397031: val Epoch: [19][58/72]	Time  0.728 ( 0.712)	Data  0.527 ( 0.356)	Loss 6.7243e-02 (1.3841e-01) 
2023-05-25 01:52:07.935245: val Epoch: [19][59/72]	Time  0.538 ( 0.709)	Data  0.002 ( 0.350)	Loss 1.5036e-01 (1.3861e-01) 
2023-05-25 01:52:08.862685: val Epoch: [19][60/72]	Time  0.927 ( 0.713)	Data  0.642 ( 0.355)	Loss 8.5628e-02 (1.3774e-01) 
2023-05-25 01:52:09.180944: val Epoch: [19][61/72]	Time  0.318 ( 0.706)	Data  0.001 ( 0.350)	Loss 7.7164e-02 (1.3676e-01) 
2023-05-25 01:52:10.359783: val Epoch: [19][62/72]	Time  1.179 ( 0.714)	Data  0.819 ( 0.357)	Loss 1.5751e-01 (1.3709e-01) 
2023-05-25 01:52:10.604719: val Epoch: [19][63/72]	Time  0.245 ( 0.707)	Data  0.001 ( 0.351)	Loss 6.1323e-02 (1.3591e-01) 
2023-05-25 01:52:11.621109: val Epoch: [19][64/72]	Time  1.016 ( 0.711)	Data  0.732 ( 0.357)	Loss 6.1711e-02 (1.3477e-01) 
2023-05-25 01:52:11.800336: val Epoch: [19][65/72]	Time  0.179 ( 0.703)	Data  0.001 ( 0.352)	Loss 6.3626e-01 (1.4236e-01) 
2023-05-25 01:52:13.201048: val Epoch: [19][66/72]	Time  1.401 ( 0.714)	Data  0.918 ( 0.360)	Loss 5.9954e-02 (1.4113e-01) 
2023-05-25 01:52:13.557601: val Epoch: [19][67/72]	Time  0.357 ( 0.708)	Data  0.004 ( 0.355)	Loss 5.0414e-01 (1.4647e-01) 
2023-05-25 01:52:14.501951: val Epoch: [19][68/72]	Time  0.944 ( 0.712)	Data  0.509 ( 0.357)	Loss 1.3896e-01 (1.4636e-01) 
2023-05-25 01:52:14.735922: val Epoch: [19][69/72]	Time  0.234 ( 0.705)	Data  0.001 ( 0.352)	Loss 2.2537e-01 (1.4749e-01) 
2023-05-25 01:52:15.583014: val Epoch: [19][70/72]	Time  0.847 ( 0.707)	Data  0.632 ( 0.356)	Loss 1.5057e-01 (1.4754e-01) 
2023-05-25 01:52:15.933332: val Epoch: [19][71/72]	Time  0.350 ( 0.702)	Data  0.001 ( 0.351)	Loss 7.4789e-02 (1.4653e-01) 
2023-05-25 01:52:16.217058: Epoch 19 :Val : ['ET : 0.7374629974365234', 'TC : 0.7607839107513428', 'WT : 0.8402370810508728'] 
2023-05-25 01:52:16.222705: Epoch 19 :Val : ['ET : 0.7374629974365234', 'TC : 0.7607839107513428', 'WT : 0.8402370810508728'] 
2023-05-25 01:52:16.228655: Saving the model with DSC 0.7747467756271362 
2023-05-25 01:52:17.345414: Val epoch done in 53.06899125489872 s 
2023-05-25 01:52:17.362820: Batches per epoch:  193 
2023-05-25 01:52:21.994546: train Epoch: [20][  0/193]	Time  4.631 ( 4.631)	Data  3.125 ( 3.125)	Loss 1.5994e-01 (1.5994e-01) 
2023-05-25 01:52:23.084886: train Epoch: [20][  1/193]	Time  1.090 ( 2.861)	Data  0.001 ( 1.563)	Loss 1.3420e-01 (1.4707e-01) 
2023-05-25 01:52:24.255187: train Epoch: [20][  2/193]	Time  1.170 ( 2.297)	Data  0.075 ( 1.067)	Loss 2.1137e-01 (1.6851e-01) 
2023-05-25 01:52:25.247058: train Epoch: [20][  3/193]	Time  0.992 ( 1.971)	Data  0.001 ( 0.800)	Loss 6.5578e-02 (1.4277e-01) 
2023-05-25 01:52:26.940098: train Epoch: [20][  4/193]	Time  1.693 ( 1.915)	Data  0.546 ( 0.749)	Loss 1.2060e-01 (1.3834e-01) 
2023-05-25 01:52:28.154387: train Epoch: [20][  5/193]	Time  1.214 ( 1.799)	Data  0.001 ( 0.625)	Loss 1.0339e-01 (1.3251e-01) 
2023-05-25 01:52:29.630878: train Epoch: [20][  6/193]	Time  1.476 ( 1.753)	Data  0.427 ( 0.596)	Loss 9.0084e-02 (1.2645e-01) 
2023-05-25 01:52:30.776498: train Epoch: [20][  7/193]	Time  1.146 ( 1.677)	Data  0.001 ( 0.522)	Loss 5.3150e-02 (1.1729e-01) 
2023-05-25 01:52:32.378521: train Epoch: [20][  8/193]	Time  1.602 ( 1.668)	Data  0.488 ( 0.518)	Loss 1.8153e-01 (1.2443e-01) 
2023-05-25 01:52:33.353944: train Epoch: [20][  9/193]	Time  0.975 ( 1.599)	Data  0.001 ( 0.467)	Loss 7.6369e-02 (1.1962e-01) 
2023-05-25 01:52:34.912668: train Epoch: [20][ 10/193]	Time  1.559 ( 1.595)	Data  0.644 ( 0.483)	Loss 6.2510e-02 (1.1443e-01) 
2023-05-25 01:52:35.846505: train Epoch: [20][ 11/193]	Time  0.934 ( 1.540)	Data  0.001 ( 0.443)	Loss 8.4439e-02 (1.1193e-01) 
2023-05-25 01:52:37.824977: train Epoch: [20][ 12/193]	Time  1.978 ( 1.574)	Data  0.864 ( 0.475)	Loss 1.7464e-01 (1.1675e-01) 
2023-05-25 01:52:38.913287: train Epoch: [20][ 13/193]	Time  1.088 ( 1.539)	Data  0.001 ( 0.441)	Loss 1.3473e-01 (1.1804e-01) 
2023-05-25 01:52:40.582010: train Epoch: [20][ 14/193]	Time  1.669 ( 1.548)	Data  0.436 ( 0.441)	Loss 8.5857e-02 (1.1589e-01) 
2023-05-25 01:52:41.683715: train Epoch: [20][ 15/193]	Time  1.102 ( 1.520)	Data  0.001 ( 0.413)	Loss 7.3580e-02 (1.1325e-01) 
2023-05-25 01:52:43.084988: train Epoch: [20][ 16/193]	Time  1.401 ( 1.513)	Data  0.412 ( 0.413)	Loss 1.3199e-01 (1.1435e-01) 
2023-05-25 01:52:44.112827: train Epoch: [20][ 17/193]	Time  1.028 ( 1.486)	Data  0.001 ( 0.390)	Loss 2.8878e-01 (1.2404e-01) 
2023-05-25 01:52:45.900266: train Epoch: [20][ 18/193]	Time  1.787 ( 1.502)	Data  0.644 ( 0.404)	Loss 6.7497e-02 (1.2107e-01) 
2023-05-25 01:52:47.015859: train Epoch: [20][ 19/193]	Time  1.116 ( 1.483)	Data  0.001 ( 0.384)	Loss 1.1745e-01 (1.2088e-01) 
2023-05-25 01:52:48.725642: train Epoch: [20][ 20/193]	Time  1.710 ( 1.493)	Data  0.524 ( 0.390)	Loss 1.0826e-01 (1.2028e-01) 
2023-05-25 01:52:49.796044: train Epoch: [20][ 21/193]	Time  1.070 ( 1.474)	Data  0.002 ( 0.373)	Loss 1.2552e-01 (1.2052e-01) 
2023-05-25 01:52:51.184314: train Epoch: [20][ 22/193]	Time  1.388 ( 1.470)	Data  0.416 ( 0.374)	Loss 1.0436e-01 (1.1982e-01) 
2023-05-25 01:52:52.167207: train Epoch: [20][ 23/193]	Time  0.983 ( 1.450)	Data  0.002 ( 0.359)	Loss 8.0685e-02 (1.1819e-01) 
2023-05-25 01:52:53.844216: train Epoch: [20][ 24/193]	Time  1.677 ( 1.459)	Data  0.745 ( 0.374)	Loss 9.8940e-02 (1.1742e-01) 
2023-05-25 01:52:54.879468: train Epoch: [20][ 25/193]	Time  1.035 ( 1.443)	Data  0.001 ( 0.360)	Loss 5.3625e-02 (1.1496e-01) 
2023-05-25 01:52:56.896669: train Epoch: [20][ 26/193]	Time  2.017 ( 1.464)	Data  0.675 ( 0.372)	Loss 1.0343e-01 (1.1454e-01) 
2023-05-25 01:52:57.865845: train Epoch: [20][ 27/193]	Time  0.969 ( 1.447)	Data  0.001 ( 0.358)	Loss 3.3360e-02 (1.1164e-01) 
2023-05-25 01:52:59.486179: train Epoch: [20][ 28/193]	Time  1.620 ( 1.453)	Data  0.353 ( 0.358)	Loss 7.9598e-02 (1.1053e-01) 
2023-05-25 01:53:00.520328: train Epoch: [20][ 29/193]	Time  1.034 ( 1.439)	Data  0.001 ( 0.346)	Loss 1.3952e-01 (1.1150e-01) 
2023-05-25 01:53:01.994870: train Epoch: [20][ 30/193]	Time  1.474 ( 1.440)	Data  0.349 ( 0.346)	Loss 7.2387e-02 (1.1024e-01) 
2023-05-25 01:53:03.099666: train Epoch: [20][ 31/193]	Time  1.105 ( 1.429)	Data  0.001 ( 0.336)	Loss 1.0571e-01 (1.1010e-01) 
2023-05-25 01:53:04.648980: train Epoch: [20][ 32/193]	Time  1.549 ( 1.433)	Data  0.449 ( 0.339)	Loss 6.9815e-02 (1.0888e-01) 
2023-05-25 01:53:05.890294: train Epoch: [20][ 33/193]	Time  1.241 ( 1.427)	Data  0.001 ( 0.329)	Loss 5.1176e-02 (1.0718e-01) 
2023-05-25 01:53:07.377226: train Epoch: [20][ 34/193]	Time  1.487 ( 1.429)	Data  0.355 ( 0.330)	Loss 8.1855e-02 (1.0645e-01) 
2023-05-25 01:53:08.500190: train Epoch: [20][ 35/193]	Time  1.123 ( 1.420)	Data  0.001 ( 0.321)	Loss 1.1440e-01 (1.0668e-01) 
2023-05-25 01:53:10.103484: train Epoch: [20][ 36/193]	Time  1.603 ( 1.425)	Data  0.440 ( 0.324)	Loss 1.1584e-01 (1.0692e-01) 
2023-05-25 01:53:11.114055: train Epoch: [20][ 37/193]	Time  1.011 ( 1.414)	Data  0.001 ( 0.315)	Loss 8.3630e-02 (1.0631e-01) 
2023-05-25 01:53:12.565559: train Epoch: [20][ 38/193]	Time  1.451 ( 1.415)	Data  0.502 ( 0.320)	Loss 8.4337e-02 (1.0575e-01) 
2023-05-25 01:53:13.518539: train Epoch: [20][ 39/193]	Time  0.953 ( 1.404)	Data  0.001 ( 0.312)	Loss 9.2975e-02 (1.0543e-01) 
2023-05-25 01:53:15.445958: train Epoch: [20][ 40/193]	Time  1.927 ( 1.417)	Data  0.784 ( 0.324)	Loss 1.4115e-01 (1.0630e-01) 
2023-05-25 01:53:16.376915: train Epoch: [20][ 41/193]	Time  0.931 ( 1.405)	Data  0.001 ( 0.316)	Loss 7.5641e-02 (1.0557e-01) 
2023-05-25 01:53:18.312716: train Epoch: [20][ 42/193]	Time  1.936 ( 1.417)	Data  0.683 ( 0.325)	Loss 7.8520e-02 (1.0494e-01) 
2023-05-25 01:53:19.323241: train Epoch: [20][ 43/193]	Time  1.011 ( 1.408)	Data  0.001 ( 0.317)	Loss 2.5160e-01 (1.0827e-01) 
2023-05-25 01:53:20.824557: train Epoch: [20][ 44/193]	Time  1.501 ( 1.410)	Data  0.441 ( 0.320)	Loss 1.4252e-01 (1.0903e-01) 
2023-05-25 01:53:21.880418: train Epoch: [20][ 45/193]	Time  1.056 ( 1.403)	Data  0.001 ( 0.313)	Loss 9.6223e-02 (1.0876e-01) 
2023-05-25 01:53:23.733674: train Epoch: [20][ 46/193]	Time  1.853 ( 1.412)	Data  0.572 ( 0.319)	Loss 7.9071e-02 (1.0812e-01) 
2023-05-25 01:53:24.890800: train Epoch: [20][ 47/193]	Time  1.157 ( 1.407)	Data  0.001 ( 0.312)	Loss 9.7127e-02 (1.0789e-01) 
2023-05-25 01:53:26.167898: train Epoch: [20][ 48/193]	Time  1.277 ( 1.404)	Data  0.219 ( 0.310)	Loss 9.8950e-02 (1.0771e-01) 
2023-05-25 01:53:27.366329: train Epoch: [20][ 49/193]	Time  1.198 ( 1.400)	Data  0.001 ( 0.304)	Loss 1.2264e-01 (1.0801e-01) 
2023-05-25 01:53:29.160620: train Epoch: [20][ 50/193]	Time  1.794 ( 1.408)	Data  0.540 ( 0.309)	Loss 1.4022e-01 (1.0864e-01) 
2023-05-25 01:53:30.279902: train Epoch: [20][ 51/193]	Time  1.119 ( 1.402)	Data  0.001 ( 0.303)	Loss 1.0951e-01 (1.0866e-01) 
2023-05-25 01:53:31.863130: train Epoch: [20][ 52/193]	Time  1.583 ( 1.406)	Data  0.264 ( 0.302)	Loss 2.1326e-01 (1.1063e-01) 
2023-05-25 01:53:33.206961: train Epoch: [20][ 53/193]	Time  1.344 ( 1.405)	Data  0.001 ( 0.296)	Loss 1.1041e-01 (1.1063e-01) 
2023-05-25 01:53:34.286576: train Epoch: [20][ 54/193]	Time  1.080 ( 1.399)	Data  0.054 ( 0.292)	Loss 8.6414e-02 (1.1019e-01) 
2023-05-25 01:53:35.334587: train Epoch: [20][ 55/193]	Time  1.048 ( 1.392)	Data  0.001 ( 0.287)	Loss 9.9206e-02 (1.0999e-01) 
2023-05-25 01:53:36.898532: train Epoch: [20][ 56/193]	Time  1.564 ( 1.395)	Data  0.574 ( 0.292)	Loss 2.0557e-01 (1.1167e-01) 
2023-05-25 01:53:37.988500: train Epoch: [20][ 57/193]	Time  1.090 ( 1.390)	Data  0.001 ( 0.287)	Loss 7.9404e-02 (1.1111e-01) 
2023-05-25 01:53:39.745228: train Epoch: [20][ 58/193]	Time  1.757 ( 1.396)	Data  0.606 ( 0.292)	Loss 9.1663e-02 (1.1078e-01) 
2023-05-25 01:53:40.793717: train Epoch: [20][ 59/193]	Time  1.048 ( 1.391)	Data  0.001 ( 0.287)	Loss 9.2610e-02 (1.1048e-01) 
2023-05-25 01:53:42.486634: train Epoch: [20][ 60/193]	Time  1.693 ( 1.395)	Data  0.511 ( 0.291)	Loss 1.1638e-01 (1.1058e-01) 
2023-05-25 01:53:43.451395: train Epoch: [20][ 61/193]	Time  0.965 ( 1.389)	Data  0.001 ( 0.286)	Loss 3.4530e-01 (1.1436e-01) 
2023-05-25 01:53:45.251466: train Epoch: [20][ 62/193]	Time  1.800 ( 1.395)	Data  0.511 ( 0.290)	Loss 6.9398e-02 (1.1365e-01) 
2023-05-25 01:53:46.339214: train Epoch: [20][ 63/193]	Time  1.088 ( 1.390)	Data  0.001 ( 0.285)	Loss 1.0442e-01 (1.1350e-01) 
2023-05-25 01:53:47.821879: train Epoch: [20][ 64/193]	Time  1.483 ( 1.392)	Data  0.423 ( 0.287)	Loss 1.0543e-01 (1.1338e-01) 
2023-05-25 01:53:49.112744: train Epoch: [20][ 65/193]	Time  1.291 ( 1.390)	Data  0.001 ( 0.283)	Loss 9.1936e-02 (1.1306e-01) 
2023-05-25 01:53:50.521054: train Epoch: [20][ 66/193]	Time  1.408 ( 1.390)	Data  0.419 ( 0.285)	Loss 1.7922e-01 (1.1404e-01) 
2023-05-25 01:53:51.645146: train Epoch: [20][ 67/193]	Time  1.124 ( 1.386)	Data  0.001 ( 0.281)	Loss 1.1638e-01 (1.1408e-01) 
2023-05-25 01:53:53.303726: train Epoch: [20][ 68/193]	Time  1.659 ( 1.390)	Data  0.594 ( 0.286)	Loss 9.0887e-02 (1.1374e-01) 
2023-05-25 01:53:54.275812: train Epoch: [20][ 69/193]	Time  0.972 ( 1.384)	Data  0.001 ( 0.281)	Loss 7.9367e-02 (1.1325e-01) 
2023-05-25 01:53:55.854825: train Epoch: [20][ 70/193]	Time  1.579 ( 1.387)	Data  0.631 ( 0.286)	Loss 1.3880e-01 (1.1361e-01) 
2023-05-25 01:53:56.853262: train Epoch: [20][ 71/193]	Time  0.998 ( 1.382)	Data  0.001 ( 0.282)	Loss 9.6581e-02 (1.1337e-01) 
2023-05-25 01:53:58.892907: train Epoch: [20][ 72/193]	Time  2.040 ( 1.391)	Data  0.758 ( 0.289)	Loss 1.2654e-01 (1.1355e-01) 
2023-05-25 01:53:59.873832: train Epoch: [20][ 73/193]	Time  0.981 ( 1.385)	Data  0.001 ( 0.285)	Loss 5.4959e-02 (1.1276e-01) 
2023-05-25 01:54:01.283476: train Epoch: [20][ 74/193]	Time  1.410 ( 1.386)	Data  0.366 ( 0.286)	Loss 1.5491e-01 (1.1332e-01) 
2023-05-25 01:54:02.328866: train Epoch: [20][ 75/193]	Time  1.045 ( 1.381)	Data  0.001 ( 0.282)	Loss 1.5224e-01 (1.1384e-01) 
2023-05-25 01:54:04.176733: train Epoch: [20][ 76/193]	Time  1.848 ( 1.387)	Data  0.596 ( 0.286)	Loss 8.6922e-02 (1.1349e-01) 
2023-05-25 01:54:05.251721: train Epoch: [20][ 77/193]	Time  1.075 ( 1.383)	Data  0.001 ( 0.283)	Loss 8.1305e-02 (1.1307e-01) 
2023-05-25 01:54:06.631866: train Epoch: [20][ 78/193]	Time  1.380 ( 1.383)	Data  0.334 ( 0.283)	Loss 1.2238e-01 (1.1319e-01) 
2023-05-25 01:54:07.839741: train Epoch: [20][ 79/193]	Time  1.208 ( 1.381)	Data  0.001 ( 0.280)	Loss 9.4061e-02 (1.1295e-01) 
2023-05-25 01:54:09.175543: train Epoch: [20][ 80/193]	Time  1.336 ( 1.380)	Data  0.371 ( 0.281)	Loss 9.5426e-02 (1.1274e-01) 
2023-05-25 01:54:10.316888: train Epoch: [20][ 81/193]	Time  1.141 ( 1.377)	Data  0.001 ( 0.278)	Loss 1.3797e-01 (1.1304e-01) 
2023-05-25 01:54:11.962150: train Epoch: [20][ 82/193]	Time  1.645 ( 1.381)	Data  0.635 ( 0.282)	Loss 9.5097e-02 (1.1283e-01) 
2023-05-25 01:54:12.982599: train Epoch: [20][ 83/193]	Time  1.020 ( 1.376)	Data  0.001 ( 0.279)	Loss 6.6909e-02 (1.1228e-01) 
2023-05-25 01:54:14.887452: train Epoch: [20][ 84/193]	Time  1.905 ( 1.383)	Data  0.721 ( 0.284)	Loss 4.9932e-02 (1.1155e-01) 
2023-05-25 01:54:15.878057: train Epoch: [20][ 85/193]	Time  0.991 ( 1.378)	Data  0.001 ( 0.280)	Loss 1.0906e-01 (1.1152e-01) 
2023-05-25 01:54:17.438202: train Epoch: [20][ 86/193]	Time  1.560 ( 1.380)	Data  0.553 ( 0.284)	Loss 1.5776e-01 (1.1205e-01) 
2023-05-25 01:54:18.540409: train Epoch: [20][ 87/193]	Time  1.102 ( 1.377)	Data  0.001 ( 0.280)	Loss 1.0634e-01 (1.1199e-01) 
2023-05-25 01:54:20.495214: train Epoch: [20][ 88/193]	Time  1.955 ( 1.384)	Data  0.570 ( 0.284)	Loss 8.1489e-02 (1.1164e-01) 
2023-05-25 01:54:21.508585: train Epoch: [20][ 89/193]	Time  1.013 ( 1.379)	Data  0.001 ( 0.281)	Loss 7.5684e-02 (1.1124e-01) 
2023-05-25 01:54:23.060555: train Epoch: [20][ 90/193]	Time  1.552 ( 1.381)	Data  0.303 ( 0.281)	Loss 9.4804e-02 (1.1106e-01) 
2023-05-25 01:54:24.052351: train Epoch: [20][ 91/193]	Time  0.992 ( 1.377)	Data  0.001 ( 0.278)	Loss 1.6309e-01 (1.1163e-01) 
2023-05-25 01:54:25.532852: train Epoch: [20][ 92/193]	Time  1.481 ( 1.378)	Data  0.424 ( 0.279)	Loss 8.4185e-02 (1.1133e-01) 
2023-05-25 01:54:26.771127: train Epoch: [20][ 93/193]	Time  1.238 ( 1.377)	Data  0.001 ( 0.276)	Loss 9.2288e-02 (1.1113e-01) 
2023-05-25 01:54:28.271163: train Epoch: [20][ 94/193]	Time  1.500 ( 1.378)	Data  0.431 ( 0.278)	Loss 9.0426e-02 (1.1091e-01) 
2023-05-25 01:54:29.519139: train Epoch: [20][ 95/193]	Time  1.248 ( 1.377)	Data  0.001 ( 0.275)	Loss 1.3927e-01 (1.1121e-01) 
2023-05-25 01:54:30.985850: train Epoch: [20][ 96/193]	Time  1.467 ( 1.378)	Data  0.387 ( 0.276)	Loss 1.4715e-01 (1.1158e-01) 
2023-05-25 01:54:32.005696: train Epoch: [20][ 97/193]	Time  1.020 ( 1.374)	Data  0.001 ( 0.273)	Loss 1.1474e-01 (1.1161e-01) 
2023-05-25 01:54:33.866317: train Epoch: [20][ 98/193]	Time  1.861 ( 1.379)	Data  0.583 ( 0.277)	Loss 5.8032e-02 (1.1107e-01) 
2023-05-25 01:54:34.848500: train Epoch: [20][ 99/193]	Time  0.982 ( 1.375)	Data  0.001 ( 0.274)	Loss 1.0257e-01 (1.1098e-01) 
2023-05-25 01:54:36.384179: train Epoch: [20][100/193]	Time  1.536 ( 1.376)	Data  0.429 ( 0.275)	Loss 1.1445e-01 (1.1102e-01) 
2023-05-25 01:54:37.451586: train Epoch: [20][101/193]	Time  1.067 ( 1.373)	Data  0.001 ( 0.273)	Loss 9.0356e-02 (1.1082e-01) 
2023-05-25 01:54:39.315001: train Epoch: [20][102/193]	Time  1.863 ( 1.378)	Data  0.526 ( 0.275)	Loss 1.9492e-01 (1.1163e-01) 
2023-05-25 01:54:40.584282: train Epoch: [20][103/193]	Time  1.269 ( 1.377)	Data  0.001 ( 0.272)	Loss 8.0244e-02 (1.1133e-01) 
2023-05-25 01:54:41.727114: train Epoch: [20][104/193]	Time  1.143 ( 1.375)	Data  0.050 ( 0.270)	Loss 1.4098e-01 (1.1161e-01) 
2023-05-25 01:54:42.927076: train Epoch: [20][105/193]	Time  1.200 ( 1.373)	Data  0.001 ( 0.268)	Loss 1.1407e-01 (1.1164e-01) 
2023-05-25 01:54:44.527747: train Epoch: [20][106/193]	Time  1.601 ( 1.375)	Data  0.415 ( 0.269)	Loss 1.0310e-01 (1.1156e-01) 
2023-05-25 01:54:45.750740: train Epoch: [20][107/193]	Time  1.223 ( 1.374)	Data  0.001 ( 0.267)	Loss 7.8015e-02 (1.1125e-01) 
2023-05-25 01:54:46.975278: train Epoch: [20][108/193]	Time  1.225 ( 1.373)	Data  0.220 ( 0.266)	Loss 1.2022e-01 (1.1133e-01) 
2023-05-25 01:54:48.014013: train Epoch: [20][109/193]	Time  1.039 ( 1.370)	Data  0.001 ( 0.264)	Loss 9.2622e-02 (1.1116e-01) 
2023-05-25 01:54:49.644624: train Epoch: [20][110/193]	Time  1.631 ( 1.372)	Data  0.673 ( 0.268)	Loss 9.7197e-02 (1.1103e-01) 
2023-05-25 01:54:50.645963: train Epoch: [20][111/193]	Time  1.001 ( 1.369)	Data  0.001 ( 0.265)	Loss 1.5919e-01 (1.1146e-01) 
2023-05-25 01:54:52.660557: train Epoch: [20][112/193]	Time  2.015 ( 1.374)	Data  0.654 ( 0.269)	Loss 1.2079e-01 (1.1155e-01) 
2023-05-25 01:54:53.702278: train Epoch: [20][113/193]	Time  1.042 ( 1.371)	Data  0.001 ( 0.266)	Loss 1.0226e-01 (1.1146e-01) 
2023-05-25 01:54:55.084370: train Epoch: [20][114/193]	Time  1.382 ( 1.371)	Data  0.325 ( 0.267)	Loss 1.0716e-01 (1.1143e-01) 
2023-05-25 01:54:56.099642: train Epoch: [20][115/193]	Time  1.015 ( 1.368)	Data  0.001 ( 0.265)	Loss 9.1476e-02 (1.1125e-01) 
2023-05-25 01:54:57.831640: train Epoch: [20][116/193]	Time  1.732 ( 1.372)	Data  0.627 ( 0.268)	Loss 9.7339e-02 (1.1114e-01) 
2023-05-25 01:54:58.994227: train Epoch: [20][117/193]	Time  1.163 ( 1.370)	Data  0.001 ( 0.265)	Loss 7.9803e-02 (1.1087e-01) 
2023-05-25 01:55:00.589894: train Epoch: [20][118/193]	Time  1.596 ( 1.372)	Data  0.384 ( 0.266)	Loss 1.2647e-01 (1.1100e-01) 
2023-05-25 01:55:01.636059: train Epoch: [20][119/193]	Time  1.046 ( 1.369)	Data  0.001 ( 0.264)	Loss 1.1751e-01 (1.1106e-01) 
2023-05-25 01:55:03.078837: train Epoch: [20][120/193]	Time  1.443 ( 1.370)	Data  0.434 ( 0.266)	Loss 1.0064e-01 (1.1097e-01) 
2023-05-25 01:55:04.101567: train Epoch: [20][121/193]	Time  1.023 ( 1.367)	Data  0.001 ( 0.263)	Loss 1.3878e-01 (1.1120e-01) 
2023-05-25 01:55:05.763221: train Epoch: [20][122/193]	Time  1.662 ( 1.369)	Data  0.608 ( 0.266)	Loss 1.4393e-01 (1.1146e-01) 
2023-05-25 01:55:06.910991: train Epoch: [20][123/193]	Time  1.148 ( 1.367)	Data  0.001 ( 0.264)	Loss 1.7497e-01 (1.1198e-01) 
2023-05-25 01:55:08.821855: train Epoch: [20][124/193]	Time  1.911 ( 1.372)	Data  0.476 ( 0.266)	Loss 1.6166e-01 (1.1237e-01) 
2023-05-25 01:55:09.950634: train Epoch: [20][125/193]	Time  1.129 ( 1.370)	Data  0.001 ( 0.264)	Loss 1.2383e-01 (1.1246e-01) 
2023-05-25 01:55:11.223137: train Epoch: [20][126/193]	Time  1.272 ( 1.369)	Data  0.100 ( 0.262)	Loss 6.3958e-02 (1.1208e-01) 
2023-05-25 01:55:12.383963: train Epoch: [20][127/193]	Time  1.161 ( 1.367)	Data  0.001 ( 0.260)	Loss 1.8854e-01 (1.1268e-01) 
2023-05-25 01:55:13.899374: train Epoch: [20][128/193]	Time  1.515 ( 1.368)	Data  0.314 ( 0.261)	Loss 1.1466e-01 (1.1269e-01) 
2023-05-25 01:55:14.947028: train Epoch: [20][129/193]	Time  1.048 ( 1.366)	Data  0.001 ( 0.259)	Loss 4.5940e-02 (1.1218e-01) 
2023-05-25 01:55:16.455645: train Epoch: [20][130/193]	Time  1.509 ( 1.367)	Data  0.410 ( 0.260)	Loss 1.0596e-01 (1.1213e-01) 
2023-05-25 01:55:17.463197: train Epoch: [20][131/193]	Time  1.008 ( 1.364)	Data  0.001 ( 0.258)	Loss 1.4262e-01 (1.1236e-01) 
2023-05-25 01:55:19.233261: train Epoch: [20][132/193]	Time  1.770 ( 1.367)	Data  0.596 ( 0.260)	Loss 1.1432e-01 (1.1238e-01) 
2023-05-25 01:55:20.320711: train Epoch: [20][133/193]	Time  1.087 ( 1.365)	Data  0.001 ( 0.259)	Loss 6.5040e-02 (1.1203e-01) 
2023-05-25 01:55:22.171062: train Epoch: [20][134/193]	Time  1.850 ( 1.369)	Data  0.480 ( 0.260)	Loss 1.9386e-01 (1.1263e-01) 
2023-05-25 01:55:23.138829: train Epoch: [20][135/193]	Time  0.968 ( 1.366)	Data  0.001 ( 0.258)	Loss 6.1326e-02 (1.1225e-01) 
2023-05-25 01:55:24.717471: train Epoch: [20][136/193]	Time  1.579 ( 1.368)	Data  0.339 ( 0.259)	Loss 7.5795e-02 (1.1199e-01) 
2023-05-25 01:55:25.811106: train Epoch: [20][137/193]	Time  1.094 ( 1.366)	Data  0.001 ( 0.257)	Loss 8.4289e-02 (1.1179e-01) 
2023-05-25 01:55:27.121724: train Epoch: [20][138/193]	Time  1.311 ( 1.365)	Data  0.313 ( 0.257)	Loss 9.6543e-02 (1.1168e-01) 
2023-05-25 01:55:28.190937: train Epoch: [20][139/193]	Time  1.069 ( 1.363)	Data  0.001 ( 0.256)	Loss 1.1163e-01 (1.1168e-01) 
2023-05-25 01:55:29.979970: train Epoch: [20][140/193]	Time  1.789 ( 1.366)	Data  0.657 ( 0.258)	Loss 1.4875e-01 (1.1194e-01) 
2023-05-25 01:55:31.107440: train Epoch: [20][141/193]	Time  1.127 ( 1.364)	Data  0.001 ( 0.257)	Loss 7.7744e-02 (1.1170e-01) 
2023-05-25 01:55:32.722128: train Epoch: [20][142/193]	Time  1.615 ( 1.366)	Data  0.480 ( 0.258)	Loss 1.3946e-01 (1.1189e-01) 
2023-05-25 01:55:33.850957: train Epoch: [20][143/193]	Time  1.129 ( 1.364)	Data  0.001 ( 0.256)	Loss 5.8719e-02 (1.1152e-01) 
2023-05-25 01:55:35.549251: train Epoch: [20][144/193]	Time  1.698 ( 1.367)	Data  0.504 ( 0.258)	Loss 7.9022e-02 (1.1130e-01) 
2023-05-25 01:55:36.520015: train Epoch: [20][145/193]	Time  0.971 ( 1.364)	Data  0.001 ( 0.256)	Loss 1.1186e-01 (1.1130e-01) 
2023-05-25 01:55:38.315756: train Epoch: [20][146/193]	Time  1.796 ( 1.367)	Data  0.545 ( 0.258)	Loss 1.3373e-01 (1.1146e-01) 
2023-05-25 01:55:39.256751: train Epoch: [20][147/193]	Time  0.941 ( 1.364)	Data  0.001 ( 0.257)	Loss 1.0097e-01 (1.1139e-01) 
2023-05-25 01:55:40.959653: train Epoch: [20][148/193]	Time  1.703 ( 1.366)	Data  0.425 ( 0.258)	Loss 1.6066e-01 (1.1172e-01) 
2023-05-25 01:55:41.934680: train Epoch: [20][149/193]	Time  0.975 ( 1.364)	Data  0.001 ( 0.256)	Loss 1.0434e-01 (1.1167e-01) 
2023-05-25 01:55:43.583216: train Epoch: [20][150/193]	Time  1.649 ( 1.366)	Data  0.472 ( 0.257)	Loss 9.0557e-02 (1.1153e-01) 
2023-05-25 01:55:44.591437: train Epoch: [20][151/193]	Time  1.008 ( 1.363)	Data  0.001 ( 0.256)	Loss 7.0489e-02 (1.1126e-01) 
2023-05-25 01:55:46.301052: train Epoch: [20][152/193]	Time  1.710 ( 1.366)	Data  0.491 ( 0.257)	Loss 7.3879e-02 (1.1101e-01) 
2023-05-25 01:55:47.469823: train Epoch: [20][153/193]	Time  1.169 ( 1.364)	Data  0.001 ( 0.256)	Loss 9.1833e-02 (1.1089e-01) 
2023-05-25 01:55:48.884346: train Epoch: [20][154/193]	Time  1.414 ( 1.365)	Data  0.316 ( 0.256)	Loss 1.1345e-01 (1.1091e-01) 
2023-05-25 01:55:49.883744: train Epoch: [20][155/193]	Time  0.999 ( 1.362)	Data  0.001 ( 0.254)	Loss 8.7647e-02 (1.1076e-01) 
2023-05-25 01:55:51.562076: train Epoch: [20][156/193]	Time  1.678 ( 1.364)	Data  0.667 ( 0.257)	Loss 1.7768e-01 (1.1118e-01) 
2023-05-25 01:55:52.612855: train Epoch: [20][157/193]	Time  1.051 ( 1.362)	Data  0.001 ( 0.255)	Loss 1.4782e-01 (1.1141e-01) 
2023-05-25 01:55:54.529738: train Epoch: [20][158/193]	Time  1.917 ( 1.366)	Data  0.645 ( 0.258)	Loss 1.2945e-01 (1.1153e-01) 
2023-05-25 01:55:55.628999: train Epoch: [20][159/193]	Time  1.099 ( 1.364)	Data  0.001 ( 0.256)	Loss 8.2119e-02 (1.1134e-01) 
2023-05-25 01:55:57.044347: train Epoch: [20][160/193]	Time  1.415 ( 1.364)	Data  0.334 ( 0.257)	Loss 9.2642e-02 (1.1123e-01) 
2023-05-25 01:55:58.246263: train Epoch: [20][161/193]	Time  1.202 ( 1.363)	Data  0.001 ( 0.255)	Loss 4.9661e-02 (1.1085e-01) 
2023-05-25 01:55:59.724899: train Epoch: [20][162/193]	Time  1.479 ( 1.364)	Data  0.456 ( 0.256)	Loss 6.7732e-02 (1.1058e-01) 
2023-05-25 01:56:00.941003: train Epoch: [20][163/193]	Time  1.216 ( 1.363)	Data  0.001 ( 0.255)	Loss 6.8551e-02 (1.1033e-01) 
2023-05-25 01:56:02.557044: train Epoch: [20][164/193]	Time  1.616 ( 1.365)	Data  0.444 ( 0.256)	Loss 1.5763e-01 (1.1061e-01) 
2023-05-25 01:56:03.783996: train Epoch: [20][165/193]	Time  1.227 ( 1.364)	Data  0.001 ( 0.254)	Loss 5.8870e-02 (1.1030e-01) 
2023-05-25 01:56:05.107878: train Epoch: [20][166/193]	Time  1.324 ( 1.364)	Data  0.333 ( 0.255)	Loss 1.1476e-01 (1.1033e-01) 
2023-05-25 01:56:06.232071: train Epoch: [20][167/193]	Time  1.124 ( 1.362)	Data  0.001 ( 0.253)	Loss 1.6171e-01 (1.1063e-01) 
2023-05-25 01:56:07.802068: train Epoch: [20][168/193]	Time  1.570 ( 1.364)	Data  0.580 ( 0.255)	Loss 1.8274e-01 (1.1106e-01) 
2023-05-25 01:56:08.890843: train Epoch: [20][169/193]	Time  1.089 ( 1.362)	Data  0.001 ( 0.254)	Loss 1.1593e-01 (1.1109e-01) 
2023-05-25 01:56:10.486694: train Epoch: [20][170/193]	Time  1.596 ( 1.363)	Data  0.535 ( 0.255)	Loss 1.9839e-01 (1.1160e-01) 
2023-05-25 01:56:11.465771: train Epoch: [20][171/193]	Time  0.979 ( 1.361)	Data  0.001 ( 0.254)	Loss 1.1607e-01 (1.1163e-01) 
2023-05-25 01:56:13.452143: train Epoch: [20][172/193]	Time  1.986 ( 1.365)	Data  0.687 ( 0.256)	Loss 1.2464e-01 (1.1170e-01) 
2023-05-25 01:56:14.449470: train Epoch: [20][173/193]	Time  0.997 ( 1.363)	Data  0.001 ( 0.255)	Loss 7.7523e-02 (1.1151e-01) 
2023-05-25 01:56:15.827417: train Epoch: [20][174/193]	Time  1.378 ( 1.363)	Data  0.434 ( 0.256)	Loss 9.2845e-02 (1.1140e-01) 
2023-05-25 01:56:16.815622: train Epoch: [20][175/193]	Time  0.988 ( 1.361)	Data  0.001 ( 0.255)	Loss 9.9368e-02 (1.1133e-01) 
2023-05-25 01:56:18.898982: train Epoch: [20][176/193]	Time  2.083 ( 1.365)	Data  0.873 ( 0.258)	Loss 6.7118e-02 (1.1108e-01) 
2023-05-25 01:56:19.982744: train Epoch: [20][177/193]	Time  1.084 ( 1.363)	Data  0.001 ( 0.257)	Loss 6.7361e-02 (1.1084e-01) 
2023-05-25 01:56:21.400022: train Epoch: [20][178/193]	Time  1.417 ( 1.363)	Data  0.425 ( 0.258)	Loss 2.4987e-01 (1.1161e-01) 
2023-05-25 01:56:22.448435: train Epoch: [20][179/193]	Time  1.048 ( 1.362)	Data  0.001 ( 0.256)	Loss 1.0441e-01 (1.1157e-01) 
2023-05-25 01:56:24.398586: train Epoch: [20][180/193]	Time  1.950 ( 1.365)	Data  0.717 ( 0.259)	Loss 1.0815e-01 (1.1155e-01) 
2023-05-25 01:56:25.521925: train Epoch: [20][181/193]	Time  1.123 ( 1.364)	Data  0.001 ( 0.257)	Loss 1.0308e-01 (1.1151e-01) 
2023-05-25 01:56:27.146869: train Epoch: [20][182/193]	Time  1.625 ( 1.365)	Data  0.402 ( 0.258)	Loss 7.7845e-02 (1.1132e-01) 
2023-05-25 01:56:28.342480: train Epoch: [20][183/193]	Time  1.196 ( 1.364)	Data  0.001 ( 0.257)	Loss 5.3664e-02 (1.1101e-01) 
2023-05-25 01:56:29.944297: train Epoch: [20][184/193]	Time  1.602 ( 1.365)	Data  0.287 ( 0.257)	Loss 7.1631e-02 (1.1080e-01) 
2023-05-25 01:56:30.961660: train Epoch: [20][185/193]	Time  1.017 ( 1.363)	Data  0.001 ( 0.255)	Loss 1.0435e-01 (1.1076e-01) 
2023-05-25 01:56:32.534044: train Epoch: [20][186/193]	Time  1.572 ( 1.365)	Data  0.327 ( 0.256)	Loss 5.4616e-02 (1.1046e-01) 
2023-05-25 01:56:33.613090: train Epoch: [20][187/193]	Time  1.079 ( 1.363)	Data  0.001 ( 0.254)	Loss 5.4042e-02 (1.1016e-01) 
2023-05-25 01:56:35.298098: train Epoch: [20][188/193]	Time  1.685 ( 1.365)	Data  0.370 ( 0.255)	Loss 1.0372e-01 (1.1013e-01) 
2023-05-25 01:56:36.304496: train Epoch: [20][189/193]	Time  1.006 ( 1.363)	Data  0.001 ( 0.254)	Loss 9.5486e-02 (1.1005e-01) 
2023-05-25 01:56:37.529016: train Epoch: [20][190/193]	Time  1.225 ( 1.362)	Data  0.220 ( 0.254)	Loss 5.9770e-02 (1.0979e-01) 
2023-05-25 01:56:38.600500: train Epoch: [20][191/193]	Time  1.071 ( 1.361)	Data  0.001 ( 0.252)	Loss 7.9827e-02 (1.0963e-01) 
2023-05-25 01:56:39.945559: train Epoch: [20][192/193]	Time  1.345 ( 1.361)	Data  0.230 ( 0.252)	Loss 9.8447e-02 (1.0957e-01) 
2023-05-25 01:56:40.065253: Train Epoch done in 262.70249775098637 s 
2023-05-25 01:56:43.123174: val Epoch: [20][ 0/72]	Time  2.102 ( 2.102)	Data  1.790 ( 1.790)	Loss 6.2660e-02 (6.2660e-02) 
2023-05-25 01:56:43.482611: val Epoch: [20][ 1/72]	Time  0.360 ( 1.231)	Data  0.002 ( 0.896)	Loss 4.8060e-02 (5.5360e-02) 
2023-05-25 01:56:44.645558: val Epoch: [20][ 2/72]	Time  1.163 ( 1.208)	Data  0.801 ( 0.864)	Loss 6.7425e-02 (5.9382e-02) 
2023-05-25 01:56:44.999334: val Epoch: [20][ 3/72]	Time  0.354 ( 0.995)	Data  0.012 ( 0.651)	Loss 3.6220e-01 (1.3509e-01) 
2023-05-25 01:56:45.879481: val Epoch: [20][ 4/72]	Time  0.880 ( 0.972)	Data  0.671 ( 0.655)	Loss 1.8478e-01 (1.4503e-01) 
2023-05-25 01:56:46.323814: val Epoch: [20][ 5/72]	Time  0.444 ( 0.884)	Data  0.001 ( 0.546)	Loss 1.7546e-01 (1.5010e-01) 
2023-05-25 01:56:47.468209: val Epoch: [20][ 6/72]	Time  1.144 ( 0.921)	Data  0.767 ( 0.578)	Loss 6.7355e-02 (1.3828e-01) 
2023-05-25 01:56:47.788410: val Epoch: [20][ 7/72]	Time  0.320 ( 0.846)	Data  0.001 ( 0.506)	Loss 7.0651e-02 (1.2983e-01) 
2023-05-25 01:56:48.990203: val Epoch: [20][ 8/72]	Time  1.202 ( 0.885)	Data  0.732 ( 0.531)	Loss 2.1183e-01 (1.3894e-01) 
2023-05-25 01:56:49.329916: val Epoch: [20][ 9/72]	Time  0.340 ( 0.831)	Data  0.001 ( 0.478)	Loss 1.2792e-01 (1.3784e-01) 
2023-05-25 01:56:50.146167: val Epoch: [20][10/72]	Time  0.816 ( 0.830)	Data  0.611 ( 0.490)	Loss 2.0277e-01 (1.4374e-01) 
2023-05-25 01:56:50.399823: val Epoch: [20][11/72]	Time  0.254 ( 0.782)	Data  0.001 ( 0.449)	Loss 2.3105e-01 (1.5101e-01) 
2023-05-25 01:56:51.713550: val Epoch: [20][12/72]	Time  1.314 ( 0.822)	Data  0.939 ( 0.487)	Loss 1.1231e-01 (1.4804e-01) 
2023-05-25 01:56:52.100530: val Epoch: [20][13/72]	Time  0.387 ( 0.791)	Data  0.001 ( 0.452)	Loss 4.7209e-01 (1.7118e-01) 
2023-05-25 01:56:53.220301: val Epoch: [20][14/72]	Time  1.120 ( 0.813)	Data  0.686 ( 0.468)	Loss 1.5745e-01 (1.7027e-01) 
2023-05-25 01:56:53.419752: val Epoch: [20][15/72]	Time  0.199 ( 0.775)	Data  0.001 ( 0.439)	Loss 1.6910e-01 (1.7020e-01) 
2023-05-25 01:56:54.450450: val Epoch: [20][16/72]	Time  1.031 ( 0.790)	Data  0.652 ( 0.451)	Loss 5.1552e-02 (1.6322e-01) 
2023-05-25 01:56:54.639768: val Epoch: [20][17/72]	Time  0.189 ( 0.757)	Data  0.001 ( 0.426)	Loss 1.9855e-01 (1.6518e-01) 
2023-05-25 01:56:55.695829: val Epoch: [20][18/72]	Time  1.056 ( 0.772)	Data  0.775 ( 0.444)	Loss 5.6618e-02 (1.5947e-01) 
2023-05-25 01:56:56.189944: val Epoch: [20][19/72]	Time  0.494 ( 0.758)	Data  0.001 ( 0.422)	Loss 1.2431e-01 (1.5771e-01) 
2023-05-25 01:56:57.181537: val Epoch: [20][20/72]	Time  0.992 ( 0.770)	Data  0.605 ( 0.431)	Loss 1.8981e-01 (1.5924e-01) 
2023-05-25 01:56:57.372154: val Epoch: [20][21/72]	Time  0.191 ( 0.743)	Data  0.001 ( 0.411)	Loss 6.8546e-02 (1.5511e-01) 
2023-05-25 01:56:58.528654: val Epoch: [20][22/72]	Time  1.156 ( 0.761)	Data  0.872 ( 0.431)	Loss 9.8138e-02 (1.5264e-01) 
2023-05-25 01:56:59.033777: val Epoch: [20][23/72]	Time  0.505 ( 0.751)	Data  0.001 ( 0.414)	Loss 2.9514e-01 (1.5857e-01) 
2023-05-25 01:57:00.192137: val Epoch: [20][24/72]	Time  1.158 ( 0.767)	Data  0.584 ( 0.420)	Loss 5.6490e-02 (1.5449e-01) 
2023-05-25 01:57:00.644968: val Epoch: [20][25/72]	Time  0.453 ( 0.755)	Data  0.001 ( 0.404)	Loss 2.1247e-01 (1.5672e-01) 
2023-05-25 01:57:01.154542: val Epoch: [20][26/72]	Time  0.510 ( 0.746)	Data  0.311 ( 0.401)	Loss 6.8230e-02 (1.5344e-01) 
2023-05-25 01:57:01.640438: val Epoch: [20][27/72]	Time  0.486 ( 0.736)	Data  0.003 ( 0.387)	Loss 6.6261e-02 (1.5033e-01) 
2023-05-25 01:57:02.648440: val Epoch: [20][28/72]	Time  1.008 ( 0.746)	Data  0.700 ( 0.397)	Loss 8.2132e-02 (1.4798e-01) 
2023-05-25 01:57:03.027085: val Epoch: [20][29/72]	Time  0.379 ( 0.734)	Data  0.001 ( 0.384)	Loss 3.1745e-01 (1.5363e-01) 
2023-05-25 01:57:04.300134: val Epoch: [20][30/72]	Time  1.273 ( 0.751)	Data  0.719 ( 0.395)	Loss 8.6120e-02 (1.5145e-01) 
2023-05-25 01:57:04.506855: val Epoch: [20][31/72]	Time  0.207 ( 0.734)	Data  0.001 ( 0.383)	Loss 1.2415e-01 (1.5060e-01) 
2023-05-25 01:57:05.362048: val Epoch: [20][32/72]	Time  0.855 ( 0.738)	Data  0.564 ( 0.388)	Loss 7.0217e-02 (1.4816e-01) 
2023-05-25 01:57:05.727990: val Epoch: [20][33/72]	Time  0.366 ( 0.727)	Data  0.001 ( 0.377)	Loss 8.5742e-02 (1.4632e-01) 
2023-05-25 01:57:06.778355: val Epoch: [20][34/72]	Time  1.050 ( 0.736)	Data  0.687 ( 0.386)	Loss 6.2729e-02 (1.4394e-01) 
2023-05-25 01:57:07.095724: val Epoch: [20][35/72]	Time  0.317 ( 0.724)	Data  0.001 ( 0.375)	Loss 1.4890e-01 (1.4407e-01) 
2023-05-25 01:57:08.011631: val Epoch: [20][36/72]	Time  0.916 ( 0.729)	Data  0.711 ( 0.384)	Loss 4.6304e-02 (1.4143e-01) 
2023-05-25 01:57:08.308276: val Epoch: [20][37/72]	Time  0.297 ( 0.718)	Data  0.001 ( 0.374)	Loss 1.1257e-01 (1.4067e-01) 
2023-05-25 01:57:09.610214: val Epoch: [20][38/72]	Time  1.302 ( 0.733)	Data  0.906 ( 0.388)	Loss 3.3327e-01 (1.4561e-01) 
2023-05-25 01:57:09.966271: val Epoch: [20][39/72]	Time  0.356 ( 0.724)	Data  0.002 ( 0.378)	Loss 1.6980e-01 (1.4622e-01) 
2023-05-25 01:57:10.958924: val Epoch: [20][40/72]	Time  0.993 ( 0.730)	Data  0.582 ( 0.383)	Loss 5.3466e-02 (1.4395e-01) 
2023-05-25 01:57:11.396420: val Epoch: [20][41/72]	Time  0.438 ( 0.723)	Data  0.001 ( 0.374)	Loss 3.4958e-01 (1.4885e-01) 
2023-05-25 01:57:12.314725: val Epoch: [20][42/72]	Time  0.918 ( 0.728)	Data  0.553 ( 0.378)	Loss 1.5624e-01 (1.4902e-01) 
2023-05-25 01:57:12.570099: val Epoch: [20][43/72]	Time  0.255 ( 0.717)	Data  0.001 ( 0.369)	Loss 1.3546e-01 (1.4871e-01) 
2023-05-25 01:57:13.810564: val Epoch: [20][44/72]	Time  1.240 ( 0.729)	Data  0.816 ( 0.379)	Loss 8.6051e-02 (1.4732e-01) 
2023-05-25 01:57:14.156320: val Epoch: [20][45/72]	Time  0.346 ( 0.720)	Data  0.001 ( 0.371)	Loss 5.4045e-02 (1.4529e-01) 
2023-05-25 01:57:14.987061: val Epoch: [20][46/72]	Time  0.831 ( 0.723)	Data  0.622 ( 0.376)	Loss 3.2894e-01 (1.4920e-01) 
2023-05-25 01:57:15.339771: val Epoch: [20][47/72]	Time  0.353 ( 0.715)	Data  0.001 ( 0.369)	Loss 4.6636e-01 (1.5581e-01) 
2023-05-25 01:57:16.612718: val Epoch: [20][48/72]	Time  1.273 ( 0.726)	Data  0.816 ( 0.378)	Loss 2.3997e-01 (1.5753e-01) 
2023-05-25 01:57:16.893741: val Epoch: [20][49/72]	Time  0.281 ( 0.717)	Data  0.001 ( 0.370)	Loss 2.6691e-01 (1.5971e-01) 
2023-05-25 01:57:17.997678: val Epoch: [20][50/72]	Time  1.104 ( 0.725)	Data  0.639 ( 0.376)	Loss 2.0835e-01 (1.6067e-01) 
2023-05-25 01:57:18.396639: val Epoch: [20][51/72]	Time  0.399 ( 0.719)	Data  0.001 ( 0.368)	Loss 1.1647e-01 (1.5982e-01) 
2023-05-25 01:57:19.139098: val Epoch: [20][52/72]	Time  0.742 ( 0.719)	Data  0.494 ( 0.371)	Loss 5.9147e-02 (1.5792e-01) 
2023-05-25 01:57:19.435619: val Epoch: [20][53/72]	Time  0.297 ( 0.711)	Data  0.001 ( 0.364)	Loss 3.0632e-01 (1.6067e-01) 
2023-05-25 01:57:20.614902: val Epoch: [20][54/72]	Time  1.179 ( 0.720)	Data  0.817 ( 0.372)	Loss 7.8901e-02 (1.5918e-01) 
2023-05-25 01:57:20.998170: val Epoch: [20][55/72]	Time  0.383 ( 0.714)	Data  0.001 ( 0.365)	Loss 1.0761e-01 (1.5826e-01) 
2023-05-25 01:57:21.850496: val Epoch: [20][56/72]	Time  0.852 ( 0.716)	Data  0.603 ( 0.370)	Loss 4.8728e-02 (1.5634e-01) 
2023-05-25 01:57:22.248562: val Epoch: [20][57/72]	Time  0.398 ( 0.711)	Data  0.001 ( 0.363)	Loss 1.1442e-01 (1.5561e-01) 
2023-05-25 01:57:23.263885: val Epoch: [20][58/72]	Time  1.015 ( 0.716)	Data  0.782 ( 0.370)	Loss 9.7434e-02 (1.5463e-01) 
2023-05-25 01:57:23.646648: val Epoch: [20][59/72]	Time  0.383 ( 0.710)	Data  0.001 ( 0.364)	Loss 9.2568e-02 (1.5359e-01) 
2023-05-25 01:57:25.040513: val Epoch: [20][60/72]	Time  1.394 ( 0.722)	Data  0.832 ( 0.372)	Loss 1.7641e-01 (1.5397e-01) 
2023-05-25 01:57:25.451812: val Epoch: [20][61/72]	Time  0.411 ( 0.717)	Data  0.002 ( 0.366)	Loss 1.1497e-01 (1.5334e-01) 
2023-05-25 01:57:26.362624: val Epoch: [20][62/72]	Time  0.911 ( 0.720)	Data  0.466 ( 0.368)	Loss 7.0959e-02 (1.5203e-01) 
2023-05-25 01:57:26.557297: val Epoch: [20][63/72]	Time  0.195 ( 0.711)	Data  0.001 ( 0.362)	Loss 1.5386e-01 (1.5206e-01) 
2023-05-25 01:57:27.641164: val Epoch: [20][64/72]	Time  1.084 ( 0.717)	Data  0.752 ( 0.368)	Loss 8.4699e-02 (1.5102e-01) 
2023-05-25 01:57:27.943057: val Epoch: [20][65/72]	Time  0.302 ( 0.711)	Data  0.001 ( 0.362)	Loss 3.5751e-01 (1.5415e-01) 
2023-05-25 01:57:29.027312: val Epoch: [20][66/72]	Time  1.084 ( 0.717)	Data  0.794 ( 0.369)	Loss 6.1321e-02 (1.5277e-01) 
2023-05-25 01:57:29.299598: val Epoch: [20][67/72]	Time  0.272 ( 0.710)	Data  0.002 ( 0.363)	Loss 4.9395e-02 (1.5125e-01) 
2023-05-25 01:57:30.294740: val Epoch: [20][68/72]	Time  0.995 ( 0.714)	Data  0.802 ( 0.370)	Loss 3.7387e-02 (1.4960e-01) 
2023-05-25 01:57:30.576269: val Epoch: [20][69/72]	Time  0.282 ( 0.708)	Data  0.001 ( 0.364)	Loss 5.6829e-02 (1.4827e-01) 
2023-05-25 01:57:31.841005: val Epoch: [20][70/72]	Time  1.265 ( 0.716)	Data  0.852 ( 0.371)	Loss 7.2580e-02 (1.4720e-01) 
2023-05-25 01:57:32.070351: val Epoch: [20][71/72]	Time  0.229 ( 0.709)	Data  0.001 ( 0.366)	Loss 9.8692e-02 (1.4653e-01) 
2023-05-25 01:57:32.683179: Epoch 20 :Val : ['ET : 0.723689079284668', 'TC : 0.7474048137664795', 'WT : 0.8489279747009277'] 
2023-05-25 01:57:32.686491: Epoch 20 :Val : ['ET : 0.723689079284668', 'TC : 0.7474048137664795', 'WT : 0.8489279747009277'] 
2023-05-25 01:57:32.690536: Val epoch done in 52.62528251192998 s 
2023-05-25 01:57:32.701486: Batches per epoch:  193 
2023-05-25 01:57:37.256508: train Epoch: [21][  0/193]	Time  4.554 ( 4.554)	Data  3.228 ( 3.228)	Loss 6.4923e-02 (6.4923e-02) 
2023-05-25 01:57:38.352197: train Epoch: [21][  1/193]	Time  1.096 ( 2.825)	Data  0.001 ( 1.615)	Loss 1.1905e-01 (9.1989e-02) 
2023-05-25 01:57:39.915973: train Epoch: [21][  2/193]	Time  1.564 ( 2.405)	Data  0.286 ( 1.172)	Loss 1.4210e-01 (1.0869e-01) 
2023-05-25 01:57:40.883158: train Epoch: [21][  3/193]	Time  0.967 ( 2.045)	Data  0.001 ( 0.879)	Loss 1.1066e-01 (1.0919e-01) 
2023-05-25 01:57:42.593022: train Epoch: [21][  4/193]	Time  1.710 ( 1.978)	Data  0.512 ( 0.806)	Loss 9.1974e-02 (1.0574e-01) 
2023-05-25 01:57:43.606129: train Epoch: [21][  5/193]	Time  1.013 ( 1.817)	Data  0.002 ( 0.672)	Loss 5.7465e-02 (9.7696e-02) 
2023-05-25 01:57:45.562843: train Epoch: [21][  6/193]	Time  1.957 ( 1.837)	Data  0.794 ( 0.689)	Loss 8.2064e-02 (9.5463e-02) 
2023-05-25 01:57:46.676752: train Epoch: [21][  7/193]	Time  1.114 ( 1.747)	Data  0.001 ( 0.603)	Loss 1.5269e-01 (1.0262e-01) 
2023-05-25 01:57:48.396848: train Epoch: [21][  8/193]	Time  1.720 ( 1.744)	Data  0.440 ( 0.585)	Loss 5.4658e-02 (9.7287e-02) 
2023-05-25 01:57:49.518595: train Epoch: [21][  9/193]	Time  1.122 ( 1.682)	Data  0.001 ( 0.527)	Loss 6.8340e-02 (9.4393e-02) 
2023-05-25 01:57:51.074860: train Epoch: [21][ 10/193]	Time  1.556 ( 1.670)	Data  0.254 ( 0.502)	Loss 7.6334e-02 (9.2751e-02) 
2023-05-25 01:57:52.267628: train Epoch: [21][ 11/193]	Time  1.193 ( 1.630)	Data  0.001 ( 0.460)	Loss 1.3614e-01 (9.6367e-02) 
2023-05-25 01:57:53.340221: train Epoch: [21][ 12/193]	Time  1.073 ( 1.588)	Data  0.240 ( 0.443)	Loss 9.5104e-02 (9.6270e-02) 
2023-05-25 01:57:54.468062: train Epoch: [21][ 13/193]	Time  1.128 ( 1.555)	Data  0.001 ( 0.412)	Loss 1.3090e-01 (9.8744e-02) 
2023-05-25 01:57:56.248517: train Epoch: [21][ 14/193]	Time  1.780 ( 1.570)	Data  0.728 ( 0.433)	Loss 7.6205e-02 (9.7241e-02) 
2023-05-25 01:57:57.215317: train Epoch: [21][ 15/193]	Time  0.967 ( 1.532)	Data  0.001 ( 0.406)	Loss 7.2679e-02 (9.5706e-02) 
2023-05-25 01:57:59.105955: train Epoch: [21][ 16/193]	Time  1.891 ( 1.553)	Data  0.618 ( 0.418)	Loss 1.0308e-01 (9.6140e-02) 
2023-05-25 01:58:00.089720: train Epoch: [21][ 17/193]	Time  0.984 ( 1.522)	Data  0.001 ( 0.395)	Loss 5.8122e-02 (9.4028e-02) 
2023-05-25 01:58:01.585782: train Epoch: [21][ 18/193]	Time  1.496 ( 1.520)	Data  0.401 ( 0.395)	Loss 1.2816e-01 (9.5824e-02) 
2023-05-25 01:58:02.591255: train Epoch: [21][ 19/193]	Time  1.005 ( 1.494)	Data  0.003 ( 0.376)	Loss 9.4078e-02 (9.5737e-02) 
2023-05-25 01:58:04.233733: train Epoch: [21][ 20/193]	Time  1.642 ( 1.501)	Data  0.566 ( 0.385)	Loss 6.3210e-02 (9.4188e-02) 
2023-05-25 01:58:05.289794: train Epoch: [21][ 21/193]	Time  1.056 ( 1.481)	Data  0.002 ( 0.367)	Loss 1.1469e-01 (9.5120e-02) 
2023-05-25 01:58:07.112644: train Epoch: [21][ 22/193]	Time  1.823 ( 1.496)	Data  0.560 ( 0.376)	Loss 1.1378e-01 (9.5931e-02) 
2023-05-25 01:58:08.405008: train Epoch: [21][ 23/193]	Time  1.292 ( 1.488)	Data  0.001 ( 0.360)	Loss 1.1233e-01 (9.6614e-02) 
2023-05-25 01:58:09.464776: train Epoch: [21][ 24/193]	Time  1.060 ( 1.470)	Data  0.090 ( 0.349)	Loss 1.1338e-01 (9.7285e-02) 
2023-05-25 01:58:10.395357: train Epoch: [21][ 25/193]	Time  0.931 ( 1.450)	Data  0.001 ( 0.336)	Loss 6.4508e-02 (9.6024e-02) 
2023-05-25 01:58:12.001937: train Epoch: [21][ 26/193]	Time  1.607 ( 1.456)	Data  0.702 ( 0.350)	Loss 2.2661e-01 (1.0086e-01) 
2023-05-25 01:58:12.941629: train Epoch: [21][ 27/193]	Time  0.940 ( 1.437)	Data  0.001 ( 0.337)	Loss 1.0142e-01 (1.0088e-01) 
2023-05-25 01:58:14.814033: train Epoch: [21][ 28/193]	Time  1.872 ( 1.452)	Data  0.871 ( 0.356)	Loss 1.2495e-01 (1.0171e-01) 
2023-05-25 01:58:15.946899: train Epoch: [21][ 29/193]	Time  1.133 ( 1.441)	Data  0.001 ( 0.344)	Loss 1.3930e-01 (1.0296e-01) 
2023-05-25 01:58:17.700459: train Epoch: [21][ 30/193]	Time  1.754 ( 1.452)	Data  0.603 ( 0.352)	Loss 8.4734e-02 (1.0238e-01) 
2023-05-25 01:58:18.871728: train Epoch: [21][ 31/193]	Time  1.171 ( 1.443)	Data  0.001 ( 0.341)	Loss 1.5918e-01 (1.0415e-01) 
2023-05-25 01:58:20.532664: train Epoch: [21][ 32/193]	Time  1.661 ( 1.449)	Data  0.336 ( 0.341)	Loss 9.3539e-02 (1.0383e-01) 
2023-05-25 01:58:21.606194: train Epoch: [21][ 33/193]	Time  1.074 ( 1.438)	Data  0.001 ( 0.331)	Loss 7.0033e-02 (1.0284e-01) 
2023-05-25 01:58:23.326820: train Epoch: [21][ 34/193]	Time  1.721 ( 1.446)	Data  0.281 ( 0.330)	Loss 7.3667e-02 (1.0200e-01) 
2023-05-25 01:58:24.447251: train Epoch: [21][ 35/193]	Time  1.120 ( 1.437)	Data  0.001 ( 0.320)	Loss 6.8387e-02 (1.0107e-01) 
2023-05-25 01:58:25.669884: train Epoch: [21][ 36/193]	Time  1.223 ( 1.432)	Data  0.130 ( 0.315)	Loss 1.4564e-01 (1.0227e-01) 
2023-05-25 01:58:27.042697: train Epoch: [21][ 37/193]	Time  1.373 ( 1.430)	Data  0.001 ( 0.307)	Loss 5.7800e-02 (1.0110e-01) 
2023-05-25 01:58:28.195431: train Epoch: [21][ 38/193]	Time  1.153 ( 1.423)	Data  0.145 ( 0.303)	Loss 2.1513e-01 (1.0403e-01) 
2023-05-25 01:58:29.413170: train Epoch: [21][ 39/193]	Time  1.218 ( 1.418)	Data  0.001 ( 0.295)	Loss 6.7945e-02 (1.0312e-01) 
2023-05-25 01:58:31.121544: train Epoch: [21][ 40/193]	Time  1.708 ( 1.425)	Data  0.573 ( 0.302)	Loss 8.6694e-02 (1.0272e-01) 
2023-05-25 01:58:32.201866: train Epoch: [21][ 41/193]	Time  1.080 ( 1.417)	Data  0.001 ( 0.295)	Loss 9.8971e-02 (1.0263e-01) 
2023-05-25 01:58:33.869411: train Epoch: [21][ 42/193]	Time  1.668 ( 1.422)	Data  0.548 ( 0.301)	Loss 5.1732e-02 (1.0145e-01) 
2023-05-25 01:58:34.833080: train Epoch: [21][ 43/193]	Time  0.964 ( 1.412)	Data  0.001 ( 0.294)	Loss 5.7318e-02 (1.0045e-01) 
2023-05-25 01:58:36.648152: train Epoch: [21][ 44/193]	Time  1.815 ( 1.421)	Data  0.668 ( 0.302)	Loss 8.4834e-02 (1.0010e-01) 
2023-05-25 01:58:37.677161: train Epoch: [21][ 45/193]	Time  1.029 ( 1.412)	Data  0.001 ( 0.296)	Loss 4.8379e-02 (9.8976e-02) 
2023-05-25 01:58:39.437107: train Epoch: [21][ 46/193]	Time  1.760 ( 1.420)	Data  0.530 ( 0.301)	Loss 1.0841e-01 (9.9177e-02) 
2023-05-25 01:58:40.603095: train Epoch: [21][ 47/193]	Time  1.166 ( 1.415)	Data  0.002 ( 0.295)	Loss 5.1328e-02 (9.8180e-02) 
2023-05-25 01:58:41.969976: train Epoch: [21][ 48/193]	Time  1.367 ( 1.414)	Data  0.292 ( 0.294)	Loss 9.6143e-02 (9.8138e-02) 
2023-05-25 01:58:43.268894: train Epoch: [21][ 49/193]	Time  1.299 ( 1.411)	Data  0.001 ( 0.289)	Loss 1.1257e-01 (9.8427e-02) 
2023-05-25 01:58:44.639994: train Epoch: [21][ 50/193]	Time  1.371 ( 1.411)	Data  0.298 ( 0.289)	Loss 6.8217e-02 (9.7834e-02) 
2023-05-25 01:58:45.896190: train Epoch: [21][ 51/193]	Time  1.256 ( 1.408)	Data  0.002 ( 0.283)	Loss 7.1824e-02 (9.7334e-02) 
2023-05-25 01:58:47.242410: train Epoch: [21][ 52/193]	Time  1.346 ( 1.406)	Data  0.325 ( 0.284)	Loss 7.7456e-02 (9.6959e-02) 
2023-05-25 01:58:48.332157: train Epoch: [21][ 53/193]	Time  1.090 ( 1.401)	Data  0.001 ( 0.279)	Loss 1.7990e-01 (9.8495e-02) 
2023-05-25 01:58:49.925699: train Epoch: [21][ 54/193]	Time  1.594 ( 1.404)	Data  0.601 ( 0.285)	Loss 1.1220e-01 (9.8744e-02) 
2023-05-25 01:58:50.888930: train Epoch: [21][ 55/193]	Time  0.963 ( 1.396)	Data  0.001 ( 0.280)	Loss 8.6202e-02 (9.8520e-02) 
2023-05-25 01:58:52.816888: train Epoch: [21][ 56/193]	Time  1.928 ( 1.406)	Data  0.744 ( 0.288)	Loss 6.6197e-02 (9.7953e-02) 
2023-05-25 01:58:53.813930: train Epoch: [21][ 57/193]	Time  0.997 ( 1.398)	Data  0.001 ( 0.283)	Loss 9.8070e-02 (9.7955e-02) 
2023-05-25 01:58:55.553419: train Epoch: [21][ 58/193]	Time  1.739 ( 1.404)	Data  0.491 ( 0.286)	Loss 1.0270e-01 (9.8036e-02) 
2023-05-25 01:58:56.577265: train Epoch: [21][ 59/193]	Time  1.024 ( 1.398)	Data  0.001 ( 0.282)	Loss 1.3786e-01 (9.8700e-02) 
2023-05-25 01:58:58.359419: train Epoch: [21][ 60/193]	Time  1.782 ( 1.404)	Data  0.432 ( 0.284)	Loss 1.1963e-01 (9.9043e-02) 
2023-05-25 01:58:59.391617: train Epoch: [21][ 61/193]	Time  1.032 ( 1.398)	Data  0.001 ( 0.279)	Loss 8.1048e-02 (9.8753e-02) 
2023-05-25 01:59:00.796866: train Epoch: [21][ 62/193]	Time  1.405 ( 1.398)	Data  0.299 ( 0.280)	Loss 6.3129e-02 (9.8187e-02) 
2023-05-25 01:59:01.984436: train Epoch: [21][ 63/193]	Time  1.188 ( 1.395)	Data  0.001 ( 0.275)	Loss 7.6199e-02 (9.7844e-02) 
2023-05-25 01:59:03.389957: train Epoch: [21][ 64/193]	Time  1.406 ( 1.395)	Data  0.398 ( 0.277)	Loss 1.2017e-01 (9.8187e-02) 
2023-05-25 01:59:04.652602: train Epoch: [21][ 65/193]	Time  1.263 ( 1.393)	Data  0.002 ( 0.273)	Loss 1.3763e-01 (9.8785e-02) 
2023-05-25 01:59:06.229716: train Epoch: [21][ 66/193]	Time  1.577 ( 1.396)	Data  0.444 ( 0.276)	Loss 5.1215e-02 (9.8075e-02) 
2023-05-25 01:59:07.318649: train Epoch: [21][ 67/193]	Time  1.089 ( 1.391)	Data  0.001 ( 0.272)	Loss 7.5240e-02 (9.7739e-02) 
2023-05-25 01:59:09.027829: train Epoch: [21][ 68/193]	Time  1.709 ( 1.396)	Data  0.491 ( 0.275)	Loss 2.8480e-02 (9.6735e-02) 
2023-05-25 01:59:09.998779: train Epoch: [21][ 69/193]	Time  0.971 ( 1.390)	Data  0.001 ( 0.271)	Loss 7.5363e-02 (9.6430e-02) 
2023-05-25 01:59:11.763931: train Epoch: [21][ 70/193]	Time  1.765 ( 1.395)	Data  0.503 ( 0.274)	Loss 9.6435e-02 (9.6430e-02) 
2023-05-25 01:59:12.807476: train Epoch: [21][ 71/193]	Time  1.044 ( 1.390)	Data  0.001 ( 0.270)	Loss 8.3048e-02 (9.6244e-02) 
2023-05-25 01:59:14.367948: train Epoch: [21][ 72/193]	Time  1.560 ( 1.393)	Data  0.377 ( 0.272)	Loss 7.8128e-02 (9.5996e-02) 
2023-05-25 01:59:15.353313: train Epoch: [21][ 73/193]	Time  0.985 ( 1.387)	Data  0.001 ( 0.268)	Loss 6.7922e-02 (9.5616e-02) 
2023-05-25 01:59:17.152109: train Epoch: [21][ 74/193]	Time  1.799 ( 1.393)	Data  0.524 ( 0.272)	Loss 7.4681e-02 (9.5337e-02) 
2023-05-25 01:59:18.494904: train Epoch: [21][ 75/193]	Time  1.343 ( 1.392)	Data  0.001 ( 0.268)	Loss 1.0969e-01 (9.5526e-02) 
2023-05-25 01:59:19.572325: train Epoch: [21][ 76/193]	Time  1.077 ( 1.388)	Data  0.086 ( 0.266)	Loss 1.2783e-01 (9.5946e-02) 
2023-05-25 01:59:20.629588: train Epoch: [21][ 77/193]	Time  1.057 ( 1.384)	Data  0.001 ( 0.262)	Loss 8.8081e-02 (9.5845e-02) 
2023-05-25 01:59:22.313371: train Epoch: [21][ 78/193]	Time  1.684 ( 1.387)	Data  0.651 ( 0.267)	Loss 9.2004e-02 (9.5796e-02) 
2023-05-25 01:59:23.459104: train Epoch: [21][ 79/193]	Time  1.146 ( 1.384)	Data  0.001 ( 0.264)	Loss 8.8250e-02 (9.5702e-02) 
2023-05-25 01:59:25.101535: train Epoch: [21][ 80/193]	Time  1.642 ( 1.388)	Data  0.428 ( 0.266)	Loss 6.2590e-02 (9.5293e-02) 
2023-05-25 01:59:26.088901: train Epoch: [21][ 81/193]	Time  0.987 ( 1.383)	Data  0.001 ( 0.263)	Loss 1.3149e-01 (9.5735e-02) 
2023-05-25 01:59:27.740770: train Epoch: [21][ 82/193]	Time  1.652 ( 1.386)	Data  0.427 ( 0.265)	Loss 7.9777e-02 (9.5542e-02) 
2023-05-25 01:59:28.755732: train Epoch: [21][ 83/193]	Time  1.015 ( 1.382)	Data  0.001 ( 0.262)	Loss 1.2791e-01 (9.5928e-02) 
2023-05-25 01:59:30.290329: train Epoch: [21][ 84/193]	Time  1.535 ( 1.383)	Data  0.483 ( 0.264)	Loss 8.3989e-02 (9.5787e-02) 
2023-05-25 01:59:31.487613: train Epoch: [21][ 85/193]	Time  1.197 ( 1.381)	Data  0.001 ( 0.261)	Loss 1.5004e-01 (9.6418e-02) 
2023-05-25 01:59:33.113747: train Epoch: [21][ 86/193]	Time  1.626 ( 1.384)	Data  0.479 ( 0.264)	Loss 1.4526e-01 (9.6979e-02) 
2023-05-25 01:59:34.414050: train Epoch: [21][ 87/193]	Time  1.300 ( 1.383)	Data  0.001 ( 0.261)	Loss 1.3772e-01 (9.7442e-02) 
2023-05-25 01:59:36.001111: train Epoch: [21][ 88/193]	Time  1.587 ( 1.385)	Data  0.322 ( 0.261)	Loss 1.1646e-01 (9.7656e-02) 
2023-05-25 01:59:37.049679: train Epoch: [21][ 89/193]	Time  1.049 ( 1.382)	Data  0.001 ( 0.258)	Loss 7.8007e-02 (9.7438e-02) 
2023-05-25 01:59:38.387316: train Epoch: [21][ 90/193]	Time  1.338 ( 1.381)	Data  0.366 ( 0.260)	Loss 9.9178e-02 (9.7457e-02) 
2023-05-25 01:59:39.347639: train Epoch: [21][ 91/193]	Time  0.960 ( 1.377)	Data  0.001 ( 0.257)	Loss 6.0341e-02 (9.7053e-02) 
2023-05-25 01:59:41.279077: train Epoch: [21][ 92/193]	Time  1.931 ( 1.383)	Data  0.754 ( 0.262)	Loss 7.3787e-02 (9.6803e-02) 
2023-05-25 01:59:42.336061: train Epoch: [21][ 93/193]	Time  1.057 ( 1.379)	Data  0.001 ( 0.259)	Loss 1.7183e-01 (9.7601e-02) 
2023-05-25 01:59:43.810750: train Epoch: [21][ 94/193]	Time  1.475 ( 1.380)	Data  0.396 ( 0.261)	Loss 7.4674e-02 (9.7360e-02) 
2023-05-25 01:59:44.935206: train Epoch: [21][ 95/193]	Time  1.124 ( 1.377)	Data  0.001 ( 0.258)	Loss 5.5750e-02 (9.6927e-02) 
2023-05-25 01:59:46.726374: train Epoch: [21][ 96/193]	Time  1.791 ( 1.382)	Data  0.490 ( 0.260)	Loss 8.4543e-02 (9.6799e-02) 
2023-05-25 01:59:47.866428: train Epoch: [21][ 97/193]	Time  1.140 ( 1.379)	Data  0.001 ( 0.258)	Loss 8.1767e-02 (9.6646e-02) 
2023-05-25 01:59:49.093809: train Epoch: [21][ 98/193]	Time  1.227 ( 1.378)	Data  0.281 ( 0.258)	Loss 1.3473e-01 (9.7030e-02) 
2023-05-25 01:59:50.082317: train Epoch: [21][ 99/193]	Time  0.989 ( 1.374)	Data  0.001 ( 0.255)	Loss 6.5977e-02 (9.6720e-02) 
2023-05-25 01:59:51.930420: train Epoch: [21][100/193]	Time  1.848 ( 1.378)	Data  0.820 ( 0.261)	Loss 1.0380e-01 (9.6790e-02) 
2023-05-25 01:59:52.909513: train Epoch: [21][101/193]	Time  0.979 ( 1.375)	Data  0.002 ( 0.259)	Loss 1.4865e-01 (9.7298e-02) 
2023-05-25 01:59:54.743266: train Epoch: [21][102/193]	Time  1.834 ( 1.379)	Data  0.685 ( 0.263)	Loss 7.2072e-02 (9.7053e-02) 
2023-05-25 01:59:55.775024: train Epoch: [21][103/193]	Time  1.032 ( 1.376)	Data  0.001 ( 0.260)	Loss 1.6245e-01 (9.7682e-02) 
2023-05-25 01:59:57.515472: train Epoch: [21][104/193]	Time  1.740 ( 1.379)	Data  0.451 ( 0.262)	Loss 9.0136e-02 (9.7610e-02) 
2023-05-25 01:59:58.491678: train Epoch: [21][105/193]	Time  0.976 ( 1.375)	Data  0.001 ( 0.260)	Loss 9.7895e-02 (9.7613e-02) 
2023-05-25 02:00:00.149698: train Epoch: [21][106/193]	Time  1.658 ( 1.378)	Data  0.395 ( 0.261)	Loss 1.0669e-01 (9.7698e-02) 
2023-05-25 02:00:01.279641: train Epoch: [21][107/193]	Time  1.130 ( 1.376)	Data  0.001 ( 0.258)	Loss 2.2153e-01 (9.8845e-02) 
2023-05-25 02:00:02.743731: train Epoch: [21][108/193]	Time  1.464 ( 1.377)	Data  0.367 ( 0.259)	Loss 8.6052e-02 (9.8727e-02) 
2023-05-25 02:00:03.829451: train Epoch: [21][109/193]	Time  1.086 ( 1.374)	Data  0.001 ( 0.257)	Loss 1.0955e-01 (9.8826e-02) 
2023-05-25 02:00:05.616798: train Epoch: [21][110/193]	Time  1.787 ( 1.378)	Data  0.565 ( 0.260)	Loss 1.1452e-01 (9.8967e-02) 
2023-05-25 02:00:06.684299: train Epoch: [21][111/193]	Time  1.068 ( 1.375)	Data  0.001 ( 0.257)	Loss 2.4240e-01 (1.0025e-01) 
2023-05-25 02:00:08.121672: train Epoch: [21][112/193]	Time  1.437 ( 1.375)	Data  0.462 ( 0.259)	Loss 5.3388e-02 (9.9833e-02) 
2023-05-25 02:00:09.089795: train Epoch: [21][113/193]	Time  0.968 ( 1.372)	Data  0.001 ( 0.257)	Loss 6.9835e-02 (9.9570e-02) 
2023-05-25 02:00:10.938864: train Epoch: [21][114/193]	Time  1.849 ( 1.376)	Data  0.739 ( 0.261)	Loss 1.0255e-01 (9.9596e-02) 
2023-05-25 02:00:11.986005: train Epoch: [21][115/193]	Time  1.047 ( 1.373)	Data  0.001 ( 0.259)	Loss 5.9531e-02 (9.9250e-02) 
2023-05-25 02:00:13.854425: train Epoch: [21][116/193]	Time  1.868 ( 1.377)	Data  0.548 ( 0.261)	Loss 8.2656e-02 (9.9109e-02) 
2023-05-25 02:00:14.865969: train Epoch: [21][117/193]	Time  1.012 ( 1.374)	Data  0.001 ( 0.259)	Loss 1.0209e-01 (9.9134e-02) 
2023-05-25 02:00:16.205287: train Epoch: [21][118/193]	Time  1.339 ( 1.374)	Data  0.305 ( 0.260)	Loss 5.1454e-02 (9.8733e-02) 
2023-05-25 02:00:17.352570: train Epoch: [21][119/193]	Time  1.147 ( 1.372)	Data  0.001 ( 0.257)	Loss 1.8924e-01 (9.9487e-02) 
2023-05-25 02:00:18.961546: train Epoch: [21][120/193]	Time  1.609 ( 1.374)	Data  0.571 ( 0.260)	Loss 8.3583e-02 (9.9356e-02) 
2023-05-25 02:00:20.177018: train Epoch: [21][121/193]	Time  1.215 ( 1.373)	Data  0.001 ( 0.258)	Loss 1.6486e-01 (9.9893e-02) 
2023-05-25 02:00:21.787709: train Epoch: [21][122/193]	Time  1.611 ( 1.375)	Data  0.506 ( 0.260)	Loss 1.3851e-01 (1.0021e-01) 
2023-05-25 02:00:23.117776: train Epoch: [21][123/193]	Time  1.330 ( 1.374)	Data  0.001 ( 0.258)	Loss 1.0565e-01 (1.0025e-01) 
2023-05-25 02:00:24.533225: train Epoch: [21][124/193]	Time  1.415 ( 1.375)	Data  0.284 ( 0.258)	Loss 1.7489e-01 (1.0085e-01) 
2023-05-25 02:00:25.512081: train Epoch: [21][125/193]	Time  0.979 ( 1.372)	Data  0.001 ( 0.256)	Loss 7.2371e-02 (1.0062e-01) 
2023-05-25 02:00:27.036106: train Epoch: [21][126/193]	Time  1.524 ( 1.373)	Data  0.558 ( 0.258)	Loss 1.8941e-01 (1.0132e-01) 
2023-05-25 02:00:28.121750: train Epoch: [21][127/193]	Time  1.086 ( 1.370)	Data  0.001 ( 0.256)	Loss 1.0041e-01 (1.0131e-01) 
2023-05-25 02:00:30.018851: train Epoch: [21][128/193]	Time  1.897 ( 1.375)	Data  0.691 ( 0.260)	Loss 9.5124e-02 (1.0127e-01) 
2023-05-25 02:00:30.999121: train Epoch: [21][129/193]	Time  0.980 ( 1.372)	Data  0.001 ( 0.258)	Loss 1.0921e-01 (1.0133e-01) 
2023-05-25 02:00:32.662867: train Epoch: [21][130/193]	Time  1.664 ( 1.374)	Data  0.440 ( 0.259)	Loss 1.2941e-01 (1.0154e-01) 
