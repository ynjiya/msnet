2023-05-25 21:32:19.571859: Created model 
2023-05-25 21:32:19.572679: total number of trainable parameters 20757084 
2023-05-25 21:32:19.934074: resuming the training from epoch 18 
2023-05-25 21:32:19.937348: <bound method EDiceLoss.metric of EDiceLoss()> 
2023-05-25 21:32:19.943130: Train dataset number of batch: 129 
2023-05-25 21:32:19.943220: Val dataset number of batch: 72 
2023-05-25 21:32:19.943261: Bench Test dataset number of batch: 25 
2023-05-25 21:32:19.943352: start training now! 
2023-05-25 21:32:19.943400: Batches per epoch:  129 
2023-05-25 21:32:25.969760: train Epoch: [18][  0/129]	Time  6.026 ( 6.026)	Data  4.272 ( 4.272)	Loss 8.1306e-02 (8.1306e-02) 
2023-05-25 21:32:26.920626: train Epoch: [18][  1/129]	Time  0.951 ( 3.489)	Data  0.002 ( 2.137)	Loss 9.3806e-02 (8.7556e-02) 
2023-05-25 21:32:28.791860: train Epoch: [18][  2/129]	Time  1.871 ( 2.949)	Data  0.921 ( 1.732)	Loss 2.2928e-01 (1.3480e-01) 
2023-05-25 21:32:29.742010: train Epoch: [18][  3/129]	Time  0.950 ( 2.450)	Data  0.001 ( 1.299)	Loss 1.2124e-01 (1.3141e-01) 
2023-05-25 21:32:32.535177: train Epoch: [18][  4/129]	Time  2.793 ( 2.518)	Data  1.846 ( 1.408)	Loss 6.8721e-02 (1.1887e-01) 
2023-05-25 21:32:33.483782: train Epoch: [18][  5/129]	Time  0.949 ( 2.257)	Data  0.001 ( 1.174)	Loss 6.3368e-02 (1.0962e-01) 
2023-05-25 21:32:36.150535: train Epoch: [18][  6/129]	Time  2.667 ( 2.315)	Data  1.720 ( 1.252)	Loss 1.0760e-01 (1.0933e-01) 
2023-05-25 21:32:37.099782: train Epoch: [18][  7/129]	Time  0.949 ( 2.145)	Data  0.001 ( 1.095)	Loss 8.2130e-02 (1.0593e-01) 
2023-05-25 21:32:39.742002: train Epoch: [18][  8/129]	Time  2.642 ( 2.200)	Data  1.696 ( 1.162)	Loss 8.1838e-02 (1.0325e-01) 
2023-05-25 21:32:40.690043: train Epoch: [18][  9/129]	Time  0.948 ( 2.075)	Data  0.001 ( 1.046)	Loss 9.3469e-02 (1.0228e-01) 
2023-05-25 21:32:43.332283: train Epoch: [18][ 10/129]	Time  2.642 ( 2.126)	Data  1.696 ( 1.105)	Loss 9.7049e-02 (1.0180e-01) 
2023-05-25 21:32:44.281355: train Epoch: [18][ 11/129]	Time  0.949 ( 2.028)	Data  0.001 ( 1.013)	Loss 1.0327e-01 (1.0192e-01) 
2023-05-25 21:32:46.964304: train Epoch: [18][ 12/129]	Time  2.683 ( 2.079)	Data  1.737 ( 1.069)	Loss 1.5691e-01 (1.0615e-01) 
2023-05-25 21:32:47.912250: train Epoch: [18][ 13/129]	Time  0.948 ( 1.998)	Data  0.001 ( 0.992)	Loss 9.7336e-02 (1.0552e-01) 
2023-05-25 21:32:50.461983: train Epoch: [18][ 14/129]	Time  2.550 ( 2.035)	Data  1.604 ( 1.033)	Loss 1.2542e-01 (1.0685e-01) 
2023-05-25 21:32:51.414907: train Epoch: [18][ 15/129]	Time  0.953 ( 1.967)	Data  0.001 ( 0.969)	Loss 1.6850e-01 (1.1070e-01) 
2023-05-25 21:32:54.128465: train Epoch: [18][ 16/129]	Time  2.714 ( 2.011)	Data  1.766 ( 1.016)	Loss 1.1122e-01 (1.1073e-01) 
2023-05-25 21:32:55.076385: train Epoch: [18][ 17/129]	Time  0.948 ( 1.952)	Data  0.001 ( 0.959)	Loss 2.4687e-01 (1.1830e-01) 
2023-05-25 21:32:57.725131: train Epoch: [18][ 18/129]	Time  2.649 ( 1.989)	Data  1.703 ( 0.998)	Loss 6.9170e-02 (1.1571e-01) 
2023-05-25 21:32:58.674458: train Epoch: [18][ 19/129]	Time  0.949 ( 1.937)	Data  0.001 ( 0.949)	Loss 1.0906e-01 (1.1538e-01) 
2023-05-25 21:33:01.405382: train Epoch: [18][ 20/129]	Time  2.731 ( 1.974)	Data  1.784 ( 0.988)	Loss 1.0872e-01 (1.1506e-01) 
2023-05-25 21:33:02.353768: train Epoch: [18][ 21/129]	Time  0.948 ( 1.928)	Data  0.001 ( 0.943)	Loss 1.5289e-01 (1.1678e-01) 
2023-05-25 21:33:04.953233: train Epoch: [18][ 22/129]	Time  2.599 ( 1.957)	Data  1.653 ( 0.974)	Loss 1.2320e-01 (1.1706e-01) 
2023-05-25 21:33:05.903070: train Epoch: [18][ 23/129]	Time  0.950 ( 1.915)	Data  0.001 ( 0.934)	Loss 1.4102e-01 (1.1806e-01) 
2023-05-25 21:33:08.566384: train Epoch: [18][ 24/129]	Time  2.663 ( 1.945)	Data  1.718 ( 0.965)	Loss 8.5414e-02 (1.1675e-01) 
2023-05-25 21:33:09.513828: train Epoch: [18][ 25/129]	Time  0.947 ( 1.907)	Data  0.001 ( 0.928)	Loss 1.5937e-01 (1.1839e-01) 
2023-05-25 21:33:12.163778: train Epoch: [18][ 26/129]	Time  2.650 ( 1.934)	Data  1.702 ( 0.957)	Loss 1.0011e-01 (1.1771e-01) 
2023-05-25 21:33:13.110956: train Epoch: [18][ 27/129]	Time  0.947 ( 1.899)	Data  0.001 ( 0.923)	Loss 1.3048e-01 (1.1817e-01) 
2023-05-25 21:33:15.739090: train Epoch: [18][ 28/129]	Time  2.628 ( 1.924)	Data  1.680 ( 0.949)	Loss 2.2531e-01 (1.2187e-01) 
2023-05-25 21:33:16.687709: train Epoch: [18][ 29/129]	Time  0.949 ( 1.891)	Data  0.001 ( 0.917)	Loss 1.0916e-01 (1.2144e-01) 
2023-05-25 21:33:19.369694: train Epoch: [18][ 30/129]	Time  2.682 ( 1.917)	Data  1.733 ( 0.943)	Loss 1.6356e-01 (1.2280e-01) 
2023-05-25 21:33:20.318633: train Epoch: [18][ 31/129]	Time  0.949 ( 1.887)	Data  0.001 ( 0.914)	Loss 9.0088e-02 (1.2178e-01) 
2023-05-25 21:33:23.020169: train Epoch: [18][ 32/129]	Time  2.702 ( 1.911)	Data  1.753 ( 0.939)	Loss 8.0156e-02 (1.2052e-01) 
2023-05-25 21:33:23.969585: train Epoch: [18][ 33/129]	Time  0.949 ( 1.883)	Data  0.001 ( 0.912)	Loss 1.1927e-01 (1.2048e-01) 
2023-05-25 21:33:26.644397: train Epoch: [18][ 34/129]	Time  2.675 ( 1.906)	Data  1.728 ( 0.935)	Loss 9.6506e-02 (1.1980e-01) 
2023-05-25 21:33:27.593189: train Epoch: [18][ 35/129]	Time  0.949 ( 1.879)	Data  0.001 ( 0.909)	Loss 6.0565e-02 (1.1815e-01) 
2023-05-25 21:33:30.086751: train Epoch: [18][ 36/129]	Time  2.494 ( 1.896)	Data  1.546 ( 0.926)	Loss 1.1584e-01 (1.1809e-01) 
2023-05-25 21:33:31.037556: train Epoch: [18][ 37/129]	Time  0.951 ( 1.871)	Data  0.001 ( 0.902)	Loss 1.1535e-01 (1.1802e-01) 
2023-05-25 21:33:33.694737: train Epoch: [18][ 38/129]	Time  2.657 ( 1.891)	Data  1.707 ( 0.923)	Loss 1.0227e-01 (1.1761e-01) 
2023-05-25 21:33:34.646357: train Epoch: [18][ 39/129]	Time  0.952 ( 1.868)	Data  0.001 ( 0.900)	Loss 1.0343e-01 (1.1726e-01) 
2023-05-25 21:33:37.453770: train Epoch: [18][ 40/129]	Time  2.807 ( 1.890)	Data  1.860 ( 0.923)	Loss 7.5025e-02 (1.1623e-01) 
2023-05-25 21:33:38.405324: train Epoch: [18][ 41/129]	Time  0.952 ( 1.868)	Data  0.001 ( 0.901)	Loss 7.8863e-02 (1.1534e-01) 
2023-05-25 21:33:41.079264: train Epoch: [18][ 42/129]	Time  2.674 ( 1.887)	Data  1.728 ( 0.920)	Loss 8.5785e-02 (1.1465e-01) 
2023-05-25 21:33:42.029706: train Epoch: [18][ 43/129]	Time  0.950 ( 1.866)	Data  0.001 ( 0.899)	Loss 1.5639e-01 (1.1560e-01) 
2023-05-25 21:33:44.731849: train Epoch: [18][ 44/129]	Time  2.702 ( 1.884)	Data  1.754 ( 0.918)	Loss 1.8679e-01 (1.1718e-01) 
2023-05-25 21:33:45.681357: train Epoch: [18][ 45/129]	Time  0.950 ( 1.864)	Data  0.001 ( 0.898)	Loss 1.0361e-01 (1.1689e-01) 
2023-05-25 21:33:48.481219: train Epoch: [18][ 46/129]	Time  2.800 ( 1.884)	Data  1.853 ( 0.919)	Loss 1.0476e-01 (1.1663e-01) 
2023-05-25 21:33:49.433067: train Epoch: [18][ 47/129]	Time  0.952 ( 1.864)	Data  0.001 ( 0.900)	Loss 1.1041e-01 (1.1650e-01) 
2023-05-25 21:33:52.021469: train Epoch: [18][ 48/129]	Time  2.588 ( 1.879)	Data  1.643 ( 0.915)	Loss 1.7993e-01 (1.1779e-01) 
2023-05-25 21:33:52.970608: train Epoch: [18][ 49/129]	Time  0.949 ( 1.861)	Data  0.001 ( 0.897)	Loss 8.4245e-02 (1.1712e-01) 
2023-05-25 21:33:55.690315: train Epoch: [18][ 50/129]	Time  2.720 ( 1.877)	Data  1.772 ( 0.914)	Loss 8.7101e-02 (1.1653e-01) 
2023-05-25 21:33:56.640424: train Epoch: [18][ 51/129]	Time  0.950 ( 1.860)	Data  0.001 ( 0.896)	Loss 8.1191e-02 (1.1585e-01) 
2023-05-25 21:33:59.290585: train Epoch: [18][ 52/129]	Time  2.650 ( 1.874)	Data  1.704 ( 0.911)	Loss 7.9948e-02 (1.1518e-01) 
2023-05-25 21:34:00.239263: train Epoch: [18][ 53/129]	Time  0.949 ( 1.857)	Data  0.001 ( 0.895)	Loss 1.3189e-01 (1.1549e-01) 
2023-05-25 21:34:02.967939: train Epoch: [18][ 54/129]	Time  2.729 ( 1.873)	Data  1.779 ( 0.911)	Loss 1.3166e-01 (1.1578e-01) 
2023-05-25 21:34:03.921441: train Epoch: [18][ 55/129]	Time  0.953 ( 1.857)	Data  0.001 ( 0.894)	Loss 1.0338e-01 (1.1556e-01) 
2023-05-25 21:34:06.568452: train Epoch: [18][ 56/129]	Time  2.647 ( 1.871)	Data  1.701 ( 0.909)	Loss 7.0296e-02 (1.1476e-01) 
2023-05-25 21:34:07.516579: train Epoch: [18][ 57/129]	Time  0.948 ( 1.855)	Data  0.001 ( 0.893)	Loss 8.3809e-02 (1.1423e-01) 
2023-05-25 21:34:10.181131: train Epoch: [18][ 58/129]	Time  2.665 ( 1.868)	Data  1.717 ( 0.907)	Loss 6.2787e-02 (1.1336e-01) 
2023-05-25 21:34:11.130320: train Epoch: [18][ 59/129]	Time  0.949 ( 1.853)	Data  0.001 ( 0.892)	Loss 1.1145e-01 (1.1333e-01) 
2023-05-25 21:34:13.817299: train Epoch: [18][ 60/129]	Time  2.687 ( 1.867)	Data  1.741 ( 0.906)	Loss 6.3349e-02 (1.1251e-01) 
2023-05-25 21:34:14.765585: train Epoch: [18][ 61/129]	Time  0.948 ( 1.852)	Data  0.001 ( 0.891)	Loss 1.1213e-01 (1.1250e-01) 
2023-05-25 21:34:17.328041: train Epoch: [18][ 62/129]	Time  2.562 ( 1.863)	Data  1.616 ( 0.903)	Loss 9.7934e-02 (1.1227e-01) 
2023-05-25 21:34:18.278282: train Epoch: [18][ 63/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.888)	Loss 7.8417e-02 (1.1174e-01) 
2023-05-25 21:34:20.979332: train Epoch: [18][ 64/129]	Time  2.701 ( 1.862)	Data  1.755 ( 0.902)	Loss 1.1442e-01 (1.1178e-01) 
2023-05-25 21:34:21.927698: train Epoch: [18][ 65/129]	Time  0.948 ( 1.848)	Data  0.001 ( 0.888)	Loss 7.3740e-02 (1.1121e-01) 
2023-05-25 21:34:24.602651: train Epoch: [18][ 66/129]	Time  2.675 ( 1.861)	Data  1.728 ( 0.901)	Loss 1.4903e-01 (1.1177e-01) 
2023-05-25 21:34:25.552298: train Epoch: [18][ 67/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.887)	Loss 1.5541e-01 (1.1241e-01) 
2023-05-25 21:34:28.092601: train Epoch: [18][ 68/129]	Time  2.540 ( 1.857)	Data  1.594 ( 0.898)	Loss 9.0309e-02 (1.1209e-01) 
2023-05-25 21:34:29.042524: train Epoch: [18][ 69/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.885)	Loss 1.2463e-01 (1.1227e-01) 
2023-05-25 21:34:31.618018: train Epoch: [18][ 70/129]	Time  2.575 ( 1.855)	Data  1.628 ( 0.895)	Loss 7.7740e-02 (1.1178e-01) 
2023-05-25 21:34:32.568717: train Epoch: [18][ 71/129]	Time  0.951 ( 1.842)	Data  0.001 ( 0.883)	Loss 1.0398e-01 (1.1168e-01) 
2023-05-25 21:34:35.204242: train Epoch: [18][ 72/129]	Time  2.636 ( 1.853)	Data  1.690 ( 0.894)	Loss 8.3970e-02 (1.1130e-01) 
2023-05-25 21:34:36.153644: train Epoch: [18][ 73/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.882)	Loss 6.7143e-02 (1.1070e-01) 
2023-05-25 21:34:38.689423: train Epoch: [18][ 74/129]	Time  2.536 ( 1.850)	Data  1.589 ( 0.891)	Loss 8.3402e-02 (1.1034e-01) 
2023-05-25 21:34:39.638991: train Epoch: [18][ 75/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.880)	Loss 1.5086e-01 (1.1087e-01) 
2023-05-25 21:34:42.256153: train Epoch: [18][ 76/129]	Time  2.617 ( 1.848)	Data  1.673 ( 0.890)	Loss 1.1871e-01 (1.1097e-01) 
2023-05-25 21:34:43.205307: train Epoch: [18][ 77/129]	Time  0.949 ( 1.837)	Data  0.001 ( 0.879)	Loss 5.5521e-02 (1.1026e-01) 
2023-05-25 21:34:45.750942: train Epoch: [18][ 78/129]	Time  2.546 ( 1.846)	Data  1.601 ( 0.888)	Loss 1.0484e-01 (1.1019e-01) 
2023-05-25 21:34:46.698638: train Epoch: [18][ 79/129]	Time  0.948 ( 1.834)	Data  0.001 ( 0.877)	Loss 8.9969e-02 (1.0994e-01) 
2023-05-25 21:34:49.269903: train Epoch: [18][ 80/129]	Time  2.571 ( 1.844)	Data  1.626 ( 0.886)	Loss 7.0115e-02 (1.0945e-01) 
2023-05-25 21:34:50.219432: train Epoch: [18][ 81/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.875)	Loss 8.3940e-02 (1.0914e-01) 
2023-05-25 21:34:52.839620: train Epoch: [18][ 82/129]	Time  2.620 ( 1.842)	Data  1.673 ( 0.885)	Loss 6.6462e-02 (1.0862e-01) 
2023-05-25 21:34:53.790657: train Epoch: [18][ 83/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.874)	Loss 1.4025e-01 (1.0900e-01) 
2023-05-25 21:34:56.489902: train Epoch: [18][ 84/129]	Time  2.699 ( 1.842)	Data  1.753 ( 0.884)	Loss 1.4042e-01 (1.0937e-01) 
2023-05-25 21:34:57.438297: train Epoch: [18][ 85/129]	Time  0.948 ( 1.831)	Data  0.001 ( 0.874)	Loss 7.8573e-02 (1.0901e-01) 
2023-05-25 21:35:00.093606: train Epoch: [18][ 86/129]	Time  2.655 ( 1.841)	Data  1.709 ( 0.884)	Loss 1.5042e-01 (1.0949e-01) 
2023-05-25 21:35:01.044048: train Epoch: [18][ 87/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.874)	Loss 1.0218e-01 (1.0940e-01) 
2023-05-25 21:35:03.665324: train Epoch: [18][ 88/129]	Time  2.621 ( 1.840)	Data  1.675 ( 0.883)	Loss 7.4478e-02 (1.0901e-01) 
2023-05-25 21:35:04.615514: train Epoch: [18][ 89/129]	Time  0.950 ( 1.830)	Data  0.001 ( 0.873)	Loss 9.7843e-02 (1.0889e-01) 
2023-05-25 21:35:07.294805: train Epoch: [18][ 90/129]	Time  2.679 ( 1.839)	Data  1.733 ( 0.882)	Loss 2.7507e-01 (1.1071e-01) 
2023-05-25 21:35:08.243164: train Epoch: [18][ 91/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.873)	Loss 1.0723e-01 (1.1068e-01) 
2023-05-25 21:35:10.913074: train Epoch: [18][ 92/129]	Time  2.670 ( 1.838)	Data  1.724 ( 0.882)	Loss 8.4324e-02 (1.1039e-01) 
2023-05-25 21:35:11.861089: train Epoch: [18][ 93/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.873)	Loss 1.1240e-01 (1.1041e-01) 
2023-05-25 21:35:14.458275: train Epoch: [18][ 94/129]	Time  2.597 ( 1.837)	Data  1.651 ( 0.881)	Loss 1.0855e-01 (1.1039e-01) 
2023-05-25 21:35:15.406569: train Epoch: [18][ 95/129]	Time  0.948 ( 1.828)	Data  0.001 ( 0.872)	Loss 8.9176e-02 (1.1017e-01) 
2023-05-25 21:35:18.001499: train Epoch: [18][ 96/129]	Time  2.595 ( 1.836)	Data  1.644 ( 0.880)	Loss 1.2537e-01 (1.1033e-01) 
2023-05-25 21:35:18.951335: train Epoch: [18][ 97/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.871)	Loss 8.4092e-02 (1.1006e-01) 
2023-05-25 21:35:21.558157: train Epoch: [18][ 98/129]	Time  2.607 ( 1.834)	Data  1.662 ( 0.879)	Loss 1.2814e-01 (1.1024e-01) 
2023-05-25 21:35:22.507125: train Epoch: [18][ 99/129]	Time  0.949 ( 1.826)	Data  0.001 ( 0.870)	Loss 6.7114e-02 (1.0981e-01) 
2023-05-25 21:35:25.024725: train Epoch: [18][100/129]	Time  2.518 ( 1.832)	Data  1.571 ( 0.877)	Loss 1.1334e-01 (1.0985e-01) 
2023-05-25 21:35:25.975084: train Epoch: [18][101/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.868)	Loss 1.0027e-01 (1.0975e-01) 
2023-05-25 21:35:28.590803: train Epoch: [18][102/129]	Time  2.616 ( 1.832)	Data  1.668 ( 0.876)	Loss 1.0461e-01 (1.0970e-01) 
2023-05-25 21:35:29.539898: train Epoch: [18][103/129]	Time  0.949 ( 1.823)	Data  0.001 ( 0.868)	Loss 8.3834e-02 (1.0946e-01) 
2023-05-25 21:35:32.096874: train Epoch: [18][104/129]	Time  2.557 ( 1.830)	Data  1.611 ( 0.875)	Loss 8.9472e-02 (1.0926e-01) 
2023-05-25 21:35:33.044676: train Epoch: [18][105/129]	Time  0.948 ( 1.822)	Data  0.001 ( 0.866)	Loss 9.6419e-02 (1.0914e-01) 
2023-05-25 21:35:35.607970: train Epoch: [18][106/129]	Time  2.563 ( 1.829)	Data  1.617 ( 0.873)	Loss 1.0692e-01 (1.0912e-01) 
2023-05-25 21:35:36.558046: train Epoch: [18][107/129]	Time  0.950 ( 1.821)	Data  0.001 ( 0.865)	Loss 1.7283e-01 (1.0971e-01) 
2023-05-25 21:35:39.193962: train Epoch: [18][108/129]	Time  2.636 ( 1.828)	Data  1.690 ( 0.873)	Loss 1.4777e-01 (1.1006e-01) 
2023-05-25 21:35:40.144960: train Epoch: [18][109/129]	Time  0.951 ( 1.820)	Data  0.001 ( 0.865)	Loss 1.0509e-01 (1.1002e-01) 
2023-05-25 21:35:42.790804: train Epoch: [18][110/129]	Time  2.646 ( 1.827)	Data  1.698 ( 0.872)	Loss 1.2759e-01 (1.1017e-01) 
2023-05-25 21:35:43.749663: train Epoch: [18][111/129]	Time  0.959 ( 1.820)	Data  0.001 ( 0.865)	Loss 1.5997e-01 (1.1062e-01) 
2023-05-25 21:35:46.337602: train Epoch: [18][112/129]	Time  2.588 ( 1.826)	Data  1.633 ( 0.871)	Loss 7.1713e-02 (1.1028e-01) 
2023-05-25 21:35:47.289094: train Epoch: [18][113/129]	Time  0.951 ( 1.819)	Data  0.001 ( 0.864)	Loss 7.5588e-02 (1.0997e-01) 
2023-05-25 21:35:49.924069: train Epoch: [18][114/129]	Time  2.635 ( 1.826)	Data  1.688 ( 0.871)	Loss 1.0338e-01 (1.0991e-01) 
2023-05-25 21:35:50.871713: train Epoch: [18][115/129]	Time  0.948 ( 1.818)	Data  0.001 ( 0.864)	Loss 1.2944e-01 (1.1008e-01) 
2023-05-25 21:35:53.412047: train Epoch: [18][116/129]	Time  2.540 ( 1.825)	Data  1.595 ( 0.870)	Loss 1.1002e-01 (1.1008e-01) 
2023-05-25 21:35:54.361475: train Epoch: [18][117/129]	Time  0.949 ( 1.817)	Data  0.001 ( 0.862)	Loss 1.6801e-01 (1.1057e-01) 
2023-05-25 21:35:56.973492: train Epoch: [18][118/129]	Time  2.612 ( 1.824)	Data  1.665 ( 0.869)	Loss 1.0136e-01 (1.1049e-01) 
2023-05-25 21:35:57.924273: train Epoch: [18][119/129]	Time  0.951 ( 1.817)	Data  0.001 ( 0.862)	Loss 2.1832e-01 (1.1139e-01) 
2023-05-25 21:36:00.517057: train Epoch: [18][120/129]	Time  2.593 ( 1.823)	Data  1.646 ( 0.868)	Loss 8.4390e-02 (1.1117e-01) 
2023-05-25 21:36:01.466964: train Epoch: [18][121/129]	Time  0.950 ( 1.816)	Data  0.001 ( 0.861)	Loss 1.4666e-01 (1.1146e-01) 
2023-05-25 21:36:04.047409: train Epoch: [18][122/129]	Time  2.580 ( 1.822)	Data  1.634 ( 0.868)	Loss 2.1984e-01 (1.1234e-01) 
2023-05-25 21:36:04.995375: train Epoch: [18][123/129]	Time  0.948 ( 1.815)	Data  0.001 ( 0.861)	Loss 9.3066e-02 (1.1219e-01) 
2023-05-25 21:36:07.586814: train Epoch: [18][124/129]	Time  2.591 ( 1.821)	Data  1.646 ( 0.867)	Loss 1.9071e-01 (1.1282e-01) 
2023-05-25 21:36:08.535200: train Epoch: [18][125/129]	Time  0.948 ( 1.814)	Data  0.001 ( 0.860)	Loss 1.0641e-01 (1.1276e-01) 
2023-05-25 21:36:10.707345: train Epoch: [18][126/129]	Time  2.172 ( 1.817)	Data  1.225 ( 0.863)	Loss 7.6604e-02 (1.1248e-01) 
2023-05-25 21:36:11.653876: train Epoch: [18][127/129]	Time  0.947 ( 1.810)	Data  0.001 ( 0.856)	Loss 9.7953e-02 (1.1237e-01) 
2023-05-25 21:36:13.136735: train Epoch: [18][128/129]	Time  1.483 ( 1.808)	Data  0.538 ( 0.854)	Loss 6.9618e-02 (1.1203e-01) 
2023-05-25 21:36:13.162458: Train Epoch done in 233.21905534100006 s 
2023-05-25 21:36:15.416143: val Epoch: [18][ 0/72]	Time  1.558 ( 1.558)	Data  1.342 ( 1.342)	Loss 7.4643e-02 (7.4643e-02) 
2023-05-25 21:36:15.538935: val Epoch: [18][ 1/72]	Time  0.123 ( 0.841)	Data  0.001 ( 0.672)	Loss 5.9015e-02 (6.6829e-02) 
2023-05-25 21:36:16.563665: val Epoch: [18][ 2/72]	Time  1.025 ( 0.902)	Data  0.902 ( 0.748)	Loss 1.2606e-01 (8.6573e-02) 
2023-05-25 21:36:16.685243: val Epoch: [18][ 3/72]	Time  0.122 ( 0.707)	Data  0.001 ( 0.562)	Loss 1.1812e-01 (9.4460e-02) 
2023-05-25 21:36:17.732402: val Epoch: [18][ 4/72]	Time  1.047 ( 0.775)	Data  0.925 ( 0.634)	Loss 6.7340e-02 (8.9036e-02) 
2023-05-25 21:36:17.898325: val Epoch: [18][ 5/72]	Time  0.166 ( 0.673)	Data  0.042 ( 0.535)	Loss 1.5552e-01 (1.0012e-01) 
2023-05-25 21:36:18.933894: val Epoch: [18][ 6/72]	Time  1.036 ( 0.725)	Data  0.911 ( 0.589)	Loss 5.8845e-02 (9.4220e-02) 
2023-05-25 21:36:19.099940: val Epoch: [18][ 7/72]	Time  0.166 ( 0.655)	Data  0.041 ( 0.520)	Loss 6.9042e-02 (9.1073e-02) 
2023-05-25 21:36:20.148733: val Epoch: [18][ 8/72]	Time  1.049 ( 0.699)	Data  0.924 ( 0.565)	Loss 1.5138e-01 (9.7774e-02) 
2023-05-25 21:36:20.332160: val Epoch: [18][ 9/72]	Time  0.183 ( 0.647)	Data  0.059 ( 0.515)	Loss 5.5179e-02 (9.3515e-02) 
2023-05-25 21:36:21.341088: val Epoch: [18][10/72]	Time  1.009 ( 0.680)	Data  0.887 ( 0.548)	Loss 5.1027e-02 (8.9652e-02) 
2023-05-25 21:36:21.509372: val Epoch: [18][11/72]	Time  0.168 ( 0.638)	Data  0.047 ( 0.507)	Loss 1.4310e-01 (9.4106e-02) 
2023-05-25 21:36:22.529207: val Epoch: [18][12/72]	Time  1.020 ( 0.667)	Data  0.898 ( 0.537)	Loss 6.5620e-02 (9.1915e-02) 
2023-05-25 21:36:22.762043: val Epoch: [18][13/72]	Time  0.233 ( 0.636)	Data  0.111 ( 0.506)	Loss 3.5043e-01 (1.1038e-01) 
2023-05-25 21:36:23.810848: val Epoch: [18][14/72]	Time  1.049 ( 0.664)	Data  0.924 ( 0.534)	Loss 1.4056e-01 (1.1239e-01) 
2023-05-25 21:36:23.998198: val Epoch: [18][15/72]	Time  0.187 ( 0.634)	Data  0.063 ( 0.505)	Loss 4.3376e-01 (1.3248e-01) 
2023-05-25 21:36:24.984112: val Epoch: [18][16/72]	Time  0.986 ( 0.654)	Data  0.864 ( 0.526)	Loss 9.0305e-02 (1.3000e-01) 
2023-05-25 21:36:25.207793: val Epoch: [18][17/72]	Time  0.224 ( 0.631)	Data  0.103 ( 0.502)	Loss 6.5645e-02 (1.2642e-01) 
2023-05-25 21:36:26.243785: val Epoch: [18][18/72]	Time  1.036 ( 0.652)	Data  0.914 ( 0.524)	Loss 5.3815e-01 (1.4809e-01) 
2023-05-25 21:36:26.427984: val Epoch: [18][19/72]	Time  0.184 ( 0.629)	Data  0.063 ( 0.501)	Loss 2.3388e-01 (1.5238e-01) 
2023-05-25 21:36:27.477215: val Epoch: [18][20/72]	Time  1.049 ( 0.649)	Data  0.927 ( 0.521)	Loss 8.6821e-02 (1.4926e-01) 
2023-05-25 21:36:27.666364: val Epoch: [18][21/72]	Time  0.189 ( 0.628)	Data  0.063 ( 0.500)	Loss 3.6420e-01 (1.5903e-01) 
2023-05-25 21:36:28.647622: val Epoch: [18][22/72]	Time  0.981 ( 0.643)	Data  0.859 ( 0.516)	Loss 1.5871e-01 (1.5902e-01) 
2023-05-25 21:36:28.929149: val Epoch: [18][23/72]	Time  0.282 ( 0.628)	Data  0.161 ( 0.501)	Loss 8.0130e-02 (1.5573e-01) 
2023-05-25 21:36:29.898671: val Epoch: [18][24/72]	Time  0.970 ( 0.642)	Data  0.848 ( 0.515)	Loss 1.1745e-01 (1.5420e-01) 
2023-05-25 21:36:30.166024: val Epoch: [18][25/72]	Time  0.267 ( 0.627)	Data  0.146 ( 0.501)	Loss 3.3392e-01 (1.6111e-01) 
2023-05-25 21:36:31.160671: val Epoch: [18][26/72]	Time  0.995 ( 0.641)	Data  0.872 ( 0.515)	Loss 1.7706e-01 (1.6170e-01) 
2023-05-25 21:36:31.425777: val Epoch: [18][27/72]	Time  0.265 ( 0.627)	Data  0.143 ( 0.501)	Loss 6.0843e-02 (1.5810e-01) 
2023-05-25 21:36:32.353571: val Epoch: [18][28/72]	Time  0.928 ( 0.638)	Data  0.802 ( 0.512)	Loss 1.9803e-01 (1.5948e-01) 
2023-05-25 21:36:32.588529: val Epoch: [18][29/72]	Time  0.235 ( 0.624)	Data  0.113 ( 0.498)	Loss 5.0506e-02 (1.5584e-01) 
2023-05-25 21:36:33.532798: val Epoch: [18][30/72]	Time  0.944 ( 0.635)	Data  0.822 ( 0.509)	Loss 4.3839e-02 (1.5223e-01) 
2023-05-25 21:36:33.805164: val Epoch: [18][31/72]	Time  0.272 ( 0.623)	Data  0.151 ( 0.498)	Loss 3.0748e-01 (1.5708e-01) 
2023-05-25 21:36:34.771915: val Epoch: [18][32/72]	Time  0.967 ( 0.634)	Data  0.847 ( 0.508)	Loss 4.3937e-01 (1.6564e-01) 
2023-05-25 21:36:35.046260: val Epoch: [18][33/72]	Time  0.274 ( 0.623)	Data  0.158 ( 0.498)	Loss 1.2533e-01 (1.6445e-01) 
2023-05-25 21:36:35.983798: val Epoch: [18][34/72]	Time  0.938 ( 0.632)	Data  0.817 ( 0.507)	Loss 5.4921e-02 (1.6132e-01) 
2023-05-25 21:36:36.272427: val Epoch: [18][35/72]	Time  0.289 ( 0.623)	Data  0.165 ( 0.498)	Loss 2.1217e-01 (1.6273e-01) 
2023-05-25 21:36:37.202231: val Epoch: [18][36/72]	Time  0.930 ( 0.631)	Data  0.808 ( 0.506)	Loss 5.5287e-02 (1.5983e-01) 
2023-05-25 21:36:37.437345: val Epoch: [18][37/72]	Time  0.235 ( 0.621)	Data  0.111 ( 0.496)	Loss 7.2463e-02 (1.5753e-01) 
2023-05-25 21:36:38.464095: val Epoch: [18][38/72]	Time  1.027 ( 0.631)	Data  0.901 ( 0.506)	Loss 1.1485e-01 (1.5644e-01) 
2023-05-25 21:36:38.642745: val Epoch: [18][39/72]	Time  0.179 ( 0.620)	Data  0.057 ( 0.495)	Loss 7.2653e-02 (1.5434e-01) 
2023-05-25 21:36:39.687888: val Epoch: [18][40/72]	Time  1.045 ( 0.630)	Data  0.923 ( 0.505)	Loss 6.0087e-02 (1.5204e-01) 
2023-05-25 21:36:39.849935: val Epoch: [18][41/72]	Time  0.162 ( 0.619)	Data  0.040 ( 0.494)	Loss 7.6067e-02 (1.5023e-01) 
2023-05-25 21:36:40.898357: val Epoch: [18][42/72]	Time  1.048 ( 0.629)	Data  0.926 ( 0.504)	Loss 5.3346e-02 (1.4798e-01) 
2023-05-25 21:36:41.058698: val Epoch: [18][43/72]	Time  0.160 ( 0.618)	Data  0.036 ( 0.494)	Loss 1.3260e-01 (1.4763e-01) 
2023-05-25 21:36:42.202680: val Epoch: [18][44/72]	Time  1.144 ( 0.630)	Data  1.014 ( 0.505)	Loss 9.6825e-02 (1.4650e-01) 
2023-05-25 21:36:42.326680: val Epoch: [18][45/72]	Time  0.124 ( 0.619)	Data  0.001 ( 0.494)	Loss 7.7125e-02 (1.4499e-01) 
2023-05-25 21:36:43.454280: val Epoch: [18][46/72]	Time  1.128 ( 0.630)	Data  0.999 ( 0.505)	Loss 8.2293e-02 (1.4366e-01) 
2023-05-25 21:36:43.574727: val Epoch: [18][47/72]	Time  0.120 ( 0.619)	Data  0.001 ( 0.494)	Loss 1.2943e-01 (1.4336e-01) 
2023-05-25 21:36:44.668039: val Epoch: [18][48/72]	Time  1.093 ( 0.629)	Data  0.972 ( 0.504)	Loss 7.1346e-02 (1.4189e-01) 
2023-05-25 21:36:44.784522: val Epoch: [18][49/72]	Time  0.116 ( 0.619)	Data  0.000 ( 0.494)	Loss 1.0047e-01 (1.4107e-01) 
2023-05-25 21:36:45.894459: val Epoch: [18][50/72]	Time  1.110 ( 0.628)	Data  0.990 ( 0.504)	Loss 5.1468e-02 (1.3931e-01) 
2023-05-25 21:36:46.013421: val Epoch: [18][51/72]	Time  0.119 ( 0.618)	Data  0.000 ( 0.494)	Loss 6.7751e-02 (1.3793e-01) 
2023-05-25 21:36:47.033416: val Epoch: [18][52/72]	Time  1.020 ( 0.626)	Data  0.901 ( 0.502)	Loss 1.7116e-01 (1.3856e-01) 
2023-05-25 21:36:47.235382: val Epoch: [18][53/72]	Time  0.202 ( 0.618)	Data  0.086 ( 0.494)	Loss 3.1950e-01 (1.4191e-01) 
2023-05-25 21:36:48.236102: val Epoch: [18][54/72]	Time  1.001 ( 0.625)	Data  0.884 ( 0.501)	Loss 1.4346e-01 (1.4194e-01) 
2023-05-25 21:36:48.430756: val Epoch: [18][55/72]	Time  0.195 ( 0.617)	Data  0.079 ( 0.494)	Loss 6.5760e-02 (1.4058e-01) 
2023-05-25 21:36:49.459481: val Epoch: [18][56/72]	Time  1.029 ( 0.625)	Data  0.911 ( 0.501)	Loss 9.3790e-02 (1.3976e-01) 
2023-05-25 21:36:49.641911: val Epoch: [18][57/72]	Time  0.182 ( 0.617)	Data  0.067 ( 0.493)	Loss 9.0671e-02 (1.3891e-01) 
2023-05-25 21:36:50.763353: val Epoch: [18][58/72]	Time  1.121 ( 0.626)	Data  0.998 ( 0.502)	Loss 8.8967e-02 (1.3806e-01) 
2023-05-25 21:36:50.884675: val Epoch: [18][59/72]	Time  0.121 ( 0.617)	Data  0.001 ( 0.494)	Loss 5.6986e-02 (1.3671e-01) 
2023-05-25 21:36:52.049808: val Epoch: [18][60/72]	Time  1.165 ( 0.626)	Data  1.039 ( 0.503)	Loss 1.1153e-01 (1.3630e-01) 
2023-05-25 21:36:52.173760: val Epoch: [18][61/72]	Time  0.124 ( 0.618)	Data  0.001 ( 0.494)	Loss 2.8819e-01 (1.3875e-01) 
2023-05-25 21:36:53.386557: val Epoch: [18][62/72]	Time  1.213 ( 0.627)	Data  1.085 ( 0.504)	Loss 1.3096e-01 (1.3863e-01) 
2023-05-25 21:36:53.510887: val Epoch: [18][63/72]	Time  0.124 ( 0.620)	Data  0.001 ( 0.496)	Loss 1.3549e-01 (1.3858e-01) 
2023-05-25 21:36:54.632761: val Epoch: [18][64/72]	Time  1.122 ( 0.627)	Data  0.997 ( 0.504)	Loss 2.2007e-01 (1.3983e-01) 
2023-05-25 21:36:54.753235: val Epoch: [18][65/72]	Time  0.120 ( 0.620)	Data  0.001 ( 0.496)	Loss 4.5734e-01 (1.4464e-01) 
2023-05-25 21:36:55.918945: val Epoch: [18][66/72]	Time  1.166 ( 0.628)	Data  1.040 ( 0.504)	Loss 3.4523e-01 (1.4764e-01) 
2023-05-25 21:36:56.039758: val Epoch: [18][67/72]	Time  0.121 ( 0.620)	Data  0.001 ( 0.497)	Loss 1.6148e-01 (1.4784e-01) 
2023-05-25 21:36:57.158876: val Epoch: [18][68/72]	Time  1.119 ( 0.628)	Data  0.995 ( 0.504)	Loss 2.1444e-01 (1.4880e-01) 
2023-05-25 21:36:57.279979: val Epoch: [18][69/72]	Time  0.121 ( 0.620)	Data  0.000 ( 0.497)	Loss 1.4218e-01 (1.4871e-01) 
2023-05-25 21:36:58.454105: val Epoch: [18][70/72]	Time  1.174 ( 0.628)	Data  1.050 ( 0.505)	Loss 1.5500e-01 (1.4880e-01) 
2023-05-25 21:36:58.571153: val Epoch: [18][71/72]	Time  0.117 ( 0.621)	Data  0.000 ( 0.498)	Loss 1.2733e-01 (1.4850e-01) 
2023-05-25 21:36:58.778154: Epoch 18 :Val : ['ET : 0.7003869414329529', 'TC : 0.7524312734603882', 'WT : 0.8417220711708069'] 
2023-05-25 21:36:58.780959: Epoch 18 :Val : ['ET : 0.7003869414329529', 'TC : 0.7524312734603882', 'WT : 0.8417220711708069'] 
2023-05-25 21:36:58.785491: Saving the model with DSC 0.7704412341117859 
2023-05-25 21:36:59.374971: Val epoch done in 46.21250814900122 s 
2023-05-25 21:36:59.380097: Batches per epoch:  129 
2023-05-25 21:37:04.116759: train Epoch: [19][  0/129]	Time  4.736 ( 4.736)	Data  3.734 ( 3.734)	Loss 7.7492e-02 (7.7492e-02) 
2023-05-25 21:37:05.065379: train Epoch: [19][  1/129]	Time  0.949 ( 2.843)	Data  0.001 ( 1.867)	Loss 8.3904e-02 (8.0698e-02) 
2023-05-25 21:37:07.686092: train Epoch: [19][  2/129]	Time  2.621 ( 2.769)	Data  1.667 ( 1.800)	Loss 7.2778e-02 (7.8058e-02) 
2023-05-25 21:37:08.634502: train Epoch: [19][  3/129]	Time  0.948 ( 2.314)	Data  0.001 ( 1.351)	Loss 1.2127e-01 (8.8862e-02) 
2023-05-25 21:37:11.360771: train Epoch: [19][  4/129]	Time  2.726 ( 2.396)	Data  1.769 ( 1.434)	Loss 1.4222e-01 (9.9534e-02) 
2023-05-25 21:37:12.308964: train Epoch: [19][  5/129]	Time  0.948 ( 2.155)	Data  0.001 ( 1.195)	Loss 9.0220e-02 (9.7982e-02) 
2023-05-25 21:37:15.155150: train Epoch: [19][  6/129]	Time  2.846 ( 2.254)	Data  1.900 ( 1.296)	Loss 1.2007e-01 (1.0114e-01) 
2023-05-25 21:37:16.102808: train Epoch: [19][  7/129]	Time  0.948 ( 2.090)	Data  0.001 ( 1.134)	Loss 8.8428e-02 (9.9548e-02) 
2023-05-25 21:37:18.793514: train Epoch: [19][  8/129]	Time  2.691 ( 2.157)	Data  1.746 ( 1.202)	Loss 7.5189e-02 (9.6842e-02) 
2023-05-25 21:37:19.741447: train Epoch: [19][  9/129]	Time  0.948 ( 2.036)	Data  0.001 ( 1.082)	Loss 8.9059e-02 (9.6063e-02) 
2023-05-25 21:37:22.498173: train Epoch: [19][ 10/129]	Time  2.757 ( 2.102)	Data  1.810 ( 1.148)	Loss 7.7839e-02 (9.4407e-02) 
2023-05-25 21:37:23.444976: train Epoch: [19][ 11/129]	Time  0.947 ( 2.005)	Data  0.001 ( 1.053)	Loss 1.3684e-01 (9.7942e-02) 
2023-05-25 21:37:26.287452: train Epoch: [19][ 12/129]	Time  2.842 ( 2.070)	Data  1.896 ( 1.117)	Loss 9.9311e-02 (9.8048e-02) 
2023-05-25 21:37:27.234457: train Epoch: [19][ 13/129]	Time  0.947 ( 1.990)	Data  0.001 ( 1.038)	Loss 8.2454e-02 (9.6934e-02) 
2023-05-25 21:37:29.918077: train Epoch: [19][ 14/129]	Time  2.684 ( 2.036)	Data  1.737 ( 1.084)	Loss 1.3473e-01 (9.9454e-02) 
2023-05-25 21:37:30.864346: train Epoch: [19][ 15/129]	Time  0.946 ( 1.968)	Data  0.001 ( 1.017)	Loss 7.5686e-02 (9.7968e-02) 
2023-05-25 21:37:33.501835: train Epoch: [19][ 16/129]	Time  2.637 ( 2.007)	Data  1.693 ( 1.056)	Loss 1.4286e-01 (1.0061e-01) 
2023-05-25 21:37:34.449526: train Epoch: [19][ 17/129]	Time  0.948 ( 1.948)	Data  0.001 ( 0.998)	Loss 5.0411e-02 (9.7820e-02) 
2023-05-25 21:37:37.128936: train Epoch: [19][ 18/129]	Time  2.679 ( 1.987)	Data  1.735 ( 1.037)	Loss 5.6414e-02 (9.5641e-02) 
2023-05-25 21:37:38.076584: train Epoch: [19][ 19/129]	Time  0.948 ( 1.935)	Data  0.001 ( 0.985)	Loss 7.3112e-02 (9.4515e-02) 
2023-05-25 21:37:40.745844: train Epoch: [19][ 20/129]	Time  2.669 ( 1.970)	Data  1.722 ( 1.020)	Loss 8.0825e-02 (9.3863e-02) 
2023-05-25 21:37:41.704202: train Epoch: [19][ 21/129]	Time  0.958 ( 1.924)	Data  0.001 ( 0.974)	Loss 1.0857e-01 (9.4531e-02) 
2023-05-25 21:37:44.381814: train Epoch: [19][ 22/129]	Time  2.678 ( 1.957)	Data  1.722 ( 1.006)	Loss 7.5342e-02 (9.3697e-02) 
2023-05-25 21:37:45.337768: train Epoch: [19][ 23/129]	Time  0.956 ( 1.915)	Data  0.001 ( 0.964)	Loss 1.4164e-01 (9.5694e-02) 
2023-05-25 21:37:48.009682: train Epoch: [19][ 24/129]	Time  2.672 ( 1.945)	Data  1.717 ( 0.994)	Loss 1.7321e-01 (9.8795e-02) 
2023-05-25 21:37:48.968602: train Epoch: [19][ 25/129]	Time  0.959 ( 1.907)	Data  0.001 ( 0.956)	Loss 9.4420e-02 (9.8627e-02) 
2023-05-25 21:37:51.605982: train Epoch: [19][ 26/129]	Time  2.637 ( 1.934)	Data  1.688 ( 0.983)	Loss 9.3397e-02 (9.8433e-02) 
2023-05-25 21:37:52.552864: train Epoch: [19][ 27/129]	Time  0.947 ( 1.899)	Data  0.001 ( 0.948)	Loss 6.7011e-02 (9.7311e-02) 
2023-05-25 21:37:55.222071: train Epoch: [19][ 28/129]	Time  2.669 ( 1.926)	Data  1.721 ( 0.975)	Loss 1.4465e-01 (9.8943e-02) 
2023-05-25 21:37:56.168526: train Epoch: [19][ 29/129]	Time  0.946 ( 1.893)	Data  0.001 ( 0.942)	Loss 6.6012e-02 (9.7845e-02) 
2023-05-25 21:37:58.775927: train Epoch: [19][ 30/129]	Time  2.607 ( 1.916)	Data  1.660 ( 0.966)	Loss 9.8752e-02 (9.7874e-02) 
2023-05-25 21:37:59.720566: train Epoch: [19][ 31/129]	Time  0.945 ( 1.886)	Data  0.001 ( 0.935)	Loss 7.3452e-02 (9.7111e-02) 
2023-05-25 21:38:02.304624: train Epoch: [19][ 32/129]	Time  2.584 ( 1.907)	Data  1.638 ( 0.957)	Loss 1.1673e-01 (9.7706e-02) 
2023-05-25 21:38:03.255374: train Epoch: [19][ 33/129]	Time  0.951 ( 1.879)	Data  0.001 ( 0.929)	Loss 9.6935e-02 (9.7683e-02) 
2023-05-25 21:38:06.016771: train Epoch: [19][ 34/129]	Time  2.761 ( 1.904)	Data  1.805 ( 0.954)	Loss 1.1521e-01 (9.8184e-02) 
2023-05-25 21:38:06.973465: train Epoch: [19][ 35/129]	Time  0.957 ( 1.878)	Data  0.001 ( 0.927)	Loss 9.4082e-02 (9.8070e-02) 
2023-05-25 21:38:09.623339: train Epoch: [19][ 36/129]	Time  2.650 ( 1.898)	Data  1.705 ( 0.948)	Loss 8.7277e-02 (9.7778e-02) 
2023-05-25 21:38:10.572731: train Epoch: [19][ 37/129]	Time  0.949 ( 1.873)	Data  0.001 ( 0.923)	Loss 1.1992e-01 (9.8361e-02) 
2023-05-25 21:38:13.248682: train Epoch: [19][ 38/129]	Time  2.676 ( 1.894)	Data  1.733 ( 0.944)	Loss 7.8447e-02 (9.7850e-02) 
2023-05-25 21:38:14.200159: train Epoch: [19][ 39/129]	Time  0.951 ( 1.870)	Data  0.001 ( 0.920)	Loss 6.6651e-02 (9.7070e-02) 
2023-05-25 21:38:16.926108: train Epoch: [19][ 40/129]	Time  2.726 ( 1.891)	Data  1.780 ( 0.941)	Loss 7.0525e-02 (9.6423e-02) 
2023-05-25 21:38:17.873565: train Epoch: [19][ 41/129]	Time  0.947 ( 1.869)	Data  0.001 ( 0.919)	Loss 8.2450e-02 (9.6090e-02) 
2023-05-25 21:38:20.497968: train Epoch: [19][ 42/129]	Time  2.624 ( 1.886)	Data  1.679 ( 0.937)	Loss 6.8653e-02 (9.5452e-02) 
2023-05-25 21:38:21.443946: train Epoch: [19][ 43/129]	Time  0.946 ( 1.865)	Data  0.001 ( 0.915)	Loss 7.2660e-02 (9.4934e-02) 
2023-05-25 21:38:24.077803: train Epoch: [19][ 44/129]	Time  2.634 ( 1.882)	Data  1.689 ( 0.933)	Loss 7.5380e-02 (9.4499e-02) 
2023-05-25 21:38:25.025163: train Epoch: [19][ 45/129]	Time  0.947 ( 1.862)	Data  0.001 ( 0.912)	Loss 1.5584e-01 (9.5833e-02) 
2023-05-25 21:38:27.692816: train Epoch: [19][ 46/129]	Time  2.668 ( 1.879)	Data  1.723 ( 0.930)	Loss 1.0240e-01 (9.5973e-02) 
2023-05-25 21:38:28.639761: train Epoch: [19][ 47/129]	Time  0.947 ( 1.860)	Data  0.001 ( 0.910)	Loss 9.7952e-02 (9.6014e-02) 
2023-05-25 21:38:31.247611: train Epoch: [19][ 48/129]	Time  2.608 ( 1.875)	Data  1.663 ( 0.926)	Loss 2.3366e-01 (9.8823e-02) 
2023-05-25 21:38:32.195530: train Epoch: [19][ 49/129]	Time  0.948 ( 1.856)	Data  0.001 ( 0.907)	Loss 1.7707e-01 (1.0039e-01) 
2023-05-25 21:38:34.877815: train Epoch: [19][ 50/129]	Time  2.682 ( 1.872)	Data  1.732 ( 0.923)	Loss 1.2346e-01 (1.0084e-01) 
2023-05-25 21:38:35.826563: train Epoch: [19][ 51/129]	Time  0.949 ( 1.855)	Data  0.001 ( 0.906)	Loss 1.6636e-01 (1.0210e-01) 
2023-05-25 21:38:38.526029: train Epoch: [19][ 52/129]	Time  2.699 ( 1.871)	Data  1.755 ( 0.922)	Loss 8.1929e-02 (1.0172e-01) 
2023-05-25 21:38:39.473490: train Epoch: [19][ 53/129]	Time  0.947 ( 1.854)	Data  0.001 ( 0.904)	Loss 8.1657e-02 (1.0135e-01) 
2023-05-25 21:38:42.184618: train Epoch: [19][ 54/129]	Time  2.711 ( 1.869)	Data  1.764 ( 0.920)	Loss 5.7778e-02 (1.0056e-01) 
2023-05-25 21:38:43.132438: train Epoch: [19][ 55/129]	Time  0.948 ( 1.853)	Data  0.001 ( 0.904)	Loss 8.6482e-02 (1.0030e-01) 
2023-05-25 21:38:45.807414: train Epoch: [19][ 56/129]	Time  2.675 ( 1.867)	Data  1.732 ( 0.918)	Loss 8.3942e-02 (1.0002e-01) 
2023-05-25 21:38:46.767647: train Epoch: [19][ 57/129]	Time  0.960 ( 1.852)	Data  0.002 ( 0.902)	Loss 8.0947e-02 (9.9689e-02) 
2023-05-25 21:38:49.579860: train Epoch: [19][ 58/129]	Time  2.812 ( 1.868)	Data  1.857 ( 0.919)	Loss 1.8890e-01 (1.0120e-01) 
2023-05-25 21:38:50.538997: train Epoch: [19][ 59/129]	Time  0.959 ( 1.853)	Data  0.001 ( 0.903)	Loss 1.1707e-01 (1.0147e-01) 
2023-05-25 21:38:53.323830: train Epoch: [19][ 60/129]	Time  2.785 ( 1.868)	Data  1.830 ( 0.919)	Loss 6.7279e-02 (1.0091e-01) 
2023-05-25 21:38:54.282216: train Epoch: [19][ 61/129]	Time  0.958 ( 1.853)	Data  0.001 ( 0.904)	Loss 8.0392e-02 (1.0057e-01) 
2023-05-25 21:38:56.901914: train Epoch: [19][ 62/129]	Time  2.620 ( 1.865)	Data  1.663 ( 0.916)	Loss 8.9569e-02 (1.0040e-01) 
2023-05-25 21:38:57.859731: train Epoch: [19][ 63/129]	Time  0.958 ( 1.851)	Data  0.001 ( 0.901)	Loss 1.2788e-01 (1.0083e-01) 
2023-05-25 21:39:00.505083: train Epoch: [19][ 64/129]	Time  2.645 ( 1.863)	Data  1.689 ( 0.914)	Loss 6.6792e-02 (1.0031e-01) 
2023-05-25 21:39:01.463158: train Epoch: [19][ 65/129]	Time  0.958 ( 1.850)	Data  0.001 ( 0.900)	Loss 2.3702e-01 (1.0238e-01) 
2023-05-25 21:39:04.154685: train Epoch: [19][ 66/129]	Time  2.692 ( 1.862)	Data  1.736 ( 0.912)	Loss 8.4396e-02 (1.0211e-01) 
2023-05-25 21:39:05.111998: train Epoch: [19][ 67/129]	Time  0.957 ( 1.849)	Data  0.001 ( 0.899)	Loss 9.9794e-02 (1.0207e-01) 
2023-05-25 21:39:07.747559: train Epoch: [19][ 68/129]	Time  2.636 ( 1.860)	Data  1.679 ( 0.910)	Loss 5.7305e-02 (1.0143e-01) 
2023-05-25 21:39:08.706434: train Epoch: [19][ 69/129]	Time  0.959 ( 1.848)	Data  0.001 ( 0.897)	Loss 1.0892e-01 (1.0153e-01) 
2023-05-25 21:39:11.372036: train Epoch: [19][ 70/129]	Time  2.666 ( 1.859)	Data  1.710 ( 0.909)	Loss 8.8205e-02 (1.0134e-01) 
2023-05-25 21:39:12.330770: train Epoch: [19][ 71/129]	Time  0.959 ( 1.847)	Data  0.001 ( 0.896)	Loss 8.7655e-02 (1.0115e-01) 
2023-05-25 21:39:14.996100: train Epoch: [19][ 72/129]	Time  2.665 ( 1.858)	Data  1.709 ( 0.907)	Loss 7.1952e-02 (1.0075e-01) 
2023-05-25 21:39:15.954967: train Epoch: [19][ 73/129]	Time  0.959 ( 1.846)	Data  0.001 ( 0.895)	Loss 7.0238e-02 (1.0034e-01) 
2023-05-25 21:39:18.527420: train Epoch: [19][ 74/129]	Time  2.572 ( 1.855)	Data  1.615 ( 0.904)	Loss 7.6791e-02 (1.0003e-01) 
2023-05-25 21:39:19.486371: train Epoch: [19][ 75/129]	Time  0.959 ( 1.843)	Data  0.001 ( 0.893)	Loss 7.6289e-02 (9.9716e-02) 
2023-05-25 21:39:22.120021: train Epoch: [19][ 76/129]	Time  2.634 ( 1.854)	Data  1.677 ( 0.903)	Loss 1.1631e-01 (9.9931e-02) 
2023-05-25 21:39:23.079451: train Epoch: [19][ 77/129]	Time  0.959 ( 1.842)	Data  0.001 ( 0.891)	Loss 9.5298e-02 (9.9872e-02) 
2023-05-25 21:39:25.633209: train Epoch: [19][ 78/129]	Time  2.554 ( 1.851)	Data  1.597 ( 0.900)	Loss 7.4289e-02 (9.9548e-02) 
2023-05-25 21:39:26.591890: train Epoch: [19][ 79/129]	Time  0.959 ( 1.840)	Data  0.001 ( 0.889)	Loss 8.6112e-02 (9.9380e-02) 
2023-05-25 21:39:29.174757: train Epoch: [19][ 80/129]	Time  2.583 ( 1.849)	Data  1.624 ( 0.898)	Loss 8.4596e-02 (9.9198e-02) 
2023-05-25 21:39:30.134604: train Epoch: [19][ 81/129]	Time  0.960 ( 1.838)	Data  0.001 ( 0.887)	Loss 2.2690e-01 (1.0076e-01) 
2023-05-25 21:39:32.805739: train Epoch: [19][ 82/129]	Time  2.671 ( 1.848)	Data  1.714 ( 0.897)	Loss 7.1469e-02 (1.0040e-01) 
2023-05-25 21:39:33.765059: train Epoch: [19][ 83/129]	Time  0.959 ( 1.838)	Data  0.001 ( 0.886)	Loss 8.6286e-02 (1.0023e-01) 
2023-05-25 21:39:36.416072: train Epoch: [19][ 84/129]	Time  2.651 ( 1.847)	Data  1.695 ( 0.896)	Loss 1.3884e-01 (1.0069e-01) 
2023-05-25 21:39:37.374842: train Epoch: [19][ 85/129]	Time  0.959 ( 1.837)	Data  0.001 ( 0.885)	Loss 5.6309e-02 (1.0017e-01) 
2023-05-25 21:39:39.920487: train Epoch: [19][ 86/129]	Time  2.546 ( 1.845)	Data  1.599 ( 0.894)	Loss 8.5090e-02 (9.9999e-02) 
2023-05-25 21:39:40.870425: train Epoch: [19][ 87/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.883)	Loss 8.6578e-02 (9.9846e-02) 
2023-05-25 21:39:43.489835: train Epoch: [19][ 88/129]	Time  2.619 ( 1.844)	Data  1.672 ( 0.892)	Loss 5.5964e-02 (9.9353e-02) 
2023-05-25 21:39:44.438934: train Epoch: [19][ 89/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.882)	Loss 1.4921e-01 (9.9907e-02) 
2023-05-25 21:39:47.191565: train Epoch: [19][ 90/129]	Time  2.753 ( 1.844)	Data  1.806 ( 0.893)	Loss 7.3750e-02 (9.9620e-02) 
2023-05-25 21:39:48.149528: train Epoch: [19][ 91/129]	Time  0.958 ( 1.834)	Data  0.001 ( 0.883)	Loss 1.0665e-01 (9.9696e-02) 
2023-05-25 21:39:50.769049: train Epoch: [19][ 92/129]	Time  2.620 ( 1.843)	Data  1.669 ( 0.891)	Loss 8.6933e-02 (9.9559e-02) 
2023-05-25 21:39:51.717886: train Epoch: [19][ 93/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.882)	Loss 8.7388e-02 (9.9430e-02) 
2023-05-25 21:39:54.427769: train Epoch: [19][ 94/129]	Time  2.710 ( 1.843)	Data  1.765 ( 0.891)	Loss 1.2853e-01 (9.9736e-02) 
2023-05-25 21:39:55.376981: train Epoch: [19][ 95/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.882)	Loss 9.9357e-02 (9.9732e-02) 
2023-05-25 21:39:58.077204: train Epoch: [19][ 96/129]	Time  2.700 ( 1.842)	Data  1.754 ( 0.891)	Loss 1.7484e-01 (1.0051e-01) 
2023-05-25 21:39:59.025967: train Epoch: [19][ 97/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.882)	Loss 1.2429e-01 (1.0075e-01) 
2023-05-25 21:40:01.868748: train Epoch: [19][ 98/129]	Time  2.843 ( 1.843)	Data  1.897 ( 0.892)	Loss 1.0839e-01 (1.0083e-01) 
2023-05-25 21:40:02.817413: train Epoch: [19][ 99/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.883)	Loss 6.2738e-02 (1.0045e-01) 
2023-05-25 21:40:05.655459: train Epoch: [19][100/129]	Time  2.838 ( 1.844)	Data  1.892 ( 0.893)	Loss 1.1471e-01 (1.0059e-01) 
2023-05-25 21:40:06.605084: train Epoch: [19][101/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.884)	Loss 9.1302e-02 (1.0050e-01) 
2023-05-25 21:40:09.370011: train Epoch: [19][102/129]	Time  2.765 ( 1.845)	Data  1.817 ( 0.893)	Loss 9.1594e-02 (1.0041e-01) 
2023-05-25 21:40:10.319016: train Epoch: [19][103/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.885)	Loss 9.4182e-02 (1.0035e-01) 
2023-05-25 21:40:13.104371: train Epoch: [19][104/129]	Time  2.785 ( 1.845)	Data  1.839 ( 0.894)	Loss 5.7555e-02 (9.9942e-02) 
2023-05-25 21:40:14.051314: train Epoch: [19][105/129]	Time  0.947 ( 1.837)	Data  0.001 ( 0.886)	Loss 1.2660e-01 (1.0019e-01) 
2023-05-25 21:40:16.795250: train Epoch: [19][106/129]	Time  2.744 ( 1.845)	Data  1.799 ( 0.894)	Loss 7.7722e-02 (9.9983e-02) 
2023-05-25 21:40:17.744115: train Epoch: [19][107/129]	Time  0.949 ( 1.837)	Data  0.001 ( 0.886)	Loss 9.0444e-02 (9.9895e-02) 
2023-05-25 21:40:20.519002: train Epoch: [19][108/129]	Time  2.775 ( 1.845)	Data  1.828 ( 0.894)	Loss 6.4049e-02 (9.9566e-02) 
2023-05-25 21:40:21.466169: train Epoch: [19][109/129]	Time  0.947 ( 1.837)	Data  0.001 ( 0.886)	Loss 6.5231e-02 (9.9254e-02) 
2023-05-25 21:40:24.184651: train Epoch: [19][110/129]	Time  2.718 ( 1.845)	Data  1.773 ( 0.894)	Loss 7.6281e-02 (9.9047e-02) 
2023-05-25 21:40:25.133063: train Epoch: [19][111/129]	Time  0.948 ( 1.837)	Data  0.001 ( 0.886)	Loss 8.3540e-02 (9.8908e-02) 
2023-05-25 21:40:27.750124: train Epoch: [19][112/129]	Time  2.617 ( 1.844)	Data  1.671 ( 0.893)	Loss 1.0073e-01 (9.8925e-02) 
2023-05-25 21:40:28.699005: train Epoch: [19][113/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.885)	Loss 1.1008e-01 (9.9022e-02) 
2023-05-25 21:40:31.261041: train Epoch: [19][114/129]	Time  2.562 ( 1.842)	Data  1.614 ( 0.892)	Loss 9.8034e-02 (9.9014e-02) 
2023-05-25 21:40:32.209298: train Epoch: [19][115/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.884)	Loss 9.7022e-02 (9.8997e-02) 
2023-05-25 21:40:34.832486: train Epoch: [19][116/129]	Time  2.623 ( 1.841)	Data  1.665 ( 0.891)	Loss 4.7651e-02 (9.8558e-02) 
2023-05-25 21:40:35.791880: train Epoch: [19][117/129]	Time  0.959 ( 1.834)	Data  0.001 ( 0.883)	Loss 8.0622e-02 (9.8406e-02) 
2023-05-25 21:40:38.500334: train Epoch: [19][118/129]	Time  2.708 ( 1.841)	Data  1.750 ( 0.890)	Loss 1.3880e-01 (9.8745e-02) 
2023-05-25 21:40:39.459226: train Epoch: [19][119/129]	Time  0.959 ( 1.834)	Data  0.001 ( 0.883)	Loss 7.1081e-02 (9.8515e-02) 
2023-05-25 21:40:42.110918: train Epoch: [19][120/129]	Time  2.652 ( 1.841)	Data  1.697 ( 0.890)	Loss 1.2546e-01 (9.8737e-02) 
2023-05-25 21:40:43.068838: train Epoch: [19][121/129]	Time  0.958 ( 1.834)	Data  0.001 ( 0.883)	Loss 7.1724e-02 (9.8516e-02) 
2023-05-25 21:40:45.650754: train Epoch: [19][122/129]	Time  2.582 ( 1.840)	Data  1.627 ( 0.889)	Loss 7.8962e-02 (9.8357e-02) 
2023-05-25 21:40:46.601631: train Epoch: [19][123/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.881)	Loss 1.3061e-01 (9.8617e-02) 
2023-05-25 21:40:49.213355: train Epoch: [19][124/129]	Time  2.612 ( 1.839)	Data  1.668 ( 0.888)	Loss 8.7592e-02 (9.8529e-02) 
2023-05-25 21:40:50.161181: train Epoch: [19][125/129]	Time  0.948 ( 1.832)	Data  0.001 ( 0.881)	Loss 6.5136e-02 (9.8264e-02) 
2023-05-25 21:40:52.488893: train Epoch: [19][126/129]	Time  2.328 ( 1.835)	Data  1.383 ( 0.885)	Loss 1.2125e-01 (9.8445e-02) 
2023-05-25 21:40:53.432213: train Epoch: [19][127/129]	Time  0.943 ( 1.829)	Data  0.001 ( 0.878)	Loss 7.6026e-02 (9.8270e-02) 
2023-05-25 21:40:54.901037: train Epoch: [19][128/129]	Time  1.469 ( 1.826)	Data  0.527 ( 0.875)	Loss 7.2385e-02 (9.8069e-02) 
2023-05-25 21:40:54.929948: Train Epoch done in 235.54989992400078 s 
2023-05-25 21:40:57.257288: val Epoch: [19][ 0/72]	Time  1.603 ( 1.603)	Data  1.406 ( 1.406)	Loss 1.5704e-01 (1.5704e-01) 
2023-05-25 21:40:57.378785: val Epoch: [19][ 1/72]	Time  0.122 ( 0.863)	Data  0.001 ( 0.704)	Loss 5.4106e-02 (1.0557e-01) 
2023-05-25 21:40:58.384925: val Epoch: [19][ 2/72]	Time  1.006 ( 0.910)	Data  0.884 ( 0.764)	Loss 4.6641e-01 (2.2585e-01) 
2023-05-25 21:40:58.506144: val Epoch: [19][ 3/72]	Time  0.121 ( 0.713)	Data  0.001 ( 0.573)	Loss 1.5200e-01 (2.0739e-01) 
2023-05-25 21:40:59.615173: val Epoch: [19][ 4/72]	Time  1.109 ( 0.792)	Data  0.982 ( 0.655)	Loss 1.5346e-01 (1.9660e-01) 
2023-05-25 21:40:59.737821: val Epoch: [19][ 5/72]	Time  0.123 ( 0.681)	Data  0.000 ( 0.546)	Loss 1.2934e-01 (1.8539e-01) 
2023-05-25 21:41:00.837673: val Epoch: [19][ 6/72]	Time  1.100 ( 0.741)	Data  0.981 ( 0.608)	Loss 9.1505e-02 (1.7198e-01) 
2023-05-25 21:41:00.954370: val Epoch: [19][ 7/72]	Time  0.117 ( 0.663)	Data  0.000 ( 0.532)	Loss 1.5556e-01 (1.6993e-01) 
2023-05-25 21:41:02.060239: val Epoch: [19][ 8/72]	Time  1.106 ( 0.712)	Data  0.989 ( 0.583)	Loss 1.9910e-01 (1.7317e-01) 
2023-05-25 21:41:02.176849: val Epoch: [19][ 9/72]	Time  0.117 ( 0.652)	Data  0.000 ( 0.525)	Loss 7.7604e-02 (1.6361e-01) 
2023-05-25 21:41:03.296708: val Epoch: [19][10/72]	Time  1.120 ( 0.695)	Data  1.002 ( 0.568)	Loss 6.6479e-02 (1.5478e-01) 
2023-05-25 21:41:03.413944: val Epoch: [19][11/72]	Time  0.117 ( 0.647)	Data  0.001 ( 0.521)	Loss 1.4688e-01 (1.5412e-01) 
2023-05-25 21:41:04.523974: val Epoch: [19][12/72]	Time  1.110 ( 0.682)	Data  0.992 ( 0.557)	Loss 5.7684e-02 (1.4671e-01) 
2023-05-25 21:41:04.640547: val Epoch: [19][13/72]	Time  0.117 ( 0.642)	Data  0.001 ( 0.517)	Loss 1.3819e-01 (1.4610e-01) 
2023-05-25 21:41:05.772101: val Epoch: [19][14/72]	Time  1.132 ( 0.675)	Data  1.011 ( 0.550)	Loss 1.3126e-01 (1.4511e-01) 
2023-05-25 21:41:05.889085: val Epoch: [19][15/72]	Time  0.117 ( 0.640)	Data  0.000 ( 0.516)	Loss 6.1015e-02 (1.3985e-01) 
2023-05-25 21:41:06.971128: val Epoch: [19][16/72]	Time  1.082 ( 0.666)	Data  0.960 ( 0.542)	Loss 6.7365e-02 (1.3559e-01) 
2023-05-25 21:41:07.087481: val Epoch: [19][17/72]	Time  0.116 ( 0.635)	Data  0.000 ( 0.512)	Loss 1.3291e-01 (1.3544e-01) 
2023-05-25 21:41:08.204853: val Epoch: [19][18/72]	Time  1.117 ( 0.661)	Data  0.997 ( 0.537)	Loss 7.8514e-02 (1.3244e-01) 
2023-05-25 21:41:08.321459: val Epoch: [19][19/72]	Time  0.117 ( 0.633)	Data  0.000 ( 0.511)	Loss 9.4880e-02 (1.3057e-01) 
2023-05-25 21:41:09.489536: val Epoch: [19][20/72]	Time  1.168 ( 0.659)	Data  1.042 ( 0.536)	Loss 3.6731e-01 (1.4184e-01) 
2023-05-25 21:41:09.611398: val Epoch: [19][21/72]	Time  0.122 ( 0.634)	Data  0.001 ( 0.511)	Loss 8.9046e-02 (1.3944e-01) 
2023-05-25 21:41:10.676008: val Epoch: [19][22/72]	Time  1.065 ( 0.653)	Data  0.943 ( 0.530)	Loss 1.0974e-01 (1.3815e-01) 
2023-05-25 21:41:10.833127: val Epoch: [19][23/72]	Time  0.157 ( 0.632)	Data  0.037 ( 0.510)	Loss 1.0756e-01 (1.3687e-01) 
2023-05-25 21:41:11.863340: val Epoch: [19][24/72]	Time  1.030 ( 0.648)	Data  0.908 ( 0.526)	Loss 3.0486e-01 (1.4359e-01) 
2023-05-25 21:41:12.009337: val Epoch: [19][25/72]	Time  0.146 ( 0.629)	Data  0.026 ( 0.506)	Loss 9.7506e-02 (1.4182e-01) 
2023-05-25 21:41:13.041260: val Epoch: [19][26/72]	Time  1.032 ( 0.644)	Data  0.911 ( 0.521)	Loss 1.4072e-01 (1.4178e-01) 
2023-05-25 21:41:13.223568: val Epoch: [19][27/72]	Time  0.182 ( 0.627)	Data  0.062 ( 0.505)	Loss 2.6436e-01 (1.4616e-01) 
2023-05-25 21:41:14.281370: val Epoch: [19][28/72]	Time  1.058 ( 0.642)	Data  0.936 ( 0.520)	Loss 1.0754e-01 (1.4483e-01) 
2023-05-25 21:41:14.495885: val Epoch: [19][29/72]	Time  0.215 ( 0.628)	Data  0.094 ( 0.506)	Loss 6.1508e-02 (1.4205e-01) 
2023-05-25 21:41:15.508813: val Epoch: [19][30/72]	Time  1.013 ( 0.640)	Data  0.891 ( 0.518)	Loss 5.1607e-02 (1.3913e-01) 
2023-05-25 21:41:15.730512: val Epoch: [19][31/72]	Time  0.222 ( 0.627)	Data  0.101 ( 0.505)	Loss 4.5399e-01 (1.4897e-01) 
2023-05-25 21:41:16.761264: val Epoch: [19][32/72]	Time  1.031 ( 0.640)	Data  0.909 ( 0.517)	Loss 7.5456e-02 (1.4674e-01) 
2023-05-25 21:41:16.896997: val Epoch: [19][33/72]	Time  0.136 ( 0.625)	Data  0.015 ( 0.503)	Loss 7.6309e-02 (1.4467e-01) 
2023-05-25 21:41:17.926371: val Epoch: [19][34/72]	Time  1.029 ( 0.636)	Data  0.908 ( 0.514)	Loss 1.2659e-01 (1.4415e-01) 
2023-05-25 21:41:18.076939: val Epoch: [19][35/72]	Time  0.151 ( 0.623)	Data  0.030 ( 0.501)	Loss 3.8870e-02 (1.4123e-01) 
2023-05-25 21:41:19.100367: val Epoch: [19][36/72]	Time  1.023 ( 0.634)	Data  0.901 ( 0.511)	Loss 4.7967e-02 (1.3871e-01) 
2023-05-25 21:41:19.334195: val Epoch: [19][37/72]	Time  0.234 ( 0.623)	Data  0.114 ( 0.501)	Loss 4.9271e-01 (1.4802e-01) 
2023-05-25 21:41:20.269975: val Epoch: [19][38/72]	Time  0.936 ( 0.631)	Data  0.814 ( 0.509)	Loss 5.0112e-02 (1.4551e-01) 
2023-05-25 21:41:20.549693: val Epoch: [19][39/72]	Time  0.280 ( 0.622)	Data  0.159 ( 0.500)	Loss 1.5107e-01 (1.4565e-01) 
2023-05-25 21:41:21.443361: val Epoch: [19][40/72]	Time  0.894 ( 0.629)	Data  0.771 ( 0.507)	Loss 5.5152e-02 (1.4345e-01) 
2023-05-25 21:41:21.732318: val Epoch: [19][41/72]	Time  0.289 ( 0.621)	Data  0.168 ( 0.499)	Loss 2.1706e-01 (1.4520e-01) 
2023-05-25 21:41:22.645289: val Epoch: [19][42/72]	Time  0.913 ( 0.628)	Data  0.791 ( 0.506)	Loss 6.0761e-02 (1.4323e-01) 
2023-05-25 21:41:22.982769: val Epoch: [19][43/72]	Time  0.337 ( 0.621)	Data  0.217 ( 0.499)	Loss 1.2008e-01 (1.4271e-01) 
2023-05-25 21:41:23.915717: val Epoch: [19][44/72]	Time  0.933 ( 0.628)	Data  0.811 ( 0.506)	Loss 1.1296e-01 (1.4205e-01) 
2023-05-25 21:41:24.194781: val Epoch: [19][45/72]	Time  0.279 ( 0.620)	Data  0.159 ( 0.498)	Loss 9.7774e-02 (1.4108e-01) 
2023-05-25 21:41:25.191305: val Epoch: [19][46/72]	Time  0.997 ( 0.628)	Data  0.875 ( 0.506)	Loss 1.9839e-01 (1.4230e-01) 
2023-05-25 21:41:25.402029: val Epoch: [19][47/72]	Time  0.211 ( 0.620)	Data  0.090 ( 0.498)	Loss 5.2328e-02 (1.4043e-01) 
2023-05-25 21:41:26.416995: val Epoch: [19][48/72]	Time  1.015 ( 0.628)	Data  0.894 ( 0.506)	Loss 2.2313e-01 (1.4212e-01) 
2023-05-25 21:41:26.605542: val Epoch: [19][49/72]	Time  0.189 ( 0.619)	Data  0.067 ( 0.497)	Loss 6.3534e-02 (1.4055e-01) 
2023-05-25 21:41:27.638988: val Epoch: [19][50/72]	Time  1.033 ( 0.627)	Data  0.912 ( 0.505)	Loss 6.4925e-02 (1.3906e-01) 
2023-05-25 21:41:27.832490: val Epoch: [19][51/72]	Time  0.193 ( 0.619)	Data  0.073 ( 0.497)	Loss 2.9856e-01 (1.4213e-01) 
2023-05-25 21:41:28.869694: val Epoch: [19][52/72]	Time  1.037 ( 0.627)	Data  0.916 ( 0.505)	Loss 1.0789e-01 (1.4148e-01) 
2023-05-25 21:41:29.024597: val Epoch: [19][53/72]	Time  0.155 ( 0.618)	Data  0.034 ( 0.496)	Loss 5.5111e-02 (1.3988e-01) 
2023-05-25 21:41:30.164501: val Epoch: [19][54/72]	Time  1.140 ( 0.627)	Data  1.014 ( 0.506)	Loss 8.6915e-02 (1.3892e-01) 
2023-05-25 21:41:30.285365: val Epoch: [19][55/72]	Time  0.121 ( 0.618)	Data  0.001 ( 0.497)	Loss 7.0014e-02 (1.3769e-01) 
2023-05-25 21:41:31.466065: val Epoch: [19][56/72]	Time  1.181 ( 0.628)	Data  1.051 ( 0.506)	Loss 3.4289e-01 (1.4129e-01) 
2023-05-25 21:41:31.588546: val Epoch: [19][57/72]	Time  0.122 ( 0.620)	Data  0.001 ( 0.498)	Loss 6.0569e-02 (1.3990e-01) 
2023-05-25 21:41:32.715163: val Epoch: [19][58/72]	Time  1.127 ( 0.628)	Data  1.010 ( 0.506)	Loss 6.5474e-02 (1.3864e-01) 
2023-05-25 21:41:32.831882: val Epoch: [19][59/72]	Time  0.117 ( 0.620)	Data  0.000 ( 0.498)	Loss 1.0185e-01 (1.3802e-01) 
2023-05-25 21:41:34.010339: val Epoch: [19][60/72]	Time  1.178 ( 0.629)	Data  1.061 ( 0.507)	Loss 1.1553e-01 (1.3766e-01) 
2023-05-25 21:41:34.126864: val Epoch: [19][61/72]	Time  0.117 ( 0.621)	Data  0.000 ( 0.499)	Loss 3.6210e-01 (1.4128e-01) 
2023-05-25 21:41:35.300964: val Epoch: [19][62/72]	Time  1.174 ( 0.629)	Data  1.058 ( 0.508)	Loss 9.4663e-02 (1.4054e-01) 
2023-05-25 21:41:35.417161: val Epoch: [19][63/72]	Time  0.116 ( 0.621)	Data  0.001 ( 0.500)	Loss 5.7746e-02 (1.3924e-01) 
2023-05-25 21:41:36.589153: val Epoch: [19][64/72]	Time  1.172 ( 0.630)	Data  1.055 ( 0.508)	Loss 1.0753e-01 (1.3875e-01) 
2023-05-25 21:41:36.705542: val Epoch: [19][65/72]	Time  0.116 ( 0.622)	Data  0.000 ( 0.501)	Loss 8.6862e-02 (1.3797e-01) 
2023-05-25 21:41:37.812584: val Epoch: [19][66/72]	Time  1.107 ( 0.629)	Data  0.991 ( 0.508)	Loss 2.4988e-01 (1.3964e-01) 
2023-05-25 21:41:37.929142: val Epoch: [19][67/72]	Time  0.117 ( 0.622)	Data  0.000 ( 0.501)	Loss 4.7487e-02 (1.3828e-01) 
2023-05-25 21:41:39.056387: val Epoch: [19][68/72]	Time  1.127 ( 0.629)	Data  1.010 ( 0.508)	Loss 6.5807e-02 (1.3723e-01) 
2023-05-25 21:41:39.172887: val Epoch: [19][69/72]	Time  0.116 ( 0.622)	Data  0.000 ( 0.501)	Loss 3.4213e-01 (1.4016e-01) 
2023-05-25 21:41:40.303490: val Epoch: [19][70/72]	Time  1.131 ( 0.629)	Data  1.014 ( 0.508)	Loss 3.2190e-01 (1.4272e-01) 
2023-05-25 21:41:40.418293: val Epoch: [19][71/72]	Time  0.115 ( 0.622)	Data  0.000 ( 0.501)	Loss 4.7134e-02 (1.4139e-01) 
2023-05-25 21:41:40.599080: Epoch 19 :Val : ['ET : 0.6923952102661133', 'TC : 0.7669631242752075', 'WT : 0.8555729389190674'] 
2023-05-25 21:41:40.601696: Epoch 19 :Val : ['ET : 0.6923952102661133', 'TC : 0.7669631242752075', 'WT : 0.8555729389190674'] 
2023-05-25 21:41:40.603403: Saving the model with DSC 0.7817093133926392 
2023-05-25 21:41:41.251661: Val epoch done in 46.32170598799894 s 
2023-05-25 21:41:41.256875: Batches per epoch:  129 
2023-05-25 21:41:46.192017: train Epoch: [20][  0/129]	Time  4.935 ( 4.935)	Data  3.942 ( 3.942)	Loss 7.3528e-02 (7.3528e-02) 
2023-05-25 21:41:47.138603: train Epoch: [20][  1/129]	Time  0.947 ( 2.941)	Data  0.001 ( 1.972)	Loss 7.1823e-02 (7.2676e-02) 
2023-05-25 21:41:49.842702: train Epoch: [20][  2/129]	Time  2.704 ( 2.862)	Data  1.758 ( 1.901)	Loss 1.6466e-01 (1.0334e-01) 
2023-05-25 21:41:50.789429: train Epoch: [20][  3/129]	Time  0.947 ( 2.383)	Data  0.001 ( 1.426)	Loss 7.6219e-02 (9.6559e-02) 
2023-05-25 21:41:53.393937: train Epoch: [20][  4/129]	Time  2.605 ( 2.427)	Data  1.660 ( 1.472)	Loss 5.2604e-02 (8.7768e-02) 
2023-05-25 21:41:54.341295: train Epoch: [20][  5/129]	Time  0.947 ( 2.181)	Data  0.001 ( 1.227)	Loss 6.0978e-02 (8.3303e-02) 
2023-05-25 21:41:57.053437: train Epoch: [20][  6/129]	Time  2.712 ( 2.257)	Data  1.768 ( 1.304)	Loss 6.5163e-02 (8.0711e-02) 
2023-05-25 21:41:58.000294: train Epoch: [20][  7/129]	Time  0.947 ( 2.093)	Data  0.001 ( 1.141)	Loss 8.0591e-02 (8.0696e-02) 
2023-05-25 21:42:00.712619: train Epoch: [20][  8/129]	Time  2.712 ( 2.162)	Data  1.769 ( 1.211)	Loss 7.2875e-02 (7.9827e-02) 
2023-05-25 21:42:01.660431: train Epoch: [20][  9/129]	Time  0.948 ( 2.040)	Data  0.001 ( 1.090)	Loss 1.1278e-01 (8.3122e-02) 
2023-05-25 21:42:04.280348: train Epoch: [20][ 10/129]	Time  2.620 ( 2.093)	Data  1.676 ( 1.143)	Loss 1.2395e-01 (8.6834e-02) 
2023-05-25 21:42:05.228387: train Epoch: [20][ 11/129]	Time  0.948 ( 1.998)	Data  0.002 ( 1.048)	Loss 4.1249e-02 (8.3035e-02) 
2023-05-25 21:42:07.817958: train Epoch: [20][ 12/129]	Time  2.590 ( 2.043)	Data  1.646 ( 1.094)	Loss 1.1870e-01 (8.5778e-02) 
2023-05-25 21:42:08.764894: train Epoch: [20][ 13/129]	Time  0.947 ( 1.965)	Data  0.001 ( 1.016)	Loss 5.9704e-02 (8.3916e-02) 
2023-05-25 21:42:11.404784: train Epoch: [20][ 14/129]	Time  2.640 ( 2.010)	Data  1.696 ( 1.061)	Loss 1.1110e-01 (8.5728e-02) 
2023-05-25 21:42:12.351461: train Epoch: [20][ 15/129]	Time  0.947 ( 1.943)	Data  0.001 ( 0.995)	Loss 1.0094e-01 (8.6679e-02) 
2023-05-25 21:42:14.925694: train Epoch: [20][ 16/129]	Time  2.574 ( 1.981)	Data  1.630 ( 1.032)	Loss 6.8665e-02 (8.5619e-02) 
2023-05-25 21:42:15.872353: train Epoch: [20][ 17/129]	Time  0.947 ( 1.923)	Data  0.001 ( 0.975)	Loss 9.4886e-02 (8.6134e-02) 
2023-05-25 21:42:18.516941: train Epoch: [20][ 18/129]	Time  2.645 ( 1.961)	Data  1.701 ( 1.013)	Loss 8.6703e-02 (8.6164e-02) 
2023-05-25 21:42:19.464934: train Epoch: [20][ 19/129]	Time  0.948 ( 1.910)	Data  0.001 ( 0.963)	Loss 5.6509e-02 (8.4681e-02) 
2023-05-25 21:42:22.070526: train Epoch: [20][ 20/129]	Time  2.606 ( 1.943)	Data  1.661 ( 0.996)	Loss 5.8406e-02 (8.3430e-02) 
2023-05-25 21:42:23.019093: train Epoch: [20][ 21/129]	Time  0.949 ( 1.898)	Data  0.001 ( 0.951)	Loss 8.1653e-02 (8.3349e-02) 
2023-05-25 21:42:25.630866: train Epoch: [20][ 22/129]	Time  2.612 ( 1.929)	Data  1.668 ( 0.982)	Loss 6.9731e-02 (8.2757e-02) 
2023-05-25 21:42:26.576604: train Epoch: [20][ 23/129]	Time  0.946 ( 1.888)	Data  0.001 ( 0.941)	Loss 9.6368e-02 (8.3324e-02) 
2023-05-25 21:42:29.220245: train Epoch: [20][ 24/129]	Time  2.644 ( 1.919)	Data  1.691 ( 0.971)	Loss 6.9593e-02 (8.2775e-02) 
2023-05-25 21:42:30.177574: train Epoch: [20][ 25/129]	Time  0.957 ( 1.882)	Data  0.001 ( 0.934)	Loss 7.3670e-02 (8.2425e-02) 
2023-05-25 21:42:32.693222: train Epoch: [20][ 26/129]	Time  2.516 ( 1.905)	Data  1.561 ( 0.957)	Loss 9.7267e-02 (8.2975e-02) 
2023-05-25 21:42:33.640283: train Epoch: [20][ 27/129]	Time  0.947 ( 1.871)	Data  0.001 ( 0.923)	Loss 8.5824e-02 (8.3076e-02) 
2023-05-25 21:42:36.280027: train Epoch: [20][ 28/129]	Time  2.640 ( 1.897)	Data  1.696 ( 0.949)	Loss 7.3411e-02 (8.2743e-02) 
2023-05-25 21:42:37.227329: train Epoch: [20][ 29/129]	Time  0.947 ( 1.866)	Data  0.001 ( 0.918)	Loss 9.7716e-02 (8.3242e-02) 
2023-05-25 21:42:39.822214: train Epoch: [20][ 30/129]	Time  2.595 ( 1.889)	Data  1.642 ( 0.941)	Loss 1.2327e-01 (8.4533e-02) 
2023-05-25 21:42:40.779087: train Epoch: [20][ 31/129]	Time  0.957 ( 1.860)	Data  0.001 ( 0.912)	Loss 7.2868e-02 (8.4169e-02) 
2023-05-25 21:42:43.354455: train Epoch: [20][ 32/129]	Time  2.575 ( 1.882)	Data  1.623 ( 0.933)	Loss 7.0274e-02 (8.3748e-02) 
2023-05-25 21:42:44.309455: train Epoch: [20][ 33/129]	Time  0.955 ( 1.854)	Data  0.001 ( 0.906)	Loss 6.2245e-02 (8.3115e-02) 
2023-05-25 21:42:46.958942: train Epoch: [20][ 34/129]	Time  2.649 ( 1.877)	Data  1.697 ( 0.929)	Loss 2.0047e-01 (8.6468e-02) 
2023-05-25 21:42:47.914192: train Epoch: [20][ 35/129]	Time  0.955 ( 1.852)	Data  0.001 ( 0.903)	Loss 1.0909e-01 (8.7097e-02) 
2023-05-25 21:42:50.530186: train Epoch: [20][ 36/129]	Time  2.616 ( 1.872)	Data  1.664 ( 0.923)	Loss 1.0125e-01 (8.7479e-02) 
2023-05-25 21:42:51.478719: train Epoch: [20][ 37/129]	Time  0.949 ( 1.848)	Data  0.001 ( 0.899)	Loss 1.4074e-01 (8.8881e-02) 
2023-05-25 21:42:54.231129: train Epoch: [20][ 38/129]	Time  2.752 ( 1.871)	Data  1.807 ( 0.922)	Loss 9.2951e-02 (8.8985e-02) 
2023-05-25 21:42:55.179747: train Epoch: [20][ 39/129]	Time  0.949 ( 1.848)	Data  0.001 ( 0.899)	Loss 1.0939e-01 (8.9495e-02) 
2023-05-25 21:42:57.864791: train Epoch: [20][ 40/129]	Time  2.685 ( 1.868)	Data  1.740 ( 0.920)	Loss 1.0924e-01 (8.9977e-02) 
2023-05-25 21:42:58.812772: train Epoch: [20][ 41/129]	Time  0.948 ( 1.847)	Data  0.001 ( 0.898)	Loss 9.4511e-02 (9.0085e-02) 
2023-05-25 21:43:01.466637: train Epoch: [20][ 42/129]	Time  2.654 ( 1.865)	Data  1.710 ( 0.917)	Loss 1.0122e-01 (9.0344e-02) 
2023-05-25 21:43:02.413108: train Epoch: [20][ 43/129]	Time  0.946 ( 1.844)	Data  0.001 ( 0.896)	Loss 1.0419e-01 (9.0659e-02) 
2023-05-25 21:43:04.989526: train Epoch: [20][ 44/129]	Time  2.576 ( 1.861)	Data  1.632 ( 0.912)	Loss 9.7687e-02 (9.0815e-02) 
2023-05-25 21:43:05.937295: train Epoch: [20][ 45/129]	Time  0.948 ( 1.841)	Data  0.001 ( 0.893)	Loss 8.2926e-02 (9.0643e-02) 
2023-05-25 21:43:08.550674: train Epoch: [20][ 46/129]	Time  2.613 ( 1.857)	Data  1.669 ( 0.909)	Loss 9.2233e-02 (9.0677e-02) 
2023-05-25 21:43:09.497673: train Epoch: [20][ 47/129]	Time  0.947 ( 1.838)	Data  0.001 ( 0.890)	Loss 1.6842e-01 (9.2297e-02) 
2023-05-25 21:43:12.148254: train Epoch: [20][ 48/129]	Time  2.651 ( 1.855)	Data  1.706 ( 0.907)	Loss 8.6683e-02 (9.2182e-02) 
2023-05-25 21:43:13.096534: train Epoch: [20][ 49/129]	Time  0.948 ( 1.837)	Data  0.001 ( 0.889)	Loss 6.9311e-02 (9.1725e-02) 
2023-05-25 21:43:15.726789: train Epoch: [20][ 50/129]	Time  2.630 ( 1.852)	Data  1.676 ( 0.904)	Loss 9.4213e-02 (9.1774e-02) 
2023-05-25 21:43:16.678759: train Epoch: [20][ 51/129]	Time  0.952 ( 1.835)	Data  0.001 ( 0.887)	Loss 1.0934e-01 (9.2111e-02) 
2023-05-25 21:43:19.286050: train Epoch: [20][ 52/129]	Time  2.607 ( 1.850)	Data  1.651 ( 0.901)	Loss 7.8341e-02 (9.1852e-02) 
2023-05-25 21:43:20.232836: train Epoch: [20][ 53/129]	Time  0.947 ( 1.833)	Data  0.001 ( 0.884)	Loss 6.6905e-02 (9.1390e-02) 
2023-05-25 21:43:22.743032: train Epoch: [20][ 54/129]	Time  2.510 ( 1.845)	Data  1.565 ( 0.897)	Loss 6.7054e-02 (9.0947e-02) 
2023-05-25 21:43:23.691481: train Epoch: [20][ 55/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.881)	Loss 5.6937e-02 (9.0340e-02) 
2023-05-25 21:43:26.329425: train Epoch: [20][ 56/129]	Time  2.638 ( 1.843)	Data  1.693 ( 0.895)	Loss 1.5525e-01 (9.1479e-02) 
2023-05-25 21:43:27.281416: train Epoch: [20][ 57/129]	Time  0.952 ( 1.828)	Data  0.001 ( 0.880)	Loss 5.5251e-02 (9.0854e-02) 
2023-05-25 21:43:29.942365: train Epoch: [20][ 58/129]	Time  2.661 ( 1.842)	Data  1.713 ( 0.894)	Loss 1.0019e-01 (9.1012e-02) 
2023-05-25 21:43:30.889329: train Epoch: [20][ 59/129]	Time  0.947 ( 1.827)	Data  0.001 ( 0.879)	Loss 1.3390e-01 (9.1727e-02) 
2023-05-25 21:43:33.534349: train Epoch: [20][ 60/129]	Time  2.645 ( 1.841)	Data  1.690 ( 0.892)	Loss 9.0004e-02 (9.1699e-02) 
2023-05-25 21:43:34.481344: train Epoch: [20][ 61/129]	Time  0.947 ( 1.826)	Data  0.001 ( 0.878)	Loss 1.0239e-01 (9.1871e-02) 
2023-05-25 21:43:37.077879: train Epoch: [20][ 62/129]	Time  2.597 ( 1.838)	Data  1.653 ( 0.890)	Loss 5.9829e-02 (9.1363e-02) 
2023-05-25 21:43:38.024594: train Epoch: [20][ 63/129]	Time  0.947 ( 1.824)	Data  0.001 ( 0.876)	Loss 6.9572e-02 (9.1022e-02) 
2023-05-25 21:43:40.726606: train Epoch: [20][ 64/129]	Time  2.702 ( 1.838)	Data  1.755 ( 0.890)	Loss 1.2920e-01 (9.1610e-02) 
2023-05-25 21:43:41.675772: train Epoch: [20][ 65/129]	Time  0.949 ( 1.825)	Data  0.001 ( 0.876)	Loss 7.9601e-02 (9.1428e-02) 
2023-05-25 21:43:44.413897: train Epoch: [20][ 66/129]	Time  2.738 ( 1.838)	Data  1.790 ( 0.890)	Loss 8.6357e-02 (9.1352e-02) 
2023-05-25 21:43:45.366710: train Epoch: [20][ 67/129]	Time  0.953 ( 1.825)	Data  0.001 ( 0.877)	Loss 7.0210e-02 (9.1041e-02) 
2023-05-25 21:43:48.073164: train Epoch: [20][ 68/129]	Time  2.706 ( 1.838)	Data  1.750 ( 0.890)	Loss 1.3503e-01 (9.1679e-02) 
2023-05-25 21:43:49.024801: train Epoch: [20][ 69/129]	Time  0.952 ( 1.825)	Data  0.001 ( 0.877)	Loss 6.5613e-02 (9.1306e-02) 
2023-05-25 21:43:51.753719: train Epoch: [20][ 70/129]	Time  2.729 ( 1.838)	Data  1.770 ( 0.889)	Loss 1.3066e-01 (9.1861e-02) 
2023-05-25 21:43:52.704270: train Epoch: [20][ 71/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.877)	Loss 9.8763e-02 (9.1956e-02) 
2023-05-25 21:43:55.458976: train Epoch: [20][ 72/129]	Time  2.755 ( 1.838)	Data  1.793 ( 0.890)	Loss 9.5995e-02 (9.2012e-02) 
2023-05-25 21:43:56.408661: train Epoch: [20][ 73/129]	Time  0.950 ( 1.826)	Data  0.001 ( 0.878)	Loss 1.2652e-01 (9.2478e-02) 
2023-05-25 21:43:59.199938: train Epoch: [20][ 74/129]	Time  2.791 ( 1.839)	Data  1.843 ( 0.890)	Loss 9.6093e-02 (9.2526e-02) 
2023-05-25 21:44:00.148615: train Epoch: [20][ 75/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.879)	Loss 1.2275e-01 (9.2924e-02) 
2023-05-25 21:44:02.939855: train Epoch: [20][ 76/129]	Time  2.791 ( 1.840)	Data  1.833 ( 0.891)	Loss 5.1630e-02 (9.2388e-02) 
2023-05-25 21:44:03.890958: train Epoch: [20][ 77/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.880)	Loss 6.4140e-02 (9.2026e-02) 
2023-05-25 21:44:06.698375: train Epoch: [20][ 78/129]	Time  2.807 ( 1.841)	Data  1.861 ( 0.892)	Loss 8.8322e-02 (9.1979e-02) 
2023-05-25 21:44:07.648075: train Epoch: [20][ 79/129]	Time  0.950 ( 1.830)	Data  0.001 ( 0.881)	Loss 8.7491e-02 (9.1923e-02) 
2023-05-25 21:44:10.366008: train Epoch: [20][ 80/129]	Time  2.718 ( 1.841)	Data  1.771 ( 0.892)	Loss 8.9892e-02 (9.1897e-02) 
2023-05-25 21:44:11.315364: train Epoch: [20][ 81/129]	Time  0.949 ( 1.830)	Data  0.001 ( 0.881)	Loss 6.9410e-02 (9.1623e-02) 
2023-05-25 21:44:13.980781: train Epoch: [20][ 82/129]	Time  2.665 ( 1.840)	Data  1.720 ( 0.891)	Loss 7.6488e-02 (9.1441e-02) 
2023-05-25 21:44:14.928417: train Epoch: [20][ 83/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.881)	Loss 1.1046e-01 (9.1667e-02) 
2023-05-25 21:44:17.545979: train Epoch: [20][ 84/129]	Time  2.618 ( 1.839)	Data  1.670 ( 0.890)	Loss 1.4447e-01 (9.2289e-02) 
2023-05-25 21:44:18.495349: train Epoch: [20][ 85/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.880)	Loss 1.0627e-01 (9.2451e-02) 
2023-05-25 21:44:21.146937: train Epoch: [20][ 86/129]	Time  2.652 ( 1.838)	Data  1.706 ( 0.889)	Loss 1.0056e-01 (9.2544e-02) 
2023-05-25 21:44:22.096127: train Epoch: [20][ 87/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.879)	Loss 9.1912e-02 (9.2537e-02) 
2023-05-25 21:44:24.707596: train Epoch: [20][ 88/129]	Time  2.611 ( 1.837)	Data  1.665 ( 0.888)	Loss 9.4379e-02 (9.2558e-02) 
2023-05-25 21:44:25.656844: train Epoch: [20][ 89/129]	Time  0.949 ( 1.827)	Data  0.001 ( 0.878)	Loss 7.6630e-02 (9.2381e-02) 
2023-05-25 21:44:28.334656: train Epoch: [20][ 90/129]	Time  2.678 ( 1.836)	Data  1.731 ( 0.887)	Loss 9.6220e-02 (9.2423e-02) 
2023-05-25 21:44:29.283762: train Epoch: [20][ 91/129]	Time  0.949 ( 1.826)	Data  0.001 ( 0.878)	Loss 9.3568e-02 (9.2436e-02) 
2023-05-25 21:44:31.915833: train Epoch: [20][ 92/129]	Time  2.632 ( 1.835)	Data  1.688 ( 0.886)	Loss 9.1161e-02 (9.2422e-02) 
2023-05-25 21:44:32.866136: train Epoch: [20][ 93/129]	Time  0.950 ( 1.826)	Data  0.001 ( 0.877)	Loss 1.0939e-01 (9.2602e-02) 
2023-05-25 21:44:35.603127: train Epoch: [20][ 94/129]	Time  2.737 ( 1.835)	Data  1.792 ( 0.887)	Loss 9.5255e-02 (9.2630e-02) 
2023-05-25 21:44:36.552489: train Epoch: [20][ 95/129]	Time  0.949 ( 1.826)	Data  0.001 ( 0.877)	Loss 1.4197e-01 (9.3144e-02) 
2023-05-25 21:44:39.304600: train Epoch: [20][ 96/129]	Time  2.752 ( 1.836)	Data  1.808 ( 0.887)	Loss 7.2027e-02 (9.2927e-02) 
2023-05-25 21:44:40.252944: train Epoch: [20][ 97/129]	Time  0.948 ( 1.826)	Data  0.001 ( 0.878)	Loss 8.0030e-02 (9.2795e-02) 
2023-05-25 21:44:42.858294: train Epoch: [20][ 98/129]	Time  2.605 ( 1.834)	Data  1.661 ( 0.886)	Loss 7.4986e-02 (9.2615e-02) 
2023-05-25 21:44:43.808241: train Epoch: [20][ 99/129]	Time  0.950 ( 1.826)	Data  0.001 ( 0.877)	Loss 9.0827e-02 (9.2597e-02) 
2023-05-25 21:44:46.360845: train Epoch: [20][100/129]	Time  2.553 ( 1.833)	Data  1.606 ( 0.884)	Loss 6.0225e-02 (9.2277e-02) 
2023-05-25 21:44:47.309989: train Epoch: [20][101/129]	Time  0.949 ( 1.824)	Data  0.001 ( 0.876)	Loss 6.0311e-02 (9.1963e-02) 
2023-05-25 21:44:49.984986: train Epoch: [20][102/129]	Time  2.675 ( 1.832)	Data  1.728 ( 0.884)	Loss 1.1256e-01 (9.2163e-02) 
2023-05-25 21:44:50.934158: train Epoch: [20][103/129]	Time  0.949 ( 1.824)	Data  0.001 ( 0.875)	Loss 9.7128e-02 (9.2211e-02) 
2023-05-25 21:44:53.603953: train Epoch: [20][104/129]	Time  2.670 ( 1.832)	Data  1.725 ( 0.883)	Loss 8.6120e-02 (9.2153e-02) 
2023-05-25 21:44:54.552836: train Epoch: [20][105/129]	Time  0.949 ( 1.824)	Data  0.001 ( 0.875)	Loss 1.1947e-01 (9.2411e-02) 
2023-05-25 21:44:57.123656: train Epoch: [20][106/129]	Time  2.571 ( 1.831)	Data  1.626 ( 0.882)	Loss 9.5205e-02 (9.2437e-02) 
2023-05-25 21:44:58.073311: train Epoch: [20][107/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.874)	Loss 1.6249e-01 (9.3085e-02) 
2023-05-25 21:45:00.714401: train Epoch: [20][108/129]	Time  2.641 ( 1.830)	Data  1.695 ( 0.882)	Loss 9.7448e-02 (9.3126e-02) 
2023-05-25 21:45:01.663060: train Epoch: [20][109/129]	Time  0.949 ( 1.822)	Data  0.001 ( 0.873)	Loss 7.1179e-02 (9.2926e-02) 
2023-05-25 21:45:04.382418: train Epoch: [20][110/129]	Time  2.719 ( 1.830)	Data  1.772 ( 0.882)	Loss 6.3632e-02 (9.2662e-02) 
2023-05-25 21:45:05.331358: train Epoch: [20][111/129]	Time  0.949 ( 1.822)	Data  0.001 ( 0.874)	Loss 8.4126e-02 (9.2586e-02) 
2023-05-25 21:45:08.035494: train Epoch: [20][112/129]	Time  2.704 ( 1.830)	Data  1.759 ( 0.882)	Loss 1.0547e-01 (9.2700e-02) 
2023-05-25 21:45:08.983767: train Epoch: [20][113/129]	Time  0.948 ( 1.822)	Data  0.001 ( 0.874)	Loss 1.0223e-01 (9.2784e-02) 
2023-05-25 21:45:11.632349: train Epoch: [20][114/129]	Time  2.649 ( 1.829)	Data  1.700 ( 0.881)	Loss 8.8909e-02 (9.2750e-02) 
2023-05-25 21:45:12.586783: train Epoch: [20][115/129]	Time  0.954 ( 1.822)	Data  0.001 ( 0.873)	Loss 1.1972e-01 (9.2982e-02) 
2023-05-25 21:45:15.301312: train Epoch: [20][116/129]	Time  2.715 ( 1.829)	Data  1.760 ( 0.881)	Loss 5.5107e-02 (9.2659e-02) 
2023-05-25 21:45:16.261205: train Epoch: [20][117/129]	Time  0.960 ( 1.822)	Data  0.001 ( 0.874)	Loss 1.3389e-01 (9.3008e-02) 
2023-05-25 21:45:18.890342: train Epoch: [20][118/129]	Time  2.629 ( 1.829)	Data  1.675 ( 0.880)	Loss 2.5594e-01 (9.4377e-02) 
2023-05-25 21:45:19.847520: train Epoch: [20][119/129]	Time  0.957 ( 1.822)	Data  0.001 ( 0.873)	Loss 6.3327e-02 (9.4118e-02) 
2023-05-25 21:45:22.489625: train Epoch: [20][120/129]	Time  2.642 ( 1.828)	Data  1.687 ( 0.880)	Loss 6.5956e-02 (9.3886e-02) 
2023-05-25 21:45:23.436741: train Epoch: [20][121/129]	Time  0.947 ( 1.821)	Data  0.001 ( 0.872)	Loss 8.7356e-02 (9.3832e-02) 
2023-05-25 21:45:26.157389: train Epoch: [20][122/129]	Time  2.721 ( 1.828)	Data  1.775 ( 0.880)	Loss 7.3605e-02 (9.3668e-02) 
2023-05-25 21:45:27.105230: train Epoch: [20][123/129]	Time  0.948 ( 1.821)	Data  0.001 ( 0.873)	Loss 1.0471e-01 (9.3757e-02) 
2023-05-25 21:45:29.792823: train Epoch: [20][124/129]	Time  2.688 ( 1.828)	Data  1.742 ( 0.880)	Loss 1.1255e-01 (9.3907e-02) 
2023-05-25 21:45:30.741065: train Epoch: [20][125/129]	Time  0.948 ( 1.821)	Data  0.001 ( 0.873)	Loss 1.5522e-01 (9.4394e-02) 
2023-05-25 21:45:33.280856: train Epoch: [20][126/129]	Time  2.540 ( 1.827)	Data  1.594 ( 0.878)	Loss 1.8707e-01 (9.5123e-02) 
2023-05-25 21:45:34.225542: train Epoch: [20][127/129]	Time  0.945 ( 1.820)	Data  0.001 ( 0.872)	Loss 1.1289e-01 (9.5262e-02) 
2023-05-25 21:45:35.708741: train Epoch: [20][128/129]	Time  1.483 ( 1.817)	Data  0.539 ( 0.869)	Loss 5.9801e-02 (9.4987e-02) 
2023-05-25 21:45:35.739375: Train Epoch done in 234.48252684100044 s 
2023-05-25 21:45:38.092525: val Epoch: [20][ 0/72]	Time  1.621 ( 1.621)	Data  1.450 ( 1.450)	Loss 6.1465e-02 (6.1465e-02) 
2023-05-25 21:45:38.212115: val Epoch: [20][ 1/72]	Time  0.120 ( 0.870)	Data  0.002 ( 0.726)	Loss 6.7599e-02 (6.4532e-02) 
2023-05-25 21:45:39.252629: val Epoch: [20][ 2/72]	Time  1.041 ( 0.927)	Data  0.922 ( 0.791)	Loss 1.2120e-01 (8.3420e-02) 
2023-05-25 21:45:39.369680: val Epoch: [20][ 3/72]	Time  0.117 ( 0.724)	Data  0.001 ( 0.594)	Loss 3.6020e-01 (1.5262e-01) 
2023-05-25 21:45:40.482884: val Epoch: [20][ 4/72]	Time  1.113 ( 0.802)	Data  0.995 ( 0.674)	Loss 5.3069e-02 (1.3271e-01) 
2023-05-25 21:45:40.599446: val Epoch: [20][ 5/72]	Time  0.117 ( 0.688)	Data  0.000 ( 0.562)	Loss 6.8633e-02 (1.2203e-01) 
2023-05-25 21:45:41.672107: val Epoch: [20][ 6/72]	Time  1.073 ( 0.743)	Data  0.955 ( 0.618)	Loss 4.9753e-02 (1.1170e-01) 
2023-05-25 21:45:41.788843: val Epoch: [20][ 7/72]	Time  0.117 ( 0.665)	Data  0.000 ( 0.541)	Loss 2.1006e-01 (1.2400e-01) 
2023-05-25 21:45:42.838155: val Epoch: [20][ 8/72]	Time  1.049 ( 0.707)	Data  0.929 ( 0.584)	Loss 9.2959e-02 (1.2055e-01) 
2023-05-25 21:45:42.980969: val Epoch: [20][ 9/72]	Time  0.143 ( 0.651)	Data  0.026 ( 0.528)	Loss 5.4439e-02 (1.1394e-01) 
2023-05-25 21:45:44.122412: val Epoch: [20][10/72]	Time  1.141 ( 0.696)	Data  1.024 ( 0.573)	Loss 2.0640e-01 (1.2234e-01) 
2023-05-25 21:45:44.240862: val Epoch: [20][11/72]	Time  0.118 ( 0.647)	Data  0.001 ( 0.525)	Loss 6.4593e-02 (1.1753e-01) 
2023-05-25 21:45:45.348632: val Epoch: [20][12/72]	Time  1.108 ( 0.683)	Data  0.983 ( 0.561)	Loss 3.3434e-01 (1.3421e-01) 
2023-05-25 21:45:45.510530: val Epoch: [20][13/72]	Time  0.162 ( 0.646)	Data  0.038 ( 0.523)	Loss 7.0714e-02 (1.2967e-01) 
2023-05-25 21:45:46.529091: val Epoch: [20][14/72]	Time  1.019 ( 0.670)	Data  0.897 ( 0.548)	Loss 6.4711e-02 (1.2534e-01) 
2023-05-25 21:45:46.739603: val Epoch: [20][15/72]	Time  0.211 ( 0.642)	Data  0.086 ( 0.519)	Loss 9.4355e-02 (1.2341e-01) 
2023-05-25 21:45:47.764144: val Epoch: [20][16/72]	Time  1.025 ( 0.664)	Data  0.902 ( 0.542)	Loss 1.1386e-01 (1.2284e-01) 
2023-05-25 21:45:47.966333: val Epoch: [20][17/72]	Time  0.202 ( 0.639)	Data  0.077 ( 0.516)	Loss 7.5950e-02 (1.2024e-01) 
2023-05-25 21:45:49.031814: val Epoch: [20][18/72]	Time  1.065 ( 0.661)	Data  0.940 ( 0.538)	Loss 7.6128e-02 (1.1792e-01) 
2023-05-25 21:45:49.190585: val Epoch: [20][19/72]	Time  0.159 ( 0.636)	Data  0.034 ( 0.513)	Loss 4.6105e-02 (1.1433e-01) 
2023-05-25 21:45:50.251834: val Epoch: [20][20/72]	Time  1.061 ( 0.656)	Data  0.935 ( 0.533)	Loss 8.5576e-02 (1.1296e-01) 
2023-05-25 21:45:50.465299: val Epoch: [20][21/72]	Time  0.213 ( 0.636)	Data  0.089 ( 0.513)	Loss 1.6323e-01 (1.1524e-01) 
2023-05-25 21:45:51.483196: val Epoch: [20][22/72]	Time  1.018 ( 0.653)	Data  0.895 ( 0.530)	Loss 2.9549e-01 (1.2308e-01) 
2023-05-25 21:45:51.720730: val Epoch: [20][23/72]	Time  0.238 ( 0.635)	Data  0.113 ( 0.512)	Loss 3.4982e-01 (1.3253e-01) 
2023-05-25 21:45:52.738386: val Epoch: [20][24/72]	Time  1.018 ( 0.651)	Data  0.892 ( 0.527)	Loss 5.3122e-01 (1.4847e-01) 
2023-05-25 21:45:52.906064: val Epoch: [20][25/72]	Time  0.168 ( 0.632)	Data  0.046 ( 0.509)	Loss 7.3250e-02 (1.4558e-01) 
2023-05-25 21:45:53.958371: val Epoch: [20][26/72]	Time  1.052 ( 0.648)	Data  0.930 ( 0.525)	Loss 1.6089e-01 (1.4615e-01) 
2023-05-25 21:45:54.144753: val Epoch: [20][27/72]	Time  0.186 ( 0.631)	Data  0.065 ( 0.508)	Loss 4.9160e-01 (1.5849e-01) 
2023-05-25 21:45:55.197960: val Epoch: [20][28/72]	Time  1.053 ( 0.646)	Data  0.931 ( 0.523)	Loss 1.1903e-01 (1.5713e-01) 
2023-05-25 21:45:55.339593: val Epoch: [20][29/72]	Time  0.142 ( 0.629)	Data  0.020 ( 0.506)	Loss 1.0003e-01 (1.5522e-01) 
2023-05-25 21:45:56.497836: val Epoch: [20][30/72]	Time  1.158 ( 0.646)	Data  1.032 ( 0.523)	Loss 1.1438e-01 (1.5390e-01) 
2023-05-25 21:45:56.619072: val Epoch: [20][31/72]	Time  0.121 ( 0.630)	Data  0.001 ( 0.507)	Loss 1.5572e-01 (1.5396e-01) 
2023-05-25 21:45:57.735139: val Epoch: [20][32/72]	Time  1.116 ( 0.644)	Data  0.986 ( 0.521)	Loss 1.1961e-01 (1.5292e-01) 
2023-05-25 21:45:57.856860: val Epoch: [20][33/72]	Time  0.122 ( 0.629)	Data  0.001 ( 0.506)	Loss 4.5903e-02 (1.4977e-01) 
2023-05-25 21:45:59.021983: val Epoch: [20][34/72]	Time  1.165 ( 0.644)	Data  1.037 ( 0.521)	Loss 2.6474e-01 (1.5306e-01) 
2023-05-25 21:45:59.141663: val Epoch: [20][35/72]	Time  0.120 ( 0.630)	Data  0.000 ( 0.507)	Loss 1.8718e-01 (1.5401e-01) 
2023-05-25 21:46:00.345514: val Epoch: [20][36/72]	Time  1.204 ( 0.645)	Data  1.082 ( 0.522)	Loss 3.8700e-01 (1.6030e-01) 
2023-05-25 21:46:00.461850: val Epoch: [20][37/72]	Time  0.116 ( 0.631)	Data  0.000 ( 0.508)	Loss 6.9725e-02 (1.5792e-01) 
2023-05-25 21:46:01.663491: val Epoch: [20][38/72]	Time  1.202 ( 0.646)	Data  1.082 ( 0.523)	Loss 8.0418e-02 (1.5593e-01) 
2023-05-25 21:46:01.780519: val Epoch: [20][39/72]	Time  0.117 ( 0.633)	Data  0.000 ( 0.510)	Loss 4.9556e-01 (1.6442e-01) 
2023-05-25 21:46:02.913589: val Epoch: [20][40/72]	Time  1.133 ( 0.645)	Data  1.013 ( 0.522)	Loss 1.6357e-01 (1.6440e-01) 
2023-05-25 21:46:03.029729: val Epoch: [20][41/72]	Time  0.116 ( 0.632)	Data  0.000 ( 0.510)	Loss 1.9919e-01 (1.6523e-01) 
2023-05-25 21:46:04.149740: val Epoch: [20][42/72]	Time  1.120 ( 0.644)	Data  1.000 ( 0.521)	Loss 1.3099e-01 (1.6443e-01) 
2023-05-25 21:46:04.266498: val Epoch: [20][43/72]	Time  0.117 ( 0.632)	Data  0.000 ( 0.509)	Loss 4.4556e-01 (1.7082e-01) 
2023-05-25 21:46:05.526717: val Epoch: [20][44/72]	Time  1.260 ( 0.646)	Data  1.143 ( 0.524)	Loss 6.3261e-02 (1.6843e-01) 
2023-05-25 21:46:05.646200: val Epoch: [20][45/72]	Time  0.119 ( 0.634)	Data  0.000 ( 0.512)	Loss 4.4738e-02 (1.6574e-01) 
2023-05-25 21:46:06.794098: val Epoch: [20][46/72]	Time  1.148 ( 0.645)	Data  1.028 ( 0.523)	Loss 8.9571e-02 (1.6412e-01) 
2023-05-25 21:46:06.913144: val Epoch: [20][47/72]	Time  0.119 ( 0.634)	Data  0.000 ( 0.512)	Loss 4.5376e-02 (1.6165e-01) 
2023-05-25 21:46:08.064982: val Epoch: [20][48/72]	Time  1.152 ( 0.645)	Data  1.033 ( 0.523)	Loss 1.1424e-01 (1.6068e-01) 
2023-05-25 21:46:08.184347: val Epoch: [20][49/72]	Time  0.119 ( 0.634)	Data  0.000 ( 0.512)	Loss 6.7614e-02 (1.5882e-01) 
2023-05-25 21:46:09.333415: val Epoch: [20][50/72]	Time  1.149 ( 0.644)	Data  1.029 ( 0.523)	Loss 1.0190e-01 (1.5770e-01) 
2023-05-25 21:46:09.452567: val Epoch: [20][51/72]	Time  0.119 ( 0.634)	Data  0.001 ( 0.513)	Loss 1.6635e-01 (1.5787e-01) 
2023-05-25 21:46:10.521959: val Epoch: [20][52/72]	Time  1.069 ( 0.642)	Data  0.950 ( 0.521)	Loss 4.4370e-02 (1.5573e-01) 
2023-05-25 21:46:10.640903: val Epoch: [20][53/72]	Time  0.119 ( 0.633)	Data  0.000 ( 0.511)	Loss 1.4895e-01 (1.5560e-01) 
2023-05-25 21:46:11.737230: val Epoch: [20][54/72]	Time  1.096 ( 0.641)	Data  0.976 ( 0.520)	Loss 4.8373e-02 (1.5365e-01) 
2023-05-25 21:46:11.855987: val Epoch: [20][55/72]	Time  0.119 ( 0.632)	Data  0.000 ( 0.510)	Loss 1.0321e-01 (1.5275e-01) 
2023-05-25 21:46:12.939148: val Epoch: [20][56/72]	Time  1.083 ( 0.640)	Data  0.964 ( 0.518)	Loss 6.2956e-02 (1.5118e-01) 
2023-05-25 21:46:13.057644: val Epoch: [20][57/72]	Time  0.118 ( 0.631)	Data  0.000 ( 0.509)	Loss 1.1896e-01 (1.5062e-01) 
2023-05-25 21:46:14.120086: val Epoch: [20][58/72]	Time  1.062 ( 0.638)	Data  0.943 ( 0.517)	Loss 5.9261e-02 (1.4907e-01) 
2023-05-25 21:46:14.238979: val Epoch: [20][59/72]	Time  0.119 ( 0.629)	Data  0.000 ( 0.508)	Loss 5.7111e-02 (1.4754e-01) 
2023-05-25 21:46:15.313623: val Epoch: [20][60/72]	Time  1.075 ( 0.637)	Data  0.955 ( 0.515)	Loss 5.5767e-02 (1.4604e-01) 
2023-05-25 21:46:15.432608: val Epoch: [20][61/72]	Time  0.119 ( 0.628)	Data  0.000 ( 0.507)	Loss 1.0365e-01 (1.4535e-01) 
2023-05-25 21:46:16.554655: val Epoch: [20][62/72]	Time  1.122 ( 0.636)	Data  1.003 ( 0.515)	Loss 8.3159e-02 (1.4437e-01) 
2023-05-25 21:46:16.673821: val Epoch: [20][63/72]	Time  0.119 ( 0.628)	Data  0.000 ( 0.507)	Loss 2.4665e-01 (1.4596e-01) 
2023-05-25 21:46:17.788248: val Epoch: [20][64/72]	Time  1.114 ( 0.636)	Data  0.995 ( 0.514)	Loss 5.1814e-02 (1.4452e-01) 
2023-05-25 21:46:17.904413: val Epoch: [20][65/72]	Time  0.116 ( 0.628)	Data  0.000 ( 0.507)	Loss 6.4992e-02 (1.4331e-01) 
2023-05-25 21:46:19.023361: val Epoch: [20][66/72]	Time  1.119 ( 0.635)	Data  0.999 ( 0.514)	Loss 6.2025e-02 (1.4210e-01) 
2023-05-25 21:46:19.141966: val Epoch: [20][67/72]	Time  0.119 ( 0.627)	Data  0.001 ( 0.506)	Loss 1.3723e-01 (1.4203e-01) 
2023-05-25 21:46:20.256183: val Epoch: [20][68/72]	Time  1.114 ( 0.635)	Data  0.997 ( 0.514)	Loss 1.4812e-01 (1.4211e-01) 
2023-05-25 21:46:20.374182: val Epoch: [20][69/72]	Time  0.118 ( 0.627)	Data  0.000 ( 0.506)	Loss 2.9863e-01 (1.4435e-01) 
2023-05-25 21:46:21.411893: val Epoch: [20][70/72]	Time  1.038 ( 0.633)	Data  0.919 ( 0.512)	Loss 1.0217e-01 (1.4376e-01) 
2023-05-25 21:46:21.530573: val Epoch: [20][71/72]	Time  0.119 ( 0.626)	Data  0.000 ( 0.505)	Loss 1.1692e-01 (1.4338e-01) 
2023-05-25 21:46:21.716890: Epoch 20 :Val : ['ET : 0.7215831279754639', 'TC : 0.7652484178543091', 'WT : 0.8382861018180847'] 
2023-05-25 21:46:21.719613: Epoch 20 :Val : ['ET : 0.7215831279754639', 'TC : 0.7652484178543091', 'WT : 0.8382861018180847'] 
2023-05-25 21:46:21.721466: Val epoch done in 45.982100868001 s 
2023-05-25 21:46:21.726065: Batches per epoch:  129 
2023-05-25 21:46:26.635607: train Epoch: [21][  0/129]	Time  4.909 ( 4.909)	Data  3.937 ( 3.937)	Loss 9.2375e-02 (9.2375e-02) 
2023-05-25 21:46:27.576263: train Epoch: [21][  1/129]	Time  0.941 ( 2.925)	Data  0.001 ( 1.969)	Loss 7.3065e-02 (8.2720e-02) 
2023-05-25 21:46:30.029750: train Epoch: [21][  2/129]	Time  2.453 ( 2.768)	Data  1.507 ( 1.815)	Loss 8.7749e-02 (8.4396e-02) 
2023-05-25 21:46:30.976706: train Epoch: [21][  3/129]	Time  0.947 ( 2.313)	Data  0.001 ( 1.362)	Loss 1.2777e-01 (9.5241e-02) 
2023-05-25 21:46:33.524989: train Epoch: [21][  4/129]	Time  2.548 ( 2.360)	Data  1.604 ( 1.410)	Loss 1.5672e-01 (1.0754e-01) 
2023-05-25 21:46:34.475657: train Epoch: [21][  5/129]	Time  0.951 ( 2.125)	Data  0.001 ( 1.175)	Loss 6.9998e-02 (1.0128e-01) 
2023-05-25 21:46:36.976901: train Epoch: [21][  6/129]	Time  2.501 ( 2.179)	Data  1.558 ( 1.230)	Loss 8.9099e-02 (9.9540e-02) 
2023-05-25 21:46:37.924352: train Epoch: [21][  7/129]	Time  0.947 ( 2.025)	Data  0.001 ( 1.076)	Loss 1.0083e-01 (9.9701e-02) 
2023-05-25 21:46:40.595171: train Epoch: [21][  8/129]	Time  2.671 ( 2.097)	Data  1.727 ( 1.149)	Loss 1.0967e-01 (1.0081e-01) 
2023-05-25 21:46:41.544253: train Epoch: [21][  9/129]	Time  0.949 ( 1.982)	Data  0.001 ( 1.034)	Loss 1.0982e-01 (1.0171e-01) 
2023-05-25 21:46:44.105411: train Epoch: [21][ 10/129]	Time  2.561 ( 2.034)	Data  1.616 ( 1.087)	Loss 8.2095e-02 (9.9927e-02) 
2023-05-25 21:46:45.053529: train Epoch: [21][ 11/129]	Time  0.948 ( 1.944)	Data  0.001 ( 0.996)	Loss 7.4125e-02 (9.7777e-02) 
2023-05-25 21:46:47.709930: train Epoch: [21][ 12/129]	Time  2.656 ( 1.999)	Data  1.712 ( 1.051)	Loss 1.2986e-01 (1.0024e-01) 
2023-05-25 21:46:48.658965: train Epoch: [21][ 13/129]	Time  0.949 ( 1.924)	Data  0.001 ( 0.976)	Loss 6.9227e-02 (9.8029e-02) 
2023-05-25 21:46:51.274566: train Epoch: [21][ 14/129]	Time  2.616 ( 1.970)	Data  1.672 ( 1.023)	Loss 1.0255e-01 (9.8331e-02) 
2023-05-25 21:46:52.223177: train Epoch: [21][ 15/129]	Time  0.949 ( 1.906)	Data  0.001 ( 0.959)	Loss 7.6962e-02 (9.6995e-02) 
2023-05-25 21:46:54.801864: train Epoch: [21][ 16/129]	Time  2.579 ( 1.946)	Data  1.635 ( 0.999)	Loss 8.3819e-02 (9.6220e-02) 
2023-05-25 21:46:55.749029: train Epoch: [21][ 17/129]	Time  0.947 ( 1.890)	Data  0.001 ( 0.943)	Loss 1.8908e-01 (1.0138e-01) 
2023-05-25 21:46:58.397471: train Epoch: [21][ 18/129]	Time  2.648 ( 1.930)	Data  1.705 ( 0.983)	Loss 1.0364e-01 (1.0150e-01) 
2023-05-25 21:46:59.343886: train Epoch: [21][ 19/129]	Time  0.946 ( 1.881)	Data  0.001 ( 0.934)	Loss 7.6204e-02 (1.0023e-01) 
2023-05-25 21:47:01.959007: train Epoch: [21][ 20/129]	Time  2.615 ( 1.916)	Data  1.671 ( 0.969)	Loss 8.3472e-02 (9.9435e-02) 
2023-05-25 21:47:02.905693: train Epoch: [21][ 21/129]	Time  0.947 ( 1.872)	Data  0.001 ( 0.925)	Loss 5.6575e-02 (9.7487e-02) 
2023-05-25 21:47:05.506374: train Epoch: [21][ 22/129]	Time  2.601 ( 1.903)	Data  1.653 ( 0.957)	Loss 8.7257e-02 (9.7042e-02) 
2023-05-25 21:47:06.453707: train Epoch: [21][ 23/129]	Time  0.947 ( 1.864)	Data  0.001 ( 0.917)	Loss 7.6590e-02 (9.6190e-02) 
2023-05-25 21:47:09.109887: train Epoch: [21][ 24/129]	Time  2.656 ( 1.895)	Data  1.711 ( 0.949)	Loss 1.3291e-01 (9.7659e-02) 
2023-05-25 21:47:10.058780: train Epoch: [21][ 25/129]	Time  0.949 ( 1.859)	Data  0.001 ( 0.912)	Loss 8.1180e-02 (9.7025e-02) 
2023-05-25 21:47:12.694018: train Epoch: [21][ 26/129]	Time  2.635 ( 1.888)	Data  1.689 ( 0.941)	Loss 6.4532e-02 (9.5822e-02) 
2023-05-25 21:47:13.641803: train Epoch: [21][ 27/129]	Time  0.948 ( 1.854)	Data  0.001 ( 0.907)	Loss 1.1673e-01 (9.6568e-02) 
2023-05-25 21:47:16.174789: train Epoch: [21][ 28/129]	Time  2.533 ( 1.878)	Data  1.588 ( 0.931)	Loss 8.4759e-02 (9.6161e-02) 
2023-05-25 21:47:17.123192: train Epoch: [21][ 29/129]	Time  0.948 ( 1.847)	Data  0.001 ( 0.900)	Loss 7.5496e-02 (9.5472e-02) 
2023-05-25 21:47:19.799917: train Epoch: [21][ 30/129]	Time  2.677 ( 1.873)	Data  1.729 ( 0.927)	Loss 9.3346e-02 (9.5404e-02) 
2023-05-25 21:47:20.749508: train Epoch: [21][ 31/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.898)	Loss 1.1240e-01 (9.5935e-02) 
2023-05-25 21:47:23.287311: train Epoch: [21][ 32/129]	Time  2.538 ( 1.865)	Data  1.592 ( 0.919)	Loss 6.4369e-02 (9.4978e-02) 
2023-05-25 21:47:24.236059: train Epoch: [21][ 33/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.892)	Loss 9.7744e-02 (9.5060e-02) 
2023-05-25 21:47:26.899216: train Epoch: [21][ 34/129]	Time  2.663 ( 1.862)	Data  1.718 ( 0.915)	Loss 1.0057e-01 (9.5217e-02) 
2023-05-25 21:47:27.847524: train Epoch: [21][ 35/129]	Time  0.948 ( 1.837)	Data  0.001 ( 0.890)	Loss 1.1211e-01 (9.5687e-02) 
2023-05-25 21:47:30.507767: train Epoch: [21][ 36/129]	Time  2.660 ( 1.859)	Data  1.717 ( 0.912)	Loss 1.2418e-01 (9.6457e-02) 
2023-05-25 21:47:31.455758: train Epoch: [21][ 37/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.888)	Loss 8.9136e-02 (9.6264e-02) 
2023-05-25 21:47:34.050379: train Epoch: [21][ 38/129]	Time  2.595 ( 1.854)	Data  1.649 ( 0.908)	Loss 1.2667e-01 (9.7044e-02) 
2023-05-25 21:47:34.999521: train Epoch: [21][ 39/129]	Time  0.949 ( 1.832)	Data  0.001 ( 0.885)	Loss 1.0911e-01 (9.7345e-02) 
2023-05-25 21:47:37.605052: train Epoch: [21][ 40/129]	Time  2.606 ( 1.851)	Data  1.660 ( 0.904)	Loss 1.1713e-01 (9.7828e-02) 
2023-05-25 21:47:38.553815: train Epoch: [21][ 41/129]	Time  0.949 ( 1.829)	Data  0.001 ( 0.883)	Loss 7.3407e-02 (9.7246e-02) 
2023-05-25 21:47:41.141734: train Epoch: [21][ 42/129]	Time  2.588 ( 1.847)	Data  1.642 ( 0.900)	Loss 1.3227e-01 (9.8061e-02) 
2023-05-25 21:47:42.089516: train Epoch: [21][ 43/129]	Time  0.948 ( 1.826)	Data  0.001 ( 0.880)	Loss 7.5013e-02 (9.7537e-02) 
2023-05-25 21:47:44.691831: train Epoch: [21][ 44/129]	Time  2.602 ( 1.844)	Data  1.656 ( 0.897)	Loss 8.2602e-02 (9.7205e-02) 
2023-05-25 21:47:45.639769: train Epoch: [21][ 45/129]	Time  0.948 ( 1.824)	Data  0.001 ( 0.878)	Loss 5.7162e-02 (9.6335e-02) 
2023-05-25 21:47:48.218456: train Epoch: [21][ 46/129]	Time  2.579 ( 1.840)	Data  1.633 ( 0.894)	Loss 5.8993e-02 (9.5540e-02) 
2023-05-25 21:47:49.166563: train Epoch: [21][ 47/129]	Time  0.948 ( 1.822)	Data  0.001 ( 0.875)	Loss 1.0504e-01 (9.5738e-02) 
2023-05-25 21:47:51.878594: train Epoch: [21][ 48/129]	Time  2.712 ( 1.840)	Data  1.766 ( 0.893)	Loss 7.4487e-02 (9.5304e-02) 
2023-05-25 21:47:52.825619: train Epoch: [21][ 49/129]	Time  0.947 ( 1.822)	Data  0.001 ( 0.875)	Loss 8.1738e-02 (9.5033e-02) 
2023-05-25 21:47:55.393252: train Epoch: [21][ 50/129]	Time  2.568 ( 1.837)	Data  1.622 ( 0.890)	Loss 7.6840e-02 (9.4676e-02) 
2023-05-25 21:47:56.340781: train Epoch: [21][ 51/129]	Time  0.948 ( 1.820)	Data  0.001 ( 0.873)	Loss 9.3826e-02 (9.4660e-02) 
2023-05-25 21:47:58.874646: train Epoch: [21][ 52/129]	Time  2.534 ( 1.833)	Data  1.587 ( 0.886)	Loss 1.1058e-01 (9.4960e-02) 
2023-05-25 21:47:59.823612: train Epoch: [21][ 53/129]	Time  0.949 ( 1.817)	Data  0.001 ( 0.870)	Loss 6.9639e-02 (9.4491e-02) 
2023-05-25 21:48:02.513360: train Epoch: [21][ 54/129]	Time  2.690 ( 1.832)	Data  1.741 ( 0.886)	Loss 7.1721e-02 (9.4077e-02) 
2023-05-25 21:48:03.460828: train Epoch: [21][ 55/129]	Time  0.947 ( 1.817)	Data  0.001 ( 0.870)	Loss 1.0634e-01 (9.4296e-02) 
2023-05-25 21:48:05.912895: train Epoch: [21][ 56/129]	Time  2.452 ( 1.828)	Data  1.506 ( 0.881)	Loss 6.6775e-02 (9.3813e-02) 
2023-05-25 21:48:06.860034: train Epoch: [21][ 57/129]	Time  0.947 ( 1.813)	Data  0.001 ( 0.866)	Loss 5.8044e-02 (9.3197e-02) 
2023-05-25 21:48:09.515557: train Epoch: [21][ 58/129]	Time  2.656 ( 1.827)	Data  1.710 ( 0.880)	Loss 1.0989e-01 (9.3480e-02) 
2023-05-25 21:48:10.462135: train Epoch: [21][ 59/129]	Time  0.947 ( 1.812)	Data  0.001 ( 0.866)	Loss 7.1899e-02 (9.3120e-02) 
2023-05-25 21:48:12.988394: train Epoch: [21][ 60/129]	Time  2.526 ( 1.824)	Data  1.580 ( 0.877)	Loss 1.1462e-01 (9.3472e-02) 
2023-05-25 21:48:13.934308: train Epoch: [21][ 61/129]	Time  0.946 ( 1.810)	Data  0.001 ( 0.863)	Loss 8.5041e-02 (9.3336e-02) 
2023-05-25 21:48:16.465594: train Epoch: [21][ 62/129]	Time  2.531 ( 1.821)	Data  1.586 ( 0.875)	Loss 9.4693e-02 (9.3358e-02) 
2023-05-25 21:48:17.414039: train Epoch: [21][ 63/129]	Time  0.948 ( 1.808)	Data  0.001 ( 0.861)	Loss 8.6013e-02 (9.3243e-02) 
2023-05-25 21:48:20.004466: train Epoch: [21][ 64/129]	Time  2.590 ( 1.820)	Data  1.645 ( 0.873)	Loss 7.4101e-02 (9.2949e-02) 
2023-05-25 21:48:20.955657: train Epoch: [21][ 65/129]	Time  0.951 ( 1.807)	Data  0.001 ( 0.860)	Loss 1.4669e-01 (9.3763e-02) 
2023-05-25 21:48:23.639230: train Epoch: [21][ 66/129]	Time  2.684 ( 1.820)	Data  1.740 ( 0.873)	Loss 7.0442e-02 (9.3415e-02) 
2023-05-25 21:48:24.587836: train Epoch: [21][ 67/129]	Time  0.949 ( 1.807)	Data  0.001 ( 0.860)	Loss 6.4286e-02 (9.2987e-02) 
2023-05-25 21:48:27.231640: train Epoch: [21][ 68/129]	Time  2.644 ( 1.819)	Data  1.700 ( 0.872)	Loss 1.3489e-01 (9.3594e-02) 
2023-05-25 21:48:28.178307: train Epoch: [21][ 69/129]	Time  0.947 ( 1.806)	Data  0.001 ( 0.860)	Loss 5.6296e-02 (9.3061e-02) 
2023-05-25 21:48:30.726343: train Epoch: [21][ 70/129]	Time  2.548 ( 1.817)	Data  1.602 ( 0.870)	Loss 1.2597e-01 (9.3524e-02) 
2023-05-25 21:48:31.674969: train Epoch: [21][ 71/129]	Time  0.949 ( 1.805)	Data  0.001 ( 0.858)	Loss 7.7255e-02 (9.3298e-02) 
2023-05-25 21:48:34.256794: train Epoch: [21][ 72/129]	Time  2.582 ( 1.815)	Data  1.636 ( 0.869)	Loss 2.0027e-01 (9.4764e-02) 
2023-05-25 21:48:35.206002: train Epoch: [21][ 73/129]	Time  0.949 ( 1.804)	Data  0.001 ( 0.857)	Loss 6.0535e-02 (9.4301e-02) 
2023-05-25 21:48:37.815989: train Epoch: [21][ 74/129]	Time  2.610 ( 1.815)	Data  1.663 ( 0.868)	Loss 1.0688e-01 (9.4469e-02) 
2023-05-25 21:48:38.766883: train Epoch: [21][ 75/129]	Time  0.951 ( 1.803)	Data  0.001 ( 0.857)	Loss 7.6331e-02 (9.4230e-02) 
2023-05-25 21:48:41.307585: train Epoch: [21][ 76/129]	Time  2.541 ( 1.813)	Data  1.593 ( 0.866)	Loss 1.0066e-01 (9.4314e-02) 
2023-05-25 21:48:42.266186: train Epoch: [21][ 77/129]	Time  0.959 ( 1.802)	Data  0.001 ( 0.855)	Loss 2.4375e-01 (9.6230e-02) 
2023-05-25 21:48:44.754367: train Epoch: [21][ 78/129]	Time  2.488 ( 1.810)	Data  1.541 ( 0.864)	Loss 1.2838e-01 (9.6637e-02) 
2023-05-25 21:48:45.702615: train Epoch: [21][ 79/129]	Time  0.948 ( 1.800)	Data  0.001 ( 0.853)	Loss 1.2728e-01 (9.7020e-02) 
2023-05-25 21:48:48.303466: train Epoch: [21][ 80/129]	Time  2.601 ( 1.810)	Data  1.655 ( 0.863)	Loss 9.7319e-02 (9.7023e-02) 
2023-05-25 21:48:49.251327: train Epoch: [21][ 81/129]	Time  0.948 ( 1.799)	Data  0.001 ( 0.852)	Loss 1.2349e-01 (9.7346e-02) 
2023-05-25 21:48:51.787702: train Epoch: [21][ 82/129]	Time  2.536 ( 1.808)	Data  1.584 ( 0.861)	Loss 7.0893e-02 (9.7027e-02) 
2023-05-25 21:48:52.737138: train Epoch: [21][ 83/129]	Time  0.949 ( 1.798)	Data  0.001 ( 0.851)	Loss 1.0751e-01 (9.7152e-02) 
2023-05-25 21:48:55.347950: train Epoch: [21][ 84/129]	Time  2.611 ( 1.807)	Data  1.665 ( 0.860)	Loss 8.1971e-02 (9.6974e-02) 
2023-05-25 21:48:56.309346: train Epoch: [21][ 85/129]	Time  0.961 ( 1.797)	Data  0.001 ( 0.850)	Loss 6.6349e-02 (9.6617e-02) 
2023-05-25 21:48:58.982993: train Epoch: [21][ 86/129]	Time  2.674 ( 1.808)	Data  1.718 ( 0.860)	Loss 7.1721e-02 (9.6331e-02) 
2023-05-25 21:48:59.943192: train Epoch: [21][ 87/129]	Time  0.960 ( 1.798)	Data  0.001 ( 0.851)	Loss 8.9266e-02 (9.6251e-02) 
2023-05-25 21:49:02.572420: train Epoch: [21][ 88/129]	Time  2.629 ( 1.807)	Data  1.672 ( 0.860)	Loss 8.4917e-02 (9.6124e-02) 
2023-05-25 21:49:03.530456: train Epoch: [21][ 89/129]	Time  0.958 ( 1.798)	Data  0.001 ( 0.850)	Loss 8.4156e-02 (9.5991e-02) 
2023-05-25 21:49:05.997784: train Epoch: [21][ 90/129]	Time  2.467 ( 1.805)	Data  1.512 ( 0.858)	Loss 8.7061e-02 (9.5893e-02) 
2023-05-25 21:49:06.957694: train Epoch: [21][ 91/129]	Time  0.960 ( 1.796)	Data  0.001 ( 0.848)	Loss 1.5473e-01 (9.6532e-02) 
2023-05-25 21:49:09.572555: train Epoch: [21][ 92/129]	Time  2.615 ( 1.805)	Data  1.660 ( 0.857)	Loss 8.2835e-02 (9.6385e-02) 
2023-05-25 21:49:10.530921: train Epoch: [21][ 93/129]	Time  0.958 ( 1.796)	Data  0.001 ( 0.848)	Loss 8.6700e-02 (9.6282e-02) 
2023-05-25 21:49:13.053079: train Epoch: [21][ 94/129]	Time  2.522 ( 1.803)	Data  1.566 ( 0.855)	Loss 7.4795e-02 (9.6056e-02) 
2023-05-25 21:49:14.012115: train Epoch: [21][ 95/129]	Time  0.959 ( 1.795)	Data  0.001 ( 0.847)	Loss 7.8248e-02 (9.5870e-02) 
2023-05-25 21:49:16.539213: train Epoch: [21][ 96/129]	Time  2.527 ( 1.802)	Data  1.571 ( 0.854)	Loss 4.5909e-02 (9.5355e-02) 
2023-05-25 21:49:17.499100: train Epoch: [21][ 97/129]	Time  0.960 ( 1.794)	Data  0.001 ( 0.845)	Loss 1.1410e-01 (9.5546e-02) 
2023-05-25 21:49:20.038192: train Epoch: [21][ 98/129]	Time  2.539 ( 1.801)	Data  1.583 ( 0.853)	Loss 1.0261e-01 (9.5618e-02) 
2023-05-25 21:49:20.997299: train Epoch: [21][ 99/129]	Time  0.959 ( 1.793)	Data  0.001 ( 0.844)	Loss 8.2421e-02 (9.5486e-02) 
2023-05-25 21:49:23.560143: train Epoch: [21][100/129]	Time  2.563 ( 1.800)	Data  1.605 ( 0.852)	Loss 8.6932e-02 (9.5401e-02) 
2023-05-25 21:49:24.518877: train Epoch: [21][101/129]	Time  0.959 ( 1.792)	Data  0.001 ( 0.843)	Loss 1.2016e-01 (9.5644e-02) 
2023-05-25 21:49:27.056166: train Epoch: [21][102/129]	Time  2.537 ( 1.799)	Data  1.579 ( 0.851)	Loss 7.1863e-02 (9.5413e-02) 
2023-05-25 21:49:28.015248: train Epoch: [21][103/129]	Time  0.959 ( 1.791)	Data  0.001 ( 0.842)	Loss 1.2550e-01 (9.5702e-02) 
2023-05-25 21:49:30.590738: train Epoch: [21][104/129]	Time  2.575 ( 1.799)	Data  1.618 ( 0.850)	Loss 6.2475e-02 (9.5386e-02) 
2023-05-25 21:49:31.550754: train Epoch: [21][105/129]	Time  0.960 ( 1.791)	Data  0.001 ( 0.842)	Loss 9.3054e-02 (9.5364e-02) 
2023-05-25 21:49:34.076226: train Epoch: [21][106/129]	Time  2.525 ( 1.798)	Data  1.568 ( 0.849)	Loss 4.9670e-02 (9.4937e-02) 
2023-05-25 21:49:35.035305: train Epoch: [21][107/129]	Time  0.959 ( 1.790)	Data  0.001 ( 0.841)	Loss 7.8097e-02 (9.4781e-02) 
2023-05-25 21:49:37.548453: train Epoch: [21][108/129]	Time  2.513 ( 1.797)	Data  1.557 ( 0.847)	Loss 7.9791e-02 (9.4643e-02) 
2023-05-25 21:49:38.507446: train Epoch: [21][109/129]	Time  0.959 ( 1.789)	Data  0.001 ( 0.840)	Loss 1.5516e-01 (9.5193e-02) 
2023-05-25 21:49:41.016807: train Epoch: [21][110/129]	Time  2.509 ( 1.795)	Data  1.553 ( 0.846)	Loss 1.1123e-01 (9.5338e-02) 
2023-05-25 21:49:41.976376: train Epoch: [21][111/129]	Time  0.960 ( 1.788)	Data  0.001 ( 0.838)	Loss 1.9514e-01 (9.6229e-02) 
2023-05-25 21:49:44.506937: train Epoch: [21][112/129]	Time  2.531 ( 1.795)	Data  1.574 ( 0.845)	Loss 8.1221e-02 (9.6096e-02) 
2023-05-25 21:49:45.467213: train Epoch: [21][113/129]	Time  0.960 ( 1.787)	Data  0.001 ( 0.838)	Loss 1.2557e-01 (9.6355e-02) 
2023-05-25 21:49:48.069059: train Epoch: [21][114/129]	Time  2.602 ( 1.794)	Data  1.645 ( 0.845)	Loss 1.8099e-01 (9.7091e-02) 
2023-05-25 21:49:49.026411: train Epoch: [21][115/129]	Time  0.957 ( 1.787)	Data  0.001 ( 0.837)	Loss 7.9640e-02 (9.6940e-02) 
2023-05-25 21:49:51.567827: train Epoch: [21][116/129]	Time  2.541 ( 1.794)	Data  1.584 ( 0.844)	Loss 1.3018e-01 (9.7224e-02) 
2023-05-25 21:49:52.516011: train Epoch: [21][117/129]	Time  0.948 ( 1.786)	Data  0.001 ( 0.837)	Loss 1.6640e-01 (9.7810e-02) 
2023-05-25 21:49:55.118809: train Epoch: [21][118/129]	Time  2.603 ( 1.793)	Data  1.655 ( 0.843)	Loss 8.6704e-02 (9.7717e-02) 
2023-05-25 21:49:56.067012: train Epoch: [21][119/129]	Time  0.948 ( 1.786)	Data  0.001 ( 0.836)	Loss 1.1553e-01 (9.7866e-02) 
2023-05-25 21:49:58.738593: train Epoch: [21][120/129]	Time  2.672 ( 1.793)	Data  1.726 ( 0.844)	Loss 1.0519e-01 (9.7926e-02) 
2023-05-25 21:49:59.686879: train Epoch: [21][121/129]	Time  0.948 ( 1.787)	Data  0.001 ( 0.837)	Loss 1.4549e-01 (9.8316e-02) 
2023-05-25 21:50:02.256113: train Epoch: [21][122/129]	Time  2.569 ( 1.793)	Data  1.623 ( 0.843)	Loss 9.4090e-02 (9.8282e-02) 
2023-05-25 21:50:03.205498: train Epoch: [21][123/129]	Time  0.949 ( 1.786)	Data  0.001 ( 0.836)	Loss 7.9881e-02 (9.8133e-02) 
2023-05-25 21:50:05.859724: train Epoch: [21][124/129]	Time  2.654 ( 1.793)	Data  1.709 ( 0.843)	Loss 7.9120e-02 (9.7981e-02) 
2023-05-25 21:50:06.806227: train Epoch: [21][125/129]	Time  0.947 ( 1.786)	Data  0.001 ( 0.837)	Loss 5.9180e-02 (9.7673e-02) 
2023-05-25 21:50:09.314177: train Epoch: [21][126/129]	Time  2.508 ( 1.792)	Data  1.561 ( 0.842)	Loss 1.9348e-01 (9.8428e-02) 
2023-05-25 21:50:10.265075: train Epoch: [21][127/129]	Time  0.951 ( 1.785)	Data  0.001 ( 0.836)	Loss 1.5079e-01 (9.8837e-02) 
2023-05-25 21:50:11.711784: train Epoch: [21][128/129]	Time  1.447 ( 1.783)	Data  0.501 ( 0.833)	Loss 9.7877e-02 (9.8829e-02) 
2023-05-25 21:50:11.743114: Train Epoch done in 230.01707752199945 s 
2023-05-25 21:50:14.002850: val Epoch: [21][ 0/72]	Time  1.519 ( 1.519)	Data  1.342 ( 1.342)	Loss 1.9835e-01 (1.9835e-01) 
2023-05-25 21:50:14.122538: val Epoch: [21][ 1/72]	Time  0.120 ( 0.819)	Data  0.001 ( 0.672)	Loss 6.5841e-02 (1.3209e-01) 
2023-05-25 21:50:15.249283: val Epoch: [21][ 2/72]	Time  1.127 ( 0.922)	Data  1.005 ( 0.783)	Loss 6.1128e-01 (2.9182e-01) 
2023-05-25 21:50:15.368889: val Epoch: [21][ 3/72]	Time  0.120 ( 0.721)	Data  0.000 ( 0.587)	Loss 8.1996e-02 (2.3937e-01) 
2023-05-25 21:50:16.523667: val Epoch: [21][ 4/72]	Time  1.155 ( 0.808)	Data  1.035 ( 0.677)	Loss 2.6060e-01 (2.4361e-01) 
2023-05-25 21:50:16.643834: val Epoch: [21][ 5/72]	Time  0.120 ( 0.693)	Data  0.000 ( 0.564)	Loss 7.5298e-02 (2.1556e-01) 
2023-05-25 21:50:17.788522: val Epoch: [21][ 6/72]	Time  1.145 ( 0.758)	Data  1.024 ( 0.630)	Loss 4.1596e-01 (2.4419e-01) 
2023-05-25 21:50:17.907886: val Epoch: [21][ 7/72]	Time  0.119 ( 0.678)	Data  0.000 ( 0.551)	Loss 1.0455e-01 (2.2673e-01) 
2023-05-25 21:50:19.043589: val Epoch: [21][ 8/72]	Time  1.136 ( 0.729)	Data  1.017 ( 0.603)	Loss 1.0343e-01 (2.1303e-01) 
2023-05-25 21:50:19.163722: val Epoch: [21][ 9/72]	Time  0.120 ( 0.668)	Data  0.000 ( 0.543)	Loss 1.3424e-01 (2.0515e-01) 
2023-05-25 21:50:20.279317: val Epoch: [21][10/72]	Time  1.116 ( 0.709)	Data  0.998 ( 0.584)	Loss 4.6220e-02 (1.9071e-01) 
2023-05-25 21:50:20.399273: val Epoch: [21][11/72]	Time  0.120 ( 0.660)	Data  0.000 ( 0.535)	Loss 8.0831e-02 (1.8155e-01) 
2023-05-25 21:50:21.536700: val Epoch: [21][12/72]	Time  1.137 ( 0.696)	Data  1.019 ( 0.573)	Loss 1.2895e-01 (1.7750e-01) 
2023-05-25 21:50:21.653843: val Epoch: [21][13/72]	Time  0.117 ( 0.655)	Data  0.001 ( 0.532)	Loss 1.1050e-01 (1.7272e-01) 
2023-05-25 21:50:22.875280: val Epoch: [21][14/72]	Time  1.221 ( 0.693)	Data  1.105 ( 0.570)	Loss 1.2367e-01 (1.6945e-01) 
2023-05-25 21:50:22.995034: val Epoch: [21][15/72]	Time  0.120 ( 0.657)	Data  0.000 ( 0.534)	Loss 5.9650e-02 (1.6258e-01) 
2023-05-25 21:50:24.148455: val Epoch: [21][16/72]	Time  1.153 ( 0.686)	Data  1.028 ( 0.563)	Loss 2.4507e-01 (1.6744e-01) 
2023-05-25 21:50:24.269698: val Epoch: [21][17/72]	Time  0.121 ( 0.655)	Data  0.001 ( 0.532)	Loss 7.3493e-02 (1.6222e-01) 
2023-05-25 21:50:25.400502: val Epoch: [21][18/72]	Time  1.131 ( 0.680)	Data  1.009 ( 0.557)	Loss 6.0746e-02 (1.5688e-01) 
2023-05-25 21:50:25.522250: val Epoch: [21][19/72]	Time  0.122 ( 0.652)	Data  0.001 ( 0.529)	Loss 4.8772e-02 (1.5147e-01) 
2023-05-25 21:50:26.612012: val Epoch: [21][20/72]	Time  1.090 ( 0.673)	Data  0.968 ( 0.550)	Loss 7.3117e-02 (1.4774e-01) 
2023-05-25 21:50:26.733861: val Epoch: [21][21/72]	Time  0.122 ( 0.648)	Data  0.001 ( 0.525)	Loss 1.2101e-01 (1.4653e-01) 
2023-05-25 21:50:27.899494: val Epoch: [21][22/72]	Time  1.166 ( 0.670)	Data  1.044 ( 0.548)	Loss 5.8375e-01 (1.6554e-01) 
2023-05-25 21:50:28.024357: val Epoch: [21][23/72]	Time  0.125 ( 0.648)	Data  0.000 ( 0.525)	Loss 7.4449e-02 (1.6174e-01) 
2023-05-25 21:50:29.176745: val Epoch: [21][24/72]	Time  1.152 ( 0.668)	Data  1.031 ( 0.545)	Loss 6.7993e-02 (1.5799e-01) 
2023-05-25 21:50:29.301159: val Epoch: [21][25/72]	Time  0.124 ( 0.647)	Data  0.000 ( 0.524)	Loss 5.4804e-02 (1.5402e-01) 
2023-05-25 21:50:30.381099: val Epoch: [21][26/72]	Time  1.080 ( 0.663)	Data  0.958 ( 0.540)	Loss 6.5545e-02 (1.5074e-01) 
2023-05-25 21:50:30.505635: val Epoch: [21][27/72]	Time  0.125 ( 0.644)	Data  0.000 ( 0.521)	Loss 1.7180e-01 (1.5150e-01) 
2023-05-25 21:50:31.592543: val Epoch: [21][28/72]	Time  1.087 ( 0.659)	Data  0.966 ( 0.536)	Loss 2.1481e-01 (1.5368e-01) 
2023-05-25 21:50:31.713647: val Epoch: [21][29/72]	Time  0.121 ( 0.641)	Data  0.000 ( 0.519)	Loss 3.0631e-01 (1.5877e-01) 
2023-05-25 21:50:32.780248: val Epoch: [21][30/72]	Time  1.067 ( 0.655)	Data  0.945 ( 0.532)	Loss 5.9518e-02 (1.5557e-01) 
2023-05-25 21:50:32.904665: val Epoch: [21][31/72]	Time  0.124 ( 0.638)	Data  0.001 ( 0.516)	Loss 1.1326e-01 (1.5424e-01) 
2023-05-25 21:50:34.014904: val Epoch: [21][32/72]	Time  1.110 ( 0.652)	Data  0.986 ( 0.530)	Loss 2.0207e-01 (1.5569e-01) 
2023-05-25 21:50:34.139548: val Epoch: [21][33/72]	Time  0.125 ( 0.637)	Data  0.001 ( 0.514)	Loss 1.8495e-01 (1.5655e-01) 
2023-05-25 21:50:35.221096: val Epoch: [21][34/72]	Time  1.082 ( 0.650)	Data  0.960 ( 0.527)	Loss 8.0090e-02 (1.5437e-01) 
2023-05-25 21:50:35.345953: val Epoch: [21][35/72]	Time  0.125 ( 0.635)	Data  0.001 ( 0.513)	Loss 3.6221e-01 (1.6014e-01) 
2023-05-25 21:50:36.509200: val Epoch: [21][36/72]	Time  1.163 ( 0.649)	Data  1.042 ( 0.527)	Loss 1.9840e-01 (1.6118e-01) 
2023-05-25 21:50:36.630367: val Epoch: [21][37/72]	Time  0.121 ( 0.635)	Data  0.000 ( 0.513)	Loss 6.4236e-02 (1.5862e-01) 
2023-05-25 21:50:37.719208: val Epoch: [21][38/72]	Time  1.089 ( 0.647)	Data  0.967 ( 0.525)	Loss 4.7603e-01 (1.6676e-01) 
2023-05-25 21:50:37.843428: val Epoch: [21][39/72]	Time  0.124 ( 0.634)	Data  0.000 ( 0.512)	Loss 2.1485e-01 (1.6797e-01) 
2023-05-25 21:50:38.992772: val Epoch: [21][40/72]	Time  1.149 ( 0.647)	Data  1.028 ( 0.524)	Loss 1.2552e-01 (1.6693e-01) 
2023-05-25 21:50:39.114565: val Epoch: [21][41/72]	Time  0.122 ( 0.634)	Data  0.001 ( 0.512)	Loss 1.4752e-01 (1.6647e-01) 
2023-05-25 21:50:40.176964: val Epoch: [21][42/72]	Time  1.062 ( 0.644)	Data  0.941 ( 0.522)	Loss 1.6825e-01 (1.6651e-01) 
2023-05-25 21:50:40.301506: val Epoch: [21][43/72]	Time  0.125 ( 0.632)	Data  0.001 ( 0.510)	Loss 6.1236e-02 (1.6412e-01) 
2023-05-25 21:50:41.370476: val Epoch: [21][44/72]	Time  1.069 ( 0.642)	Data  0.948 ( 0.520)	Loss 1.6091e-01 (1.6405e-01) 
2023-05-25 21:50:41.494516: val Epoch: [21][45/72]	Time  0.124 ( 0.631)	Data  0.000 ( 0.508)	Loss 1.9249e-01 (1.6466e-01) 
2023-05-25 21:50:42.589975: val Epoch: [21][46/72]	Time  1.095 ( 0.641)	Data  0.974 ( 0.518)	Loss 5.5629e-02 (1.6234e-01) 
2023-05-25 21:50:42.714814: val Epoch: [21][47/72]	Time  0.125 ( 0.630)	Data  0.000 ( 0.507)	Loss 1.0051e-01 (1.6106e-01) 
2023-05-25 21:50:43.803502: val Epoch: [21][48/72]	Time  1.089 ( 0.639)	Data  0.967 ( 0.517)	Loss 5.9505e-02 (1.5898e-01) 
2023-05-25 21:50:43.920521: val Epoch: [21][49/72]	Time  0.117 ( 0.629)	Data  0.000 ( 0.506)	Loss 8.2074e-02 (1.5745e-01) 
2023-05-25 21:50:44.991804: val Epoch: [21][50/72]	Time  1.071 ( 0.637)	Data  0.954 ( 0.515)	Loss 1.6626e-01 (1.5762e-01) 
2023-05-25 21:50:45.110592: val Epoch: [21][51/72]	Time  0.119 ( 0.627)	Data  0.000 ( 0.505)	Loss 1.1788e-01 (1.5685e-01) 
2023-05-25 21:50:46.188233: val Epoch: [21][52/72]	Time  1.078 ( 0.636)	Data  0.960 ( 0.514)	Loss 6.3125e-02 (1.5509e-01) 
2023-05-25 21:50:46.307828: val Epoch: [21][53/72]	Time  0.120 ( 0.626)	Data  0.000 ( 0.504)	Loss 8.0112e-02 (1.5370e-01) 
2023-05-25 21:50:47.433102: val Epoch: [21][54/72]	Time  1.125 ( 0.635)	Data  1.004 ( 0.513)	Loss 4.0557e-01 (1.5828e-01) 
2023-05-25 21:50:47.557862: val Epoch: [21][55/72]	Time  0.125 ( 0.626)	Data  0.000 ( 0.504)	Loss 2.0690e-01 (1.5914e-01) 
2023-05-25 21:50:48.694945: val Epoch: [21][56/72]	Time  1.137 ( 0.635)	Data  1.012 ( 0.513)	Loss 9.6546e-02 (1.5805e-01) 
2023-05-25 21:50:48.819288: val Epoch: [21][57/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.504)	Loss 1.1733e-01 (1.5734e-01) 
2023-05-25 21:50:49.860804: val Epoch: [21][58/72]	Time  1.042 ( 0.634)	Data  0.920 ( 0.511)	Loss 8.2192e-02 (1.5607e-01) 
2023-05-25 21:50:49.982019: val Epoch: [21][59/72]	Time  0.121 ( 0.625)	Data  0.001 ( 0.503)	Loss 1.8690e-01 (1.5658e-01) 
2023-05-25 21:50:51.043207: val Epoch: [21][60/72]	Time  1.061 ( 0.632)	Data  0.940 ( 0.510)	Loss 9.6452e-02 (1.5560e-01) 
2023-05-25 21:50:51.167975: val Epoch: [21][61/72]	Time  0.125 ( 0.624)	Data  0.001 ( 0.502)	Loss 2.5926e-01 (1.5727e-01) 
2023-05-25 21:50:52.280597: val Epoch: [21][62/72]	Time  1.113 ( 0.632)	Data  0.991 ( 0.510)	Loss 4.0031e-01 (1.6113e-01) 
2023-05-25 21:50:52.405208: val Epoch: [21][63/72]	Time  0.125 ( 0.624)	Data  0.000 ( 0.502)	Loss 3.5037e-01 (1.6409e-01) 
2023-05-25 21:50:53.479325: val Epoch: [21][64/72]	Time  1.074 ( 0.631)	Data  0.953 ( 0.509)	Loss 9.0978e-02 (1.6296e-01) 
2023-05-25 21:50:53.600305: val Epoch: [21][65/72]	Time  0.121 ( 0.623)	Data  0.000 ( 0.501)	Loss 7.3578e-02 (1.6161e-01) 
2023-05-25 21:50:54.688419: val Epoch: [21][66/72]	Time  1.088 ( 0.630)	Data  0.966 ( 0.508)	Loss 9.3361e-02 (1.6059e-01) 
2023-05-25 21:50:54.808122: val Epoch: [21][67/72]	Time  0.120 ( 0.622)	Data  0.001 ( 0.500)	Loss 6.6300e-01 (1.6798e-01) 
2023-05-25 21:50:55.886556: val Epoch: [21][68/72]	Time  1.078 ( 0.629)	Data  0.961 ( 0.507)	Loss 5.9179e-02 (1.6640e-01) 
2023-05-25 21:50:56.003735: val Epoch: [21][69/72]	Time  0.117 ( 0.622)	Data  0.000 ( 0.500)	Loss 2.2088e-01 (1.6718e-01) 
2023-05-25 21:50:57.042304: val Epoch: [21][70/72]	Time  1.039 ( 0.628)	Data  0.922 ( 0.506)	Loss 6.9014e-02 (1.6580e-01) 
2023-05-25 21:50:57.160623: val Epoch: [21][71/72]	Time  0.118 ( 0.621)	Data  0.000 ( 0.499)	Loss 1.0664e-01 (1.6497e-01) 
2023-05-25 21:50:57.324327: Epoch 21 :Val : ['ET : 0.6857408881187439', 'TC : 0.7255089282989502', 'WT : 0.8209584355354309'] 
2023-05-25 21:50:57.325028: Epoch 21 :Val : ['ET : 0.6857408881187439', 'TC : 0.7255089282989502', 'WT : 0.8209584355354309'] 
2023-05-25 21:50:57.328053: Val epoch done in 45.58493652500147 s 
2023-05-25 21:50:57.337500: Batches per epoch:  129 
2023-05-25 21:51:02.048881: train Epoch: [22][  0/129]	Time  4.711 ( 4.711)	Data  3.702 ( 3.702)	Loss 1.2295e-01 (1.2295e-01) 
2023-05-25 21:51:03.002548: train Epoch: [22][  1/129]	Time  0.954 ( 2.832)	Data  0.001 ( 1.851)	Loss 1.1744e-01 (1.2019e-01) 
2023-05-25 21:51:05.595374: train Epoch: [22][  2/129]	Time  2.593 ( 2.753)	Data  1.645 ( 1.783)	Loss 7.5132e-02 (1.0517e-01) 
2023-05-25 21:51:06.544149: train Epoch: [22][  3/129]	Time  0.949 ( 2.302)	Data  0.001 ( 1.337)	Loss 1.3032e-01 (1.1146e-01) 
2023-05-25 21:51:09.094478: train Epoch: [22][  4/129]	Time  2.550 ( 2.351)	Data  1.601 ( 1.390)	Loss 9.2868e-02 (1.0774e-01) 
2023-05-25 21:51:10.054437: train Epoch: [22][  5/129]	Time  0.960 ( 2.119)	Data  0.001 ( 1.158)	Loss 9.2188e-02 (1.0515e-01) 
2023-05-25 21:51:12.599319: train Epoch: [22][  6/129]	Time  2.545 ( 2.180)	Data  1.589 ( 1.220)	Loss 8.0026e-02 (1.0156e-01) 
2023-05-25 21:51:13.550090: train Epoch: [22][  7/129]	Time  0.951 ( 2.027)	Data  0.001 ( 1.067)	Loss 1.0327e-01 (1.0177e-01) 
2023-05-25 21:51:16.088764: train Epoch: [22][  8/129]	Time  2.539 ( 2.083)	Data  1.590 ( 1.126)	Loss 1.5824e-01 (1.0805e-01) 
2023-05-25 21:51:17.037597: train Epoch: [22][  9/129]	Time  0.949 ( 1.970)	Data  0.001 ( 1.013)	Loss 7.4894e-02 (1.0473e-01) 
2023-05-25 21:51:19.601651: train Epoch: [22][ 10/129]	Time  2.564 ( 2.024)	Data  1.612 ( 1.068)	Loss 7.5030e-02 (1.0203e-01) 
2023-05-25 21:51:20.551325: train Epoch: [22][ 11/129]	Time  0.950 ( 1.934)	Data  0.001 ( 0.979)	Loss 7.7530e-02 (9.9990e-02) 
2023-05-25 21:51:23.181541: train Epoch: [22][ 12/129]	Time  2.630 ( 1.988)	Data  1.677 ( 1.032)	Loss 2.3663e-01 (1.1050e-01) 
2023-05-25 21:51:24.133011: train Epoch: [22][ 13/129]	Time  0.951 ( 1.914)	Data  0.001 ( 0.959)	Loss 1.4086e-01 (1.1267e-01) 
2023-05-25 21:51:26.736977: train Epoch: [22][ 14/129]	Time  2.604 ( 1.960)	Data  1.657 ( 1.005)	Loss 1.6909e-01 (1.1643e-01) 
2023-05-25 21:51:27.688336: train Epoch: [22][ 15/129]	Time  0.951 ( 1.897)	Data  0.001 ( 0.942)	Loss 5.5082e-02 (1.1260e-01) 
2023-05-25 21:51:30.392972: train Epoch: [22][ 16/129]	Time  2.705 ( 1.944)	Data  1.747 ( 0.990)	Loss 9.5680e-02 (1.1160e-01) 
2023-05-25 21:51:31.344189: train Epoch: [22][ 17/129]	Time  0.951 ( 1.889)	Data  0.001 ( 0.935)	Loss 7.8175e-02 (1.0974e-01) 
2023-05-25 21:51:33.936863: train Epoch: [22][ 18/129]	Time  2.593 ( 1.926)	Data  1.636 ( 0.972)	Loss 4.3077e-02 (1.0624e-01) 
2023-05-25 21:51:34.885879: train Epoch: [22][ 19/129]	Time  0.949 ( 1.877)	Data  0.001 ( 0.923)	Loss 9.5821e-02 (1.0571e-01) 
2023-05-25 21:51:37.485241: train Epoch: [22][ 20/129]	Time  2.599 ( 1.912)	Data  1.643 ( 0.958)	Loss 1.0992e-01 (1.0592e-01) 
2023-05-25 21:51:38.434627: train Epoch: [22][ 21/129]	Time  0.949 ( 1.868)	Data  0.001 ( 0.914)	Loss 1.0937e-01 (1.0607e-01) 
2023-05-25 21:51:41.055400: train Epoch: [22][ 22/129]	Time  2.621 ( 1.901)	Data  1.673 ( 0.947)	Loss 2.3916e-01 (1.1186e-01) 
2023-05-25 21:51:42.004088: train Epoch: [22][ 23/129]	Time  0.949 ( 1.861)	Data  0.001 ( 0.908)	Loss 1.8159e-01 (1.1476e-01) 
2023-05-25 21:51:44.682563: train Epoch: [22][ 24/129]	Time  2.678 ( 1.894)	Data  1.733 ( 0.941)	Loss 9.0007e-02 (1.1377e-01) 
2023-05-25 21:51:45.631912: train Epoch: [22][ 25/129]	Time  0.949 ( 1.857)	Data  0.001 ( 0.905)	Loss 1.2388e-01 (1.1416e-01) 
2023-05-25 21:51:48.212891: train Epoch: [22][ 26/129]	Time  2.581 ( 1.884)	Data  1.634 ( 0.932)	Loss 7.3038e-02 (1.1264e-01) 
2023-05-25 21:51:49.163196: train Epoch: [22][ 27/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.898)	Loss 8.4037e-02 (1.1162e-01) 
2023-05-25 21:51:51.751372: train Epoch: [22][ 28/129]	Time  2.588 ( 1.876)	Data  1.641 ( 0.924)	Loss 1.5095e-01 (1.1297e-01) 
2023-05-25 21:51:52.699985: train Epoch: [22][ 29/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.893)	Loss 9.0231e-02 (1.1222e-01) 
2023-05-25 21:51:55.294289: train Epoch: [22][ 30/129]	Time  2.594 ( 1.870)	Data  1.644 ( 0.917)	Loss 9.1897e-02 (1.1156e-01) 
2023-05-25 21:51:56.244078: train Epoch: [22][ 31/129]	Time  0.950 ( 1.841)	Data  0.001 ( 0.889)	Loss 9.3471e-02 (1.1100e-01) 
2023-05-25 21:51:58.843572: train Epoch: [22][ 32/129]	Time  2.599 ( 1.864)	Data  1.654 ( 0.912)	Loss 6.5864e-02 (1.0963e-01) 
2023-05-25 21:51:59.792330: train Epoch: [22][ 33/129]	Time  0.949 ( 1.837)	Data  0.001 ( 0.885)	Loss 7.4755e-02 (1.0860e-01) 
2023-05-25 21:52:02.484806: train Epoch: [22][ 34/129]	Time  2.692 ( 1.861)	Data  1.738 ( 0.909)	Loss 8.3359e-02 (1.0788e-01) 
2023-05-25 21:52:03.445414: train Epoch: [22][ 35/129]	Time  0.961 ( 1.836)	Data  0.001 ( 0.884)	Loss 8.5452e-02 (1.0726e-01) 
2023-05-25 21:52:06.283212: train Epoch: [22][ 36/129]	Time  2.838 ( 1.863)	Data  1.876 ( 0.911)	Loss 1.6205e-01 (1.0874e-01) 
2023-05-25 21:52:07.234727: train Epoch: [22][ 37/129]	Time  0.952 ( 1.839)	Data  0.001 ( 0.887)	Loss 7.0566e-02 (1.0773e-01) 
2023-05-25 21:52:09.944930: train Epoch: [22][ 38/129]	Time  2.710 ( 1.862)	Data  1.763 ( 0.910)	Loss 9.8744e-02 (1.0750e-01) 
2023-05-25 21:52:10.893861: train Epoch: [22][ 39/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.887)	Loss 5.8006e-02 (1.0627e-01) 
2023-05-25 21:52:13.818748: train Epoch: [22][ 40/129]	Time  2.925 ( 1.865)	Data  1.979 ( 0.913)	Loss 1.6338e-01 (1.0766e-01) 
2023-05-25 21:52:14.767059: train Epoch: [22][ 41/129]	Time  0.948 ( 1.844)	Data  0.001 ( 0.892)	Loss 8.3410e-02 (1.0708e-01) 
2023-05-25 21:52:17.408474: train Epoch: [22][ 42/129]	Time  2.641 ( 1.862)	Data  1.696 ( 0.910)	Loss 8.1589e-02 (1.0649e-01) 
2023-05-25 21:52:18.360277: train Epoch: [22][ 43/129]	Time  0.952 ( 1.841)	Data  0.001 ( 0.890)	Loss 2.1921e-01 (1.0905e-01) 
2023-05-25 21:52:21.088887: train Epoch: [22][ 44/129]	Time  2.729 ( 1.861)	Data  1.784 ( 0.910)	Loss 9.9844e-02 (1.0885e-01) 
2023-05-25 21:52:22.035591: train Epoch: [22][ 45/129]	Time  0.947 ( 1.841)	Data  0.001 ( 0.890)	Loss 6.1816e-02 (1.0782e-01) 
2023-05-25 21:52:24.628139: train Epoch: [22][ 46/129]	Time  2.593 ( 1.857)	Data  1.648 ( 0.906)	Loss 6.2954e-02 (1.0687e-01) 
2023-05-25 21:52:25.574617: train Epoch: [22][ 47/129]	Time  0.947 ( 1.838)	Data  0.001 ( 0.887)	Loss 1.6216e-01 (1.0802e-01) 
2023-05-25 21:52:28.118070: train Epoch: [22][ 48/129]	Time  2.543 ( 1.853)	Data  1.598 ( 0.902)	Loss 9.8617e-02 (1.0783e-01) 
2023-05-25 21:52:29.066963: train Epoch: [22][ 49/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.884)	Loss 7.7621e-02 (1.0722e-01) 
2023-05-25 21:52:31.727834: train Epoch: [22][ 50/129]	Time  2.661 ( 1.851)	Data  1.716 ( 0.900)	Loss 1.1950e-01 (1.0747e-01) 
2023-05-25 21:52:32.675318: train Epoch: [22][ 51/129]	Time  0.947 ( 1.833)	Data  0.001 ( 0.883)	Loss 1.2391e-01 (1.0778e-01) 
2023-05-25 21:52:35.284951: train Epoch: [22][ 52/129]	Time  2.610 ( 1.848)	Data  1.665 ( 0.897)	Loss 1.0756e-01 (1.0778e-01) 
2023-05-25 21:52:36.235689: train Epoch: [22][ 53/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.881)	Loss 1.9112e-01 (1.0932e-01) 
2023-05-25 21:52:38.885195: train Epoch: [22][ 54/129]	Time  2.649 ( 1.846)	Data  1.704 ( 0.896)	Loss 1.5013e-01 (1.1006e-01) 
2023-05-25 21:52:39.845205: train Epoch: [22][ 55/129]	Time  0.960 ( 1.830)	Data  0.001 ( 0.880)	Loss 9.1178e-02 (1.0973e-01) 
2023-05-25 21:52:42.562588: train Epoch: [22][ 56/129]	Time  2.717 ( 1.846)	Data  1.763 ( 0.895)	Loss 1.4007e-01 (1.1026e-01) 
2023-05-25 21:52:43.518062: train Epoch: [22][ 57/129]	Time  0.955 ( 1.831)	Data  0.001 ( 0.880)	Loss 1.8732e-01 (1.1159e-01) 
2023-05-25 21:52:46.049993: train Epoch: [22][ 58/129]	Time  2.532 ( 1.843)	Data  1.586 ( 0.892)	Loss 7.5355e-02 (1.1097e-01) 
2023-05-25 21:52:46.999685: train Epoch: [22][ 59/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.877)	Loss 9.3103e-02 (1.1067e-01) 
2023-05-25 21:52:49.685184: train Epoch: [22][ 60/129]	Time  2.685 ( 1.842)	Data  1.741 ( 0.891)	Loss 1.1115e-01 (1.1068e-01) 
2023-05-25 21:52:50.632782: train Epoch: [22][ 61/129]	Time  0.948 ( 1.827)	Data  0.001 ( 0.877)	Loss 8.4490e-02 (1.1026e-01) 
2023-05-25 21:52:53.380864: train Epoch: [22][ 62/129]	Time  2.748 ( 1.842)	Data  1.803 ( 0.891)	Loss 8.6365e-02 (1.0988e-01) 
2023-05-25 21:52:54.326492: train Epoch: [22][ 63/129]	Time  0.946 ( 1.828)	Data  0.001 ( 0.878)	Loss 1.0003e-01 (1.0973e-01) 
2023-05-25 21:52:57.069547: train Epoch: [22][ 64/129]	Time  2.743 ( 1.842)	Data  1.796 ( 0.892)	Loss 1.1759e-01 (1.0985e-01) 
2023-05-25 21:52:58.015456: train Epoch: [22][ 65/129]	Time  0.946 ( 1.828)	Data  0.001 ( 0.878)	Loss 7.1393e-02 (1.0927e-01) 
2023-05-25 21:53:00.616469: train Epoch: [22][ 66/129]	Time  2.601 ( 1.840)	Data  1.653 ( 0.890)	Loss 9.4728e-02 (1.0905e-01) 
2023-05-25 21:53:01.564472: train Epoch: [22][ 67/129]	Time  0.948 ( 1.827)	Data  0.001 ( 0.877)	Loss 6.7790e-02 (1.0844e-01) 
2023-05-25 21:53:04.321107: train Epoch: [22][ 68/129]	Time  2.757 ( 1.840)	Data  1.809 ( 0.890)	Loss 6.6128e-02 (1.0783e-01) 
2023-05-25 21:53:05.270968: train Epoch: [22][ 69/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.878)	Loss 7.5332e-02 (1.0736e-01) 
2023-05-25 21:53:07.951407: train Epoch: [22][ 70/129]	Time  2.680 ( 1.840)	Data  1.733 ( 0.890)	Loss 1.0817e-01 (1.0738e-01) 
2023-05-25 21:53:08.899880: train Epoch: [22][ 71/129]	Time  0.948 ( 1.827)	Data  0.001 ( 0.877)	Loss 1.5894e-01 (1.0809e-01) 
2023-05-25 21:53:11.475213: train Epoch: [22][ 72/129]	Time  2.575 ( 1.837)	Data  1.627 ( 0.888)	Loss 1.4650e-01 (1.0862e-01) 
2023-05-25 21:53:12.428215: train Epoch: [22][ 73/129]	Time  0.953 ( 1.826)	Data  0.001 ( 0.876)	Loss 9.4759e-02 (1.0843e-01) 
2023-05-25 21:53:15.015942: train Epoch: [22][ 74/129]	Time  2.588 ( 1.836)	Data  1.638 ( 0.886)	Loss 9.1868e-02 (1.0821e-01) 
2023-05-25 21:53:15.964914: train Epoch: [22][ 75/129]	Time  0.949 ( 1.824)	Data  0.001 ( 0.874)	Loss 1.4709e-01 (1.0872e-01) 
2023-05-25 21:53:18.526723: train Epoch: [22][ 76/129]	Time  2.562 ( 1.834)	Data  1.613 ( 0.884)	Loss 7.6036e-02 (1.0830e-01) 
2023-05-25 21:53:19.477406: train Epoch: [22][ 77/129]	Time  0.951 ( 1.822)	Data  0.001 ( 0.872)	Loss 1.2475e-01 (1.0851e-01) 
2023-05-25 21:53:22.131409: train Epoch: [22][ 78/129]	Time  2.654 ( 1.833)	Data  1.706 ( 0.883)	Loss 1.0182e-01 (1.0842e-01) 
2023-05-25 21:53:23.083105: train Epoch: [22][ 79/129]	Time  0.952 ( 1.822)	Data  0.001 ( 0.872)	Loss 9.9150e-02 (1.0831e-01) 
2023-05-25 21:53:25.739214: train Epoch: [22][ 80/129]	Time  2.656 ( 1.832)	Data  1.707 ( 0.882)	Loss 1.0308e-01 (1.0824e-01) 
2023-05-25 21:53:26.689519: train Epoch: [22][ 81/129]	Time  0.950 ( 1.821)	Data  0.001 ( 0.871)	Loss 9.1221e-02 (1.0804e-01) 
2023-05-25 21:53:29.441143: train Epoch: [22][ 82/129]	Time  2.752 ( 1.833)	Data  1.803 ( 0.883)	Loss 1.3299e-01 (1.0834e-01) 
2023-05-25 21:53:30.390382: train Epoch: [22][ 83/129]	Time  0.949 ( 1.822)	Data  0.001 ( 0.872)	Loss 7.8733e-02 (1.0798e-01) 
2023-05-25 21:53:33.069152: train Epoch: [22][ 84/129]	Time  2.679 ( 1.832)	Data  1.731 ( 0.882)	Loss 9.5107e-02 (1.0783e-01) 
2023-05-25 21:53:34.019418: train Epoch: [22][ 85/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.872)	Loss 4.2328e-02 (1.0707e-01) 
2023-05-25 21:53:36.732938: train Epoch: [22][ 86/129]	Time  2.714 ( 1.832)	Data  1.766 ( 0.882)	Loss 1.3887e-01 (1.0744e-01) 
2023-05-25 21:53:37.683817: train Epoch: [22][ 87/129]	Time  0.951 ( 1.822)	Data  0.001 ( 0.872)	Loss 6.0095e-02 (1.0690e-01) 
2023-05-25 21:53:40.386212: train Epoch: [22][ 88/129]	Time  2.702 ( 1.832)	Data  1.758 ( 0.882)	Loss 1.2942e-01 (1.0715e-01) 
2023-05-25 21:53:41.336331: train Epoch: [22][ 89/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.872)	Loss 7.5999e-02 (1.0680e-01) 
2023-05-25 21:53:44.031899: train Epoch: [22][ 90/129]	Time  2.696 ( 1.832)	Data  1.751 ( 0.882)	Loss 6.0520e-02 (1.0630e-01) 
2023-05-25 21:53:44.980198: train Epoch: [22][ 91/129]	Time  0.948 ( 1.822)	Data  0.001 ( 0.872)	Loss 6.9827e-02 (1.0590e-01) 
2023-05-25 21:53:47.587176: train Epoch: [22][ 92/129]	Time  2.607 ( 1.831)	Data  1.661 ( 0.881)	Loss 6.1971e-02 (1.0543e-01) 
2023-05-25 21:53:48.538806: train Epoch: [22][ 93/129]	Time  0.952 ( 1.821)	Data  0.001 ( 0.872)	Loss 1.0783e-01 (1.0545e-01) 
2023-05-25 21:53:51.200452: train Epoch: [22][ 94/129]	Time  2.662 ( 1.830)	Data  1.715 ( 0.880)	Loss 1.0453e-01 (1.0544e-01) 
2023-05-25 21:53:52.149515: train Epoch: [22][ 95/129]	Time  0.949 ( 1.821)	Data  0.001 ( 0.871)	Loss 9.2980e-02 (1.0531e-01) 
2023-05-25 21:53:54.780527: train Epoch: [22][ 96/129]	Time  2.631 ( 1.829)	Data  1.685 ( 0.880)	Loss 9.5169e-02 (1.0521e-01) 
2023-05-25 21:53:55.730205: train Epoch: [22][ 97/129]	Time  0.950 ( 1.820)	Data  0.001 ( 0.871)	Loss 1.2988e-01 (1.0546e-01) 
2023-05-25 21:53:58.369772: train Epoch: [22][ 98/129]	Time  2.640 ( 1.829)	Data  1.694 ( 0.879)	Loss 8.6386e-02 (1.0527e-01) 
2023-05-25 21:53:59.318118: train Epoch: [22][ 99/129]	Time  0.948 ( 1.820)	Data  0.001 ( 0.870)	Loss 1.1949e-01 (1.0541e-01) 
2023-05-25 21:54:01.977495: train Epoch: [22][100/129]	Time  2.659 ( 1.828)	Data  1.713 ( 0.879)	Loss 1.6545e-01 (1.0600e-01) 
2023-05-25 21:54:02.925535: train Epoch: [22][101/129]	Time  0.948 ( 1.819)	Data  0.001 ( 0.870)	Loss 1.1550e-01 (1.0610e-01) 
2023-05-25 21:54:05.573920: train Epoch: [22][102/129]	Time  2.648 ( 1.828)	Data  1.702 ( 0.878)	Loss 1.3823e-01 (1.0641e-01) 
2023-05-25 21:54:06.522652: train Epoch: [22][103/129]	Time  0.949 ( 1.819)	Data  0.001 ( 0.870)	Loss 2.2832e-01 (1.0758e-01) 
2023-05-25 21:54:09.231339: train Epoch: [22][104/129]	Time  2.709 ( 1.828)	Data  1.764 ( 0.878)	Loss 1.0412e-01 (1.0755e-01) 
2023-05-25 21:54:10.180483: train Epoch: [22][105/129]	Time  0.949 ( 1.819)	Data  0.001 ( 0.870)	Loss 6.6824e-02 (1.0716e-01) 
2023-05-25 21:54:12.779374: train Epoch: [22][106/129]	Time  2.599 ( 1.827)	Data  1.654 ( 0.877)	Loss 9.6776e-02 (1.0707e-01) 
2023-05-25 21:54:13.727724: train Epoch: [22][107/129]	Time  0.948 ( 1.818)	Data  0.001 ( 0.869)	Loss 7.6978e-02 (1.0679e-01) 
2023-05-25 21:54:16.388742: train Epoch: [22][108/129]	Time  2.661 ( 1.826)	Data  1.716 ( 0.877)	Loss 1.1754e-01 (1.0689e-01) 
2023-05-25 21:54:17.335928: train Epoch: [22][109/129]	Time  0.947 ( 1.818)	Data  0.001 ( 0.869)	Loss 8.9101e-02 (1.0673e-01) 
2023-05-25 21:54:20.036354: train Epoch: [22][110/129]	Time  2.700 ( 1.826)	Data  1.756 ( 0.877)	Loss 1.0256e-01 (1.0669e-01) 
2023-05-25 21:54:20.983226: train Epoch: [22][111/129]	Time  0.947 ( 1.818)	Data  0.001 ( 0.869)	Loss 1.0640e-01 (1.0669e-01) 
2023-05-25 21:54:23.670997: train Epoch: [22][112/129]	Time  2.688 ( 1.826)	Data  1.742 ( 0.877)	Loss 7.9551e-02 (1.0645e-01) 
2023-05-25 21:54:24.620906: train Epoch: [22][113/129]	Time  0.950 ( 1.818)	Data  0.001 ( 0.869)	Loss 1.4091e-01 (1.0675e-01) 
2023-05-25 21:54:27.249578: train Epoch: [22][114/129]	Time  2.629 ( 1.825)	Data  1.684 ( 0.876)	Loss 2.8781e-01 (1.0832e-01) 
2023-05-25 21:54:28.196098: train Epoch: [22][115/129]	Time  0.947 ( 1.818)	Data  0.001 ( 0.869)	Loss 1.0589e-01 (1.0830e-01) 
2023-05-25 21:54:30.815043: train Epoch: [22][116/129]	Time  2.619 ( 1.825)	Data  1.675 ( 0.876)	Loss 1.7910e-01 (1.0891e-01) 
2023-05-25 21:54:31.764943: train Epoch: [22][117/129]	Time  0.950 ( 1.817)	Data  0.001 ( 0.868)	Loss 9.5961e-02 (1.0880e-01) 
2023-05-25 21:54:34.486560: train Epoch: [22][118/129]	Time  2.722 ( 1.825)	Data  1.776 ( 0.876)	Loss 9.3054e-02 (1.0866e-01) 
2023-05-25 21:54:35.433243: train Epoch: [22][119/129]	Time  0.947 ( 1.817)	Data  0.001 ( 0.868)	Loss 8.2203e-02 (1.0844e-01) 
2023-05-25 21:54:38.093485: train Epoch: [22][120/129]	Time  2.660 ( 1.824)	Data  1.716 ( 0.875)	Loss 9.6020e-02 (1.0834e-01) 
2023-05-25 21:54:39.043028: train Epoch: [22][121/129]	Time  0.950 ( 1.817)	Data  0.001 ( 0.868)	Loss 1.2599e-01 (1.0849e-01) 
2023-05-25 21:54:41.738360: train Epoch: [22][122/129]	Time  2.695 ( 1.824)	Data  1.751 ( 0.875)	Loss 1.0490e-01 (1.0846e-01) 
2023-05-25 21:54:42.684953: train Epoch: [22][123/129]	Time  0.947 ( 1.817)	Data  0.001 ( 0.868)	Loss 7.7826e-02 (1.0821e-01) 
2023-05-25 21:54:45.238781: train Epoch: [22][124/129]	Time  2.554 ( 1.823)	Data  1.611 ( 0.874)	Loss 1.4314e-01 (1.0849e-01) 
2023-05-25 21:54:46.186414: train Epoch: [22][125/129]	Time  0.948 ( 1.816)	Data  0.001 ( 0.867)	Loss 1.3756e-01 (1.0872e-01) 
2023-05-25 21:54:48.409715: train Epoch: [22][126/129]	Time  2.223 ( 1.819)	Data  1.276 ( 0.871)	Loss 7.7055e-02 (1.0847e-01) 
2023-05-25 21:54:49.354353: train Epoch: [22][127/129]	Time  0.945 ( 1.813)	Data  0.001 ( 0.864)	Loss 9.0561e-02 (1.0833e-01) 
2023-05-25 21:54:50.831165: train Epoch: [22][128/129]	Time  1.477 ( 1.810)	Data  0.534 ( 0.861)	Loss 6.1585e-02 (1.0797e-01) 
2023-05-25 21:54:50.861753: Train Epoch done in 233.52427964099843 s 
2023-05-25 21:54:53.183026: val Epoch: [22][ 0/72]	Time  1.592 ( 1.592)	Data  1.388 ( 1.388)	Loss 1.7532e-01 (1.7532e-01) 
2023-05-25 21:54:53.308540: val Epoch: [22][ 1/72]	Time  0.126 ( 0.859)	Data  0.001 ( 0.695)	Loss 6.1211e-02 (1.1827e-01) 
2023-05-25 21:54:54.370142: val Epoch: [22][ 2/72]	Time  1.062 ( 0.926)	Data  0.936 ( 0.775)	Loss 7.4531e-02 (1.0369e-01) 
2023-05-25 21:54:54.494987: val Epoch: [22][ 3/72]	Time  0.125 ( 0.726)	Data  0.001 ( 0.582)	Loss 6.3581e-02 (9.3662e-02) 
2023-05-25 21:54:55.586745: val Epoch: [22][ 4/72]	Time  1.092 ( 0.799)	Data  0.967 ( 0.659)	Loss 1.7719e-01 (1.1037e-01) 
2023-05-25 21:54:55.712354: val Epoch: [22][ 5/72]	Time  0.126 ( 0.687)	Data  0.001 ( 0.549)	Loss 2.5342e-01 (1.3421e-01) 
2023-05-25 21:54:56.829904: val Epoch: [22][ 6/72]	Time  1.118 ( 0.748)	Data  0.993 ( 0.612)	Loss 6.7008e-02 (1.2461e-01) 
2023-05-25 21:54:56.954877: val Epoch: [22][ 7/72]	Time  0.125 ( 0.670)	Data  0.001 ( 0.536)	Loss 1.4900e-01 (1.2766e-01) 
2023-05-25 21:54:58.073390: val Epoch: [22][ 8/72]	Time  1.119 ( 0.720)	Data  0.993 ( 0.587)	Loss 7.6502e-02 (1.2197e-01) 
2023-05-25 21:54:58.198582: val Epoch: [22][ 9/72]	Time  0.125 ( 0.661)	Data  0.001 ( 0.528)	Loss 5.6225e-02 (1.1540e-01) 
2023-05-25 21:54:59.276464: val Epoch: [22][10/72]	Time  1.078 ( 0.699)	Data  0.956 ( 0.567)	Loss 6.8401e-02 (1.1113e-01) 
2023-05-25 21:54:59.401229: val Epoch: [22][11/72]	Time  0.125 ( 0.651)	Data  0.001 ( 0.520)	Loss 1.8130e-01 (1.1697e-01) 
2023-05-25 21:55:00.502759: val Epoch: [22][12/72]	Time  1.102 ( 0.686)	Data  0.977 ( 0.555)	Loss 1.3240e-01 (1.1816e-01) 
2023-05-25 21:55:00.627996: val Epoch: [22][13/72]	Time  0.125 ( 0.645)	Data  0.001 ( 0.515)	Loss 5.1538e-01 (1.4653e-01) 
2023-05-25 21:55:01.670478: val Epoch: [22][14/72]	Time  1.042 ( 0.672)	Data  0.921 ( 0.542)	Loss 1.0965e-01 (1.4408e-01) 
2023-05-25 21:55:01.791965: val Epoch: [22][15/72]	Time  0.121 ( 0.638)	Data  0.001 ( 0.509)	Loss 1.0625e-01 (1.4171e-01) 
2023-05-25 21:55:02.935959: val Epoch: [22][16/72]	Time  1.144 ( 0.667)	Data  1.019 ( 0.539)	Loss 1.2712e-01 (1.4085e-01) 
2023-05-25 21:55:03.061189: val Epoch: [22][17/72]	Time  0.125 ( 0.637)	Data  0.001 ( 0.509)	Loss 9.7770e-02 (1.3846e-01) 
2023-05-25 21:55:04.151128: val Epoch: [22][18/72]	Time  1.090 ( 0.661)	Data  0.969 ( 0.533)	Loss 1.1447e-01 (1.3720e-01) 
2023-05-25 21:55:04.276003: val Epoch: [22][19/72]	Time  0.125 ( 0.634)	Data  0.001 ( 0.506)	Loss 2.6859e-01 (1.4377e-01) 
2023-05-25 21:55:05.378766: val Epoch: [22][20/72]	Time  1.103 ( 0.657)	Data  0.981 ( 0.529)	Loss 1.2552e-01 (1.4290e-01) 
2023-05-25 21:55:05.500111: val Epoch: [22][21/72]	Time  0.121 ( 0.632)	Data  0.001 ( 0.505)	Loss 9.5084e-02 (1.4072e-01) 
2023-05-25 21:55:06.599571: val Epoch: [22][22/72]	Time  1.099 ( 0.653)	Data  0.978 ( 0.525)	Loss 1.0827e-01 (1.3931e-01) 
2023-05-25 21:55:06.720891: val Epoch: [22][23/72]	Time  0.121 ( 0.630)	Data  0.001 ( 0.504)	Loss 2.2572e-01 (1.4291e-01) 
2023-05-25 21:55:07.851038: val Epoch: [22][24/72]	Time  1.130 ( 0.650)	Data  1.005 ( 0.524)	Loss 3.9705e-01 (1.5308e-01) 
2023-05-25 21:55:07.972505: val Epoch: [22][25/72]	Time  0.121 ( 0.630)	Data  0.001 ( 0.504)	Loss 1.3128e-01 (1.5224e-01) 
2023-05-25 21:55:09.034547: val Epoch: [22][26/72]	Time  1.062 ( 0.646)	Data  0.938 ( 0.520)	Loss 9.1998e-02 (1.5001e-01) 
2023-05-25 21:55:09.155933: val Epoch: [22][27/72]	Time  0.121 ( 0.627)	Data  0.000 ( 0.501)	Loss 1.7791e-01 (1.5101e-01) 
2023-05-25 21:55:10.301703: val Epoch: [22][28/72]	Time  1.146 ( 0.645)	Data  1.024 ( 0.519)	Loss 1.6035e-01 (1.5133e-01) 
2023-05-25 21:55:10.426059: val Epoch: [22][29/72]	Time  0.124 ( 0.628)	Data  0.001 ( 0.502)	Loss 1.7797e-01 (1.5222e-01) 
2023-05-25 21:55:11.504027: val Epoch: [22][30/72]	Time  1.078 ( 0.642)	Data  0.956 ( 0.517)	Loss 6.7913e-02 (1.4950e-01) 
2023-05-25 21:55:11.628434: val Epoch: [22][31/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.500)	Loss 2.1252e-01 (1.5147e-01) 
2023-05-25 21:55:12.764597: val Epoch: [22][32/72]	Time  1.136 ( 0.642)	Data  1.012 ( 0.516)	Loss 1.4855e-01 (1.5138e-01) 
2023-05-25 21:55:12.886902: val Epoch: [22][33/72]	Time  0.122 ( 0.626)	Data  0.001 ( 0.501)	Loss 5.8998e-02 (1.4866e-01) 
2023-05-25 21:55:13.982287: val Epoch: [22][34/72]	Time  1.095 ( 0.640)	Data  0.973 ( 0.514)	Loss 7.4192e-02 (1.4653e-01) 
2023-05-25 21:55:14.107913: val Epoch: [22][35/72]	Time  0.126 ( 0.625)	Data  0.001 ( 0.500)	Loss 7.4703e-02 (1.4454e-01) 
2023-05-25 21:55:15.233254: val Epoch: [22][36/72]	Time  1.125 ( 0.639)	Data  1.004 ( 0.514)	Loss 6.1965e-02 (1.4231e-01) 
2023-05-25 21:55:15.359033: val Epoch: [22][37/72]	Time  0.126 ( 0.625)	Data  0.001 ( 0.500)	Loss 6.6365e-02 (1.4031e-01) 
2023-05-25 21:55:16.434110: val Epoch: [22][38/72]	Time  1.075 ( 0.637)	Data  0.954 ( 0.512)	Loss 3.8695e-01 (1.4663e-01) 
2023-05-25 21:55:16.560093: val Epoch: [22][39/72]	Time  0.126 ( 0.624)	Data  0.001 ( 0.499)	Loss 3.4070e-01 (1.5148e-01) 
2023-05-25 21:55:17.638258: val Epoch: [22][40/72]	Time  1.078 ( 0.635)	Data  0.954 ( 0.510)	Loss 3.0877e-01 (1.5532e-01) 
2023-05-25 21:55:17.764078: val Epoch: [22][41/72]	Time  0.126 ( 0.623)	Data  0.001 ( 0.498)	Loss 5.8480e-01 (1.6555e-01) 
2023-05-25 21:55:18.825526: val Epoch: [22][42/72]	Time  1.061 ( 0.633)	Data  0.937 ( 0.508)	Loss 8.6774e-02 (1.6371e-01) 
2023-05-25 21:55:18.951134: val Epoch: [22][43/72]	Time  0.126 ( 0.622)	Data  0.001 ( 0.497)	Loss 1.1026e-01 (1.6250e-01) 
2023-05-25 21:55:20.003983: val Epoch: [22][44/72]	Time  1.053 ( 0.631)	Data  0.929 ( 0.506)	Loss 4.8529e-02 (1.5997e-01) 
2023-05-25 21:55:20.129809: val Epoch: [22][45/72]	Time  0.126 ( 0.620)	Data  0.001 ( 0.495)	Loss 5.9940e-02 (1.5779e-01) 
2023-05-25 21:55:21.242974: val Epoch: [22][46/72]	Time  1.113 ( 0.631)	Data  0.992 ( 0.506)	Loss 4.0379e-01 (1.6303e-01) 
2023-05-25 21:55:21.369414: val Epoch: [22][47/72]	Time  0.126 ( 0.620)	Data  0.001 ( 0.495)	Loss 1.5655e-01 (1.6289e-01) 
2023-05-25 21:55:22.459545: val Epoch: [22][48/72]	Time  1.090 ( 0.630)	Data  0.965 ( 0.505)	Loss 1.4146e-01 (1.6245e-01) 
2023-05-25 21:55:22.581367: val Epoch: [22][49/72]	Time  0.122 ( 0.620)	Data  0.001 ( 0.495)	Loss 2.1429e-01 (1.6349e-01) 
2023-05-25 21:55:23.649537: val Epoch: [22][50/72]	Time  1.068 ( 0.629)	Data  0.947 ( 0.504)	Loss 5.3270e-02 (1.6133e-01) 
2023-05-25 21:55:23.775413: val Epoch: [22][51/72]	Time  0.126 ( 0.619)	Data  0.001 ( 0.494)	Loss 1.3107e-01 (1.6075e-01) 
2023-05-25 21:55:24.842365: val Epoch: [22][52/72]	Time  1.067 ( 0.627)	Data  0.945 ( 0.502)	Loss 5.9075e-02 (1.5883e-01) 
2023-05-25 21:55:24.970556: val Epoch: [22][53/72]	Time  0.128 ( 0.618)	Data  0.001 ( 0.493)	Loss 9.8237e-02 (1.5771e-01) 
2023-05-25 21:55:26.036895: val Epoch: [22][54/72]	Time  1.066 ( 0.626)	Data  0.939 ( 0.501)	Loss 2.1487e-01 (1.5875e-01) 
2023-05-25 21:55:26.163473: val Epoch: [22][55/72]	Time  0.127 ( 0.617)	Data  0.001 ( 0.492)	Loss 4.9503e-02 (1.5680e-01) 
2023-05-25 21:55:27.212223: val Epoch: [22][56/72]	Time  1.049 ( 0.625)	Data  0.923 ( 0.500)	Loss 7.7897e-02 (1.5541e-01) 
2023-05-25 21:55:27.338890: val Epoch: [22][57/72]	Time  0.127 ( 0.616)	Data  0.001 ( 0.491)	Loss 4.2051e-01 (1.5998e-01) 
2023-05-25 21:55:28.385433: val Epoch: [22][58/72]	Time  1.047 ( 0.624)	Data  0.921 ( 0.499)	Loss 7.7862e-02 (1.5859e-01) 
2023-05-25 21:55:28.512397: val Epoch: [22][59/72]	Time  0.127 ( 0.615)	Data  0.001 ( 0.490)	Loss 1.1026e-01 (1.5778e-01) 
2023-05-25 21:55:29.665468: val Epoch: [22][60/72]	Time  1.153 ( 0.624)	Data  1.030 ( 0.499)	Loss 3.9649e-01 (1.6170e-01) 
2023-05-25 21:55:29.792855: val Epoch: [22][61/72]	Time  0.127 ( 0.616)	Data  0.001 ( 0.491)	Loss 7.0562e-02 (1.6023e-01) 
2023-05-25 21:55:30.973990: val Epoch: [22][62/72]	Time  1.181 ( 0.625)	Data  1.057 ( 0.500)	Loss 1.5698e-01 (1.6018e-01) 
2023-05-25 21:55:31.099423: val Epoch: [22][63/72]	Time  0.125 ( 0.617)	Data  0.001 ( 0.492)	Loss 1.5837e-01 (1.6015e-01) 
2023-05-25 21:55:32.185283: val Epoch: [22][64/72]	Time  1.086 ( 0.625)	Data  0.959 ( 0.499)	Loss 1.6778e-01 (1.6027e-01) 
2023-05-25 21:55:32.311744: val Epoch: [22][65/72]	Time  0.126 ( 0.617)	Data  0.001 ( 0.492)	Loss 2.7347e-01 (1.6198e-01) 
2023-05-25 21:55:33.463593: val Epoch: [22][66/72]	Time  1.152 ( 0.625)	Data  1.030 ( 0.500)	Loss 4.4627e-01 (1.6622e-01) 
2023-05-25 21:55:33.592185: val Epoch: [22][67/72]	Time  0.129 ( 0.618)	Data  0.001 ( 0.493)	Loss 6.3334e-02 (1.6471e-01) 
2023-05-25 21:55:34.654773: val Epoch: [22][68/72]	Time  1.063 ( 0.624)	Data  0.945 ( 0.499)	Loss 1.1930e-01 (1.6405e-01) 
2023-05-25 21:55:34.779080: val Epoch: [22][69/72]	Time  0.124 ( 0.617)	Data  0.000 ( 0.492)	Loss 8.0602e-02 (1.6286e-01) 
2023-05-25 21:55:35.564940: val Epoch: [22][70/72]	Time  0.786 ( 0.619)	Data  0.667 ( 0.494)	Loss 2.7808e-01 (1.6448e-01) 
2023-05-25 21:55:35.683760: val Epoch: [22][71/72]	Time  0.119 ( 0.612)	Data  0.000 ( 0.488)	Loss 8.4641e-02 (1.6337e-01) 
2023-05-25 21:55:35.874296: Epoch 22 :Val : ['ET : 0.7171281576156616', 'TC : 0.7152668833732605', 'WT : 0.8073358535766602'] 
2023-05-25 21:55:35.876815: Epoch 22 :Val : ['ET : 0.7171281576156616', 'TC : 0.7152668833732605', 'WT : 0.8073358535766602'] 
2023-05-25 21:55:35.878593: Val epoch done in 45.016847087001224 s 
2023-05-25 21:55:35.884274: Batches per epoch:  129 
2023-05-25 21:55:40.871644: train Epoch: [23][  0/129]	Time  4.987 ( 4.987)	Data  3.978 ( 3.978)	Loss 1.7123e-01 (1.7123e-01) 
2023-05-25 21:55:41.828295: train Epoch: [23][  1/129]	Time  0.957 ( 2.972)	Data  0.001 ( 1.989)	Loss 8.5083e-02 (1.2816e-01) 
2023-05-25 21:55:44.329889: train Epoch: [23][  2/129]	Time  2.502 ( 2.815)	Data  1.550 ( 1.843)	Loss 1.2279e-01 (1.2637e-01) 
2023-05-25 21:55:45.276801: train Epoch: [23][  3/129]	Time  0.947 ( 2.348)	Data  0.001 ( 1.383)	Loss 1.1887e-01 (1.2449e-01) 
2023-05-25 21:55:47.831437: train Epoch: [23][  4/129]	Time  2.555 ( 2.389)	Data  1.608 ( 1.428)	Loss 1.4905e-01 (1.2940e-01) 
2023-05-25 21:55:48.778730: train Epoch: [23][  5/129]	Time  0.947 ( 2.149)	Data  0.001 ( 1.190)	Loss 7.8194e-02 (1.2087e-01) 
2023-05-25 21:55:51.457867: train Epoch: [23][  6/129]	Time  2.679 ( 2.225)	Data  1.734 ( 1.268)	Loss 8.1442e-02 (1.1524e-01) 
2023-05-25 21:55:52.403097: train Epoch: [23][  7/129]	Time  0.945 ( 2.065)	Data  0.001 ( 1.109)	Loss 9.9211e-02 (1.1323e-01) 
2023-05-25 21:55:55.046215: train Epoch: [23][  8/129]	Time  2.643 ( 2.129)	Data  1.689 ( 1.174)	Loss 1.0217e-01 (1.1200e-01) 
2023-05-25 21:55:55.994589: train Epoch: [23][  9/129]	Time  0.948 ( 2.011)	Data  0.001 ( 1.056)	Loss 8.5207e-02 (1.0932e-01) 
2023-05-25 21:55:58.653676: train Epoch: [23][ 10/129]	Time  2.659 ( 2.070)	Data  1.713 ( 1.116)	Loss 5.6114e-02 (1.0449e-01) 
2023-05-25 21:55:59.599877: train Epoch: [23][ 11/129]	Time  0.946 ( 1.976)	Data  0.001 ( 1.023)	Loss 1.7173e-01 (1.1009e-01) 
2023-05-25 21:56:02.181378: train Epoch: [23][ 12/129]	Time  2.581 ( 2.023)	Data  1.638 ( 1.071)	Loss 5.5424e-02 (1.0588e-01) 
2023-05-25 21:56:03.127891: train Epoch: [23][ 13/129]	Time  0.947 ( 1.946)	Data  0.001 ( 0.994)	Loss 7.1542e-02 (1.0343e-01) 
2023-05-25 21:56:05.799375: train Epoch: [23][ 14/129]	Time  2.671 ( 1.994)	Data  1.725 ( 1.043)	Loss 1.3995e-01 (1.0587e-01) 
2023-05-25 21:56:06.747861: train Epoch: [23][ 15/129]	Time  0.948 ( 1.929)	Data  0.001 ( 0.978)	Loss 1.0268e-01 (1.0567e-01) 
2023-05-25 21:56:09.334358: train Epoch: [23][ 16/129]	Time  2.586 ( 1.968)	Data  1.641 ( 1.017)	Loss 1.4556e-01 (1.0801e-01) 
2023-05-25 21:56:10.282677: train Epoch: [23][ 17/129]	Time  0.948 ( 1.911)	Data  0.001 ( 0.960)	Loss 6.7011e-02 (1.0574e-01) 
2023-05-25 21:56:12.908219: train Epoch: [23][ 18/129]	Time  2.626 ( 1.949)	Data  1.681 ( 0.998)	Loss 7.0156e-02 (1.0386e-01) 
2023-05-25 21:56:13.857680: train Epoch: [23][ 19/129]	Time  0.949 ( 1.899)	Data  0.001 ( 0.948)	Loss 1.1121e-01 (1.0423e-01) 
2023-05-25 21:56:16.410680: train Epoch: [23][ 20/129]	Time  2.553 ( 1.930)	Data  1.608 ( 0.980)	Loss 5.8849e-02 (1.0207e-01) 
2023-05-25 21:56:17.359286: train Epoch: [23][ 21/129]	Time  0.949 ( 1.885)	Data  0.001 ( 0.935)	Loss 9.6975e-02 (1.0184e-01) 
2023-05-25 21:56:20.022633: train Epoch: [23][ 22/129]	Time  2.663 ( 1.919)	Data  1.716 ( 0.969)	Loss 7.4667e-02 (1.0066e-01) 
2023-05-25 21:56:20.969651: train Epoch: [23][ 23/129]	Time  0.947 ( 1.879)	Data  0.001 ( 0.929)	Loss 6.0466e-02 (9.8982e-02) 
2023-05-25 21:56:23.587007: train Epoch: [23][ 24/129]	Time  2.617 ( 1.908)	Data  1.673 ( 0.959)	Loss 1.1516e-01 (9.9629e-02) 
2023-05-25 21:56:24.533466: train Epoch: [23][ 25/129]	Time  0.946 ( 1.871)	Data  0.001 ( 0.922)	Loss 8.6408e-02 (9.9121e-02) 
2023-05-25 21:56:27.055930: train Epoch: [23][ 26/129]	Time  2.522 ( 1.895)	Data  1.578 ( 0.946)	Loss 8.9967e-02 (9.8782e-02) 
2023-05-25 21:56:28.002576: train Epoch: [23][ 27/129]	Time  0.947 ( 1.861)	Data  0.001 ( 0.912)	Loss 8.8688e-02 (9.8421e-02) 
2023-05-25 21:56:30.627197: train Epoch: [23][ 28/129]	Time  2.625 ( 1.888)	Data  1.680 ( 0.939)	Loss 8.0983e-02 (9.7820e-02) 
2023-05-25 21:56:31.573848: train Epoch: [23][ 29/129]	Time  0.947 ( 1.856)	Data  0.001 ( 0.908)	Loss 7.0820e-02 (9.6920e-02) 
2023-05-25 21:56:34.205152: train Epoch: [23][ 30/129]	Time  2.631 ( 1.881)	Data  1.686 ( 0.933)	Loss 7.2482e-02 (9.6131e-02) 
2023-05-25 21:56:35.152231: train Epoch: [23][ 31/129]	Time  0.947 ( 1.852)	Data  0.001 ( 0.904)	Loss 7.6308e-02 (9.5512e-02) 
2023-05-25 21:56:37.719931: train Epoch: [23][ 32/129]	Time  2.568 ( 1.874)	Data  1.622 ( 0.925)	Loss 1.0412e-01 (9.5773e-02) 
2023-05-25 21:56:38.671594: train Epoch: [23][ 33/129]	Time  0.952 ( 1.847)	Data  0.001 ( 0.898)	Loss 1.0650e-01 (9.6088e-02) 
2023-05-25 21:56:41.328644: train Epoch: [23][ 34/129]	Time  2.657 ( 1.870)	Data  1.712 ( 0.921)	Loss 6.6640e-02 (9.5247e-02) 
2023-05-25 21:56:42.274978: train Epoch: [23][ 35/129]	Time  0.946 ( 1.844)	Data  0.001 ( 0.896)	Loss 5.6051e-02 (9.4158e-02) 
2023-05-25 21:56:44.816476: train Epoch: [23][ 36/129]	Time  2.541 ( 1.863)	Data  1.595 ( 0.915)	Loss 5.0031e-02 (9.2965e-02) 
2023-05-25 21:56:45.764930: train Epoch: [23][ 37/129]	Time  0.948 ( 1.839)	Data  0.001 ( 0.891)	Loss 7.9188e-02 (9.2603e-02) 
2023-05-25 21:56:48.392186: train Epoch: [23][ 38/129]	Time  2.627 ( 1.859)	Data  1.683 ( 0.911)	Loss 1.1482e-01 (9.3173e-02) 
2023-05-25 21:56:49.341012: train Epoch: [23][ 39/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.888)	Loss 1.0745e-01 (9.3530e-02) 
2023-05-25 21:56:51.977386: train Epoch: [23][ 40/129]	Time  2.636 ( 1.856)	Data  1.682 ( 0.908)	Loss 5.9362e-02 (9.2696e-02) 
2023-05-25 21:56:52.938277: train Epoch: [23][ 41/129]	Time  0.961 ( 1.835)	Data  0.001 ( 0.886)	Loss 1.1597e-01 (9.3251e-02) 
2023-05-25 21:56:55.546480: train Epoch: [23][ 42/129]	Time  2.608 ( 1.853)	Data  1.654 ( 0.904)	Loss 6.9316e-02 (9.2694e-02) 
2023-05-25 21:56:56.496875: train Epoch: [23][ 43/129]	Time  0.950 ( 1.832)	Data  0.001 ( 0.883)	Loss 7.9714e-02 (9.2399e-02) 
2023-05-25 21:56:59.232437: train Epoch: [23][ 44/129]	Time  2.736 ( 1.852)	Data  1.789 ( 0.903)	Loss 8.0250e-02 (9.2129e-02) 
2023-05-25 21:57:00.179661: train Epoch: [23][ 45/129]	Time  0.947 ( 1.832)	Data  0.001 ( 0.884)	Loss 1.2626e-01 (9.2871e-02) 
2023-05-25 21:57:02.727191: train Epoch: [23][ 46/129]	Time  2.548 ( 1.848)	Data  1.600 ( 0.899)	Loss 5.5771e-02 (9.2082e-02) 
2023-05-25 21:57:03.686358: train Epoch: [23][ 47/129]	Time  0.959 ( 1.829)	Data  0.001 ( 0.880)	Loss 6.5163e-02 (9.1521e-02) 
2023-05-25 21:57:06.338241: train Epoch: [23][ 48/129]	Time  2.652 ( 1.846)	Data  1.689 ( 0.897)	Loss 8.8686e-02 (9.1463e-02) 
2023-05-25 21:57:07.296011: train Epoch: [23][ 49/129]	Time  0.958 ( 1.828)	Data  0.001 ( 0.879)	Loss 1.1701e-01 (9.1974e-02) 
2023-05-25 21:57:09.947698: train Epoch: [23][ 50/129]	Time  2.652 ( 1.844)	Data  1.697 ( 0.895)	Loss 6.7453e-02 (9.1493e-02) 
2023-05-25 21:57:10.905168: train Epoch: [23][ 51/129]	Time  0.957 ( 1.827)	Data  0.001 ( 0.878)	Loss 7.5112e-02 (9.1178e-02) 
2023-05-25 21:57:13.507919: train Epoch: [23][ 52/129]	Time  2.603 ( 1.842)	Data  1.647 ( 0.892)	Loss 8.9469e-02 (9.1146e-02) 
2023-05-25 21:57:14.466588: train Epoch: [23][ 53/129]	Time  0.959 ( 1.826)	Data  0.001 ( 0.876)	Loss 9.1822e-02 (9.1158e-02) 
2023-05-25 21:57:17.164923: train Epoch: [23][ 54/129]	Time  2.698 ( 1.841)	Data  1.736 ( 0.891)	Loss 9.5080e-02 (9.1230e-02) 
2023-05-25 21:57:18.129343: train Epoch: [23][ 55/129]	Time  0.964 ( 1.826)	Data  0.001 ( 0.876)	Loss 9.6270e-02 (9.1320e-02) 
2023-05-25 21:57:20.839286: train Epoch: [23][ 56/129]	Time  2.710 ( 1.841)	Data  1.761 ( 0.891)	Loss 7.5733e-02 (9.1046e-02) 
2023-05-25 21:57:21.792913: train Epoch: [23][ 57/129]	Time  0.954 ( 1.826)	Data  0.001 ( 0.876)	Loss 1.2431e-01 (9.1620e-02) 
2023-05-25 21:57:24.558603: train Epoch: [23][ 58/129]	Time  2.766 ( 1.842)	Data  1.820 ( 0.892)	Loss 6.8471e-02 (9.1227e-02) 
2023-05-25 21:57:25.506091: train Epoch: [23][ 59/129]	Time  0.947 ( 1.827)	Data  0.001 ( 0.877)	Loss 7.0902e-02 (9.0888e-02) 
2023-05-25 21:57:28.145035: train Epoch: [23][ 60/129]	Time  2.639 ( 1.840)	Data  1.695 ( 0.890)	Loss 9.2056e-02 (9.0908e-02) 
2023-05-25 21:57:29.097242: train Epoch: [23][ 61/129]	Time  0.952 ( 1.826)	Data  0.001 ( 0.876)	Loss 1.1621e-01 (9.1316e-02) 
2023-05-25 21:57:31.745949: train Epoch: [23][ 62/129]	Time  2.649 ( 1.839)	Data  1.704 ( 0.889)	Loss 8.1304e-02 (9.1157e-02) 
2023-05-25 21:57:32.691745: train Epoch: [23][ 63/129]	Time  0.946 ( 1.825)	Data  0.001 ( 0.875)	Loss 8.2161e-02 (9.1016e-02) 
2023-05-25 21:57:35.350351: train Epoch: [23][ 64/129]	Time  2.659 ( 1.838)	Data  1.713 ( 0.888)	Loss 9.6949e-02 (9.1107e-02) 
2023-05-25 21:57:36.297624: train Epoch: [23][ 65/129]	Time  0.947 ( 1.824)	Data  0.001 ( 0.875)	Loss 1.1922e-01 (9.1533e-02) 
2023-05-25 21:57:38.871515: train Epoch: [23][ 66/129]	Time  2.574 ( 1.836)	Data  1.626 ( 0.886)	Loss 8.9441e-02 (9.1502e-02) 
2023-05-25 21:57:39.818920: train Epoch: [23][ 67/129]	Time  0.947 ( 1.823)	Data  0.001 ( 0.873)	Loss 8.3352e-02 (9.1382e-02) 
2023-05-25 21:57:42.456148: train Epoch: [23][ 68/129]	Time  2.637 ( 1.834)	Data  1.692 ( 0.885)	Loss 1.3465e-01 (9.2009e-02) 
2023-05-25 21:57:43.403489: train Epoch: [23][ 69/129]	Time  0.947 ( 1.822)	Data  0.001 ( 0.872)	Loss 1.3621e-01 (9.2641e-02) 
2023-05-25 21:57:45.997880: train Epoch: [23][ 70/129]	Time  2.594 ( 1.833)	Data  1.649 ( 0.883)	Loss 5.3408e-02 (9.2088e-02) 
2023-05-25 21:57:46.946163: train Epoch: [23][ 71/129]	Time  0.948 ( 1.820)	Data  0.001 ( 0.871)	Loss 1.0136e-01 (9.2217e-02) 
2023-05-25 21:57:49.450772: train Epoch: [23][ 72/129]	Time  2.505 ( 1.830)	Data  1.558 ( 0.880)	Loss 1.1574e-01 (9.2539e-02) 
2023-05-25 21:57:50.398665: train Epoch: [23][ 73/129]	Time  0.948 ( 1.818)	Data  0.001 ( 0.868)	Loss 1.6902e-01 (9.3573e-02) 
2023-05-25 21:57:53.090419: train Epoch: [23][ 74/129]	Time  2.692 ( 1.829)	Data  1.746 ( 0.880)	Loss 1.3556e-01 (9.4133e-02) 
2023-05-25 21:57:54.039207: train Epoch: [23][ 75/129]	Time  0.949 ( 1.818)	Data  0.001 ( 0.868)	Loss 6.8642e-02 (9.3797e-02) 
2023-05-25 21:57:56.630668: train Epoch: [23][ 76/129]	Time  2.591 ( 1.828)	Data  1.646 ( 0.879)	Loss 1.0715e-01 (9.3971e-02) 
2023-05-25 21:57:57.580684: train Epoch: [23][ 77/129]	Time  0.950 ( 1.817)	Data  0.001 ( 0.867)	Loss 1.4427e-01 (9.4615e-02) 
2023-05-25 21:58:00.381067: train Epoch: [23][ 78/129]	Time  2.800 ( 1.829)	Data  1.853 ( 0.880)	Loss 1.2390e-01 (9.4986e-02) 
2023-05-25 21:58:01.332363: train Epoch: [23][ 79/129]	Time  0.951 ( 1.818)	Data  0.001 ( 0.869)	Loss 8.5789e-02 (9.4871e-02) 
2023-05-25 21:58:04.190814: train Epoch: [23][ 80/129]	Time  2.858 ( 1.831)	Data  1.912 ( 0.882)	Loss 1.0023e-01 (9.4937e-02) 
2023-05-25 21:58:05.139981: train Epoch: [23][ 81/129]	Time  0.949 ( 1.820)	Data  0.001 ( 0.871)	Loss 8.3344e-02 (9.4796e-02) 
2023-05-25 21:58:07.788274: train Epoch: [23][ 82/129]	Time  2.648 ( 1.830)	Data  1.701 ( 0.881)	Loss 7.8207e-02 (9.4596e-02) 
2023-05-25 21:58:08.742200: train Epoch: [23][ 83/129]	Time  0.954 ( 1.820)	Data  0.001 ( 0.870)	Loss 7.6690e-02 (9.4383e-02) 
2023-05-25 21:58:11.444213: train Epoch: [23][ 84/129]	Time  2.702 ( 1.830)	Data  1.753 ( 0.881)	Loss 8.0638e-02 (9.4221e-02) 
2023-05-25 21:58:12.392207: train Epoch: [23][ 85/129]	Time  0.948 ( 1.820)	Data  0.001 ( 0.871)	Loss 6.1095e-02 (9.3836e-02) 
2023-05-25 21:58:15.021851: train Epoch: [23][ 86/129]	Time  2.630 ( 1.829)	Data  1.682 ( 0.880)	Loss 7.2105e-02 (9.3586e-02) 
2023-05-25 21:58:15.970568: train Epoch: [23][ 87/129]	Time  0.949 ( 1.819)	Data  0.001 ( 0.870)	Loss 5.4543e-02 (9.3143e-02) 
2023-05-25 21:58:18.637297: train Epoch: [23][ 88/129]	Time  2.667 ( 1.829)	Data  1.720 ( 0.879)	Loss 6.5409e-02 (9.2831e-02) 
2023-05-25 21:58:19.586121: train Epoch: [23][ 89/129]	Time  0.949 ( 1.819)	Data  0.001 ( 0.870)	Loss 9.5108e-02 (9.2856e-02) 
2023-05-25 21:58:22.208295: train Epoch: [23][ 90/129]	Time  2.622 ( 1.828)	Data  1.675 ( 0.879)	Loss 5.9877e-02 (9.2494e-02) 
2023-05-25 21:58:23.157218: train Epoch: [23][ 91/129]	Time  0.949 ( 1.818)	Data  0.001 ( 0.869)	Loss 9.3166e-02 (9.2501e-02) 
2023-05-25 21:58:25.725719: train Epoch: [23][ 92/129]	Time  2.568 ( 1.826)	Data  1.623 ( 0.877)	Loss 1.2883e-01 (9.2892e-02) 
2023-05-25 21:58:26.675435: train Epoch: [23][ 93/129]	Time  0.950 ( 1.817)	Data  0.001 ( 0.868)	Loss 1.6521e-01 (9.3661e-02) 
2023-05-25 21:58:29.302936: train Epoch: [23][ 94/129]	Time  2.627 ( 1.825)	Data  1.681 ( 0.876)	Loss 1.1188e-01 (9.3853e-02) 
2023-05-25 21:58:30.251400: train Epoch: [23][ 95/129]	Time  0.948 ( 1.816)	Data  0.001 ( 0.867)	Loss 1.3330e-01 (9.4264e-02) 
2023-05-25 21:58:32.921838: train Epoch: [23][ 96/129]	Time  2.670 ( 1.825)	Data  1.723 ( 0.876)	Loss 1.1392e-01 (9.4466e-02) 
2023-05-25 21:58:33.873302: train Epoch: [23][ 97/129]	Time  0.951 ( 1.816)	Data  0.001 ( 0.867)	Loss 8.7021e-02 (9.4390e-02) 
2023-05-25 21:58:36.483989: train Epoch: [23][ 98/129]	Time  2.611 ( 1.824)	Data  1.664 ( 0.875)	Loss 1.6477e-01 (9.5101e-02) 
2023-05-25 21:58:37.434189: train Epoch: [23][ 99/129]	Time  0.950 ( 1.815)	Data  0.001 ( 0.866)	Loss 9.0623e-02 (9.5057e-02) 
2023-05-25 21:58:40.176405: train Epoch: [23][100/129]	Time  2.742 ( 1.825)	Data  1.795 ( 0.876)	Loss 1.1723e-01 (9.5276e-02) 
2023-05-25 21:58:41.123250: train Epoch: [23][101/129]	Time  0.947 ( 1.816)	Data  0.001 ( 0.867)	Loss 1.1517e-01 (9.5471e-02) 
2023-05-25 21:58:43.749518: train Epoch: [23][102/129]	Time  2.626 ( 1.824)	Data  1.680 ( 0.875)	Loss 9.5913e-02 (9.5475e-02) 
2023-05-25 21:58:44.697339: train Epoch: [23][103/129]	Time  0.948 ( 1.816)	Data  0.001 ( 0.867)	Loss 1.0032e-01 (9.5522e-02) 
2023-05-25 21:58:47.288912: train Epoch: [23][104/129]	Time  2.592 ( 1.823)	Data  1.647 ( 0.874)	Loss 1.6346e-01 (9.6169e-02) 
2023-05-25 21:58:48.238468: train Epoch: [23][105/129]	Time  0.950 ( 1.815)	Data  0.001 ( 0.866)	Loss 1.3499e-01 (9.6535e-02) 
2023-05-25 21:58:50.872941: train Epoch: [23][106/129]	Time  2.634 ( 1.822)	Data  1.689 ( 0.873)	Loss 5.3423e-02 (9.6132e-02) 
2023-05-25 21:58:51.820460: train Epoch: [23][107/129]	Time  0.948 ( 1.814)	Data  0.001 ( 0.865)	Loss 6.0840e-02 (9.5806e-02) 
2023-05-25 21:58:54.390702: train Epoch: [23][108/129]	Time  2.570 ( 1.821)	Data  1.625 ( 0.872)	Loss 1.6257e-01 (9.6418e-02) 
2023-05-25 21:58:55.339534: train Epoch: [23][109/129]	Time  0.949 ( 1.813)	Data  0.001 ( 0.864)	Loss 7.6329e-02 (9.6235e-02) 
2023-05-25 21:58:57.920837: train Epoch: [23][110/129]	Time  2.581 ( 1.820)	Data  1.637 ( 0.871)	Loss 6.1464e-02 (9.5922e-02) 
2023-05-25 21:58:58.887615: train Epoch: [23][111/129]	Time  0.967 ( 1.813)	Data  0.001 ( 0.864)	Loss 9.8630e-02 (9.5946e-02) 
2023-05-25 21:59:01.421033: train Epoch: [23][112/129]	Time  2.533 ( 1.819)	Data  1.585 ( 0.870)	Loss 5.9887e-02 (9.5627e-02) 
2023-05-25 21:59:02.369451: train Epoch: [23][113/129]	Time  0.948 ( 1.811)	Data  0.001 ( 0.862)	Loss 8.4601e-02 (9.5531e-02) 
2023-05-25 21:59:04.979716: train Epoch: [23][114/129]	Time  2.610 ( 1.818)	Data  1.664 ( 0.869)	Loss 7.8813e-02 (9.5385e-02) 
2023-05-25 21:59:05.929728: train Epoch: [23][115/129]	Time  0.950 ( 1.811)	Data  0.001 ( 0.862)	Loss 7.2920e-02 (9.5192e-02) 
2023-05-25 21:59:08.588234: train Epoch: [23][116/129]	Time  2.658 ( 1.818)	Data  1.711 ( 0.869)	Loss 9.2111e-02 (9.5165e-02) 
2023-05-25 21:59:09.536969: train Epoch: [23][117/129]	Time  0.949 ( 1.811)	Data  0.001 ( 0.862)	Loss 1.4366e-01 (9.5576e-02) 
2023-05-25 21:59:12.150524: train Epoch: [23][118/129]	Time  2.614 ( 1.817)	Data  1.666 ( 0.869)	Loss 9.6909e-02 (9.5587e-02) 
2023-05-25 21:59:13.100948: train Epoch: [23][119/129]	Time  0.950 ( 1.810)	Data  0.001 ( 0.861)	Loss 8.8550e-02 (9.5529e-02) 
2023-05-25 21:59:15.662971: train Epoch: [23][120/129]	Time  2.562 ( 1.816)	Data  1.615 ( 0.868)	Loss 7.6607e-02 (9.5372e-02) 
2023-05-25 21:59:16.614583: train Epoch: [23][121/129]	Time  0.952 ( 1.809)	Data  0.001 ( 0.860)	Loss 9.8934e-02 (9.5402e-02) 
2023-05-25 21:59:19.272010: train Epoch: [23][122/129]	Time  2.657 ( 1.816)	Data  1.710 ( 0.867)	Loss 8.0029e-02 (9.5277e-02) 
2023-05-25 21:59:20.222368: train Epoch: [23][123/129]	Time  0.950 ( 1.809)	Data  0.001 ( 0.860)	Loss 1.2454e-01 (9.5513e-02) 
2023-05-25 21:59:22.879509: train Epoch: [23][124/129]	Time  2.657 ( 1.816)	Data  1.711 ( 0.867)	Loss 1.0866e-01 (9.5618e-02) 
2023-05-25 21:59:23.829873: train Epoch: [23][125/129]	Time  0.950 ( 1.809)	Data  0.001 ( 0.860)	Loss 7.7681e-02 (9.5475e-02) 
2023-05-25 21:59:26.394010: train Epoch: [23][126/129]	Time  2.564 ( 1.815)	Data  1.617 ( 0.866)	Loss 1.0727e-01 (9.5568e-02) 
2023-05-25 21:59:27.340392: train Epoch: [23][127/129]	Time  0.946 ( 1.808)	Data  0.001 ( 0.859)	Loss 8.3402e-02 (9.5473e-02) 
2023-05-25 21:59:28.833709: train Epoch: [23][128/129]	Time  1.493 ( 1.806)	Data  0.549 ( 0.857)	Loss 2.3989e-01 (9.6593e-02) 
2023-05-25 21:59:28.865633: Train Epoch done in 232.98138786599884 s 
2023-05-25 21:59:31.175064: val Epoch: [23][ 0/72]	Time  1.644 ( 1.644)	Data  1.436 ( 1.436)	Loss 5.7186e-02 (5.7186e-02) 
2023-05-25 21:59:31.300862: val Epoch: [23][ 1/72]	Time  0.126 ( 0.885)	Data  0.002 ( 0.719)	Loss 1.0525e-01 (8.1216e-02) 
2023-05-25 21:59:32.387156: val Epoch: [23][ 2/72]	Time  1.086 ( 0.952)	Data  0.960 ( 0.799)	Loss 1.7549e-01 (1.1264e-01) 
2023-05-25 21:59:32.512602: val Epoch: [23][ 3/72]	Time  0.125 ( 0.745)	Data  0.001 ( 0.599)	Loss 5.5022e-02 (9.8236e-02) 
2023-05-25 21:59:33.697417: val Epoch: [23][ 4/72]	Time  1.185 ( 0.833)	Data  1.059 ( 0.691)	Loss 3.7274e-01 (1.5314e-01) 
2023-05-25 21:59:33.823848: val Epoch: [23][ 5/72]	Time  0.126 ( 0.715)	Data  0.001 ( 0.576)	Loss 1.0801e-01 (1.4561e-01) 
2023-05-25 21:59:35.005890: val Epoch: [23][ 6/72]	Time  1.182 ( 0.782)	Data  1.057 ( 0.645)	Loss 6.1081e-02 (1.3354e-01) 
2023-05-25 21:59:35.131129: val Epoch: [23][ 7/72]	Time  0.125 ( 0.700)	Data  0.001 ( 0.564)	Loss 3.4305e-01 (1.5973e-01) 
2023-05-25 21:59:36.271144: val Epoch: [23][ 8/72]	Time  1.140 ( 0.749)	Data  1.014 ( 0.614)	Loss 4.6767e-01 (1.9394e-01) 
2023-05-25 21:59:36.396749: val Epoch: [23][ 9/72]	Time  0.126 ( 0.687)	Data  0.001 ( 0.553)	Loss 1.3335e-01 (1.8788e-01) 
2023-05-25 21:59:37.531634: val Epoch: [23][10/72]	Time  1.135 ( 0.727)	Data  1.013 ( 0.595)	Loss 7.2304e-02 (1.7738e-01) 
2023-05-25 21:59:37.652968: val Epoch: [23][11/72]	Time  0.121 ( 0.677)	Data  0.001 ( 0.545)	Loss 4.9586e-02 (1.6673e-01) 
2023-05-25 21:59:38.822000: val Epoch: [23][12/72]	Time  1.169 ( 0.715)	Data  1.044 ( 0.584)	Loss 7.1290e-02 (1.5939e-01) 
2023-05-25 21:59:38.944150: val Epoch: [23][13/72]	Time  0.122 ( 0.672)	Data  0.001 ( 0.542)	Loss 2.3523e-01 (1.6480e-01) 
2023-05-25 21:59:40.097264: val Epoch: [23][14/72]	Time  1.153 ( 0.704)	Data  1.031 ( 0.575)	Loss 6.6567e-02 (1.5825e-01) 
2023-05-25 21:59:40.222584: val Epoch: [23][15/72]	Time  0.125 ( 0.668)	Data  0.001 ( 0.539)	Loss 7.0794e-02 (1.5279e-01) 
2023-05-25 21:59:41.344688: val Epoch: [23][16/72]	Time  1.122 ( 0.695)	Data  1.001 ( 0.566)	Loss 1.1911e-01 (1.5081e-01) 
2023-05-25 21:59:41.469584: val Epoch: [23][17/72]	Time  0.125 ( 0.663)	Data  0.001 ( 0.534)	Loss 6.5969e-02 (1.4609e-01) 
2023-05-25 21:59:42.619741: val Epoch: [23][18/72]	Time  1.150 ( 0.689)	Data  1.026 ( 0.560)	Loss 2.1187e-01 (1.4956e-01) 
2023-05-25 21:59:42.744610: val Epoch: [23][19/72]	Time  0.125 ( 0.661)	Data  0.001 ( 0.532)	Loss 6.4817e-02 (1.4532e-01) 
2023-05-25 21:59:43.873884: val Epoch: [23][20/72]	Time  1.129 ( 0.683)	Data  1.005 ( 0.555)	Loss 5.2160e-01 (1.6324e-01) 
2023-05-25 21:59:43.998476: val Epoch: [23][21/72]	Time  0.125 ( 0.658)	Data  0.000 ( 0.530)	Loss 1.5136e-01 (1.6270e-01) 
2023-05-25 21:59:45.100089: val Epoch: [23][22/72]	Time  1.102 ( 0.677)	Data  0.977 ( 0.549)	Loss 1.4067e-01 (1.6174e-01) 
2023-05-25 21:59:45.224765: val Epoch: [23][23/72]	Time  0.125 ( 0.654)	Data  0.001 ( 0.526)	Loss 5.0269e-02 (1.5709e-01) 
2023-05-25 21:59:46.356441: val Epoch: [23][24/72]	Time  1.132 ( 0.673)	Data  1.007 ( 0.546)	Loss 3.3551e-01 (1.6423e-01) 
2023-05-25 21:59:46.480726: val Epoch: [23][25/72]	Time  0.124 ( 0.652)	Data  0.000 ( 0.525)	Loss 9.1889e-02 (1.6145e-01) 
2023-05-25 21:59:47.565101: val Epoch: [23][26/72]	Time  1.084 ( 0.668)	Data  0.960 ( 0.541)	Loss 4.4115e-02 (1.5710e-01) 
2023-05-25 21:59:47.690443: val Epoch: [23][27/72]	Time  0.125 ( 0.649)	Data  0.001 ( 0.521)	Loss 9.8277e-02 (1.5500e-01) 
2023-05-25 21:59:48.781187: val Epoch: [23][28/72]	Time  1.091 ( 0.664)	Data  0.966 ( 0.537)	Loss 7.6616e-02 (1.5230e-01) 
2023-05-25 21:59:48.906137: val Epoch: [23][29/72]	Time  0.125 ( 0.646)	Data  0.001 ( 0.519)	Loss 1.4384e-01 (1.5202e-01) 
2023-05-25 21:59:49.987518: val Epoch: [23][30/72]	Time  1.081 ( 0.660)	Data  0.957 ( 0.533)	Loss 4.9645e-02 (1.4872e-01) 
2023-05-25 21:59:50.112164: val Epoch: [23][31/72]	Time  0.125 ( 0.643)	Data  0.001 ( 0.516)	Loss 2.3963e-01 (1.5156e-01) 
2023-05-25 21:59:51.194341: val Epoch: [23][32/72]	Time  1.082 ( 0.656)	Data  0.958 ( 0.530)	Loss 2.9189e-01 (1.5581e-01) 
2023-05-25 21:59:51.318880: val Epoch: [23][33/72]	Time  0.125 ( 0.641)	Data  0.001 ( 0.514)	Loss 1.3826e-01 (1.5529e-01) 
2023-05-25 21:59:52.360911: val Epoch: [23][34/72]	Time  1.042 ( 0.652)	Data  0.918 ( 0.526)	Loss 6.4582e-02 (1.5270e-01) 
2023-05-25 21:59:52.485295: val Epoch: [23][35/72]	Time  0.124 ( 0.638)	Data  0.000 ( 0.511)	Loss 2.1533e-01 (1.5444e-01) 
2023-05-25 21:59:53.610552: val Epoch: [23][36/72]	Time  1.125 ( 0.651)	Data  1.001 ( 0.524)	Loss 4.1589e-01 (1.6151e-01) 
2023-05-25 21:59:53.734113: val Epoch: [23][37/72]	Time  0.124 ( 0.637)	Data  0.001 ( 0.511)	Loss 6.8756e-02 (1.5907e-01) 
2023-05-25 21:59:54.858945: val Epoch: [23][38/72]	Time  1.125 ( 0.649)	Data  1.005 ( 0.523)	Loss 1.4562e-01 (1.5872e-01) 
2023-05-25 21:59:54.978580: val Epoch: [23][39/72]	Time  0.120 ( 0.636)	Data  0.000 ( 0.510)	Loss 6.8605e-02 (1.5647e-01) 
2023-05-25 21:59:56.115652: val Epoch: [23][40/72]	Time  1.137 ( 0.648)	Data  1.017 ( 0.523)	Loss 5.8911e-02 (1.5409e-01) 
2023-05-25 21:59:56.234976: val Epoch: [23][41/72]	Time  0.119 ( 0.636)	Data  0.000 ( 0.510)	Loss 6.5980e-02 (1.5199e-01) 
2023-05-25 21:59:57.319250: val Epoch: [23][42/72]	Time  1.084 ( 0.646)	Data  0.965 ( 0.521)	Loss 1.8905e-01 (1.5285e-01) 
2023-05-25 21:59:57.438783: val Epoch: [23][43/72]	Time  0.120 ( 0.634)	Data  0.000 ( 0.509)	Loss 3.9050e-01 (1.5825e-01) 
2023-05-25 21:59:58.529091: val Epoch: [23][44/72]	Time  1.090 ( 0.644)	Data  0.970 ( 0.519)	Loss 6.4384e-02 (1.5617e-01) 
2023-05-25 21:59:58.648600: val Epoch: [23][45/72]	Time  0.120 ( 0.633)	Data  0.000 ( 0.508)	Loss 9.9599e-02 (1.5494e-01) 
2023-05-25 21:59:59.774259: val Epoch: [23][46/72]	Time  1.126 ( 0.643)	Data  1.006 ( 0.518)	Loss 1.1330e-01 (1.5405e-01) 
2023-05-25 21:59:59.893649: val Epoch: [23][47/72]	Time  0.119 ( 0.633)	Data  0.000 ( 0.508)	Loss 9.0736e-02 (1.5273e-01) 
2023-05-25 22:00:00.978512: val Epoch: [23][48/72]	Time  1.085 ( 0.642)	Data  0.966 ( 0.517)	Loss 7.3560e-02 (1.5112e-01) 
2023-05-25 22:00:01.097693: val Epoch: [23][49/72]	Time  0.119 ( 0.631)	Data  0.000 ( 0.507)	Loss 1.1707e-01 (1.5044e-01) 
2023-05-25 22:00:02.232093: val Epoch: [23][50/72]	Time  1.134 ( 0.641)	Data  1.015 ( 0.517)	Loss 1.0614e-01 (1.4957e-01) 
2023-05-25 22:00:02.351975: val Epoch: [23][51/72]	Time  0.120 ( 0.631)	Data  0.000 ( 0.507)	Loss 7.7370e-02 (1.4818e-01) 
2023-05-25 22:00:03.444221: val Epoch: [23][52/72]	Time  1.092 ( 0.640)	Data  0.973 ( 0.515)	Loss 5.6840e-02 (1.4646e-01) 
2023-05-25 22:00:03.564493: val Epoch: [23][53/72]	Time  0.120 ( 0.630)	Data  0.000 ( 0.506)	Loss 5.6710e-02 (1.4479e-01) 
2023-05-25 22:00:04.608751: val Epoch: [23][54/72]	Time  1.044 ( 0.638)	Data  0.927 ( 0.514)	Loss 4.8341e-02 (1.4304e-01) 
2023-05-25 22:00:04.728929: val Epoch: [23][55/72]	Time  0.120 ( 0.629)	Data  0.000 ( 0.504)	Loss 4.0864e-02 (1.4122e-01) 
2023-05-25 22:00:05.781465: val Epoch: [23][56/72]	Time  1.053 ( 0.636)	Data  0.933 ( 0.512)	Loss 6.7875e-02 (1.3993e-01) 
2023-05-25 22:00:05.897832: val Epoch: [23][57/72]	Time  0.116 ( 0.627)	Data  0.000 ( 0.503)	Loss 4.3066e-01 (1.4494e-01) 
2023-05-25 22:00:07.021700: val Epoch: [23][58/72]	Time  1.124 ( 0.635)	Data  1.006 ( 0.512)	Loss 2.7298e-01 (1.4711e-01) 
2023-05-25 22:00:07.141021: val Epoch: [23][59/72]	Time  0.119 ( 0.627)	Data  0.000 ( 0.503)	Loss 1.1959e-01 (1.4665e-01) 
2023-05-25 22:00:08.265371: val Epoch: [23][60/72]	Time  1.124 ( 0.635)	Data  1.004 ( 0.511)	Loss 6.0541e-02 (1.4524e-01) 
2023-05-25 22:00:08.382495: val Epoch: [23][61/72]	Time  0.117 ( 0.627)	Data  0.000 ( 0.503)	Loss 6.1631e-02 (1.4389e-01) 
2023-05-25 22:00:09.506694: val Epoch: [23][62/72]	Time  1.124 ( 0.635)	Data  1.006 ( 0.511)	Loss 1.3764e-01 (1.4379e-01) 
2023-05-25 22:00:09.626137: val Epoch: [23][63/72]	Time  0.119 ( 0.626)	Data  0.000 ( 0.503)	Loss 5.3145e-02 (1.4238e-01) 
2023-05-25 22:00:10.697114: val Epoch: [23][64/72]	Time  1.071 ( 0.633)	Data  0.953 ( 0.510)	Loss 8.4997e-02 (1.4149e-01) 
2023-05-25 22:00:10.816408: val Epoch: [23][65/72]	Time  0.119 ( 0.626)	Data  0.000 ( 0.502)	Loss 2.2976e-01 (1.4283e-01) 
2023-05-25 22:00:11.962021: val Epoch: [23][66/72]	Time  1.146 ( 0.633)	Data  1.028 ( 0.510)	Loss 8.1511e-02 (1.4192e-01) 
2023-05-25 22:00:12.081153: val Epoch: [23][67/72]	Time  0.119 ( 0.626)	Data  0.001 ( 0.503)	Loss 7.2238e-02 (1.4089e-01) 
2023-05-25 22:00:13.157891: val Epoch: [23][68/72]	Time  1.077 ( 0.632)	Data  0.960 ( 0.509)	Loss 5.4941e-02 (1.3965e-01) 
2023-05-25 22:00:13.277783: val Epoch: [23][69/72]	Time  0.120 ( 0.625)	Data  0.000 ( 0.502)	Loss 1.6134e-01 (1.3996e-01) 
2023-05-25 22:00:14.289779: val Epoch: [23][70/72]	Time  1.012 ( 0.630)	Data  0.892 ( 0.508)	Loss 2.1153e-01 (1.4096e-01) 
2023-05-25 22:00:14.406181: val Epoch: [23][71/72]	Time  0.116 ( 0.623)	Data  0.000 ( 0.500)	Loss 8.7291e-02 (1.4022e-01) 
2023-05-25 22:00:14.584400: Epoch 23 :Val : ['ET : 0.7393526434898376', 'TC : 0.7622475028038025', 'WT : 0.8497743606567383'] 
2023-05-25 22:00:14.589688: Epoch 23 :Val : ['ET : 0.7393526434898376', 'TC : 0.7622475028038025', 'WT : 0.8497743606567383'] 
2023-05-25 22:00:14.591466: Val epoch done in 45.72583626800042 s 
2023-05-25 22:00:14.596788: Batches per epoch:  129 
2023-05-25 22:00:19.368616: train Epoch: [24][  0/129]	Time  4.772 ( 4.772)	Data  3.744 ( 3.744)	Loss 7.0828e-02 (7.0828e-02) 
2023-05-25 22:00:20.333670: train Epoch: [24][  1/129]	Time  0.965 ( 2.868)	Data  0.001 ( 1.873)	Loss 9.4409e-02 (8.2619e-02) 
2023-05-25 22:00:22.984679: train Epoch: [24][  2/129]	Time  2.651 ( 2.796)	Data  1.683 ( 1.809)	Loss 7.9490e-02 (8.1576e-02) 
2023-05-25 22:00:23.946456: train Epoch: [24][  3/129]	Time  0.962 ( 2.337)	Data  0.001 ( 1.357)	Loss 1.2819e-01 (9.3228e-02) 
2023-05-25 22:00:26.648704: train Epoch: [24][  4/129]	Time  2.702 ( 2.410)	Data  1.741 ( 1.434)	Loss 8.7968e-02 (9.2176e-02) 
2023-05-25 22:00:27.604167: train Epoch: [24][  5/129]	Time  0.955 ( 2.168)	Data  0.001 ( 1.195)	Loss 1.4395e-01 (1.0081e-01) 
2023-05-25 22:00:30.474176: train Epoch: [24][  6/129]	Time  2.870 ( 2.268)	Data  1.910 ( 1.297)	Loss 7.1840e-02 (9.6668e-02) 
2023-05-25 22:00:31.426626: train Epoch: [24][  7/129]	Time  0.952 ( 2.104)	Data  0.001 ( 1.135)	Loss 9.3302e-02 (9.6247e-02) 
2023-05-25 22:00:34.020439: train Epoch: [24][  8/129]	Time  2.594 ( 2.158)	Data  1.641 ( 1.191)	Loss 1.0184e-01 (9.6868e-02) 
2023-05-25 22:00:34.983655: train Epoch: [24][  9/129]	Time  0.963 ( 2.039)	Data  0.001 ( 1.072)	Loss 6.3599e-02 (9.3541e-02) 
2023-05-25 22:00:37.632332: train Epoch: [24][ 10/129]	Time  2.649 ( 2.094)	Data  1.676 ( 1.127)	Loss 6.8389e-02 (9.1255e-02) 
2023-05-25 22:00:38.592376: train Epoch: [24][ 11/129]	Time  0.960 ( 2.000)	Data  0.001 ( 1.033)	Loss 8.7285e-02 (9.0924e-02) 
2023-05-25 22:00:41.250766: train Epoch: [24][ 12/129]	Time  2.658 ( 2.050)	Data  1.710 ( 1.085)	Loss 6.1619e-02 (8.8670e-02) 
2023-05-25 22:00:42.202054: train Epoch: [24][ 13/129]	Time  0.951 ( 1.972)	Data  0.001 ( 1.008)	Loss 5.4401e-02 (8.6222e-02) 
2023-05-25 22:00:44.913241: train Epoch: [24][ 14/129]	Time  2.711 ( 2.021)	Data  1.762 ( 1.058)	Loss 6.2626e-02 (8.4649e-02) 
2023-05-25 22:00:45.863953: train Epoch: [24][ 15/129]	Time  0.951 ( 1.954)	Data  0.001 ( 0.992)	Loss 6.1452e-02 (8.3199e-02) 
2023-05-25 22:00:48.627810: train Epoch: [24][ 16/129]	Time  2.764 ( 2.002)	Data  1.811 ( 1.040)	Loss 4.8053e-02 (8.1132e-02) 
2023-05-25 22:00:49.579505: train Epoch: [24][ 17/129]	Time  0.952 ( 1.943)	Data  0.001 ( 0.983)	Loss 9.6539e-02 (8.1988e-02) 
2023-05-25 22:00:52.233379: train Epoch: [24][ 18/129]	Time  2.654 ( 1.981)	Data  1.702 ( 1.020)	Loss 9.4754e-02 (8.2659e-02) 
2023-05-25 22:00:53.184275: train Epoch: [24][ 19/129]	Time  0.951 ( 1.929)	Data  0.001 ( 0.969)	Loss 1.3818e-01 (8.5435e-02) 
2023-05-25 22:00:55.803445: train Epoch: [24][ 20/129]	Time  2.619 ( 1.962)	Data  1.669 ( 1.003)	Loss 1.0631e-01 (8.6429e-02) 
2023-05-25 22:00:56.754894: train Epoch: [24][ 21/129]	Time  0.951 ( 1.916)	Data  0.001 ( 0.957)	Loss 6.2192e-02 (8.5328e-02) 
2023-05-25 22:00:59.313385: train Epoch: [24][ 22/129]	Time  2.558 ( 1.944)	Data  1.594 ( 0.985)	Loss 7.4492e-02 (8.4857e-02) 
2023-05-25 22:01:00.280018: train Epoch: [24][ 23/129]	Time  0.967 ( 1.903)	Data  0.001 ( 0.944)	Loss 6.3694e-02 (8.3975e-02) 
2023-05-25 22:01:02.915429: train Epoch: [24][ 24/129]	Time  2.635 ( 1.933)	Data  1.675 ( 0.973)	Loss 1.2206e-01 (8.5498e-02) 
2023-05-25 22:01:03.876359: train Epoch: [24][ 25/129]	Time  0.961 ( 1.895)	Data  0.001 ( 0.936)	Loss 5.8677e-02 (8.4467e-02) 
2023-05-25 22:01:06.483878: train Epoch: [24][ 26/129]	Time  2.608 ( 1.922)	Data  1.647 ( 0.962)	Loss 8.2476e-02 (8.4393e-02) 
2023-05-25 22:01:07.436503: train Epoch: [24][ 27/129]	Time  0.953 ( 1.887)	Data  0.001 ( 0.928)	Loss 1.0377e-01 (8.5085e-02) 
2023-05-25 22:01:10.187277: train Epoch: [24][ 28/129]	Time  2.751 ( 1.917)	Data  1.800 ( 0.958)	Loss 9.5331e-02 (8.5438e-02) 
2023-05-25 22:01:11.138930: train Epoch: [24][ 29/129]	Time  0.952 ( 1.885)	Data  0.001 ( 0.926)	Loss 9.1020e-02 (8.5624e-02) 
2023-05-25 22:01:13.815743: train Epoch: [24][ 30/129]	Time  2.677 ( 1.910)	Data  1.728 ( 0.952)	Loss 1.9512e-01 (8.9157e-02) 
2023-05-25 22:01:14.768282: train Epoch: [24][ 31/129]	Time  0.953 ( 1.880)	Data  0.001 ( 0.922)	Loss 6.5088e-02 (8.8404e-02) 
2023-05-25 22:01:17.404119: train Epoch: [24][ 32/129]	Time  2.636 ( 1.903)	Data  1.687 ( 0.945)	Loss 1.1568e-01 (8.9231e-02) 
2023-05-25 22:01:18.354708: train Epoch: [24][ 33/129]	Time  0.951 ( 1.875)	Data  0.001 ( 0.918)	Loss 6.0957e-02 (8.8399e-02) 
2023-05-25 22:01:21.073743: train Epoch: [24][ 34/129]	Time  2.719 ( 1.899)	Data  1.769 ( 0.942)	Loss 6.4378e-02 (8.7713e-02) 
2023-05-25 22:01:22.024164: train Epoch: [24][ 35/129]	Time  0.950 ( 1.873)	Data  0.001 ( 0.916)	Loss 5.5548e-02 (8.6820e-02) 
2023-05-25 22:01:24.710611: train Epoch: [24][ 36/129]	Time  2.686 ( 1.895)	Data  1.722 ( 0.938)	Loss 6.1117e-02 (8.6125e-02) 
2023-05-25 22:01:25.673709: train Epoch: [24][ 37/129]	Time  0.963 ( 1.870)	Data  0.001 ( 0.913)	Loss 5.7772e-02 (8.5379e-02) 
2023-05-25 22:01:28.248577: train Epoch: [24][ 38/129]	Time  2.575 ( 1.888)	Data  1.604 ( 0.931)	Loss 8.3095e-02 (8.5320e-02) 
2023-05-25 22:01:29.212184: train Epoch: [24][ 39/129]	Time  0.964 ( 1.865)	Data  0.001 ( 0.907)	Loss 6.0767e-02 (8.4706e-02) 
2023-05-25 22:01:31.838459: train Epoch: [24][ 40/129]	Time  2.626 ( 1.884)	Data  1.656 ( 0.926)	Loss 8.2926e-02 (8.4663e-02) 
2023-05-25 22:01:32.792682: train Epoch: [24][ 41/129]	Time  0.954 ( 1.862)	Data  0.001 ( 0.904)	Loss 8.6966e-02 (8.4718e-02) 
2023-05-25 22:01:35.439098: train Epoch: [24][ 42/129]	Time  2.646 ( 1.880)	Data  1.685 ( 0.922)	Loss 1.1240e-01 (8.5361e-02) 
2023-05-25 22:01:36.401288: train Epoch: [24][ 43/129]	Time  0.962 ( 1.859)	Data  0.001 ( 0.901)	Loss 7.0409e-02 (8.5022e-02) 
2023-05-25 22:01:39.021716: train Epoch: [24][ 44/129]	Time  2.620 ( 1.876)	Data  1.661 ( 0.918)	Loss 9.0831e-02 (8.5151e-02) 
2023-05-25 22:01:39.983999: train Epoch: [24][ 45/129]	Time  0.962 ( 1.856)	Data  0.001 ( 0.898)	Loss 7.3881e-02 (8.4906e-02) 
2023-05-25 22:01:42.747391: train Epoch: [24][ 46/129]	Time  2.763 ( 1.876)	Data  1.788 ( 0.917)	Loss 1.0633e-01 (8.5362e-02) 
2023-05-25 22:01:43.710102: train Epoch: [24][ 47/129]	Time  0.963 ( 1.857)	Data  0.001 ( 0.898)	Loss 1.1149e-01 (8.5906e-02) 
2023-05-25 22:01:46.274335: train Epoch: [24][ 48/129]	Time  2.564 ( 1.871)	Data  1.605 ( 0.912)	Loss 7.6561e-02 (8.5715e-02) 
2023-05-25 22:01:47.237273: train Epoch: [24][ 49/129]	Time  0.963 ( 1.853)	Data  0.001 ( 0.894)	Loss 1.2454e-01 (8.6492e-02) 
2023-05-25 22:01:49.961339: train Epoch: [24][ 50/129]	Time  2.724 ( 1.870)	Data  1.766 ( 0.911)	Loss 4.8619e-02 (8.5749e-02) 
2023-05-25 22:01:50.925161: train Epoch: [24][ 51/129]	Time  0.964 ( 1.852)	Data  0.001 ( 0.893)	Loss 9.1560e-02 (8.5861e-02) 
2023-05-25 22:01:53.605609: train Epoch: [24][ 52/129]	Time  2.680 ( 1.868)	Data  1.720 ( 0.909)	Loss 1.6512e-01 (8.7356e-02) 
2023-05-25 22:01:54.568483: train Epoch: [24][ 53/129]	Time  0.963 ( 1.851)	Data  0.001 ( 0.892)	Loss 6.1631e-02 (8.6880e-02) 
2023-05-25 22:01:57.169058: train Epoch: [24][ 54/129]	Time  2.601 ( 1.865)	Data  1.639 ( 0.906)	Loss 6.7550e-02 (8.6528e-02) 
2023-05-25 22:01:58.120497: train Epoch: [24][ 55/129]	Time  0.951 ( 1.849)	Data  0.001 ( 0.890)	Loss 5.8092e-02 (8.6021e-02) 
2023-05-25 22:02:00.795956: train Epoch: [24][ 56/129]	Time  2.675 ( 1.863)	Data  1.716 ( 0.904)	Loss 6.2103e-02 (8.5601e-02) 
2023-05-25 22:02:01.756418: train Epoch: [24][ 57/129]	Time  0.960 ( 1.848)	Data  0.001 ( 0.889)	Loss 1.1006e-01 (8.6023e-02) 
2023-05-25 22:02:04.420416: train Epoch: [24][ 58/129]	Time  2.664 ( 1.861)	Data  1.704 ( 0.902)	Loss 6.7766e-02 (8.5713e-02) 
2023-05-25 22:02:05.381602: train Epoch: [24][ 59/129]	Time  0.961 ( 1.846)	Data  0.001 ( 0.887)	Loss 8.1750e-02 (8.5647e-02) 
2023-05-25 22:02:08.094635: train Epoch: [24][ 60/129]	Time  2.713 ( 1.861)	Data  1.742 ( 0.901)	Loss 1.0367e-01 (8.5943e-02) 
2023-05-25 22:02:09.056192: train Epoch: [24][ 61/129]	Time  0.962 ( 1.846)	Data  0.001 ( 0.887)	Loss 1.1147e-01 (8.6355e-02) 
2023-05-25 22:02:11.683468: train Epoch: [24][ 62/129]	Time  2.627 ( 1.859)	Data  1.666 ( 0.899)	Loss 5.9942e-02 (8.5935e-02) 
2023-05-25 22:02:12.634269: train Epoch: [24][ 63/129]	Time  0.951 ( 1.844)	Data  0.001 ( 0.885)	Loss 5.7462e-02 (8.5490e-02) 
2023-05-25 22:02:15.289171: train Epoch: [24][ 64/129]	Time  2.655 ( 1.857)	Data  1.698 ( 0.898)	Loss 1.6713e-01 (8.6746e-02) 
2023-05-25 22:02:16.251094: train Epoch: [24][ 65/129]	Time  0.962 ( 1.843)	Data  0.001 ( 0.884)	Loss 9.7074e-02 (8.6903e-02) 
2023-05-25 22:02:18.818435: train Epoch: [24][ 66/129]	Time  2.567 ( 1.854)	Data  1.608 ( 0.895)	Loss 1.1622e-01 (8.7340e-02) 
2023-05-25 22:02:19.779304: train Epoch: [24][ 67/129]	Time  0.961 ( 1.841)	Data  0.001 ( 0.882)	Loss 1.3071e-01 (8.7978e-02) 
2023-05-25 22:02:22.527395: train Epoch: [24][ 68/129]	Time  2.748 ( 1.854)	Data  1.778 ( 0.895)	Loss 7.3789e-02 (8.7772e-02) 
2023-05-25 22:02:23.478627: train Epoch: [24][ 69/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.882)	Loss 9.7914e-02 (8.7917e-02) 
2023-05-25 22:02:26.166806: train Epoch: [24][ 70/129]	Time  2.688 ( 1.853)	Data  1.726 ( 0.894)	Loss 8.9109e-02 (8.7934e-02) 
2023-05-25 22:02:27.116666: train Epoch: [24][ 71/129]	Time  0.950 ( 1.841)	Data  0.001 ( 0.881)	Loss 8.1704e-02 (8.7848e-02) 
2023-05-25 22:02:29.769667: train Epoch: [24][ 72/129]	Time  2.653 ( 1.852)	Data  1.696 ( 0.893)	Loss 9.7384e-02 (8.7978e-02) 
2023-05-25 22:02:30.738747: train Epoch: [24][ 73/129]	Time  0.969 ( 1.840)	Data  0.001 ( 0.881)	Loss 8.8303e-02 (8.7983e-02) 
2023-05-25 22:02:33.397338: train Epoch: [24][ 74/129]	Time  2.659 ( 1.851)	Data  1.688 ( 0.891)	Loss 1.1770e-01 (8.8379e-02) 
2023-05-25 22:02:34.358482: train Epoch: [24][ 75/129]	Time  0.961 ( 1.839)	Data  0.001 ( 0.880)	Loss 7.0680e-02 (8.8146e-02) 
2023-05-25 22:02:37.092640: train Epoch: [24][ 76/129]	Time  2.734 ( 1.851)	Data  1.771 ( 0.891)	Loss 1.1114e-01 (8.8445e-02) 
2023-05-25 22:02:38.043688: train Epoch: [24][ 77/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.880)	Loss 7.5825e-02 (8.8283e-02) 
2023-05-25 22:02:40.587761: train Epoch: [24][ 78/129]	Time  2.544 ( 1.848)	Data  1.593 ( 0.889)	Loss 4.5866e-02 (8.7746e-02) 
2023-05-25 22:02:41.539220: train Epoch: [24][ 79/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.878)	Loss 1.1063e-01 (8.8032e-02) 
2023-05-25 22:02:44.312286: train Epoch: [24][ 80/129]	Time  2.773 ( 1.848)	Data  1.826 ( 0.889)	Loss 1.2570e-01 (8.8497e-02) 
2023-05-25 22:02:45.262207: train Epoch: [24][ 81/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.879)	Loss 7.7650e-02 (8.8365e-02) 
2023-05-25 22:02:47.935500: train Epoch: [24][ 82/129]	Time  2.673 ( 1.847)	Data  1.712 ( 0.889)	Loss 7.4622e-02 (8.8199e-02) 
2023-05-25 22:02:48.885756: train Epoch: [24][ 83/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.878)	Loss 7.3645e-02 (8.8026e-02) 
2023-05-25 22:02:51.426069: train Epoch: [24][ 84/129]	Time  2.540 ( 1.845)	Data  1.590 ( 0.886)	Loss 8.5955e-02 (8.8001e-02) 
2023-05-25 22:02:52.374519: train Epoch: [24][ 85/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.876)	Loss 7.5172e-02 (8.7852e-02) 
2023-05-25 22:02:55.034064: train Epoch: [24][ 86/129]	Time  2.660 ( 1.844)	Data  1.705 ( 0.886)	Loss 7.4375e-02 (8.7697e-02) 
2023-05-25 22:02:55.983605: train Epoch: [24][ 87/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.876)	Loss 6.3888e-02 (8.7427e-02) 
2023-05-25 22:02:58.585903: train Epoch: [24][ 88/129]	Time  2.602 ( 1.843)	Data  1.651 ( 0.884)	Loss 1.4973e-01 (8.8127e-02) 
2023-05-25 22:02:59.535461: train Epoch: [24][ 89/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.875)	Loss 9.3613e-02 (8.8188e-02) 
2023-05-25 22:03:02.197779: train Epoch: [24][ 90/129]	Time  2.662 ( 1.842)	Data  1.702 ( 0.884)	Loss 1.6124e-01 (8.8991e-02) 
2023-05-25 22:03:03.162660: train Epoch: [24][ 91/129]	Time  0.965 ( 1.832)	Data  0.001 ( 0.874)	Loss 5.8109e-02 (8.8655e-02) 
2023-05-25 22:03:05.919603: train Epoch: [24][ 92/129]	Time  2.757 ( 1.842)	Data  1.794 ( 0.884)	Loss 7.3837e-02 (8.8496e-02) 
2023-05-25 22:03:06.873811: train Epoch: [24][ 93/129]	Time  0.954 ( 1.833)	Data  0.001 ( 0.875)	Loss 9.4708e-02 (8.8562e-02) 
2023-05-25 22:03:09.647672: train Epoch: [24][ 94/129]	Time  2.774 ( 1.843)	Data  1.815 ( 0.884)	Loss 1.0953e-01 (8.8782e-02) 
2023-05-25 22:03:10.598881: train Epoch: [24][ 95/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.875)	Loss 7.5044e-02 (8.8639e-02) 
2023-05-25 22:03:13.365421: train Epoch: [24][ 96/129]	Time  2.767 ( 1.843)	Data  1.816 ( 0.885)	Loss 6.5554e-02 (8.8401e-02) 
2023-05-25 22:03:14.316582: train Epoch: [24][ 97/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.876)	Loss 1.2174e-01 (8.8741e-02) 
2023-05-25 22:03:16.937700: train Epoch: [24][ 98/129]	Time  2.621 ( 1.842)	Data  1.668 ( 0.884)	Loss 6.2878e-02 (8.8480e-02) 
2023-05-25 22:03:17.889436: train Epoch: [24][ 99/129]	Time  0.952 ( 1.833)	Data  0.001 ( 0.875)	Loss 1.1232e-01 (8.8719e-02) 
2023-05-25 22:03:20.580276: train Epoch: [24][100/129]	Time  2.691 ( 1.841)	Data  1.739 ( 0.884)	Loss 7.8396e-02 (8.8616e-02) 
2023-05-25 22:03:21.533099: train Epoch: [24][101/129]	Time  0.953 ( 1.833)	Data  0.001 ( 0.875)	Loss 5.7556e-02 (8.8312e-02) 
2023-05-25 22:03:24.199989: train Epoch: [24][102/129]	Time  2.667 ( 1.841)	Data  1.706 ( 0.883)	Loss 1.2106e-01 (8.8630e-02) 
2023-05-25 22:03:25.152104: train Epoch: [24][103/129]	Time  0.952 ( 1.832)	Data  0.001 ( 0.875)	Loss 1.0468e-01 (8.8784e-02) 
2023-05-25 22:03:27.905709: train Epoch: [24][104/129]	Time  2.754 ( 1.841)	Data  1.795 ( 0.883)	Loss 5.6661e-02 (8.8478e-02) 
2023-05-25 22:03:28.868630: train Epoch: [24][105/129]	Time  0.963 ( 1.833)	Data  0.001 ( 0.875)	Loss 8.4312e-02 (8.8439e-02) 
2023-05-25 22:03:31.617414: train Epoch: [24][106/129]	Time  2.749 ( 1.841)	Data  1.787 ( 0.884)	Loss 1.1497e-01 (8.8687e-02) 
2023-05-25 22:03:32.581357: train Epoch: [24][107/129]	Time  0.964 ( 1.833)	Data  0.001 ( 0.875)	Loss 1.2190e-01 (8.8994e-02) 
2023-05-25 22:03:35.310391: train Epoch: [24][108/129]	Time  2.729 ( 1.841)	Data  1.761 ( 0.883)	Loss 1.1563e-01 (8.9239e-02) 
2023-05-25 22:03:36.275779: train Epoch: [24][109/129]	Time  0.965 ( 1.833)	Data  0.001 ( 0.875)	Loss 1.4148e-01 (8.9714e-02) 
2023-05-25 22:03:39.089423: train Epoch: [24][110/129]	Time  2.814 ( 1.842)	Data  1.842 ( 0.884)	Loss 1.5102e-01 (9.0266e-02) 
2023-05-25 22:03:40.054892: train Epoch: [24][111/129]	Time  0.965 ( 1.834)	Data  0.001 ( 0.876)	Loss 7.7580e-02 (9.0153e-02) 
2023-05-25 22:03:42.788672: train Epoch: [24][112/129]	Time  2.734 ( 1.842)	Data  1.766 ( 0.884)	Loss 8.4783e-02 (9.0105e-02) 
2023-05-25 22:03:43.754088: train Epoch: [24][113/129]	Time  0.965 ( 1.835)	Data  0.001 ( 0.876)	Loss 1.8741e-01 (9.0959e-02) 
2023-05-25 22:03:46.415639: train Epoch: [24][114/129]	Time  2.662 ( 1.842)	Data  1.706 ( 0.884)	Loss 1.2208e-01 (9.1229e-02) 
2023-05-25 22:03:47.368321: train Epoch: [24][115/129]	Time  0.953 ( 1.834)	Data  0.001 ( 0.876)	Loss 9.0874e-02 (9.1226e-02) 
2023-05-25 22:03:50.012586: train Epoch: [24][116/129]	Time  2.644 ( 1.841)	Data  1.694 ( 0.883)	Loss 8.9261e-02 (9.1210e-02) 
2023-05-25 22:03:50.964142: train Epoch: [24][117/129]	Time  0.952 ( 1.834)	Data  0.001 ( 0.876)	Loss 8.2389e-02 (9.1135e-02) 
2023-05-25 22:03:53.689713: train Epoch: [24][118/129]	Time  2.726 ( 1.841)	Data  1.776 ( 0.883)	Loss 7.7034e-02 (9.1016e-02) 
2023-05-25 22:03:54.642510: train Epoch: [24][119/129]	Time  0.953 ( 1.834)	Data  0.001 ( 0.876)	Loss 6.7773e-02 (9.0823e-02) 
2023-05-25 22:03:57.374500: train Epoch: [24][120/129]	Time  2.732 ( 1.841)	Data  1.781 ( 0.883)	Loss 4.9901e-02 (9.0484e-02) 
2023-05-25 22:03:58.327067: train Epoch: [24][121/129]	Time  0.953 ( 1.834)	Data  0.001 ( 0.876)	Loss 7.3889e-02 (9.0348e-02) 
2023-05-25 22:04:01.102085: train Epoch: [24][122/129]	Time  2.775 ( 1.842)	Data  1.812 ( 0.884)	Loss 6.4125e-02 (9.0135e-02) 
2023-05-25 22:04:02.055509: train Epoch: [24][123/129]	Time  0.953 ( 1.834)	Data  0.001 ( 0.876)	Loss 9.5127e-02 (9.0175e-02) 
2023-05-25 22:04:04.986931: train Epoch: [24][124/129]	Time  2.931 ( 1.843)	Data  1.983 ( 0.885)	Loss 9.7408e-02 (9.0233e-02) 
2023-05-25 22:04:05.936186: train Epoch: [24][125/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.878)	Loss 8.0264e-02 (9.0154e-02) 
2023-05-25 22:04:08.666550: train Epoch: [24][126/129]	Time  2.730 ( 1.843)	Data  1.778 ( 0.885)	Loss 8.2855e-02 (9.0097e-02) 
2023-05-25 22:04:09.614379: train Epoch: [24][127/129]	Time  0.948 ( 1.836)	Data  0.001 ( 0.879)	Loss 6.1701e-02 (8.9875e-02) 
2023-05-25 22:04:11.109087: train Epoch: [24][128/129]	Time  1.495 ( 1.833)	Data  0.546 ( 0.876)	Loss 6.8811e-02 (8.9712e-02) 
2023-05-25 22:04:11.139631: Train Epoch done in 236.54287396600012 s 
2023-05-25 22:04:13.372442: val Epoch: [24][ 0/72]	Time  1.525 ( 1.525)	Data  1.347 ( 1.347)	Loss 3.7005e-02 (3.7005e-02) 
2023-05-25 22:04:13.493246: val Epoch: [24][ 1/72]	Time  0.121 ( 0.823)	Data  0.001 ( 0.674)	Loss 2.9977e-01 (1.6839e-01) 
2023-05-25 22:04:14.439048: val Epoch: [24][ 2/72]	Time  0.946 ( 0.864)	Data  0.825 ( 0.724)	Loss 4.6904e-02 (1.2789e-01) 
2023-05-25 22:04:14.597457: val Epoch: [24][ 3/72]	Time  0.158 ( 0.687)	Data  0.038 ( 0.553)	Loss 3.3521e-01 (1.7972e-01) 
2023-05-25 22:04:15.635796: val Epoch: [24][ 4/72]	Time  1.038 ( 0.758)	Data  0.917 ( 0.626)	Loss 1.1571e-01 (1.6692e-01) 
2023-05-25 22:04:15.825455: val Epoch: [24][ 5/72]	Time  0.190 ( 0.663)	Data  0.064 ( 0.532)	Loss 9.8244e-02 (1.5547e-01) 
2023-05-25 22:04:16.858518: val Epoch: [24][ 6/72]	Time  1.033 ( 0.716)	Data  0.907 ( 0.586)	Loss 2.0418e-01 (1.6243e-01) 
2023-05-25 22:04:17.042924: val Epoch: [24][ 7/72]	Time  0.184 ( 0.649)	Data  0.059 ( 0.520)	Loss 6.7860e-02 (1.5061e-01) 
2023-05-25 22:04:18.118280: val Epoch: [24][ 8/72]	Time  1.075 ( 0.697)	Data  0.947 ( 0.567)	Loss 1.3556e-01 (1.4894e-01) 
2023-05-25 22:04:18.250067: val Epoch: [24][ 9/72]	Time  0.132 ( 0.640)	Data  0.012 ( 0.512)	Loss 1.4656e-01 (1.4870e-01) 
2023-05-25 22:04:19.374171: val Epoch: [24][10/72]	Time  1.124 ( 0.684)	Data  0.993 ( 0.556)	Loss 1.0015e-01 (1.4429e-01) 
2023-05-25 22:04:19.500134: val Epoch: [24][11/72]	Time  0.126 ( 0.638)	Data  0.001 ( 0.509)	Loss 4.1806e-02 (1.3575e-01) 
2023-05-25 22:04:20.652206: val Epoch: [24][12/72]	Time  1.152 ( 0.677)	Data  1.026 ( 0.549)	Loss 5.4464e-01 (1.6720e-01) 
2023-05-25 22:04:20.779142: val Epoch: [24][13/72]	Time  0.127 ( 0.638)	Data  0.001 ( 0.510)	Loss 4.4630e-02 (1.5844e-01) 
2023-05-25 22:04:21.872913: val Epoch: [24][14/72]	Time  1.094 ( 0.668)	Data  0.971 ( 0.541)	Loss 3.0843e-01 (1.6844e-01) 
2023-05-25 22:04:22.039742: val Epoch: [24][15/72]	Time  0.167 ( 0.637)	Data  0.041 ( 0.509)	Loss 6.3271e-02 (1.6187e-01) 
2023-05-25 22:04:23.092743: val Epoch: [24][16/72]	Time  1.053 ( 0.661)	Data  0.931 ( 0.534)	Loss 1.4789e-01 (1.6105e-01) 
2023-05-25 22:04:23.311471: val Epoch: [24][17/72]	Time  0.219 ( 0.637)	Data  0.094 ( 0.510)	Loss 7.0787e-02 (1.5603e-01) 
2023-05-25 22:04:24.349737: val Epoch: [24][18/72]	Time  1.038 ( 0.658)	Data  0.916 ( 0.531)	Loss 1.8632e-01 (1.5763e-01) 
2023-05-25 22:04:24.487188: val Epoch: [24][19/72]	Time  0.137 ( 0.632)	Data  0.016 ( 0.505)	Loss 9.5906e-02 (1.5454e-01) 
2023-05-25 22:04:25.632259: val Epoch: [24][20/72]	Time  1.145 ( 0.656)	Data  1.016 ( 0.530)	Loss 9.6281e-02 (1.5177e-01) 
2023-05-25 22:04:25.757426: val Epoch: [24][21/72]	Time  0.125 ( 0.632)	Data  0.001 ( 0.506)	Loss 5.5842e-01 (1.7025e-01) 
2023-05-25 22:04:26.825810: val Epoch: [24][22/72]	Time  1.068 ( 0.651)	Data  0.946 ( 0.525)	Loss 5.4161e-02 (1.6520e-01) 
2023-05-25 22:04:26.999943: val Epoch: [24][23/72]	Time  0.174 ( 0.631)	Data  0.048 ( 0.505)	Loss 8.7949e-02 (1.6199e-01) 
2023-05-25 22:04:28.049533: val Epoch: [24][24/72]	Time  1.050 ( 0.648)	Data  0.927 ( 0.522)	Loss 4.1566e-01 (1.7213e-01) 
2023-05-25 22:04:28.206680: val Epoch: [24][25/72]	Time  0.157 ( 0.629)	Data  0.033 ( 0.503)	Loss 6.2287e-02 (1.6791e-01) 
2023-05-25 22:04:29.247910: val Epoch: [24][26/72]	Time  1.041 ( 0.644)	Data  0.918 ( 0.518)	Loss 8.2732e-02 (1.6475e-01) 
2023-05-25 22:04:29.419996: val Epoch: [24][27/72]	Time  0.172 ( 0.628)	Data  0.051 ( 0.502)	Loss 4.4096e-02 (1.6044e-01) 
2023-05-25 22:04:30.462249: val Epoch: [24][28/72]	Time  1.042 ( 0.642)	Data  0.920 ( 0.516)	Loss 2.9050e-01 (1.6493e-01) 
2023-05-25 22:04:30.613847: val Epoch: [24][29/72]	Time  0.152 ( 0.626)	Data  0.027 ( 0.500)	Loss 4.5402e-02 (1.6094e-01) 
2023-05-25 22:04:31.687368: val Epoch: [24][30/72]	Time  1.074 ( 0.640)	Data  0.951 ( 0.514)	Loss 5.6096e-02 (1.5756e-01) 
2023-05-25 22:04:31.847395: val Epoch: [24][31/72]	Time  0.160 ( 0.625)	Data  0.038 ( 0.500)	Loss 4.4244e-01 (1.6646e-01) 
2023-05-25 22:04:32.878908: val Epoch: [24][32/72]	Time  1.032 ( 0.637)	Data  0.909 ( 0.512)	Loss 1.0607e-01 (1.6463e-01) 
2023-05-25 22:04:33.058709: val Epoch: [24][33/72]	Time  0.180 ( 0.624)	Data  0.058 ( 0.499)	Loss 5.4240e-02 (1.6139e-01) 
2023-05-25 22:04:34.110491: val Epoch: [24][34/72]	Time  1.052 ( 0.636)	Data  0.929 ( 0.511)	Loss 7.3705e-02 (1.5888e-01) 
2023-05-25 22:04:34.281072: val Epoch: [24][35/72]	Time  0.171 ( 0.623)	Data  0.046 ( 0.498)	Loss 4.2376e-02 (1.5565e-01) 
2023-05-25 22:04:35.366084: val Epoch: [24][36/72]	Time  1.085 ( 0.636)	Data  0.962 ( 0.511)	Loss 9.8688e-02 (1.5411e-01) 
2023-05-25 22:04:35.527904: val Epoch: [24][37/72]	Time  0.162 ( 0.623)	Data  0.037 ( 0.498)	Loss 1.5562e-01 (1.5415e-01) 
2023-05-25 22:04:36.587844: val Epoch: [24][38/72]	Time  1.060 ( 0.634)	Data  0.934 ( 0.509)	Loss 4.5683e-02 (1.5137e-01) 
2023-05-25 22:04:36.748335: val Epoch: [24][39/72]	Time  0.160 ( 0.623)	Data  0.036 ( 0.497)	Loss 6.1344e-02 (1.4911e-01) 
2023-05-25 22:04:37.750453: val Epoch: [24][40/72]	Time  1.002 ( 0.632)	Data  0.880 ( 0.507)	Loss 7.6702e-02 (1.4735e-01) 
2023-05-25 22:04:37.952175: val Epoch: [24][41/72]	Time  0.202 ( 0.622)	Data  0.077 ( 0.497)	Loss 2.2550e-01 (1.4921e-01) 
2023-05-25 22:04:38.999194: val Epoch: [24][42/72]	Time  1.047 ( 0.631)	Data  0.921 ( 0.506)	Loss 3.8858e-01 (1.5478e-01) 
2023-05-25 22:04:39.165961: val Epoch: [24][43/72]	Time  0.167 ( 0.621)	Data  0.042 ( 0.496)	Loss 5.3387e-02 (1.5247e-01) 
2023-05-25 22:04:40.248759: val Epoch: [24][44/72]	Time  1.083 ( 0.631)	Data  0.956 ( 0.506)	Loss 1.2052e-01 (1.5176e-01) 
2023-05-25 22:04:40.370579: val Epoch: [24][45/72]	Time  0.122 ( 0.620)	Data  0.001 ( 0.495)	Loss 5.4894e-02 (1.4966e-01) 
2023-05-25 22:04:41.430513: val Epoch: [24][46/72]	Time  1.060 ( 0.629)	Data  0.938 ( 0.504)	Loss 6.9574e-02 (1.4795e-01) 
2023-05-25 22:04:41.626021: val Epoch: [24][47/72]	Time  0.196 ( 0.620)	Data  0.074 ( 0.496)	Loss 2.7279e-01 (1.5055e-01) 
2023-05-25 22:04:42.598630: val Epoch: [24][48/72]	Time  0.973 ( 0.628)	Data  0.847 ( 0.503)	Loss 4.5515e-02 (1.4841e-01) 
2023-05-25 22:04:42.849708: val Epoch: [24][49/72]	Time  0.251 ( 0.620)	Data  0.130 ( 0.495)	Loss 2.1664e-01 (1.4977e-01) 
2023-05-25 22:04:43.791023: val Epoch: [24][50/72]	Time  0.941 ( 0.626)	Data  0.816 ( 0.502)	Loss 6.3484e-02 (1.4808e-01) 
2023-05-25 22:04:44.076413: val Epoch: [24][51/72]	Time  0.285 ( 0.620)	Data  0.162 ( 0.495)	Loss 9.1315e-02 (1.4699e-01) 
2023-05-25 22:04:45.074301: val Epoch: [24][52/72]	Time  0.998 ( 0.627)	Data  0.873 ( 0.502)	Loss 8.0274e-02 (1.4573e-01) 
2023-05-25 22:04:45.287678: val Epoch: [24][53/72]	Time  0.213 ( 0.619)	Data  0.090 ( 0.494)	Loss 5.8044e-02 (1.4411e-01) 
2023-05-25 22:04:46.326433: val Epoch: [24][54/72]	Time  1.039 ( 0.627)	Data  0.917 ( 0.502)	Loss 5.7116e-02 (1.4253e-01) 
2023-05-25 22:04:46.481192: val Epoch: [24][55/72]	Time  0.155 ( 0.618)	Data  0.039 ( 0.494)	Loss 6.3147e-02 (1.4111e-01) 
2023-05-25 22:04:47.535505: val Epoch: [24][56/72]	Time  1.054 ( 0.626)	Data  0.936 ( 0.502)	Loss 6.2484e-02 (1.3973e-01) 
2023-05-25 22:04:47.735362: val Epoch: [24][57/72]	Time  0.200 ( 0.619)	Data  0.084 ( 0.494)	Loss 1.0185e-01 (1.3908e-01) 
2023-05-25 22:04:48.770068: val Epoch: [24][58/72]	Time  1.035 ( 0.626)	Data  0.910 ( 0.501)	Loss 1.4260e-01 (1.3914e-01) 
2023-05-25 22:04:48.953424: val Epoch: [24][59/72]	Time  0.183 ( 0.618)	Data  0.059 ( 0.494)	Loss 7.1300e-02 (1.3800e-01) 
2023-05-25 22:04:49.966545: val Epoch: [24][60/72]	Time  1.013 ( 0.625)	Data  0.887 ( 0.501)	Loss 1.3137e-01 (1.3790e-01) 
2023-05-25 22:04:50.211343: val Epoch: [24][61/72]	Time  0.245 ( 0.619)	Data  0.120 ( 0.494)	Loss 3.8540e-01 (1.4189e-01) 
2023-05-25 22:04:51.180276: val Epoch: [24][62/72]	Time  0.969 ( 0.624)	Data  0.846 ( 0.500)	Loss 6.2311e-02 (1.4063e-01) 
2023-05-25 22:04:51.447095: val Epoch: [24][63/72]	Time  0.267 ( 0.619)	Data  0.145 ( 0.494)	Loss 1.5007e-01 (1.4077e-01) 
2023-05-25 22:04:52.445817: val Epoch: [24][64/72]	Time  0.999 ( 0.625)	Data  0.877 ( 0.500)	Loss 1.0618e-01 (1.4024e-01) 
2023-05-25 22:04:52.636737: val Epoch: [24][65/72]	Time  0.191 ( 0.618)	Data  0.067 ( 0.494)	Loss 5.1352e-02 (1.3889e-01) 
2023-05-25 22:04:53.695081: val Epoch: [24][66/72]	Time  1.058 ( 0.625)	Data  0.932 ( 0.500)	Loss 1.1153e-01 (1.3849e-01) 
2023-05-25 22:04:53.882715: val Epoch: [24][67/72]	Time  0.188 ( 0.618)	Data  0.063 ( 0.494)	Loss 1.4502e-01 (1.3858e-01) 
2023-05-25 22:04:54.890501: val Epoch: [24][68/72]	Time  1.008 ( 0.624)	Data  0.885 ( 0.500)	Loss 1.3130e-01 (1.3848e-01) 
2023-05-25 22:04:55.107322: val Epoch: [24][69/72]	Time  0.217 ( 0.618)	Data  0.093 ( 0.494)	Loss 1.8935e-01 (1.3920e-01) 
2023-05-25 22:04:56.109644: val Epoch: [24][70/72]	Time  1.002 ( 0.623)	Data  0.877 ( 0.499)	Loss 1.3608e-01 (1.3916e-01) 
2023-05-25 22:04:56.247083: val Epoch: [24][71/72]	Time  0.137 ( 0.617)	Data  0.014 ( 0.492)	Loss 1.3309e-01 (1.3907e-01) 
2023-05-25 22:04:56.428166: Epoch 24 :Val : ['ET : 0.7391865849494934', 'TC : 0.7659819722175598', 'WT : 0.8521668910980225'] 
2023-05-25 22:04:56.430925: Epoch 24 :Val : ['ET : 0.7391865849494934', 'TC : 0.7659819722175598', 'WT : 0.8521668910980225'] 
2023-05-25 22:04:56.432839: Val epoch done in 45.29321263699967 s 
2023-05-25 22:04:56.438262: Batches per epoch:  129 
2023-05-25 22:05:01.206734: train Epoch: [25][  0/129]	Time  4.764 ( 4.764)	Data  3.760 ( 3.760)	Loss 3.3960e-02 (3.3960e-02) 
2023-05-25 22:05:02.167238: train Epoch: [25][  1/129]	Time  0.961 ( 2.862)	Data  0.001 ( 1.881)	Loss 6.7932e-02 (5.0946e-02) 
2023-05-25 22:05:04.949745: train Epoch: [25][  2/129]	Time  2.783 ( 2.836)	Data  1.825 ( 1.862)	Loss 7.1089e-02 (5.7661e-02) 
2023-05-25 22:05:05.909927: train Epoch: [25][  3/129]	Time  0.960 ( 2.367)	Data  0.001 ( 1.397)	Loss 1.1911e-01 (7.3023e-02) 
2023-05-25 22:05:08.561160: train Epoch: [25][  4/129]	Time  2.651 ( 2.424)	Data  1.691 ( 1.456)	Loss 9.1590e-02 (7.6736e-02) 
2023-05-25 22:05:09.522666: train Epoch: [25][  5/129]	Time  0.961 ( 2.180)	Data  0.001 ( 1.213)	Loss 1.0808e-01 (8.1961e-02) 
2023-05-25 22:05:12.181199: train Epoch: [25][  6/129]	Time  2.659 ( 2.248)	Data  1.712 ( 1.284)	Loss 1.0301e-01 (8.4967e-02) 
2023-05-25 22:05:13.131261: train Epoch: [25][  7/129]	Time  0.950 ( 2.086)	Data  0.001 ( 1.124)	Loss 7.2292e-02 (8.3383e-02) 
2023-05-25 22:05:15.774702: train Epoch: [25][  8/129]	Time  2.643 ( 2.148)	Data  1.698 ( 1.188)	Loss 1.0757e-01 (8.6070e-02) 
2023-05-25 22:05:16.725525: train Epoch: [25][  9/129]	Time  0.951 ( 2.028)	Data  0.001 ( 1.069)	Loss 9.4410e-02 (8.6904e-02) 
2023-05-25 22:05:19.338950: train Epoch: [25][ 10/129]	Time  2.613 ( 2.081)	Data  1.666 ( 1.123)	Loss 1.0930e-01 (8.8940e-02) 
2023-05-25 22:05:20.287723: train Epoch: [25][ 11/129]	Time  0.949 ( 1.987)	Data  0.001 ( 1.030)	Loss 8.8122e-02 (8.8872e-02) 
2023-05-25 22:05:23.006343: train Epoch: [25][ 12/129]	Time  2.719 ( 2.043)	Data  1.771 ( 1.087)	Loss 7.0874e-02 (8.7488e-02) 
2023-05-25 22:05:23.955825: train Epoch: [25][ 13/129]	Time  0.949 ( 1.965)	Data  0.001 ( 1.009)	Loss 6.5780e-02 (8.5937e-02) 
2023-05-25 22:05:26.621411: train Epoch: [25][ 14/129]	Time  2.666 ( 2.012)	Data  1.719 ( 1.057)	Loss 8.8634e-02 (8.6117e-02) 
2023-05-25 22:05:27.571805: train Epoch: [25][ 15/129]	Time  0.950 ( 1.946)	Data  0.001 ( 0.991)	Loss 6.8850e-02 (8.5038e-02) 
2023-05-25 22:05:30.228668: train Epoch: [25][ 16/129]	Time  2.657 ( 1.987)	Data  1.711 ( 1.033)	Loss 2.0605e-01 (9.2156e-02) 
2023-05-25 22:05:31.177076: train Epoch: [25][ 17/129]	Time  0.948 ( 1.930)	Data  0.001 ( 0.976)	Loss 6.8147e-02 (9.0822e-02) 
2023-05-25 22:05:33.852626: train Epoch: [25][ 18/129]	Time  2.676 ( 1.969)	Data  1.727 ( 1.015)	Loss 8.5688e-02 (9.0552e-02) 
2023-05-25 22:05:34.802953: train Epoch: [25][ 19/129]	Time  0.950 ( 1.918)	Data  0.001 ( 0.964)	Loss 5.8761e-02 (8.8962e-02) 
2023-05-25 22:05:37.485026: train Epoch: [25][ 20/129]	Time  2.682 ( 1.954)	Data  1.736 ( 1.001)	Loss 9.2021e-02 (8.9108e-02) 
2023-05-25 22:05:38.433775: train Epoch: [25][ 21/129]	Time  0.949 ( 1.909)	Data  0.001 ( 0.956)	Loss 1.8920e-01 (9.3658e-02) 
2023-05-25 22:05:41.113707: train Epoch: [25][ 22/129]	Time  2.680 ( 1.942)	Data  1.733 ( 0.990)	Loss 6.9227e-02 (9.2596e-02) 
2023-05-25 22:05:42.063877: train Epoch: [25][ 23/129]	Time  0.950 ( 1.901)	Data  0.001 ( 0.948)	Loss 6.1788e-02 (9.1312e-02) 
2023-05-25 22:05:44.667306: train Epoch: [25][ 24/129]	Time  2.603 ( 1.929)	Data  1.656 ( 0.977)	Loss 8.6783e-02 (9.1131e-02) 
2023-05-25 22:05:45.618459: train Epoch: [25][ 25/129]	Time  0.951 ( 1.891)	Data  0.001 ( 0.939)	Loss 6.2407e-02 (9.0026e-02) 
2023-05-25 22:05:48.214550: train Epoch: [25][ 26/129]	Time  2.596 ( 1.917)	Data  1.649 ( 0.965)	Loss 9.2478e-02 (9.0117e-02) 
2023-05-25 22:05:49.165125: train Epoch: [25][ 27/129]	Time  0.951 ( 1.883)	Data  0.001 ( 0.931)	Loss 8.9809e-02 (9.0106e-02) 
2023-05-25 22:05:51.872353: train Epoch: [25][ 28/129]	Time  2.707 ( 1.911)	Data  1.760 ( 0.960)	Loss 1.6579e-01 (9.2716e-02) 
2023-05-25 22:05:52.823378: train Epoch: [25][ 29/129]	Time  0.951 ( 1.879)	Data  0.001 ( 0.928)	Loss 9.3603e-02 (9.2745e-02) 
2023-05-25 22:05:55.462862: train Epoch: [25][ 30/129]	Time  2.639 ( 1.904)	Data  1.695 ( 0.952)	Loss 1.2974e-01 (9.3939e-02) 
2023-05-25 22:05:56.411720: train Epoch: [25][ 31/129]	Time  0.949 ( 1.874)	Data  0.001 ( 0.923)	Loss 5.7048e-02 (9.2786e-02) 
2023-05-25 22:05:59.065910: train Epoch: [25][ 32/129]	Time  2.654 ( 1.898)	Data  1.708 ( 0.946)	Loss 1.2049e-01 (9.3625e-02) 
2023-05-25 22:06:00.018216: train Epoch: [25][ 33/129]	Time  0.952 ( 1.870)	Data  0.001 ( 0.919)	Loss 1.0330e-01 (9.3910e-02) 
2023-05-25 22:06:02.773502: train Epoch: [25][ 34/129]	Time  2.755 ( 1.895)	Data  1.808 ( 0.944)	Loss 7.2673e-02 (9.3303e-02) 
2023-05-25 22:06:03.723455: train Epoch: [25][ 35/129]	Time  0.950 ( 1.869)	Data  0.001 ( 0.918)	Loss 8.3248e-02 (9.3024e-02) 
2023-05-25 22:06:06.464646: train Epoch: [25][ 36/129]	Time  2.741 ( 1.892)	Data  1.795 ( 0.942)	Loss 7.7296e-02 (9.2599e-02) 
2023-05-25 22:06:07.414659: train Epoch: [25][ 37/129]	Time  0.950 ( 1.868)	Data  0.001 ( 0.917)	Loss 7.0722e-02 (9.2023e-02) 
2023-05-25 22:06:10.075048: train Epoch: [25][ 38/129]	Time  2.660 ( 1.888)	Data  1.714 ( 0.937)	Loss 1.1128e-01 (9.2517e-02) 
2023-05-25 22:06:11.026645: train Epoch: [25][ 39/129]	Time  0.952 ( 1.865)	Data  0.001 ( 0.914)	Loss 9.0092e-02 (9.2456e-02) 
2023-05-25 22:06:13.688754: train Epoch: [25][ 40/129]	Time  2.662 ( 1.884)	Data  1.716 ( 0.933)	Loss 7.8692e-02 (9.2121e-02) 
2023-05-25 22:06:14.638725: train Epoch: [25][ 41/129]	Time  0.950 ( 1.862)	Data  0.001 ( 0.911)	Loss 8.5318e-02 (9.1959e-02) 
2023-05-25 22:06:17.346362: train Epoch: [25][ 42/129]	Time  2.708 ( 1.881)	Data  1.761 ( 0.931)	Loss 1.1482e-01 (9.2490e-02) 
2023-05-25 22:06:18.297746: train Epoch: [25][ 43/129]	Time  0.951 ( 1.860)	Data  0.001 ( 0.910)	Loss 7.9289e-02 (9.2190e-02) 
2023-05-25 22:06:20.915654: train Epoch: [25][ 44/129]	Time  2.618 ( 1.877)	Data  1.671 ( 0.927)	Loss 8.7352e-02 (9.2083e-02) 
2023-05-25 22:06:21.868688: train Epoch: [25][ 45/129]	Time  0.953 ( 1.857)	Data  0.001 ( 0.907)	Loss 7.5060e-02 (9.1713e-02) 
2023-05-25 22:06:24.549695: train Epoch: [25][ 46/129]	Time  2.681 ( 1.875)	Data  1.732 ( 0.924)	Loss 8.0784e-02 (9.1480e-02) 
2023-05-25 22:06:25.499264: train Epoch: [25][ 47/129]	Time  0.950 ( 1.855)	Data  0.001 ( 0.905)	Loss 9.7936e-02 (9.1615e-02) 
2023-05-25 22:06:28.210685: train Epoch: [25][ 48/129]	Time  2.711 ( 1.873)	Data  1.766 ( 0.922)	Loss 9.7006e-02 (9.1725e-02) 
2023-05-25 22:06:29.161128: train Epoch: [25][ 49/129]	Time  0.950 ( 1.854)	Data  0.001 ( 0.904)	Loss 6.5784e-02 (9.1206e-02) 
2023-05-25 22:06:31.836467: train Epoch: [25][ 50/129]	Time  2.675 ( 1.870)	Data  1.729 ( 0.920)	Loss 1.2322e-01 (9.1834e-02) 
2023-05-25 22:06:32.789889: train Epoch: [25][ 51/129]	Time  0.953 ( 1.853)	Data  0.001 ( 0.903)	Loss 6.4712e-02 (9.1312e-02) 
2023-05-25 22:06:35.485314: train Epoch: [25][ 52/129]	Time  2.695 ( 1.869)	Data  1.748 ( 0.918)	Loss 7.9724e-02 (9.1093e-02) 
2023-05-25 22:06:36.435605: train Epoch: [25][ 53/129]	Time  0.950 ( 1.852)	Data  0.001 ( 0.901)	Loss 7.2745e-02 (9.0754e-02) 
2023-05-25 22:06:39.015170: train Epoch: [25][ 54/129]	Time  2.580 ( 1.865)	Data  1.633 ( 0.915)	Loss 8.1868e-02 (9.0592e-02) 
2023-05-25 22:06:39.965655: train Epoch: [25][ 55/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.898)	Loss 1.7141e-01 (9.2035e-02) 
2023-05-25 22:06:42.604050: train Epoch: [25][ 56/129]	Time  2.638 ( 1.862)	Data  1.690 ( 0.912)	Loss 9.5243e-02 (9.2091e-02) 
2023-05-25 22:06:43.557144: train Epoch: [25][ 57/129]	Time  0.953 ( 1.847)	Data  0.001 ( 0.897)	Loss 8.6424e-02 (9.1994e-02) 
2023-05-25 22:06:46.252689: train Epoch: [25][ 58/129]	Time  2.696 ( 1.861)	Data  1.748 ( 0.911)	Loss 9.4632e-02 (9.2038e-02) 
2023-05-25 22:06:47.202399: train Epoch: [25][ 59/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.896)	Loss 6.3148e-02 (9.1557e-02) 
2023-05-25 22:06:49.880238: train Epoch: [25][ 60/129]	Time  2.678 ( 1.860)	Data  1.730 ( 0.910)	Loss 8.3996e-02 (9.1433e-02) 
2023-05-25 22:06:50.832512: train Epoch: [25][ 61/129]	Time  0.952 ( 1.845)	Data  0.001 ( 0.895)	Loss 8.7267e-02 (9.1366e-02) 
2023-05-25 22:06:53.462289: train Epoch: [25][ 62/129]	Time  2.630 ( 1.857)	Data  1.683 ( 0.907)	Loss 8.6072e-02 (9.1282e-02) 
2023-05-25 22:06:54.413676: train Epoch: [25][ 63/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.893)	Loss 8.6031e-02 (9.1200e-02) 
2023-05-25 22:06:57.125986: train Epoch: [25][ 64/129]	Time  2.712 ( 1.857)	Data  1.766 ( 0.907)	Loss 1.0539e-01 (9.1418e-02) 
2023-05-25 22:06:58.077036: train Epoch: [25][ 65/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.893)	Loss 1.0176e-01 (9.1575e-02) 
2023-05-25 22:07:00.831293: train Epoch: [25][ 66/129]	Time  2.754 ( 1.857)	Data  1.807 ( 0.907)	Loss 9.4177e-02 (9.1614e-02) 
2023-05-25 22:07:01.781886: train Epoch: [25][ 67/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.893)	Loss 9.7559e-02 (9.1701e-02) 
2023-05-25 22:07:04.355476: train Epoch: [25][ 68/129]	Time  2.574 ( 1.854)	Data  1.627 ( 0.904)	Loss 7.0563e-02 (9.1395e-02) 
2023-05-25 22:07:05.304040: train Epoch: [25][ 69/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.891)	Loss 1.4322e-01 (9.2135e-02) 
2023-05-25 22:07:07.978652: train Epoch: [25][ 70/129]	Time  2.675 ( 1.853)	Data  1.727 ( 0.903)	Loss 1.5835e-01 (9.3068e-02) 
2023-05-25 22:07:08.929622: train Epoch: [25][ 71/129]	Time  0.951 ( 1.840)	Data  0.001 ( 0.890)	Loss 6.5144e-02 (9.2680e-02) 
2023-05-25 22:07:11.644225: train Epoch: [25][ 72/129]	Time  2.715 ( 1.852)	Data  1.768 ( 0.902)	Loss 8.5181e-02 (9.2577e-02) 
2023-05-25 22:07:12.597316: train Epoch: [25][ 73/129]	Time  0.953 ( 1.840)	Data  0.001 ( 0.890)	Loss 1.1581e-01 (9.2891e-02) 
2023-05-25 22:07:15.265194: train Epoch: [25][ 74/129]	Time  2.668 ( 1.851)	Data  1.722 ( 0.901)	Loss 9.9974e-02 (9.2985e-02) 
2023-05-25 22:07:16.215376: train Epoch: [25][ 75/129]	Time  0.950 ( 1.839)	Data  0.001 ( 0.889)	Loss 6.7478e-02 (9.2650e-02) 
2023-05-25 22:07:18.938691: train Epoch: [25][ 76/129]	Time  2.723 ( 1.851)	Data  1.776 ( 0.901)	Loss 5.3351e-02 (9.2139e-02) 
2023-05-25 22:07:19.889584: train Epoch: [25][ 77/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.889)	Loss 5.1918e-02 (9.1624e-02) 
2023-05-25 22:07:22.672424: train Epoch: [25][ 78/129]	Time  2.783 ( 1.851)	Data  1.832 ( 0.901)	Loss 1.2379e-01 (9.2031e-02) 
2023-05-25 22:07:23.620244: train Epoch: [25][ 79/129]	Time  0.948 ( 1.840)	Data  0.001 ( 0.890)	Loss 1.5378e-01 (9.2803e-02) 
2023-05-25 22:07:26.123015: train Epoch: [25][ 80/129]	Time  2.503 ( 1.848)	Data  1.552 ( 0.898)	Loss 7.9891e-02 (9.2643e-02) 
2023-05-25 22:07:27.072820: train Epoch: [25][ 81/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.887)	Loss 1.0523e-01 (9.2797e-02) 
2023-05-25 22:07:29.826097: train Epoch: [25][ 82/129]	Time  2.753 ( 1.848)	Data  1.802 ( 0.898)	Loss 1.5832e-01 (9.3586e-02) 
2023-05-25 22:07:30.776647: train Epoch: [25][ 83/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.888)	Loss 8.2375e-02 (9.3453e-02) 
2023-05-25 22:07:33.553509: train Epoch: [25][ 84/129]	Time  2.777 ( 1.848)	Data  1.827 ( 0.899)	Loss 5.9592e-02 (9.3055e-02) 
2023-05-25 22:07:34.505859: train Epoch: [25][ 85/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.888)	Loss 8.3209e-02 (9.2940e-02) 
2023-05-25 22:07:37.235949: train Epoch: [25][ 86/129]	Time  2.730 ( 1.848)	Data  1.780 ( 0.898)	Loss 5.8320e-02 (9.2542e-02) 
2023-05-25 22:07:38.189000: train Epoch: [25][ 87/129]	Time  0.953 ( 1.838)	Data  0.001 ( 0.888)	Loss 8.2066e-02 (9.2423e-02) 
2023-05-25 22:07:40.922615: train Epoch: [25][ 88/129]	Time  2.734 ( 1.848)	Data  1.784 ( 0.898)	Loss 8.0974e-02 (9.2294e-02) 
2023-05-25 22:07:41.873823: train Epoch: [25][ 89/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.888)	Loss 8.5231e-02 (9.2216e-02) 
2023-05-25 22:07:44.566644: train Epoch: [25][ 90/129]	Time  2.693 ( 1.848)	Data  1.746 ( 0.898)	Loss 7.8894e-02 (9.2070e-02) 
2023-05-25 22:07:45.518604: train Epoch: [25][ 91/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.888)	Loss 1.2793e-01 (9.2459e-02) 
2023-05-25 22:07:48.358597: train Epoch: [25][ 92/129]	Time  2.840 ( 1.849)	Data  1.891 ( 0.899)	Loss 8.0302e-02 (9.2329e-02) 
2023-05-25 22:07:49.310415: train Epoch: [25][ 93/129]	Time  0.952 ( 1.839)	Data  0.001 ( 0.889)	Loss 6.7545e-02 (9.2065e-02) 
2023-05-25 22:07:52.077617: train Epoch: [25][ 94/129]	Time  2.767 ( 1.849)	Data  1.819 ( 0.899)	Loss 7.3235e-02 (9.1867e-02) 
2023-05-25 22:07:53.028478: train Epoch: [25][ 95/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.890)	Loss 4.2992e-02 (9.1358e-02) 
2023-05-25 22:07:55.771396: train Epoch: [25][ 96/129]	Time  2.743 ( 1.849)	Data  1.797 ( 0.899)	Loss 5.3825e-02 (9.0971e-02) 
2023-05-25 22:07:56.721420: train Epoch: [25][ 97/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.890)	Loss 1.1144e-01 (9.1180e-02) 
2023-05-25 22:07:59.392389: train Epoch: [25][ 98/129]	Time  2.671 ( 1.848)	Data  1.722 ( 0.898)	Loss 9.0614e-02 (9.1174e-02) 
2023-05-25 22:08:00.343349: train Epoch: [25][ 99/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.889)	Loss 1.3736e-01 (9.1636e-02) 
2023-05-25 22:08:02.940883: train Epoch: [25][100/129]	Time  2.598 ( 1.847)	Data  1.638 ( 0.897)	Loss 7.5384e-02 (9.1475e-02) 
2023-05-25 22:08:03.902187: train Epoch: [25][101/129]	Time  0.961 ( 1.838)	Data  0.001 ( 0.888)	Loss 7.7684e-02 (9.1340e-02) 
2023-05-25 22:08:06.550773: train Epoch: [25][102/129]	Time  2.649 ( 1.846)	Data  1.688 ( 0.896)	Loss 7.1580e-02 (9.1148e-02) 
2023-05-25 22:08:07.517273: train Epoch: [25][103/129]	Time  0.966 ( 1.837)	Data  0.001 ( 0.887)	Loss 7.6557e-02 (9.1007e-02) 
2023-05-25 22:08:10.216367: train Epoch: [25][104/129]	Time  2.699 ( 1.845)	Data  1.741 ( 0.895)	Loss 1.1508e-01 (9.1237e-02) 
2023-05-25 22:08:11.177219: train Epoch: [25][105/129]	Time  0.961 ( 1.837)	Data  0.001 ( 0.887)	Loss 1.4302e-01 (9.1725e-02) 
2023-05-25 22:08:13.825373: train Epoch: [25][106/129]	Time  2.648 ( 1.845)	Data  1.687 ( 0.894)	Loss 6.1807e-02 (9.1446e-02) 
2023-05-25 22:08:14.786536: train Epoch: [25][107/129]	Time  0.961 ( 1.837)	Data  0.001 ( 0.886)	Loss 9.0944e-02 (9.1441e-02) 
2023-05-25 22:08:17.611906: train Epoch: [25][108/129]	Time  2.825 ( 1.846)	Data  1.878 ( 0.895)	Loss 1.0570e-01 (9.1572e-02) 
2023-05-25 22:08:18.564141: train Epoch: [25][109/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.887)	Loss 7.1997e-02 (9.1394e-02) 
2023-05-25 22:08:21.401468: train Epoch: [25][110/129]	Time  2.837 ( 1.846)	Data  1.891 ( 0.896)	Loss 8.0420e-02 (9.1295e-02) 
2023-05-25 22:08:22.353106: train Epoch: [25][111/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.888)	Loss 5.6677e-02 (9.0986e-02) 
2023-05-25 22:08:24.990403: train Epoch: [25][112/129]	Time  2.637 ( 1.846)	Data  1.689 ( 0.895)	Loss 9.2345e-02 (9.0998e-02) 
2023-05-25 22:08:25.939429: train Epoch: [25][113/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.887)	Loss 9.3426e-02 (9.1019e-02) 
2023-05-25 22:08:28.643621: train Epoch: [25][114/129]	Time  2.704 ( 1.845)	Data  1.754 ( 0.895)	Loss 5.1472e-02 (9.0675e-02) 
2023-05-25 22:08:29.594090: train Epoch: [25][115/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.887)	Loss 6.7390e-02 (9.0475e-02) 
2023-05-25 22:08:32.351757: train Epoch: [25][116/129]	Time  2.758 ( 1.845)	Data  1.809 ( 0.895)	Loss 8.4301e-02 (9.0422e-02) 
2023-05-25 22:08:33.303062: train Epoch: [25][117/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.887)	Loss 7.9685e-02 (9.0331e-02) 
2023-05-25 22:08:35.919526: train Epoch: [25][118/129]	Time  2.616 ( 1.844)	Data  1.669 ( 0.894)	Loss 7.1958e-02 (9.0176e-02) 
2023-05-25 22:08:36.871343: train Epoch: [25][119/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.887)	Loss 5.1021e-02 (8.9850e-02) 
2023-05-25 22:08:39.497829: train Epoch: [25][120/129]	Time  2.626 ( 1.843)	Data  1.677 ( 0.893)	Loss 5.1240e-02 (8.9531e-02) 
2023-05-25 22:08:40.448829: train Epoch: [25][121/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.886)	Loss 4.7246e-02 (8.9184e-02) 
2023-05-25 22:08:43.056914: train Epoch: [25][122/129]	Time  2.608 ( 1.842)	Data  1.658 ( 0.892)	Loss 7.6176e-02 (8.9079e-02) 
2023-05-25 22:08:44.007338: train Epoch: [25][123/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.885)	Loss 8.5772e-02 (8.9052e-02) 
2023-05-25 22:08:46.705514: train Epoch: [25][124/129]	Time  2.698 ( 1.842)	Data  1.749 ( 0.892)	Loss 7.5547e-02 (8.8944e-02) 
2023-05-25 22:08:47.657950: train Epoch: [25][125/129]	Time  0.952 ( 1.835)	Data  0.001 ( 0.885)	Loss 1.4930e-01 (8.9423e-02) 
2023-05-25 22:08:50.063282: train Epoch: [25][126/129]	Time  2.405 ( 1.840)	Data  1.456 ( 0.889)	Loss 8.9026e-02 (8.9420e-02) 
2023-05-25 22:08:51.009144: train Epoch: [25][127/129]	Time  0.946 ( 1.833)	Data  0.001 ( 0.882)	Loss 4.6326e-02 (8.9083e-02) 
2023-05-25 22:08:52.495267: train Epoch: [25][128/129]	Time  1.486 ( 1.830)	Data  0.540 ( 0.880)	Loss 6.0612e-02 (8.8862e-02) 
2023-05-25 22:08:52.525178: Train Epoch done in 236.0869408969993 s 
2023-05-25 22:08:55.021164: val Epoch: [25][ 0/72]	Time  1.602 ( 1.602)	Data  1.400 ( 1.400)	Loss 1.5503e-01 (1.5503e-01) 
2023-05-25 22:08:55.143068: val Epoch: [25][ 1/72]	Time  0.122 ( 0.862)	Data  0.001 ( 0.701)	Loss 4.4259e-02 (9.9645e-02) 
2023-05-25 22:08:56.123355: val Epoch: [25][ 2/72]	Time  0.980 ( 0.901)	Data  0.858 ( 0.753)	Loss 5.4601e-02 (8.4631e-02) 
2023-05-25 22:08:56.244997: val Epoch: [25][ 3/72]	Time  0.122 ( 0.707)	Data  0.001 ( 0.565)	Loss 4.5031e-02 (7.4731e-02) 
2023-05-25 22:08:57.359241: val Epoch: [25][ 4/72]	Time  1.114 ( 0.788)	Data  0.992 ( 0.651)	Loss 4.6171e-02 (6.9019e-02) 
2023-05-25 22:08:57.484811: val Epoch: [25][ 5/72]	Time  0.126 ( 0.678)	Data  0.001 ( 0.542)	Loss 6.6124e-02 (6.8536e-02) 
2023-05-25 22:08:58.646547: val Epoch: [25][ 6/72]	Time  1.162 ( 0.747)	Data  1.040 ( 0.613)	Loss 1.4466e-01 (7.9411e-02) 
2023-05-25 22:08:58.771895: val Epoch: [25][ 7/72]	Time  0.125 ( 0.669)	Data  0.001 ( 0.537)	Loss 2.6141e-01 (1.0216e-01) 
2023-05-25 22:08:59.897312: val Epoch: [25][ 8/72]	Time  1.125 ( 0.720)	Data  1.004 ( 0.589)	Loss 1.2834e-01 (1.0507e-01) 
2023-05-25 22:09:00.022998: val Epoch: [25][ 9/72]	Time  0.126 ( 0.660)	Data  0.001 ( 0.530)	Loss 8.9602e-02 (1.0352e-01) 
2023-05-25 22:09:01.162670: val Epoch: [25][10/72]	Time  1.140 ( 0.704)	Data  1.018 ( 0.574)	Loss 9.9342e-02 (1.0314e-01) 
2023-05-25 22:09:01.288471: val Epoch: [25][11/72]	Time  0.126 ( 0.656)	Data  0.001 ( 0.526)	Loss 1.0592e-01 (1.0337e-01) 
2023-05-25 22:09:02.455726: val Epoch: [25][12/72]	Time  1.167 ( 0.695)	Data  1.045 ( 0.566)	Loss 3.3542e-01 (1.2122e-01) 
2023-05-25 22:09:02.576931: val Epoch: [25][13/72]	Time  0.121 ( 0.654)	Data  0.001 ( 0.526)	Loss 1.5391e-01 (1.2356e-01) 
2023-05-25 22:09:03.685663: val Epoch: [25][14/72]	Time  1.109 ( 0.684)	Data  0.981 ( 0.556)	Loss 3.0294e-01 (1.3552e-01) 
2023-05-25 22:09:03.810320: val Epoch: [25][15/72]	Time  0.125 ( 0.649)	Data  0.001 ( 0.522)	Loss 4.4131e-02 (1.2981e-01) 
2023-05-25 22:09:04.859530: val Epoch: [25][16/72]	Time  1.049 ( 0.673)	Data  0.924 ( 0.545)	Loss 5.2187e-02 (1.2524e-01) 
2023-05-25 22:09:04.984364: val Epoch: [25][17/72]	Time  0.125 ( 0.643)	Data  0.000 ( 0.515)	Loss 5.3585e-02 (1.2126e-01) 
2023-05-25 22:09:06.120037: val Epoch: [25][18/72]	Time  1.136 ( 0.668)	Data  1.014 ( 0.541)	Loss 4.7727e-01 (1.4000e-01) 
2023-05-25 22:09:06.245012: val Epoch: [25][19/72]	Time  0.125 ( 0.641)	Data  0.001 ( 0.514)	Loss 1.0969e-01 (1.3848e-01) 
2023-05-25 22:09:07.334723: val Epoch: [25][20/72]	Time  1.090 ( 0.663)	Data  0.968 ( 0.536)	Loss 9.6436e-02 (1.3648e-01) 
2023-05-25 22:09:07.459095: val Epoch: [25][21/72]	Time  0.124 ( 0.638)	Data  0.001 ( 0.512)	Loss 4.1319e-01 (1.4906e-01) 
2023-05-25 22:09:08.562186: val Epoch: [25][22/72]	Time  1.103 ( 0.658)	Data  0.981 ( 0.532)	Loss 4.1771e-02 (1.4439e-01) 
2023-05-25 22:09:08.683449: val Epoch: [25][23/72]	Time  0.121 ( 0.636)	Data  0.001 ( 0.510)	Loss 1.3221e-01 (1.4388e-01) 
2023-05-25 22:09:09.771811: val Epoch: [25][24/72]	Time  1.088 ( 0.654)	Data  0.967 ( 0.528)	Loss 4.3120e-02 (1.3985e-01) 
2023-05-25 22:09:09.896992: val Epoch: [25][25/72]	Time  0.125 ( 0.634)	Data  0.001 ( 0.508)	Loss 6.8115e-02 (1.3710e-01) 
2023-05-25 22:09:10.989322: val Epoch: [25][26/72]	Time  1.092 ( 0.651)	Data  0.969 ( 0.525)	Loss 1.2559e-01 (1.3667e-01) 
2023-05-25 22:09:11.116724: val Epoch: [25][27/72]	Time  0.127 ( 0.632)	Data  0.001 ( 0.506)	Loss 6.4009e-02 (1.3407e-01) 
2023-05-25 22:09:12.184707: val Epoch: [25][28/72]	Time  1.068 ( 0.647)	Data  0.950 ( 0.521)	Loss 7.0353e-02 (1.3188e-01) 
2023-05-25 22:09:12.305841: val Epoch: [25][29/72]	Time  0.121 ( 0.630)	Data  0.001 ( 0.504)	Loss 7.5452e-02 (1.3000e-01) 
2023-05-25 22:09:13.414812: val Epoch: [25][30/72]	Time  1.109 ( 0.645)	Data  0.987 ( 0.520)	Loss 5.6319e-02 (1.2762e-01) 
2023-05-25 22:09:13.539083: val Epoch: [25][31/72]	Time  0.124 ( 0.629)	Data  0.001 ( 0.503)	Loss 7.2901e-02 (1.2591e-01) 
2023-05-25 22:09:14.642448: val Epoch: [25][32/72]	Time  1.103 ( 0.643)	Data  0.982 ( 0.518)	Loss 5.1792e-02 (1.2366e-01) 
2023-05-25 22:09:14.766695: val Epoch: [25][33/72]	Time  0.124 ( 0.628)	Data  0.000 ( 0.503)	Loss 1.3396e-01 (1.2397e-01) 
2023-05-25 22:09:15.898427: val Epoch: [25][34/72]	Time  1.132 ( 0.642)	Data  1.010 ( 0.517)	Loss 3.7535e-01 (1.3115e-01) 
2023-05-25 22:09:16.022435: val Epoch: [25][35/72]	Time  0.124 ( 0.628)	Data  0.000 ( 0.503)	Loss 4.5539e-02 (1.2877e-01) 
2023-05-25 22:09:17.136047: val Epoch: [25][36/72]	Time  1.114 ( 0.641)	Data  0.989 ( 0.516)	Loss 6.2216e-02 (1.2697e-01) 
2023-05-25 22:09:17.257705: val Epoch: [25][37/72]	Time  0.122 ( 0.627)	Data  0.001 ( 0.502)	Loss 1.2408e-01 (1.2690e-01) 
2023-05-25 22:09:18.360692: val Epoch: [25][38/72]	Time  1.103 ( 0.640)	Data  0.982 ( 0.515)	Loss 4.0500e-02 (1.2468e-01) 
2023-05-25 22:09:18.485339: val Epoch: [25][39/72]	Time  0.125 ( 0.627)	Data  0.001 ( 0.502)	Loss 6.0172e-02 (1.2307e-01) 
2023-05-25 22:09:19.567226: val Epoch: [25][40/72]	Time  1.082 ( 0.638)	Data  0.961 ( 0.513)	Loss 6.8214e-02 (1.2173e-01) 
2023-05-25 22:09:19.690995: val Epoch: [25][41/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.501)	Loss 1.9380e-01 (1.2345e-01) 
2023-05-25 22:09:20.814783: val Epoch: [25][42/72]	Time  1.124 ( 0.637)	Data  1.002 ( 0.513)	Loss 1.3315e-01 (1.2367e-01) 
2023-05-25 22:09:20.935816: val Epoch: [25][43/72]	Time  0.121 ( 0.625)	Data  0.001 ( 0.501)	Loss 4.5189e-01 (1.3113e-01) 
2023-05-25 22:09:22.013147: val Epoch: [25][44/72]	Time  1.077 ( 0.635)	Data  0.955 ( 0.511)	Loss 6.1834e-02 (1.2959e-01) 
2023-05-25 22:09:22.134495: val Epoch: [25][45/72]	Time  0.121 ( 0.624)	Data  0.001 ( 0.500)	Loss 7.2925e-02 (1.2836e-01) 
2023-05-25 22:09:23.280693: val Epoch: [25][46/72]	Time  1.146 ( 0.635)	Data  1.024 ( 0.511)	Loss 5.7739e-02 (1.2686e-01) 
2023-05-25 22:09:23.404979: val Epoch: [25][47/72]	Time  0.124 ( 0.625)	Data  0.001 ( 0.500)	Loss 2.4990e-01 (1.2942e-01) 
2023-05-25 22:09:24.543932: val Epoch: [25][48/72]	Time  1.139 ( 0.635)	Data  1.018 ( 0.511)	Loss 8.9004e-02 (1.2860e-01) 
2023-05-25 22:09:24.668050: val Epoch: [25][49/72]	Time  0.124 ( 0.625)	Data  0.001 ( 0.501)	Loss 2.9115e-01 (1.3185e-01) 
2023-05-25 22:09:25.730712: val Epoch: [25][50/72]	Time  1.063 ( 0.634)	Data  0.942 ( 0.509)	Loss 1.1068e-01 (1.3143e-01) 
2023-05-25 22:09:25.852009: val Epoch: [25][51/72]	Time  0.121 ( 0.624)	Data  0.001 ( 0.500)	Loss 5.7320e-01 (1.3993e-01) 
2023-05-25 22:09:26.904293: val Epoch: [25][52/72]	Time  1.052 ( 0.632)	Data  0.928 ( 0.508)	Loss 7.1115e-02 (1.3863e-01) 
2023-05-25 22:09:27.028291: val Epoch: [25][53/72]	Time  0.124 ( 0.622)	Data  0.001 ( 0.498)	Loss 6.5776e-02 (1.3728e-01) 
2023-05-25 22:09:28.113857: val Epoch: [25][54/72]	Time  1.086 ( 0.631)	Data  0.961 ( 0.507)	Loss 5.2778e-02 (1.3574e-01) 
2023-05-25 22:09:28.238554: val Epoch: [25][55/72]	Time  0.125 ( 0.622)	Data  0.001 ( 0.498)	Loss 6.3609e-02 (1.3445e-01) 
2023-05-25 22:09:29.294769: val Epoch: [25][56/72]	Time  1.056 ( 0.629)	Data  0.932 ( 0.505)	Loss 2.3061e-01 (1.3614e-01) 
2023-05-25 22:09:29.419523: val Epoch: [25][57/72]	Time  0.125 ( 0.621)	Data  0.001 ( 0.497)	Loss 5.5241e-02 (1.3475e-01) 
2023-05-25 22:09:30.495406: val Epoch: [25][58/72]	Time  1.076 ( 0.628)	Data  0.952 ( 0.504)	Loss 1.6890e-01 (1.3533e-01) 
2023-05-25 22:09:30.620157: val Epoch: [25][59/72]	Time  0.125 ( 0.620)	Data  0.001 ( 0.496)	Loss 6.3545e-02 (1.3413e-01) 
2023-05-25 22:09:31.753475: val Epoch: [25][60/72]	Time  1.133 ( 0.628)	Data  1.011 ( 0.504)	Loss 9.7535e-02 (1.3353e-01) 
2023-05-25 22:09:31.872236: val Epoch: [25][61/72]	Time  0.119 ( 0.620)	Data  0.000 ( 0.496)	Loss 3.8345e-01 (1.3756e-01) 
2023-05-25 22:09:32.998918: val Epoch: [25][62/72]	Time  1.127 ( 0.628)	Data  1.007 ( 0.504)	Loss 9.7649e-02 (1.3693e-01) 
2023-05-25 22:09:33.118022: val Epoch: [25][63/72]	Time  0.119 ( 0.620)	Data  0.000 ( 0.496)	Loss 1.0470e-01 (1.3642e-01) 
2023-05-25 22:09:34.250386: val Epoch: [25][64/72]	Time  1.132 ( 0.628)	Data  1.013 ( 0.504)	Loss 1.0529e-01 (1.3594e-01) 
2023-05-25 22:09:34.369227: val Epoch: [25][65/72]	Time  0.119 ( 0.620)	Data  0.000 ( 0.497)	Loss 1.4910e-01 (1.3614e-01) 
2023-05-25 22:09:35.466391: val Epoch: [25][66/72]	Time  1.097 ( 0.628)	Data  0.978 ( 0.504)	Loss 8.3565e-02 (1.3536e-01) 
2023-05-25 22:09:35.585507: val Epoch: [25][67/72]	Time  0.119 ( 0.620)	Data  0.001 ( 0.497)	Loss 2.0912e-01 (1.3644e-01) 
2023-05-25 22:09:36.694442: val Epoch: [25][68/72]	Time  1.109 ( 0.627)	Data  0.989 ( 0.504)	Loss 9.9602e-02 (1.3591e-01) 
2023-05-25 22:09:36.813206: val Epoch: [25][69/72]	Time  0.119 ( 0.620)	Data  0.000 ( 0.497)	Loss 9.0770e-02 (1.3527e-01) 
2023-05-25 22:09:37.852980: val Epoch: [25][70/72]	Time  1.040 ( 0.626)	Data  0.921 ( 0.502)	Loss 1.0575e-01 (1.3485e-01) 
2023-05-25 22:09:37.971480: val Epoch: [25][71/72]	Time  0.118 ( 0.619)	Data  0.000 ( 0.496)	Loss 3.2792e-01 (1.3753e-01) 
2023-05-25 22:09:38.159485: Epoch 25 :Val : ['ET : 0.7174645662307739', 'TC : 0.769278883934021', 'WT : 0.8526273965835571'] 
2023-05-25 22:09:38.162233: Epoch 25 :Val : ['ET : 0.7174645662307739', 'TC : 0.769278883934021', 'WT : 0.8526273965835571'] 
2023-05-25 22:09:38.164045: Saving the model with DSC 0.7857301831245422 
2023-05-25 22:09:38.828834: Val epoch done in 46.30364835900036 s 
2023-05-25 22:09:38.834681: Batches per epoch:  129 
2023-05-25 22:09:43.756961: train Epoch: [26][  0/129]	Time  4.922 ( 4.922)	Data  3.919 ( 3.919)	Loss 9.8831e-02 (9.8831e-02) 
2023-05-25 22:09:44.705519: train Epoch: [26][  1/129]	Time  0.949 ( 2.935)	Data  0.001 ( 1.960)	Loss 1.2289e-01 (1.1086e-01) 
2023-05-25 22:09:47.239411: train Epoch: [26][  2/129]	Time  2.534 ( 2.801)	Data  1.578 ( 1.833)	Loss 1.0037e-01 (1.0736e-01) 
2023-05-25 22:09:48.188395: train Epoch: [26][  3/129]	Time  0.949 ( 2.338)	Data  0.001 ( 1.375)	Loss 6.4296e-02 (9.6597e-02) 
2023-05-25 22:09:50.914109: train Epoch: [26][  4/129]	Time  2.726 ( 2.416)	Data  1.779 ( 1.456)	Loss 1.0031e-01 (9.7340e-02) 
2023-05-25 22:09:51.861930: train Epoch: [26][  5/129]	Time  0.948 ( 2.171)	Data  0.001 ( 1.213)	Loss 1.4593e-01 (1.0544e-01) 
2023-05-25 22:09:54.603006: train Epoch: [26][  6/129]	Time  2.741 ( 2.253)	Data  1.795 ( 1.296)	Loss 7.9922e-02 (1.0179e-01) 
2023-05-25 22:09:55.551474: train Epoch: [26][  7/129]	Time  0.948 ( 2.090)	Data  0.001 ( 1.134)	Loss 8.4885e-02 (9.9680e-02) 
2023-05-25 22:09:58.370074: train Epoch: [26][  8/129]	Time  2.819 ( 2.171)	Data  1.863 ( 1.215)	Loss 7.5672e-02 (9.7012e-02) 
2023-05-25 22:09:59.329527: train Epoch: [26][  9/129]	Time  0.959 ( 2.049)	Data  0.001 ( 1.094)	Loss 8.1130e-02 (9.5424e-02) 
2023-05-25 22:10:02.023959: train Epoch: [26][ 10/129]	Time  2.694 ( 2.108)	Data  1.739 ( 1.153)	Loss 8.8602e-02 (9.4804e-02) 
2023-05-25 22:10:02.982456: train Epoch: [26][ 11/129]	Time  0.958 ( 2.012)	Data  0.001 ( 1.057)	Loss 8.4030e-02 (9.3906e-02) 
2023-05-25 22:10:05.687287: train Epoch: [26][ 12/129]	Time  2.705 ( 2.066)	Data  1.748 ( 1.110)	Loss 1.0299e-01 (9.4605e-02) 
2023-05-25 22:10:06.638045: train Epoch: [26][ 13/129]	Time  0.951 ( 1.986)	Data  0.001 ( 1.031)	Loss 5.3305e-02 (9.1655e-02) 
2023-05-25 22:10:09.475629: train Epoch: [26][ 14/129]	Time  2.838 ( 2.043)	Data  1.890 ( 1.088)	Loss 1.2457e-01 (9.3849e-02) 
2023-05-25 22:10:10.424331: train Epoch: [26][ 15/129]	Time  0.949 ( 1.974)	Data  0.001 ( 1.020)	Loss 5.5853e-02 (9.1474e-02) 
2023-05-25 22:10:13.234602: train Epoch: [26][ 16/129]	Time  2.810 ( 2.023)	Data  1.865 ( 1.070)	Loss 7.3283e-02 (9.0404e-02) 
2023-05-25 22:10:14.183326: train Epoch: [26][ 17/129]	Time  0.949 ( 1.964)	Data  0.001 ( 1.010)	Loss 7.6204e-02 (8.9615e-02) 
2023-05-25 22:10:16.818609: train Epoch: [26][ 18/129]	Time  2.635 ( 1.999)	Data  1.678 ( 1.045)	Loss 9.6970e-02 (9.0002e-02) 
2023-05-25 22:10:17.779319: train Epoch: [26][ 19/129]	Time  0.961 ( 1.947)	Data  0.001 ( 0.993)	Loss 1.3643e-01 (9.2324e-02) 
2023-05-25 22:10:20.456021: train Epoch: [26][ 20/129]	Time  2.677 ( 1.982)	Data  1.723 ( 1.028)	Loss 5.0059e-02 (9.0311e-02) 
2023-05-25 22:10:21.405528: train Epoch: [26][ 21/129]	Time  0.950 ( 1.935)	Data  0.001 ( 0.981)	Loss 6.2785e-02 (8.9060e-02) 
2023-05-25 22:10:23.893181: train Epoch: [26][ 22/129]	Time  2.488 ( 1.959)	Data  1.536 ( 1.005)	Loss 8.0263e-02 (8.8678e-02) 
2023-05-25 22:10:24.841299: train Epoch: [26][ 23/129]	Time  0.948 ( 1.917)	Data  0.001 ( 0.964)	Loss 6.6039e-02 (8.7734e-02) 
2023-05-25 22:10:27.531858: train Epoch: [26][ 24/129]	Time  2.691 ( 1.948)	Data  1.734 ( 0.994)	Loss 5.9949e-02 (8.6623e-02) 
2023-05-25 22:10:28.481867: train Epoch: [26][ 25/129]	Time  0.950 ( 1.909)	Data  0.001 ( 0.956)	Loss 6.2738e-02 (8.5704e-02) 
2023-05-25 22:10:31.102634: train Epoch: [26][ 26/129]	Time  2.621 ( 1.936)	Data  1.668 ( 0.983)	Loss 9.8743e-02 (8.6187e-02) 
2023-05-25 22:10:32.052859: train Epoch: [26][ 27/129]	Time  0.950 ( 1.901)	Data  0.001 ( 0.947)	Loss 1.0116e-01 (8.6722e-02) 
2023-05-25 22:10:34.821154: train Epoch: [26][ 28/129]	Time  2.768 ( 1.931)	Data  1.819 ( 0.978)	Loss 7.0270e-02 (8.6155e-02) 
2023-05-25 22:10:35.769922: train Epoch: [26][ 29/129]	Time  0.949 ( 1.898)	Data  0.001 ( 0.945)	Loss 5.8773e-02 (8.5242e-02) 
2023-05-25 22:10:38.495720: train Epoch: [26][ 30/129]	Time  2.726 ( 1.925)	Data  1.779 ( 0.972)	Loss 7.1328e-02 (8.4793e-02) 
2023-05-25 22:10:39.446638: train Epoch: [26][ 31/129]	Time  0.951 ( 1.894)	Data  0.001 ( 0.942)	Loss 9.5526e-02 (8.5129e-02) 
2023-05-25 22:10:41.999089: train Epoch: [26][ 32/129]	Time  2.552 ( 1.914)	Data  1.589 ( 0.961)	Loss 5.1786e-02 (8.4118e-02) 
2023-05-25 22:10:42.958180: train Epoch: [26][ 33/129]	Time  0.959 ( 1.886)	Data  0.001 ( 0.933)	Loss 6.3610e-02 (8.3515e-02) 
2023-05-25 22:10:45.650790: train Epoch: [26][ 34/129]	Time  2.693 ( 1.909)	Data  1.725 ( 0.956)	Loss 7.6765e-02 (8.3322e-02) 
2023-05-25 22:10:46.609497: train Epoch: [26][ 35/129]	Time  0.959 ( 1.883)	Data  0.001 ( 0.929)	Loss 1.1252e-01 (8.4133e-02) 
2023-05-25 22:10:49.170055: train Epoch: [26][ 36/129]	Time  2.561 ( 1.901)	Data  1.594 ( 0.947)	Loss 9.5561e-02 (8.4442e-02) 
2023-05-25 22:10:50.129775: train Epoch: [26][ 37/129]	Time  0.960 ( 1.876)	Data  0.001 ( 0.922)	Loss 5.7186e-02 (8.3725e-02) 
2023-05-25 22:10:52.716358: train Epoch: [26][ 38/129]	Time  2.587 ( 1.894)	Data  1.631 ( 0.940)	Loss 8.9471e-02 (8.3872e-02) 
2023-05-25 22:10:53.672905: train Epoch: [26][ 39/129]	Time  0.957 ( 1.871)	Data  0.001 ( 0.917)	Loss 6.7395e-02 (8.3460e-02) 
2023-05-25 22:10:56.317986: train Epoch: [26][ 40/129]	Time  2.645 ( 1.890)	Data  1.688 ( 0.936)	Loss 5.4885e-02 (8.2763e-02) 
2023-05-25 22:10:57.277803: train Epoch: [26][ 41/129]	Time  0.960 ( 1.868)	Data  0.001 ( 0.913)	Loss 2.2040e-01 (8.6040e-02) 
2023-05-25 22:10:59.923206: train Epoch: [26][ 42/129]	Time  2.645 ( 1.886)	Data  1.689 ( 0.931)	Loss 9.6841e-02 (8.6292e-02) 
2023-05-25 22:11:00.871323: train Epoch: [26][ 43/129]	Time  0.948 ( 1.864)	Data  0.001 ( 0.910)	Loss 8.1758e-02 (8.6189e-02) 
2023-05-25 22:11:03.499563: train Epoch: [26][ 44/129]	Time  2.628 ( 1.881)	Data  1.671 ( 0.927)	Loss 1.0142e-01 (8.6527e-02) 
2023-05-25 22:11:04.448403: train Epoch: [26][ 45/129]	Time  0.949 ( 1.861)	Data  0.001 ( 0.907)	Loss 1.1394e-01 (8.7123e-02) 
2023-05-25 22:11:07.146840: train Epoch: [26][ 46/129]	Time  2.698 ( 1.879)	Data  1.738 ( 0.925)	Loss 1.2400e-01 (8.7908e-02) 
2023-05-25 22:11:08.095499: train Epoch: [26][ 47/129]	Time  0.949 ( 1.860)	Data  0.001 ( 0.905)	Loss 6.9789e-02 (8.7530e-02) 
2023-05-25 22:11:10.716585: train Epoch: [26][ 48/129]	Time  2.621 ( 1.875)	Data  1.665 ( 0.921)	Loss 1.1242e-01 (8.8038e-02) 
2023-05-25 22:11:11.665746: train Epoch: [26][ 49/129]	Time  0.949 ( 1.857)	Data  0.001 ( 0.903)	Loss 1.4882e-01 (8.9254e-02) 
2023-05-25 22:11:14.264755: train Epoch: [26][ 50/129]	Time  2.599 ( 1.871)	Data  1.652 ( 0.917)	Loss 9.5109e-02 (8.9369e-02) 
2023-05-25 22:11:15.226450: train Epoch: [26][ 51/129]	Time  0.962 ( 1.854)	Data  0.001 ( 0.900)	Loss 6.5552e-02 (8.8911e-02) 
2023-05-25 22:11:17.855709: train Epoch: [26][ 52/129]	Time  2.629 ( 1.868)	Data  1.667 ( 0.914)	Loss 1.5518e-01 (9.0161e-02) 
2023-05-25 22:11:18.815061: train Epoch: [26][ 53/129]	Time  0.959 ( 1.851)	Data  0.001 ( 0.897)	Loss 1.3775e-01 (9.1042e-02) 
2023-05-25 22:11:21.465533: train Epoch: [26][ 54/129]	Time  2.650 ( 1.866)	Data  1.693 ( 0.912)	Loss 7.5526e-02 (9.0760e-02) 
2023-05-25 22:11:22.427194: train Epoch: [26][ 55/129]	Time  0.962 ( 1.850)	Data  0.001 ( 0.895)	Loss 1.0637e-01 (9.1039e-02) 
2023-05-25 22:11:25.014274: train Epoch: [26][ 56/129]	Time  2.587 ( 1.863)	Data  1.630 ( 0.908)	Loss 1.0518e-01 (9.1287e-02) 
2023-05-25 22:11:25.973185: train Epoch: [26][ 57/129]	Time  0.959 ( 1.847)	Data  0.001 ( 0.893)	Loss 1.3610e-01 (9.2059e-02) 
2023-05-25 22:11:28.579966: train Epoch: [26][ 58/129]	Time  2.607 ( 1.860)	Data  1.650 ( 0.905)	Loss 9.0360e-02 (9.2031e-02) 
2023-05-25 22:11:29.539640: train Epoch: [26][ 59/129]	Time  0.960 ( 1.845)	Data  0.001 ( 0.890)	Loss 6.2017e-02 (9.1530e-02) 
2023-05-25 22:11:32.171063: train Epoch: [26][ 60/129]	Time  2.631 ( 1.858)	Data  1.673 ( 0.903)	Loss 9.3556e-02 (9.1564e-02) 
2023-05-25 22:11:33.131347: train Epoch: [26][ 61/129]	Time  0.960 ( 1.843)	Data  0.001 ( 0.889)	Loss 1.3779e-01 (9.2309e-02) 
2023-05-25 22:11:35.797925: train Epoch: [26][ 62/129]	Time  2.667 ( 1.857)	Data  1.711 ( 0.902)	Loss 8.1593e-02 (9.2139e-02) 
2023-05-25 22:11:36.757968: train Epoch: [26][ 63/129]	Time  0.960 ( 1.843)	Data  0.001 ( 0.888)	Loss 3.3171e-01 (9.5882e-02) 
2023-05-25 22:11:39.406683: train Epoch: [26][ 64/129]	Time  2.649 ( 1.855)	Data  1.692 ( 0.900)	Loss 9.1770e-02 (9.5819e-02) 
2023-05-25 22:11:40.366056: train Epoch: [26][ 65/129]	Time  0.959 ( 1.841)	Data  0.001 ( 0.886)	Loss 9.5597e-02 (9.5816e-02) 
2023-05-25 22:11:42.990732: train Epoch: [26][ 66/129]	Time  2.625 ( 1.853)	Data  1.667 ( 0.898)	Loss 1.1709e-01 (9.6133e-02) 
2023-05-25 22:11:43.951604: train Epoch: [26][ 67/129]	Time  0.961 ( 1.840)	Data  0.001 ( 0.885)	Loss 7.4037e-02 (9.5808e-02) 
2023-05-25 22:11:46.608211: train Epoch: [26][ 68/129]	Time  2.657 ( 1.852)	Data  1.691 ( 0.896)	Loss 8.1560e-02 (9.5602e-02) 
2023-05-25 22:11:47.568086: train Epoch: [26][ 69/129]	Time  0.960 ( 1.839)	Data  0.001 ( 0.884)	Loss 4.9163e-02 (9.4938e-02) 
2023-05-25 22:11:50.138922: train Epoch: [26][ 70/129]	Time  2.571 ( 1.849)	Data  1.603 ( 0.894)	Loss 6.4946e-02 (9.4516e-02) 
2023-05-25 22:11:51.088753: train Epoch: [26][ 71/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.881)	Loss 7.8767e-02 (9.4297e-02) 
2023-05-25 22:11:53.709826: train Epoch: [26][ 72/129]	Time  2.621 ( 1.848)	Data  1.672 ( 0.892)	Loss 7.8537e-02 (9.4081e-02) 
2023-05-25 22:11:54.660793: train Epoch: [26][ 73/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.880)	Loss 7.5557e-02 (9.3831e-02) 
2023-05-25 22:11:57.285685: train Epoch: [26][ 74/129]	Time  2.625 ( 1.846)	Data  1.677 ( 0.891)	Loss 7.6029e-02 (9.3594e-02) 
2023-05-25 22:11:58.237803: train Epoch: [26][ 75/129]	Time  0.952 ( 1.834)	Data  0.001 ( 0.879)	Loss 6.7210e-02 (9.3247e-02) 
2023-05-25 22:12:00.844256: train Epoch: [26][ 76/129]	Time  2.606 ( 1.844)	Data  1.659 ( 0.889)	Loss 8.2883e-02 (9.3112e-02) 
2023-05-25 22:12:01.793078: train Epoch: [26][ 77/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.878)	Loss 6.8798e-02 (9.2800e-02) 
2023-05-25 22:12:04.460236: train Epoch: [26][ 78/129]	Time  2.667 ( 1.843)	Data  1.720 ( 0.889)	Loss 9.4384e-02 (9.2820e-02) 
2023-05-25 22:12:05.410663: train Epoch: [26][ 79/129]	Time  0.950 ( 1.832)	Data  0.001 ( 0.877)	Loss 1.3698e-01 (9.3372e-02) 
2023-05-25 22:12:08.142413: train Epoch: [26][ 80/129]	Time  2.732 ( 1.843)	Data  1.782 ( 0.889)	Loss 1.5938e-01 (9.4187e-02) 
2023-05-25 22:12:09.089967: train Epoch: [26][ 81/129]	Time  0.948 ( 1.832)	Data  0.001 ( 0.878)	Loss 1.4065e-01 (9.4754e-02) 
2023-05-25 22:12:11.874558: train Epoch: [26][ 82/129]	Time  2.785 ( 1.844)	Data  1.837 ( 0.889)	Loss 4.3750e-02 (9.4139e-02) 
2023-05-25 22:12:12.823626: train Epoch: [26][ 83/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.879)	Loss 1.0650e-01 (9.4286e-02) 
2023-05-25 22:12:15.461337: train Epoch: [26][ 84/129]	Time  2.638 ( 1.843)	Data  1.689 ( 0.888)	Loss 1.4075e-01 (9.4833e-02) 
2023-05-25 22:12:16.411600: train Epoch: [26][ 85/129]	Time  0.950 ( 1.832)	Data  0.001 ( 0.878)	Loss 7.4037e-02 (9.4591e-02) 
2023-05-25 22:12:19.107292: train Epoch: [26][ 86/129]	Time  2.696 ( 1.842)	Data  1.747 ( 0.888)	Loss 9.8338e-02 (9.4634e-02) 
2023-05-25 22:12:20.057017: train Epoch: [26][ 87/129]	Time  0.950 ( 1.832)	Data  0.001 ( 0.878)	Loss 1.1061e-01 (9.4816e-02) 
2023-05-25 22:12:22.699972: train Epoch: [26][ 88/129]	Time  2.643 ( 1.841)	Data  1.697 ( 0.887)	Loss 1.1710e-01 (9.5066e-02) 
2023-05-25 22:12:23.650639: train Epoch: [26][ 89/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.877)	Loss 5.9481e-02 (9.4671e-02) 
2023-05-25 22:12:26.261878: train Epoch: [26][ 90/129]	Time  2.611 ( 1.840)	Data  1.661 ( 0.886)	Loss 1.6656e-01 (9.5461e-02) 
2023-05-25 22:12:27.221517: train Epoch: [26][ 91/129]	Time  0.960 ( 1.830)	Data  0.001 ( 0.876)	Loss 6.6582e-02 (9.5147e-02) 
2023-05-25 22:12:29.824988: train Epoch: [26][ 92/129]	Time  2.603 ( 1.839)	Data  1.645 ( 0.884)	Loss 8.3241e-02 (9.5019e-02) 
2023-05-25 22:12:30.785346: train Epoch: [26][ 93/129]	Time  0.960 ( 1.829)	Data  0.001 ( 0.875)	Loss 7.7024e-02 (9.4827e-02) 
2023-05-25 22:12:33.421476: train Epoch: [26][ 94/129]	Time  2.636 ( 1.838)	Data  1.679 ( 0.884)	Loss 7.6017e-02 (9.4629e-02) 
2023-05-25 22:12:34.381278: train Epoch: [26][ 95/129]	Time  0.960 ( 1.829)	Data  0.001 ( 0.874)	Loss 8.1428e-02 (9.4492e-02) 
2023-05-25 22:12:36.957187: train Epoch: [26][ 96/129]	Time  2.576 ( 1.836)	Data  1.614 ( 0.882)	Loss 8.1312e-02 (9.4356e-02) 
2023-05-25 22:12:37.908568: train Epoch: [26][ 97/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.873)	Loss 9.8069e-02 (9.4394e-02) 
2023-05-25 22:12:40.499968: train Epoch: [26][ 98/129]	Time  2.591 ( 1.835)	Data  1.644 ( 0.881)	Loss 1.1650e-01 (9.4617e-02) 
2023-05-25 22:12:41.451291: train Epoch: [26][ 99/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.872)	Loss 1.0151e-01 (9.4686e-02) 
2023-05-25 22:12:44.081697: train Epoch: [26][100/129]	Time  2.630 ( 1.834)	Data  1.674 ( 0.880)	Loss 9.0286e-02 (9.4643e-02) 
2023-05-25 22:12:45.030418: train Epoch: [26][101/129]	Time  0.949 ( 1.825)	Data  0.001 ( 0.871)	Loss 1.2692e-01 (9.4959e-02) 
2023-05-25 22:12:47.656279: train Epoch: [26][102/129]	Time  2.626 ( 1.833)	Data  1.678 ( 0.879)	Loss 8.1067e-02 (9.4824e-02) 
2023-05-25 22:12:48.606775: train Epoch: [26][103/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.871)	Loss 8.3018e-02 (9.4711e-02) 
2023-05-25 22:12:51.182230: train Epoch: [26][104/129]	Time  2.575 ( 1.832)	Data  1.627 ( 0.878)	Loss 8.5218e-02 (9.4620e-02) 
2023-05-25 22:12:52.134111: train Epoch: [26][105/129]	Time  0.952 ( 1.824)	Data  0.001 ( 0.870)	Loss 7.5538e-02 (9.4440e-02) 
2023-05-25 22:12:54.968367: train Epoch: [26][106/129]	Time  2.834 ( 1.833)	Data  1.878 ( 0.879)	Loss 7.7010e-02 (9.4277e-02) 
2023-05-25 22:12:55.918119: train Epoch: [26][107/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.871)	Loss 1.4141e-01 (9.4714e-02) 
2023-05-25 22:12:58.584691: train Epoch: [26][108/129]	Time  2.667 ( 1.833)	Data  1.721 ( 0.879)	Loss 1.0557e-01 (9.4813e-02) 
2023-05-25 22:12:59.535617: train Epoch: [26][109/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.871)	Loss 1.0305e-01 (9.4888e-02) 
2023-05-25 22:13:02.284109: train Epoch: [26][110/129]	Time  2.748 ( 1.833)	Data  1.801 ( 0.879)	Loss 1.1111e-01 (9.5034e-02) 
2023-05-25 22:13:03.235490: train Epoch: [26][111/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.871)	Loss 7.8590e-02 (9.4888e-02) 
2023-05-25 22:13:05.818928: train Epoch: [26][112/129]	Time  2.583 ( 1.832)	Data  1.627 ( 0.878)	Loss 1.1936e-01 (9.5104e-02) 
2023-05-25 22:13:06.769517: train Epoch: [26][113/129]	Time  0.951 ( 1.824)	Data  0.001 ( 0.870)	Loss 6.9203e-02 (9.4877e-02) 
2023-05-25 22:13:09.349762: train Epoch: [26][114/129]	Time  2.580 ( 1.831)	Data  1.633 ( 0.877)	Loss 1.2178e-01 (9.5111e-02) 
2023-05-25 22:13:10.298562: train Epoch: [26][115/129]	Time  0.949 ( 1.823)	Data  0.001 ( 0.869)	Loss 8.0522e-02 (9.4985e-02) 
2023-05-25 22:13:12.962793: train Epoch: [26][116/129]	Time  2.664 ( 1.830)	Data  1.715 ( 0.877)	Loss 8.5711e-02 (9.4906e-02) 
2023-05-25 22:13:13.911659: train Epoch: [26][117/129]	Time  0.949 ( 1.823)	Data  0.001 ( 0.869)	Loss 6.5010e-02 (9.4652e-02) 
2023-05-25 22:13:16.546739: train Epoch: [26][118/129]	Time  2.635 ( 1.830)	Data  1.685 ( 0.876)	Loss 1.2169e-01 (9.4880e-02) 
2023-05-25 22:13:17.496566: train Epoch: [26][119/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.869)	Loss 7.7655e-02 (9.4736e-02) 
2023-05-25 22:13:20.143888: train Epoch: [26][120/129]	Time  2.647 ( 1.829)	Data  1.700 ( 0.876)	Loss 1.1054e-01 (9.4867e-02) 
2023-05-25 22:13:21.094350: train Epoch: [26][121/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.868)	Loss 7.9663e-02 (9.4742e-02) 
2023-05-25 22:13:23.737869: train Epoch: [26][122/129]	Time  2.644 ( 1.828)	Data  1.690 ( 0.875)	Loss 6.4371e-02 (9.4495e-02) 
2023-05-25 22:13:24.690121: train Epoch: [26][123/129]	Time  0.952 ( 1.821)	Data  0.001 ( 0.868)	Loss 9.2944e-02 (9.4483e-02) 
2023-05-25 22:13:27.443138: train Epoch: [26][124/129]	Time  2.753 ( 1.829)	Data  1.806 ( 0.876)	Loss 4.7832e-02 (9.4109e-02) 
2023-05-25 22:13:28.393625: train Epoch: [26][125/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.869)	Loss 1.7038e-01 (9.4715e-02) 
2023-05-25 22:13:31.070877: train Epoch: [26][126/129]	Time  2.677 ( 1.829)	Data  1.729 ( 0.875)	Loss 1.0361e-01 (9.4785e-02) 
2023-05-25 22:13:32.018813: train Epoch: [26][127/129]	Time  0.948 ( 1.822)	Data  0.001 ( 0.869)	Loss 1.3274e-01 (9.5081e-02) 
2023-05-25 22:13:33.600951: train Epoch: [26][128/129]	Time  1.582 ( 1.820)	Data  0.637 ( 0.867)	Loss 7.1772e-02 (9.4901e-02) 
2023-05-25 22:13:33.632698: Train Epoch done in 234.7980528199987 s 
2023-05-25 22:13:36.007140: val Epoch: [26][ 0/72]	Time  1.605 ( 1.605)	Data  1.435 ( 1.435)	Loss 7.4857e-02 (7.4857e-02) 
2023-05-25 22:13:36.124108: val Epoch: [26][ 1/72]	Time  0.117 ( 0.861)	Data  0.001 ( 0.718)	Loss 8.6135e-02 (8.0496e-02) 
2023-05-25 22:13:37.197381: val Epoch: [26][ 2/72]	Time  1.073 ( 0.932)	Data  0.956 ( 0.797)	Loss 8.7496e-02 (8.2829e-02) 
2023-05-25 22:13:37.314389: val Epoch: [26][ 3/72]	Time  0.117 ( 0.728)	Data  0.000 ( 0.598)	Loss 5.6751e-02 (7.6310e-02) 
2023-05-25 22:13:38.453476: val Epoch: [26][ 4/72]	Time  1.139 ( 0.810)	Data  1.022 ( 0.683)	Loss 8.7415e-02 (7.8531e-02) 
2023-05-25 22:13:38.570028: val Epoch: [26][ 5/72]	Time  0.117 ( 0.695)	Data  0.000 ( 0.569)	Loss 1.0961e-01 (8.3710e-02) 
2023-05-25 22:13:39.714883: val Epoch: [26][ 6/72]	Time  1.145 ( 0.759)	Data  1.028 ( 0.635)	Loss 5.0955e-02 (7.9031e-02) 
2023-05-25 22:13:39.831187: val Epoch: [26][ 7/72]	Time  0.116 ( 0.679)	Data  0.000 ( 0.555)	Loss 2.6316e-01 (1.0205e-01) 
2023-05-25 22:13:41.005838: val Epoch: [26][ 8/72]	Time  1.175 ( 0.734)	Data  1.058 ( 0.611)	Loss 2.7390e-01 (1.2114e-01) 
2023-05-25 22:13:41.122391: val Epoch: [26][ 9/72]	Time  0.117 ( 0.672)	Data  0.000 ( 0.550)	Loss 1.0586e-01 (1.1961e-01) 
2023-05-25 22:13:42.216249: val Epoch: [26][10/72]	Time  1.094 ( 0.710)	Data  0.977 ( 0.589)	Loss 5.3035e-02 (1.1356e-01) 
2023-05-25 22:13:42.333417: val Epoch: [26][11/72]	Time  0.117 ( 0.661)	Data  0.000 ( 0.540)	Loss 3.3932e-01 (1.3237e-01) 
2023-05-25 22:13:43.440433: val Epoch: [26][12/72]	Time  1.107 ( 0.695)	Data  0.987 ( 0.574)	Loss 3.6680e-02 (1.2501e-01) 
2023-05-25 22:13:43.556830: val Epoch: [26][13/72]	Time  0.116 ( 0.654)	Data  0.000 ( 0.533)	Loss 1.7325e-01 (1.2846e-01) 
2023-05-25 22:13:44.628257: val Epoch: [26][14/72]	Time  1.071 ( 0.682)	Data  0.951 ( 0.561)	Loss 4.7180e-02 (1.2304e-01) 
2023-05-25 22:13:44.744461: val Epoch: [26][15/72]	Time  0.116 ( 0.646)	Data  0.000 ( 0.526)	Loss 7.5189e-02 (1.2005e-01) 
2023-05-25 22:13:45.902144: val Epoch: [26][16/72]	Time  1.158 ( 0.676)	Data  1.038 ( 0.556)	Loss 1.4372e-01 (1.2144e-01) 
2023-05-25 22:13:46.018449: val Epoch: [26][17/72]	Time  0.116 ( 0.645)	Data  0.000 ( 0.525)	Loss 1.3605e-01 (1.2225e-01) 
2023-05-25 22:13:47.138134: val Epoch: [26][18/72]	Time  1.120 ( 0.670)	Data  1.002 ( 0.550)	Loss 5.5389e-02 (1.1873e-01) 
2023-05-25 22:13:47.254049: val Epoch: [26][19/72]	Time  0.116 ( 0.643)	Data  0.000 ( 0.523)	Loss 1.2437e-01 (1.1902e-01) 
2023-05-25 22:13:48.420844: val Epoch: [26][20/72]	Time  1.167 ( 0.668)	Data  1.048 ( 0.548)	Loss 3.7356e-01 (1.3114e-01) 
2023-05-25 22:13:48.536708: val Epoch: [26][21/72]	Time  0.116 ( 0.642)	Data  0.000 ( 0.523)	Loss 1.0749e-01 (1.3006e-01) 
2023-05-25 22:13:49.694953: val Epoch: [26][22/72]	Time  1.158 ( 0.665)	Data  1.041 ( 0.546)	Loss 6.6414e-02 (1.2729e-01) 
2023-05-25 22:13:49.810956: val Epoch: [26][23/72]	Time  0.116 ( 0.642)	Data  0.001 ( 0.523)	Loss 9.0925e-02 (1.2578e-01) 
2023-05-25 22:13:51.026209: val Epoch: [26][24/72]	Time  1.215 ( 0.665)	Data  1.099 ( 0.546)	Loss 5.5510e-02 (1.2297e-01) 
2023-05-25 22:13:51.142471: val Epoch: [26][25/72]	Time  0.116 ( 0.644)	Data  0.000 ( 0.525)	Loss 6.8963e-02 (1.2089e-01) 
2023-05-25 22:13:52.289114: val Epoch: [26][26/72]	Time  1.147 ( 0.662)	Data  1.030 ( 0.544)	Loss 5.1825e-02 (1.1833e-01) 
2023-05-25 22:13:52.405039: val Epoch: [26][27/72]	Time  0.116 ( 0.643)	Data  0.000 ( 0.524)	Loss 7.6912e-02 (1.1685e-01) 
2023-05-25 22:13:53.525037: val Epoch: [26][28/72]	Time  1.120 ( 0.659)	Data  1.003 ( 0.541)	Loss 4.0300e-02 (1.1421e-01) 
2023-05-25 22:13:53.641071: val Epoch: [26][29/72]	Time  0.116 ( 0.641)	Data  0.000 ( 0.523)	Loss 1.6307e-01 (1.1584e-01) 
2023-05-25 22:13:54.752858: val Epoch: [26][30/72]	Time  1.112 ( 0.656)	Data  0.995 ( 0.538)	Loss 5.0456e-02 (1.1373e-01) 
2023-05-25 22:13:54.869079: val Epoch: [26][31/72]	Time  0.116 ( 0.640)	Data  0.000 ( 0.521)	Loss 2.3858e-01 (1.1763e-01) 
2023-05-25 22:13:55.962758: val Epoch: [26][32/72]	Time  1.094 ( 0.653)	Data  0.977 ( 0.535)	Loss 1.8971e-01 (1.1982e-01) 
2023-05-25 22:13:56.079030: val Epoch: [26][33/72]	Time  0.116 ( 0.638)	Data  0.000 ( 0.519)	Loss 6.6174e-02 (1.1824e-01) 
2023-05-25 22:13:57.222527: val Epoch: [26][34/72]	Time  1.143 ( 0.652)	Data  1.026 ( 0.534)	Loss 2.1535e-01 (1.2102e-01) 
2023-05-25 22:13:57.339080: val Epoch: [26][35/72]	Time  0.117 ( 0.637)	Data  0.000 ( 0.519)	Loss 6.2785e-02 (1.1940e-01) 
2023-05-25 22:13:58.471744: val Epoch: [26][36/72]	Time  1.133 ( 0.651)	Data  1.016 ( 0.532)	Loss 6.6767e-02 (1.1798e-01) 
2023-05-25 22:13:58.588607: val Epoch: [26][37/72]	Time  0.117 ( 0.636)	Data  0.000 ( 0.518)	Loss 7.9032e-02 (1.1695e-01) 
2023-05-25 22:13:59.732898: val Epoch: [26][38/72]	Time  1.144 ( 0.650)	Data  1.028 ( 0.531)	Loss 9.4585e-02 (1.1638e-01) 
2023-05-25 22:13:59.849083: val Epoch: [26][39/72]	Time  0.116 ( 0.636)	Data  0.001 ( 0.518)	Loss 1.1826e-01 (1.1642e-01) 
2023-05-25 22:14:00.929895: val Epoch: [26][40/72]	Time  1.081 ( 0.647)	Data  0.964 ( 0.529)	Loss 6.0350e-02 (1.1506e-01) 
2023-05-25 22:14:01.046700: val Epoch: [26][41/72]	Time  0.117 ( 0.634)	Data  0.001 ( 0.516)	Loss 4.7957e-02 (1.1346e-01) 
2023-05-25 22:14:02.178269: val Epoch: [26][42/72]	Time  1.132 ( 0.646)	Data  1.015 ( 0.528)	Loss 1.6943e-01 (1.1476e-01) 
2023-05-25 22:14:02.296184: val Epoch: [26][43/72]	Time  0.118 ( 0.634)	Data  0.000 ( 0.516)	Loss 4.4087e-01 (1.2217e-01) 
2023-05-25 22:14:03.430456: val Epoch: [26][44/72]	Time  1.134 ( 0.645)	Data  1.018 ( 0.527)	Loss 3.8409e-01 (1.2799e-01) 
2023-05-25 22:14:03.546373: val Epoch: [26][45/72]	Time  0.116 ( 0.634)	Data  0.000 ( 0.516)	Loss 1.4864e-01 (1.2844e-01) 
2023-05-25 22:14:04.650954: val Epoch: [26][46/72]	Time  1.105 ( 0.644)	Data  0.988 ( 0.526)	Loss 5.9352e-02 (1.2697e-01) 
2023-05-25 22:14:04.767123: val Epoch: [26][47/72]	Time  0.116 ( 0.633)	Data  0.000 ( 0.515)	Loss 8.0775e-02 (1.2601e-01) 
2023-05-25 22:14:05.935247: val Epoch: [26][48/72]	Time  1.168 ( 0.644)	Data  1.052 ( 0.526)	Loss 1.7708e-01 (1.2705e-01) 
2023-05-25 22:14:06.051550: val Epoch: [26][49/72]	Time  0.116 ( 0.633)	Data  0.001 ( 0.515)	Loss 6.7083e-02 (1.2585e-01) 
2023-05-25 22:14:07.173509: val Epoch: [26][50/72]	Time  1.122 ( 0.643)	Data  1.005 ( 0.525)	Loss 4.3446e-01 (1.3190e-01) 
2023-05-25 22:14:07.290086: val Epoch: [26][51/72]	Time  0.117 ( 0.632)	Data  0.000 ( 0.515)	Loss 4.4043e-02 (1.3021e-01) 
2023-05-25 22:14:08.423600: val Epoch: [26][52/72]	Time  1.134 ( 0.642)	Data  1.016 ( 0.524)	Loss 5.4064e-01 (1.3796e-01) 
2023-05-25 22:14:08.540407: val Epoch: [26][53/72]	Time  0.117 ( 0.632)	Data  0.000 ( 0.515)	Loss 1.0930e-01 (1.3743e-01) 
2023-05-25 22:14:09.638140: val Epoch: [26][54/72]	Time  1.098 ( 0.641)	Data  0.981 ( 0.523)	Loss 6.5949e-02 (1.3613e-01) 
2023-05-25 22:14:09.753744: val Epoch: [26][55/72]	Time  0.116 ( 0.631)	Data  0.000 ( 0.514)	Loss 9.0924e-02 (1.3532e-01) 
2023-05-25 22:14:10.903340: val Epoch: [26][56/72]	Time  1.150 ( 0.640)	Data  1.033 ( 0.523)	Loss 6.5623e-02 (1.3410e-01) 
2023-05-25 22:14:11.019334: val Epoch: [26][57/72]	Time  0.116 ( 0.631)	Data  0.000 ( 0.514)	Loss 5.1676e-01 (1.4069e-01) 
2023-05-25 22:14:12.142051: val Epoch: [26][58/72]	Time  1.123 ( 0.640)	Data  1.006 ( 0.522)	Loss 9.8314e-02 (1.3998e-01) 
2023-05-25 22:14:12.259083: val Epoch: [26][59/72]	Time  0.117 ( 0.631)	Data  0.001 ( 0.513)	Loss 2.1470e-01 (1.4122e-01) 
2023-05-25 22:14:13.354079: val Epoch: [26][60/72]	Time  1.095 ( 0.639)	Data  0.978 ( 0.521)	Loss 4.8072e-02 (1.3969e-01) 
2023-05-25 22:14:13.471051: val Epoch: [26][61/72]	Time  0.117 ( 0.630)	Data  0.001 ( 0.513)	Loss 5.2167e-02 (1.3828e-01) 
2023-05-25 22:14:14.556531: val Epoch: [26][62/72]	Time  1.085 ( 0.637)	Data  0.969 ( 0.520)	Loss 6.9153e-02 (1.3719e-01) 
2023-05-25 22:14:14.672795: val Epoch: [26][63/72]	Time  0.116 ( 0.629)	Data  0.000 ( 0.512)	Loss 1.2209e-01 (1.3695e-01) 
2023-05-25 22:14:15.806020: val Epoch: [26][64/72]	Time  1.133 ( 0.637)	Data  1.017 ( 0.520)	Loss 3.7176e-01 (1.4056e-01) 
2023-05-25 22:14:15.921868: val Epoch: [26][65/72]	Time  0.116 ( 0.629)	Data  0.000 ( 0.512)	Loss 8.5523e-02 (1.3973e-01) 
2023-05-25 22:14:17.057757: val Epoch: [26][66/72]	Time  1.136 ( 0.637)	Data  1.020 ( 0.519)	Loss 1.3121e-01 (1.3960e-01) 
2023-05-25 22:14:17.173512: val Epoch: [26][67/72]	Time  0.116 ( 0.629)	Data  0.000 ( 0.512)	Loss 3.4342e-01 (1.4260e-01) 
2023-05-25 22:14:18.347487: val Epoch: [26][68/72]	Time  1.174 ( 0.637)	Data  1.057 ( 0.520)	Loss 7.3357e-02 (1.4160e-01) 
2023-05-25 22:14:18.465433: val Epoch: [26][69/72]	Time  0.118 ( 0.629)	Data  0.000 ( 0.512)	Loss 1.5605e-01 (1.4180e-01) 
2023-05-25 22:14:19.490245: val Epoch: [26][70/72]	Time  1.025 ( 0.635)	Data  0.909 ( 0.518)	Loss 1.4880e-01 (1.4190e-01) 
2023-05-25 22:14:19.605473: val Epoch: [26][71/72]	Time  0.115 ( 0.628)	Data  0.000 ( 0.511)	Loss 8.3834e-02 (1.4109e-01) 
2023-05-25 22:14:19.782183: Epoch 26 :Val : ['ET : 0.7168253660202026', 'TC : 0.7539278864860535', 'WT : 0.8464421629905701'] 
2023-05-25 22:14:19.784976: Epoch 26 :Val : ['ET : 0.7168253660202026', 'TC : 0.7539278864860535', 'WT : 0.8464421629905701'] 
2023-05-25 22:14:19.787023: Val epoch done in 46.154332778000025 s 
2023-05-25 22:14:19.792431: Batches per epoch:  129 
2023-05-25 22:14:24.752514: train Epoch: [27][  0/129]	Time  4.960 ( 4.960)	Data  3.955 ( 3.955)	Loss 2.4119e-01 (2.4119e-01) 
2023-05-25 22:14:25.703072: train Epoch: [27][  1/129]	Time  0.951 ( 2.955)	Data  0.001 ( 1.978)	Loss 7.7610e-02 (1.5940e-01) 
2023-05-25 22:14:28.413049: train Epoch: [27][  2/129]	Time  2.710 ( 2.873)	Data  1.763 ( 1.906)	Loss 9.4382e-02 (1.3773e-01) 
2023-05-25 22:14:29.360193: train Epoch: [27][  3/129]	Time  0.947 ( 2.392)	Data  0.001 ( 1.430)	Loss 8.1373e-02 (1.2364e-01) 
2023-05-25 22:14:32.012654: train Epoch: [27][  4/129]	Time  2.652 ( 2.444)	Data  1.707 ( 1.485)	Loss 6.2044e-02 (1.1132e-01) 
2023-05-25 22:14:32.961069: train Epoch: [27][  5/129]	Time  0.948 ( 2.195)	Data  0.001 ( 1.238)	Loss 1.1146e-01 (1.1134e-01) 
2023-05-25 22:14:35.634647: train Epoch: [27][  6/129]	Time  2.674 ( 2.263)	Data  1.728 ( 1.308)	Loss 9.1617e-02 (1.0852e-01) 
2023-05-25 22:14:36.588892: train Epoch: [27][  7/129]	Time  0.954 ( 2.100)	Data  0.001 ( 1.145)	Loss 9.5710e-02 (1.0692e-01) 
2023-05-25 22:14:39.283061: train Epoch: [27][  8/129]	Time  2.694 ( 2.166)	Data  1.750 ( 1.212)	Loss 1.0585e-01 (1.0680e-01) 
2023-05-25 22:14:40.234340: train Epoch: [27][  9/129]	Time  0.951 ( 2.044)	Data  0.001 ( 1.091)	Loss 9.4142e-02 (1.0554e-01) 
2023-05-25 22:14:42.886187: train Epoch: [27][ 10/129]	Time  2.652 ( 2.099)	Data  1.705 ( 1.147)	Loss 7.4354e-02 (1.0270e-01) 
2023-05-25 22:14:43.835365: train Epoch: [27][ 11/129]	Time  0.949 ( 2.004)	Data  0.001 ( 1.051)	Loss 1.8937e-01 (1.0993e-01) 
2023-05-25 22:14:46.451471: train Epoch: [27][ 12/129]	Time  2.616 ( 2.051)	Data  1.671 ( 1.099)	Loss 5.7158e-02 (1.0587e-01) 
2023-05-25 22:14:47.401815: train Epoch: [27][ 13/129]	Time  0.950 ( 1.972)	Data  0.001 ( 1.020)	Loss 1.0108e-01 (1.0552e-01) 
2023-05-25 22:14:50.049871: train Epoch: [27][ 14/129]	Time  2.648 ( 2.017)	Data  1.702 ( 1.066)	Loss 1.0135e-01 (1.0525e-01) 
2023-05-25 22:14:50.999442: train Epoch: [27][ 15/129]	Time  0.950 ( 1.950)	Data  0.001 ( 0.999)	Loss 7.4722e-02 (1.0334e-01) 
2023-05-25 22:14:53.661642: train Epoch: [27][ 16/129]	Time  2.662 ( 1.992)	Data  1.716 ( 1.041)	Loss 8.5900e-02 (1.0231e-01) 
2023-05-25 22:14:54.611315: train Epoch: [27][ 17/129]	Time  0.950 ( 1.934)	Data  0.001 ( 0.984)	Loss 5.9081e-02 (9.9911e-02) 
2023-05-25 22:14:57.195807: train Epoch: [27][ 18/129]	Time  2.584 ( 1.969)	Data  1.636 ( 1.018)	Loss 1.3964e-01 (1.0200e-01) 
2023-05-25 22:14:58.145394: train Epoch: [27][ 19/129]	Time  0.950 ( 1.918)	Data  0.001 ( 0.967)	Loss 9.4935e-02 (1.0165e-01) 
2023-05-25 22:15:00.842121: train Epoch: [27][ 20/129]	Time  2.697 ( 1.955)	Data  1.751 ( 1.004)	Loss 1.0735e-01 (1.0192e-01) 
2023-05-25 22:15:01.792228: train Epoch: [27][ 21/129]	Time  0.950 ( 1.909)	Data  0.001 ( 0.959)	Loss 6.8072e-02 (1.0038e-01) 
2023-05-25 22:15:04.527698: train Epoch: [27][ 22/129]	Time  2.735 ( 1.945)	Data  1.789 ( 0.995)	Loss 1.9839e-01 (1.0464e-01) 
2023-05-25 22:15:05.481803: train Epoch: [27][ 23/129]	Time  0.954 ( 1.904)	Data  0.001 ( 0.953)	Loss 7.8555e-02 (1.0356e-01) 
2023-05-25 22:15:08.166704: train Epoch: [27][ 24/129]	Time  2.685 ( 1.935)	Data  1.738 ( 0.985)	Loss 8.7190e-02 (1.0290e-01) 
2023-05-25 22:15:09.119094: train Epoch: [27][ 25/129]	Time  0.952 ( 1.897)	Data  0.001 ( 0.947)	Loss 7.2432e-02 (1.0173e-01) 
2023-05-25 22:15:11.819756: train Epoch: [27][ 26/129]	Time  2.701 ( 1.927)	Data  1.755 ( 0.977)	Loss 1.3641e-01 (1.0301e-01) 
2023-05-25 22:15:12.768954: train Epoch: [27][ 27/129]	Time  0.949 ( 1.892)	Data  0.001 ( 0.942)	Loss 5.2520e-02 (1.0121e-01) 
2023-05-25 22:15:15.403422: train Epoch: [27][ 28/129]	Time  2.634 ( 1.918)	Data  1.689 ( 0.968)	Loss 9.6888e-02 (1.0106e-01) 
2023-05-25 22:15:16.351237: train Epoch: [27][ 29/129]	Time  0.948 ( 1.885)	Data  0.001 ( 0.936)	Loss 1.3375e-01 (1.0215e-01) 
2023-05-25 22:15:19.016171: train Epoch: [27][ 30/129]	Time  2.665 ( 1.910)	Data  1.720 ( 0.961)	Loss 1.0367e-01 (1.0220e-01) 
2023-05-25 22:15:19.965345: train Epoch: [27][ 31/129]	Time  0.949 ( 1.880)	Data  0.001 ( 0.931)	Loss 7.6327e-02 (1.0139e-01) 
2023-05-25 22:15:22.632104: train Epoch: [27][ 32/129]	Time  2.667 ( 1.904)	Data  1.722 ( 0.955)	Loss 2.6477e-01 (1.0634e-01) 
2023-05-25 22:15:23.580472: train Epoch: [27][ 33/129]	Time  0.948 ( 1.876)	Data  0.001 ( 0.927)	Loss 1.1851e-01 (1.0670e-01) 
2023-05-25 22:15:26.179920: train Epoch: [27][ 34/129]	Time  2.599 ( 1.897)	Data  1.654 ( 0.948)	Loss 6.2315e-02 (1.0543e-01) 
2023-05-25 22:15:27.129634: train Epoch: [27][ 35/129]	Time  0.950 ( 1.870)	Data  0.001 ( 0.921)	Loss 7.0626e-02 (1.0447e-01) 
2023-05-25 22:15:29.717645: train Epoch: [27][ 36/129]	Time  2.588 ( 1.890)	Data  1.642 ( 0.941)	Loss 9.5180e-02 (1.0421e-01) 
2023-05-25 22:15:30.666681: train Epoch: [27][ 37/129]	Time  0.949 ( 1.865)	Data  0.001 ( 0.916)	Loss 1.1215e-01 (1.0442e-01) 
2023-05-25 22:15:33.403045: train Epoch: [27][ 38/129]	Time  2.736 ( 1.887)	Data  1.791 ( 0.938)	Loss 7.4107e-02 (1.0365e-01) 
2023-05-25 22:15:34.352800: train Epoch: [27][ 39/129]	Time  0.950 ( 1.864)	Data  0.001 ( 0.915)	Loss 1.1574e-01 (1.0395e-01) 
2023-05-25 22:15:37.095632: train Epoch: [27][ 40/129]	Time  2.743 ( 1.885)	Data  1.785 ( 0.936)	Loss 7.0734e-02 (1.0314e-01) 
2023-05-25 22:15:38.045531: train Epoch: [27][ 41/129]	Time  0.950 ( 1.863)	Data  0.001 ( 0.914)	Loss 1.0579e-01 (1.0320e-01) 
2023-05-25 22:15:40.818075: train Epoch: [27][ 42/129]	Time  2.773 ( 1.884)	Data  1.815 ( 0.935)	Loss 8.8158e-02 (1.0285e-01) 
2023-05-25 22:15:41.778518: train Epoch: [27][ 43/129]	Time  0.960 ( 1.863)	Data  0.001 ( 0.914)	Loss 7.6659e-02 (1.0226e-01) 
2023-05-25 22:15:44.470498: train Epoch: [27][ 44/129]	Time  2.692 ( 1.882)	Data  1.729 ( 0.932)	Loss 1.0557e-01 (1.0233e-01) 
2023-05-25 22:15:45.430059: train Epoch: [27][ 45/129]	Time  0.960 ( 1.862)	Data  0.001 ( 0.912)	Loss 8.7913e-02 (1.0202e-01) 
2023-05-25 22:15:48.108719: train Epoch: [27][ 46/129]	Time  2.679 ( 1.879)	Data  1.719 ( 0.929)	Loss 8.6082e-02 (1.0168e-01) 
2023-05-25 22:15:49.063770: train Epoch: [27][ 47/129]	Time  0.955 ( 1.860)	Data  0.001 ( 0.909)	Loss 1.5002e-01 (1.0268e-01) 
2023-05-25 22:15:51.761883: train Epoch: [27][ 48/129]	Time  2.698 ( 1.877)	Data  1.750 ( 0.927)	Loss 1.8218e-01 (1.0431e-01) 
2023-05-25 22:15:52.712370: train Epoch: [27][ 49/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.908)	Loss 1.2013e-01 (1.0462e-01) 
2023-05-25 22:15:55.513972: train Epoch: [27][ 50/129]	Time  2.802 ( 1.877)	Data  1.855 ( 0.927)	Loss 6.7526e-02 (1.0390e-01) 
2023-05-25 22:15:56.465323: train Epoch: [27][ 51/129]	Time  0.951 ( 1.859)	Data  0.001 ( 0.909)	Loss 1.1620e-01 (1.0413e-01) 
2023-05-25 22:15:59.220860: train Epoch: [27][ 52/129]	Time  2.756 ( 1.876)	Data  1.797 ( 0.926)	Loss 9.3968e-02 (1.0394e-01) 
2023-05-25 22:16:00.170045: train Epoch: [27][ 53/129]	Time  0.949 ( 1.859)	Data  0.001 ( 0.909)	Loss 9.4071e-02 (1.0376e-01) 
2023-05-25 22:16:03.035565: train Epoch: [27][ 54/129]	Time  2.866 ( 1.877)	Data  1.906 ( 0.927)	Loss 7.3468e-02 (1.0321e-01) 
2023-05-25 22:16:03.986676: train Epoch: [27][ 55/129]	Time  0.951 ( 1.861)	Data  0.001 ( 0.910)	Loss 1.2950e-01 (1.0368e-01) 
2023-05-25 22:16:06.676275: train Epoch: [27][ 56/129]	Time  2.690 ( 1.875)	Data  1.732 ( 0.925)	Loss 8.9861e-02 (1.0343e-01) 
2023-05-25 22:16:07.627586: train Epoch: [27][ 57/129]	Time  0.951 ( 1.859)	Data  0.001 ( 0.909)	Loss 8.3004e-02 (1.0308e-01) 
2023-05-25 22:16:10.220826: train Epoch: [27][ 58/129]	Time  2.593 ( 1.872)	Data  1.642 ( 0.921)	Loss 7.4316e-02 (1.0259e-01) 
2023-05-25 22:16:11.170673: train Epoch: [27][ 59/129]	Time  0.950 ( 1.856)	Data  0.001 ( 0.906)	Loss 7.2575e-02 (1.0209e-01) 
2023-05-25 22:16:13.799339: train Epoch: [27][ 60/129]	Time  2.629 ( 1.869)	Data  1.680 ( 0.918)	Loss 7.8833e-02 (1.0171e-01) 
2023-05-25 22:16:14.748443: train Epoch: [27][ 61/129]	Time  0.949 ( 1.854)	Data  0.001 ( 0.904)	Loss 9.0603e-02 (1.0153e-01) 
2023-05-25 22:16:17.424806: train Epoch: [27][ 62/129]	Time  2.676 ( 1.867)	Data  1.721 ( 0.917)	Loss 8.2574e-02 (1.0123e-01) 
2023-05-25 22:16:18.374478: train Epoch: [27][ 63/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.902)	Loss 6.8468e-02 (1.0072e-01) 
2023-05-25 22:16:20.959799: train Epoch: [27][ 64/129]	Time  2.585 ( 1.864)	Data  1.624 ( 0.913)	Loss 8.1818e-02 (1.0043e-01) 
2023-05-25 22:16:21.911061: train Epoch: [27][ 65/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.900)	Loss 6.5575e-02 (9.9902e-02) 
2023-05-25 22:16:24.501221: train Epoch: [27][ 66/129]	Time  2.590 ( 1.861)	Data  1.642 ( 0.911)	Loss 9.4491e-02 (9.9821e-02) 
2023-05-25 22:16:25.452503: train Epoch: [27][ 67/129]	Time  0.951 ( 1.848)	Data  0.001 ( 0.897)	Loss 8.2614e-02 (9.9568e-02) 
2023-05-25 22:16:28.059561: train Epoch: [27][ 68/129]	Time  2.607 ( 1.859)	Data  1.652 ( 0.908)	Loss 1.1335e-01 (9.9768e-02) 
2023-05-25 22:16:29.010701: train Epoch: [27][ 69/129]	Time  0.951 ( 1.846)	Data  0.001 ( 0.895)	Loss 1.2198e-01 (1.0009e-01) 
2023-05-25 22:16:31.595999: train Epoch: [27][ 70/129]	Time  2.585 ( 1.856)	Data  1.633 ( 0.906)	Loss 9.1378e-02 (9.9963e-02) 
2023-05-25 22:16:32.546490: train Epoch: [27][ 71/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.893)	Loss 7.5885e-02 (9.9628e-02) 
2023-05-25 22:16:35.277628: train Epoch: [27][ 72/129]	Time  2.731 ( 1.856)	Data  1.782 ( 0.905)	Loss 4.9642e-02 (9.8943e-02) 
2023-05-25 22:16:36.229562: train Epoch: [27][ 73/129]	Time  0.952 ( 1.844)	Data  0.001 ( 0.893)	Loss 6.1827e-02 (9.8442e-02) 
2023-05-25 22:16:39.003798: train Epoch: [27][ 74/129]	Time  2.774 ( 1.856)	Data  1.805 ( 0.905)	Loss 1.0870e-01 (9.8579e-02) 
2023-05-25 22:16:39.964991: train Epoch: [27][ 75/129]	Time  0.961 ( 1.844)	Data  0.001 ( 0.893)	Loss 8.5045e-02 (9.8401e-02) 
2023-05-25 22:16:42.644311: train Epoch: [27][ 76/129]	Time  2.679 ( 1.855)	Data  1.720 ( 0.904)	Loss 6.7906e-02 (9.8005e-02) 
2023-05-25 22:16:43.594159: train Epoch: [27][ 77/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.892)	Loss 1.0303e-01 (9.8069e-02) 
2023-05-25 22:16:46.206388: train Epoch: [27][ 78/129]	Time  2.612 ( 1.853)	Data  1.663 ( 0.902)	Loss 1.1052e-01 (9.8227e-02) 
2023-05-25 22:16:47.157016: train Epoch: [27][ 79/129]	Time  0.951 ( 1.842)	Data  0.001 ( 0.891)	Loss 5.2167e-02 (9.7651e-02) 
2023-05-25 22:16:49.738729: train Epoch: [27][ 80/129]	Time  2.582 ( 1.851)	Data  1.633 ( 0.900)	Loss 7.3647e-02 (9.7354e-02) 
2023-05-25 22:16:50.688058: train Epoch: [27][ 81/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.889)	Loss 1.0765e-01 (9.7480e-02) 
2023-05-25 22:16:53.428542: train Epoch: [27][ 82/129]	Time  2.740 ( 1.851)	Data  1.790 ( 0.900)	Loss 6.9453e-02 (9.7142e-02) 
2023-05-25 22:16:54.377901: train Epoch: [27][ 83/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.889)	Loss 1.0095e-01 (9.7188e-02) 
2023-05-25 22:16:57.076909: train Epoch: [27][ 84/129]	Time  2.699 ( 1.850)	Data  1.749 ( 0.899)	Loss 1.2801e-01 (9.7550e-02) 
2023-05-25 22:16:58.026591: train Epoch: [27][ 85/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.889)	Loss 6.8048e-02 (9.7207e-02) 
2023-05-25 22:17:00.817187: train Epoch: [27][ 86/129]	Time  2.791 ( 1.851)	Data  1.843 ( 0.900)	Loss 9.8621e-02 (9.7223e-02) 
2023-05-25 22:17:01.766572: train Epoch: [27][ 87/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.890)	Loss 8.9764e-02 (9.7139e-02) 
2023-05-25 22:17:04.423139: train Epoch: [27][ 88/129]	Time  2.657 ( 1.850)	Data  1.703 ( 0.899)	Loss 1.8718e-01 (9.8150e-02) 
2023-05-25 22:17:05.372171: train Epoch: [27][ 89/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.889)	Loss 9.0595e-02 (9.8066e-02) 
2023-05-25 22:17:08.095006: train Epoch: [27][ 90/129]	Time  2.723 ( 1.849)	Data  1.775 ( 0.899)	Loss 9.3874e-02 (9.8020e-02) 
2023-05-25 22:17:09.045506: train Epoch: [27][ 91/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.889)	Loss 8.0026e-02 (9.7825e-02) 
2023-05-25 22:17:11.707130: train Epoch: [27][ 92/129]	Time  2.662 ( 1.849)	Data  1.714 ( 0.898)	Loss 6.0311e-02 (9.7421e-02) 
2023-05-25 22:17:12.656010: train Epoch: [27][ 93/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.888)	Loss 4.8948e-02 (9.6906e-02) 
2023-05-25 22:17:15.314365: train Epoch: [27][ 94/129]	Time  2.658 ( 1.848)	Data  1.709 ( 0.897)	Loss 1.9829e-01 (9.7973e-02) 
2023-05-25 22:17:16.266051: train Epoch: [27][ 95/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.887)	Loss 1.2174e-01 (9.8220e-02) 
2023-05-25 22:17:19.019277: train Epoch: [27][ 96/129]	Time  2.753 ( 1.848)	Data  1.797 ( 0.897)	Loss 7.3482e-02 (9.7965e-02) 
2023-05-25 22:17:19.969652: train Epoch: [27][ 97/129]	Time  0.950 ( 1.839)	Data  0.001 ( 0.888)	Loss 9.5825e-02 (9.7944e-02) 
2023-05-25 22:17:22.619774: train Epoch: [27][ 98/129]	Time  2.650 ( 1.847)	Data  1.692 ( 0.896)	Loss 8.4006e-02 (9.7803e-02) 
2023-05-25 22:17:23.570432: train Epoch: [27][ 99/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.887)	Loss 8.1726e-02 (9.7642e-02) 
2023-05-25 22:17:26.201998: train Epoch: [27][100/129]	Time  2.632 ( 1.846)	Data  1.684 ( 0.895)	Loss 1.3513e-01 (9.8013e-02) 
2023-05-25 22:17:27.152907: train Epoch: [27][101/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.886)	Loss 1.2276e-01 (9.8256e-02) 
2023-05-25 22:17:30.043174: train Epoch: [27][102/129]	Time  2.890 ( 1.847)	Data  1.943 ( 0.896)	Loss 2.1706e-01 (9.9409e-02) 
2023-05-25 22:17:30.995871: train Epoch: [27][103/129]	Time  0.953 ( 1.838)	Data  0.001 ( 0.888)	Loss 5.8455e-02 (9.9016e-02) 
2023-05-25 22:17:33.756702: train Epoch: [27][104/129]	Time  2.761 ( 1.847)	Data  1.814 ( 0.896)	Loss 1.2499e-01 (9.9263e-02) 
2023-05-25 22:17:34.707878: train Epoch: [27][105/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.888)	Loss 2.1015e-01 (1.0031e-01) 
2023-05-25 22:17:37.485202: train Epoch: [27][106/129]	Time  2.777 ( 1.848)	Data  1.830 ( 0.897)	Loss 1.4656e-01 (1.0074e-01) 
2023-05-25 22:17:38.436014: train Epoch: [27][107/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.889)	Loss 7.1253e-02 (1.0047e-01) 
2023-05-25 22:17:41.076448: train Epoch: [27][108/129]	Time  2.640 ( 1.847)	Data  1.693 ( 0.896)	Loss 6.1932e-02 (1.0011e-01) 
2023-05-25 22:17:42.026732: train Epoch: [27][109/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.888)	Loss 9.8402e-02 (1.0010e-01) 
2023-05-25 22:17:44.711734: train Epoch: [27][110/129]	Time  2.685 ( 1.846)	Data  1.739 ( 0.895)	Loss 8.2321e-02 (9.9939e-02) 
2023-05-25 22:17:45.661295: train Epoch: [27][111/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.887)	Loss 7.6282e-02 (9.9728e-02) 
2023-05-25 22:17:48.362680: train Epoch: [27][112/129]	Time  2.701 ( 1.846)	Data  1.755 ( 0.895)	Loss 1.4118e-01 (1.0009e-01) 
2023-05-25 22:17:49.312471: train Epoch: [27][113/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.887)	Loss 1.5737e-01 (1.0060e-01) 
2023-05-25 22:17:51.917402: train Epoch: [27][114/129]	Time  2.605 ( 1.845)	Data  1.647 ( 0.894)	Loss 6.8891e-02 (1.0032e-01) 
2023-05-25 22:17:52.878970: train Epoch: [27][115/129]	Time  0.962 ( 1.837)	Data  0.001 ( 0.886)	Loss 8.4459e-02 (1.0018e-01) 
2023-05-25 22:17:55.536456: train Epoch: [27][116/129]	Time  2.657 ( 1.844)	Data  1.702 ( 0.893)	Loss 7.2551e-02 (9.9948e-02) 
2023-05-25 22:17:56.495259: train Epoch: [27][117/129]	Time  0.959 ( 1.836)	Data  0.001 ( 0.886)	Loss 1.7060e-01 (1.0055e-01) 
2023-05-25 22:17:59.180071: train Epoch: [27][118/129]	Time  2.685 ( 1.844)	Data  1.738 ( 0.893)	Loss 1.9387e-01 (1.0133e-01) 
2023-05-25 22:18:00.131158: train Epoch: [27][119/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.885)	Loss 1.1025e-01 (1.0141e-01) 
2023-05-25 22:18:02.851411: train Epoch: [27][120/129]	Time  2.720 ( 1.843)	Data  1.774 ( 0.893)	Loss 8.6758e-02 (1.0128e-01) 
2023-05-25 22:18:03.803104: train Epoch: [27][121/129]	Time  0.952 ( 1.836)	Data  0.001 ( 0.885)	Loss 1.2820e-01 (1.0151e-01) 
2023-05-25 22:18:06.532396: train Epoch: [27][122/129]	Time  2.729 ( 1.843)	Data  1.784 ( 0.893)	Loss 1.9249e-01 (1.0224e-01) 
2023-05-25 22:18:07.481918: train Epoch: [27][123/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.885)	Loss 1.8050e-01 (1.0288e-01) 
2023-05-25 22:18:10.044555: train Epoch: [27][124/129]	Time  2.563 ( 1.842)	Data  1.616 ( 0.891)	Loss 2.6217e-01 (1.0415e-01) 
2023-05-25 22:18:10.996105: train Epoch: [27][125/129]	Time  0.952 ( 1.835)	Data  0.001 ( 0.884)	Loss 6.8777e-02 (1.0387e-01) 
2023-05-25 22:18:13.615138: train Epoch: [27][126/129]	Time  2.619 ( 1.841)	Data  1.672 ( 0.890)	Loss 1.1609e-01 (1.0397e-01) 
2023-05-25 22:18:14.562317: train Epoch: [27][127/129]	Time  0.947 ( 1.834)	Data  0.001 ( 0.883)	Loss 9.8201e-02 (1.0392e-01) 
2023-05-25 22:18:16.082199: train Epoch: [27][128/129]	Time  1.520 ( 1.832)	Data  0.574 ( 0.881)	Loss 1.5969e-01 (1.0435e-01) 
2023-05-25 22:18:16.113083: Train Epoch done in 236.32067743299922 s 
2023-05-25 22:18:18.438268: val Epoch: [27][ 0/72]	Time  1.613 ( 1.613)	Data  1.437 ( 1.437)	Loss 1.0275e-01 (1.0275e-01) 
2023-05-25 22:18:18.555503: val Epoch: [27][ 1/72]	Time  0.117 ( 0.865)	Data  0.001 ( 0.719)	Loss 3.2648e-01 (2.1462e-01) 
2023-05-25 22:18:19.598423: val Epoch: [27][ 2/72]	Time  1.043 ( 0.924)	Data  0.925 ( 0.788)	Loss 6.6796e-02 (1.6534e-01) 
2023-05-25 22:18:19.716153: val Epoch: [27][ 3/72]	Time  0.118 ( 0.723)	Data  0.001 ( 0.591)	Loss 8.6530e-02 (1.4564e-01) 
2023-05-25 22:18:20.839411: val Epoch: [27][ 4/72]	Time  1.123 ( 0.803)	Data  1.006 ( 0.674)	Loss 5.9845e-02 (1.2848e-01) 
2023-05-25 22:18:20.962232: val Epoch: [27][ 5/72]	Time  0.123 ( 0.690)	Data  0.000 ( 0.562)	Loss 6.9010e-02 (1.1857e-01) 
2023-05-25 22:18:22.123826: val Epoch: [27][ 6/72]	Time  1.162 ( 0.757)	Data  1.037 ( 0.630)	Loss 1.7448e-01 (1.2656e-01) 
2023-05-25 22:18:22.240933: val Epoch: [27][ 7/72]	Time  0.117 ( 0.677)	Data  0.000 ( 0.551)	Loss 7.3040e-02 (1.1987e-01) 
2023-05-25 22:18:23.436946: val Epoch: [27][ 8/72]	Time  1.196 ( 0.735)	Data  1.078 ( 0.610)	Loss 8.2092e-02 (1.1567e-01) 
2023-05-25 22:18:23.553610: val Epoch: [27][ 9/72]	Time  0.117 ( 0.673)	Data  0.000 ( 0.549)	Loss 1.7074e-01 (1.2118e-01) 
2023-05-25 22:18:24.688471: val Epoch: [27][10/72]	Time  1.135 ( 0.715)	Data  1.017 ( 0.591)	Loss 2.3738e-01 (1.3174e-01) 
2023-05-25 22:18:24.805342: val Epoch: [27][11/72]	Time  0.117 ( 0.665)	Data  0.000 ( 0.542)	Loss 1.1144e-01 (1.3005e-01) 
2023-05-25 22:18:26.001468: val Epoch: [27][12/72]	Time  1.196 ( 0.706)	Data  1.077 ( 0.583)	Loss 5.4785e-02 (1.2426e-01) 
2023-05-25 22:18:26.118624: val Epoch: [27][13/72]	Time  0.117 ( 0.664)	Data  0.001 ( 0.542)	Loss 3.5872e-01 (1.4101e-01) 
2023-05-25 22:18:27.323766: val Epoch: [27][14/72]	Time  1.205 ( 0.700)	Data  1.088 ( 0.578)	Loss 6.5008e-02 (1.3594e-01) 
2023-05-25 22:18:27.440968: val Epoch: [27][15/72]	Time  0.117 ( 0.663)	Data  0.001 ( 0.542)	Loss 2.6450e-01 (1.4398e-01) 
2023-05-25 22:18:28.626376: val Epoch: [27][16/72]	Time  1.185 ( 0.694)	Data  1.067 ( 0.573)	Loss 9.2855e-02 (1.4097e-01) 
2023-05-25 22:18:28.743884: val Epoch: [27][17/72]	Time  0.118 ( 0.662)	Data  0.001 ( 0.541)	Loss 3.3844e-01 (1.5194e-01) 
2023-05-25 22:18:29.913961: val Epoch: [27][18/72]	Time  1.170 ( 0.689)	Data  1.053 ( 0.568)	Loss 4.6939e-01 (1.6865e-01) 
2023-05-25 22:18:30.030796: val Epoch: [27][19/72]	Time  0.117 ( 0.660)	Data  0.000 ( 0.540)	Loss 3.1467e-01 (1.7595e-01) 
2023-05-25 22:18:31.214335: val Epoch: [27][20/72]	Time  1.184 ( 0.685)	Data  1.066 ( 0.565)	Loss 1.2452e-01 (1.7350e-01) 
2023-05-25 22:18:31.331800: val Epoch: [27][21/72]	Time  0.117 ( 0.659)	Data  0.000 ( 0.539)	Loss 1.8916e-01 (1.7421e-01) 
2023-05-25 22:18:32.527594: val Epoch: [27][22/72]	Time  1.196 ( 0.683)	Data  1.079 ( 0.562)	Loss 2.6636e-01 (1.7822e-01) 
2023-05-25 22:18:32.644213: val Epoch: [27][23/72]	Time  0.117 ( 0.659)	Data  0.000 ( 0.539)	Loss 9.1783e-02 (1.7462e-01) 
2023-05-25 22:18:33.788600: val Epoch: [27][24/72]	Time  1.144 ( 0.679)	Data  1.027 ( 0.559)	Loss 1.3280e-01 (1.7294e-01) 
2023-05-25 22:18:33.904946: val Epoch: [27][25/72]	Time  0.116 ( 0.657)	Data  0.000 ( 0.537)	Loss 2.2635e-01 (1.7500e-01) 
2023-05-25 22:18:35.000531: val Epoch: [27][26/72]	Time  1.096 ( 0.673)	Data  0.978 ( 0.553)	Loss 2.0526e-01 (1.7612e-01) 
2023-05-25 22:18:35.117434: val Epoch: [27][27/72]	Time  0.117 ( 0.653)	Data  0.001 ( 0.534)	Loss 4.0771e-01 (1.8439e-01) 
2023-05-25 22:18:36.213727: val Epoch: [27][28/72]	Time  1.096 ( 0.669)	Data  0.979 ( 0.549)	Loss 5.3224e-02 (1.7987e-01) 
2023-05-25 22:18:36.331188: val Epoch: [27][29/72]	Time  0.117 ( 0.650)	Data  0.001 ( 0.531)	Loss 7.3093e-02 (1.7631e-01) 
2023-05-25 22:18:37.475130: val Epoch: [27][30/72]	Time  1.144 ( 0.666)	Data  1.024 ( 0.547)	Loss 1.0072e-01 (1.7387e-01) 
2023-05-25 22:18:37.597349: val Epoch: [27][31/72]	Time  0.122 ( 0.649)	Data  0.001 ( 0.530)	Loss 4.0207e-01 (1.8100e-01) 
2023-05-25 22:18:38.691622: val Epoch: [27][32/72]	Time  1.094 ( 0.663)	Data  0.972 ( 0.543)	Loss 2.5326e-01 (1.8319e-01) 
2023-05-25 22:18:38.812923: val Epoch: [27][33/72]	Time  0.121 ( 0.647)	Data  0.000 ( 0.527)	Loss 7.8162e-02 (1.8010e-01) 
2023-05-25 22:18:39.902892: val Epoch: [27][34/72]	Time  1.090 ( 0.659)	Data  0.968 ( 0.540)	Loss 4.7002e-01 (1.8838e-01) 
2023-05-25 22:18:40.024261: val Epoch: [27][35/72]	Time  0.121 ( 0.644)	Data  0.001 ( 0.525)	Loss 1.6114e-01 (1.8763e-01) 
2023-05-25 22:18:41.099466: val Epoch: [27][36/72]	Time  1.075 ( 0.656)	Data  0.954 ( 0.536)	Loss 5.4379e-02 (1.8403e-01) 
2023-05-25 22:18:41.220641: val Epoch: [27][37/72]	Time  0.121 ( 0.642)	Data  0.001 ( 0.522)	Loss 1.6956e-01 (1.8365e-01) 
2023-05-25 22:18:42.304061: val Epoch: [27][38/72]	Time  1.083 ( 0.653)	Data  0.962 ( 0.533)	Loss 4.6737e-02 (1.8014e-01) 
2023-05-25 22:18:42.425779: val Epoch: [27][39/72]	Time  0.122 ( 0.640)	Data  0.001 ( 0.520)	Loss 4.8474e-02 (1.7684e-01) 
2023-05-25 22:18:43.499475: val Epoch: [27][40/72]	Time  1.074 ( 0.651)	Data  0.952 ( 0.531)	Loss 1.4235e-01 (1.7600e-01) 
2023-05-25 22:18:43.620748: val Epoch: [27][41/72]	Time  0.121 ( 0.638)	Data  0.001 ( 0.518)	Loss 1.1262e-01 (1.7449e-01) 
2023-05-25 22:18:44.747810: val Epoch: [27][42/72]	Time  1.127 ( 0.649)	Data  1.009 ( 0.529)	Loss 2.1301e-01 (1.7539e-01) 
2023-05-25 22:18:44.864577: val Epoch: [27][43/72]	Time  0.117 ( 0.637)	Data  0.000 ( 0.517)	Loss 4.6445e-01 (1.8196e-01) 
2023-05-25 22:18:45.919999: val Epoch: [27][44/72]	Time  1.055 ( 0.647)	Data  0.938 ( 0.527)	Loss 6.6373e-02 (1.7939e-01) 
2023-05-25 22:18:46.036150: val Epoch: [27][45/72]	Time  0.116 ( 0.635)	Data  0.000 ( 0.515)	Loss 5.6713e-02 (1.7672e-01) 
2023-05-25 22:18:47.170359: val Epoch: [27][46/72]	Time  1.134 ( 0.646)	Data  1.017 ( 0.526)	Loss 9.1127e-02 (1.7490e-01) 
2023-05-25 22:18:47.286586: val Epoch: [27][47/72]	Time  0.116 ( 0.635)	Data  0.000 ( 0.515)	Loss 4.4578e-02 (1.7219e-01) 
2023-05-25 22:18:48.349642: val Epoch: [27][48/72]	Time  1.063 ( 0.643)	Data  0.946 ( 0.524)	Loss 7.7856e-02 (1.7026e-01) 
2023-05-25 22:18:48.470448: val Epoch: [27][49/72]	Time  0.121 ( 0.633)	Data  0.001 ( 0.513)	Loss 1.2897e-01 (1.6944e-01) 
2023-05-25 22:18:49.546411: val Epoch: [27][50/72]	Time  1.076 ( 0.642)	Data  0.958 ( 0.522)	Loss 9.9540e-02 (1.6807e-01) 
2023-05-25 22:18:49.663442: val Epoch: [27][51/72]	Time  0.117 ( 0.632)	Data  0.001 ( 0.512)	Loss 1.7407e-01 (1.6818e-01) 
2023-05-25 22:18:50.780925: val Epoch: [27][52/72]	Time  1.117 ( 0.641)	Data  1.000 ( 0.521)	Loss 3.3852e-01 (1.7139e-01) 
2023-05-25 22:18:50.897266: val Epoch: [27][53/72]	Time  0.116 ( 0.631)	Data  0.000 ( 0.512)	Loss 8.3252e-02 (1.6976e-01) 
2023-05-25 22:18:52.017559: val Epoch: [27][54/72]	Time  1.120 ( 0.640)	Data  1.003 ( 0.521)	Loss 6.7766e-02 (1.6791e-01) 
2023-05-25 22:18:52.134997: val Epoch: [27][55/72]	Time  0.117 ( 0.631)	Data  0.001 ( 0.511)	Loss 9.3633e-02 (1.6658e-01) 
2023-05-25 22:18:53.231553: val Epoch: [27][56/72]	Time  1.097 ( 0.639)	Data  0.979 ( 0.520)	Loss 9.5259e-02 (1.6533e-01) 
2023-05-25 22:18:53.348598: val Epoch: [27][57/72]	Time  0.117 ( 0.630)	Data  0.001 ( 0.511)	Loss 5.6394e-02 (1.6345e-01) 
2023-05-25 22:18:54.466493: val Epoch: [27][58/72]	Time  1.118 ( 0.638)	Data  1.001 ( 0.519)	Loss 1.0922e-01 (1.6253e-01) 
2023-05-25 22:18:54.582966: val Epoch: [27][59/72]	Time  0.116 ( 0.629)	Data  0.000 ( 0.510)	Loss 1.4858e-01 (1.6230e-01) 
2023-05-25 22:18:55.688028: val Epoch: [27][60/72]	Time  1.105 ( 0.637)	Data  0.988 ( 0.518)	Loss 2.4708e-01 (1.6369e-01) 
2023-05-25 22:18:55.804650: val Epoch: [27][61/72]	Time  0.117 ( 0.629)	Data  0.000 ( 0.510)	Loss 1.1346e-01 (1.6288e-01) 
2023-05-25 22:18:56.853032: val Epoch: [27][62/72]	Time  1.048 ( 0.635)	Data  0.931 ( 0.516)	Loss 4.7294e-02 (1.6105e-01) 
2023-05-25 22:18:56.969330: val Epoch: [27][63/72]	Time  0.116 ( 0.627)	Data  0.000 ( 0.508)	Loss 3.0314e-01 (1.6327e-01) 
2023-05-25 22:18:58.062627: val Epoch: [27][64/72]	Time  1.093 ( 0.634)	Data  0.976 ( 0.516)	Loss 5.3980e-02 (1.6158e-01) 
2023-05-25 22:18:58.179701: val Epoch: [27][65/72]	Time  0.117 ( 0.627)	Data  0.000 ( 0.508)	Loss 1.0167e-01 (1.6068e-01) 
2023-05-25 22:18:59.266282: val Epoch: [27][66/72]	Time  1.087 ( 0.633)	Data  0.969 ( 0.515)	Loss 6.6673e-02 (1.5927e-01) 
2023-05-25 22:18:59.383010: val Epoch: [27][67/72]	Time  0.117 ( 0.626)	Data  0.000 ( 0.507)	Loss 5.0859e-02 (1.5768e-01) 
2023-05-25 22:19:00.450029: val Epoch: [27][68/72]	Time  1.067 ( 0.632)	Data  0.950 ( 0.514)	Loss 6.1256e-02 (1.5628e-01) 
2023-05-25 22:19:00.566323: val Epoch: [27][69/72]	Time  0.116 ( 0.625)	Data  0.000 ( 0.506)	Loss 7.6411e-02 (1.5514e-01) 
2023-05-25 22:19:01.608175: val Epoch: [27][70/72]	Time  1.042 ( 0.631)	Data  0.925 ( 0.512)	Loss 5.1192e-01 (1.6017e-01) 
2023-05-25 22:19:01.723684: val Epoch: [27][71/72]	Time  0.116 ( 0.624)	Data  0.000 ( 0.505)	Loss 9.1437e-02 (1.5921e-01) 
2023-05-25 22:19:01.900771: Epoch 27 :Val : ['ET : 0.6838979721069336', 'TC : 0.7322240471839905', 'WT : 0.8280081152915955'] 
2023-05-25 22:19:01.903392: Epoch 27 :Val : ['ET : 0.6838979721069336', 'TC : 0.7322240471839905', 'WT : 0.8280081152915955'] 
2023-05-25 22:19:01.905339: Val epoch done in 45.792262142000254 s 
2023-05-25 22:19:01.910686: Batches per epoch:  129 
2023-05-25 22:19:06.789532: train Epoch: [28][  0/129]	Time  4.878 ( 4.878)	Data  3.879 ( 3.879)	Loss 1.1653e-01 (1.1653e-01) 
2023-05-25 22:19:07.750018: train Epoch: [28][  1/129]	Time  0.961 ( 2.920)	Data  0.001 ( 1.940)	Loss 6.2310e-02 (8.9419e-02) 
2023-05-25 22:19:10.419987: train Epoch: [28][  2/129]	Time  2.670 ( 2.836)	Data  1.714 ( 1.865)	Loss 7.7369e-02 (8.5402e-02) 
2023-05-25 22:19:11.368722: train Epoch: [28][  3/129]	Time  0.949 ( 2.364)	Data  0.001 ( 1.399)	Loss 2.6256e-01 (1.2969e-01) 
2023-05-25 22:19:13.957302: train Epoch: [28][  4/129]	Time  2.589 ( 2.409)	Data  1.642 ( 1.448)	Loss 6.9400e-02 (1.1763e-01) 
2023-05-25 22:19:14.911295: train Epoch: [28][  5/129]	Time  0.954 ( 2.167)	Data  0.001 ( 1.206)	Loss 1.7270e-01 (1.2681e-01) 
2023-05-25 22:19:17.504021: train Epoch: [28][  6/129]	Time  2.593 ( 2.228)	Data  1.647 ( 1.269)	Loss 2.3164e-01 (1.4179e-01) 
2023-05-25 22:19:18.453102: train Epoch: [28][  7/129]	Time  0.949 ( 2.068)	Data  0.001 ( 1.111)	Loss 6.5933e-02 (1.3230e-01) 
2023-05-25 22:19:21.139960: train Epoch: [28][  8/129]	Time  2.687 ( 2.137)	Data  1.741 ( 1.181)	Loss 2.0288e-01 (1.4015e-01) 
2023-05-25 22:19:22.090309: train Epoch: [28][  9/129]	Time  0.950 ( 2.018)	Data  0.001 ( 1.063)	Loss 2.4436e-01 (1.5057e-01) 
2023-05-25 22:19:24.712997: train Epoch: [28][ 10/129]	Time  2.623 ( 2.073)	Data  1.675 ( 1.118)	Loss 6.3108e-02 (1.4262e-01) 
2023-05-25 22:19:25.662694: train Epoch: [28][ 11/129]	Time  0.950 ( 1.979)	Data  0.001 ( 1.025)	Loss 1.2313e-01 (1.4099e-01) 
2023-05-25 22:19:28.279432: train Epoch: [28][ 12/129]	Time  2.617 ( 2.028)	Data  1.669 ( 1.075)	Loss 2.5313e-01 (1.4962e-01) 
2023-05-25 22:19:29.229113: train Epoch: [28][ 13/129]	Time  0.950 ( 1.951)	Data  0.001 ( 0.998)	Loss 1.0383e-01 (1.4635e-01) 
2023-05-25 22:19:31.840470: train Epoch: [28][ 14/129]	Time  2.611 ( 1.995)	Data  1.666 ( 1.043)	Loss 1.9863e-01 (1.4983e-01) 
2023-05-25 22:19:32.790663: train Epoch: [28][ 15/129]	Time  0.950 ( 1.930)	Data  0.001 ( 0.978)	Loss 2.0692e-01 (1.5340e-01) 
2023-05-25 22:19:35.417847: train Epoch: [28][ 16/129]	Time  2.627 ( 1.971)	Data  1.680 ( 1.019)	Loss 9.6380e-02 (1.5005e-01) 
2023-05-25 22:19:36.367131: train Epoch: [28][ 17/129]	Time  0.949 ( 1.914)	Data  0.001 ( 0.962)	Loss 7.0514e-02 (1.4563e-01) 
2023-05-25 22:19:39.025817: train Epoch: [28][ 18/129]	Time  2.659 ( 1.953)	Data  1.711 ( 1.002)	Loss 1.0994e-01 (1.4375e-01) 
2023-05-25 22:19:39.976747: train Epoch: [28][ 19/129]	Time  0.951 ( 1.903)	Data  0.001 ( 0.952)	Loss 1.0023e-01 (1.4157e-01) 
2023-05-25 22:19:42.672490: train Epoch: [28][ 20/129]	Time  2.696 ( 1.941)	Data  1.750 ( 0.990)	Loss 2.3592e-01 (1.4607e-01) 
2023-05-25 22:19:43.622966: train Epoch: [28][ 21/129]	Time  0.950 ( 1.896)	Data  0.001 ( 0.945)	Loss 8.1394e-02 (1.4313e-01) 
2023-05-25 22:19:46.177054: train Epoch: [28][ 22/129]	Time  2.554 ( 1.925)	Data  1.607 ( 0.974)	Loss 2.0295e-01 (1.4573e-01) 
2023-05-25 22:19:47.126147: train Epoch: [28][ 23/129]	Time  0.949 ( 1.884)	Data  0.001 ( 0.933)	Loss 8.3474e-02 (1.4313e-01) 
2023-05-25 22:19:49.821795: train Epoch: [28][ 24/129]	Time  2.696 ( 1.916)	Data  1.750 ( 0.966)	Loss 1.2160e-01 (1.4227e-01) 
2023-05-25 22:19:50.773687: train Epoch: [28][ 25/129]	Time  0.952 ( 1.879)	Data  0.001 ( 0.929)	Loss 1.3328e-01 (1.4193e-01) 
2023-05-25 22:19:53.412022: train Epoch: [28][ 26/129]	Time  2.638 ( 1.907)	Data  1.691 ( 0.957)	Loss 9.0554e-02 (1.4002e-01) 
2023-05-25 22:19:54.361502: train Epoch: [28][ 27/129]	Time  0.949 ( 1.873)	Data  0.001 ( 0.923)	Loss 1.3576e-01 (1.3987e-01) 
2023-05-25 22:19:56.954640: train Epoch: [28][ 28/129]	Time  2.593 ( 1.898)	Data  1.646 ( 0.948)	Loss 9.3683e-02 (1.3828e-01) 
2023-05-25 22:19:57.904087: train Epoch: [28][ 29/129]	Time  0.949 ( 1.866)	Data  0.001 ( 0.916)	Loss 1.0963e-01 (1.3732e-01) 
2023-05-25 22:20:00.645776: train Epoch: [28][ 30/129]	Time  2.742 ( 1.895)	Data  1.794 ( 0.944)	Loss 1.0843e-01 (1.3639e-01) 
2023-05-25 22:20:01.594333: train Epoch: [28][ 31/129]	Time  0.949 ( 1.865)	Data  0.001 ( 0.915)	Loss 1.3280e-01 (1.3628e-01) 
2023-05-25 22:20:04.289640: train Epoch: [28][ 32/129]	Time  2.695 ( 1.890)	Data  1.749 ( 0.940)	Loss 1.2129e-01 (1.3583e-01) 
2023-05-25 22:20:05.240251: train Epoch: [28][ 33/129]	Time  0.951 ( 1.863)	Data  0.001 ( 0.913)	Loss 1.0135e-01 (1.3481e-01) 
2023-05-25 22:20:07.948995: train Epoch: [28][ 34/129]	Time  2.709 ( 1.887)	Data  1.764 ( 0.937)	Loss 1.6865e-01 (1.3578e-01) 
2023-05-25 22:20:08.897867: train Epoch: [28][ 35/129]	Time  0.949 ( 1.861)	Data  0.001 ( 0.911)	Loss 1.1394e-01 (1.3517e-01) 
2023-05-25 22:20:11.565980: train Epoch: [28][ 36/129]	Time  2.668 ( 1.883)	Data  1.721 ( 0.933)	Loss 1.7337e-01 (1.3620e-01) 
2023-05-25 22:20:12.515848: train Epoch: [28][ 37/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.908)	Loss 7.2141e-02 (1.3452e-01) 
2023-05-25 22:20:15.196023: train Epoch: [28][ 38/129]	Time  2.680 ( 1.879)	Data  1.735 ( 0.929)	Loss 6.6122e-02 (1.3276e-01) 
2023-05-25 22:20:16.147182: train Epoch: [28][ 39/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.906)	Loss 9.6629e-02 (1.3186e-01) 
2023-05-25 22:20:18.840373: train Epoch: [28][ 40/129]	Time  2.693 ( 1.876)	Data  1.748 ( 0.927)	Loss 2.2027e-01 (1.3402e-01) 
2023-05-25 22:20:19.789218: train Epoch: [28][ 41/129]	Time  0.949 ( 1.854)	Data  0.001 ( 0.905)	Loss 8.9759e-02 (1.3296e-01) 
2023-05-25 22:20:22.393572: train Epoch: [28][ 42/129]	Time  2.604 ( 1.872)	Data  1.657 ( 0.922)	Loss 7.1938e-02 (1.3154e-01) 
2023-05-25 22:20:23.342911: train Epoch: [28][ 43/129]	Time  0.949 ( 1.851)	Data  0.001 ( 0.901)	Loss 1.4036e-01 (1.3174e-01) 
2023-05-25 22:20:26.126369: train Epoch: [28][ 44/129]	Time  2.783 ( 1.871)	Data  1.837 ( 0.922)	Loss 8.5659e-02 (1.3072e-01) 
2023-05-25 22:20:27.076239: train Epoch: [28][ 45/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.902)	Loss 8.0800e-02 (1.2964e-01) 
2023-05-25 22:20:29.767363: train Epoch: [28][ 46/129]	Time  2.691 ( 1.869)	Data  1.746 ( 0.920)	Loss 1.1211e-01 (1.2926e-01) 
2023-05-25 22:20:30.716309: train Epoch: [28][ 47/129]	Time  0.949 ( 1.850)	Data  0.001 ( 0.901)	Loss 8.3728e-02 (1.2831e-01) 
2023-05-25 22:20:33.326893: train Epoch: [28][ 48/129]	Time  2.611 ( 1.866)	Data  1.665 ( 0.916)	Loss 6.5276e-02 (1.2703e-01) 
2023-05-25 22:20:34.277406: train Epoch: [28][ 49/129]	Time  0.951 ( 1.847)	Data  0.001 ( 0.898)	Loss 1.6085e-01 (1.2770e-01) 
2023-05-25 22:20:36.881545: train Epoch: [28][ 50/129]	Time  2.604 ( 1.862)	Data  1.658 ( 0.913)	Loss 6.6319e-02 (1.2650e-01) 
2023-05-25 22:20:37.830937: train Epoch: [28][ 51/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.895)	Loss 1.1783e-01 (1.2633e-01) 
2023-05-25 22:20:40.576715: train Epoch: [28][ 52/129]	Time  2.746 ( 1.862)	Data  1.801 ( 0.913)	Loss 6.7246e-02 (1.2522e-01) 
2023-05-25 22:20:41.526332: train Epoch: [28][ 53/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.896)	Loss 6.9426e-02 (1.2419e-01) 
2023-05-25 22:20:44.261167: train Epoch: [28][ 54/129]	Time  2.735 ( 1.861)	Data  1.790 ( 0.912)	Loss 8.0174e-02 (1.2339e-01) 
2023-05-25 22:20:45.210207: train Epoch: [28][ 55/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.896)	Loss 7.1172e-02 (1.2245e-01) 
2023-05-25 22:20:47.875332: train Epoch: [28][ 56/129]	Time  2.665 ( 1.859)	Data  1.720 ( 0.910)	Loss 9.0183e-02 (1.2189e-01) 
2023-05-25 22:20:48.825849: train Epoch: [28][ 57/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.894)	Loss 9.4125e-02 (1.2141e-01) 
2023-05-25 22:20:51.350993: train Epoch: [28][ 58/129]	Time  2.525 ( 1.855)	Data  1.578 ( 0.906)	Loss 5.3960e-02 (1.2026e-01) 
2023-05-25 22:20:52.300611: train Epoch: [28][ 59/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.891)	Loss 1.2965e-01 (1.2042e-01) 
2023-05-25 22:20:54.843171: train Epoch: [28][ 60/129]	Time  2.543 ( 1.851)	Data  1.595 ( 0.903)	Loss 7.7607e-02 (1.1972e-01) 
2023-05-25 22:20:55.794014: train Epoch: [28][ 61/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.888)	Loss 2.5401e-01 (1.2189e-01) 
2023-05-25 22:20:58.520499: train Epoch: [28][ 62/129]	Time  2.726 ( 1.851)	Data  1.779 ( 0.902)	Loss 8.4317e-02 (1.2129e-01) 
2023-05-25 22:20:59.470486: train Epoch: [28][ 63/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.888)	Loss 6.8128e-02 (1.2046e-01) 
2023-05-25 22:21:02.252856: train Epoch: [28][ 64/129]	Time  2.782 ( 1.851)	Data  1.835 ( 0.903)	Loss 1.0129e-01 (1.2016e-01) 
2023-05-25 22:21:03.205204: train Epoch: [28][ 65/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.889)	Loss 1.3368e-01 (1.2037e-01) 
2023-05-25 22:21:05.940710: train Epoch: [28][ 66/129]	Time  2.736 ( 1.851)	Data  1.790 ( 0.902)	Loss 2.5960e-01 (1.2245e-01) 
2023-05-25 22:21:06.890446: train Epoch: [28][ 67/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.889)	Loss 6.8971e-02 (1.2166e-01) 
2023-05-25 22:21:09.572261: train Epoch: [28][ 68/129]	Time  2.682 ( 1.850)	Data  1.736 ( 0.901)	Loss 7.2947e-02 (1.2095e-01) 
2023-05-25 22:21:10.536600: train Epoch: [28][ 69/129]	Time  0.964 ( 1.838)	Data  0.001 ( 0.889)	Loss 8.8002e-02 (1.2048e-01) 
2023-05-25 22:21:13.113581: train Epoch: [28][ 70/129]	Time  2.577 ( 1.848)	Data  1.622 ( 0.899)	Loss 8.3148e-02 (1.1996e-01) 
2023-05-25 22:21:14.061790: train Epoch: [28][ 71/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.886)	Loss 8.2464e-02 (1.1944e-01) 
2023-05-25 22:21:16.783327: train Epoch: [28][ 72/129]	Time  2.722 ( 1.848)	Data  1.762 ( 0.898)	Loss 7.4195e-02 (1.1882e-01) 
2023-05-25 22:21:17.735884: train Epoch: [28][ 73/129]	Time  0.953 ( 1.835)	Data  0.001 ( 0.886)	Loss 9.2607e-02 (1.1846e-01) 
2023-05-25 22:21:20.501665: train Epoch: [28][ 74/129]	Time  2.766 ( 1.848)	Data  1.811 ( 0.899)	Loss 1.9854e-01 (1.1953e-01) 
2023-05-25 22:21:21.451103: train Epoch: [28][ 75/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.887)	Loss 1.1080e-01 (1.1942e-01) 
2023-05-25 22:21:24.062043: train Epoch: [28][ 76/129]	Time  2.611 ( 1.846)	Data  1.650 ( 0.897)	Loss 5.9946e-02 (1.1864e-01) 
2023-05-25 22:21:25.012536: train Epoch: [28][ 77/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.885)	Loss 7.0820e-02 (1.1803e-01) 
2023-05-25 22:21:27.631054: train Epoch: [28][ 78/129]	Time  2.619 ( 1.845)	Data  1.660 ( 0.895)	Loss 4.9945e-02 (1.1717e-01) 
2023-05-25 22:21:28.585513: train Epoch: [28][ 79/129]	Time  0.954 ( 1.833)	Data  0.001 ( 0.884)	Loss 8.7304e-02 (1.1679e-01) 
2023-05-25 22:21:31.256865: train Epoch: [28][ 80/129]	Time  2.671 ( 1.844)	Data  1.722 ( 0.894)	Loss 1.0578e-01 (1.1666e-01) 
2023-05-25 22:21:32.207456: train Epoch: [28][ 81/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.883)	Loss 1.1317e-01 (1.1662e-01) 
2023-05-25 22:21:34.894602: train Epoch: [28][ 82/129]	Time  2.687 ( 1.843)	Data  1.736 ( 0.894)	Loss 1.1242e-01 (1.1657e-01) 
2023-05-25 22:21:35.845502: train Epoch: [28][ 83/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.883)	Loss 6.9685e-02 (1.1601e-01) 
2023-05-25 22:21:38.501053: train Epoch: [28][ 84/129]	Time  2.656 ( 1.842)	Data  1.707 ( 0.893)	Loss 1.1368e-01 (1.1598e-01) 
2023-05-25 22:21:39.451743: train Epoch: [28][ 85/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.882)	Loss 1.1486e-01 (1.1597e-01) 
2023-05-25 22:21:42.066342: train Epoch: [28][ 86/129]	Time  2.615 ( 1.841)	Data  1.666 ( 0.891)	Loss 1.0167e-01 (1.1580e-01) 
2023-05-25 22:21:43.016471: train Epoch: [28][ 87/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.881)	Loss 9.1076e-02 (1.1552e-01) 
2023-05-25 22:21:45.713841: train Epoch: [28][ 88/129]	Time  2.697 ( 1.840)	Data  1.745 ( 0.891)	Loss 8.9425e-02 (1.1523e-01) 
2023-05-25 22:21:46.664337: train Epoch: [28][ 89/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.881)	Loss 8.1383e-02 (1.1485e-01) 
2023-05-25 22:21:49.305607: train Epoch: [28][ 90/129]	Time  2.641 ( 1.839)	Data  1.678 ( 0.890)	Loss 1.0016e-01 (1.1469e-01) 
2023-05-25 22:21:50.255631: train Epoch: [28][ 91/129]	Time  0.950 ( 1.830)	Data  0.001 ( 0.880)	Loss 6.0187e-02 (1.1410e-01) 
2023-05-25 22:21:52.896483: train Epoch: [28][ 92/129]	Time  2.641 ( 1.839)	Data  1.682 ( 0.889)	Loss 1.5776e-01 (1.1457e-01) 
2023-05-25 22:21:53.845654: train Epoch: [28][ 93/129]	Time  0.949 ( 1.829)	Data  0.001 ( 0.879)	Loss 1.0163e-01 (1.1443e-01) 
2023-05-25 22:21:56.420219: train Epoch: [28][ 94/129]	Time  2.575 ( 1.837)	Data  1.626 ( 0.887)	Loss 1.1593e-01 (1.1445e-01) 
2023-05-25 22:21:57.374120: train Epoch: [28][ 95/129]	Time  0.954 ( 1.828)	Data  0.001 ( 0.878)	Loss 1.9379e-01 (1.1527e-01) 
2023-05-25 22:22:00.004780: train Epoch: [28][ 96/129]	Time  2.631 ( 1.836)	Data  1.682 ( 0.886)	Loss 9.5208e-02 (1.1507e-01) 
2023-05-25 22:22:00.955416: train Epoch: [28][ 97/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.877)	Loss 1.0330e-01 (1.1495e-01) 
2023-05-25 22:22:03.616426: train Epoch: [28][ 98/129]	Time  2.661 ( 1.835)	Data  1.713 ( 0.886)	Loss 8.3568e-02 (1.1463e-01) 
2023-05-25 22:22:04.567222: train Epoch: [28][ 99/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.877)	Loss 1.5570e-01 (1.1504e-01) 
2023-05-25 22:22:07.222632: train Epoch: [28][100/129]	Time  2.655 ( 1.835)	Data  1.704 ( 0.885)	Loss 1.2114e-01 (1.1510e-01) 
2023-05-25 22:22:08.173501: train Epoch: [28][101/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.876)	Loss 8.0401e-02 (1.1476e-01) 
2023-05-25 22:22:10.758688: train Epoch: [28][102/129]	Time  2.585 ( 1.833)	Data  1.638 ( 0.884)	Loss 6.2063e-02 (1.1425e-01) 
2023-05-25 22:22:11.711172: train Epoch: [28][103/129]	Time  0.952 ( 1.825)	Data  0.001 ( 0.875)	Loss 6.7519e-02 (1.1380e-01) 
2023-05-25 22:22:14.330532: train Epoch: [28][104/129]	Time  2.619 ( 1.833)	Data  1.670 ( 0.883)	Loss 9.5503e-02 (1.1362e-01) 
2023-05-25 22:22:15.281145: train Epoch: [28][105/129]	Time  0.951 ( 1.824)	Data  0.001 ( 0.874)	Loss 7.4844e-02 (1.1326e-01) 
2023-05-25 22:22:17.997221: train Epoch: [28][106/129]	Time  2.716 ( 1.833)	Data  1.757 ( 0.883)	Loss 7.4669e-02 (1.1290e-01) 
2023-05-25 22:22:18.959340: train Epoch: [28][107/129]	Time  0.962 ( 1.825)	Data  0.001 ( 0.875)	Loss 6.6977e-02 (1.1247e-01) 
2023-05-25 22:22:21.633107: train Epoch: [28][108/129]	Time  2.674 ( 1.832)	Data  1.715 ( 0.882)	Loss 4.9044e-02 (1.1189e-01) 
2023-05-25 22:22:22.595030: train Epoch: [28][109/129]	Time  0.962 ( 1.824)	Data  0.001 ( 0.874)	Loss 1.0472e-01 (1.1183e-01) 
2023-05-25 22:22:25.197790: train Epoch: [28][110/129]	Time  2.603 ( 1.831)	Data  1.645 ( 0.881)	Loss 1.1987e-01 (1.1190e-01) 
2023-05-25 22:22:26.148275: train Epoch: [28][111/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.873)	Loss 8.7901e-02 (1.1168e-01) 
2023-05-25 22:22:28.856485: train Epoch: [28][112/129]	Time  2.708 ( 1.831)	Data  1.747 ( 0.881)	Loss 4.8393e-02 (1.1112e-01) 
2023-05-25 22:22:29.806986: train Epoch: [28][113/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.873)	Loss 1.0456e-01 (1.1107e-01) 
2023-05-25 22:22:32.485526: train Epoch: [28][114/129]	Time  2.679 ( 1.831)	Data  1.719 ( 0.881)	Loss 9.3233e-02 (1.1091e-01) 
2023-05-25 22:22:33.435537: train Epoch: [28][115/129]	Time  0.950 ( 1.823)	Data  0.001 ( 0.873)	Loss 9.4541e-02 (1.1077e-01) 
2023-05-25 22:22:36.064200: train Epoch: [28][116/129]	Time  2.629 ( 1.830)	Data  1.681 ( 0.880)	Loss 5.2025e-02 (1.1027e-01) 
2023-05-25 22:22:37.014547: train Epoch: [28][117/129]	Time  0.950 ( 1.823)	Data  0.001 ( 0.873)	Loss 6.2450e-02 (1.0986e-01) 
2023-05-25 22:22:39.690430: train Epoch: [28][118/129]	Time  2.676 ( 1.830)	Data  1.717 ( 0.880)	Loss 8.0040e-02 (1.0961e-01) 
2023-05-25 22:22:40.651682: train Epoch: [28][119/129]	Time  0.961 ( 1.823)	Data  0.001 ( 0.872)	Loss 9.2387e-02 (1.0947e-01) 
2023-05-25 22:22:43.493020: train Epoch: [28][120/129]	Time  2.841 ( 1.831)	Data  1.879 ( 0.881)	Loss 1.4394e-01 (1.0975e-01) 
2023-05-25 22:22:44.455925: train Epoch: [28][121/129]	Time  0.963 ( 1.824)	Data  0.001 ( 0.873)	Loss 5.8923e-02 (1.0934e-01) 
2023-05-25 22:22:47.223340: train Epoch: [28][122/129]	Time  2.767 ( 1.832)	Data  1.813 ( 0.881)	Loss 7.3999e-02 (1.0905e-01) 
2023-05-25 22:22:48.174729: train Epoch: [28][123/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.874)	Loss 5.7739e-02 (1.0864e-01) 
2023-05-25 22:22:50.902928: train Epoch: [28][124/129]	Time  2.728 ( 1.832)	Data  1.778 ( 0.881)	Loss 2.0831e-01 (1.0943e-01) 
2023-05-25 22:22:51.853125: train Epoch: [28][125/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.874)	Loss 8.4233e-02 (1.0923e-01) 
2023-05-25 22:22:54.381948: train Epoch: [28][126/129]	Time  2.529 ( 1.830)	Data  1.581 ( 0.880)	Loss 6.9504e-02 (1.0892e-01) 
2023-05-25 22:22:55.329357: train Epoch: [28][127/129]	Time  0.947 ( 1.824)	Data  0.001 ( 0.873)	Loss 8.4998e-02 (1.0873e-01) 
2023-05-25 22:22:56.870060: train Epoch: [28][128/129]	Time  1.541 ( 1.821)	Data  0.595 ( 0.871)	Loss 1.0317e-01 (1.0869e-01) 
2023-05-25 22:22:56.900565: Train Epoch done in 234.98990518199935 s 
2023-05-25 22:22:59.273702: val Epoch: [28][ 0/72]	Time  1.662 ( 1.662)	Data  1.460 ( 1.460)	Loss 3.4813e-01 (3.4813e-01) 
2023-05-25 22:22:59.396276: val Epoch: [28][ 1/72]	Time  0.123 ( 0.892)	Data  0.001 ( 0.731)	Loss 5.6575e-02 (2.0235e-01) 
2023-05-25 22:23:00.369207: val Epoch: [28][ 2/72]	Time  0.973 ( 0.919)	Data  0.851 ( 0.771)	Loss 5.5634e-02 (1.5345e-01) 
2023-05-25 22:23:00.491369: val Epoch: [28][ 3/72]	Time  0.122 ( 0.720)	Data  0.001 ( 0.578)	Loss 1.0651e-01 (1.4171e-01) 
2023-05-25 22:23:01.645926: val Epoch: [28][ 4/72]	Time  1.155 ( 0.807)	Data  1.033 ( 0.669)	Loss 1.4141e-01 (1.4165e-01) 
2023-05-25 22:23:01.766168: val Epoch: [28][ 5/72]	Time  0.120 ( 0.692)	Data  0.001 ( 0.558)	Loss 1.3397e-01 (1.4037e-01) 
2023-05-25 22:23:02.903230: val Epoch: [28][ 6/72]	Time  1.137 ( 0.756)	Data  1.020 ( 0.624)	Loss 5.2798e-02 (1.2786e-01) 
2023-05-25 22:23:03.020451: val Epoch: [28][ 7/72]	Time  0.117 ( 0.676)	Data  0.000 ( 0.546)	Loss 1.2574e-01 (1.2760e-01) 
2023-05-25 22:23:04.133585: val Epoch: [28][ 8/72]	Time  1.113 ( 0.725)	Data  0.996 ( 0.596)	Loss 1.0235e-01 (1.2479e-01) 
2023-05-25 22:23:04.249703: val Epoch: [28][ 9/72]	Time  0.116 ( 0.664)	Data  0.000 ( 0.536)	Loss 9.5017e-02 (1.2181e-01) 
2023-05-25 22:23:05.355326: val Epoch: [28][10/72]	Time  1.106 ( 0.704)	Data  0.988 ( 0.577)	Loss 6.3653e-02 (1.1653e-01) 
2023-05-25 22:23:05.472606: val Epoch: [28][11/72]	Time  0.117 ( 0.655)	Data  0.000 ( 0.529)	Loss 8.7067e-02 (1.1407e-01) 
2023-05-25 22:23:06.609336: val Epoch: [28][12/72]	Time  1.137 ( 0.692)	Data  1.020 ( 0.567)	Loss 1.0521e-01 (1.1339e-01) 
2023-05-25 22:23:06.726133: val Epoch: [28][13/72]	Time  0.117 ( 0.651)	Data  0.001 ( 0.527)	Loss 2.2653e-01 (1.2147e-01) 
2023-05-25 22:23:07.868232: val Epoch: [28][14/72]	Time  1.142 ( 0.684)	Data  1.025 ( 0.560)	Loss 8.8493e-02 (1.1927e-01) 
2023-05-25 22:23:07.985774: val Epoch: [28][15/72]	Time  0.118 ( 0.648)	Data  0.000 ( 0.525)	Loss 5.1419e-02 (1.1503e-01) 
2023-05-25 22:23:09.109744: val Epoch: [28][16/72]	Time  1.124 ( 0.676)	Data  1.006 ( 0.553)	Loss 3.7976e-01 (1.3060e-01) 
2023-05-25 22:23:09.227173: val Epoch: [28][17/72]	Time  0.117 ( 0.645)	Data  0.001 ( 0.522)	Loss 3.6275e-01 (1.4350e-01) 
2023-05-25 22:23:10.357422: val Epoch: [28][18/72]	Time  1.130 ( 0.671)	Data  1.013 ( 0.548)	Loss 7.2542e-02 (1.3977e-01) 
2023-05-25 22:23:10.474838: val Epoch: [28][19/72]	Time  0.117 ( 0.643)	Data  0.000 ( 0.521)	Loss 1.6360e-01 (1.4096e-01) 
2023-05-25 22:23:11.606500: val Epoch: [28][20/72]	Time  1.132 ( 0.666)	Data  1.013 ( 0.544)	Loss 2.6038e-01 (1.4664e-01) 
2023-05-25 22:23:11.726185: val Epoch: [28][21/72]	Time  0.120 ( 0.642)	Data  0.000 ( 0.520)	Loss 2.8086e-01 (1.5275e-01) 
2023-05-25 22:23:12.804744: val Epoch: [28][22/72]	Time  1.079 ( 0.661)	Data  0.962 ( 0.539)	Loss 1.4974e-01 (1.5261e-01) 
2023-05-25 22:23:12.921508: val Epoch: [28][23/72]	Time  0.117 ( 0.638)	Data  0.000 ( 0.516)	Loss 6.0491e-02 (1.4878e-01) 
2023-05-25 22:23:14.028772: val Epoch: [28][24/72]	Time  1.107 ( 0.657)	Data  0.989 ( 0.535)	Loss 9.1187e-02 (1.4647e-01) 
2023-05-25 22:23:14.145530: val Epoch: [28][25/72]	Time  0.117 ( 0.636)	Data  0.000 ( 0.515)	Loss 1.9443e-01 (1.4832e-01) 
2023-05-25 22:23:15.256742: val Epoch: [28][26/72]	Time  1.111 ( 0.654)	Data  0.994 ( 0.532)	Loss 4.3691e-01 (1.5901e-01) 
2023-05-25 22:23:15.373171: val Epoch: [28][27/72]	Time  0.116 ( 0.634)	Data  0.000 ( 0.513)	Loss 1.2192e-01 (1.5768e-01) 
2023-05-25 22:23:16.522327: val Epoch: [28][28/72]	Time  1.149 ( 0.652)	Data  1.032 ( 0.531)	Loss 6.8153e-02 (1.5459e-01) 
2023-05-25 22:23:16.640283: val Epoch: [28][29/72]	Time  0.118 ( 0.634)	Data  0.000 ( 0.514)	Loss 9.8208e-02 (1.5271e-01) 
2023-05-25 22:23:17.755710: val Epoch: [28][30/72]	Time  1.115 ( 0.650)	Data  0.998 ( 0.529)	Loss 4.4349e-01 (1.6209e-01) 
2023-05-25 22:23:17.872791: val Epoch: [28][31/72]	Time  0.117 ( 0.633)	Data  0.000 ( 0.513)	Loss 5.5390e-02 (1.5876e-01) 
2023-05-25 22:23:18.971087: val Epoch: [28][32/72]	Time  1.098 ( 0.647)	Data  0.981 ( 0.527)	Loss 4.5516e-02 (1.5533e-01) 
2023-05-25 22:23:19.087659: val Epoch: [28][33/72]	Time  0.117 ( 0.632)	Data  0.000 ( 0.511)	Loss 6.4145e-02 (1.5265e-01) 
2023-05-25 22:23:20.184746: val Epoch: [28][34/72]	Time  1.097 ( 0.645)	Data  0.980 ( 0.525)	Loss 2.9993e-01 (1.5685e-01) 
2023-05-25 22:23:20.301553: val Epoch: [28][35/72]	Time  0.117 ( 0.630)	Data  0.001 ( 0.510)	Loss 1.0416e-01 (1.5539e-01) 
2023-05-25 22:23:21.351426: val Epoch: [28][36/72]	Time  1.050 ( 0.642)	Data  0.933 ( 0.522)	Loss 6.3535e-02 (1.5291e-01) 
2023-05-25 22:23:21.468641: val Epoch: [28][37/72]	Time  0.117 ( 0.628)	Data  0.000 ( 0.508)	Loss 2.8070e-01 (1.5627e-01) 
2023-05-25 22:23:22.568508: val Epoch: [28][38/72]	Time  1.100 ( 0.640)	Data  0.982 ( 0.520)	Loss 1.0370e-01 (1.5492e-01) 
2023-05-25 22:23:22.685885: val Epoch: [28][39/72]	Time  0.117 ( 0.627)	Data  0.000 ( 0.507)	Loss 4.7432e-02 (1.5224e-01) 
2023-05-25 22:23:23.773858: val Epoch: [28][40/72]	Time  1.088 ( 0.638)	Data  0.970 ( 0.518)	Loss 6.0800e-02 (1.5001e-01) 
2023-05-25 22:23:23.891420: val Epoch: [28][41/72]	Time  0.118 ( 0.626)	Data  0.000 ( 0.506)	Loss 1.1405e-01 (1.4915e-01) 
2023-05-25 22:23:24.973764: val Epoch: [28][42/72]	Time  1.082 ( 0.636)	Data  0.965 ( 0.517)	Loss 6.0542e-02 (1.4709e-01) 
2023-05-25 22:23:25.090379: val Epoch: [28][43/72]	Time  0.117 ( 0.625)	Data  0.000 ( 0.505)	Loss 7.6884e-02 (1.4549e-01) 
2023-05-25 22:23:26.196993: val Epoch: [28][44/72]	Time  1.107 ( 0.635)	Data  0.990 ( 0.516)	Loss 4.6011e-02 (1.4328e-01) 
2023-05-25 22:23:26.313712: val Epoch: [28][45/72]	Time  0.117 ( 0.624)	Data  0.000 ( 0.505)	Loss 4.8175e-02 (1.4121e-01) 
2023-05-25 22:23:27.411019: val Epoch: [28][46/72]	Time  1.097 ( 0.634)	Data  0.980 ( 0.515)	Loss 8.4191e-02 (1.4000e-01) 
2023-05-25 22:23:27.527638: val Epoch: [28][47/72]	Time  0.117 ( 0.623)	Data  0.000 ( 0.504)	Loss 9.7853e-02 (1.3912e-01) 
2023-05-25 22:23:28.626109: val Epoch: [28][48/72]	Time  1.098 ( 0.633)	Data  0.982 ( 0.514)	Loss 1.3222e-01 (1.3898e-01) 
2023-05-25 22:23:28.742437: val Epoch: [28][49/72]	Time  0.116 ( 0.623)	Data  0.000 ( 0.503)	Loss 3.6209e-01 (1.4344e-01) 
2023-05-25 22:23:29.872718: val Epoch: [28][50/72]	Time  1.130 ( 0.633)	Data  1.012 ( 0.513)	Loss 1.7108e-01 (1.4399e-01) 
2023-05-25 22:23:29.993494: val Epoch: [28][51/72]	Time  0.121 ( 0.623)	Data  0.001 ( 0.504)	Loss 9.3286e-02 (1.4301e-01) 
2023-05-25 22:23:31.059950: val Epoch: [28][52/72]	Time  1.066 ( 0.631)	Data  0.945 ( 0.512)	Loss 6.8949e-02 (1.4161e-01) 
2023-05-25 22:23:31.180644: val Epoch: [28][53/72]	Time  0.121 ( 0.622)	Data  0.001 ( 0.502)	Loss 4.5058e-02 (1.3983e-01) 
2023-05-25 22:23:32.315930: val Epoch: [28][54/72]	Time  1.135 ( 0.631)	Data  1.014 ( 0.512)	Loss 5.1280e-01 (1.4661e-01) 
2023-05-25 22:23:32.437376: val Epoch: [28][55/72]	Time  0.121 ( 0.622)	Data  0.001 ( 0.503)	Loss 7.2697e-02 (1.4529e-01) 
2023-05-25 22:23:33.570164: val Epoch: [28][56/72]	Time  1.133 ( 0.631)	Data  1.010 ( 0.512)	Loss 3.2252e-01 (1.4840e-01) 
2023-05-25 22:23:33.691536: val Epoch: [28][57/72]	Time  0.121 ( 0.622)	Data  0.001 ( 0.503)	Loss 4.7800e-02 (1.4666e-01) 
2023-05-25 22:23:34.778205: val Epoch: [28][58/72]	Time  1.087 ( 0.630)	Data  0.966 ( 0.511)	Loss 5.9814e-02 (1.4519e-01) 
2023-05-25 22:23:34.899169: val Epoch: [28][59/72]	Time  0.121 ( 0.621)	Data  0.001 ( 0.502)	Loss 2.0232e-01 (1.4614e-01) 
2023-05-25 22:23:35.972676: val Epoch: [28][60/72]	Time  1.074 ( 0.629)	Data  0.953 ( 0.509)	Loss 5.3206e-02 (1.4462e-01) 
2023-05-25 22:23:36.093700: val Epoch: [28][61/72]	Time  0.121 ( 0.621)	Data  0.000 ( 0.501)	Loss 7.3587e-02 (1.4347e-01) 
2023-05-25 22:23:37.189276: val Epoch: [28][62/72]	Time  1.096 ( 0.628)	Data  0.975 ( 0.509)	Loss 2.1240e-01 (1.4457e-01) 
2023-05-25 22:23:37.310134: val Epoch: [28][63/72]	Time  0.121 ( 0.620)	Data  0.001 ( 0.501)	Loss 4.2926e-01 (1.4902e-01) 
2023-05-25 22:23:38.389884: val Epoch: [28][64/72]	Time  1.080 ( 0.627)	Data  0.958 ( 0.508)	Loss 1.2016e-01 (1.4857e-01) 
2023-05-25 22:23:38.510559: val Epoch: [28][65/72]	Time  0.121 ( 0.620)	Data  0.001 ( 0.500)	Loss 4.6680e-02 (1.4703e-01) 
2023-05-25 22:23:39.596120: val Epoch: [28][66/72]	Time  1.086 ( 0.627)	Data  0.964 ( 0.507)	Loss 4.2423e-01 (1.5117e-01) 
2023-05-25 22:23:39.717394: val Epoch: [28][67/72]	Time  0.121 ( 0.619)	Data  0.001 ( 0.500)	Loss 1.4169e-01 (1.5103e-01) 
2023-05-25 22:23:40.802200: val Epoch: [28][68/72]	Time  1.085 ( 0.626)	Data  0.963 ( 0.506)	Loss 9.5765e-02 (1.5023e-01) 
2023-05-25 22:23:40.923844: val Epoch: [28][69/72]	Time  0.122 ( 0.619)	Data  0.000 ( 0.499)	Loss 9.9926e-02 (1.4951e-01) 
2023-05-25 22:23:41.898700: val Epoch: [28][70/72]	Time  0.975 ( 0.624)	Data  0.854 ( 0.504)	Loss 5.0804e-02 (1.4812e-01) 
2023-05-25 22:23:42.018679: val Epoch: [28][71/72]	Time  0.120 ( 0.617)	Data  0.000 ( 0.497)	Loss 6.8611e-02 (1.4701e-01) 
2023-05-25 22:23:42.171641: Epoch 28 :Val : ['ET : 0.7219577431678772', 'TC : 0.7434601783752441', 'WT : 0.8505381345748901'] 
2023-05-25 22:23:42.172724: Epoch 28 :Val : ['ET : 0.7219577431678772', 'TC : 0.7434601783752441', 'WT : 0.8505381345748901'] 
2023-05-25 22:23:42.178639: Val epoch done in 45.27807834300074 s 
2023-05-25 22:23:42.188939: Batches per epoch:  129 
2023-05-25 22:23:46.999038: train Epoch: [29][  0/129]	Time  4.810 ( 4.810)	Data  3.785 ( 3.785)	Loss 7.9228e-02 (7.9228e-02) 
2023-05-25 22:23:47.960305: train Epoch: [29][  1/129]	Time  0.961 ( 2.885)	Data  0.001 ( 1.893)	Loss 7.6810e-02 (7.8019e-02) 
2023-05-25 22:23:50.514007: train Epoch: [29][  2/129]	Time  2.554 ( 2.775)	Data  1.595 ( 1.794)	Loss 1.0750e-01 (8.7845e-02) 
2023-05-25 22:23:51.462111: train Epoch: [29][  3/129]	Time  0.948 ( 2.318)	Data  0.001 ( 1.345)	Loss 6.3412e-02 (8.1737e-02) 
2023-05-25 22:23:54.007382: train Epoch: [29][  4/129]	Time  2.545 ( 2.364)	Data  1.598 ( 1.396)	Loss 6.6709e-02 (7.8732e-02) 
2023-05-25 22:23:54.956323: train Epoch: [29][  5/129]	Time  0.949 ( 2.128)	Data  0.001 ( 1.163)	Loss 7.0701e-02 (7.7393e-02) 
2023-05-25 22:23:57.674165: train Epoch: [29][  6/129]	Time  2.718 ( 2.212)	Data  1.759 ( 1.249)	Loss 1.0097e-01 (8.0761e-02) 
2023-05-25 22:23:58.623139: train Epoch: [29][  7/129]	Time  0.949 ( 2.054)	Data  0.001 ( 1.093)	Loss 1.1520e-01 (8.5066e-02) 
2023-05-25 22:24:01.329776: train Epoch: [29][  8/129]	Time  2.707 ( 2.127)	Data  1.760 ( 1.167)	Loss 1.6224e-01 (9.3641e-02) 
2023-05-25 22:24:02.279631: train Epoch: [29][  9/129]	Time  0.950 ( 2.009)	Data  0.001 ( 1.050)	Loss 1.0218e-01 (9.4495e-02) 
2023-05-25 22:24:05.017880: train Epoch: [29][ 10/129]	Time  2.738 ( 2.075)	Data  1.790 ( 1.118)	Loss 6.9604e-02 (9.2233e-02) 
2023-05-25 22:24:05.975553: train Epoch: [29][ 11/129]	Time  0.958 ( 1.982)	Data  0.001 ( 1.024)	Loss 1.1972e-01 (9.4523e-02) 
2023-05-25 22:24:08.700921: train Epoch: [29][ 12/129]	Time  2.725 ( 2.039)	Data  1.769 ( 1.082)	Loss 8.8459e-02 (9.4057e-02) 
2023-05-25 22:24:09.661976: train Epoch: [29][ 13/129]	Time  0.961 ( 1.962)	Data  0.001 ( 1.005)	Loss 1.0299e-01 (9.4695e-02) 
2023-05-25 22:24:12.323817: train Epoch: [29][ 14/129]	Time  2.662 ( 2.009)	Data  1.698 ( 1.051)	Loss 1.7723e-01 (1.0020e-01) 
2023-05-25 22:24:13.289153: train Epoch: [29][ 15/129]	Time  0.965 ( 1.944)	Data  0.001 ( 0.985)	Loss 7.3645e-02 (9.8538e-02) 
2023-05-25 22:24:15.942387: train Epoch: [29][ 16/129]	Time  2.653 ( 1.985)	Data  1.699 ( 1.027)	Loss 7.1087e-02 (9.6923e-02) 
2023-05-25 22:24:16.890969: train Epoch: [29][ 17/129]	Time  0.949 ( 1.928)	Data  0.001 ( 0.970)	Loss 4.6625e-02 (9.4129e-02) 
2023-05-25 22:24:19.652229: train Epoch: [29][ 18/129]	Time  2.761 ( 1.972)	Data  1.807 ( 1.014)	Loss 7.4780e-02 (9.3111e-02) 
2023-05-25 22:24:20.601515: train Epoch: [29][ 19/129]	Time  0.949 ( 1.921)	Data  0.001 ( 0.963)	Loss 1.6659e-01 (9.6785e-02) 
2023-05-25 22:24:23.318956: train Epoch: [29][ 20/129]	Time  2.717 ( 1.959)	Data  1.772 ( 1.002)	Loss 8.7884e-02 (9.6361e-02) 
2023-05-25 22:24:24.268211: train Epoch: [29][ 21/129]	Time  0.949 ( 1.913)	Data  0.001 ( 0.956)	Loss 1.7963e-01 (1.0015e-01) 
2023-05-25 22:24:26.970977: train Epoch: [29][ 22/129]	Time  2.703 ( 1.947)	Data  1.750 ( 0.991)	Loss 9.5952e-02 (9.9964e-02) 
2023-05-25 22:24:27.918984: train Epoch: [29][ 23/129]	Time  0.948 ( 1.905)	Data  0.001 ( 0.950)	Loss 7.6252e-02 (9.8976e-02) 
2023-05-25 22:24:30.839552: train Epoch: [29][ 24/129]	Time  2.921 ( 1.946)	Data  1.976 ( 0.991)	Loss 8.4450e-02 (9.8395e-02) 
2023-05-25 22:24:31.787488: train Epoch: [29][ 25/129]	Time  0.948 ( 1.908)	Data  0.001 ( 0.953)	Loss 7.2297e-02 (9.7391e-02) 
2023-05-25 22:24:34.460378: train Epoch: [29][ 26/129]	Time  2.673 ( 1.936)	Data  1.711 ( 0.981)	Loss 8.7215e-02 (9.7014e-02) 
2023-05-25 22:24:35.409507: train Epoch: [29][ 27/129]	Time  0.949 ( 1.901)	Data  0.001 ( 0.946)	Loss 8.4973e-02 (9.6584e-02) 
2023-05-25 22:24:38.179702: train Epoch: [29][ 28/129]	Time  2.770 ( 1.931)	Data  1.810 ( 0.976)	Loss 5.5096e-02 (9.5153e-02) 
2023-05-25 22:24:39.129527: train Epoch: [29][ 29/129]	Time  0.950 ( 1.898)	Data  0.001 ( 0.943)	Loss 1.0216e-01 (9.5387e-02) 
2023-05-25 22:24:41.836981: train Epoch: [29][ 30/129]	Time  2.707 ( 1.924)	Data  1.762 ( 0.969)	Loss 9.3018e-02 (9.5310e-02) 
2023-05-25 22:24:42.785428: train Epoch: [29][ 31/129]	Time  0.948 ( 1.894)	Data  0.001 ( 0.939)	Loss 1.0092e-01 (9.5485e-02) 
2023-05-25 22:24:45.417561: train Epoch: [29][ 32/129]	Time  2.632 ( 1.916)	Data  1.686 ( 0.962)	Loss 7.3686e-02 (9.4825e-02) 
2023-05-25 22:24:46.365635: train Epoch: [29][ 33/129]	Time  0.948 ( 1.888)	Data  0.001 ( 0.934)	Loss 7.0573e-02 (9.4112e-02) 
2023-05-25 22:24:49.010276: train Epoch: [29][ 34/129]	Time  2.645 ( 1.909)	Data  1.699 ( 0.955)	Loss 5.8416e-02 (9.3092e-02) 
2023-05-25 22:24:49.957815: train Epoch: [29][ 35/129]	Time  0.948 ( 1.882)	Data  0.001 ( 0.929)	Loss 7.9212e-02 (9.2706e-02) 
2023-05-25 22:24:52.621637: train Epoch: [29][ 36/129]	Time  2.664 ( 1.904)	Data  1.718 ( 0.950)	Loss 1.0352e-01 (9.2999e-02) 
2023-05-25 22:24:53.571656: train Epoch: [29][ 37/129]	Time  0.950 ( 1.878)	Data  0.001 ( 0.925)	Loss 5.9440e-02 (9.2115e-02) 
2023-05-25 22:24:56.171253: train Epoch: [29][ 38/129]	Time  2.600 ( 1.897)	Data  1.655 ( 0.944)	Loss 7.5421e-02 (9.1687e-02) 
2023-05-25 22:24:57.117430: train Epoch: [29][ 39/129]	Time  0.946 ( 1.873)	Data  0.001 ( 0.920)	Loss 1.1297e-01 (9.2220e-02) 
2023-05-25 22:24:59.770010: train Epoch: [29][ 40/129]	Time  2.653 ( 1.892)	Data  1.710 ( 0.940)	Loss 1.2037e-01 (9.2906e-02) 
2023-05-25 22:25:00.714312: train Epoch: [29][ 41/129]	Time  0.944 ( 1.870)	Data  0.001 ( 0.917)	Loss 7.4305e-02 (9.2463e-02) 
2023-05-25 22:25:03.348399: train Epoch: [29][ 42/129]	Time  2.634 ( 1.887)	Data  1.688 ( 0.935)	Loss 8.0071e-02 (9.2175e-02) 
2023-05-25 22:25:04.297331: train Epoch: [29][ 43/129]	Time  0.949 ( 1.866)	Data  0.001 ( 0.914)	Loss 8.9116e-02 (9.2106e-02) 
2023-05-25 22:25:06.916614: train Epoch: [29][ 44/129]	Time  2.619 ( 1.883)	Data  1.675 ( 0.931)	Loss 7.8363e-02 (9.1800e-02) 
2023-05-25 22:25:07.863425: train Epoch: [29][ 45/129]	Time  0.947 ( 1.862)	Data  0.001 ( 0.911)	Loss 1.3088e-01 (9.2650e-02) 
2023-05-25 22:25:10.501343: train Epoch: [29][ 46/129]	Time  2.638 ( 1.879)	Data  1.694 ( 0.927)	Loss 6.2539e-02 (9.2009e-02) 
2023-05-25 22:25:11.448325: train Epoch: [29][ 47/129]	Time  0.947 ( 1.860)	Data  0.001 ( 0.908)	Loss 7.9040e-02 (9.1739e-02) 
2023-05-25 22:25:14.031173: train Epoch: [29][ 48/129]	Time  2.583 ( 1.874)	Data  1.639 ( 0.923)	Loss 9.1576e-02 (9.1736e-02) 
2023-05-25 22:25:14.980001: train Epoch: [29][ 49/129]	Time  0.949 ( 1.856)	Data  0.001 ( 0.905)	Loss 5.1580e-02 (9.0933e-02) 
2023-05-25 22:25:17.685324: train Epoch: [29][ 50/129]	Time  2.705 ( 1.872)	Data  1.761 ( 0.921)	Loss 8.1040e-02 (9.0739e-02) 
2023-05-25 22:25:18.632089: train Epoch: [29][ 51/129]	Time  0.947 ( 1.855)	Data  0.001 ( 0.904)	Loss 8.4900e-02 (9.0626e-02) 
2023-05-25 22:25:21.378426: train Epoch: [29][ 52/129]	Time  2.746 ( 1.871)	Data  1.802 ( 0.921)	Loss 1.1070e-01 (9.1005e-02) 
2023-05-25 22:25:22.325521: train Epoch: [29][ 53/129]	Time  0.947 ( 1.854)	Data  0.001 ( 0.904)	Loss 7.1420e-02 (9.0643e-02) 
2023-05-25 22:25:24.979538: train Epoch: [29][ 54/129]	Time  2.654 ( 1.869)	Data  1.711 ( 0.918)	Loss 4.3336e-02 (8.9782e-02) 
2023-05-25 22:25:25.926869: train Epoch: [29][ 55/129]	Time  0.947 ( 1.852)	Data  0.001 ( 0.902)	Loss 5.9207e-02 (8.9236e-02) 
2023-05-25 22:25:28.540214: train Epoch: [29][ 56/129]	Time  2.613 ( 1.866)	Data  1.668 ( 0.915)	Loss 5.8156e-02 (8.8691e-02) 
2023-05-25 22:25:29.488836: train Epoch: [29][ 57/129]	Time  0.949 ( 1.850)	Data  0.001 ( 0.900)	Loss 1.2041e-01 (8.9238e-02) 
2023-05-25 22:25:32.200486: train Epoch: [29][ 58/129]	Time  2.712 ( 1.865)	Data  1.768 ( 0.914)	Loss 1.0099e-01 (8.9437e-02) 
2023-05-25 22:25:33.148411: train Epoch: [29][ 59/129]	Time  0.948 ( 1.849)	Data  0.001 ( 0.899)	Loss 9.9228e-02 (8.9600e-02) 
2023-05-25 22:25:35.763821: train Epoch: [29][ 60/129]	Time  2.615 ( 1.862)	Data  1.671 ( 0.912)	Loss 1.0452e-01 (8.9845e-02) 
2023-05-25 22:25:36.711671: train Epoch: [29][ 61/129]	Time  0.948 ( 1.847)	Data  0.001 ( 0.897)	Loss 1.1984e-01 (9.0329e-02) 
2023-05-25 22:25:39.310648: train Epoch: [29][ 62/129]	Time  2.599 ( 1.859)	Data  1.655 ( 0.909)	Loss 5.8098e-02 (8.9817e-02) 
2023-05-25 22:25:40.257686: train Epoch: [29][ 63/129]	Time  0.947 ( 1.845)	Data  0.001 ( 0.895)	Loss 1.2357e-01 (9.0344e-02) 
2023-05-25 22:25:42.980626: train Epoch: [29][ 64/129]	Time  2.723 ( 1.858)	Data  1.779 ( 0.908)	Loss 7.2584e-02 (9.0071e-02) 
2023-05-25 22:25:43.928300: train Epoch: [29][ 65/129]	Time  0.948 ( 1.845)	Data  0.001 ( 0.895)	Loss 1.1807e-01 (9.0495e-02) 
2023-05-25 22:25:46.653299: train Epoch: [29][ 66/129]	Time  2.725 ( 1.858)	Data  1.780 ( 0.908)	Loss 1.3444e-01 (9.1151e-02) 
2023-05-25 22:25:47.600242: train Epoch: [29][ 67/129]	Time  0.947 ( 1.844)	Data  0.001 ( 0.895)	Loss 7.7449e-02 (9.0950e-02) 
2023-05-25 22:25:50.210536: train Epoch: [29][ 68/129]	Time  2.610 ( 1.855)	Data  1.665 ( 0.906)	Loss 9.8370e-02 (9.1057e-02) 
2023-05-25 22:25:51.158712: train Epoch: [29][ 69/129]	Time  0.948 ( 1.842)	Data  0.001 ( 0.893)	Loss 8.9466e-02 (9.1035e-02) 
2023-05-25 22:25:53.847323: train Epoch: [29][ 70/129]	Time  2.689 ( 1.854)	Data  1.740 ( 0.905)	Loss 1.0765e-01 (9.1269e-02) 
2023-05-25 22:25:54.796655: train Epoch: [29][ 71/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.892)	Loss 1.9918e-01 (9.2767e-02) 
2023-05-25 22:25:57.567669: train Epoch: [29][ 72/129]	Time  2.771 ( 1.854)	Data  1.807 ( 0.905)	Loss 6.6568e-02 (9.2409e-02) 
2023-05-25 22:25:58.525543: train Epoch: [29][ 73/129]	Time  0.958 ( 1.842)	Data  0.001 ( 0.892)	Loss 1.1518e-01 (9.2716e-02) 
2023-05-25 22:26:01.257398: train Epoch: [29][ 74/129]	Time  2.732 ( 1.854)	Data  1.775 ( 0.904)	Loss 9.3657e-02 (9.2729e-02) 
2023-05-25 22:26:02.210423: train Epoch: [29][ 75/129]	Time  0.953 ( 1.842)	Data  0.001 ( 0.892)	Loss 8.2127e-02 (9.2589e-02) 
2023-05-25 22:26:04.918226: train Epoch: [29][ 76/129]	Time  2.708 ( 1.854)	Data  1.760 ( 0.904)	Loss 1.0403e-01 (9.2738e-02) 
2023-05-25 22:26:05.866490: train Epoch: [29][ 77/129]	Time  0.948 ( 1.842)	Data  0.001 ( 0.892)	Loss 1.1725e-01 (9.3052e-02) 
2023-05-25 22:26:08.441623: train Epoch: [29][ 78/129]	Time  2.575 ( 1.851)	Data  1.628 ( 0.901)	Loss 4.9100e-02 (9.2496e-02) 
2023-05-25 22:26:09.395925: train Epoch: [29][ 79/129]	Time  0.954 ( 1.840)	Data  0.001 ( 0.890)	Loss 9.8697e-02 (9.2573e-02) 
2023-05-25 22:26:12.057205: train Epoch: [29][ 80/129]	Time  2.661 ( 1.850)	Data  1.710 ( 0.900)	Loss 5.8490e-02 (9.2152e-02) 
2023-05-25 22:26:13.006710: train Epoch: [29][ 81/129]	Time  0.950 ( 1.839)	Data  0.001 ( 0.889)	Loss 1.0033e-01 (9.2252e-02) 
2023-05-25 22:26:15.625939: train Epoch: [29][ 82/129]	Time  2.619 ( 1.849)	Data  1.672 ( 0.899)	Loss 7.1044e-02 (9.1997e-02) 
2023-05-25 22:26:16.575523: train Epoch: [29][ 83/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.888)	Loss 1.0124e-01 (9.2107e-02) 
2023-05-25 22:26:19.354604: train Epoch: [29][ 84/129]	Time  2.779 ( 1.849)	Data  1.828 ( 0.899)	Loss 6.4652e-02 (9.1784e-02) 
2023-05-25 22:26:20.313754: train Epoch: [29][ 85/129]	Time  0.959 ( 1.839)	Data  0.001 ( 0.889)	Loss 3.9338e-02 (9.1174e-02) 
2023-05-25 22:26:22.900136: train Epoch: [29][ 86/129]	Time  2.586 ( 1.847)	Data  1.632 ( 0.897)	Loss 1.0807e-01 (9.1368e-02) 
2023-05-25 22:26:23.849149: train Epoch: [29][ 87/129]	Time  0.949 ( 1.837)	Data  0.001 ( 0.887)	Loss 4.9537e-02 (9.0893e-02) 
2023-05-25 22:26:26.442710: train Epoch: [29][ 88/129]	Time  2.594 ( 1.846)	Data  1.646 ( 0.896)	Loss 6.5069e-02 (9.0603e-02) 
2023-05-25 22:26:27.392308: train Epoch: [29][ 89/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.886)	Loss 1.7347e-01 (9.1523e-02) 
2023-05-25 22:26:30.080616: train Epoch: [29][ 90/129]	Time  2.688 ( 1.845)	Data  1.741 ( 0.895)	Loss 7.4210e-02 (9.1333e-02) 
2023-05-25 22:26:31.031079: train Epoch: [29][ 91/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.885)	Loss 6.7803e-02 (9.1077e-02) 
2023-05-25 22:26:33.781751: train Epoch: [29][ 92/129]	Time  2.751 ( 1.845)	Data  1.803 ( 0.895)	Loss 1.3379e-01 (9.1537e-02) 
2023-05-25 22:26:34.731133: train Epoch: [29][ 93/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.886)	Loss 1.6074e-01 (9.2273e-02) 
2023-05-25 22:26:37.389325: train Epoch: [29][ 94/129]	Time  2.658 ( 1.844)	Data  1.711 ( 0.894)	Loss 1.0196e-01 (9.2375e-02) 
2023-05-25 22:26:38.339952: train Epoch: [29][ 95/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.885)	Loss 1.1038e-01 (9.2562e-02) 
2023-05-25 22:26:40.936280: train Epoch: [29][ 96/129]	Time  2.596 ( 1.843)	Data  1.648 ( 0.893)	Loss 7.6972e-02 (9.2401e-02) 
2023-05-25 22:26:41.886856: train Epoch: [29][ 97/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.884)	Loss 5.7626e-02 (9.2047e-02) 
2023-05-25 22:26:44.586425: train Epoch: [29][ 98/129]	Time  2.700 ( 1.842)	Data  1.748 ( 0.892)	Loss 8.6415e-02 (9.1990e-02) 
2023-05-25 22:26:45.535891: train Epoch: [29][ 99/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.884)	Loss 6.4258e-02 (9.1712e-02) 
2023-05-25 22:26:48.207466: train Epoch: [29][100/129]	Time  2.672 ( 1.842)	Data  1.725 ( 0.892)	Loss 1.7230e-01 (9.2510e-02) 
2023-05-25 22:26:49.156636: train Epoch: [29][101/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.883)	Loss 6.6335e-02 (9.2254e-02) 
2023-05-25 22:26:51.910026: train Epoch: [29][102/129]	Time  2.753 ( 1.842)	Data  1.794 ( 0.892)	Loss 6.6661e-02 (9.2005e-02) 
2023-05-25 22:26:52.859967: train Epoch: [29][103/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.883)	Loss 8.8062e-02 (9.1967e-02) 
2023-05-25 22:26:55.452481: train Epoch: [29][104/129]	Time  2.593 ( 1.841)	Data  1.645 ( 0.891)	Loss 8.6450e-02 (9.1915e-02) 
2023-05-25 22:26:56.401929: train Epoch: [29][105/129]	Time  0.949 ( 1.832)	Data  0.001 ( 0.882)	Loss 1.2870e-01 (9.2262e-02) 
2023-05-25 22:26:59.032559: train Epoch: [29][106/129]	Time  2.631 ( 1.840)	Data  1.683 ( 0.890)	Loss 6.4179e-02 (9.1999e-02) 
2023-05-25 22:26:59.983572: train Epoch: [29][107/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.882)	Loss 8.9097e-02 (9.1973e-02) 
2023-05-25 22:27:02.565205: train Epoch: [29][108/129]	Time  2.582 ( 1.838)	Data  1.632 ( 0.888)	Loss 6.1717e-02 (9.1695e-02) 
2023-05-25 22:27:03.512920: train Epoch: [29][109/129]	Time  0.948 ( 1.830)	Data  0.001 ( 0.880)	Loss 1.3841e-01 (9.2120e-02) 
2023-05-25 22:27:06.204472: train Epoch: [29][110/129]	Time  2.692 ( 1.838)	Data  1.745 ( 0.888)	Loss 1.5269e-01 (9.2665e-02) 
2023-05-25 22:27:07.167890: train Epoch: [29][111/129]	Time  0.963 ( 1.830)	Data  0.001 ( 0.880)	Loss 7.2206e-02 (9.2483e-02) 
2023-05-25 22:27:09.890538: train Epoch: [29][112/129]	Time  2.723 ( 1.838)	Data  1.755 ( 0.888)	Loss 7.8279e-02 (9.2357e-02) 
2023-05-25 22:27:10.850183: train Epoch: [29][113/129]	Time  0.960 ( 1.830)	Data  0.001 ( 0.880)	Loss 5.1456e-02 (9.1998e-02) 
2023-05-25 22:27:13.503945: train Epoch: [29][114/129]	Time  2.654 ( 1.838)	Data  1.691 ( 0.887)	Loss 1.9525e-01 (9.2896e-02) 
2023-05-25 22:27:14.464293: train Epoch: [29][115/129]	Time  0.960 ( 1.830)	Data  0.001 ( 0.880)	Loss 7.4050e-02 (9.2733e-02) 
2023-05-25 22:27:17.060211: train Epoch: [29][116/129]	Time  2.596 ( 1.836)	Data  1.633 ( 0.886)	Loss 2.0313e-01 (9.3677e-02) 
2023-05-25 22:27:18.021349: train Epoch: [29][117/129]	Time  0.961 ( 1.829)	Data  0.001 ( 0.879)	Loss 7.1073e-02 (9.3486e-02) 
2023-05-25 22:27:20.609665: train Epoch: [29][118/129]	Time  2.588 ( 1.835)	Data  1.625 ( 0.885)	Loss 7.2221e-02 (9.3307e-02) 
2023-05-25 22:27:21.571033: train Epoch: [29][119/129]	Time  0.961 ( 1.828)	Data  0.001 ( 0.877)	Loss 7.1849e-02 (9.3128e-02) 
2023-05-25 22:27:24.215359: train Epoch: [29][120/129]	Time  2.644 ( 1.835)	Data  1.685 ( 0.884)	Loss 1.7628e-01 (9.3815e-02) 
2023-05-25 22:27:25.164806: train Epoch: [29][121/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.877)	Loss 7.9648e-02 (9.3699e-02) 
2023-05-25 22:27:27.699654: train Epoch: [29][122/129]	Time  2.535 ( 1.833)	Data  1.589 ( 0.883)	Loss 8.2486e-02 (9.3608e-02) 
2023-05-25 22:27:28.649038: train Epoch: [29][123/129]	Time  0.949 ( 1.826)	Data  0.001 ( 0.876)	Loss 1.1395e-01 (9.3772e-02) 
2023-05-25 22:27:31.369616: train Epoch: [29][124/129]	Time  2.721 ( 1.833)	Data  1.771 ( 0.883)	Loss 1.0425e-01 (9.3856e-02) 
2023-05-25 22:27:32.319116: train Epoch: [29][125/129]	Time  0.949 ( 1.826)	Data  0.001 ( 0.876)	Loss 6.3597e-02 (9.3616e-02) 
2023-05-25 22:27:34.935993: train Epoch: [29][126/129]	Time  2.617 ( 1.833)	Data  1.670 ( 0.882)	Loss 8.6578e-02 (9.3560e-02) 
2023-05-25 22:27:35.880814: train Epoch: [29][127/129]	Time  0.945 ( 1.826)	Data  0.001 ( 0.875)	Loss 9.7635e-02 (9.3592e-02) 
2023-05-25 22:27:37.453085: train Epoch: [29][128/129]	Time  1.572 ( 1.824)	Data  0.627 ( 0.873)	Loss 8.4136e-02 (9.3519e-02) 
2023-05-25 22:27:37.483832: Train Epoch done in 235.2949445130016 s 
2023-05-25 22:27:39.789941: val Epoch: [29][ 0/72]	Time  1.560 ( 1.560)	Data  1.383 ( 1.383)	Loss 5.1049e-02 (5.1049e-02) 
2023-05-25 22:27:39.906950: val Epoch: [29][ 1/72]	Time  0.117 ( 0.838)	Data  0.001 ( 0.692)	Loss 6.5347e-02 (5.8198e-02) 
2023-05-25 22:27:40.987354: val Epoch: [29][ 2/72]	Time  1.080 ( 0.919)	Data  0.962 ( 0.782)	Loss 1.2983e-01 (8.2077e-02) 
2023-05-25 22:27:41.104864: val Epoch: [29][ 3/72]	Time  0.117 ( 0.719)	Data  0.001 ( 0.587)	Loss 2.2035e-01 (1.1664e-01) 
2023-05-25 22:27:42.260330: val Epoch: [29][ 4/72]	Time  1.155 ( 0.806)	Data  1.037 ( 0.677)	Loss 1.4026e-01 (1.2137e-01) 
2023-05-25 22:27:42.377805: val Epoch: [29][ 5/72]	Time  0.117 ( 0.691)	Data  0.001 ( 0.564)	Loss 9.5582e-02 (1.1707e-01) 
2023-05-25 22:27:43.565123: val Epoch: [29][ 6/72]	Time  1.187 ( 0.762)	Data  1.069 ( 0.636)	Loss 2.9968e-01 (1.4316e-01) 
2023-05-25 22:27:43.682075: val Epoch: [29][ 7/72]	Time  0.117 ( 0.682)	Data  0.001 ( 0.557)	Loss 1.0010e-01 (1.3778e-01) 
2023-05-25 22:27:44.869372: val Epoch: [29][ 8/72]	Time  1.187 ( 0.738)	Data  1.070 ( 0.614)	Loss 3.7328e-01 (1.6394e-01) 
2023-05-25 22:27:44.986066: val Epoch: [29][ 9/72]	Time  0.117 ( 0.676)	Data  0.000 ( 0.552)	Loss 5.6049e-02 (1.5315e-01) 
2023-05-25 22:27:46.124422: val Epoch: [29][10/72]	Time  1.138 ( 0.718)	Data  1.021 ( 0.595)	Loss 6.6828e-02 (1.4531e-01) 
2023-05-25 22:27:46.242128: val Epoch: [29][11/72]	Time  0.118 ( 0.668)	Data  0.001 ( 0.545)	Loss 9.8261e-02 (1.4139e-01) 
2023-05-25 22:27:47.350622: val Epoch: [29][12/72]	Time  1.108 ( 0.702)	Data  0.989 ( 0.580)	Loss 5.4391e-02 (1.3469e-01) 
2023-05-25 22:27:47.467551: val Epoch: [29][13/72]	Time  0.117 ( 0.660)	Data  0.000 ( 0.538)	Loss 1.2961e-01 (1.3433e-01) 
2023-05-25 22:27:48.656134: val Epoch: [29][14/72]	Time  1.189 ( 0.695)	Data  1.070 ( 0.574)	Loss 7.4894e-02 (1.3037e-01) 
2023-05-25 22:27:48.772828: val Epoch: [29][15/72]	Time  0.117 ( 0.659)	Data  0.000 ( 0.538)	Loss 1.4100e-01 (1.3103e-01) 
2023-05-25 22:27:49.988867: val Epoch: [29][16/72]	Time  1.216 ( 0.692)	Data  1.098 ( 0.571)	Loss 9.6098e-02 (1.2898e-01) 
2023-05-25 22:27:50.105663: val Epoch: [29][17/72]	Time  0.117 ( 0.660)	Data  0.000 ( 0.539)	Loss 4.5911e-01 (1.4732e-01) 
2023-05-25 22:27:51.256019: val Epoch: [29][18/72]	Time  1.150 ( 0.686)	Data  1.031 ( 0.565)	Loss 6.0925e-02 (1.4277e-01) 
2023-05-25 22:27:51.374179: val Epoch: [29][19/72]	Time  0.118 ( 0.657)	Data  0.000 ( 0.537)	Loss 4.2015e-01 (1.5664e-01) 
2023-05-25 22:27:52.549675: val Epoch: [29][20/72]	Time  1.175 ( 0.682)	Data  1.058 ( 0.562)	Loss 3.3641e-01 (1.6520e-01) 
2023-05-25 22:27:52.666922: val Epoch: [29][21/72]	Time  0.117 ( 0.656)	Data  0.000 ( 0.536)	Loss 1.4827e-01 (1.6443e-01) 
2023-05-25 22:27:53.828101: val Epoch: [29][22/72]	Time  1.161 ( 0.678)	Data  1.043 ( 0.558)	Loss 1.7364e-01 (1.6483e-01) 
2023-05-25 22:27:53.944992: val Epoch: [29][23/72]	Time  0.117 ( 0.655)	Data  0.000 ( 0.535)	Loss 1.2642e-01 (1.6323e-01) 
2023-05-25 22:27:55.085196: val Epoch: [29][24/72]	Time  1.140 ( 0.674)	Data  1.023 ( 0.554)	Loss 1.9222e-01 (1.6439e-01) 
2023-05-25 22:27:55.201734: val Epoch: [29][25/72]	Time  0.117 ( 0.653)	Data  0.000 ( 0.533)	Loss 2.2115e-01 (1.6657e-01) 
2023-05-25 22:27:56.326926: val Epoch: [29][26/72]	Time  1.125 ( 0.670)	Data  1.008 ( 0.551)	Loss 4.9261e-01 (1.7865e-01) 
2023-05-25 22:27:56.444042: val Epoch: [29][27/72]	Time  0.117 ( 0.650)	Data  0.000 ( 0.531)	Loss 1.1224e-01 (1.7628e-01) 
2023-05-25 22:27:57.565544: val Epoch: [29][28/72]	Time  1.121 ( 0.667)	Data  1.004 ( 0.547)	Loss 9.2137e-02 (1.7338e-01) 
2023-05-25 22:27:57.682906: val Epoch: [29][29/72]	Time  0.117 ( 0.648)	Data  0.000 ( 0.529)	Loss 1.0987e-01 (1.7126e-01) 
2023-05-25 22:27:58.802120: val Epoch: [29][30/72]	Time  1.119 ( 0.664)	Data  1.002 ( 0.544)	Loss 5.6355e-02 (1.6755e-01) 
2023-05-25 22:27:58.918650: val Epoch: [29][31/72]	Time  0.117 ( 0.647)	Data  0.000 ( 0.527)	Loss 9.0723e-02 (1.6515e-01) 
2023-05-25 22:27:59.995631: val Epoch: [29][32/72]	Time  1.077 ( 0.660)	Data  0.960 ( 0.540)	Loss 6.3778e-02 (1.6208e-01) 
2023-05-25 22:28:00.112058: val Epoch: [29][33/72]	Time  0.116 ( 0.644)	Data  0.001 ( 0.525)	Loss 7.8562e-02 (1.5962e-01) 
2023-05-25 22:28:01.194041: val Epoch: [29][34/72]	Time  1.082 ( 0.656)	Data  0.964 ( 0.537)	Loss 8.4365e-02 (1.5747e-01) 
2023-05-25 22:28:01.310661: val Epoch: [29][35/72]	Time  0.117 ( 0.641)	Data  0.001 ( 0.522)	Loss 1.0851e-01 (1.5611e-01) 
2023-05-25 22:28:02.404379: val Epoch: [29][36/72]	Time  1.094 ( 0.653)	Data  0.976 ( 0.535)	Loss 6.8177e-02 (1.5374e-01) 
2023-05-25 22:28:02.521313: val Epoch: [29][37/72]	Time  0.117 ( 0.639)	Data  0.000 ( 0.520)	Loss 6.3393e-02 (1.5136e-01) 
2023-05-25 22:28:03.595797: val Epoch: [29][38/72]	Time  1.074 ( 0.650)	Data  0.957 ( 0.532)	Loss 4.8607e-02 (1.4872e-01) 
2023-05-25 22:28:03.712779: val Epoch: [29][39/72]	Time  0.117 ( 0.637)	Data  0.001 ( 0.518)	Loss 5.4764e-02 (1.4638e-01) 
2023-05-25 22:28:04.858040: val Epoch: [29][40/72]	Time  1.145 ( 0.649)	Data  1.028 ( 0.531)	Loss 3.5680e-01 (1.5151e-01) 
2023-05-25 22:28:04.974938: val Epoch: [29][41/72]	Time  0.117 ( 0.637)	Data  0.000 ( 0.518)	Loss 1.1089e-01 (1.5054e-01) 
2023-05-25 22:28:06.107399: val Epoch: [29][42/72]	Time  1.132 ( 0.648)	Data  1.015 ( 0.530)	Loss 4.2537e-01 (1.5693e-01) 
2023-05-25 22:28:06.224714: val Epoch: [29][43/72]	Time  0.117 ( 0.636)	Data  0.000 ( 0.518)	Loss 9.4814e-02 (1.5552e-01) 
2023-05-25 22:28:07.355196: val Epoch: [29][44/72]	Time  1.130 ( 0.647)	Data  1.013 ( 0.529)	Loss 8.5082e-02 (1.5395e-01) 
2023-05-25 22:28:07.472430: val Epoch: [29][45/72]	Time  0.117 ( 0.636)	Data  0.000 ( 0.517)	Loss 7.2707e-02 (1.5219e-01) 
2023-05-25 22:28:08.642529: val Epoch: [29][46/72]	Time  1.170 ( 0.647)	Data  1.049 ( 0.529)	Loss 5.6726e-02 (1.5016e-01) 
2023-05-25 22:28:08.763956: val Epoch: [29][47/72]	Time  0.121 ( 0.636)	Data  0.001 ( 0.518)	Loss 7.5252e-02 (1.4860e-01) 
2023-05-25 22:28:09.867750: val Epoch: [29][48/72]	Time  1.104 ( 0.646)	Data  0.982 ( 0.527)	Loss 5.0429e-02 (1.4659e-01) 
2023-05-25 22:28:09.989101: val Epoch: [29][49/72]	Time  0.121 ( 0.635)	Data  0.001 ( 0.516)	Loss 5.2963e-02 (1.4472e-01) 
2023-05-25 22:28:11.136544: val Epoch: [29][50/72]	Time  1.147 ( 0.645)	Data  1.026 ( 0.526)	Loss 3.9142e-01 (1.4956e-01) 
2023-05-25 22:28:11.258539: val Epoch: [29][51/72]	Time  0.122 ( 0.635)	Data  0.001 ( 0.516)	Loss 3.5247e-01 (1.5346e-01) 
2023-05-25 22:28:12.381098: val Epoch: [29][52/72]	Time  1.123 ( 0.644)	Data  1.001 ( 0.526)	Loss 1.9187e-01 (1.5418e-01) 
2023-05-25 22:28:12.502757: val Epoch: [29][53/72]	Time  0.122 ( 0.635)	Data  0.001 ( 0.516)	Loss 4.8101e-02 (1.5222e-01) 
2023-05-25 22:28:13.639501: val Epoch: [29][54/72]	Time  1.137 ( 0.644)	Data  1.011 ( 0.525)	Loss 4.8093e-02 (1.5033e-01) 
2023-05-25 22:28:13.761014: val Epoch: [29][55/72]	Time  0.122 ( 0.634)	Data  0.001 ( 0.515)	Loss 4.0555e-02 (1.4837e-01) 
2023-05-25 22:28:14.870382: val Epoch: [29][56/72]	Time  1.109 ( 0.643)	Data  0.988 ( 0.524)	Loss 4.5507e-02 (1.4656e-01) 
2023-05-25 22:28:14.991720: val Epoch: [29][57/72]	Time  0.121 ( 0.634)	Data  0.001 ( 0.515)	Loss 7.5522e-02 (1.4534e-01) 
2023-05-25 22:28:16.111116: val Epoch: [29][58/72]	Time  1.119 ( 0.642)	Data  0.997 ( 0.523)	Loss 1.1932e-01 (1.4490e-01) 
2023-05-25 22:28:16.233328: val Epoch: [29][59/72]	Time  0.122 ( 0.633)	Data  0.001 ( 0.514)	Loss 1.5123e-01 (1.4500e-01) 
2023-05-25 22:28:17.348270: val Epoch: [29][60/72]	Time  1.115 ( 0.641)	Data  0.993 ( 0.522)	Loss 6.3418e-02 (1.4366e-01) 
2023-05-25 22:28:17.469442: val Epoch: [29][61/72]	Time  0.121 ( 0.633)	Data  0.001 ( 0.514)	Loss 6.1852e-02 (1.4235e-01) 
2023-05-25 22:28:18.589250: val Epoch: [29][62/72]	Time  1.120 ( 0.641)	Data  0.998 ( 0.521)	Loss 8.9676e-02 (1.4151e-01) 
2023-05-25 22:28:18.710876: val Epoch: [29][63/72]	Time  0.122 ( 0.633)	Data  0.001 ( 0.513)	Loss 6.0103e-02 (1.4024e-01) 
2023-05-25 22:28:19.868090: val Epoch: [29][64/72]	Time  1.157 ( 0.641)	Data  1.035 ( 0.521)	Loss 4.3193e-01 (1.4472e-01) 
2023-05-25 22:28:19.989497: val Epoch: [29][65/72]	Time  0.121 ( 0.633)	Data  0.001 ( 0.513)	Loss 1.3452e-01 (1.4457e-01) 
2023-05-25 22:28:21.106018: val Epoch: [29][66/72]	Time  1.117 ( 0.640)	Data  0.994 ( 0.521)	Loss 8.3014e-02 (1.4365e-01) 
2023-05-25 22:28:21.227698: val Epoch: [29][67/72]	Time  0.122 ( 0.632)	Data  0.001 ( 0.513)	Loss 4.5727e-02 (1.4221e-01) 
2023-05-25 22:28:22.333545: val Epoch: [29][68/72]	Time  1.106 ( 0.639)	Data  0.979 ( 0.520)	Loss 4.5311e-02 (1.4081e-01) 
2023-05-25 22:28:22.454957: val Epoch: [29][69/72]	Time  0.121 ( 0.632)	Data  0.000 ( 0.512)	Loss 8.6141e-02 (1.4003e-01) 
2023-05-25 22:28:23.497368: val Epoch: [29][70/72]	Time  1.042 ( 0.638)	Data  0.922 ( 0.518)	Loss 4.4674e-02 (1.3868e-01) 
2023-05-25 22:28:23.613333: val Epoch: [29][71/72]	Time  0.116 ( 0.630)	Data  0.000 ( 0.511)	Loss 3.0648e-01 (1.4101e-01) 
2023-05-25 22:28:23.785866: Epoch 29 :Val : ['ET : 0.719334602355957', 'TC : 0.7593701481819153', 'WT : 0.8511251211166382'] 
2023-05-25 22:28:23.788730: Epoch 29 :Val : ['ET : 0.719334602355957', 'TC : 0.7593701481819153', 'WT : 0.8511251211166382'] 
2023-05-25 22:28:23.790642: Val epoch done in 46.30681427499985 s 
2023-05-25 22:28:23.795958: Batches per epoch:  129 
2023-05-25 22:28:28.556997: train Epoch: [30][  0/129]	Time  4.761 ( 4.761)	Data  3.733 ( 3.733)	Loss 1.1464e-01 (1.1464e-01) 
2023-05-25 22:28:29.517099: train Epoch: [30][  1/129]	Time  0.960 ( 2.860)	Data  0.001 ( 1.867)	Loss 1.1616e-01 (1.1540e-01) 
2023-05-25 22:28:32.133710: train Epoch: [30][  2/129]	Time  2.617 ( 2.779)	Data  1.659 ( 1.798)	Loss 1.2057e-01 (1.1712e-01) 
2023-05-25 22:28:33.093989: train Epoch: [30][  3/129]	Time  0.960 ( 2.324)	Data  0.001 ( 1.348)	Loss 8.3738e-02 (1.0878e-01) 
2023-05-25 22:28:35.667971: train Epoch: [30][  4/129]	Time  2.574 ( 2.374)	Data  1.616 ( 1.402)	Loss 1.0449e-01 (1.0792e-01) 
2023-05-25 22:28:36.629781: train Epoch: [30][  5/129]	Time  0.962 ( 2.139)	Data  0.001 ( 1.168)	Loss 7.3706e-02 (1.0222e-01) 
2023-05-25 22:28:39.448266: train Epoch: [30][  6/129]	Time  2.818 ( 2.236)	Data  1.855 ( 1.266)	Loss 7.0146e-02 (9.7636e-02) 
2023-05-25 22:28:40.408920: train Epoch: [30][  7/129]	Time  0.961 ( 2.077)	Data  0.001 ( 1.108)	Loss 1.4827e-01 (1.0397e-01) 
2023-05-25 22:28:43.118094: train Epoch: [30][  8/129]	Time  2.709 ( 2.147)	Data  1.746 ( 1.179)	Loss 8.4508e-02 (1.0180e-01) 
2023-05-25 22:28:44.078820: train Epoch: [30][  9/129]	Time  0.961 ( 2.028)	Data  0.001 ( 1.061)	Loss 6.4040e-02 (9.8027e-02) 
2023-05-25 22:28:46.709670: train Epoch: [30][ 10/129]	Time  2.631 ( 2.083)	Data  1.671 ( 1.117)	Loss 9.8515e-02 (9.8071e-02) 
2023-05-25 22:28:47.670440: train Epoch: [30][ 11/129]	Time  0.961 ( 1.990)	Data  0.001 ( 1.024)	Loss 1.0195e-01 (9.8394e-02) 
2023-05-25 22:28:50.306760: train Epoch: [30][ 12/129]	Time  2.636 ( 2.039)	Data  1.676 ( 1.074)	Loss 8.1164e-02 (9.7069e-02) 
2023-05-25 22:28:51.270035: train Epoch: [30][ 13/129]	Time  0.963 ( 1.962)	Data  0.001 ( 0.997)	Loss 9.6634e-02 (9.7038e-02) 
2023-05-25 22:28:53.905518: train Epoch: [30][ 14/129]	Time  2.635 ( 2.007)	Data  1.667 ( 1.042)	Loss 1.2085e-01 (9.8625e-02) 
2023-05-25 22:28:54.865328: train Epoch: [30][ 15/129]	Time  0.960 ( 1.942)	Data  0.001 ( 0.977)	Loss 6.5839e-02 (9.6576e-02) 
2023-05-25 22:28:57.500473: train Epoch: [30][ 16/129]	Time  2.635 ( 1.983)	Data  1.680 ( 1.018)	Loss 5.9009e-02 (9.4366e-02) 
2023-05-25 22:28:58.450794: train Epoch: [30][ 17/129]	Time  0.950 ( 1.925)	Data  0.001 ( 0.962)	Loss 7.4569e-02 (9.3266e-02) 
2023-05-25 22:29:01.178064: train Epoch: [30][ 18/129]	Time  2.727 ( 1.967)	Data  1.772 ( 1.004)	Loss 7.6735e-02 (9.2396e-02) 
2023-05-25 22:29:02.131548: train Epoch: [30][ 19/129]	Time  0.953 ( 1.917)	Data  0.001 ( 0.954)	Loss 8.1691e-02 (9.1861e-02) 
2023-05-25 22:29:04.874012: train Epoch: [30][ 20/129]	Time  2.742 ( 1.956)	Data  1.784 ( 0.994)	Loss 7.9085e-02 (9.1253e-02) 
2023-05-25 22:29:05.824151: train Epoch: [30][ 21/129]	Time  0.950 ( 1.910)	Data  0.001 ( 0.949)	Loss 1.1780e-01 (9.2459e-02) 
2023-05-25 22:29:08.442039: train Epoch: [30][ 22/129]	Time  2.618 ( 1.941)	Data  1.663 ( 0.980)	Loss 1.1108e-01 (9.3269e-02) 
2023-05-25 22:29:09.390424: train Epoch: [30][ 23/129]	Time  0.948 ( 1.900)	Data  0.001 ( 0.939)	Loss 2.4877e-01 (9.9748e-02) 
2023-05-25 22:29:11.914562: train Epoch: [30][ 24/129]	Time  2.524 ( 1.925)	Data  1.565 ( 0.964)	Loss 6.7534e-02 (9.8460e-02) 
2023-05-25 22:29:12.865569: train Epoch: [30][ 25/129]	Time  0.951 ( 1.887)	Data  0.001 ( 0.927)	Loss 5.8579e-02 (9.6926e-02) 
2023-05-25 22:29:15.598179: train Epoch: [30][ 26/129]	Time  2.733 ( 1.919)	Data  1.782 ( 0.959)	Loss 1.0717e-01 (9.7305e-02) 
2023-05-25 22:29:16.548162: train Epoch: [30][ 27/129]	Time  0.950 ( 1.884)	Data  0.001 ( 0.924)	Loss 7.5779e-02 (9.6536e-02) 
2023-05-25 22:29:19.187117: train Epoch: [30][ 28/129]	Time  2.639 ( 1.910)	Data  1.691 ( 0.951)	Loss 1.3458e-01 (9.7848e-02) 
2023-05-25 22:29:20.136354: train Epoch: [30][ 29/129]	Time  0.949 ( 1.878)	Data  0.001 ( 0.919)	Loss 7.9955e-02 (9.7252e-02) 
2023-05-25 22:29:22.628191: train Epoch: [30][ 30/129]	Time  2.492 ( 1.898)	Data  1.541 ( 0.939)	Loss 5.5751e-02 (9.5913e-02) 
2023-05-25 22:29:23.579954: train Epoch: [30][ 31/129]	Time  0.952 ( 1.868)	Data  0.001 ( 0.910)	Loss 1.0165e-01 (9.6092e-02) 
2023-05-25 22:29:26.192886: train Epoch: [30][ 32/129]	Time  2.613 ( 1.891)	Data  1.652 ( 0.932)	Loss 6.7902e-02 (9.5238e-02) 
2023-05-25 22:29:27.143935: train Epoch: [30][ 33/129]	Time  0.951 ( 1.863)	Data  0.001 ( 0.905)	Loss 5.3684e-02 (9.4016e-02) 
2023-05-25 22:29:29.813457: train Epoch: [30][ 34/129]	Time  2.670 ( 1.886)	Data  1.722 ( 0.928)	Loss 8.6577e-02 (9.3803e-02) 
2023-05-25 22:29:30.763501: train Epoch: [30][ 35/129]	Time  0.950 ( 1.860)	Data  0.001 ( 0.903)	Loss 5.9716e-02 (9.2856e-02) 
2023-05-25 22:29:33.379506: train Epoch: [30][ 36/129]	Time  2.616 ( 1.881)	Data  1.667 ( 0.923)	Loss 6.3329e-02 (9.2058e-02) 
2023-05-25 22:29:34.330665: train Epoch: [30][ 37/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.899)	Loss 1.3366e-01 (9.3153e-02) 
2023-05-25 22:29:37.042731: train Epoch: [30][ 38/129]	Time  2.712 ( 1.878)	Data  1.764 ( 0.921)	Loss 9.3724e-02 (9.3168e-02) 
2023-05-25 22:29:37.992520: train Epoch: [30][ 39/129]	Time  0.950 ( 1.855)	Data  0.001 ( 0.898)	Loss 8.0698e-02 (9.2856e-02) 
2023-05-25 22:29:40.645836: train Epoch: [30][ 40/129]	Time  2.653 ( 1.874)	Data  1.706 ( 0.918)	Loss 8.6799e-02 (9.2708e-02) 
2023-05-25 22:29:41.595616: train Epoch: [30][ 41/129]	Time  0.950 ( 1.852)	Data  0.001 ( 0.896)	Loss 6.9987e-02 (9.2167e-02) 
2023-05-25 22:29:44.183626: train Epoch: [30][ 42/129]	Time  2.588 ( 1.869)	Data  1.631 ( 0.913)	Loss 6.3014e-02 (9.1489e-02) 
2023-05-25 22:29:45.133261: train Epoch: [30][ 43/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.892)	Loss 3.2183e-02 (9.0141e-02) 
2023-05-25 22:29:47.752450: train Epoch: [30][ 44/129]	Time  2.619 ( 1.866)	Data  1.663 ( 0.910)	Loss 1.0267e-01 (9.0420e-02) 
2023-05-25 22:29:48.711708: train Epoch: [30][ 45/129]	Time  0.959 ( 1.846)	Data  0.001 ( 0.890)	Loss 6.8498e-02 (8.9943e-02) 
2023-05-25 22:29:51.301624: train Epoch: [30][ 46/129]	Time  2.590 ( 1.862)	Data  1.631 ( 0.906)	Loss 8.5186e-02 (8.9842e-02) 
2023-05-25 22:29:52.262345: train Epoch: [30][ 47/129]	Time  0.961 ( 1.843)	Data  0.001 ( 0.887)	Loss 8.6866e-02 (8.9780e-02) 
2023-05-25 22:29:54.877447: train Epoch: [30][ 48/129]	Time  2.615 ( 1.859)	Data  1.657 ( 0.902)	Loss 8.9033e-02 (8.9765e-02) 
2023-05-25 22:29:55.838398: train Epoch: [30][ 49/129]	Time  0.961 ( 1.841)	Data  0.001 ( 0.884)	Loss 8.3747e-02 (8.9644e-02) 
2023-05-25 22:29:58.512876: train Epoch: [30][ 50/129]	Time  2.674 ( 1.857)	Data  1.726 ( 0.901)	Loss 8.4445e-02 (8.9543e-02) 
2023-05-25 22:29:59.462828: train Epoch: [30][ 51/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.884)	Loss 8.2452e-02 (8.9406e-02) 
2023-05-25 22:30:02.137200: train Epoch: [30][ 52/129]	Time  2.674 ( 1.855)	Data  1.723 ( 0.899)	Loss 1.0503e-01 (8.9701e-02) 
2023-05-25 22:30:03.085437: train Epoch: [30][ 53/129]	Time  0.948 ( 1.839)	Data  0.001 ( 0.883)	Loss 7.7970e-02 (8.9484e-02) 
2023-05-25 22:30:05.635171: train Epoch: [30][ 54/129]	Time  2.550 ( 1.852)	Data  1.602 ( 0.896)	Loss 7.2094e-02 (8.9168e-02) 
2023-05-25 22:30:06.584509: train Epoch: [30][ 55/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.880)	Loss 5.2235e-02 (8.8508e-02) 
2023-05-25 22:30:09.221485: train Epoch: [30][ 56/129]	Time  2.637 ( 1.850)	Data  1.678 ( 0.894)	Loss 8.9254e-02 (8.8521e-02) 
2023-05-25 22:30:10.172204: train Epoch: [30][ 57/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.878)	Loss 6.1460e-02 (8.8055e-02) 
2023-05-25 22:30:12.821613: train Epoch: [30][ 58/129]	Time  2.649 ( 1.848)	Data  1.700 ( 0.892)	Loss 1.0298e-01 (8.8307e-02) 
2023-05-25 22:30:13.772368: train Epoch: [30][ 59/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.878)	Loss 6.2735e-02 (8.7881e-02) 
2023-05-25 22:30:16.317683: train Epoch: [30][ 60/129]	Time  2.545 ( 1.845)	Data  1.594 ( 0.889)	Loss 8.0434e-02 (8.7759e-02) 
2023-05-25 22:30:17.269950: train Epoch: [30][ 61/129]	Time  0.952 ( 1.830)	Data  0.001 ( 0.875)	Loss 6.0049e-02 (8.7312e-02) 
2023-05-25 22:30:19.852733: train Epoch: [30][ 62/129]	Time  2.583 ( 1.842)	Data  1.636 ( 0.887)	Loss 6.3435e-02 (8.6933e-02) 
2023-05-25 22:30:20.803032: train Epoch: [30][ 63/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.873)	Loss 6.5572e-02 (8.6600e-02) 
2023-05-25 22:30:23.437712: train Epoch: [30][ 64/129]	Time  2.635 ( 1.841)	Data  1.675 ( 0.886)	Loss 8.7062e-02 (8.6607e-02) 
2023-05-25 22:30:24.387102: train Epoch: [30][ 65/129]	Time  0.949 ( 1.827)	Data  0.001 ( 0.872)	Loss 1.1534e-01 (8.7042e-02) 
2023-05-25 22:30:27.071956: train Epoch: [30][ 66/129]	Time  2.685 ( 1.840)	Data  1.726 ( 0.885)	Loss 1.2821e-01 (8.7656e-02) 
2023-05-25 22:30:28.022366: train Epoch: [30][ 67/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.872)	Loss 1.1568e-01 (8.8069e-02) 
2023-05-25 22:30:30.798264: train Epoch: [30][ 68/129]	Time  2.776 ( 1.841)	Data  1.816 ( 0.886)	Loss 7.7758e-02 (8.7919e-02) 
2023-05-25 22:30:31.750241: train Epoch: [30][ 69/129]	Time  0.952 ( 1.828)	Data  0.001 ( 0.873)	Loss 1.0627e-01 (8.8181e-02) 
2023-05-25 22:30:34.456236: train Epoch: [30][ 70/129]	Time  2.706 ( 1.840)	Data  1.751 ( 0.885)	Loss 8.3664e-02 (8.8118e-02) 
2023-05-25 22:30:35.406040: train Epoch: [30][ 71/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.873)	Loss 6.8769e-02 (8.7849e-02) 
2023-05-25 22:30:38.016363: train Epoch: [30][ 72/129]	Time  2.610 ( 1.839)	Data  1.647 ( 0.884)	Loss 6.2907e-02 (8.7507e-02) 
2023-05-25 22:30:38.976002: train Epoch: [30][ 73/129]	Time  0.960 ( 1.827)	Data  0.001 ( 0.872)	Loss 1.4936e-01 (8.8343e-02) 
2023-05-25 22:30:41.585853: train Epoch: [30][ 74/129]	Time  2.610 ( 1.837)	Data  1.653 ( 0.882)	Loss 8.3436e-02 (8.8278e-02) 
2023-05-25 22:30:42.545817: train Epoch: [30][ 75/129]	Time  0.960 ( 1.826)	Data  0.001 ( 0.870)	Loss 1.3327e-01 (8.8870e-02) 
2023-05-25 22:30:45.132704: train Epoch: [30][ 76/129]	Time  2.587 ( 1.836)	Data  1.629 ( 0.880)	Loss 9.2776e-02 (8.8920e-02) 
2023-05-25 22:30:46.081943: train Epoch: [30][ 77/129]	Time  0.949 ( 1.824)	Data  0.001 ( 0.869)	Loss 7.5646e-02 (8.8750e-02) 
2023-05-25 22:30:48.648030: train Epoch: [30][ 78/129]	Time  2.566 ( 1.834)	Data  1.602 ( 0.878)	Loss 1.3686e-01 (8.9359e-02) 
2023-05-25 22:30:49.605045: train Epoch: [30][ 79/129]	Time  0.957 ( 1.823)	Data  0.001 ( 0.867)	Loss 9.4098e-02 (8.9418e-02) 
2023-05-25 22:30:52.253292: train Epoch: [30][ 80/129]	Time  2.648 ( 1.833)	Data  1.701 ( 0.878)	Loss 1.4449e-01 (9.0098e-02) 
2023-05-25 22:30:53.201589: train Epoch: [30][ 81/129]	Time  0.948 ( 1.822)	Data  0.001 ( 0.867)	Loss 6.8015e-02 (8.9829e-02) 
2023-05-25 22:30:55.870962: train Epoch: [30][ 82/129]	Time  2.669 ( 1.832)	Data  1.723 ( 0.877)	Loss 7.3259e-02 (8.9629e-02) 
2023-05-25 22:30:56.820018: train Epoch: [30][ 83/129]	Time  0.949 ( 1.822)	Data  0.001 ( 0.867)	Loss 7.4952e-02 (8.9455e-02) 
2023-05-25 22:30:59.458486: train Epoch: [30][ 84/129]	Time  2.638 ( 1.831)	Data  1.680 ( 0.876)	Loss 8.1994e-02 (8.9367e-02) 
2023-05-25 22:31:00.409500: train Epoch: [30][ 85/129]	Time  0.951 ( 1.821)	Data  0.001 ( 0.866)	Loss 1.3644e-01 (8.9914e-02) 
2023-05-25 22:31:03.072001: train Epoch: [30][ 86/129]	Time  2.662 ( 1.831)	Data  1.716 ( 0.876)	Loss 1.1163e-01 (9.0164e-02) 
2023-05-25 22:31:04.033100: train Epoch: [30][ 87/129]	Time  0.961 ( 1.821)	Data  0.001 ( 0.866)	Loss 5.4996e-02 (8.9764e-02) 
2023-05-25 22:31:06.805525: train Epoch: [30][ 88/129]	Time  2.772 ( 1.832)	Data  1.807 ( 0.877)	Loss 1.1354e-01 (9.0031e-02) 
2023-05-25 22:31:07.765871: train Epoch: [30][ 89/129]	Time  0.960 ( 1.822)	Data  0.001 ( 0.867)	Loss 9.3724e-02 (9.0072e-02) 
2023-05-25 22:31:10.595137: train Epoch: [30][ 90/129]	Time  2.829 ( 1.833)	Data  1.873 ( 0.878)	Loss 9.6655e-02 (9.0145e-02) 
2023-05-25 22:31:11.555243: train Epoch: [30][ 91/129]	Time  0.960 ( 1.823)	Data  0.001 ( 0.868)	Loss 1.0040e-01 (9.0256e-02) 
2023-05-25 22:31:14.233047: train Epoch: [30][ 92/129]	Time  2.678 ( 1.833)	Data  1.725 ( 0.878)	Loss 2.4595e-01 (9.1930e-02) 
2023-05-25 22:31:15.191158: train Epoch: [30][ 93/129]	Time  0.958 ( 1.823)	Data  0.001 ( 0.868)	Loss 1.0068e-01 (9.2023e-02) 
2023-05-25 22:31:17.915931: train Epoch: [30][ 94/129]	Time  2.725 ( 1.833)	Data  1.773 ( 0.878)	Loss 9.3368e-02 (9.2037e-02) 
2023-05-25 22:31:18.873141: train Epoch: [30][ 95/129]	Time  0.957 ( 1.824)	Data  0.001 ( 0.869)	Loss 7.3829e-02 (9.1848e-02) 
2023-05-25 22:31:21.624115: train Epoch: [30][ 96/129]	Time  2.751 ( 1.833)	Data  1.806 ( 0.878)	Loss 1.2706e-01 (9.2211e-02) 
2023-05-25 22:31:22.582303: train Epoch: [30][ 97/129]	Time  0.958 ( 1.824)	Data  0.001 ( 0.869)	Loss 7.8962e-02 (9.2076e-02) 
2023-05-25 22:31:25.318567: train Epoch: [30][ 98/129]	Time  2.736 ( 1.834)	Data  1.782 ( 0.879)	Loss 6.9247e-02 (9.1845e-02) 
2023-05-25 22:31:26.275628: train Epoch: [30][ 99/129]	Time  0.957 ( 1.825)	Data  0.001 ( 0.870)	Loss 9.3952e-02 (9.1866e-02) 
2023-05-25 22:31:28.922417: train Epoch: [30][100/129]	Time  2.647 ( 1.833)	Data  1.694 ( 0.878)	Loss 6.2550e-02 (9.1576e-02) 
2023-05-25 22:31:29.880492: train Epoch: [30][101/129]	Time  0.958 ( 1.824)	Data  0.001 ( 0.869)	Loss 1.1288e-01 (9.1785e-02) 
2023-05-25 22:31:32.620465: train Epoch: [30][102/129]	Time  2.740 ( 1.833)	Data  1.792 ( 0.878)	Loss 1.0695e-01 (9.1932e-02) 
2023-05-25 22:31:33.566259: train Epoch: [30][103/129]	Time  0.946 ( 1.825)	Data  0.001 ( 0.870)	Loss 6.7495e-02 (9.1697e-02) 
2023-05-25 22:31:36.143238: train Epoch: [30][104/129]	Time  2.577 ( 1.832)	Data  1.632 ( 0.877)	Loss 6.4912e-02 (9.1442e-02) 
2023-05-25 22:31:37.091167: train Epoch: [30][105/129]	Time  0.948 ( 1.824)	Data  0.001 ( 0.869)	Loss 5.9398e-02 (9.1140e-02) 
2023-05-25 22:31:39.779573: train Epoch: [30][106/129]	Time  2.688 ( 1.832)	Data  1.745 ( 0.877)	Loss 1.1126e-01 (9.1328e-02) 
2023-05-25 22:31:40.727899: train Epoch: [30][107/129]	Time  0.948 ( 1.823)	Data  0.001 ( 0.869)	Loss 1.0818e-01 (9.1484e-02) 
2023-05-25 22:31:43.514443: train Epoch: [30][108/129]	Time  2.787 ( 1.832)	Data  1.843 ( 0.878)	Loss 1.5305e-01 (9.2048e-02) 
2023-05-25 22:31:44.462598: train Epoch: [30][109/129]	Time  0.948 ( 1.824)	Data  0.001 ( 0.870)	Loss 4.6095e-02 (9.1631e-02) 
2023-05-25 22:31:47.112972: train Epoch: [30][110/129]	Time  2.650 ( 1.832)	Data  1.705 ( 0.877)	Loss 9.9641e-02 (9.1703e-02) 
2023-05-25 22:31:48.059735: train Epoch: [30][111/129]	Time  0.947 ( 1.824)	Data  0.001 ( 0.870)	Loss 7.4352e-02 (9.1548e-02) 
2023-05-25 22:31:50.616801: train Epoch: [30][112/129]	Time  2.557 ( 1.830)	Data  1.612 ( 0.876)	Loss 7.3112e-02 (9.1385e-02) 
2023-05-25 22:31:51.565831: train Epoch: [30][113/129]	Time  0.949 ( 1.823)	Data  0.001 ( 0.869)	Loss 7.6781e-02 (9.1257e-02) 
2023-05-25 22:31:54.206414: train Epoch: [30][114/129]	Time  2.641 ( 1.830)	Data  1.695 ( 0.876)	Loss 7.4924e-02 (9.1115e-02) 
2023-05-25 22:31:55.155102: train Epoch: [30][115/129]	Time  0.949 ( 1.822)	Data  0.001 ( 0.868)	Loss 8.0695e-02 (9.1025e-02) 
2023-05-25 22:31:57.944366: train Epoch: [30][116/129]	Time  2.789 ( 1.830)	Data  1.846 ( 0.877)	Loss 7.6850e-02 (9.0904e-02) 
2023-05-25 22:31:58.891933: train Epoch: [30][117/129]	Time  0.948 ( 1.823)	Data  0.001 ( 0.869)	Loss 8.2698e-02 (9.0834e-02) 
2023-05-25 22:32:01.560822: train Epoch: [30][118/129]	Time  2.669 ( 1.830)	Data  1.725 ( 0.876)	Loss 1.0121e-01 (9.0921e-02) 
2023-05-25 22:32:02.508329: train Epoch: [30][119/129]	Time  0.948 ( 1.823)	Data  0.001 ( 0.869)	Loss 7.7529e-02 (9.0810e-02) 
2023-05-25 22:32:05.203272: train Epoch: [30][120/129]	Time  2.695 ( 1.830)	Data  1.750 ( 0.876)	Loss 1.1687e-01 (9.1025e-02) 
2023-05-25 22:32:06.151427: train Epoch: [30][121/129]	Time  0.948 ( 1.823)	Data  0.001 ( 0.869)	Loss 1.5811e-01 (9.1575e-02) 
2023-05-25 22:32:08.835258: train Epoch: [30][122/129]	Time  2.684 ( 1.830)	Data  1.739 ( 0.876)	Loss 6.7791e-02 (9.1382e-02) 
2023-05-25 22:32:09.782440: train Epoch: [30][123/129]	Time  0.947 ( 1.822)	Data  0.001 ( 0.869)	Loss 7.8583e-02 (9.1278e-02) 
2023-05-25 22:32:12.481008: train Epoch: [30][124/129]	Time  2.699 ( 1.829)	Data  1.749 ( 0.876)	Loss 4.4788e-02 (9.0907e-02) 
2023-05-25 22:32:13.427432: train Epoch: [30][125/129]	Time  0.946 ( 1.822)	Data  0.001 ( 0.869)	Loss 7.0871e-02 (9.0747e-02) 
2023-05-25 22:32:15.873331: train Epoch: [30][126/129]	Time  2.446 ( 1.827)	Data  1.499 ( 0.874)	Loss 1.1841e-01 (9.0965e-02) 
2023-05-25 22:32:16.821090: train Epoch: [30][127/129]	Time  0.948 ( 1.821)	Data  0.001 ( 0.867)	Loss 1.1311e-01 (9.1138e-02) 
2023-05-25 22:32:18.368404: train Epoch: [30][128/129]	Time  1.547 ( 1.818)	Data  0.603 ( 0.865)	Loss 9.3248e-02 (9.1155e-02) 
2023-05-25 22:32:18.400234: Train Epoch done in 234.60429810900132 s 
2023-05-25 22:32:20.751788: val Epoch: [30][ 0/72]	Time  1.665 ( 1.665)	Data  1.464 ( 1.464)	Loss 5.4466e-02 (5.4466e-02) 
2023-05-25 22:32:20.874066: val Epoch: [30][ 1/72]	Time  0.123 ( 0.894)	Data  0.001 ( 0.733)	Loss 7.8784e-02 (6.6625e-02) 
2023-05-25 22:32:21.924217: val Epoch: [30][ 2/72]	Time  1.050 ( 0.946)	Data  0.928 ( 0.798)	Loss 3.3416e-01 (1.5580e-01) 
2023-05-25 22:32:22.045502: val Epoch: [30][ 3/72]	Time  0.121 ( 0.740)	Data  0.001 ( 0.599)	Loss 1.0944e-01 (1.4421e-01) 
2023-05-25 22:32:23.142054: val Epoch: [30][ 4/72]	Time  1.097 ( 0.811)	Data  0.975 ( 0.674)	Loss 5.7622e-02 (1.2689e-01) 
2023-05-25 22:32:23.263265: val Epoch: [30][ 5/72]	Time  0.121 ( 0.696)	Data  0.001 ( 0.562)	Loss 1.1260e-01 (1.2451e-01) 
2023-05-25 22:32:24.412761: val Epoch: [30][ 6/72]	Time  1.149 ( 0.761)	Data  1.028 ( 0.628)	Loss 9.9316e-02 (1.2091e-01) 
2023-05-25 22:32:24.534187: val Epoch: [30][ 7/72]	Time  0.121 ( 0.681)	Data  0.001 ( 0.550)	Loss 7.0891e-02 (1.1466e-01) 
2023-05-25 22:32:25.664700: val Epoch: [30][ 8/72]	Time  1.131 ( 0.731)	Data  1.009 ( 0.601)	Loss 4.4609e-01 (1.5149e-01) 
2023-05-25 22:32:25.785623: val Epoch: [30][ 9/72]	Time  0.121 ( 0.670)	Data  0.000 ( 0.541)	Loss 5.3945e-02 (1.4173e-01) 
2023-05-25 22:32:26.897625: val Epoch: [30][10/72]	Time  1.112 ( 0.710)	Data  0.991 ( 0.582)	Loss 1.4439e-01 (1.4197e-01) 
2023-05-25 22:32:27.018353: val Epoch: [30][11/72]	Time  0.121 ( 0.661)	Data  0.001 ( 0.533)	Loss 2.3322e-01 (1.4958e-01) 
2023-05-25 22:32:28.121094: val Epoch: [30][12/72]	Time  1.103 ( 0.695)	Data  0.982 ( 0.568)	Loss 4.4448e-01 (1.7226e-01) 
2023-05-25 22:32:28.242120: val Epoch: [30][13/72]	Time  0.121 ( 0.654)	Data  0.001 ( 0.527)	Loss 8.5544e-02 (1.6607e-01) 
2023-05-25 22:32:29.367166: val Epoch: [30][14/72]	Time  1.125 ( 0.685)	Data  1.004 ( 0.559)	Loss 1.2225e-01 (1.6315e-01) 
2023-05-25 22:32:29.488598: val Epoch: [30][15/72]	Time  0.121 ( 0.650)	Data  0.001 ( 0.524)	Loss 7.2309e-02 (1.5747e-01) 
2023-05-25 22:32:30.634969: val Epoch: [30][16/72]	Time  1.146 ( 0.679)	Data  1.025 ( 0.554)	Loss 6.1032e-02 (1.5180e-01) 
2023-05-25 22:32:30.756552: val Epoch: [30][17/72]	Time  0.122 ( 0.648)	Data  0.000 ( 0.523)	Loss 8.8392e-02 (1.4827e-01) 
2023-05-25 22:32:31.880414: val Epoch: [30][18/72]	Time  1.124 ( 0.673)	Data  1.002 ( 0.548)	Loss 1.4395e-01 (1.4805e-01) 
2023-05-25 22:32:32.002040: val Epoch: [30][19/72]	Time  0.122 ( 0.646)	Data  0.001 ( 0.521)	Loss 1.1164e-01 (1.4623e-01) 
2023-05-25 22:32:33.075538: val Epoch: [30][20/72]	Time  1.073 ( 0.666)	Data  0.952 ( 0.541)	Loss 3.6325e-02 (1.4099e-01) 
2023-05-25 22:32:33.196904: val Epoch: [30][21/72]	Time  0.121 ( 0.641)	Data  0.001 ( 0.517)	Loss 6.9835e-02 (1.3776e-01) 
2023-05-25 22:32:34.292153: val Epoch: [30][22/72]	Time  1.095 ( 0.661)	Data  0.974 ( 0.537)	Loss 3.1077e-01 (1.4528e-01) 
2023-05-25 22:32:34.413453: val Epoch: [30][23/72]	Time  0.121 ( 0.639)	Data  0.000 ( 0.514)	Loss 9.7382e-02 (1.4329e-01) 
2023-05-25 22:32:35.492709: val Epoch: [30][24/72]	Time  1.079 ( 0.656)	Data  0.958 ( 0.532)	Loss 6.3420e-02 (1.4009e-01) 
2023-05-25 22:32:35.614263: val Epoch: [30][25/72]	Time  0.122 ( 0.636)	Data  0.001 ( 0.512)	Loss 5.6568e-02 (1.3688e-01) 
2023-05-25 22:32:36.710668: val Epoch: [30][26/72]	Time  1.096 ( 0.653)	Data  0.975 ( 0.529)	Loss 1.3010e-01 (1.3663e-01) 
2023-05-25 22:32:36.831997: val Epoch: [30][27/72]	Time  0.121 ( 0.634)	Data  0.001 ( 0.510)	Loss 1.1010e-01 (1.3568e-01) 
2023-05-25 22:32:37.917386: val Epoch: [30][28/72]	Time  1.085 ( 0.649)	Data  0.964 ( 0.525)	Loss 5.0657e-02 (1.3275e-01) 
2023-05-25 22:32:38.039318: val Epoch: [30][29/72]	Time  0.122 ( 0.632)	Data  0.001 ( 0.508)	Loss 1.3571e-01 (1.3285e-01) 
2023-05-25 22:32:39.096828: val Epoch: [30][30/72]	Time  1.058 ( 0.645)	Data  0.936 ( 0.522)	Loss 9.7012e-02 (1.3169e-01) 
2023-05-25 22:32:39.218023: val Epoch: [30][31/72]	Time  0.121 ( 0.629)	Data  0.000 ( 0.506)	Loss 1.4897e-01 (1.3223e-01) 
2023-05-25 22:32:40.329979: val Epoch: [30][32/72]	Time  1.112 ( 0.644)	Data  0.990 ( 0.520)	Loss 3.5340e-01 (1.3893e-01) 
2023-05-25 22:32:40.451027: val Epoch: [30][33/72]	Time  0.121 ( 0.628)	Data  0.001 ( 0.505)	Loss 6.2996e-02 (1.3670e-01) 
2023-05-25 22:32:41.555528: val Epoch: [30][34/72]	Time  1.104 ( 0.642)	Data  0.983 ( 0.519)	Loss 4.3339e-01 (1.4518e-01) 
2023-05-25 22:32:41.676797: val Epoch: [30][35/72]	Time  0.121 ( 0.628)	Data  0.001 ( 0.504)	Loss 3.1603e-01 (1.4992e-01) 
2023-05-25 22:32:42.802713: val Epoch: [30][36/72]	Time  1.126 ( 0.641)	Data  1.004 ( 0.518)	Loss 2.7310e-01 (1.5325e-01) 
2023-05-25 22:32:42.923657: val Epoch: [30][37/72]	Time  0.121 ( 0.627)	Data  0.001 ( 0.504)	Loss 3.7425e-01 (1.5907e-01) 
2023-05-25 22:32:43.985667: val Epoch: [30][38/72]	Time  1.062 ( 0.638)	Data  0.940 ( 0.515)	Loss 9.4184e-02 (1.5740e-01) 
2023-05-25 22:32:44.108258: val Epoch: [30][39/72]	Time  0.123 ( 0.626)	Data  0.001 ( 0.502)	Loss 1.1080e-01 (1.5624e-01) 
2023-05-25 22:32:45.176745: val Epoch: [30][40/72]	Time  1.068 ( 0.636)	Data  0.947 ( 0.513)	Loss 1.6332e-01 (1.5641e-01) 
2023-05-25 22:32:45.297761: val Epoch: [30][41/72]	Time  0.121 ( 0.624)	Data  0.001 ( 0.501)	Loss 7.3165e-02 (1.5443e-01) 
2023-05-25 22:32:46.378029: val Epoch: [30][42/72]	Time  1.080 ( 0.635)	Data  0.959 ( 0.512)	Loss 4.7188e-02 (1.5193e-01) 
2023-05-25 22:32:46.499607: val Epoch: [30][43/72]	Time  0.122 ( 0.623)	Data  0.001 ( 0.500)	Loss 1.0556e-01 (1.5088e-01) 
2023-05-25 22:32:47.583079: val Epoch: [30][44/72]	Time  1.083 ( 0.633)	Data  0.962 ( 0.510)	Loss 4.5792e-02 (1.4855e-01) 
2023-05-25 22:32:47.704673: val Epoch: [30][45/72]	Time  0.122 ( 0.622)	Data  0.001 ( 0.499)	Loss 4.0431e-02 (1.4620e-01) 
2023-05-25 22:32:48.831078: val Epoch: [30][46/72]	Time  1.126 ( 0.633)	Data  1.004 ( 0.510)	Loss 4.5106e-01 (1.5268e-01) 
2023-05-25 22:32:48.952602: val Epoch: [30][47/72]	Time  0.122 ( 0.622)	Data  0.001 ( 0.499)	Loss 4.1275e-02 (1.5036e-01) 
2023-05-25 22:32:50.040121: val Epoch: [30][48/72]	Time  1.088 ( 0.632)	Data  0.966 ( 0.509)	Loss 2.9185e-01 (1.5325e-01) 
2023-05-25 22:32:50.160730: val Epoch: [30][49/72]	Time  0.121 ( 0.621)	Data  0.001 ( 0.499)	Loss 1.7714e-01 (1.5373e-01) 
2023-05-25 22:32:51.222246: val Epoch: [30][50/72]	Time  1.062 ( 0.630)	Data  0.940 ( 0.507)	Loss 5.1265e-02 (1.5172e-01) 
2023-05-25 22:32:51.344153: val Epoch: [30][51/72]	Time  0.122 ( 0.620)	Data  0.001 ( 0.498)	Loss 8.1869e-02 (1.5037e-01) 
2023-05-25 22:32:52.388753: val Epoch: [30][52/72]	Time  1.045 ( 0.628)	Data  0.923 ( 0.506)	Loss 7.9353e-02 (1.4903e-01) 
2023-05-25 22:32:52.509665: val Epoch: [30][53/72]	Time  0.121 ( 0.619)	Data  0.001 ( 0.496)	Loss 6.5358e-02 (1.4748e-01) 
2023-05-25 22:32:53.621206: val Epoch: [30][54/72]	Time  1.112 ( 0.628)	Data  0.990 ( 0.505)	Loss 8.6329e-02 (1.4637e-01) 
2023-05-25 22:32:53.742283: val Epoch: [30][55/72]	Time  0.121 ( 0.619)	Data  0.001 ( 0.496)	Loss 1.7124e-01 (1.4682e-01) 
2023-05-25 22:32:54.851688: val Epoch: [30][56/72]	Time  1.109 ( 0.627)	Data  0.988 ( 0.505)	Loss 5.5281e-02 (1.4521e-01) 
2023-05-25 22:32:54.972790: val Epoch: [30][57/72]	Time  0.121 ( 0.619)	Data  0.001 ( 0.496)	Loss 5.4559e-02 (1.4365e-01) 
2023-05-25 22:32:56.036601: val Epoch: [30][58/72]	Time  1.064 ( 0.626)	Data  0.942 ( 0.504)	Loss 6.1009e-02 (1.4225e-01) 
2023-05-25 22:32:56.158033: val Epoch: [30][59/72]	Time  0.121 ( 0.618)	Data  0.001 ( 0.495)	Loss 2.1521e-01 (1.4346e-01) 
2023-05-25 22:32:57.245389: val Epoch: [30][60/72]	Time  1.087 ( 0.626)	Data  0.966 ( 0.503)	Loss 2.1343e-01 (1.4461e-01) 
2023-05-25 22:32:57.366446: val Epoch: [30][61/72]	Time  0.121 ( 0.617)	Data  0.000 ( 0.495)	Loss 1.0320e-01 (1.4394e-01) 
2023-05-25 22:32:58.422744: val Epoch: [30][62/72]	Time  1.056 ( 0.624)	Data  0.935 ( 0.502)	Loss 4.4286e-02 (1.4236e-01) 
2023-05-25 22:32:58.544295: val Epoch: [30][63/72]	Time  0.122 ( 0.617)	Data  0.001 ( 0.494)	Loss 1.4183e-01 (1.4235e-01) 
2023-05-25 22:32:59.641567: val Epoch: [30][64/72]	Time  1.097 ( 0.624)	Data  0.976 ( 0.502)	Loss 4.6547e-02 (1.4088e-01) 
2023-05-25 22:32:59.764346: val Epoch: [30][65/72]	Time  0.123 ( 0.616)	Data  0.001 ( 0.494)	Loss 7.7799e-02 (1.3992e-01) 
2023-05-25 22:33:00.822230: val Epoch: [30][66/72]	Time  1.058 ( 0.623)	Data  0.937 ( 0.501)	Loss 6.4393e-02 (1.3880e-01) 
2023-05-25 22:33:00.943471: val Epoch: [30][67/72]	Time  0.121 ( 0.616)	Data  0.001 ( 0.493)	Loss 4.3418e-02 (1.3739e-01) 
2023-05-25 22:33:02.060815: val Epoch: [30][68/72]	Time  1.117 ( 0.623)	Data  0.996 ( 0.501)	Loss 1.1319e-01 (1.3704e-01) 
2023-05-25 22:33:02.182056: val Epoch: [30][69/72]	Time  0.121 ( 0.616)	Data  0.000 ( 0.493)	Loss 4.6841e-02 (1.3575e-01) 
2023-05-25 22:33:03.186120: val Epoch: [30][70/72]	Time  1.004 ( 0.621)	Data  0.883 ( 0.499)	Loss 9.6346e-02 (1.3520e-01) 
2023-05-25 22:33:03.304674: val Epoch: [30][71/72]	Time  0.119 ( 0.614)	Data  0.000 ( 0.492)	Loss 6.9431e-02 (1.3428e-01) 
2023-05-25 22:33:03.477160: Epoch 30 :Val : ['ET : 0.7279322147369385', 'TC : 0.7768273949623108', 'WT : 0.8595406413078308'] 
2023-05-25 22:33:03.484405: Epoch 30 :Val : ['ET : 0.7279322147369385', 'TC : 0.7768273949623108', 'WT : 0.8595406413078308'] 
2023-05-25 22:33:03.487689: Saving the model with DSC 0.7940735220909119 
2023-05-25 22:33:04.133733: Val epoch done in 45.73349444499763 s 
2023-05-25 22:33:04.139385: Batches per epoch:  129 
2023-05-25 22:33:08.924906: train Epoch: [31][  0/129]	Time  4.785 ( 4.785)	Data  3.756 ( 3.756)	Loss 6.8723e-02 (6.8723e-02) 
2023-05-25 22:33:09.887419: train Epoch: [31][  1/129]	Time  0.963 ( 2.874)	Data  0.001 ( 1.879)	Loss 9.0822e-02 (7.9773e-02) 
2023-05-25 22:33:12.677712: train Epoch: [31][  2/129]	Time  2.790 ( 2.846)	Data  1.830 ( 1.862)	Loss 9.3971e-02 (8.4506e-02) 
2023-05-25 22:33:13.628979: train Epoch: [31][  3/129]	Time  0.951 ( 2.372)	Data  0.001 ( 1.397)	Loss 7.6624e-02 (8.2535e-02) 
2023-05-25 22:33:16.212050: train Epoch: [31][  4/129]	Time  2.583 ( 2.414)	Data  1.636 ( 1.445)	Loss 6.6518e-02 (7.9332e-02) 
2023-05-25 22:33:17.165195: train Epoch: [31][  5/129]	Time  0.953 ( 2.171)	Data  0.001 ( 1.204)	Loss 1.3425e-01 (8.8485e-02) 
2023-05-25 22:33:19.865074: train Epoch: [31][  6/129]	Time  2.700 ( 2.246)	Data  1.746 ( 1.282)	Loss 7.6743e-02 (8.6808e-02) 
2023-05-25 22:33:20.815282: train Epoch: [31][  7/129]	Time  0.950 ( 2.084)	Data  0.001 ( 1.121)	Loss 8.5161e-02 (8.6602e-02) 
2023-05-25 22:33:23.500983: train Epoch: [31][  8/129]	Time  2.686 ( 2.151)	Data  1.735 ( 1.190)	Loss 1.5919e-01 (9.4667e-02) 
2023-05-25 22:33:24.451726: train Epoch: [31][  9/129]	Time  0.951 ( 2.031)	Data  0.001 ( 1.071)	Loss 6.5757e-02 (9.1776e-02) 
2023-05-25 22:33:27.092865: train Epoch: [31][ 10/129]	Time  2.641 ( 2.087)	Data  1.692 ( 1.127)	Loss 8.4065e-02 (9.1075e-02) 
2023-05-25 22:33:28.042561: train Epoch: [31][ 11/129]	Time  0.950 ( 1.992)	Data  0.001 ( 1.033)	Loss 8.3693e-02 (9.0460e-02) 
2023-05-25 22:33:30.610779: train Epoch: [31][ 12/129]	Time  2.568 ( 2.036)	Data  1.608 ( 1.078)	Loss 6.7999e-02 (8.8732e-02) 
2023-05-25 22:33:31.562246: train Epoch: [31][ 13/129]	Time  0.951 ( 1.959)	Data  0.001 ( 1.001)	Loss 7.1540e-02 (8.7504e-02) 
2023-05-25 22:33:34.186105: train Epoch: [31][ 14/129]	Time  2.624 ( 2.003)	Data  1.675 ( 1.046)	Loss 6.6488e-02 (8.6103e-02) 
2023-05-25 22:33:35.137466: train Epoch: [31][ 15/129]	Time  0.951 ( 1.937)	Data  0.001 ( 0.980)	Loss 9.9766e-02 (8.6957e-02) 
2023-05-25 22:33:37.801949: train Epoch: [31][ 16/129]	Time  2.664 ( 1.980)	Data  1.715 ( 1.024)	Loss 1.2423e-01 (8.9150e-02) 
2023-05-25 22:33:38.753311: train Epoch: [31][ 17/129]	Time  0.951 ( 1.923)	Data  0.001 ( 0.967)	Loss 9.0597e-02 (8.9230e-02) 
2023-05-25 22:33:41.241251: train Epoch: [31][ 18/129]	Time  2.488 ( 1.953)	Data  1.540 ( 0.997)	Loss 5.7289e-02 (8.7549e-02) 
2023-05-25 22:33:42.188042: train Epoch: [31][ 19/129]	Time  0.947 ( 1.902)	Data  0.001 ( 0.947)	Loss 1.1423e-01 (8.8883e-02) 
2023-05-25 22:33:44.678424: train Epoch: [31][ 20/129]	Time  2.490 ( 1.930)	Data  1.538 ( 0.975)	Loss 8.5878e-02 (8.8740e-02) 
2023-05-25 22:33:45.626726: train Epoch: [31][ 21/129]	Time  0.948 ( 1.886)	Data  0.001 ( 0.931)	Loss 8.8672e-02 (8.8737e-02) 
2023-05-25 22:33:48.108075: train Epoch: [31][ 22/129]	Time  2.481 ( 1.912)	Data  1.535 ( 0.957)	Loss 1.1014e-01 (8.9667e-02) 
2023-05-25 22:33:49.055287: train Epoch: [31][ 23/129]	Time  0.947 ( 1.871)	Data  0.001 ( 0.917)	Loss 1.2525e-01 (9.1150e-02) 
2023-05-25 22:33:51.691172: train Epoch: [31][ 24/129]	Time  2.636 ( 1.902)	Data  1.691 ( 0.948)	Loss 1.1825e-01 (9.2234e-02) 
2023-05-25 22:33:52.640226: train Epoch: [31][ 25/129]	Time  0.949 ( 1.865)	Data  0.001 ( 0.912)	Loss 1.4737e-01 (9.4355e-02) 
2023-05-25 22:33:55.297418: train Epoch: [31][ 26/129]	Time  2.657 ( 1.895)	Data  1.712 ( 0.942)	Loss 9.8584e-02 (9.4511e-02) 
2023-05-25 22:33:56.297126: train Epoch: [31][ 27/129]	Time  1.000 ( 1.863)	Data  0.053 ( 0.910)	Loss 9.2021e-02 (9.4422e-02) 
2023-05-25 22:33:58.882258: train Epoch: [31][ 28/129]	Time  2.585 ( 1.888)	Data  1.640 ( 0.935)	Loss 1.0976e-01 (9.4951e-02) 
2023-05-25 22:33:59.898936: train Epoch: [31][ 29/129]	Time  1.017 ( 1.859)	Data  0.070 ( 0.906)	Loss 1.0253e-01 (9.5204e-02) 
2023-05-25 22:34:02.476926: train Epoch: [31][ 30/129]	Time  2.578 ( 1.882)	Data  1.632 ( 0.930)	Loss 8.4031e-02 (9.4843e-02) 
2023-05-25 22:34:03.541280: train Epoch: [31][ 31/129]	Time  1.064 ( 1.856)	Data  0.113 ( 0.904)	Loss 6.5020e-02 (9.3911e-02) 
2023-05-25 22:34:06.073340: train Epoch: [31][ 32/129]	Time  2.532 ( 1.877)	Data  1.588 ( 0.925)	Loss 6.4697e-02 (9.3026e-02) 
2023-05-25 22:34:07.122298: train Epoch: [31][ 33/129]	Time  1.049 ( 1.852)	Data  0.101 ( 0.901)	Loss 7.3463e-02 (9.2451e-02) 
2023-05-25 22:34:09.783488: train Epoch: [31][ 34/129]	Time  2.661 ( 1.876)	Data  1.708 ( 0.924)	Loss 1.0648e-01 (9.2851e-02) 
2023-05-25 22:34:10.731702: train Epoch: [31][ 35/129]	Time  0.948 ( 1.850)	Data  0.001 ( 0.898)	Loss 1.3490e-01 (9.4020e-02) 
2023-05-25 22:34:13.311750: train Epoch: [31][ 36/129]	Time  2.580 ( 1.870)	Data  1.634 ( 0.918)	Loss 1.1128e-01 (9.4486e-02) 
2023-05-25 22:34:14.361517: train Epoch: [31][ 37/129]	Time  1.050 ( 1.848)	Data  0.102 ( 0.896)	Loss 1.1851e-01 (9.5118e-02) 
2023-05-25 22:34:16.938924: train Epoch: [31][ 38/129]	Time  2.577 ( 1.867)	Data  1.633 ( 0.915)	Loss 8.4502e-02 (9.4846e-02) 
2023-05-25 22:34:17.900088: train Epoch: [31][ 39/129]	Time  0.961 ( 1.844)	Data  0.013 ( 0.893)	Loss 8.8009e-02 (9.4675e-02) 
2023-05-25 22:34:20.566019: train Epoch: [31][ 40/129]	Time  2.666 ( 1.864)	Data  1.720 ( 0.913)	Loss 1.1464e-01 (9.5162e-02) 
2023-05-25 22:34:21.565796: train Epoch: [31][ 41/129]	Time  1.000 ( 1.843)	Data  0.051 ( 0.892)	Loss 1.5160e-01 (9.6506e-02) 
2023-05-25 22:34:24.223846: train Epoch: [31][ 42/129]	Time  2.658 ( 1.862)	Data  1.713 ( 0.912)	Loss 8.9739e-02 (9.6349e-02) 
2023-05-25 22:34:25.174130: train Epoch: [31][ 43/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.891)	Loss 1.4875e-01 (9.7540e-02) 
2023-05-25 22:34:27.785522: train Epoch: [31][ 44/129]	Time  2.611 ( 1.859)	Data  1.666 ( 0.908)	Loss 1.0940e-01 (9.7803e-02) 
2023-05-25 22:34:28.736293: train Epoch: [31][ 45/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.888)	Loss 6.8744e-02 (9.7171e-02) 
2023-05-25 22:34:31.355994: train Epoch: [31][ 46/129]	Time  2.620 ( 1.856)	Data  1.674 ( 0.905)	Loss 8.0104e-02 (9.6808e-02) 
2023-05-25 22:34:32.355347: train Epoch: [31][ 47/129]	Time  0.999 ( 1.838)	Data  0.050 ( 0.887)	Loss 7.7616e-02 (9.6408e-02) 
2023-05-25 22:34:34.961338: train Epoch: [31][ 48/129]	Time  2.606 ( 1.853)	Data  1.660 ( 0.903)	Loss 2.3286e-01 (9.9193e-02) 
2023-05-25 22:34:36.003556: train Epoch: [31][ 49/129]	Time  1.042 ( 1.837)	Data  0.094 ( 0.887)	Loss 1.0162e-01 (9.9242e-02) 
2023-05-25 22:34:38.591391: train Epoch: [31][ 50/129]	Time  2.588 ( 1.852)	Data  1.641 ( 0.902)	Loss 7.0131e-02 (9.8671e-02) 
2023-05-25 22:34:39.810211: train Epoch: [31][ 51/129]	Time  1.219 ( 1.840)	Data  0.271 ( 0.889)	Loss 1.1081e-01 (9.8904e-02) 
2023-05-25 22:34:42.167632: train Epoch: [31][ 52/129]	Time  2.357 ( 1.850)	Data  1.410 ( 0.899)	Loss 6.4727e-02 (9.8260e-02) 
2023-05-25 22:34:43.540679: train Epoch: [31][ 53/129]	Time  1.373 ( 1.841)	Data  0.426 ( 0.891)	Loss 1.1677e-01 (9.8602e-02) 
2023-05-25 22:34:45.794294: train Epoch: [31][ 54/129]	Time  2.254 ( 1.848)	Data  1.307 ( 0.898)	Loss 9.7598e-02 (9.8584e-02) 
2023-05-25 22:34:47.137712: train Epoch: [31][ 55/129]	Time  1.343 ( 1.839)	Data  0.397 ( 0.889)	Loss 9.1510e-02 (9.8458e-02) 
2023-05-25 22:34:49.413498: train Epoch: [31][ 56/129]	Time  2.276 ( 1.847)	Data  1.328 ( 0.897)	Loss 6.1869e-02 (9.7816e-02) 
2023-05-25 22:34:50.732164: train Epoch: [31][ 57/129]	Time  1.319 ( 1.838)	Data  0.374 ( 0.888)	Loss 1.3236e-01 (9.8411e-02) 
2023-05-25 22:34:53.148400: train Epoch: [31][ 58/129]	Time  2.416 ( 1.848)	Data  1.468 ( 0.898)	Loss 1.2127e-01 (9.8799e-02) 
2023-05-25 22:34:54.448291: train Epoch: [31][ 59/129]	Time  1.300 ( 1.838)	Data  0.353 ( 0.889)	Loss 7.2400e-02 (9.8359e-02) 
2023-05-25 22:34:56.964936: train Epoch: [31][ 60/129]	Time  2.517 ( 1.850)	Data  1.570 ( 0.900)	Loss 7.5906e-02 (9.7991e-02) 
2023-05-25 22:34:58.207025: train Epoch: [31][ 61/129]	Time  1.242 ( 1.840)	Data  0.295 ( 0.890)	Loss 8.3447e-02 (9.7756e-02) 
2023-05-25 22:35:00.686633: train Epoch: [31][ 62/129]	Time  2.480 ( 1.850)	Data  1.534 ( 0.900)	Loss 5.1705e-02 (9.7025e-02) 
2023-05-25 22:35:01.942715: train Epoch: [31][ 63/129]	Time  1.256 ( 1.841)	Data  0.309 ( 0.891)	Loss 8.7376e-02 (9.6874e-02) 
2023-05-25 22:35:04.436694: train Epoch: [31][ 64/129]	Time  2.494 ( 1.851)	Data  1.547 ( 0.901)	Loss 4.8463e-02 (9.6130e-02) 
2023-05-25 22:35:05.776495: train Epoch: [31][ 65/129]	Time  1.340 ( 1.843)	Data  0.394 ( 0.893)	Loss 8.4116e-02 (9.5948e-02) 
2023-05-25 22:35:08.156872: train Epoch: [31][ 66/129]	Time  2.380 ( 1.851)	Data  1.433 ( 0.901)	Loss 7.5617e-02 (9.5644e-02) 
2023-05-25 22:35:09.381016: train Epoch: [31][ 67/129]	Time  1.224 ( 1.842)	Data  0.277 ( 0.892)	Loss 1.0071e-01 (9.5719e-02) 
2023-05-25 22:35:11.943048: train Epoch: [31][ 68/129]	Time  2.562 ( 1.852)	Data  1.616 ( 0.903)	Loss 1.4126e-01 (9.6379e-02) 
2023-05-25 22:35:13.091291: train Epoch: [31][ 69/129]	Time  1.148 ( 1.842)	Data  0.201 ( 0.893)	Loss 1.0127e-01 (9.6448e-02) 
2023-05-25 22:35:15.655192: train Epoch: [31][ 70/129]	Time  2.564 ( 1.852)	Data  1.618 ( 0.903)	Loss 6.6388e-02 (9.6025e-02) 
2023-05-25 22:35:16.789371: train Epoch: [31][ 71/129]	Time  1.134 ( 1.842)	Data  0.186 ( 0.893)	Loss 1.6622e-01 (9.7000e-02) 
2023-05-25 22:35:19.235149: train Epoch: [31][ 72/129]	Time  2.446 ( 1.851)	Data  1.499 ( 0.901)	Loss 5.1332e-02 (9.6374e-02) 
2023-05-25 22:35:20.518389: train Epoch: [31][ 73/129]	Time  1.283 ( 1.843)	Data  0.336 ( 0.894)	Loss 1.0690e-01 (9.6516e-02) 
2023-05-25 22:35:23.092161: train Epoch: [31][ 74/129]	Time  2.574 ( 1.853)	Data  1.629 ( 0.903)	Loss 9.1032e-02 (9.6443e-02) 
2023-05-25 22:35:24.124152: train Epoch: [31][ 75/129]	Time  1.032 ( 1.842)	Data  0.084 ( 0.893)	Loss 8.2686e-02 (9.6262e-02) 
2023-05-25 22:35:26.696742: train Epoch: [31][ 76/129]	Time  2.573 ( 1.851)	Data  1.627 ( 0.902)	Loss 5.5306e-02 (9.5730e-02) 
2023-05-25 22:35:27.732005: train Epoch: [31][ 77/129]	Time  1.035 ( 1.841)	Data  0.087 ( 0.892)	Loss 1.1800e-01 (9.6016e-02) 
2023-05-25 22:35:30.369576: train Epoch: [31][ 78/129]	Time  2.638 ( 1.851)	Data  1.695 ( 0.902)	Loss 6.3867e-02 (9.5609e-02) 
2023-05-25 22:35:31.318108: train Epoch: [31][ 79/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.891)	Loss 6.0543e-02 (9.5171e-02) 
2023-05-25 22:35:33.907432: train Epoch: [31][ 80/129]	Time  2.589 ( 1.849)	Data  1.645 ( 0.900)	Loss 6.9121e-02 (9.4849e-02) 
2023-05-25 22:35:34.857192: train Epoch: [31][ 81/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.889)	Loss 8.9679e-02 (9.4786e-02) 
2023-05-25 22:35:37.514966: train Epoch: [31][ 82/129]	Time  2.658 ( 1.848)	Data  1.709 ( 0.899)	Loss 8.2830e-02 (9.4642e-02) 
2023-05-25 22:35:38.462085: train Epoch: [31][ 83/129]	Time  0.947 ( 1.837)	Data  0.001 ( 0.888)	Loss 7.5742e-02 (9.4417e-02) 
2023-05-25 22:35:41.082487: train Epoch: [31][ 84/129]	Time  2.620 ( 1.846)	Data  1.677 ( 0.897)	Loss 7.5803e-02 (9.4198e-02) 
2023-05-25 22:35:42.045819: train Epoch: [31][ 85/129]	Time  0.963 ( 1.836)	Data  0.016 ( 0.887)	Loss 8.5571e-02 (9.4098e-02) 
2023-05-25 22:35:44.713995: train Epoch: [31][ 86/129]	Time  2.668 ( 1.846)	Data  1.726 ( 0.897)	Loss 6.5190e-02 (9.3765e-02) 
2023-05-25 22:35:45.662016: train Epoch: [31][ 87/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.887)	Loss 6.4536e-02 (9.3433e-02) 
2023-05-25 22:35:48.351461: train Epoch: [31][ 88/129]	Time  2.689 ( 1.845)	Data  1.745 ( 0.896)	Loss 6.0433e-02 (9.3062e-02) 
2023-05-25 22:35:49.299161: train Epoch: [31][ 89/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.886)	Loss 7.9600e-02 (9.2913e-02) 
2023-05-25 22:35:52.006502: train Epoch: [31][ 90/129]	Time  2.707 ( 1.845)	Data  1.764 ( 0.896)	Loss 9.0704e-02 (9.2889e-02) 
2023-05-25 22:35:52.968549: train Epoch: [31][ 91/129]	Time  0.962 ( 1.835)	Data  0.014 ( 0.886)	Loss 7.3711e-02 (9.2680e-02) 
2023-05-25 22:35:55.618793: train Epoch: [31][ 92/129]	Time  2.650 ( 1.844)	Data  1.707 ( 0.895)	Loss 5.9498e-02 (9.2323e-02) 
2023-05-25 22:35:56.584520: train Epoch: [31][ 93/129]	Time  0.966 ( 1.835)	Data  0.017 ( 0.886)	Loss 9.7776e-02 (9.2381e-02) 
2023-05-25 22:35:59.255366: train Epoch: [31][ 94/129]	Time  2.671 ( 1.843)	Data  1.719 ( 0.895)	Loss 1.0112e-01 (9.2473e-02) 
2023-05-25 22:36:00.275206: train Epoch: [31][ 95/129]	Time  1.020 ( 1.835)	Data  0.064 ( 0.886)	Loss 8.9167e-02 (9.2439e-02) 
2023-05-25 22:36:02.806450: train Epoch: [31][ 96/129]	Time  2.531 ( 1.842)	Data  1.587 ( 0.893)	Loss 5.5596e-02 (9.2059e-02) 
2023-05-25 22:36:03.809850: train Epoch: [31][ 97/129]	Time  1.003 ( 1.833)	Data  0.056 ( 0.885)	Loss 7.5983e-02 (9.1895e-02) 
2023-05-25 22:36:06.491727: train Epoch: [31][ 98/129]	Time  2.682 ( 1.842)	Data  1.738 ( 0.893)	Loss 8.5527e-02 (9.1831e-02) 
2023-05-25 22:36:07.478071: train Epoch: [31][ 99/129]	Time  0.986 ( 1.833)	Data  0.038 ( 0.885)	Loss 7.9259e-02 (9.1705e-02) 
2023-05-25 22:36:10.053986: train Epoch: [31][100/129]	Time  2.576 ( 1.841)	Data  1.629 ( 0.892)	Loss 8.2195e-02 (9.1611e-02) 
2023-05-25 22:36:11.025881: train Epoch: [31][101/129]	Time  0.972 ( 1.832)	Data  0.023 ( 0.884)	Loss 5.6880e-02 (9.1270e-02) 
2023-05-25 22:36:13.679215: train Epoch: [31][102/129]	Time  2.653 ( 1.840)	Data  1.700 ( 0.892)	Loss 1.6986e-01 (9.2033e-02) 
2023-05-25 22:36:14.628159: train Epoch: [31][103/129]	Time  0.949 ( 1.832)	Data  0.001 ( 0.883)	Loss 8.9020e-02 (9.2004e-02) 
2023-05-25 22:36:17.381123: train Epoch: [31][104/129]	Time  2.753 ( 1.840)	Data  1.809 ( 0.892)	Loss 6.6184e-02 (9.1758e-02) 
2023-05-25 22:36:18.339793: train Epoch: [31][105/129]	Time  0.959 ( 1.832)	Data  0.011 ( 0.883)	Loss 8.0294e-02 (9.1650e-02) 
2023-05-25 22:36:20.950408: train Epoch: [31][106/129]	Time  2.611 ( 1.839)	Data  1.666 ( 0.891)	Loss 8.6044e-02 (9.1598e-02) 
2023-05-25 22:36:22.000658: train Epoch: [31][107/129]	Time  1.050 ( 1.832)	Data  0.103 ( 0.883)	Loss 1.9676e-01 (9.2572e-02) 
2023-05-25 22:36:24.538173: train Epoch: [31][108/129]	Time  2.538 ( 1.839)	Data  1.592 ( 0.890)	Loss 8.0272e-02 (9.2459e-02) 
2023-05-25 22:36:25.531530: train Epoch: [31][109/129]	Time  0.993 ( 1.831)	Data  0.044 ( 0.882)	Loss 6.3161e-02 (9.2192e-02) 
2023-05-25 22:36:28.093521: train Epoch: [31][110/129]	Time  2.562 ( 1.837)	Data  1.618 ( 0.889)	Loss 8.2736e-02 (9.2107e-02) 
2023-05-25 22:36:29.116582: train Epoch: [31][111/129]	Time  1.023 ( 1.830)	Data  0.076 ( 0.882)	Loss 9.7276e-02 (9.2153e-02) 
2023-05-25 22:36:31.653430: train Epoch: [31][112/129]	Time  2.537 ( 1.836)	Data  1.591 ( 0.888)	Loss 5.4352e-02 (9.1819e-02) 
2023-05-25 22:36:32.604123: train Epoch: [31][113/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.880)	Loss 6.9895e-02 (9.1627e-02) 
2023-05-25 22:36:35.321056: train Epoch: [31][114/129]	Time  2.717 ( 1.836)	Data  1.773 ( 0.888)	Loss 9.3234e-02 (9.1641e-02) 
2023-05-25 22:36:36.268661: train Epoch: [31][115/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.880)	Loss 1.2094e-01 (9.1893e-02) 
2023-05-25 22:36:38.911176: train Epoch: [31][116/129]	Time  2.643 ( 1.836)	Data  1.699 ( 0.887)	Loss 7.7586e-02 (9.1771e-02) 
2023-05-25 22:36:39.870716: train Epoch: [31][117/129]	Time  0.960 ( 1.828)	Data  0.001 ( 0.880)	Loss 5.0707e-02 (9.1423e-02) 
2023-05-25 22:36:42.622352: train Epoch: [31][118/129]	Time  2.752 ( 1.836)	Data  1.798 ( 0.887)	Loss 1.2296e-01 (9.1688e-02) 
2023-05-25 22:36:43.578771: train Epoch: [31][119/129]	Time  0.956 ( 1.829)	Data  0.001 ( 0.880)	Loss 6.1803e-02 (9.1439e-02) 
2023-05-25 22:36:46.181153: train Epoch: [31][120/129]	Time  2.602 ( 1.835)	Data  1.650 ( 0.886)	Loss 8.6906e-02 (9.1401e-02) 
2023-05-25 22:36:47.139870: train Epoch: [31][121/129]	Time  0.959 ( 1.828)	Data  0.001 ( 0.879)	Loss 7.6746e-02 (9.1281e-02) 
2023-05-25 22:36:49.753563: train Epoch: [31][122/129]	Time  2.614 ( 1.834)	Data  1.661 ( 0.886)	Loss 9.2238e-02 (9.1289e-02) 
2023-05-25 22:36:50.749428: train Epoch: [31][123/129]	Time  0.996 ( 1.827)	Data  0.036 ( 0.879)	Loss 7.7087e-02 (9.1174e-02) 
2023-05-25 22:36:53.384975: train Epoch: [31][124/129]	Time  2.636 ( 1.834)	Data  1.683 ( 0.885)	Loss 9.2622e-02 (9.1186e-02) 
2023-05-25 22:36:54.335332: train Epoch: [31][125/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.878)	Loss 6.3924e-02 (9.0970e-02) 
2023-05-25 22:36:57.060387: train Epoch: [31][126/129]	Time  2.725 ( 1.834)	Data  1.778 ( 0.885)	Loss 8.9933e-02 (9.0962e-02) 
2023-05-25 22:36:58.008453: train Epoch: [31][127/129]	Time  0.948 ( 1.827)	Data  0.001 ( 0.878)	Loss 1.1363e-01 (9.1139e-02) 
2023-05-25 22:36:59.716914: train Epoch: [31][128/129]	Time  1.708 ( 1.826)	Data  0.765 ( 0.877)	Loss 1.1059e-01 (9.1289e-02) 
2023-05-25 22:36:59.748081: Train Epoch done in 235.60872546799874 s 
2023-05-25 22:37:02.100772: val Epoch: [31][ 0/72]	Time  1.623 ( 1.623)	Data  1.417 ( 1.417)	Loss 1.3027e-01 (1.3027e-01) 
2023-05-25 22:37:02.223068: val Epoch: [31][ 1/72]	Time  0.123 ( 0.873)	Data  0.002 ( 0.709)	Loss 6.6267e-02 (9.8268e-02) 
2023-05-25 22:37:03.223376: val Epoch: [31][ 2/72]	Time  1.000 ( 0.915)	Data  0.879 ( 0.766)	Loss 1.3161e-01 (1.0938e-01) 
2023-05-25 22:37:03.340245: val Epoch: [31][ 3/72]	Time  0.117 ( 0.716)	Data  0.000 ( 0.574)	Loss 4.7376e-02 (9.3882e-02) 
2023-05-25 22:37:04.461416: val Epoch: [31][ 4/72]	Time  1.121 ( 0.797)	Data  1.004 ( 0.660)	Loss 7.9209e-02 (9.0947e-02) 
2023-05-25 22:37:04.578310: val Epoch: [31][ 5/72]	Time  0.117 ( 0.683)	Data  0.000 ( 0.550)	Loss 4.2494e-01 (1.4661e-01) 
2023-05-25 22:37:05.723610: val Epoch: [31][ 6/72]	Time  1.145 ( 0.749)	Data  1.024 ( 0.618)	Loss 2.4284e-01 (1.6036e-01) 
2023-05-25 22:37:05.840683: val Epoch: [31][ 7/72]	Time  0.117 ( 0.670)	Data  0.000 ( 0.541)	Loss 5.5209e-02 (1.4722e-01) 
2023-05-25 22:37:07.044746: val Epoch: [31][ 8/72]	Time  1.204 ( 0.730)	Data  1.087 ( 0.601)	Loss 1.6107e-01 (1.4876e-01) 
2023-05-25 22:37:07.161675: val Epoch: [31][ 9/72]	Time  0.117 ( 0.668)	Data  0.000 ( 0.541)	Loss 6.3123e-02 (1.4019e-01) 
2023-05-25 22:37:08.294029: val Epoch: [31][10/72]	Time  1.132 ( 0.711)	Data  1.014 ( 0.584)	Loss 9.7383e-02 (1.3630e-01) 
2023-05-25 22:37:08.410962: val Epoch: [31][11/72]	Time  0.117 ( 0.661)	Data  0.000 ( 0.536)	Loss 6.9183e-02 (1.3071e-01) 
2023-05-25 22:37:09.527264: val Epoch: [31][12/72]	Time  1.116 ( 0.696)	Data  0.999 ( 0.571)	Loss 4.2717e-02 (1.2394e-01) 
2023-05-25 22:37:09.644392: val Epoch: [31][13/72]	Time  0.117 ( 0.655)	Data  0.000 ( 0.531)	Loss 8.2025e-02 (1.2094e-01) 
2023-05-25 22:37:10.775321: val Epoch: [31][14/72]	Time  1.131 ( 0.687)	Data  1.014 ( 0.563)	Loss 1.9109e-01 (1.2562e-01) 
2023-05-25 22:37:10.891991: val Epoch: [31][15/72]	Time  0.117 ( 0.651)	Data  0.000 ( 0.528)	Loss 7.3522e-02 (1.2236e-01) 
2023-05-25 22:37:11.985220: val Epoch: [31][16/72]	Time  1.093 ( 0.677)	Data  0.976 ( 0.554)	Loss 6.0830e-02 (1.1875e-01) 
2023-05-25 22:37:12.102774: val Epoch: [31][17/72]	Time  0.118 ( 0.646)	Data  0.000 ( 0.523)	Loss 4.7066e-02 (1.1476e-01) 
2023-05-25 22:37:13.245199: val Epoch: [31][18/72]	Time  1.142 ( 0.672)	Data  1.023 ( 0.550)	Loss 5.3165e-02 (1.1152e-01) 
2023-05-25 22:37:13.362790: val Epoch: [31][19/72]	Time  0.118 ( 0.644)	Data  0.001 ( 0.522)	Loss 6.0330e-02 (1.0896e-01) 
2023-05-25 22:37:14.446076: val Epoch: [31][20/72]	Time  1.083 ( 0.665)	Data  0.964 ( 0.543)	Loss 4.5333e-02 (1.0593e-01) 
2023-05-25 22:37:14.563291: val Epoch: [31][21/72]	Time  0.117 ( 0.640)	Data  0.000 ( 0.518)	Loss 4.2340e-01 (1.2036e-01) 
2023-05-25 22:37:15.760866: val Epoch: [31][22/72]	Time  1.198 ( 0.664)	Data  1.079 ( 0.543)	Loss 1.0923e-01 (1.1988e-01) 
2023-05-25 22:37:15.877705: val Epoch: [31][23/72]	Time  0.117 ( 0.642)	Data  0.000 ( 0.520)	Loss 5.4785e-02 (1.1717e-01) 
2023-05-25 22:37:16.975283: val Epoch: [31][24/72]	Time  1.098 ( 0.660)	Data  0.975 ( 0.538)	Loss 5.0859e-02 (1.1451e-01) 
2023-05-25 22:37:17.092053: val Epoch: [31][25/72]	Time  0.117 ( 0.639)	Data  0.000 ( 0.518)	Loss 1.1673e-01 (1.1460e-01) 
2023-05-25 22:37:18.284450: val Epoch: [31][26/72]	Time  1.192 ( 0.660)	Data  1.076 ( 0.538)	Loss 3.3214e-01 (1.2266e-01) 
2023-05-25 22:37:18.401573: val Epoch: [31][27/72]	Time  0.117 ( 0.640)	Data  0.000 ( 0.519)	Loss 1.4108e-01 (1.2331e-01) 
2023-05-25 22:37:19.622324: val Epoch: [31][28/72]	Time  1.221 ( 0.660)	Data  1.103 ( 0.539)	Loss 1.0846e-01 (1.2280e-01) 
2023-05-25 22:37:19.739584: val Epoch: [31][29/72]	Time  0.117 ( 0.642)	Data  0.000 ( 0.521)	Loss 6.3415e-02 (1.2082e-01) 
2023-05-25 22:37:20.949023: val Epoch: [31][30/72]	Time  1.209 ( 0.660)	Data  1.088 ( 0.540)	Loss 8.2962e-02 (1.1960e-01) 
2023-05-25 22:37:21.070228: val Epoch: [31][31/72]	Time  0.121 ( 0.644)	Data  0.001 ( 0.523)	Loss 5.3907e-01 (1.3271e-01) 
2023-05-25 22:37:22.180061: val Epoch: [31][32/72]	Time  1.110 ( 0.658)	Data  0.985 ( 0.537)	Loss 5.6251e-02 (1.3039e-01) 
2023-05-25 22:37:22.297569: val Epoch: [31][33/72]	Time  0.118 ( 0.642)	Data  0.000 ( 0.521)	Loss 3.2236e-01 (1.3604e-01) 
2023-05-25 22:37:23.526828: val Epoch: [31][34/72]	Time  1.229 ( 0.659)	Data  1.112 ( 0.538)	Loss 3.7319e-01 (1.4281e-01) 
2023-05-25 22:37:23.643775: val Epoch: [31][35/72]	Time  0.117 ( 0.644)	Data  0.000 ( 0.523)	Loss 6.6985e-02 (1.4071e-01) 
2023-05-25 22:37:24.798140: val Epoch: [31][36/72]	Time  1.154 ( 0.657)	Data  1.037 ( 0.537)	Loss 1.4354e-01 (1.4078e-01) 
2023-05-25 22:37:24.915039: val Epoch: [31][37/72]	Time  0.117 ( 0.643)	Data  0.000 ( 0.523)	Loss 5.9883e-02 (1.3866e-01) 
2023-05-25 22:37:26.078682: val Epoch: [31][38/72]	Time  1.164 ( 0.656)	Data  1.047 ( 0.536)	Loss 1.1902e-01 (1.3815e-01) 
2023-05-25 22:37:26.196242: val Epoch: [31][39/72]	Time  0.118 ( 0.643)	Data  0.001 ( 0.523)	Loss 1.6646e-01 (1.3886e-01) 
2023-05-25 22:37:27.289970: val Epoch: [31][40/72]	Time  1.094 ( 0.654)	Data  0.977 ( 0.534)	Loss 6.9542e-02 (1.3717e-01) 
2023-05-25 22:37:27.406441: val Epoch: [31][41/72]	Time  0.116 ( 0.641)	Data  0.000 ( 0.521)	Loss 4.6382e-02 (1.3501e-01) 
2023-05-25 22:37:28.537219: val Epoch: [31][42/72]	Time  1.131 ( 0.653)	Data  1.007 ( 0.532)	Loss 2.0397e-01 (1.3661e-01) 
2023-05-25 22:37:28.658882: val Epoch: [31][43/72]	Time  0.122 ( 0.640)	Data  0.001 ( 0.520)	Loss 1.3092e-01 (1.3648e-01) 
2023-05-25 22:37:29.803380: val Epoch: [31][44/72]	Time  1.144 ( 0.652)	Data  1.027 ( 0.532)	Loss 4.4047e-02 (1.3443e-01) 
2023-05-25 22:37:29.920241: val Epoch: [31][45/72]	Time  0.117 ( 0.640)	Data  0.000 ( 0.520)	Loss 5.4395e-02 (1.3269e-01) 
2023-05-25 22:37:31.085375: val Epoch: [31][46/72]	Time  1.165 ( 0.651)	Data  1.045 ( 0.531)	Loss 5.8658e-02 (1.3111e-01) 
2023-05-25 22:37:31.202864: val Epoch: [31][47/72]	Time  0.117 ( 0.640)	Data  0.001 ( 0.520)	Loss 1.0863e-01 (1.3064e-01) 
2023-05-25 22:37:32.308595: val Epoch: [31][48/72]	Time  1.106 ( 0.650)	Data  0.988 ( 0.530)	Loss 8.8844e-02 (1.2979e-01) 
2023-05-25 22:37:32.425334: val Epoch: [31][49/72]	Time  0.117 ( 0.639)	Data  0.000 ( 0.519)	Loss 9.8175e-02 (1.2916e-01) 
2023-05-25 22:37:33.516150: val Epoch: [31][50/72]	Time  1.091 ( 0.648)	Data  0.973 ( 0.528)	Loss 3.2092e-01 (1.3292e-01) 
2023-05-25 22:37:33.651082: val Epoch: [31][51/72]	Time  0.135 ( 0.638)	Data  0.018 ( 0.518)	Loss 3.8986e-01 (1.3786e-01) 
2023-05-25 22:37:34.794673: val Epoch: [31][52/72]	Time  1.144 ( 0.647)	Data  1.022 ( 0.528)	Loss 3.5886e-01 (1.4203e-01) 
2023-05-25 22:37:34.911571: val Epoch: [31][53/72]	Time  0.117 ( 0.638)	Data  0.000 ( 0.518)	Loss 7.0462e-02 (1.4070e-01) 
2023-05-25 22:37:36.040339: val Epoch: [31][54/72]	Time  1.129 ( 0.647)	Data  1.005 ( 0.527)	Loss 6.1486e-02 (1.3926e-01) 
2023-05-25 22:37:36.163325: val Epoch: [31][55/72]	Time  0.123 ( 0.637)	Data  0.002 ( 0.517)	Loss 4.4760e-01 (1.4477e-01) 
2023-05-25 22:37:37.299370: val Epoch: [31][56/72]	Time  1.136 ( 0.646)	Data  1.011 ( 0.526)	Loss 1.0527e-01 (1.4408e-01) 
2023-05-25 22:37:37.415873: val Epoch: [31][57/72]	Time  0.116 ( 0.637)	Data  0.000 ( 0.517)	Loss 2.0091e-01 (1.4506e-01) 
2023-05-25 22:37:38.626353: val Epoch: [31][58/72]	Time  1.210 ( 0.647)	Data  1.094 ( 0.527)	Loss 8.7275e-02 (1.4408e-01) 
2023-05-25 22:37:38.742666: val Epoch: [31][59/72]	Time  0.116 ( 0.638)	Data  0.000 ( 0.518)	Loss 1.0545e-01 (1.4343e-01) 
2023-05-25 22:37:39.853157: val Epoch: [31][60/72]	Time  1.110 ( 0.645)	Data  0.993 ( 0.526)	Loss 2.1922e-01 (1.4468e-01) 
2023-05-25 22:37:39.970540: val Epoch: [31][61/72]	Time  0.117 ( 0.637)	Data  0.001 ( 0.517)	Loss 8.3783e-02 (1.4369e-01) 
2023-05-25 22:37:41.080022: val Epoch: [31][62/72]	Time  1.109 ( 0.644)	Data  0.991 ( 0.525)	Loss 6.4605e-02 (1.4244e-01) 
2023-05-25 22:37:41.203301: val Epoch: [31][63/72]	Time  0.123 ( 0.636)	Data  0.002 ( 0.517)	Loss 5.6882e-02 (1.4110e-01) 
2023-05-25 22:37:42.288245: val Epoch: [31][64/72]	Time  1.085 ( 0.643)	Data  0.963 ( 0.524)	Loss 4.6074e-02 (1.3964e-01) 
2023-05-25 22:37:42.410235: val Epoch: [31][65/72]	Time  0.122 ( 0.635)	Data  0.001 ( 0.516)	Loss 5.2278e-02 (1.3832e-01) 
2023-05-25 22:37:43.517463: val Epoch: [31][66/72]	Time  1.107 ( 0.642)	Data  0.987 ( 0.523)	Loss 4.3594e-02 (1.3690e-01) 
2023-05-25 22:37:43.634859: val Epoch: [31][67/72]	Time  0.117 ( 0.635)	Data  0.001 ( 0.515)	Loss 1.1316e-01 (1.3655e-01) 
2023-05-25 22:37:44.776345: val Epoch: [31][68/72]	Time  1.141 ( 0.642)	Data  1.023 ( 0.522)	Loss 9.0409e-02 (1.3588e-01) 
2023-05-25 22:37:44.893000: val Epoch: [31][69/72]	Time  0.117 ( 0.635)	Data  0.000 ( 0.515)	Loss 1.3920e-01 (1.3593e-01) 
2023-05-25 22:37:46.131159: val Epoch: [31][70/72]	Time  1.238 ( 0.643)	Data  1.122 ( 0.523)	Loss 1.6513e-01 (1.3634e-01) 
2023-05-25 22:37:46.246670: val Epoch: [31][71/72]	Time  0.116 ( 0.636)	Data  0.000 ( 0.516)	Loss 3.6681e-02 (1.3496e-01) 
2023-05-25 22:37:46.395456: Epoch 31 :Val : ['ET : 0.7044152021408081', 'TC : 0.7761267423629761', 'WT : 0.8591263890266418'] 
2023-05-25 22:37:46.396562: Epoch 31 :Val : ['ET : 0.7044152021408081', 'TC : 0.7761267423629761', 'WT : 0.8591263890266418'] 
2023-05-25 22:37:46.402353: Val epoch done in 46.65429094399951 s 
2023-05-25 22:37:46.411660: Batches per epoch:  129 
2023-05-25 22:37:51.334497: train Epoch: [32][  0/129]	Time  4.922 ( 4.922)	Data  3.928 ( 3.928)	Loss 1.0733e-01 (1.0733e-01) 
2023-05-25 22:37:52.283893: train Epoch: [32][  1/129]	Time  0.949 ( 2.936)	Data  0.001 ( 1.964)	Loss 5.0124e-02 (7.8729e-02) 
2023-05-25 22:37:54.991271: train Epoch: [32][  2/129]	Time  2.707 ( 2.860)	Data  1.748 ( 1.892)	Loss 8.4295e-02 (8.0584e-02) 
2023-05-25 22:37:55.939167: train Epoch: [32][  3/129]	Time  0.948 ( 2.382)	Data  0.001 ( 1.419)	Loss 8.7077e-02 (8.2207e-02) 
2023-05-25 22:37:58.766412: train Epoch: [32][  4/129]	Time  2.827 ( 2.471)	Data  1.870 ( 1.510)	Loss 9.9270e-02 (8.5620e-02) 
2023-05-25 22:37:59.717208: train Epoch: [32][  5/129]	Time  0.951 ( 2.217)	Data  0.001 ( 1.258)	Loss 1.1271e-01 (9.0136e-02) 
2023-05-25 22:38:02.400951: train Epoch: [32][  6/129]	Time  2.684 ( 2.284)	Data  1.732 ( 1.326)	Loss 6.2822e-02 (8.6234e-02) 
2023-05-25 22:38:03.350385: train Epoch: [32][  7/129]	Time  0.949 ( 2.117)	Data  0.001 ( 1.160)	Loss 8.6057e-02 (8.6212e-02) 
2023-05-25 22:38:06.158555: train Epoch: [32][  8/129]	Time  2.808 ( 2.194)	Data  1.863 ( 1.238)	Loss 9.2646e-02 (8.6927e-02) 
2023-05-25 22:38:07.107441: train Epoch: [32][  9/129]	Time  0.949 ( 2.070)	Data  0.001 ( 1.114)	Loss 8.9041e-02 (8.7138e-02) 
2023-05-25 22:38:09.894103: train Epoch: [32][ 10/129]	Time  2.787 ( 2.135)	Data  1.829 ( 1.179)	Loss 1.3144e-01 (9.1165e-02) 
2023-05-25 22:38:10.843847: train Epoch: [32][ 11/129]	Time  0.950 ( 2.036)	Data  0.001 ( 1.081)	Loss 1.1944e-01 (9.3521e-02) 
2023-05-25 22:38:13.574975: train Epoch: [32][ 12/129]	Time  2.731 ( 2.089)	Data  1.784 ( 1.135)	Loss 1.4551e-01 (9.7520e-02) 
2023-05-25 22:38:14.522705: train Epoch: [32][ 13/129]	Time  0.948 ( 2.008)	Data  0.001 ( 1.054)	Loss 7.9621e-02 (9.6242e-02) 
2023-05-25 22:38:17.223406: train Epoch: [32][ 14/129]	Time  2.701 ( 2.054)	Data  1.748 ( 1.100)	Loss 7.7538e-02 (9.4995e-02) 
2023-05-25 22:38:18.172620: train Epoch: [32][ 15/129]	Time  0.949 ( 1.985)	Data  0.001 ( 1.032)	Loss 5.4051e-02 (9.2436e-02) 
2023-05-25 22:38:20.891778: train Epoch: [32][ 16/129]	Time  2.719 ( 2.028)	Data  1.774 ( 1.075)	Loss 8.4607e-02 (9.1975e-02) 
2023-05-25 22:38:21.839431: train Epoch: [32][ 17/129]	Time  0.948 ( 1.968)	Data  0.001 ( 1.016)	Loss 7.5733e-02 (9.1073e-02) 
2023-05-25 22:38:24.568178: train Epoch: [32][ 18/129]	Time  2.729 ( 2.008)	Data  1.783 ( 1.056)	Loss 7.4790e-02 (9.0216e-02) 
2023-05-25 22:38:25.520743: train Epoch: [32][ 19/129]	Time  0.953 ( 1.955)	Data  0.001 ( 1.003)	Loss 7.9756e-02 (8.9693e-02) 
2023-05-25 22:38:28.245156: train Epoch: [32][ 20/129]	Time  2.724 ( 1.992)	Data  1.777 ( 1.040)	Loss 6.9135e-02 (8.8714e-02) 
2023-05-25 22:38:29.195635: train Epoch: [32][ 21/129]	Time  0.950 ( 1.945)	Data  0.001 ( 0.993)	Loss 1.0341e-01 (8.9382e-02) 
2023-05-25 22:38:32.032803: train Epoch: [32][ 22/129]	Time  2.837 ( 1.983)	Data  1.880 ( 1.032)	Loss 1.1383e-01 (9.0445e-02) 
2023-05-25 22:38:32.982236: train Epoch: [32][ 23/129]	Time  0.949 ( 1.940)	Data  0.001 ( 0.989)	Loss 9.6230e-02 (9.0686e-02) 
2023-05-25 22:38:35.728005: train Epoch: [32][ 24/129]	Time  2.746 ( 1.973)	Data  1.801 ( 1.021)	Loss 8.4586e-02 (9.0442e-02) 
2023-05-25 22:38:36.676150: train Epoch: [32][ 25/129]	Time  0.948 ( 1.933)	Data  0.001 ( 0.982)	Loss 7.5236e-02 (8.9857e-02) 
2023-05-25 22:38:39.297697: train Epoch: [32][ 26/129]	Time  2.622 ( 1.959)	Data  1.677 ( 1.008)	Loss 5.6530e-02 (8.8623e-02) 
2023-05-25 22:38:40.246527: train Epoch: [32][ 27/129]	Time  0.949 ( 1.923)	Data  0.001 ( 0.972)	Loss 8.1404e-02 (8.8365e-02) 
2023-05-25 22:38:42.870332: train Epoch: [32][ 28/129]	Time  2.624 ( 1.947)	Data  1.677 ( 0.996)	Loss 1.5353e-01 (9.0612e-02) 
2023-05-25 22:38:43.818886: train Epoch: [32][ 29/129]	Time  0.949 ( 1.914)	Data  0.001 ( 0.963)	Loss 3.5099e-01 (9.9291e-02) 
2023-05-25 22:38:46.475505: train Epoch: [32][ 30/129]	Time  2.657 ( 1.938)	Data  1.712 ( 0.987)	Loss 8.4795e-02 (9.8824e-02) 
2023-05-25 22:38:47.424012: train Epoch: [32][ 31/129]	Time  0.949 ( 1.907)	Data  0.001 ( 0.956)	Loss 1.2224e-01 (9.9555e-02) 
2023-05-25 22:38:50.073954: train Epoch: [32][ 32/129]	Time  2.650 ( 1.929)	Data  1.706 ( 0.979)	Loss 8.6995e-02 (9.9175e-02) 
2023-05-25 22:38:51.020554: train Epoch: [32][ 33/129]	Time  0.947 ( 1.900)	Data  0.001 ( 0.950)	Loss 1.4786e-01 (1.0061e-01) 
2023-05-25 22:38:53.702577: train Epoch: [32][ 34/129]	Time  2.682 ( 1.923)	Data  1.738 ( 0.973)	Loss 6.9323e-02 (9.9713e-02) 
2023-05-25 22:38:54.649059: train Epoch: [32][ 35/129]	Time  0.946 ( 1.895)	Data  0.001 ( 0.946)	Loss 8.4860e-02 (9.9300e-02) 
2023-05-25 22:38:57.374565: train Epoch: [32][ 36/129]	Time  2.725 ( 1.918)	Data  1.780 ( 0.968)	Loss 1.4436e-01 (1.0052e-01) 
2023-05-25 22:38:58.322449: train Epoch: [32][ 37/129]	Time  0.948 ( 1.892)	Data  0.001 ( 0.943)	Loss 8.8877e-02 (1.0021e-01) 
2023-05-25 22:39:00.999864: train Epoch: [32][ 38/129]	Time  2.677 ( 1.912)	Data  1.734 ( 0.963)	Loss 5.9653e-02 (9.9172e-02) 
2023-05-25 22:39:01.946436: train Epoch: [32][ 39/129]	Time  0.947 ( 1.888)	Data  0.001 ( 0.939)	Loss 4.8270e-02 (9.7899e-02) 
2023-05-25 22:39:04.530943: train Epoch: [32][ 40/129]	Time  2.584 ( 1.905)	Data  1.641 ( 0.956)	Loss 1.1978e-01 (9.8433e-02) 
2023-05-25 22:39:05.477714: train Epoch: [32][ 41/129]	Time  0.947 ( 1.883)	Data  0.001 ( 0.933)	Loss 5.3631e-02 (9.7366e-02) 
2023-05-25 22:39:08.196117: train Epoch: [32][ 42/129]	Time  2.718 ( 1.902)	Data  1.773 ( 0.953)	Loss 9.7194e-02 (9.7362e-02) 
2023-05-25 22:39:09.143056: train Epoch: [32][ 43/129]	Time  0.947 ( 1.880)	Data  0.001 ( 0.931)	Loss 1.1224e-01 (9.7700e-02) 
2023-05-25 22:39:11.786830: train Epoch: [32][ 44/129]	Time  2.644 ( 1.897)	Data  1.700 ( 0.948)	Loss 1.4810e-01 (9.8820e-02) 
2023-05-25 22:39:12.735887: train Epoch: [32][ 45/129]	Time  0.949 ( 1.877)	Data  0.001 ( 0.928)	Loss 9.3635e-02 (9.8708e-02) 
2023-05-25 22:39:15.374877: train Epoch: [32][ 46/129]	Time  2.639 ( 1.893)	Data  1.694 ( 0.944)	Loss 6.0547e-02 (9.7896e-02) 
2023-05-25 22:39:16.321691: train Epoch: [32][ 47/129]	Time  0.947 ( 1.873)	Data  0.001 ( 0.924)	Loss 9.5513e-02 (9.7846e-02) 
2023-05-25 22:39:18.954139: train Epoch: [32][ 48/129]	Time  2.632 ( 1.889)	Data  1.687 ( 0.940)	Loss 7.5675e-02 (9.7394e-02) 
2023-05-25 22:39:19.902033: train Epoch: [32][ 49/129]	Time  0.948 ( 1.870)	Data  0.001 ( 0.921)	Loss 8.2878e-02 (9.7103e-02) 
2023-05-25 22:39:22.561284: train Epoch: [32][ 50/129]	Time  2.659 ( 1.885)	Data  1.714 ( 0.937)	Loss 7.7145e-02 (9.6712e-02) 
2023-05-25 22:39:23.509422: train Epoch: [32][ 51/129]	Time  0.948 ( 1.867)	Data  0.001 ( 0.919)	Loss 1.3690e-01 (9.7485e-02) 
2023-05-25 22:39:26.171856: train Epoch: [32][ 52/129]	Time  2.662 ( 1.882)	Data  1.717 ( 0.934)	Loss 7.0010e-02 (9.6967e-02) 
2023-05-25 22:39:27.119325: train Epoch: [32][ 53/129]	Time  0.947 ( 1.865)	Data  0.001 ( 0.916)	Loss 6.9595e-02 (9.6460e-02) 
2023-05-25 22:39:29.708649: train Epoch: [32][ 54/129]	Time  2.589 ( 1.878)	Data  1.644 ( 0.930)	Loss 1.0293e-01 (9.6577e-02) 
2023-05-25 22:39:30.660121: train Epoch: [32][ 55/129]	Time  0.951 ( 1.862)	Data  0.001 ( 0.913)	Loss 8.0904e-02 (9.6297e-02) 
2023-05-25 22:39:33.287720: train Epoch: [32][ 56/129]	Time  2.628 ( 1.875)	Data  1.673 ( 0.926)	Loss 8.8395e-02 (9.6159e-02) 
2023-05-25 22:39:34.247404: train Epoch: [32][ 57/129]	Time  0.960 ( 1.859)	Data  0.001 ( 0.910)	Loss 8.1471e-02 (9.5906e-02) 
2023-05-25 22:39:36.904139: train Epoch: [32][ 58/129]	Time  2.657 ( 1.873)	Data  1.701 ( 0.924)	Loss 7.6789e-02 (9.5582e-02) 
2023-05-25 22:39:37.863692: train Epoch: [32][ 59/129]	Time  0.960 ( 1.858)	Data  0.001 ( 0.908)	Loss 8.3566e-02 (9.5381e-02) 
2023-05-25 22:39:40.551740: train Epoch: [32][ 60/129]	Time  2.688 ( 1.871)	Data  1.730 ( 0.922)	Loss 6.7472e-02 (9.4924e-02) 
2023-05-25 22:39:41.509691: train Epoch: [32][ 61/129]	Time  0.958 ( 1.856)	Data  0.001 ( 0.907)	Loss 1.1703e-01 (9.5280e-02) 
2023-05-25 22:39:44.183444: train Epoch: [32][ 62/129]	Time  2.674 ( 1.869)	Data  1.716 ( 0.920)	Loss 9.3520e-02 (9.5252e-02) 
2023-05-25 22:39:45.142280: train Epoch: [32][ 63/129]	Time  0.959 ( 1.855)	Data  0.001 ( 0.906)	Loss 2.2728e-01 (9.7315e-02) 
2023-05-25 22:39:47.796705: train Epoch: [32][ 64/129]	Time  2.654 ( 1.867)	Data  1.698 ( 0.918)	Loss 7.2608e-02 (9.6935e-02) 
2023-05-25 22:39:48.756565: train Epoch: [32][ 65/129]	Time  0.960 ( 1.854)	Data  0.001 ( 0.904)	Loss 8.8323e-02 (9.6805e-02) 
2023-05-25 22:39:51.481976: train Epoch: [32][ 66/129]	Time  2.725 ( 1.867)	Data  1.770 ( 0.917)	Loss 7.4445e-02 (9.6471e-02) 
2023-05-25 22:39:52.442402: train Epoch: [32][ 67/129]	Time  0.960 ( 1.853)	Data  0.001 ( 0.903)	Loss 9.7359e-02 (9.6484e-02) 
2023-05-25 22:39:55.144879: train Epoch: [32][ 68/129]	Time  2.702 ( 1.866)	Data  1.748 ( 0.916)	Loss 5.9408e-02 (9.5947e-02) 
2023-05-25 22:39:56.102223: train Epoch: [32][ 69/129]	Time  0.957 ( 1.853)	Data  0.001 ( 0.902)	Loss 4.4938e-02 (9.5218e-02) 
2023-05-25 22:39:58.805775: train Epoch: [32][ 70/129]	Time  2.704 ( 1.865)	Data  1.749 ( 0.914)	Loss 1.7526e-01 (9.6345e-02) 
2023-05-25 22:39:59.761907: train Epoch: [32][ 71/129]	Time  0.956 ( 1.852)	Data  0.001 ( 0.902)	Loss 6.3495e-02 (9.5889e-02) 
2023-05-25 22:40:02.396615: train Epoch: [32][ 72/129]	Time  2.635 ( 1.863)	Data  1.689 ( 0.912)	Loss 7.9601e-02 (9.5666e-02) 
2023-05-25 22:40:03.354346: train Epoch: [32][ 73/129]	Time  0.958 ( 1.851)	Data  0.001 ( 0.900)	Loss 1.6667e-01 (9.6626e-02) 
2023-05-25 22:40:06.012905: train Epoch: [32][ 74/129]	Time  2.659 ( 1.861)	Data  1.704 ( 0.911)	Loss 7.9472e-02 (9.6397e-02) 
2023-05-25 22:40:06.972496: train Epoch: [32][ 75/129]	Time  0.960 ( 1.849)	Data  0.001 ( 0.899)	Loss 6.4894e-02 (9.5982e-02) 
2023-05-25 22:40:09.667104: train Epoch: [32][ 76/129]	Time  2.695 ( 1.860)	Data  1.740 ( 0.910)	Loss 3.7763e-02 (9.5226e-02) 
2023-05-25 22:40:10.617600: train Epoch: [32][ 77/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.898)	Loss 9.4022e-02 (9.5211e-02) 
2023-05-25 22:40:13.202456: train Epoch: [32][ 78/129]	Time  2.585 ( 1.858)	Data  1.641 ( 0.908)	Loss 8.1315e-02 (9.5035e-02) 
2023-05-25 22:40:14.150245: train Epoch: [32][ 79/129]	Time  0.948 ( 1.847)	Data  0.001 ( 0.896)	Loss 7.2829e-02 (9.4757e-02) 
2023-05-25 22:40:16.782472: train Epoch: [32][ 80/129]	Time  2.632 ( 1.856)	Data  1.688 ( 0.906)	Loss 6.5260e-02 (9.4393e-02) 
2023-05-25 22:40:17.731653: train Epoch: [32][ 81/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.895)	Loss 9.4408e-02 (9.4393e-02) 
2023-05-25 22:40:20.434259: train Epoch: [32][ 82/129]	Time  2.703 ( 1.856)	Data  1.758 ( 0.905)	Loss 6.4991e-02 (9.4039e-02) 
2023-05-25 22:40:21.382067: train Epoch: [32][ 83/129]	Time  0.948 ( 1.845)	Data  0.001 ( 0.895)	Loss 6.6772e-02 (9.3714e-02) 
2023-05-25 22:40:23.986024: train Epoch: [32][ 84/129]	Time  2.604 ( 1.854)	Data  1.659 ( 0.904)	Loss 8.9184e-02 (9.3661e-02) 
2023-05-25 22:40:24.934859: train Epoch: [32][ 85/129]	Time  0.949 ( 1.843)	Data  0.001 ( 0.893)	Loss 8.6697e-02 (9.3580e-02) 
2023-05-25 22:40:27.535336: train Epoch: [32][ 86/129]	Time  2.600 ( 1.852)	Data  1.653 ( 0.902)	Loss 5.7511e-02 (9.3166e-02) 
2023-05-25 22:40:28.493174: train Epoch: [32][ 87/129]	Time  0.958 ( 1.842)	Data  0.001 ( 0.892)	Loss 7.3400e-02 (9.2941e-02) 
2023-05-25 22:40:31.200212: train Epoch: [32][ 88/129]	Time  2.707 ( 1.852)	Data  1.751 ( 0.901)	Loss 6.5683e-02 (9.2635e-02) 
2023-05-25 22:40:32.159882: train Epoch: [32][ 89/129]	Time  0.960 ( 1.842)	Data  0.001 ( 0.891)	Loss 9.5611e-02 (9.2668e-02) 
2023-05-25 22:40:34.776524: train Epoch: [32][ 90/129]	Time  2.617 ( 1.850)	Data  1.662 ( 0.900)	Loss 6.7331e-02 (9.2389e-02) 
2023-05-25 22:40:35.735938: train Epoch: [32][ 91/129]	Time  0.959 ( 1.840)	Data  0.001 ( 0.890)	Loss 1.1066e-01 (9.2588e-02) 
2023-05-25 22:40:38.431788: train Epoch: [32][ 92/129]	Time  2.696 ( 1.850)	Data  1.743 ( 0.899)	Loss 6.8338e-02 (9.2327e-02) 
2023-05-25 22:40:39.379596: train Epoch: [32][ 93/129]	Time  0.948 ( 1.840)	Data  0.001 ( 0.890)	Loss 7.6801e-02 (9.2162e-02) 
2023-05-25 22:40:42.054320: train Epoch: [32][ 94/129]	Time  2.675 ( 1.849)	Data  1.729 ( 0.898)	Loss 6.0641e-02 (9.1830e-02) 
2023-05-25 22:40:43.002860: train Epoch: [32][ 95/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.889)	Loss 3.9838e-02 (9.1289e-02) 
2023-05-25 22:40:45.545837: train Epoch: [32][ 96/129]	Time  2.543 ( 1.847)	Data  1.598 ( 0.896)	Loss 1.2212e-01 (9.1607e-02) 
2023-05-25 22:40:46.494663: train Epoch: [32][ 97/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.887)	Loss 1.3728e-01 (9.2073e-02) 
2023-05-25 22:40:49.180654: train Epoch: [32][ 98/129]	Time  2.686 ( 1.846)	Data  1.741 ( 0.896)	Loss 8.1828e-02 (9.1969e-02) 
2023-05-25 22:40:50.129048: train Epoch: [32][ 99/129]	Time  0.948 ( 1.837)	Data  0.001 ( 0.887)	Loss 6.9562e-02 (9.1745e-02) 
2023-05-25 22:40:52.858180: train Epoch: [32][100/129]	Time  2.729 ( 1.846)	Data  1.784 ( 0.896)	Loss 7.1451e-02 (9.1544e-02) 
2023-05-25 22:40:53.804917: train Epoch: [32][101/129]	Time  0.947 ( 1.837)	Data  0.001 ( 0.887)	Loss 9.1135e-02 (9.1540e-02) 
2023-05-25 22:40:56.483158: train Epoch: [32][102/129]	Time  2.678 ( 1.845)	Data  1.733 ( 0.895)	Loss 1.3932e-01 (9.2004e-02) 
2023-05-25 22:40:57.430523: train Epoch: [32][103/129]	Time  0.947 ( 1.837)	Data  0.001 ( 0.887)	Loss 7.4660e-02 (9.1837e-02) 
2023-05-25 22:41:00.118293: train Epoch: [32][104/129]	Time  2.688 ( 1.845)	Data  1.743 ( 0.895)	Loss 9.9435e-02 (9.1910e-02) 
2023-05-25 22:41:01.065302: train Epoch: [32][105/129]	Time  0.947 ( 1.836)	Data  0.001 ( 0.886)	Loss 1.1477e-01 (9.2125e-02) 
2023-05-25 22:41:03.627817: train Epoch: [32][106/129]	Time  2.563 ( 1.843)	Data  1.616 ( 0.893)	Loss 7.8542e-02 (9.1998e-02) 
2023-05-25 22:41:04.586287: train Epoch: [32][107/129]	Time  0.958 ( 1.835)	Data  0.001 ( 0.885)	Loss 1.3542e-01 (9.2400e-02) 
2023-05-25 22:41:07.321493: train Epoch: [32][108/129]	Time  2.735 ( 1.843)	Data  1.790 ( 0.893)	Loss 6.6529e-02 (9.2163e-02) 
2023-05-25 22:41:08.269109: train Epoch: [32][109/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.885)	Loss 9.1898e-02 (9.2161e-02) 
2023-05-25 22:41:10.930676: train Epoch: [32][110/129]	Time  2.662 ( 1.843)	Data  1.717 ( 0.893)	Loss 5.2091e-02 (9.1800e-02) 
2023-05-25 22:41:11.877568: train Epoch: [32][111/129]	Time  0.947 ( 1.835)	Data  0.001 ( 0.885)	Loss 1.6109e-01 (9.2418e-02) 
2023-05-25 22:41:14.430218: train Epoch: [32][112/129]	Time  2.553 ( 1.841)	Data  1.607 ( 0.891)	Loss 8.2836e-02 (9.2333e-02) 
2023-05-25 22:41:15.382155: train Epoch: [32][113/129]	Time  0.952 ( 1.833)	Data  0.001 ( 0.883)	Loss 6.1469e-02 (9.2063e-02) 
2023-05-25 22:41:18.029499: train Epoch: [32][114/129]	Time  2.647 ( 1.840)	Data  1.702 ( 0.890)	Loss 1.3310e-01 (9.2420e-02) 
2023-05-25 22:41:18.977597: train Epoch: [32][115/129]	Time  0.948 ( 1.832)	Data  0.001 ( 0.883)	Loss 6.9939e-02 (9.2226e-02) 
2023-05-25 22:41:21.755798: train Epoch: [32][116/129]	Time  2.778 ( 1.841)	Data  1.833 ( 0.891)	Loss 1.1336e-01 (9.2406e-02) 
2023-05-25 22:41:22.702449: train Epoch: [32][117/129]	Time  0.947 ( 1.833)	Data  0.001 ( 0.883)	Loss 9.7069e-02 (9.2446e-02) 
2023-05-25 22:41:25.300988: train Epoch: [32][118/129]	Time  2.599 ( 1.839)	Data  1.654 ( 0.890)	Loss 6.1991e-02 (9.2190e-02) 
2023-05-25 22:41:26.248467: train Epoch: [32][119/129]	Time  0.947 ( 1.832)	Data  0.001 ( 0.882)	Loss 1.8619e-01 (9.2973e-02) 
2023-05-25 22:41:28.842578: train Epoch: [32][120/129]	Time  2.594 ( 1.838)	Data  1.650 ( 0.889)	Loss 1.2152e-01 (9.3209e-02) 
2023-05-25 22:41:29.790282: train Epoch: [32][121/129]	Time  0.948 ( 1.831)	Data  0.001 ( 0.881)	Loss 7.5120e-02 (9.3061e-02) 
2023-05-25 22:41:32.395747: train Epoch: [32][122/129]	Time  2.605 ( 1.837)	Data  1.661 ( 0.888)	Loss 1.1966e-01 (9.3277e-02) 
2023-05-25 22:41:33.343999: train Epoch: [32][123/129]	Time  0.948 ( 1.830)	Data  0.001 ( 0.881)	Loss 7.4039e-02 (9.3122e-02) 
2023-05-25 22:41:35.974388: train Epoch: [32][124/129]	Time  2.630 ( 1.836)	Data  1.684 ( 0.887)	Loss 6.8133e-02 (9.2922e-02) 
2023-05-25 22:41:36.925090: train Epoch: [32][125/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.880)	Loss 9.4061e-02 (9.2931e-02) 
2023-05-25 22:41:39.527397: train Epoch: [32][126/129]	Time  2.602 ( 1.836)	Data  1.653 ( 0.886)	Loss 1.2589e-01 (9.3191e-02) 
2023-05-25 22:41:40.471025: train Epoch: [32][127/129]	Time  0.944 ( 1.829)	Data  0.001 ( 0.879)	Loss 8.9569e-02 (9.3162e-02) 
2023-05-25 22:41:41.888379: train Epoch: [32][128/129]	Time  1.417 ( 1.825)	Data  0.473 ( 0.876)	Loss 6.3117e-02 (9.2929e-02) 
2023-05-25 22:41:41.919627: Train Epoch done in 235.508016243999 s 
2023-05-25 22:41:44.341777: val Epoch: [32][ 0/72]	Time  1.634 ( 1.634)	Data  1.432 ( 1.432)	Loss 1.2391e-01 (1.2391e-01) 
2023-05-25 22:41:44.463725: val Epoch: [32][ 1/72]	Time  0.122 ( 0.878)	Data  0.001 ( 0.717)	Loss 5.6743e-02 (9.0328e-02) 
2023-05-25 22:41:45.475532: val Epoch: [32][ 2/72]	Time  1.012 ( 0.923)	Data  0.890 ( 0.775)	Loss 1.1313e-01 (9.7928e-02) 
2023-05-25 22:41:45.597314: val Epoch: [32][ 3/72]	Time  0.122 ( 0.722)	Data  0.001 ( 0.581)	Loss 6.2496e-02 (8.9070e-02) 
2023-05-25 22:41:46.741358: val Epoch: [32][ 4/72]	Time  1.144 ( 0.807)	Data  1.022 ( 0.669)	Loss 5.8057e-02 (8.2867e-02) 
2023-05-25 22:41:46.866049: val Epoch: [32][ 5/72]	Time  0.125 ( 0.693)	Data  0.001 ( 0.558)	Loss 2.1220e-01 (1.0442e-01) 
2023-05-25 22:41:48.039824: val Epoch: [32][ 6/72]	Time  1.174 ( 0.762)	Data  1.049 ( 0.628)	Loss 8.8359e-02 (1.0213e-01) 
2023-05-25 22:41:48.165669: val Epoch: [32][ 7/72]	Time  0.126 ( 0.682)	Data  0.001 ( 0.550)	Loss 1.4433e-01 (1.0740e-01) 
2023-05-25 22:41:49.335115: val Epoch: [32][ 8/72]	Time  1.169 ( 0.736)	Data  1.048 ( 0.605)	Loss 5.8057e-02 (1.0192e-01) 
2023-05-25 22:41:49.456415: val Epoch: [32][ 9/72]	Time  0.121 ( 0.675)	Data  0.001 ( 0.545)	Loss 9.2684e-02 (1.0100e-01) 
2023-05-25 22:41:50.594719: val Epoch: [32][10/72]	Time  1.138 ( 0.717)	Data  1.012 ( 0.587)	Loss 1.5008e-01 (1.0546e-01) 
2023-05-25 22:41:50.720228: val Epoch: [32][11/72]	Time  0.126 ( 0.668)	Data  0.001 ( 0.538)	Loss 9.5776e-02 (1.0465e-01) 
2023-05-25 22:41:51.844860: val Epoch: [32][12/72]	Time  1.125 ( 0.703)	Data  1.004 ( 0.574)	Loss 5.8521e-02 (1.0110e-01) 
2023-05-25 22:41:51.965389: val Epoch: [32][13/72]	Time  0.121 ( 0.661)	Data  0.000 ( 0.533)	Loss 1.9564e-01 (1.0786e-01) 
2023-05-25 22:41:53.065437: val Epoch: [32][14/72]	Time  1.100 ( 0.691)	Data  0.971 ( 0.562)	Loss 8.9738e-02 (1.0665e-01) 
2023-05-25 22:41:53.186036: val Epoch: [32][15/72]	Time  0.121 ( 0.655)	Data  0.000 ( 0.527)	Loss 6.7933e-02 (1.0423e-01) 
2023-05-25 22:41:54.257885: val Epoch: [32][16/72]	Time  1.072 ( 0.679)	Data  0.952 ( 0.552)	Loss 1.1870e-01 (1.0508e-01) 
2023-05-25 22:41:54.378998: val Epoch: [32][17/72]	Time  0.121 ( 0.648)	Data  0.000 ( 0.521)	Loss 1.3403e-01 (1.0669e-01) 
2023-05-25 22:41:55.472579: val Epoch: [32][18/72]	Time  1.094 ( 0.672)	Data  0.974 ( 0.545)	Loss 5.5070e-02 (1.0397e-01) 
2023-05-25 22:41:55.589736: val Epoch: [32][19/72]	Time  0.117 ( 0.644)	Data  0.000 ( 0.518)	Loss 4.1551e-02 (1.0085e-01) 
2023-05-25 22:41:56.740932: val Epoch: [32][20/72]	Time  1.151 ( 0.668)	Data  1.034 ( 0.543)	Loss 2.5733e-01 (1.0830e-01) 
2023-05-25 22:41:56.861703: val Epoch: [32][21/72]	Time  0.121 ( 0.643)	Data  0.000 ( 0.518)	Loss 3.7470e-01 (1.2041e-01) 
2023-05-25 22:41:58.033487: val Epoch: [32][22/72]	Time  1.172 ( 0.666)	Data  1.050 ( 0.541)	Loss 8.2114e-02 (1.1875e-01) 
2023-05-25 22:41:58.157750: val Epoch: [32][23/72]	Time  0.124 ( 0.644)	Data  0.001 ( 0.519)	Loss 5.7853e-02 (1.1621e-01) 
2023-05-25 22:41:59.293330: val Epoch: [32][24/72]	Time  1.136 ( 0.663)	Data  1.011 ( 0.538)	Loss 3.5630e-01 (1.2581e-01) 
2023-05-25 22:41:59.415029: val Epoch: [32][25/72]	Time  0.122 ( 0.643)	Data  0.001 ( 0.518)	Loss 5.3156e-02 (1.2302e-01) 
2023-05-25 22:42:00.528126: val Epoch: [32][26/72]	Time  1.113 ( 0.660)	Data  0.992 ( 0.535)	Loss 1.4043e-01 (1.2366e-01) 
2023-05-25 22:42:00.650175: val Epoch: [32][27/72]	Time  0.122 ( 0.641)	Data  0.001 ( 0.516)	Loss 7.0591e-02 (1.2177e-01) 
2023-05-25 22:42:01.779983: val Epoch: [32][28/72]	Time  1.130 ( 0.658)	Data  1.009 ( 0.533)	Loss 2.5346e-01 (1.2631e-01) 
2023-05-25 22:42:01.901560: val Epoch: [32][29/72]	Time  0.122 ( 0.640)	Data  0.001 ( 0.515)	Loss 4.6466e-01 (1.3759e-01) 
2023-05-25 22:42:03.031379: val Epoch: [32][30/72]	Time  1.130 ( 0.656)	Data  1.008 ( 0.531)	Loss 2.1911e-01 (1.4022e-01) 
2023-05-25 22:42:03.152647: val Epoch: [32][31/72]	Time  0.121 ( 0.639)	Data  0.001 ( 0.515)	Loss 1.0158e-01 (1.3901e-01) 
2023-05-25 22:42:04.275775: val Epoch: [32][32/72]	Time  1.123 ( 0.654)	Data  1.002 ( 0.529)	Loss 3.2837e-01 (1.4475e-01) 
2023-05-25 22:42:04.400487: val Epoch: [32][33/72]	Time  0.125 ( 0.638)	Data  0.001 ( 0.514)	Loss 6.0790e-02 (1.4228e-01) 
2023-05-25 22:42:05.474106: val Epoch: [32][34/72]	Time  1.074 ( 0.650)	Data  0.950 ( 0.526)	Loss 2.9240e-01 (1.4657e-01) 
2023-05-25 22:42:05.595505: val Epoch: [32][35/72]	Time  0.121 ( 0.636)	Data  0.001 ( 0.512)	Loss 2.3789e-01 (1.4910e-01) 
2023-05-25 22:42:06.698176: val Epoch: [32][36/72]	Time  1.103 ( 0.648)	Data  0.982 ( 0.524)	Loss 9.8140e-02 (1.4773e-01) 
2023-05-25 22:42:06.819361: val Epoch: [32][37/72]	Time  0.121 ( 0.635)	Data  0.000 ( 0.511)	Loss 5.0062e-02 (1.4516e-01) 
2023-05-25 22:42:07.908126: val Epoch: [32][38/72]	Time  1.089 ( 0.646)	Data  0.967 ( 0.522)	Loss 1.3150e-01 (1.4481e-01) 
2023-05-25 22:42:08.032538: val Epoch: [32][39/72]	Time  0.124 ( 0.633)	Data  0.001 ( 0.509)	Loss 8.0735e-02 (1.4320e-01) 
2023-05-25 22:42:09.135588: val Epoch: [32][40/72]	Time  1.103 ( 0.645)	Data  0.982 ( 0.521)	Loss 4.9826e-02 (1.4093e-01) 
2023-05-25 22:42:09.257721: val Epoch: [32][41/72]	Time  0.122 ( 0.632)	Data  0.001 ( 0.508)	Loss 7.1314e-02 (1.3927e-01) 
2023-05-25 22:42:10.324921: val Epoch: [32][42/72]	Time  1.067 ( 0.642)	Data  0.946 ( 0.519)	Loss 4.8636e-02 (1.3716e-01) 
2023-05-25 22:42:10.448889: val Epoch: [32][43/72]	Time  0.124 ( 0.630)	Data  0.001 ( 0.507)	Loss 4.4403e-02 (1.3505e-01) 
2023-05-25 22:42:11.571237: val Epoch: [32][44/72]	Time  1.122 ( 0.641)	Data  1.001 ( 0.518)	Loss 9.2954e-02 (1.3412e-01) 
2023-05-25 22:42:11.695183: val Epoch: [32][45/72]	Time  0.124 ( 0.630)	Data  0.000 ( 0.507)	Loss 5.9352e-02 (1.3249e-01) 
2023-05-25 22:42:12.798661: val Epoch: [32][46/72]	Time  1.103 ( 0.640)	Data  0.986 ( 0.517)	Loss 1.0253e-01 (1.3186e-01) 
2023-05-25 22:42:12.915800: val Epoch: [32][47/72]	Time  0.117 ( 0.629)	Data  0.000 ( 0.506)	Loss 3.7594e-01 (1.3694e-01) 
2023-05-25 22:42:14.004285: val Epoch: [32][48/72]	Time  1.088 ( 0.639)	Data  0.972 ( 0.515)	Loss 6.6205e-02 (1.3550e-01) 
2023-05-25 22:42:14.123163: val Epoch: [32][49/72]	Time  0.119 ( 0.628)	Data  0.000 ( 0.505)	Loss 9.8446e-02 (1.3476e-01) 
2023-05-25 22:42:15.216488: val Epoch: [32][50/72]	Time  1.093 ( 0.637)	Data  0.974 ( 0.514)	Loss 5.4231e-02 (1.3318e-01) 
2023-05-25 22:42:15.333074: val Epoch: [32][51/72]	Time  0.117 ( 0.627)	Data  0.001 ( 0.505)	Loss 1.0881e-01 (1.3271e-01) 
2023-05-25 22:42:16.412629: val Epoch: [32][52/72]	Time  1.080 ( 0.636)	Data  0.962 ( 0.513)	Loss 5.2396e-02 (1.3119e-01) 
2023-05-25 22:42:16.531769: val Epoch: [32][53/72]	Time  0.119 ( 0.626)	Data  0.001 ( 0.504)	Loss 4.0158e-01 (1.3620e-01) 
2023-05-25 22:42:17.614932: val Epoch: [32][54/72]	Time  1.083 ( 0.635)	Data  0.967 ( 0.512)	Loss 7.0857e-02 (1.3501e-01) 
2023-05-25 22:42:17.733710: val Epoch: [32][55/72]	Time  0.119 ( 0.625)	Data  0.001 ( 0.503)	Loss 3.6936e-02 (1.3326e-01) 
2023-05-25 22:42:18.853302: val Epoch: [32][56/72]	Time  1.120 ( 0.634)	Data  1.003 ( 0.512)	Loss 4.8250e-01 (1.3939e-01) 
2023-05-25 22:42:18.972433: val Epoch: [32][57/72]	Time  0.119 ( 0.625)	Data  0.000 ( 0.503)	Loss 4.4294e-01 (1.4462e-01) 
2023-05-25 22:42:20.113098: val Epoch: [32][58/72]	Time  1.141 ( 0.634)	Data  1.022 ( 0.512)	Loss 7.8674e-02 (1.4350e-01) 
2023-05-25 22:42:20.233830: val Epoch: [32][59/72]	Time  0.121 ( 0.625)	Data  0.001 ( 0.503)	Loss 1.1823e-01 (1.4308e-01) 
2023-05-25 22:42:21.319776: val Epoch: [32][60/72]	Time  1.086 ( 0.633)	Data  0.967 ( 0.511)	Loss 6.8377e-02 (1.4186e-01) 
2023-05-25 22:42:21.436174: val Epoch: [32][61/72]	Time  0.116 ( 0.625)	Data  0.000 ( 0.503)	Loss 7.4390e-02 (1.4077e-01) 
2023-05-25 22:42:22.566265: val Epoch: [32][62/72]	Time  1.130 ( 0.633)	Data  1.013 ( 0.511)	Loss 3.5486e-01 (1.4417e-01) 
2023-05-25 22:42:22.685245: val Epoch: [32][63/72]	Time  0.119 ( 0.625)	Data  0.000 ( 0.503)	Loss 1.0116e-01 (1.4350e-01) 
2023-05-25 22:42:23.777199: val Epoch: [32][64/72]	Time  1.092 ( 0.632)	Data  0.975 ( 0.510)	Loss 4.6305e-02 (1.4200e-01) 
2023-05-25 22:42:23.893639: val Epoch: [32][65/72]	Time  0.116 ( 0.624)	Data  0.000 ( 0.502)	Loss 1.1720e-01 (1.4162e-01) 
2023-05-25 22:42:24.955032: val Epoch: [32][66/72]	Time  1.061 ( 0.631)	Data  0.945 ( 0.509)	Loss 6.4259e-02 (1.4047e-01) 
2023-05-25 22:42:25.070946: val Epoch: [32][67/72]	Time  0.116 ( 0.623)	Data  0.000 ( 0.501)	Loss 1.6602e-01 (1.4085e-01) 
2023-05-25 22:42:26.181903: val Epoch: [32][68/72]	Time  1.111 ( 0.630)	Data  0.993 ( 0.508)	Loss 4.2851e-02 (1.3943e-01) 
2023-05-25 22:42:26.298609: val Epoch: [32][69/72]	Time  0.117 ( 0.623)	Data  0.000 ( 0.501)	Loss 6.3492e-02 (1.3834e-01) 
2023-05-25 22:42:27.315615: val Epoch: [32][70/72]	Time  1.017 ( 0.628)	Data  0.898 ( 0.507)	Loss 6.3432e-02 (1.3729e-01) 
2023-05-25 22:42:27.435003: val Epoch: [32][71/72]	Time  0.119 ( 0.621)	Data  0.000 ( 0.500)	Loss 9.6293e-02 (1.3672e-01) 
2023-05-25 22:42:27.633227: Epoch 32 :Val : ['ET : 0.7209702134132385', 'TC : 0.7691541314125061', 'WT : 0.8524999618530273'] 
2023-05-25 22:42:27.635880: Epoch 32 :Val : ['ET : 0.7209702134132385', 'TC : 0.7691541314125061', 'WT : 0.8524999618530273'] 
2023-05-25 22:42:27.637696: Val epoch done in 45.718074372001865 s 
2023-05-25 22:42:27.642918: Batches per epoch:  129 
2023-05-25 22:42:32.383181: train Epoch: [33][  0/129]	Time  4.740 ( 4.740)	Data  3.757 ( 3.757)	Loss 9.3998e-02 (9.3998e-02) 
2023-05-25 22:42:33.333029: train Epoch: [33][  1/129]	Time  0.950 ( 2.845)	Data  0.001 ( 1.879)	Loss 7.3422e-02 (8.3710e-02) 
2023-05-25 22:42:36.044645: train Epoch: [33][  2/129]	Time  2.712 ( 2.800)	Data  1.754 ( 1.837)	Loss 1.0489e-01 (9.0771e-02) 
2023-05-25 22:42:36.993469: train Epoch: [33][  3/129]	Time  0.949 ( 2.338)	Data  0.001 ( 1.378)	Loss 1.7417e-01 (1.1162e-01) 
2023-05-25 22:42:39.737851: train Epoch: [33][  4/129]	Time  2.744 ( 2.419)	Data  1.787 ( 1.460)	Loss 6.6144e-02 (1.0253e-01) 
2023-05-25 22:42:40.687875: train Epoch: [33][  5/129]	Time  0.950 ( 2.174)	Data  0.001 ( 1.217)	Loss 7.8422e-02 (9.8508e-02) 
2023-05-25 22:42:43.360300: train Epoch: [33][  6/129]	Time  2.672 ( 2.245)	Data  1.715 ( 1.288)	Loss 1.1501e-01 (1.0087e-01) 
2023-05-25 22:42:44.308851: train Epoch: [33][  7/129]	Time  0.949 ( 2.083)	Data  0.001 ( 1.127)	Loss 8.1891e-02 (9.8493e-02) 
2023-05-25 22:42:46.888880: train Epoch: [33][  8/129]	Time  2.580 ( 2.138)	Data  1.630 ( 1.183)	Loss 1.1167e-01 (9.9957e-02) 
2023-05-25 22:42:47.838520: train Epoch: [33][  9/129]	Time  0.950 ( 2.020)	Data  0.001 ( 1.065)	Loss 8.7434e-02 (9.8705e-02) 
2023-05-25 22:42:50.413939: train Epoch: [33][ 10/129]	Time  2.575 ( 2.070)	Data  1.616 ( 1.115)	Loss 8.1891e-02 (9.7176e-02) 
2023-05-25 22:42:51.375682: train Epoch: [33][ 11/129]	Time  0.962 ( 1.978)	Data  0.001 ( 1.022)	Loss 1.3229e-01 (1.0010e-01) 
2023-05-25 22:42:54.043825: train Epoch: [33][ 12/129]	Time  2.668 ( 2.031)	Data  1.709 ( 1.075)	Loss 1.0393e-01 (1.0040e-01) 
2023-05-25 22:42:54.993208: train Epoch: [33][ 13/129]	Time  0.949 ( 1.954)	Data  0.001 ( 0.998)	Loss 8.0023e-02 (9.8941e-02) 
2023-05-25 22:42:57.618648: train Epoch: [33][ 14/129]	Time  2.625 ( 1.998)	Data  1.672 ( 1.043)	Loss 7.0692e-02 (9.7058e-02) 
2023-05-25 22:42:58.567991: train Epoch: [33][ 15/129]	Time  0.949 ( 1.933)	Data  0.001 ( 0.978)	Loss 7.9651e-02 (9.5970e-02) 
2023-05-25 22:43:01.221493: train Epoch: [33][ 16/129]	Time  2.653 ( 1.975)	Data  1.707 ( 1.021)	Loss 1.3823e-01 (9.8456e-02) 
2023-05-25 22:43:02.172985: train Epoch: [33][ 17/129]	Time  0.951 ( 1.918)	Data  0.001 ( 0.964)	Loss 1.0005e-01 (9.8544e-02) 
2023-05-25 22:43:04.693885: train Epoch: [33][ 18/129]	Time  2.521 ( 1.950)	Data  1.565 ( 0.996)	Loss 5.4039e-02 (9.6202e-02) 
2023-05-25 22:43:05.653421: train Epoch: [33][ 19/129]	Time  0.960 ( 1.901)	Data  0.001 ( 0.946)	Loss 1.0650e-01 (9.6717e-02) 
2023-05-25 22:43:08.271605: train Epoch: [33][ 20/129]	Time  2.618 ( 1.935)	Data  1.660 ( 0.980)	Loss 1.0559e-01 (9.7139e-02) 
2023-05-25 22:43:09.231255: train Epoch: [33][ 21/129]	Time  0.960 ( 1.890)	Data  0.001 ( 0.936)	Loss 9.3214e-02 (9.6961e-02) 
2023-05-25 22:43:11.850379: train Epoch: [33][ 22/129]	Time  2.619 ( 1.922)	Data  1.661 ( 0.967)	Loss 8.0018e-02 (9.6224e-02) 
2023-05-25 22:43:12.809989: train Epoch: [33][ 23/129]	Time  0.960 ( 1.882)	Data  0.001 ( 0.927)	Loss 9.4181e-02 (9.6139e-02) 
2023-05-25 22:43:15.511203: train Epoch: [33][ 24/129]	Time  2.701 ( 1.915)	Data  1.737 ( 0.959)	Loss 6.0492e-02 (9.4713e-02) 
2023-05-25 22:43:16.470821: train Epoch: [33][ 25/129]	Time  0.960 ( 1.878)	Data  0.001 ( 0.922)	Loss 6.5168e-02 (9.3577e-02) 
2023-05-25 22:43:19.158652: train Epoch: [33][ 26/129]	Time  2.688 ( 1.908)	Data  1.723 ( 0.952)	Loss 5.3977e-02 (9.2110e-02) 
2023-05-25 22:43:20.118199: train Epoch: [33][ 27/129]	Time  0.960 ( 1.874)	Data  0.001 ( 0.918)	Loss 8.2341e-02 (9.1761e-02) 
2023-05-25 22:43:22.668114: train Epoch: [33][ 28/129]	Time  2.550 ( 1.897)	Data  1.593 ( 0.941)	Loss 6.2969e-02 (9.0768e-02) 
2023-05-25 22:43:23.616403: train Epoch: [33][ 29/129]	Time  0.948 ( 1.866)	Data  0.001 ( 0.910)	Loss 4.8970e-02 (8.9375e-02) 
2023-05-25 22:43:26.146122: train Epoch: [33][ 30/129]	Time  2.530 ( 1.887)	Data  1.572 ( 0.931)	Loss 6.3737e-02 (8.8548e-02) 
2023-05-25 22:43:27.096311: train Epoch: [33][ 31/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.902)	Loss 5.4336e-02 (8.7479e-02) 
2023-05-25 22:43:29.647888: train Epoch: [33][ 32/129]	Time  2.552 ( 1.879)	Data  1.596 ( 0.923)	Loss 3.6985e-02 (8.5949e-02) 
2023-05-25 22:43:30.595923: train Epoch: [33][ 33/129]	Time  0.948 ( 1.852)	Data  0.001 ( 0.896)	Loss 5.7445e-02 (8.5110e-02) 
2023-05-25 22:43:33.227161: train Epoch: [33][ 34/129]	Time  2.631 ( 1.874)	Data  1.684 ( 0.919)	Loss 9.8579e-02 (8.5495e-02) 
2023-05-25 22:43:34.175941: train Epoch: [33][ 35/129]	Time  0.949 ( 1.848)	Data  0.001 ( 0.893)	Loss 8.1485e-02 (8.5384e-02) 
2023-05-25 22:43:36.808546: train Epoch: [33][ 36/129]	Time  2.633 ( 1.869)	Data  1.684 ( 0.915)	Loss 5.8688e-02 (8.4662e-02) 
2023-05-25 22:43:37.758109: train Epoch: [33][ 37/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.891)	Loss 5.2873e-02 (8.3826e-02) 
2023-05-25 22:43:40.342947: train Epoch: [33][ 38/129]	Time  2.585 ( 1.864)	Data  1.626 ( 0.909)	Loss 7.8673e-02 (8.3694e-02) 
2023-05-25 22:43:41.293433: train Epoch: [33][ 39/129]	Time  0.950 ( 1.841)	Data  0.001 ( 0.887)	Loss 8.9823e-02 (8.3847e-02) 
2023-05-25 22:43:44.047464: train Epoch: [33][ 40/129]	Time  2.754 ( 1.864)	Data  1.803 ( 0.909)	Loss 1.6676e-01 (8.5869e-02) 
2023-05-25 22:43:44.996235: train Epoch: [33][ 41/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.887)	Loss 6.8063e-02 (8.5445e-02) 
2023-05-25 22:43:47.773384: train Epoch: [33][ 42/129]	Time  2.777 ( 1.863)	Data  1.819 ( 0.909)	Loss 6.1627e-02 (8.4891e-02) 
2023-05-25 22:43:48.724387: train Epoch: [33][ 43/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.888)	Loss 8.1707e-02 (8.4819e-02) 
2023-05-25 22:43:51.508426: train Epoch: [33][ 44/129]	Time  2.784 ( 1.864)	Data  1.840 ( 0.910)	Loss 5.8958e-02 (8.4244e-02) 
2023-05-25 22:43:52.456152: train Epoch: [33][ 45/129]	Time  0.948 ( 1.844)	Data  0.001 ( 0.890)	Loss 5.7102e-02 (8.3654e-02) 
2023-05-25 22:43:55.134367: train Epoch: [33][ 46/129]	Time  2.678 ( 1.862)	Data  1.731 ( 0.908)	Loss 5.8721e-02 (8.3124e-02) 
2023-05-25 22:43:56.082783: train Epoch: [33][ 47/129]	Time  0.948 ( 1.842)	Data  0.001 ( 0.889)	Loss 7.7077e-02 (8.2998e-02) 
2023-05-25 22:43:58.769217: train Epoch: [33][ 48/129]	Time  2.686 ( 1.860)	Data  1.724 ( 0.906)	Loss 5.9639e-02 (8.2521e-02) 
2023-05-25 22:43:59.718489: train Epoch: [33][ 49/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.888)	Loss 8.0947e-02 (8.2490e-02) 
2023-05-25 22:44:02.465635: train Epoch: [33][ 50/129]	Time  2.747 ( 1.859)	Data  1.784 ( 0.905)	Loss 1.7301e-01 (8.4265e-02) 
2023-05-25 22:44:03.414567: train Epoch: [33][ 51/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.888)	Loss 7.3184e-02 (8.4052e-02) 
2023-05-25 22:44:06.142466: train Epoch: [33][ 52/129]	Time  2.728 ( 1.858)	Data  1.783 ( 0.905)	Loss 6.0978e-02 (8.3616e-02) 
2023-05-25 22:44:07.090756: train Epoch: [33][ 53/129]	Time  0.948 ( 1.842)	Data  0.001 ( 0.888)	Loss 9.9798e-02 (8.3916e-02) 
2023-05-25 22:44:09.754294: train Epoch: [33][ 54/129]	Time  2.664 ( 1.857)	Data  1.717 ( 0.903)	Loss 8.7766e-02 (8.3986e-02) 
2023-05-25 22:44:10.702959: train Epoch: [33][ 55/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.887)	Loss 6.4038e-02 (8.3630e-02) 
2023-05-25 22:44:13.312700: train Epoch: [33][ 56/129]	Time  2.610 ( 1.854)	Data  1.663 ( 0.901)	Loss 2.0667e-01 (8.5788e-02) 
2023-05-25 22:44:14.261178: train Epoch: [33][ 57/129]	Time  0.948 ( 1.838)	Data  0.001 ( 0.885)	Loss 8.3286e-02 (8.5745e-02) 
2023-05-25 22:44:16.802883: train Epoch: [33][ 58/129]	Time  2.542 ( 1.850)	Data  1.594 ( 0.897)	Loss 5.0520e-02 (8.5148e-02) 
2023-05-25 22:44:17.751490: train Epoch: [33][ 59/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.882)	Loss 7.8428e-02 (8.5036e-02) 
2023-05-25 22:44:20.348787: train Epoch: [33][ 60/129]	Time  2.597 ( 1.848)	Data  1.653 ( 0.895)	Loss 5.0646e-02 (8.4472e-02) 
2023-05-25 22:44:21.297136: train Epoch: [33][ 61/129]	Time  0.948 ( 1.833)	Data  0.001 ( 0.880)	Loss 6.3620e-02 (8.4136e-02) 
2023-05-25 22:44:23.865974: train Epoch: [33][ 62/129]	Time  2.569 ( 1.845)	Data  1.624 ( 0.892)	Loss 9.7623e-02 (8.4350e-02) 
2023-05-25 22:44:24.814539: train Epoch: [33][ 63/129]	Time  0.949 ( 1.831)	Data  0.001 ( 0.878)	Loss 8.4550e-02 (8.4353e-02) 
2023-05-25 22:44:27.406597: train Epoch: [33][ 64/129]	Time  2.592 ( 1.843)	Data  1.646 ( 0.890)	Loss 5.6117e-02 (8.3919e-02) 
2023-05-25 22:44:28.355956: train Epoch: [33][ 65/129]	Time  0.949 ( 1.829)	Data  0.001 ( 0.877)	Loss 5.4541e-02 (8.3474e-02) 
2023-05-25 22:44:30.998793: train Epoch: [33][ 66/129]	Time  2.643 ( 1.841)	Data  1.697 ( 0.889)	Loss 8.3565e-02 (8.3475e-02) 
2023-05-25 22:44:31.945518: train Epoch: [33][ 67/129]	Time  0.947 ( 1.828)	Data  0.001 ( 0.876)	Loss 7.8823e-02 (8.3407e-02) 
2023-05-25 22:44:34.530338: train Epoch: [33][ 68/129]	Time  2.585 ( 1.839)	Data  1.640 ( 0.887)	Loss 1.0091e-01 (8.3660e-02) 
2023-05-25 22:44:35.477745: train Epoch: [33][ 69/129]	Time  0.947 ( 1.826)	Data  0.001 ( 0.874)	Loss 4.6697e-02 (8.3132e-02) 
2023-05-25 22:44:38.071462: train Epoch: [33][ 70/129]	Time  2.594 ( 1.837)	Data  1.648 ( 0.885)	Loss 6.7709e-02 (8.2915e-02) 
2023-05-25 22:44:39.019957: train Epoch: [33][ 71/129]	Time  0.948 ( 1.825)	Data  0.001 ( 0.873)	Loss 8.8697e-02 (8.2995e-02) 
2023-05-25 22:44:41.590034: train Epoch: [33][ 72/129]	Time  2.570 ( 1.835)	Data  1.625 ( 0.883)	Loss 7.4041e-02 (8.2873e-02) 
2023-05-25 22:44:42.538395: train Epoch: [33][ 73/129]	Time  0.948 ( 1.823)	Data  0.001 ( 0.871)	Loss 7.3446e-02 (8.2745e-02) 
2023-05-25 22:44:45.059191: train Epoch: [33][ 74/129]	Time  2.521 ( 1.832)	Data  1.574 ( 0.881)	Loss 7.3332e-02 (8.2620e-02) 
2023-05-25 22:44:46.008420: train Epoch: [33][ 75/129]	Time  0.949 ( 1.821)	Data  0.001 ( 0.869)	Loss 6.2673e-02 (8.2357e-02) 
2023-05-25 22:44:48.539936: train Epoch: [33][ 76/129]	Time  2.532 ( 1.830)	Data  1.586 ( 0.878)	Loss 6.3551e-02 (8.2113e-02) 
2023-05-25 22:44:49.488617: train Epoch: [33][ 77/129]	Time  0.949 ( 1.819)	Data  0.001 ( 0.867)	Loss 1.3315e-01 (8.2767e-02) 
2023-05-25 22:44:52.157455: train Epoch: [33][ 78/129]	Time  2.669 ( 1.829)	Data  1.724 ( 0.878)	Loss 1.1533e-01 (8.3179e-02) 
2023-05-25 22:44:53.106678: train Epoch: [33][ 79/129]	Time  0.949 ( 1.818)	Data  0.001 ( 0.867)	Loss 1.0363e-01 (8.3435e-02) 
2023-05-25 22:44:55.726678: train Epoch: [33][ 80/129]	Time  2.620 ( 1.828)	Data  1.666 ( 0.877)	Loss 8.8041e-02 (8.3492e-02) 
2023-05-25 22:44:56.683691: train Epoch: [33][ 81/129]	Time  0.957 ( 1.818)	Data  0.001 ( 0.866)	Loss 9.3069e-02 (8.3609e-02) 
2023-05-25 22:44:59.277272: train Epoch: [33][ 82/129]	Time  2.594 ( 1.827)	Data  1.639 ( 0.875)	Loss 1.0741e-01 (8.3895e-02) 
2023-05-25 22:45:00.233927: train Epoch: [33][ 83/129]	Time  0.957 ( 1.817)	Data  0.001 ( 0.865)	Loss 8.7022e-02 (8.3933e-02) 
2023-05-25 22:45:02.771754: train Epoch: [33][ 84/129]	Time  2.538 ( 1.825)	Data  1.582 ( 0.874)	Loss 7.3281e-02 (8.3807e-02) 
2023-05-25 22:45:03.731579: train Epoch: [33][ 85/129]	Time  0.960 ( 1.815)	Data  0.001 ( 0.863)	Loss 6.6195e-02 (8.3603e-02) 
2023-05-25 22:45:06.335414: train Epoch: [33][ 86/129]	Time  2.604 ( 1.824)	Data  1.650 ( 0.872)	Loss 9.1721e-02 (8.3696e-02) 
2023-05-25 22:45:07.293201: train Epoch: [33][ 87/129]	Time  0.958 ( 1.814)	Data  0.001 ( 0.862)	Loss 8.3858e-02 (8.3698e-02) 
2023-05-25 22:45:09.892067: train Epoch: [33][ 88/129]	Time  2.599 ( 1.823)	Data  1.644 ( 0.871)	Loss 1.0419e-01 (8.3928e-02) 
2023-05-25 22:45:10.849108: train Epoch: [33][ 89/129]	Time  0.957 ( 1.813)	Data  0.001 ( 0.862)	Loss 9.1151e-02 (8.4008e-02) 
2023-05-25 22:45:13.432336: train Epoch: [33][ 90/129]	Time  2.583 ( 1.822)	Data  1.627 ( 0.870)	Loss 7.1249e-02 (8.3868e-02) 
2023-05-25 22:45:14.391186: train Epoch: [33][ 91/129]	Time  0.959 ( 1.812)	Data  0.001 ( 0.861)	Loss 1.0309e-01 (8.4077e-02) 
2023-05-25 22:45:16.928665: train Epoch: [33][ 92/129]	Time  2.537 ( 1.820)	Data  1.585 ( 0.868)	Loss 6.9828e-02 (8.3924e-02) 
2023-05-25 22:45:17.888409: train Epoch: [33][ 93/129]	Time  0.960 ( 1.811)	Data  0.001 ( 0.859)	Loss 5.4476e-02 (8.3611e-02) 
2023-05-25 22:45:20.498154: train Epoch: [33][ 94/129]	Time  2.610 ( 1.820)	Data  1.655 ( 0.868)	Loss 1.1094e-01 (8.3898e-02) 
2023-05-25 22:45:21.455475: train Epoch: [33][ 95/129]	Time  0.957 ( 1.811)	Data  0.001 ( 0.858)	Loss 1.1830e-01 (8.4257e-02) 
2023-05-25 22:45:24.048638: train Epoch: [33][ 96/129]	Time  2.593 ( 1.819)	Data  1.640 ( 0.867)	Loss 5.8152e-02 (8.3987e-02) 
2023-05-25 22:45:25.007214: train Epoch: [33][ 97/129]	Time  0.959 ( 1.810)	Data  0.001 ( 0.858)	Loss 1.3667e-01 (8.4525e-02) 
2023-05-25 22:45:27.631167: train Epoch: [33][ 98/129]	Time  2.624 ( 1.818)	Data  1.671 ( 0.866)	Loss 1.1620e-01 (8.4845e-02) 
2023-05-25 22:45:28.589744: train Epoch: [33][ 99/129]	Time  0.959 ( 1.809)	Data  0.001 ( 0.857)	Loss 6.5035e-02 (8.4647e-02) 
2023-05-25 22:45:31.158168: train Epoch: [33][100/129]	Time  2.568 ( 1.817)	Data  1.615 ( 0.865)	Loss 1.1259e-01 (8.4923e-02) 
2023-05-25 22:45:32.117511: train Epoch: [33][101/129]	Time  0.959 ( 1.809)	Data  0.001 ( 0.856)	Loss 1.1182e-01 (8.5187e-02) 
2023-05-25 22:45:34.720468: train Epoch: [33][102/129]	Time  2.603 ( 1.816)	Data  1.649 ( 0.864)	Loss 9.5559e-02 (8.5288e-02) 
2023-05-25 22:45:35.678316: train Epoch: [33][103/129]	Time  0.958 ( 1.808)	Data  0.001 ( 0.856)	Loss 1.0110e-01 (8.5440e-02) 
2023-05-25 22:45:38.230653: train Epoch: [33][104/129]	Time  2.552 ( 1.815)	Data  1.597 ( 0.863)	Loss 8.9726e-02 (8.5481e-02) 
2023-05-25 22:45:39.190176: train Epoch: [33][105/129]	Time  0.960 ( 1.807)	Data  0.001 ( 0.855)	Loss 8.8403e-02 (8.5508e-02) 
2023-05-25 22:45:41.752750: train Epoch: [33][106/129]	Time  2.563 ( 1.814)	Data  1.605 ( 0.862)	Loss 5.7875e-02 (8.5250e-02) 
2023-05-25 22:45:42.712201: train Epoch: [33][107/129]	Time  0.959 ( 1.806)	Data  0.001 ( 0.854)	Loss 7.0769e-02 (8.5116e-02) 
2023-05-25 22:45:45.221285: train Epoch: [33][108/129]	Time  2.509 ( 1.813)	Data  1.553 ( 0.860)	Loss 7.1943e-02 (8.4995e-02) 
2023-05-25 22:45:46.182466: train Epoch: [33][109/129]	Time  0.961 ( 1.805)	Data  0.001 ( 0.852)	Loss 9.8062e-02 (8.5114e-02) 
2023-05-25 22:45:48.796885: train Epoch: [33][110/129]	Time  2.614 ( 1.812)	Data  1.661 ( 0.860)	Loss 1.2286e-01 (8.5454e-02) 
2023-05-25 22:45:49.756987: train Epoch: [33][111/129]	Time  0.960 ( 1.805)	Data  0.001 ( 0.852)	Loss 1.3568e-01 (8.5902e-02) 
2023-05-25 22:45:52.415325: train Epoch: [33][112/129]	Time  2.658 ( 1.812)	Data  1.703 ( 0.859)	Loss 7.6979e-02 (8.5823e-02) 
2023-05-25 22:45:53.372320: train Epoch: [33][113/129]	Time  0.957 ( 1.805)	Data  0.001 ( 0.852)	Loss 1.3840e-01 (8.6285e-02) 
2023-05-25 22:45:55.964887: train Epoch: [33][114/129]	Time  2.593 ( 1.811)	Data  1.639 ( 0.859)	Loss 7.8298e-02 (8.6215e-02) 
2023-05-25 22:45:56.923016: train Epoch: [33][115/129]	Time  0.958 ( 1.804)	Data  0.001 ( 0.851)	Loss 5.7459e-02 (8.5967e-02) 
2023-05-25 22:45:59.439051: train Epoch: [33][116/129]	Time  2.516 ( 1.810)	Data  1.562 ( 0.857)	Loss 5.7210e-02 (8.5722e-02) 
2023-05-25 22:46:00.397414: train Epoch: [33][117/129]	Time  0.958 ( 1.803)	Data  0.001 ( 0.850)	Loss 8.9627e-02 (8.5755e-02) 
2023-05-25 22:46:03.059536: train Epoch: [33][118/129]	Time  2.662 ( 1.810)	Data  1.707 ( 0.857)	Loss 5.2327e-02 (8.5474e-02) 
2023-05-25 22:46:04.017435: train Epoch: [33][119/129]	Time  0.958 ( 1.803)	Data  0.001 ( 0.850)	Loss 6.5543e-02 (8.5308e-02) 
2023-05-25 22:46:06.706407: train Epoch: [33][120/129]	Time  2.689 ( 1.810)	Data  1.735 ( 0.858)	Loss 1.0177e-01 (8.5444e-02) 
2023-05-25 22:46:07.664123: train Epoch: [33][121/129]	Time  0.958 ( 1.803)	Data  0.001 ( 0.851)	Loss 6.4211e-02 (8.5270e-02) 
2023-05-25 22:46:10.217198: train Epoch: [33][122/129]	Time  2.553 ( 1.810)	Data  1.599 ( 0.857)	Loss 6.9532e-02 (8.5142e-02) 
2023-05-25 22:46:11.175332: train Epoch: [33][123/129]	Time  0.958 ( 1.803)	Data  0.001 ( 0.850)	Loss 1.0565e-01 (8.5307e-02) 
2023-05-25 22:46:13.730765: train Epoch: [33][124/129]	Time  2.555 ( 1.809)	Data  1.601 ( 0.856)	Loss 9.6918e-02 (8.5400e-02) 
2023-05-25 22:46:14.689391: train Epoch: [33][125/129]	Time  0.959 ( 1.802)	Data  0.001 ( 0.849)	Loss 5.8700e-02 (8.5188e-02) 
2023-05-25 22:46:17.151646: train Epoch: [33][126/129]	Time  2.462 ( 1.807)	Data  1.517 ( 0.854)	Loss 6.7802e-02 (8.5051e-02) 
2023-05-25 22:46:18.098763: train Epoch: [33][127/129]	Time  0.947 ( 1.800)	Data  0.001 ( 0.848)	Loss 1.1041e-01 (8.5249e-02) 
2023-05-25 22:46:19.536961: train Epoch: [33][128/129]	Time  1.438 ( 1.798)	Data  0.494 ( 0.845)	Loss 2.0827e-01 (8.6203e-02) 
2023-05-25 22:46:19.568483: Train Epoch done in 231.9255903279991 s 
2023-05-25 22:46:21.880654: val Epoch: [33][ 0/72]	Time  1.614 ( 1.614)	Data  1.410 ( 1.410)	Loss 1.6734e-01 (1.6734e-01) 
2023-05-25 22:46:22.005837: val Epoch: [33][ 1/72]	Time  0.125 ( 0.870)	Data  0.001 ( 0.706)	Loss 4.2787e-02 (1.0506e-01) 
2023-05-25 22:46:23.024851: val Epoch: [33][ 2/72]	Time  1.019 ( 0.920)	Data  0.895 ( 0.769)	Loss 1.4764e-01 (1.1926e-01) 
2023-05-25 22:46:23.149690: val Epoch: [33][ 3/72]	Time  0.125 ( 0.721)	Data  0.001 ( 0.577)	Loss 1.0063e-01 (1.1460e-01) 
2023-05-25 22:46:24.279301: val Epoch: [33][ 4/72]	Time  1.130 ( 0.803)	Data  1.005 ( 0.662)	Loss 3.6168e-01 (1.6402e-01) 
2023-05-25 22:46:24.404927: val Epoch: [33][ 5/72]	Time  0.126 ( 0.690)	Data  0.001 ( 0.552)	Loss 6.4825e-02 (1.4748e-01) 
2023-05-25 22:46:25.534222: val Epoch: [33][ 6/72]	Time  1.129 ( 0.753)	Data  1.009 ( 0.617)	Loss 3.2972e-01 (1.7352e-01) 
2023-05-25 22:46:25.658283: val Epoch: [33][ 7/72]	Time  0.124 ( 0.674)	Data  0.001 ( 0.540)	Loss 4.2541e-02 (1.5715e-01) 
2023-05-25 22:46:26.780972: val Epoch: [33][ 8/72]	Time  1.123 ( 0.724)	Data  0.999 ( 0.591)	Loss 2.5090e-01 (1.6756e-01) 
2023-05-25 22:46:26.905293: val Epoch: [33][ 9/72]	Time  0.124 ( 0.664)	Data  0.001 ( 0.532)	Loss 1.8052e-01 (1.6886e-01) 
2023-05-25 22:46:27.982585: val Epoch: [33][10/72]	Time  1.077 ( 0.701)	Data  0.958 ( 0.571)	Loss 4.6642e-02 (1.5775e-01) 
2023-05-25 22:46:28.102062: val Epoch: [33][11/72]	Time  0.119 ( 0.653)	Data  0.000 ( 0.523)	Loss 3.8648e-01 (1.7681e-01) 
2023-05-25 22:46:29.178365: val Epoch: [33][12/72]	Time  1.076 ( 0.686)	Data  0.956 ( 0.557)	Loss 6.0143e-02 (1.6783e-01) 
2023-05-25 22:46:29.294374: val Epoch: [33][13/72]	Time  0.116 ( 0.645)	Data  0.000 ( 0.517)	Loss 5.2790e-02 (1.5962e-01) 
2023-05-25 22:46:30.419189: val Epoch: [33][14/72]	Time  1.125 ( 0.677)	Data  1.008 ( 0.550)	Loss 1.5115e-01 (1.5905e-01) 
2023-05-25 22:46:30.538537: val Epoch: [33][15/72]	Time  0.119 ( 0.642)	Data  0.001 ( 0.515)	Loss 8.5112e-02 (1.5443e-01) 
2023-05-25 22:46:31.619974: val Epoch: [33][16/72]	Time  1.081 ( 0.668)	Data  0.965 ( 0.542)	Loss 6.8702e-02 (1.4939e-01) 
2023-05-25 22:46:31.739455: val Epoch: [33][17/72]	Time  0.119 ( 0.637)	Data  0.000 ( 0.512)	Loss 3.9665e-02 (1.4329e-01) 
2023-05-25 22:46:32.851035: val Epoch: [33][18/72]	Time  1.112 ( 0.662)	Data  0.994 ( 0.537)	Loss 9.9572e-02 (1.4099e-01) 
2023-05-25 22:46:32.969870: val Epoch: [33][19/72]	Time  0.119 ( 0.635)	Data  0.000 ( 0.510)	Loss 5.8197e-02 (1.3685e-01) 
2023-05-25 22:46:34.096795: val Epoch: [33][20/72]	Time  1.127 ( 0.659)	Data  1.010 ( 0.534)	Loss 1.3658e-01 (1.3684e-01) 
2023-05-25 22:46:34.215742: val Epoch: [33][21/72]	Time  0.119 ( 0.634)	Data  0.000 ( 0.510)	Loss 7.1878e-02 (1.3389e-01) 
2023-05-25 22:46:35.314342: val Epoch: [33][22/72]	Time  1.099 ( 0.654)	Data  0.980 ( 0.530)	Loss 1.1902e-01 (1.3324e-01) 
2023-05-25 22:46:35.431116: val Epoch: [33][23/72]	Time  0.117 ( 0.632)	Data  0.000 ( 0.508)	Loss 7.2649e-02 (1.3072e-01) 
2023-05-25 22:46:36.524569: val Epoch: [33][24/72]	Time  1.093 ( 0.650)	Data  0.977 ( 0.527)	Loss 9.4917e-02 (1.2928e-01) 
2023-05-25 22:46:36.643616: val Epoch: [33][25/72]	Time  0.119 ( 0.630)	Data  0.000 ( 0.507)	Loss 5.0163e-02 (1.2624e-01) 
2023-05-25 22:46:37.725231: val Epoch: [33][26/72]	Time  1.082 ( 0.647)	Data  0.964 ( 0.524)	Loss 5.8705e-02 (1.2374e-01) 
2023-05-25 22:46:37.844016: val Epoch: [33][27/72]	Time  0.119 ( 0.628)	Data  0.000 ( 0.505)	Loss 8.1060e-02 (1.2221e-01) 
2023-05-25 22:46:38.992301: val Epoch: [33][28/72]	Time  1.148 ( 0.646)	Data  1.027 ( 0.523)	Loss 5.4185e-02 (1.1987e-01) 
2023-05-25 22:46:39.112877: val Epoch: [33][29/72]	Time  0.121 ( 0.628)	Data  0.000 ( 0.505)	Loss 1.0478e-01 (1.1937e-01) 
2023-05-25 22:46:40.205148: val Epoch: [33][30/72]	Time  1.092 ( 0.643)	Data  0.971 ( 0.520)	Loss 2.7963e-01 (1.2454e-01) 
2023-05-25 22:46:40.329730: val Epoch: [33][31/72]	Time  0.125 ( 0.627)	Data  0.000 ( 0.504)	Loss 8.2327e-02 (1.2322e-01) 
2023-05-25 22:46:41.455689: val Epoch: [33][32/72]	Time  1.126 ( 0.642)	Data  1.005 ( 0.519)	Loss 7.9074e-02 (1.2188e-01) 
2023-05-25 22:46:41.580413: val Epoch: [33][33/72]	Time  0.125 ( 0.627)	Data  0.001 ( 0.504)	Loss 5.8471e-02 (1.2001e-01) 
2023-05-25 22:46:42.655197: val Epoch: [33][34/72]	Time  1.075 ( 0.640)	Data  0.953 ( 0.517)	Loss 7.2276e-02 (1.1865e-01) 
2023-05-25 22:46:42.776891: val Epoch: [33][35/72]	Time  0.122 ( 0.625)	Data  0.000 ( 0.503)	Loss 1.3142e-01 (1.1901e-01) 
2023-05-25 22:46:43.833103: val Epoch: [33][36/72]	Time  1.056 ( 0.637)	Data  0.936 ( 0.514)	Loss 2.0535e-01 (1.2134e-01) 
2023-05-25 22:46:43.950286: val Epoch: [33][37/72]	Time  0.117 ( 0.623)	Data  0.000 ( 0.501)	Loss 4.4385e-01 (1.2983e-01) 
2023-05-25 22:46:45.070335: val Epoch: [33][38/72]	Time  1.120 ( 0.636)	Data  1.001 ( 0.514)	Loss 4.4072e-02 (1.2763e-01) 
2023-05-25 22:46:45.189116: val Epoch: [33][39/72]	Time  0.119 ( 0.623)	Data  0.000 ( 0.501)	Loss 3.4585e-02 (1.2530e-01) 
2023-05-25 22:46:46.256175: val Epoch: [33][40/72]	Time  1.067 ( 0.634)	Data  0.950 ( 0.512)	Loss 1.4014e-01 (1.2566e-01) 
2023-05-25 22:46:46.372868: val Epoch: [33][41/72]	Time  0.117 ( 0.622)	Data  0.000 ( 0.500)	Loss 1.0697e-01 (1.2522e-01) 
2023-05-25 22:46:47.514465: val Epoch: [33][42/72]	Time  1.142 ( 0.634)	Data  1.024 ( 0.512)	Loss 1.7187e-01 (1.2630e-01) 
2023-05-25 22:46:47.632375: val Epoch: [33][43/72]	Time  0.118 ( 0.622)	Data  0.000 ( 0.500)	Loss 1.2769e-01 (1.2633e-01) 
2023-05-25 22:46:48.746756: val Epoch: [33][44/72]	Time  1.114 ( 0.633)	Data  0.994 ( 0.511)	Loss 9.1193e-02 (1.2555e-01) 
2023-05-25 22:46:48.865519: val Epoch: [33][45/72]	Time  0.119 ( 0.622)	Data  0.000 ( 0.500)	Loss 4.9258e-02 (1.2389e-01) 
2023-05-25 22:46:50.005519: val Epoch: [33][46/72]	Time  1.140 ( 0.633)	Data  1.014 ( 0.511)	Loss 4.1376e-01 (1.3006e-01) 
2023-05-25 22:46:50.128952: val Epoch: [33][47/72]	Time  0.123 ( 0.622)	Data  0.001 ( 0.500)	Loss 4.5710e-01 (1.3688e-01) 
2023-05-25 22:46:51.252288: val Epoch: [33][48/72]	Time  1.123 ( 0.632)	Data  1.006 ( 0.511)	Loss 1.0461e-01 (1.3622e-01) 
2023-05-25 22:46:51.371568: val Epoch: [33][49/72]	Time  0.119 ( 0.622)	Data  0.000 ( 0.500)	Loss 1.0402e-01 (1.3557e-01) 
2023-05-25 22:46:52.459000: val Epoch: [33][50/72]	Time  1.087 ( 0.631)	Data  0.971 ( 0.510)	Loss 5.6059e-02 (1.3401e-01) 
2023-05-25 22:46:52.578493: val Epoch: [33][51/72]	Time  0.119 ( 0.621)	Data  0.000 ( 0.500)	Loss 5.3321e-02 (1.3246e-01) 
2023-05-25 22:46:53.676972: val Epoch: [33][52/72]	Time  1.098 ( 0.630)	Data  0.982 ( 0.509)	Loss 4.2710e-02 (1.3077e-01) 
2023-05-25 22:46:53.795781: val Epoch: [33][53/72]	Time  0.119 ( 0.621)	Data  0.000 ( 0.500)	Loss 6.1511e-02 (1.2949e-01) 
2023-05-25 22:46:54.886117: val Epoch: [33][54/72]	Time  1.090 ( 0.629)	Data  0.974 ( 0.508)	Loss 1.2172e-01 (1.2934e-01) 
2023-05-25 22:46:55.003031: val Epoch: [33][55/72]	Time  0.117 ( 0.620)	Data  0.000 ( 0.499)	Loss 7.4315e-02 (1.2836e-01) 
2023-05-25 22:46:56.049919: val Epoch: [33][56/72]	Time  1.047 ( 0.628)	Data  0.930 ( 0.507)	Loss 4.1521e-02 (1.2684e-01) 
2023-05-25 22:46:56.166326: val Epoch: [33][57/72]	Time  0.116 ( 0.619)	Data  0.000 ( 0.498)	Loss 1.0571e-01 (1.2647e-01) 
2023-05-25 22:46:57.252192: val Epoch: [33][58/72]	Time  1.086 ( 0.627)	Data  0.969 ( 0.506)	Loss 1.5521e-01 (1.2696e-01) 
2023-05-25 22:46:57.372435: val Epoch: [33][59/72]	Time  0.120 ( 0.618)	Data  0.000 ( 0.497)	Loss 2.0243e-01 (1.2822e-01) 
2023-05-25 22:46:58.490566: val Epoch: [33][60/72]	Time  1.118 ( 0.627)	Data  1.001 ( 0.506)	Loss 3.4038e-01 (1.3170e-01) 
2023-05-25 22:46:58.606962: val Epoch: [33][61/72]	Time  0.116 ( 0.618)	Data  0.000 ( 0.498)	Loss 5.0284e-02 (1.3038e-01) 
2023-05-25 22:46:59.689432: val Epoch: [33][62/72]	Time  1.082 ( 0.626)	Data  0.966 ( 0.505)	Loss 1.0302e-01 (1.2995e-01) 
2023-05-25 22:46:59.805656: val Epoch: [33][63/72]	Time  0.116 ( 0.618)	Data  0.000 ( 0.497)	Loss 1.3794e-01 (1.3007e-01) 
2023-05-25 22:47:00.914443: val Epoch: [33][64/72]	Time  1.109 ( 0.625)	Data  0.992 ( 0.505)	Loss 4.4203e-02 (1.2875e-01) 
2023-05-25 22:47:01.034538: val Epoch: [33][65/72]	Time  0.120 ( 0.618)	Data  0.000 ( 0.497)	Loss 6.4206e-02 (1.2778e-01) 
2023-05-25 22:47:02.189113: val Epoch: [33][66/72]	Time  1.155 ( 0.626)	Data  1.035 ( 0.505)	Loss 7.9298e-02 (1.2705e-01) 
2023-05-25 22:47:02.308357: val Epoch: [33][67/72]	Time  0.119 ( 0.618)	Data  0.000 ( 0.498)	Loss 3.8238e-01 (1.3081e-01) 
2023-05-25 22:47:03.384626: val Epoch: [33][68/72]	Time  1.076 ( 0.625)	Data  0.957 ( 0.504)	Loss 6.4527e-02 (1.2985e-01) 
2023-05-25 22:47:03.500753: val Epoch: [33][69/72]	Time  0.116 ( 0.618)	Data  0.000 ( 0.497)	Loss 3.3518e-01 (1.3278e-01) 
2023-05-25 22:47:04.553481: val Epoch: [33][70/72]	Time  1.053 ( 0.624)	Data  0.936 ( 0.503)	Loss 5.7449e-02 (1.3172e-01) 
2023-05-25 22:47:04.671867: val Epoch: [33][71/72]	Time  0.118 ( 0.617)	Data  0.000 ( 0.496)	Loss 5.7681e-02 (1.3069e-01) 
2023-05-25 22:47:04.837823: Epoch 33 :Val : ['ET : 0.7254099249839783', 'TC : 0.7783334255218506', 'WT : 0.8625228404998779'] 
2023-05-25 22:47:04.840619: Epoch 33 :Val : ['ET : 0.7254099249839783', 'TC : 0.7783334255218506', 'WT : 0.8625228404998779'] 
2023-05-25 22:47:04.842814: Saving the model with DSC 0.7943884134292603 
2023-05-25 22:47:05.565081: Val epoch done in 45.996589005000715 s 
2023-05-25 22:47:05.570499: Batches per epoch:  129 
2023-05-25 22:47:10.353665: train Epoch: [34][  0/129]	Time  4.783 ( 4.783)	Data  3.776 ( 3.776)	Loss 9.3082e-02 (9.3082e-02) 
2023-05-25 22:47:11.303484: train Epoch: [34][  1/129]	Time  0.950 ( 2.866)	Data  0.001 ( 1.888)	Loss 8.5047e-02 (8.9065e-02) 
2023-05-25 22:47:13.779672: train Epoch: [34][  2/129]	Time  2.476 ( 2.736)	Data  1.528 ( 1.768)	Loss 4.7707e-02 (7.5279e-02) 
2023-05-25 22:47:14.729220: train Epoch: [34][  3/129]	Time  0.950 ( 2.290)	Data  0.001 ( 1.326)	Loss 7.0513e-02 (7.4087e-02) 
2023-05-25 22:47:17.392456: train Epoch: [34][  4/129]	Time  2.663 ( 2.364)	Data  1.708 ( 1.403)	Loss 1.6328e-01 (9.1925e-02) 
2023-05-25 22:47:18.342108: train Epoch: [34][  5/129]	Time  0.950 ( 2.129)	Data  0.001 ( 1.169)	Loss 1.2413e-01 (9.7292e-02) 
2023-05-25 22:47:21.117760: train Epoch: [34][  6/129]	Time  2.776 ( 2.221)	Data  1.827 ( 1.263)	Loss 8.1789e-02 (9.5077e-02) 
2023-05-25 22:47:22.068353: train Epoch: [34][  7/129]	Time  0.951 ( 2.062)	Data  0.001 ( 1.105)	Loss 5.5631e-02 (9.0146e-02) 
2023-05-25 22:47:24.809556: train Epoch: [34][  8/129]	Time  2.741 ( 2.138)	Data  1.783 ( 1.180)	Loss 8.4223e-02 (8.9488e-02) 
2023-05-25 22:47:25.760330: train Epoch: [34][  9/129]	Time  0.951 ( 2.019)	Data  0.001 ( 1.063)	Loss 7.0978e-02 (8.7637e-02) 
2023-05-25 22:47:28.654857: train Epoch: [34][ 10/129]	Time  2.895 ( 2.099)	Data  1.947 ( 1.143)	Loss 9.4757e-02 (8.8284e-02) 
2023-05-25 22:47:29.603630: train Epoch: [34][ 11/129]	Time  0.949 ( 2.003)	Data  0.001 ( 1.048)	Loss 5.7692e-02 (8.5735e-02) 
2023-05-25 22:47:32.339643: train Epoch: [34][ 12/129]	Time  2.736 ( 2.059)	Data  1.785 ( 1.104)	Loss 8.6860e-02 (8.5822e-02) 
2023-05-25 22:47:33.291088: train Epoch: [34][ 13/129]	Time  0.951 ( 1.980)	Data  0.001 ( 1.026)	Loss 7.9035e-02 (8.5337e-02) 
2023-05-25 22:47:36.068323: train Epoch: [34][ 14/129]	Time  2.777 ( 2.033)	Data  1.826 ( 1.079)	Loss 5.4230e-02 (8.3263e-02) 
2023-05-25 22:47:37.018203: train Epoch: [34][ 15/129]	Time  0.950 ( 1.965)	Data  0.001 ( 1.012)	Loss 6.0632e-02 (8.1849e-02) 
2023-05-25 22:47:39.832524: train Epoch: [34][ 16/129]	Time  2.814 ( 2.015)	Data  1.868 ( 1.062)	Loss 5.6286e-02 (8.0345e-02) 
2023-05-25 22:47:40.781934: train Epoch: [34][ 17/129]	Time  0.949 ( 1.956)	Data  0.001 ( 1.003)	Loss 7.1191e-02 (7.9836e-02) 
2023-05-25 22:47:43.462614: train Epoch: [34][ 18/129]	Time  2.681 ( 1.994)	Data  1.737 ( 1.042)	Loss 8.1177e-02 (7.9907e-02) 
2023-05-25 22:47:44.410483: train Epoch: [34][ 19/129]	Time  0.948 ( 1.942)	Data  0.001 ( 0.990)	Loss 1.1005e-01 (8.1414e-02) 
2023-05-25 22:47:47.103433: train Epoch: [34][ 20/129]	Time  2.693 ( 1.978)	Data  1.747 ( 1.026)	Loss 7.4800e-02 (8.1099e-02) 
2023-05-25 22:47:48.050337: train Epoch: [34][ 21/129]	Time  0.947 ( 1.931)	Data  0.001 ( 0.979)	Loss 6.9538e-02 (8.0574e-02) 
2023-05-25 22:47:50.589073: train Epoch: [34][ 22/129]	Time  2.539 ( 1.957)	Data  1.593 ( 1.006)	Loss 9.3777e-02 (8.1148e-02) 
2023-05-25 22:47:51.538202: train Epoch: [34][ 23/129]	Time  0.949 ( 1.915)	Data  0.001 ( 0.964)	Loss 1.0597e-01 (8.2182e-02) 
2023-05-25 22:47:54.174617: train Epoch: [34][ 24/129]	Time  2.636 ( 1.944)	Data  1.690 ( 0.993)	Loss 9.9493e-02 (8.2874e-02) 
2023-05-25 22:47:55.124801: train Epoch: [34][ 25/129]	Time  0.950 ( 1.906)	Data  0.001 ( 0.955)	Loss 5.1628e-02 (8.1673e-02) 
2023-05-25 22:47:57.784297: train Epoch: [34][ 26/129]	Time  2.659 ( 1.934)	Data  1.715 ( 0.983)	Loss 5.4695e-02 (8.0673e-02) 
2023-05-25 22:47:58.740649: train Epoch: [34][ 27/129]	Time  0.956 ( 1.899)	Data  0.001 ( 0.948)	Loss 8.0274e-02 (8.0659e-02) 
2023-05-25 22:48:01.436322: train Epoch: [34][ 28/129]	Time  2.696 ( 1.926)	Data  1.749 ( 0.976)	Loss 7.8538e-02 (8.0586e-02) 
2023-05-25 22:48:02.386384: train Epoch: [34][ 29/129]	Time  0.950 ( 1.894)	Data  0.001 ( 0.943)	Loss 8.3921e-02 (8.0697e-02) 
2023-05-25 22:48:05.031482: train Epoch: [34][ 30/129]	Time  2.645 ( 1.918)	Data  1.689 ( 0.967)	Loss 7.6526e-02 (8.0563e-02) 
2023-05-25 22:48:05.990348: train Epoch: [34][ 31/129]	Time  0.959 ( 1.888)	Data  0.001 ( 0.937)	Loss 5.9586e-02 (7.9907e-02) 
2023-05-25 22:48:08.630022: train Epoch: [34][ 32/129]	Time  2.640 ( 1.911)	Data  1.684 ( 0.960)	Loss 7.2852e-02 (7.9693e-02) 
2023-05-25 22:48:09.590514: train Epoch: [34][ 33/129]	Time  0.960 ( 1.883)	Data  0.001 ( 0.931)	Loss 1.3110e-01 (8.1205e-02) 
2023-05-25 22:48:12.309436: train Epoch: [34][ 34/129]	Time  2.719 ( 1.907)	Data  1.772 ( 0.955)	Loss 1.0635e-01 (8.1924e-02) 
2023-05-25 22:48:13.259187: train Epoch: [34][ 35/129]	Time  0.950 ( 1.880)	Data  0.001 ( 0.929)	Loss 1.5983e-01 (8.4088e-02) 
2023-05-25 22:48:15.957957: train Epoch: [34][ 36/129]	Time  2.699 ( 1.902)	Data  1.750 ( 0.951)	Loss 8.2874e-02 (8.4055e-02) 
2023-05-25 22:48:16.907599: train Epoch: [34][ 37/129]	Time  0.950 ( 1.877)	Data  0.001 ( 0.926)	Loss 7.2355e-02 (8.3747e-02) 
2023-05-25 22:48:19.612367: train Epoch: [34][ 38/129]	Time  2.705 ( 1.898)	Data  1.758 ( 0.947)	Loss 6.7209e-02 (8.3323e-02) 
2023-05-25 22:48:20.560873: train Epoch: [34][ 39/129]	Time  0.949 ( 1.875)	Data  0.001 ( 0.924)	Loss 6.7520e-02 (8.2928e-02) 
2023-05-25 22:48:23.242828: train Epoch: [34][ 40/129]	Time  2.682 ( 1.894)	Data  1.735 ( 0.943)	Loss 6.9643e-02 (8.2604e-02) 
2023-05-25 22:48:24.190963: train Epoch: [34][ 41/129]	Time  0.948 ( 1.872)	Data  0.001 ( 0.921)	Loss 5.2975e-02 (8.1898e-02) 
2023-05-25 22:48:26.759180: train Epoch: [34][ 42/129]	Time  2.568 ( 1.888)	Data  1.622 ( 0.937)	Loss 1.2615e-01 (8.2928e-02) 
2023-05-25 22:48:27.708308: train Epoch: [34][ 43/129]	Time  0.949 ( 1.867)	Data  0.001 ( 0.916)	Loss 8.9478e-02 (8.3076e-02) 
2023-05-25 22:48:30.448172: train Epoch: [34][ 44/129]	Time  2.740 ( 1.886)	Data  1.791 ( 0.936)	Loss 8.4095e-02 (8.3099e-02) 
2023-05-25 22:48:31.395102: train Epoch: [34][ 45/129]	Time  0.947 ( 1.866)	Data  0.001 ( 0.915)	Loss 8.6224e-02 (8.3167e-02) 
2023-05-25 22:48:33.965252: train Epoch: [34][ 46/129]	Time  2.570 ( 1.881)	Data  1.622 ( 0.930)	Loss 5.6908e-02 (8.2608e-02) 
2023-05-25 22:48:34.911736: train Epoch: [34][ 47/129]	Time  0.946 ( 1.861)	Data  0.001 ( 0.911)	Loss 7.0298e-02 (8.2352e-02) 
2023-05-25 22:48:37.694499: train Epoch: [34][ 48/129]	Time  2.783 ( 1.880)	Data  1.834 ( 0.930)	Loss 9.2725e-02 (8.2564e-02) 
2023-05-25 22:48:38.644204: train Epoch: [34][ 49/129]	Time  0.950 ( 1.861)	Data  0.001 ( 0.911)	Loss 5.4837e-02 (8.2009e-02) 
2023-05-25 22:48:41.253628: train Epoch: [34][ 50/129]	Time  2.609 ( 1.876)	Data  1.660 ( 0.926)	Loss 8.9727e-02 (8.2160e-02) 
2023-05-25 22:48:42.203105: train Epoch: [34][ 51/129]	Time  0.949 ( 1.858)	Data  0.001 ( 0.908)	Loss 7.3995e-02 (8.2003e-02) 
2023-05-25 22:48:44.837541: train Epoch: [34][ 52/129]	Time  2.634 ( 1.873)	Data  1.686 ( 0.923)	Loss 7.1272e-02 (8.1801e-02) 
2023-05-25 22:48:45.786766: train Epoch: [34][ 53/129]	Time  0.949 ( 1.856)	Data  0.001 ( 0.906)	Loss 6.9916e-02 (8.1581e-02) 
2023-05-25 22:48:48.491342: train Epoch: [34][ 54/129]	Time  2.705 ( 1.871)	Data  1.757 ( 0.921)	Loss 8.7209e-02 (8.1683e-02) 
2023-05-25 22:48:49.441377: train Epoch: [34][ 55/129]	Time  0.950 ( 1.855)	Data  0.001 ( 0.905)	Loss 8.2035e-02 (8.1689e-02) 
2023-05-25 22:48:52.115600: train Epoch: [34][ 56/129]	Time  2.674 ( 1.869)	Data  1.728 ( 0.919)	Loss 1.3040e-01 (8.2544e-02) 
2023-05-25 22:48:53.064473: train Epoch: [34][ 57/129]	Time  0.949 ( 1.853)	Data  0.001 ( 0.903)	Loss 7.8071e-02 (8.2467e-02) 
2023-05-25 22:48:55.640001: train Epoch: [34][ 58/129]	Time  2.576 ( 1.866)	Data  1.629 ( 0.916)	Loss 4.9779e-02 (8.1913e-02) 
2023-05-25 22:48:56.589217: train Epoch: [34][ 59/129]	Time  0.949 ( 1.850)	Data  0.001 ( 0.900)	Loss 1.2465e-01 (8.2625e-02) 
2023-05-25 22:48:59.229496: train Epoch: [34][ 60/129]	Time  2.640 ( 1.863)	Data  1.693 ( 0.913)	Loss 4.8999e-02 (8.2074e-02) 
2023-05-25 22:49:00.178352: train Epoch: [34][ 61/129]	Time  0.949 ( 1.849)	Data  0.001 ( 0.899)	Loss 6.4330e-02 (8.1788e-02) 
2023-05-25 22:49:02.794719: train Epoch: [34][ 62/129]	Time  2.616 ( 1.861)	Data  1.669 ( 0.911)	Loss 8.1388e-02 (8.1781e-02) 
2023-05-25 22:49:03.744525: train Epoch: [34][ 63/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.897)	Loss 8.8888e-02 (8.1892e-02) 
2023-05-25 22:49:06.361965: train Epoch: [34][ 64/129]	Time  2.617 ( 1.858)	Data  1.669 ( 0.908)	Loss 7.1221e-02 (8.1728e-02) 
2023-05-25 22:49:07.309957: train Epoch: [34][ 65/129]	Time  0.948 ( 1.845)	Data  0.001 ( 0.895)	Loss 7.7174e-02 (8.1659e-02) 
2023-05-25 22:49:10.023420: train Epoch: [34][ 66/129]	Time  2.713 ( 1.857)	Data  1.765 ( 0.908)	Loss 3.3630e-02 (8.0942e-02) 
2023-05-25 22:49:10.974373: train Epoch: [34][ 67/129]	Time  0.951 ( 1.844)	Data  0.001 ( 0.894)	Loss 1.1198e-01 (8.1399e-02) 
2023-05-25 22:49:13.602405: train Epoch: [34][ 68/129]	Time  2.628 ( 1.856)	Data  1.681 ( 0.906)	Loss 9.5596e-02 (8.1604e-02) 
2023-05-25 22:49:14.550449: train Epoch: [34][ 69/129]	Time  0.948 ( 1.843)	Data  0.001 ( 0.893)	Loss 7.8791e-02 (8.1564e-02) 
2023-05-25 22:49:17.182321: train Epoch: [34][ 70/129]	Time  2.632 ( 1.854)	Data  1.683 ( 0.904)	Loss 8.8577e-02 (8.1663e-02) 
2023-05-25 22:49:18.132248: train Epoch: [34][ 71/129]	Time  0.950 ( 1.841)	Data  0.001 ( 0.891)	Loss 8.7102e-02 (8.1739e-02) 
2023-05-25 22:49:20.940268: train Epoch: [34][ 72/129]	Time  2.808 ( 1.854)	Data  1.862 ( 0.905)	Loss 7.0283e-02 (8.1582e-02) 
2023-05-25 22:49:21.890194: train Epoch: [34][ 73/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.893)	Loss 9.1282e-02 (8.1713e-02) 
2023-05-25 22:49:24.634274: train Epoch: [34][ 74/129]	Time  2.744 ( 1.854)	Data  1.798 ( 0.905)	Loss 6.2139e-02 (8.1452e-02) 
2023-05-25 22:49:25.584418: train Epoch: [34][ 75/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.893)	Loss 7.2009e-02 (8.1328e-02) 
2023-05-25 22:49:28.231513: train Epoch: [34][ 76/129]	Time  2.647 ( 1.853)	Data  1.693 ( 0.903)	Loss 5.4445e-02 (8.0978e-02) 
2023-05-25 22:49:29.180392: train Epoch: [34][ 77/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.892)	Loss 7.8476e-02 (8.0946e-02) 
2023-05-25 22:49:31.853879: train Epoch: [34][ 78/129]	Time  2.673 ( 1.852)	Data  1.727 ( 0.902)	Loss 6.3316e-02 (8.0723e-02) 
2023-05-25 22:49:32.801298: train Epoch: [34][ 79/129]	Time  0.947 ( 1.840)	Data  0.001 ( 0.891)	Loss 4.5703e-02 (8.0285e-02) 
2023-05-25 22:49:35.499074: train Epoch: [34][ 80/129]	Time  2.698 ( 1.851)	Data  1.753 ( 0.901)	Loss 1.1083e-01 (8.0663e-02) 
2023-05-25 22:49:36.448087: train Epoch: [34][ 81/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.890)	Loss 9.7242e-02 (8.0865e-02) 
2023-05-25 22:49:39.033088: train Epoch: [34][ 82/129]	Time  2.585 ( 1.849)	Data  1.637 ( 0.899)	Loss 7.2412e-02 (8.0763e-02) 
2023-05-25 22:49:39.983890: train Epoch: [34][ 83/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.889)	Loss 7.7513e-02 (8.0724e-02) 
2023-05-25 22:49:42.628552: train Epoch: [34][ 84/129]	Time  2.645 ( 1.848)	Data  1.695 ( 0.898)	Loss 9.6034e-02 (8.0904e-02) 
2023-05-25 22:49:43.578300: train Epoch: [34][ 85/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.888)	Loss 8.7469e-02 (8.0981e-02) 
2023-05-25 22:49:46.256383: train Epoch: [34][ 86/129]	Time  2.678 ( 1.847)	Data  1.730 ( 0.898)	Loss 1.1302e-01 (8.1349e-02) 
2023-05-25 22:49:47.206798: train Epoch: [34][ 87/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.887)	Loss 5.8882e-02 (8.1094e-02) 
2023-05-25 22:49:49.782433: train Epoch: [34][ 88/129]	Time  2.576 ( 1.845)	Data  1.625 ( 0.896)	Loss 5.3801e-02 (8.0787e-02) 
2023-05-25 22:49:50.730462: train Epoch: [34][ 89/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.886)	Loss 7.0474e-02 (8.0672e-02) 
2023-05-25 22:49:53.392370: train Epoch: [34][ 90/129]	Time  2.662 ( 1.844)	Data  1.714 ( 0.895)	Loss 5.9582e-02 (8.0441e-02) 
2023-05-25 22:49:54.340144: train Epoch: [34][ 91/129]	Time  0.948 ( 1.834)	Data  0.001 ( 0.885)	Loss 7.7712e-02 (8.0411e-02) 
2023-05-25 22:49:57.004614: train Epoch: [34][ 92/129]	Time  2.664 ( 1.843)	Data  1.716 ( 0.894)	Loss 1.4010e-01 (8.1053e-02) 
2023-05-25 22:49:57.954125: train Epoch: [34][ 93/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.884)	Loss 1.1717e-01 (8.1437e-02) 
2023-05-25 22:50:00.618863: train Epoch: [34][ 94/129]	Time  2.665 ( 1.843)	Data  1.712 ( 0.893)	Loss 8.7407e-02 (8.1500e-02) 
2023-05-25 22:50:01.565466: train Epoch: [34][ 95/129]	Time  0.947 ( 1.833)	Data  0.001 ( 0.884)	Loss 6.7913e-02 (8.1358e-02) 
2023-05-25 22:50:04.183889: train Epoch: [34][ 96/129]	Time  2.618 ( 1.841)	Data  1.669 ( 0.892)	Loss 5.1275e-02 (8.1048e-02) 
2023-05-25 22:50:05.138038: train Epoch: [34][ 97/129]	Time  0.954 ( 1.832)	Data  0.001 ( 0.883)	Loss 5.9532e-02 (8.0829e-02) 
2023-05-25 22:50:07.691493: train Epoch: [34][ 98/129]	Time  2.553 ( 1.840)	Data  1.606 ( 0.890)	Loss 1.3840e-01 (8.1410e-02) 
2023-05-25 22:50:08.636659: train Epoch: [34][ 99/129]	Time  0.945 ( 1.831)	Data  0.001 ( 0.881)	Loss 1.0893e-01 (8.1685e-02) 
2023-05-25 22:50:11.228333: train Epoch: [34][100/129]	Time  2.592 ( 1.838)	Data  1.644 ( 0.889)	Loss 6.7269e-02 (8.1543e-02) 
2023-05-25 22:50:12.175548: train Epoch: [34][101/129]	Time  0.947 ( 1.829)	Data  0.001 ( 0.880)	Loss 8.6535e-02 (8.1592e-02) 
2023-05-25 22:50:14.852852: train Epoch: [34][102/129]	Time  2.677 ( 1.838)	Data  1.728 ( 0.888)	Loss 7.6533e-02 (8.1542e-02) 
2023-05-25 22:50:15.799270: train Epoch: [34][103/129]	Time  0.946 ( 1.829)	Data  0.001 ( 0.880)	Loss 6.9380e-02 (8.1426e-02) 
2023-05-25 22:50:18.428120: train Epoch: [34][104/129]	Time  2.629 ( 1.837)	Data  1.681 ( 0.887)	Loss 8.5900e-02 (8.1468e-02) 
2023-05-25 22:50:19.380801: train Epoch: [34][105/129]	Time  0.953 ( 1.828)	Data  0.001 ( 0.879)	Loss 9.6821e-02 (8.1613e-02) 
2023-05-25 22:50:22.021788: train Epoch: [34][106/129]	Time  2.641 ( 1.836)	Data  1.691 ( 0.887)	Loss 6.8783e-02 (8.1493e-02) 
2023-05-25 22:50:22.969517: train Epoch: [34][107/129]	Time  0.948 ( 1.828)	Data  0.001 ( 0.879)	Loss 5.0232e-02 (8.1204e-02) 
2023-05-25 22:50:25.701309: train Epoch: [34][108/129]	Time  2.732 ( 1.836)	Data  1.780 ( 0.887)	Loss 5.9095e-02 (8.1001e-02) 
2023-05-25 22:50:26.650475: train Epoch: [34][109/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.879)	Loss 7.8463e-02 (8.0978e-02) 
2023-05-25 22:50:29.288916: train Epoch: [34][110/129]	Time  2.638 ( 1.835)	Data  1.689 ( 0.886)	Loss 1.0741e-01 (8.1216e-02) 
2023-05-25 22:50:30.242524: train Epoch: [34][111/129]	Time  0.954 ( 1.827)	Data  0.001 ( 0.878)	Loss 9.6866e-02 (8.1356e-02) 
2023-05-25 22:50:32.966732: train Epoch: [34][112/129]	Time  2.724 ( 1.835)	Data  1.774 ( 0.886)	Loss 1.0702e-01 (8.1583e-02) 
2023-05-25 22:50:33.915019: train Epoch: [34][113/129]	Time  0.948 ( 1.828)	Data  0.001 ( 0.878)	Loss 1.2186e-01 (8.1936e-02) 
2023-05-25 22:50:36.610917: train Epoch: [34][114/129]	Time  2.696 ( 1.835)	Data  1.746 ( 0.886)	Loss 9.9556e-02 (8.2089e-02) 
2023-05-25 22:50:37.561103: train Epoch: [34][115/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.878)	Loss 1.1636e-01 (8.2385e-02) 
2023-05-25 22:50:40.261853: train Epoch: [34][116/129]	Time  2.701 ( 1.835)	Data  1.752 ( 0.886)	Loss 3.5031e-02 (8.1980e-02) 
2023-05-25 22:50:41.211877: train Epoch: [34][117/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.878)	Loss 1.1125e-01 (8.2228e-02) 
2023-05-25 22:50:43.887760: train Epoch: [34][118/129]	Time  2.676 ( 1.835)	Data  1.728 ( 0.885)	Loss 5.5336e-02 (8.2002e-02) 
2023-05-25 22:50:44.841746: train Epoch: [34][119/129]	Time  0.954 ( 1.827)	Data  0.001 ( 0.878)	Loss 5.8015e-02 (8.1802e-02) 
2023-05-25 22:50:47.515220: train Epoch: [34][120/129]	Time  2.673 ( 1.834)	Data  1.727 ( 0.885)	Loss 1.0784e-01 (8.2017e-02) 
2023-05-25 22:50:48.464974: train Epoch: [34][121/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.878)	Loss 5.4886e-02 (8.1795e-02) 
2023-05-25 22:50:51.139136: train Epoch: [34][122/129]	Time  2.674 ( 1.834)	Data  1.721 ( 0.885)	Loss 1.1962e-01 (8.2102e-02) 
2023-05-25 22:50:52.089814: train Epoch: [34][123/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.877)	Loss 5.4806e-02 (8.1882e-02) 
2023-05-25 22:50:54.783763: train Epoch: [34][124/129]	Time  2.694 ( 1.834)	Data  1.745 ( 0.884)	Loss 1.2414e-01 (8.2220e-02) 
2023-05-25 22:50:55.734347: train Epoch: [34][125/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.877)	Loss 1.6207e-01 (8.2854e-02) 
2023-05-25 22:50:58.074054: train Epoch: [34][126/129]	Time  2.340 ( 1.831)	Data  1.393 ( 0.881)	Loss 1.1912e-01 (8.3140e-02) 
2023-05-25 22:50:59.020422: train Epoch: [34][127/129]	Time  0.946 ( 1.824)	Data  0.001 ( 0.875)	Loss 6.7215e-02 (8.3015e-02) 
2023-05-25 22:51:00.508943: train Epoch: [34][128/129]	Time  1.489 ( 1.821)	Data  0.542 ( 0.872)	Loss 5.9686e-02 (8.2834e-02) 
2023-05-25 22:51:00.539586: Train Epoch done in 234.9691175730004 s 
2023-05-25 22:51:02.895112: val Epoch: [34][ 0/72]	Time  1.584 ( 1.584)	Data  1.411 ( 1.411)	Loss 1.1503e-01 (1.1503e-01) 
2023-05-25 22:51:03.015535: val Epoch: [34][ 1/72]	Time  0.121 ( 0.852)	Data  0.001 ( 0.706)	Loss 6.7076e-02 (9.1051e-02) 
2023-05-25 22:51:04.046458: val Epoch: [34][ 2/72]	Time  1.031 ( 0.912)	Data  0.911 ( 0.774)	Loss 3.0992e-01 (1.6401e-01) 
2023-05-25 22:51:04.166777: val Epoch: [34][ 3/72]	Time  0.120 ( 0.714)	Data  0.000 ( 0.581)	Loss 9.4312e-02 (1.4658e-01) 
2023-05-25 22:51:05.331347: val Epoch: [34][ 4/72]	Time  1.165 ( 0.804)	Data  1.044 ( 0.674)	Loss 3.9647e-01 (1.9656e-01) 
2023-05-25 22:51:05.451547: val Epoch: [34][ 5/72]	Time  0.120 ( 0.690)	Data  0.000 ( 0.561)	Loss 5.7821e-02 (1.7344e-01) 
2023-05-25 22:51:06.615990: val Epoch: [34][ 6/72]	Time  1.164 ( 0.758)	Data  1.044 ( 0.630)	Loss 3.4252e-01 (1.9759e-01) 
2023-05-25 22:51:06.735686: val Epoch: [34][ 7/72]	Time  0.120 ( 0.678)	Data  0.000 ( 0.552)	Loss 4.0480e-02 (1.7795e-01) 
2023-05-25 22:51:07.888338: val Epoch: [34][ 8/72]	Time  1.153 ( 0.731)	Data  1.032 ( 0.605)	Loss 4.0079e-01 (2.0271e-01) 
2023-05-25 22:51:08.007375: val Epoch: [34][ 9/72]	Time  0.119 ( 0.670)	Data  0.001 ( 0.545)	Loss 4.1854e-01 (2.2430e-01) 
2023-05-25 22:51:09.124202: val Epoch: [34][10/72]	Time  1.117 ( 0.710)	Data  0.997 ( 0.586)	Loss 3.8155e-01 (2.3859e-01) 
2023-05-25 22:51:09.243710: val Epoch: [34][11/72]	Time  0.120 ( 0.661)	Data  0.000 ( 0.537)	Loss 5.6688e-02 (2.2343e-01) 
2023-05-25 22:51:10.344634: val Epoch: [34][12/72]	Time  1.101 ( 0.695)	Data  0.981 ( 0.571)	Loss 6.1014e-02 (2.1094e-01) 
2023-05-25 22:51:10.464702: val Epoch: [34][13/72]	Time  0.120 ( 0.654)	Data  0.001 ( 0.530)	Loss 1.8347e-01 (2.0898e-01) 
2023-05-25 22:51:11.538520: val Epoch: [34][14/72]	Time  1.074 ( 0.682)	Data  0.957 ( 0.559)	Loss 2.1443e-01 (2.0934e-01) 
2023-05-25 22:51:11.655498: val Epoch: [34][15/72]	Time  0.117 ( 0.647)	Data  0.000 ( 0.524)	Loss 5.0702e-02 (1.9943e-01) 
2023-05-25 22:51:12.743419: val Epoch: [34][16/72]	Time  1.088 ( 0.672)	Data  0.971 ( 0.550)	Loss 6.3307e-02 (1.9142e-01) 
2023-05-25 22:51:12.859982: val Epoch: [34][17/72]	Time  0.117 ( 0.642)	Data  0.000 ( 0.520)	Loss 4.0034e-01 (2.0303e-01) 
2023-05-25 22:51:13.980665: val Epoch: [34][18/72]	Time  1.121 ( 0.667)	Data  0.994 ( 0.545)	Loss 3.7848e-02 (1.9433e-01) 
2023-05-25 22:51:14.106234: val Epoch: [34][19/72]	Time  0.126 ( 0.640)	Data  0.001 ( 0.517)	Loss 9.3575e-02 (1.8929e-01) 
2023-05-25 22:51:15.222037: val Epoch: [34][20/72]	Time  1.116 ( 0.662)	Data  0.991 ( 0.540)	Loss 1.3588e-01 (1.8675e-01) 
2023-05-25 22:51:15.347676: val Epoch: [34][21/72]	Time  0.126 ( 0.638)	Data  0.001 ( 0.515)	Loss 5.3324e-01 (2.0250e-01) 
2023-05-25 22:51:16.499148: val Epoch: [34][22/72]	Time  1.151 ( 0.660)	Data  1.024 ( 0.538)	Loss 1.4833e-01 (2.0014e-01) 
2023-05-25 22:51:16.621061: val Epoch: [34][23/72]	Time  0.122 ( 0.638)	Data  0.001 ( 0.515)	Loss 9.3477e-02 (1.9570e-01) 
2023-05-25 22:51:17.731890: val Epoch: [34][24/72]	Time  1.111 ( 0.657)	Data  0.988 ( 0.534)	Loss 1.1738e-01 (1.9257e-01) 
2023-05-25 22:51:17.854210: val Epoch: [34][25/72]	Time  0.122 ( 0.636)	Data  0.001 ( 0.514)	Loss 1.1196e-01 (1.8947e-01) 
2023-05-25 22:51:18.913715: val Epoch: [34][26/72]	Time  1.059 ( 0.652)	Data  0.934 ( 0.529)	Loss 7.0788e-02 (1.8507e-01) 
2023-05-25 22:51:19.043825: val Epoch: [34][27/72]	Time  0.130 ( 0.633)	Data  0.008 ( 0.511)	Loss 9.8897e-02 (1.8199e-01) 
2023-05-25 22:51:20.097177: val Epoch: [34][28/72]	Time  1.053 ( 0.648)	Data  0.931 ( 0.525)	Loss 5.7404e-02 (1.7770e-01) 
2023-05-25 22:51:20.260131: val Epoch: [34][29/72]	Time  0.163 ( 0.632)	Data  0.041 ( 0.509)	Loss 5.4580e-02 (1.7359e-01) 
2023-05-25 22:51:21.302065: val Epoch: [34][30/72]	Time  1.042 ( 0.645)	Data  0.919 ( 0.522)	Loss 5.5213e-02 (1.6978e-01) 
2023-05-25 22:51:21.520311: val Epoch: [34][31/72]	Time  0.218 ( 0.632)	Data  0.097 ( 0.509)	Loss 8.4914e-02 (1.6712e-01) 
2023-05-25 22:51:22.491563: val Epoch: [34][32/72]	Time  0.971 ( 0.642)	Data  0.845 ( 0.519)	Loss 8.9802e-02 (1.6478e-01) 
2023-05-25 22:51:22.778588: val Epoch: [34][33/72]	Time  0.287 ( 0.631)	Data  0.165 ( 0.509)	Loss 9.6319e-02 (1.6277e-01) 
2023-05-25 22:51:23.741159: val Epoch: [34][34/72]	Time  0.963 ( 0.641)	Data  0.839 ( 0.518)	Loss 6.4839e-02 (1.5997e-01) 
2023-05-25 22:51:24.023788: val Epoch: [34][35/72]	Time  0.283 ( 0.631)	Data  0.161 ( 0.508)	Loss 8.0681e-02 (1.5777e-01) 
2023-05-25 22:51:24.960570: val Epoch: [34][36/72]	Time  0.937 ( 0.639)	Data  0.814 ( 0.516)	Loss 3.9631e-02 (1.5457e-01) 
2023-05-25 22:51:25.286758: val Epoch: [34][37/72]	Time  0.326 ( 0.631)	Data  0.204 ( 0.508)	Loss 1.0114e-01 (1.5317e-01) 
2023-05-25 22:51:26.235102: val Epoch: [34][38/72]	Time  0.948 ( 0.639)	Data  0.826 ( 0.516)	Loss 4.4832e-02 (1.5039e-01) 
2023-05-25 22:51:26.521477: val Epoch: [34][39/72]	Time  0.286 ( 0.630)	Data  0.165 ( 0.508)	Loss 1.2575e-01 (1.4977e-01) 
2023-05-25 22:51:27.490782: val Epoch: [34][40/72]	Time  0.969 ( 0.639)	Data  0.847 ( 0.516)	Loss 9.9481e-02 (1.4855e-01) 
2023-05-25 22:51:27.764141: val Epoch: [34][41/72]	Time  0.273 ( 0.630)	Data  0.152 ( 0.507)	Loss 1.2785e-01 (1.4805e-01) 
2023-05-25 22:51:28.769499: val Epoch: [34][42/72]	Time  1.005 ( 0.639)	Data  0.883 ( 0.516)	Loss 5.9319e-02 (1.4599e-01) 
2023-05-25 22:51:28.983677: val Epoch: [34][43/72]	Time  0.214 ( 0.629)	Data  0.093 ( 0.506)	Loss 2.7642e-01 (1.4895e-01) 
2023-05-25 22:51:29.981216: val Epoch: [34][44/72]	Time  0.998 ( 0.637)	Data  0.875 ( 0.514)	Loss 4.8391e-02 (1.4672e-01) 
2023-05-25 22:51:30.253891: val Epoch: [34][45/72]	Time  0.273 ( 0.629)	Data  0.151 ( 0.507)	Loss 8.5459e-02 (1.4539e-01) 
2023-05-25 22:51:31.196532: val Epoch: [34][46/72]	Time  0.943 ( 0.636)	Data  0.819 ( 0.513)	Loss 5.9995e-02 (1.4357e-01) 
2023-05-25 22:51:31.452995: val Epoch: [34][47/72]	Time  0.256 ( 0.628)	Data  0.135 ( 0.505)	Loss 6.4200e-02 (1.4192e-01) 
2023-05-25 22:51:32.438916: val Epoch: [34][48/72]	Time  0.986 ( 0.635)	Data  0.863 ( 0.513)	Loss 6.7299e-02 (1.4040e-01) 
2023-05-25 22:51:32.724436: val Epoch: [34][49/72]	Time  0.286 ( 0.628)	Data  0.163 ( 0.506)	Loss 5.7363e-02 (1.3873e-01) 
2023-05-25 22:51:33.698388: val Epoch: [34][50/72]	Time  0.974 ( 0.635)	Data  0.851 ( 0.512)	Loss 2.5601e-01 (1.4103e-01) 
2023-05-25 22:51:33.959969: val Epoch: [34][51/72]	Time  0.262 ( 0.628)	Data  0.141 ( 0.505)	Loss 2.9911e-01 (1.4407e-01) 
2023-05-25 22:51:34.911089: val Epoch: [34][52/72]	Time  0.951 ( 0.634)	Data  0.828 ( 0.511)	Loss 4.2010e-01 (1.4928e-01) 
2023-05-25 22:51:35.183021: val Epoch: [34][53/72]	Time  0.272 ( 0.627)	Data  0.150 ( 0.505)	Loss 9.4828e-02 (1.4827e-01) 
2023-05-25 22:51:36.150406: val Epoch: [34][54/72]	Time  0.967 ( 0.633)	Data  0.845 ( 0.511)	Loss 2.0727e-01 (1.4935e-01) 
2023-05-25 22:51:36.388432: val Epoch: [34][55/72]	Time  0.238 ( 0.626)	Data  0.116 ( 0.504)	Loss 5.1068e-02 (1.4759e-01) 
2023-05-25 22:51:37.358776: val Epoch: [34][56/72]	Time  0.970 ( 0.632)	Data  0.848 ( 0.510)	Loss 7.5961e-02 (1.4633e-01) 
2023-05-25 22:51:37.595514: val Epoch: [34][57/72]	Time  0.237 ( 0.626)	Data  0.115 ( 0.503)	Loss 1.2498e-01 (1.4597e-01) 
2023-05-25 22:51:38.537559: val Epoch: [34][58/72]	Time  0.942 ( 0.631)	Data  0.820 ( 0.508)	Loss 4.4140e-02 (1.4424e-01) 
2023-05-25 22:51:38.820473: val Epoch: [34][59/72]	Time  0.283 ( 0.625)	Data  0.161 ( 0.503)	Loss 8.1669e-02 (1.4320e-01) 
2023-05-25 22:51:39.793143: val Epoch: [34][60/72]	Time  0.973 ( 0.631)	Data  0.850 ( 0.508)	Loss 7.4595e-02 (1.4207e-01) 
2023-05-25 22:51:40.071483: val Epoch: [34][61/72]	Time  0.278 ( 0.625)	Data  0.157 ( 0.503)	Loss 4.9846e-02 (1.4059e-01) 
2023-05-25 22:51:41.067080: val Epoch: [34][62/72]	Time  0.996 ( 0.631)	Data  0.872 ( 0.509)	Loss 1.0754e-01 (1.4006e-01) 
2023-05-25 22:51:41.349892: val Epoch: [34][63/72]	Time  0.283 ( 0.626)	Data  0.161 ( 0.503)	Loss 9.6343e-02 (1.3938e-01) 
2023-05-25 22:51:42.335292: val Epoch: [34][64/72]	Time  0.985 ( 0.631)	Data  0.859 ( 0.509)	Loss 3.0805e-01 (1.4197e-01) 
2023-05-25 22:51:42.628880: val Epoch: [34][65/72]	Time  0.294 ( 0.626)	Data  0.168 ( 0.503)	Loss 1.8976e-01 (1.4270e-01) 
2023-05-25 22:51:43.547469: val Epoch: [34][66/72]	Time  0.919 ( 0.630)	Data  0.796 ( 0.508)	Loss 6.8712e-02 (1.4159e-01) 
2023-05-25 22:51:43.804813: val Epoch: [34][67/72]	Time  0.257 ( 0.625)	Data  0.136 ( 0.502)	Loss 4.1629e-02 (1.4012e-01) 
2023-05-25 22:51:44.825057: val Epoch: [34][68/72]	Time  1.020 ( 0.631)	Data  0.898 ( 0.508)	Loss 7.2848e-02 (1.3915e-01) 
2023-05-25 22:51:45.024656: val Epoch: [34][69/72]	Time  0.200 ( 0.624)	Data  0.079 ( 0.502)	Loss 3.8954e-02 (1.3772e-01) 
2023-05-25 22:51:46.019521: val Epoch: [34][70/72]	Time  0.995 ( 0.630)	Data  0.871 ( 0.507)	Loss 4.9656e-02 (1.3648e-01) 
2023-05-25 22:51:46.158445: val Epoch: [34][71/72]	Time  0.139 ( 0.623)	Data  0.022 ( 0.500)	Loss 2.3491e-01 (1.3784e-01) 
2023-05-25 22:51:46.340895: Epoch 34 :Val : ['ET : 0.7196429967880249', 'TC : 0.7688196897506714', 'WT : 0.8594070076942444'] 
2023-05-25 22:51:46.343764: Epoch 34 :Val : ['ET : 0.7196429967880249', 'TC : 0.7688196897506714', 'WT : 0.8594070076942444'] 
2023-05-25 22:51:46.345729: Val epoch done in 45.80614878299821 s 
2023-05-25 22:51:46.351122: Batches per epoch:  129 
2023-05-25 22:51:51.201144: train Epoch: [35][  0/129]	Time  4.850 ( 4.850)	Data  3.843 ( 3.843)	Loss 5.5755e-02 (5.5755e-02) 
2023-05-25 22:51:52.152700: train Epoch: [35][  1/129]	Time  0.952 ( 2.901)	Data  0.001 ( 1.922)	Loss 5.1590e-02 (5.3673e-02) 
2023-05-25 22:51:54.796743: train Epoch: [35][  2/129]	Time  2.644 ( 2.815)	Data  1.689 ( 1.844)	Loss 1.0682e-01 (7.1389e-02) 
2023-05-25 22:51:55.747049: train Epoch: [35][  3/129]	Time  0.950 ( 2.349)	Data  0.001 ( 1.383)	Loss 4.7806e-02 (6.5493e-02) 
2023-05-25 22:51:58.272527: train Epoch: [35][  4/129]	Time  2.525 ( 2.384)	Data  1.566 ( 1.420)	Loss 6.3231e-02 (6.5040e-02) 
2023-05-25 22:51:59.222749: train Epoch: [35][  5/129]	Time  0.950 ( 2.145)	Data  0.001 ( 1.183)	Loss 7.1013e-02 (6.6036e-02) 
2023-05-25 22:52:01.842160: train Epoch: [35][  6/129]	Time  2.619 ( 2.213)	Data  1.671 ( 1.253)	Loss 6.2507e-02 (6.5532e-02) 
2023-05-25 22:52:02.797365: train Epoch: [35][  7/129]	Time  0.955 ( 2.056)	Data  0.001 ( 1.097)	Loss 9.0322e-02 (6.8631e-02) 
2023-05-25 22:52:05.573434: train Epoch: [35][  8/129]	Time  2.776 ( 2.136)	Data  1.818 ( 1.177)	Loss 7.3806e-02 (6.9206e-02) 
2023-05-25 22:52:06.523526: train Epoch: [35][  9/129]	Time  0.950 ( 2.017)	Data  0.001 ( 1.059)	Loss 1.1490e-01 (7.3775e-02) 
2023-05-25 22:52:09.095488: train Epoch: [35][ 10/129]	Time  2.572 ( 2.068)	Data  1.620 ( 1.110)	Loss 7.2735e-02 (7.3681e-02) 
2023-05-25 22:52:10.045218: train Epoch: [35][ 11/129]	Time  0.950 ( 1.974)	Data  0.001 ( 1.018)	Loss 1.5019e-01 (8.0057e-02) 
2023-05-25 22:52:12.748472: train Epoch: [35][ 12/129]	Time  2.703 ( 2.031)	Data  1.756 ( 1.075)	Loss 9.6076e-02 (8.1289e-02) 
2023-05-25 22:52:13.698717: train Epoch: [35][ 13/129]	Time  0.950 ( 1.953)	Data  0.001 ( 0.998)	Loss 7.5465e-02 (8.0873e-02) 
2023-05-25 22:52:16.336104: train Epoch: [35][ 14/129]	Time  2.637 ( 1.999)	Data  1.686 ( 1.044)	Loss 1.4451e-01 (8.5116e-02) 
2023-05-25 22:52:17.286110: train Epoch: [35][ 15/129]	Time  0.950 ( 1.933)	Data  0.001 ( 0.979)	Loss 8.6923e-02 (8.5229e-02) 
2023-05-25 22:52:19.867894: train Epoch: [35][ 16/129]	Time  2.582 ( 1.972)	Data  1.635 ( 1.017)	Loss 1.1002e-01 (8.6687e-02) 
2023-05-25 22:52:20.818358: train Epoch: [35][ 17/129]	Time  0.950 ( 1.915)	Data  0.001 ( 0.961)	Loss 1.5429e-01 (9.0442e-02) 
2023-05-25 22:52:23.603808: train Epoch: [35][ 18/129]	Time  2.785 ( 1.961)	Data  1.833 ( 1.007)	Loss 6.2344e-02 (8.8963e-02) 
2023-05-25 22:52:24.553304: train Epoch: [35][ 19/129]	Time  0.949 ( 1.910)	Data  0.001 ( 0.956)	Loss 8.0460e-02 (8.8538e-02) 
2023-05-25 22:52:27.198038: train Epoch: [35][ 20/129]	Time  2.645 ( 1.945)	Data  1.693 ( 0.991)	Loss 7.9094e-02 (8.8089e-02) 
2023-05-25 22:52:28.147602: train Epoch: [35][ 21/129]	Time  0.950 ( 1.900)	Data  0.001 ( 0.946)	Loss 9.3026e-02 (8.8313e-02) 
2023-05-25 22:52:30.827323: train Epoch: [35][ 22/129]	Time  2.680 ( 1.934)	Data  1.729 ( 0.980)	Loss 9.5101e-02 (8.8608e-02) 
2023-05-25 22:52:31.789829: train Epoch: [35][ 23/129]	Time  0.963 ( 1.893)	Data  0.001 ( 0.940)	Loss 8.5933e-02 (8.8497e-02) 
2023-05-25 22:52:34.530713: train Epoch: [35][ 24/129]	Time  2.741 ( 1.927)	Data  1.780 ( 0.973)	Loss 3.6353e-01 (9.9498e-02) 
2023-05-25 22:52:35.491504: train Epoch: [35][ 25/129]	Time  0.961 ( 1.890)	Data  0.001 ( 0.936)	Loss 8.6649e-02 (9.9004e-02) 
2023-05-25 22:52:38.203027: train Epoch: [35][ 26/129]	Time  2.712 ( 1.920)	Data  1.750 ( 0.966)	Loss 7.3965e-02 (9.8076e-02) 
2023-05-25 22:52:39.164713: train Epoch: [35][ 27/129]	Time  0.962 ( 1.886)	Data  0.001 ( 0.932)	Loss 9.4616e-02 (9.7953e-02) 
2023-05-25 22:52:41.875631: train Epoch: [35][ 28/129]	Time  2.711 ( 1.915)	Data  1.751 ( 0.960)	Loss 1.2232e-01 (9.8793e-02) 
2023-05-25 22:52:42.836627: train Epoch: [35][ 29/129]	Time  0.961 ( 1.883)	Data  0.001 ( 0.928)	Loss 9.4560e-02 (9.8652e-02) 
2023-05-25 22:52:45.553308: train Epoch: [35][ 30/129]	Time  2.717 ( 1.910)	Data  1.769 ( 0.955)	Loss 7.7235e-02 (9.7961e-02) 
2023-05-25 22:52:46.504810: train Epoch: [35][ 31/129]	Time  0.952 ( 1.880)	Data  0.001 ( 0.925)	Loss 6.9615e-02 (9.7075e-02) 
2023-05-25 22:52:49.143088: train Epoch: [35][ 32/129]	Time  2.638 ( 1.903)	Data  1.682 ( 0.948)	Loss 9.4490e-02 (9.6997e-02) 
2023-05-25 22:52:50.093649: train Epoch: [35][ 33/129]	Time  0.951 ( 1.875)	Data  0.001 ( 0.920)	Loss 6.4179e-02 (9.6032e-02) 
2023-05-25 22:52:52.769565: train Epoch: [35][ 34/129]	Time  2.676 ( 1.898)	Data  1.729 ( 0.943)	Loss 1.7715e-01 (9.8350e-02) 
2023-05-25 22:52:53.719085: train Epoch: [35][ 35/129]	Time  0.950 ( 1.871)	Data  0.001 ( 0.917)	Loss 8.4779e-02 (9.7973e-02) 
2023-05-25 22:52:56.434721: train Epoch: [35][ 36/129]	Time  2.716 ( 1.894)	Data  1.767 ( 0.940)	Loss 7.6700e-02 (9.7398e-02) 
2023-05-25 22:52:57.385002: train Epoch: [35][ 37/129]	Time  0.950 ( 1.869)	Data  0.001 ( 0.915)	Loss 7.4470e-02 (9.6794e-02) 
2023-05-25 22:53:00.050102: train Epoch: [35][ 38/129]	Time  2.665 ( 1.890)	Data  1.718 ( 0.936)	Loss 8.6503e-02 (9.6530e-02) 
2023-05-25 22:53:00.999541: train Epoch: [35][ 39/129]	Time  0.949 ( 1.866)	Data  0.001 ( 0.913)	Loss 1.4150e-01 (9.7655e-02) 
2023-05-25 22:53:03.707034: train Epoch: [35][ 40/129]	Time  2.707 ( 1.887)	Data  1.760 ( 0.933)	Loss 8.2844e-02 (9.7293e-02) 
2023-05-25 22:53:04.660591: train Epoch: [35][ 41/129]	Time  0.954 ( 1.865)	Data  0.001 ( 0.911)	Loss 8.1622e-02 (9.6920e-02) 
2023-05-25 22:53:07.421441: train Epoch: [35][ 42/129]	Time  2.761 ( 1.885)	Data  1.809 ( 0.932)	Loss 8.3167e-02 (9.6600e-02) 
2023-05-25 22:53:08.370572: train Epoch: [35][ 43/129]	Time  0.949 ( 1.864)	Data  0.001 ( 0.911)	Loss 8.1106e-02 (9.6248e-02) 
2023-05-25 22:53:11.058667: train Epoch: [35][ 44/129]	Time  2.688 ( 1.882)	Data  1.732 ( 0.929)	Loss 8.1505e-02 (9.5921e-02) 
2023-05-25 22:53:12.008756: train Epoch: [35][ 45/129]	Time  0.950 ( 1.862)	Data  0.001 ( 0.909)	Loss 9.5163e-02 (9.5904e-02) 
2023-05-25 22:53:14.585439: train Epoch: [35][ 46/129]	Time  2.577 ( 1.877)	Data  1.623 ( 0.924)	Loss 8.6619e-02 (9.5707e-02) 
2023-05-25 22:53:15.535893: train Epoch: [35][ 47/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.905)	Loss 4.6138e-02 (9.4674e-02) 
2023-05-25 22:53:18.102371: train Epoch: [35][ 48/129]	Time  2.566 ( 1.872)	Data  1.618 ( 0.919)	Loss 7.3105e-02 (9.4234e-02) 
2023-05-25 22:53:19.054555: train Epoch: [35][ 49/129]	Time  0.952 ( 1.854)	Data  0.001 ( 0.901)	Loss 9.3817e-02 (9.4225e-02) 
2023-05-25 22:53:21.769877: train Epoch: [35][ 50/129]	Time  2.715 ( 1.871)	Data  1.768 ( 0.918)	Loss 1.0375e-01 (9.4412e-02) 
2023-05-25 22:53:22.721482: train Epoch: [35][ 51/129]	Time  0.952 ( 1.853)	Data  0.001 ( 0.900)	Loss 1.2038e-01 (9.4912e-02) 
2023-05-25 22:53:25.440774: train Epoch: [35][ 52/129]	Time  2.719 ( 1.870)	Data  1.761 ( 0.917)	Loss 1.0186e-01 (9.5043e-02) 
2023-05-25 22:53:26.392347: train Epoch: [35][ 53/129]	Time  0.952 ( 1.853)	Data  0.001 ( 0.900)	Loss 7.7373e-02 (9.4715e-02) 
2023-05-25 22:53:29.079195: train Epoch: [35][ 54/129]	Time  2.687 ( 1.868)	Data  1.739 ( 0.915)	Loss 6.9449e-02 (9.4256e-02) 
2023-05-25 22:53:30.029332: train Epoch: [35][ 55/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.899)	Loss 6.8143e-02 (9.3790e-02) 
2023-05-25 22:53:32.688563: train Epoch: [35][ 56/129]	Time  2.659 ( 1.866)	Data  1.710 ( 0.913)	Loss 1.0030e-01 (9.3904e-02) 
2023-05-25 22:53:33.639550: train Epoch: [35][ 57/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.897)	Loss 4.9917e-02 (9.3146e-02) 
2023-05-25 22:53:36.294497: train Epoch: [35][ 58/129]	Time  2.655 ( 1.863)	Data  1.702 ( 0.911)	Loss 1.0718e-01 (9.3383e-02) 
2023-05-25 22:53:37.247776: train Epoch: [35][ 59/129]	Time  0.953 ( 1.848)	Data  0.001 ( 0.896)	Loss 7.8193e-02 (9.3130e-02) 
2023-05-25 22:53:39.874466: train Epoch: [35][ 60/129]	Time  2.627 ( 1.861)	Data  1.667 ( 0.908)	Loss 5.8497e-02 (9.2562e-02) 
2023-05-25 22:53:40.835326: train Epoch: [35][ 61/129]	Time  0.961 ( 1.847)	Data  0.001 ( 0.894)	Loss 8.6907e-02 (9.2471e-02) 
2023-05-25 22:53:43.494899: train Epoch: [35][ 62/129]	Time  2.660 ( 1.859)	Data  1.700 ( 0.906)	Loss 6.3057e-02 (9.2004e-02) 
2023-05-25 22:53:44.456640: train Epoch: [35][ 63/129]	Time  0.962 ( 1.845)	Data  0.001 ( 0.892)	Loss 5.1931e-02 (9.1378e-02) 
2023-05-25 22:53:47.068799: train Epoch: [35][ 64/129]	Time  2.612 ( 1.857)	Data  1.646 ( 0.904)	Loss 7.0675e-02 (9.1060e-02) 
2023-05-25 22:53:48.029402: train Epoch: [35][ 65/129]	Time  0.961 ( 1.844)	Data  0.001 ( 0.890)	Loss 5.6979e-02 (9.0543e-02) 
2023-05-25 22:53:50.746723: train Epoch: [35][ 66/129]	Time  2.717 ( 1.857)	Data  1.759 ( 0.903)	Loss 1.0939e-01 (9.0825e-02) 
2023-05-25 22:53:51.697409: train Epoch: [35][ 67/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.890)	Loss 1.0009e-01 (9.0961e-02) 
2023-05-25 22:53:54.422954: train Epoch: [35][ 68/129]	Time  2.726 ( 1.856)	Data  1.776 ( 0.903)	Loss 7.2149e-02 (9.0688e-02) 
2023-05-25 22:53:55.373038: train Epoch: [35][ 69/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.890)	Loss 8.7734e-02 (9.0646e-02) 
2023-05-25 22:53:58.082110: train Epoch: [35][ 70/129]	Time  2.709 ( 1.855)	Data  1.761 ( 0.902)	Loss 7.5131e-02 (9.0427e-02) 
2023-05-25 22:53:59.037084: train Epoch: [35][ 71/129]	Time  0.955 ( 1.843)	Data  0.001 ( 0.890)	Loss 8.8579e-02 (9.0402e-02) 
2023-05-25 22:54:01.715913: train Epoch: [35][ 72/129]	Time  2.679 ( 1.854)	Data  1.726 ( 0.901)	Loss 7.9357e-02 (9.0250e-02) 
2023-05-25 22:54:02.668858: train Epoch: [35][ 73/129]	Time  0.953 ( 1.842)	Data  0.001 ( 0.889)	Loss 7.2035e-02 (9.0004e-02) 
2023-05-25 22:54:05.259432: train Epoch: [35][ 74/129]	Time  2.591 ( 1.852)	Data  1.635 ( 0.899)	Loss 1.1264e-01 (9.0306e-02) 
2023-05-25 22:54:06.210450: train Epoch: [35][ 75/129]	Time  0.951 ( 1.840)	Data  0.001 ( 0.887)	Loss 5.8075e-02 (8.9882e-02) 
2023-05-25 22:54:08.877207: train Epoch: [35][ 76/129]	Time  2.667 ( 1.851)	Data  1.716 ( 0.898)	Loss 1.0725e-01 (9.0108e-02) 
2023-05-25 22:54:09.825756: train Epoch: [35][ 77/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.886)	Loss 3.0968e-02 (8.9349e-02) 
2023-05-25 22:54:12.443044: train Epoch: [35][ 78/129]	Time  2.617 ( 1.849)	Data  1.667 ( 0.896)	Loss 1.1383e-01 (8.9659e-02) 
2023-05-25 22:54:13.395292: train Epoch: [35][ 79/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.885)	Loss 1.4454e-01 (9.0345e-02) 
2023-05-25 22:54:16.077549: train Epoch: [35][ 80/129]	Time  2.682 ( 1.848)	Data  1.725 ( 0.895)	Loss 7.1873e-02 (9.0117e-02) 
2023-05-25 22:54:17.027386: train Epoch: [35][ 81/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.884)	Loss 8.9069e-02 (9.0104e-02) 
2023-05-25 22:54:19.656497: train Epoch: [35][ 82/129]	Time  2.629 ( 1.847)	Data  1.667 ( 0.894)	Loss 6.5120e-02 (8.9803e-02) 
2023-05-25 22:54:20.616974: train Epoch: [35][ 83/129]	Time  0.960 ( 1.836)	Data  0.001 ( 0.883)	Loss 9.2289e-02 (8.9833e-02) 
2023-05-25 22:54:23.243502: train Epoch: [35][ 84/129]	Time  2.627 ( 1.846)	Data  1.661 ( 0.892)	Loss 5.7863e-02 (8.9457e-02) 
2023-05-25 22:54:24.207304: train Epoch: [35][ 85/129]	Time  0.964 ( 1.836)	Data  0.001 ( 0.882)	Loss 8.3975e-02 (8.9393e-02) 
2023-05-25 22:54:26.706341: train Epoch: [35][ 86/129]	Time  2.499 ( 1.843)	Data  1.540 ( 0.890)	Loss 4.7590e-02 (8.8913e-02) 
2023-05-25 22:54:27.666545: train Epoch: [35][ 87/129]	Time  0.960 ( 1.833)	Data  0.001 ( 0.879)	Loss 8.7330e-02 (8.8895e-02) 
2023-05-25 22:54:30.388621: train Epoch: [35][ 88/129]	Time  2.722 ( 1.843)	Data  1.762 ( 0.889)	Loss 9.9760e-02 (8.9017e-02) 
2023-05-25 22:54:31.350338: train Epoch: [35][ 89/129]	Time  0.962 ( 1.833)	Data  0.001 ( 0.880)	Loss 4.6608e-02 (8.8546e-02) 
2023-05-25 22:54:33.922348: train Epoch: [35][ 90/129]	Time  2.572 ( 1.841)	Data  1.613 ( 0.888)	Loss 6.8592e-02 (8.8326e-02) 
2023-05-25 22:54:34.883363: train Epoch: [35][ 91/129]	Time  0.961 ( 1.832)	Data  0.001 ( 0.878)	Loss 7.1339e-02 (8.8142e-02) 
2023-05-25 22:54:37.459575: train Epoch: [35][ 92/129]	Time  2.576 ( 1.840)	Data  1.616 ( 0.886)	Loss 7.5306e-02 (8.8004e-02) 
2023-05-25 22:54:38.422669: train Epoch: [35][ 93/129]	Time  0.963 ( 1.831)	Data  0.001 ( 0.876)	Loss 1.0093e-01 (8.8141e-02) 
2023-05-25 22:54:41.054641: train Epoch: [35][ 94/129]	Time  2.632 ( 1.839)	Data  1.660 ( 0.885)	Loss 6.4804e-02 (8.7895e-02) 
2023-05-25 22:54:42.016581: train Epoch: [35][ 95/129]	Time  0.962 ( 1.830)	Data  0.001 ( 0.876)	Loss 7.1842e-02 (8.7728e-02) 
2023-05-25 22:54:44.604393: train Epoch: [35][ 96/129]	Time  2.588 ( 1.838)	Data  1.630 ( 0.883)	Loss 5.9155e-02 (8.7434e-02) 
2023-05-25 22:54:45.555636: train Epoch: [35][ 97/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.874)	Loss 8.4282e-02 (8.7401e-02) 
2023-05-25 22:54:48.185791: train Epoch: [35][ 98/129]	Time  2.630 ( 1.837)	Data  1.675 ( 0.882)	Loss 7.9559e-02 (8.7322e-02) 
2023-05-25 22:54:49.135469: train Epoch: [35][ 99/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.874)	Loss 5.3019e-02 (8.6979e-02) 
2023-05-25 22:54:51.800006: train Epoch: [35][100/129]	Time  2.665 ( 1.836)	Data  1.715 ( 0.882)	Loss 6.5550e-02 (8.6767e-02) 
2023-05-25 22:54:52.761090: train Epoch: [35][101/129]	Time  0.961 ( 1.828)	Data  0.001 ( 0.873)	Loss 6.5574e-02 (8.6559e-02) 
2023-05-25 22:54:55.373202: train Epoch: [35][102/129]	Time  2.612 ( 1.835)	Data  1.653 ( 0.881)	Loss 9.1532e-02 (8.6608e-02) 
2023-05-25 22:54:56.333962: train Epoch: [35][103/129]	Time  0.961 ( 1.827)	Data  0.001 ( 0.872)	Loss 3.2549e-01 (8.8905e-02) 
2023-05-25 22:54:59.017390: train Epoch: [35][104/129]	Time  2.683 ( 1.835)	Data  1.713 ( 0.880)	Loss 5.1829e-02 (8.8551e-02) 
2023-05-25 22:54:59.977653: train Epoch: [35][105/129]	Time  0.960 ( 1.827)	Data  0.001 ( 0.872)	Loss 1.0379e-01 (8.8695e-02) 
2023-05-25 22:55:02.606502: train Epoch: [35][106/129]	Time  2.629 ( 1.834)	Data  1.666 ( 0.879)	Loss 1.2126e-01 (8.8999e-02) 
2023-05-25 22:55:03.569248: train Epoch: [35][107/129]	Time  0.963 ( 1.826)	Data  0.001 ( 0.871)	Loss 1.0054e-01 (8.9106e-02) 
2023-05-25 22:55:06.189706: train Epoch: [35][108/129]	Time  2.620 ( 1.833)	Data  1.659 ( 0.879)	Loss 7.1845e-02 (8.8948e-02) 
2023-05-25 22:55:07.142724: train Epoch: [35][109/129]	Time  0.953 ( 1.825)	Data  0.001 ( 0.871)	Loss 6.6219e-02 (8.8741e-02) 
2023-05-25 22:55:09.769279: train Epoch: [35][110/129]	Time  2.627 ( 1.833)	Data  1.677 ( 0.878)	Loss 5.9816e-02 (8.8481e-02) 
2023-05-25 22:55:10.730252: train Epoch: [35][111/129]	Time  0.961 ( 1.825)	Data  0.001 ( 0.870)	Loss 4.9718e-02 (8.8135e-02) 
2023-05-25 22:55:13.360666: train Epoch: [35][112/129]	Time  2.630 ( 1.832)	Data  1.671 ( 0.877)	Loss 1.0156e-01 (8.8253e-02) 
2023-05-25 22:55:14.321195: train Epoch: [35][113/129]	Time  0.961 ( 1.824)	Data  0.001 ( 0.869)	Loss 6.1565e-02 (8.8019e-02) 
2023-05-25 22:55:17.058774: train Epoch: [35][114/129]	Time  2.738 ( 1.832)	Data  1.765 ( 0.877)	Loss 1.1126e-01 (8.8221e-02) 
2023-05-25 22:55:18.019295: train Epoch: [35][115/129]	Time  0.961 ( 1.825)	Data  0.001 ( 0.870)	Loss 6.3583e-02 (8.8009e-02) 
2023-05-25 22:55:20.762412: train Epoch: [35][116/129]	Time  2.743 ( 1.833)	Data  1.784 ( 0.877)	Loss 9.6084e-02 (8.8078e-02) 
2023-05-25 22:55:21.713933: train Epoch: [35][117/129]	Time  0.952 ( 1.825)	Data  0.001 ( 0.870)	Loss 6.5870e-02 (8.7890e-02) 
2023-05-25 22:55:24.610368: train Epoch: [35][118/129]	Time  2.896 ( 1.834)	Data  1.937 ( 0.879)	Loss 9.9334e-02 (8.7986e-02) 
2023-05-25 22:55:25.560409: train Epoch: [35][119/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.872)	Loss 6.0963e-02 (8.7761e-02) 
2023-05-25 22:55:28.423353: train Epoch: [35][120/129]	Time  2.863 ( 1.835)	Data  1.918 ( 0.880)	Loss 1.1766e-01 (8.8008e-02) 
2023-05-25 22:55:29.371771: train Epoch: [35][121/129]	Time  0.948 ( 1.828)	Data  0.001 ( 0.873)	Loss 8.3717e-02 (8.7973e-02) 
2023-05-25 22:55:31.890745: train Epoch: [35][122/129]	Time  2.519 ( 1.834)	Data  1.573 ( 0.879)	Loss 6.7274e-02 (8.7805e-02) 
2023-05-25 22:55:32.840928: train Epoch: [35][123/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.872)	Loss 8.1193e-02 (8.7751e-02) 
2023-05-25 22:55:35.553413: train Epoch: [35][124/129]	Time  2.712 ( 1.834)	Data  1.766 ( 0.879)	Loss 5.9865e-02 (8.7528e-02) 
2023-05-25 22:55:36.505132: train Epoch: [35][125/129]	Time  0.952 ( 1.827)	Data  0.001 ( 0.872)	Loss 7.7753e-02 (8.7451e-02) 
2023-05-25 22:55:39.111015: train Epoch: [35][126/129]	Time  2.606 ( 1.833)	Data  1.659 ( 0.878)	Loss 8.9504e-02 (8.7467e-02) 
2023-05-25 22:55:40.057889: train Epoch: [35][127/129]	Time  0.947 ( 1.826)	Data  0.001 ( 0.871)	Loss 1.1427e-01 (8.7676e-02) 
2023-05-25 22:55:41.626220: train Epoch: [35][128/129]	Time  1.568 ( 1.824)	Data  0.624 ( 0.869)	Loss 6.7428e-02 (8.7519e-02) 
2023-05-25 22:55:41.657489: Train Epoch done in 235.30638097200062 s 
2023-05-25 22:55:43.943976: val Epoch: [35][ 0/72]	Time  1.531 ( 1.531)	Data  1.318 ( 1.318)	Loss 4.4461e-02 (4.4461e-02) 
2023-05-25 22:55:44.069674: val Epoch: [35][ 1/72]	Time  0.126 ( 0.828)	Data  0.002 ( 0.660)	Loss 5.0922e-02 (4.7692e-02) 
2023-05-25 22:55:45.002628: val Epoch: [35][ 2/72]	Time  0.933 ( 0.863)	Data  0.810 ( 0.710)	Loss 5.6711e-02 (5.0698e-02) 
2023-05-25 22:55:45.147977: val Epoch: [35][ 3/72]	Time  0.145 ( 0.684)	Data  0.024 ( 0.538)	Loss 3.8611e-01 (1.3455e-01) 
2023-05-25 22:55:46.233577: val Epoch: [35][ 4/72]	Time  1.086 ( 0.764)	Data  0.963 ( 0.623)	Loss 6.5787e-02 (1.2080e-01) 
2023-05-25 22:55:46.412878: val Epoch: [35][ 5/72]	Time  0.179 ( 0.667)	Data  0.057 ( 0.529)	Loss 9.8958e-02 (1.1716e-01) 
2023-05-25 22:55:47.431450: val Epoch: [35][ 6/72]	Time  1.019 ( 0.717)	Data  0.896 ( 0.581)	Loss 4.7798e-02 (1.0725e-01) 
2023-05-25 22:55:47.612169: val Epoch: [35][ 7/72]	Time  0.181 ( 0.650)	Data  0.059 ( 0.516)	Loss 5.2919e-02 (1.0046e-01) 
2023-05-25 22:55:48.646343: val Epoch: [35][ 8/72]	Time  1.034 ( 0.693)	Data  0.911 ( 0.560)	Loss 6.0295e-02 (9.5996e-02) 
2023-05-25 22:55:48.847088: val Epoch: [35][ 9/72]	Time  0.201 ( 0.643)	Data  0.075 ( 0.512)	Loss 3.9066e-02 (9.0303e-02) 
2023-05-25 22:55:49.842607: val Epoch: [35][10/72]	Time  0.996 ( 0.675)	Data  0.869 ( 0.544)	Loss 6.1083e-02 (8.7647e-02) 
2023-05-25 22:55:50.117270: val Epoch: [35][11/72]	Time  0.275 ( 0.642)	Data  0.154 ( 0.511)	Loss 1.9774e-01 (9.6821e-02) 
2023-05-25 22:55:51.060773: val Epoch: [35][12/72]	Time  0.943 ( 0.665)	Data  0.820 ( 0.535)	Loss 5.3125e-02 (9.3459e-02) 
2023-05-25 22:55:51.328152: val Epoch: [35][13/72]	Time  0.267 ( 0.637)	Data  0.141 ( 0.507)	Loss 1.0616e-01 (9.4367e-02) 
2023-05-25 22:55:52.273977: val Epoch: [35][14/72]	Time  0.946 ( 0.657)	Data  0.823 ( 0.528)	Loss 8.2959e-02 (9.3606e-02) 
2023-05-25 22:55:52.550270: val Epoch: [35][15/72]	Time  0.276 ( 0.634)	Data  0.152 ( 0.505)	Loss 3.8421e-02 (9.0157e-02) 
2023-05-25 22:55:53.521636: val Epoch: [35][16/72]	Time  0.971 ( 0.653)	Data  0.844 ( 0.525)	Loss 9.9963e-02 (9.0734e-02) 
2023-05-25 22:55:53.766323: val Epoch: [35][17/72]	Time  0.245 ( 0.631)	Data  0.120 ( 0.502)	Loss 2.9024e-01 (1.0182e-01) 
2023-05-25 22:55:54.745311: val Epoch: [35][18/72]	Time  0.979 ( 0.649)	Data  0.852 ( 0.521)	Loss 4.0517e-01 (1.1778e-01) 
2023-05-25 22:55:55.003278: val Epoch: [35][19/72]	Time  0.258 ( 0.630)	Data  0.133 ( 0.501)	Loss 1.6216e-01 (1.2000e-01) 
2023-05-25 22:55:55.999197: val Epoch: [35][20/72]	Time  0.996 ( 0.647)	Data  0.873 ( 0.519)	Loss 2.8380e-01 (1.2780e-01) 
2023-05-25 22:55:56.257285: val Epoch: [35][21/72]	Time  0.258 ( 0.629)	Data  0.133 ( 0.501)	Loss 3.3683e-01 (1.3730e-01) 
2023-05-25 22:55:57.229654: val Epoch: [35][22/72]	Time  0.972 ( 0.644)	Data  0.846 ( 0.516)	Loss 1.2974e-01 (1.3697e-01) 
2023-05-25 22:55:57.468085: val Epoch: [35][23/72]	Time  0.238 ( 0.627)	Data  0.113 ( 0.500)	Loss 1.3694e-01 (1.3697e-01) 
2023-05-25 22:55:58.441028: val Epoch: [35][24/72]	Time  0.973 ( 0.641)	Data  0.850 ( 0.514)	Loss 4.3266e-02 (1.3322e-01) 
2023-05-25 22:55:58.674135: val Epoch: [35][25/72]	Time  0.233 ( 0.625)	Data  0.108 ( 0.498)	Loss 8.9468e-02 (1.3154e-01) 
2023-05-25 22:55:59.702952: val Epoch: [35][26/72]	Time  1.029 ( 0.640)	Data  0.906 ( 0.513)	Loss 8.5646e-02 (1.2984e-01) 
2023-05-25 22:55:59.924690: val Epoch: [35][27/72]	Time  0.222 ( 0.625)	Data  0.096 ( 0.498)	Loss 4.9263e-02 (1.2696e-01) 
2023-05-25 22:56:00.949002: val Epoch: [35][28/72]	Time  1.024 ( 0.639)	Data  0.898 ( 0.512)	Loss 1.3110e-01 (1.2711e-01) 
2023-05-25 22:56:01.118651: val Epoch: [35][29/72]	Time  0.170 ( 0.624)	Data  0.044 ( 0.496)	Loss 4.7372e-02 (1.2445e-01) 
2023-05-25 22:56:02.200246: val Epoch: [35][30/72]	Time  1.082 ( 0.638)	Data  0.956 ( 0.511)	Loss 8.2241e-02 (1.2309e-01) 
2023-05-25 22:56:02.356047: val Epoch: [35][31/72]	Time  0.156 ( 0.623)	Data  0.034 ( 0.496)	Loss 3.5287e-01 (1.3027e-01) 
2023-05-25 22:56:03.384704: val Epoch: [35][32/72]	Time  1.029 ( 0.636)	Data  0.906 ( 0.509)	Loss 7.0818e-02 (1.2847e-01) 
2023-05-25 22:56:03.625682: val Epoch: [35][33/72]	Time  0.241 ( 0.624)	Data  0.116 ( 0.497)	Loss 8.5236e-02 (1.2720e-01) 
2023-05-25 22:56:04.587486: val Epoch: [35][34/72]	Time  0.962 ( 0.634)	Data  0.835 ( 0.507)	Loss 6.3278e-02 (1.2537e-01) 
2023-05-25 22:56:04.862471: val Epoch: [35][35/72]	Time  0.275 ( 0.624)	Data  0.149 ( 0.497)	Loss 4.3423e-02 (1.2309e-01) 
2023-05-25 22:56:05.788723: val Epoch: [35][36/72]	Time  0.926 ( 0.632)	Data  0.804 ( 0.505)	Loss 1.3541e-01 (1.2343e-01) 
2023-05-25 22:56:06.062557: val Epoch: [35][37/72]	Time  0.274 ( 0.622)	Data  0.149 ( 0.496)	Loss 2.4998e-01 (1.2676e-01) 
2023-05-25 22:56:07.019664: val Epoch: [35][38/72]	Time  0.957 ( 0.631)	Data  0.831 ( 0.504)	Loss 3.4043e-01 (1.3224e-01) 
2023-05-25 22:56:07.267600: val Epoch: [35][39/72]	Time  0.248 ( 0.621)	Data  0.123 ( 0.495)	Loss 1.1862e-01 (1.3189e-01) 
2023-05-25 22:56:08.270705: val Epoch: [35][40/72]	Time  1.003 ( 0.631)	Data  0.880 ( 0.504)	Loss 9.0965e-02 (1.3090e-01) 
2023-05-25 22:56:08.545938: val Epoch: [35][41/72]	Time  0.275 ( 0.622)	Data  0.150 ( 0.496)	Loss 8.7022e-02 (1.2985e-01) 
2023-05-25 22:56:09.474934: val Epoch: [35][42/72]	Time  0.929 ( 0.629)	Data  0.806 ( 0.503)	Loss 5.2727e-02 (1.2806e-01) 
2023-05-25 22:56:09.755307: val Epoch: [35][43/72]	Time  0.280 ( 0.621)	Data  0.159 ( 0.495)	Loss 4.9581e-02 (1.2627e-01) 
2023-05-25 22:56:10.748288: val Epoch: [35][44/72]	Time  0.993 ( 0.630)	Data  0.868 ( 0.504)	Loss 3.5116e-01 (1.3127e-01) 
2023-05-25 22:56:11.017774: val Epoch: [35][45/72]	Time  0.269 ( 0.622)	Data  0.152 ( 0.496)	Loss 2.0039e-01 (1.3277e-01) 
2023-05-25 22:56:11.991861: val Epoch: [35][46/72]	Time  0.974 ( 0.629)	Data  0.856 ( 0.504)	Loss 5.5506e-02 (1.3113e-01) 
2023-05-25 22:56:12.203589: val Epoch: [35][47/72]	Time  0.212 ( 0.621)	Data  0.095 ( 0.495)	Loss 4.5505e-02 (1.2935e-01) 
2023-05-25 22:56:13.199337: val Epoch: [35][48/72]	Time  0.996 ( 0.628)	Data  0.875 ( 0.503)	Loss 4.2341e-01 (1.3535e-01) 
2023-05-25 22:56:13.458784: val Epoch: [35][49/72]	Time  0.259 ( 0.621)	Data  0.135 ( 0.495)	Loss 1.0762e-01 (1.3479e-01) 
2023-05-25 22:56:14.484371: val Epoch: [35][50/72]	Time  1.026 ( 0.629)	Data  0.900 ( 0.503)	Loss 5.9894e-02 (1.3332e-01) 
2023-05-25 22:56:14.679122: val Epoch: [35][51/72]	Time  0.195 ( 0.621)	Data  0.073 ( 0.495)	Loss 1.0592e-01 (1.3280e-01) 
2023-05-25 22:56:15.670412: val Epoch: [35][52/72]	Time  0.991 ( 0.627)	Data  0.868 ( 0.502)	Loss 5.9682e-02 (1.3142e-01) 
2023-05-25 22:56:15.928182: val Epoch: [35][53/72]	Time  0.258 ( 0.621)	Data  0.137 ( 0.495)	Loss 7.1509e-02 (1.3031e-01) 
2023-05-25 22:56:16.874079: val Epoch: [35][54/72]	Time  0.946 ( 0.627)	Data  0.823 ( 0.501)	Loss 8.4160e-02 (1.2947e-01) 
2023-05-25 22:56:17.143949: val Epoch: [35][55/72]	Time  0.270 ( 0.620)	Data  0.149 ( 0.495)	Loss 4.0032e-02 (1.2787e-01) 
2023-05-25 22:56:18.094114: val Epoch: [35][56/72]	Time  0.950 ( 0.626)	Data  0.827 ( 0.501)	Loss 1.1887e-01 (1.2771e-01) 
2023-05-25 22:56:18.393489: val Epoch: [35][57/72]	Time  0.299 ( 0.620)	Data  0.178 ( 0.495)	Loss 1.1726e-01 (1.2753e-01) 
2023-05-25 22:56:19.341529: val Epoch: [35][58/72]	Time  0.948 ( 0.626)	Data  0.825 ( 0.501)	Loss 1.2234e-01 (1.2745e-01) 
2023-05-25 22:56:19.628223: val Epoch: [35][59/72]	Time  0.287 ( 0.620)	Data  0.163 ( 0.495)	Loss 7.8301e-02 (1.2663e-01) 
2023-05-25 22:56:20.596934: val Epoch: [35][60/72]	Time  0.969 ( 0.626)	Data  0.843 ( 0.501)	Loss 2.1618e-01 (1.2810e-01) 
2023-05-25 22:56:20.911630: val Epoch: [35][61/72]	Time  0.315 ( 0.621)	Data  0.194 ( 0.496)	Loss 7.7951e-02 (1.2729e-01) 
2023-05-25 22:56:21.826778: val Epoch: [35][62/72]	Time  0.915 ( 0.626)	Data  0.793 ( 0.501)	Loss 6.0986e-02 (1.2623e-01) 
2023-05-25 22:56:22.147497: val Epoch: [35][63/72]	Time  0.321 ( 0.621)	Data  0.197 ( 0.496)	Loss 8.2847e-02 (1.2556e-01) 
2023-05-25 22:56:23.093524: val Epoch: [35][64/72]	Time  0.946 ( 0.626)	Data  0.824 ( 0.501)	Loss 2.7750e-01 (1.2789e-01) 
2023-05-25 22:56:23.374991: val Epoch: [35][65/72]	Time  0.281 ( 0.621)	Data  0.157 ( 0.496)	Loss 7.5991e-02 (1.2711e-01) 
2023-05-25 22:56:24.363030: val Epoch: [35][66/72]	Time  0.988 ( 0.626)	Data  0.861 ( 0.501)	Loss 6.8632e-01 (1.3545e-01) 
2023-05-25 22:56:24.636699: val Epoch: [35][67/72]	Time  0.274 ( 0.621)	Data  0.150 ( 0.496)	Loss 9.2120e-02 (1.3482e-01) 
2023-05-25 22:56:25.584800: val Epoch: [35][68/72]	Time  0.948 ( 0.626)	Data  0.826 ( 0.501)	Loss 5.8513e-02 (1.3371e-01) 
2023-05-25 22:56:25.883766: val Epoch: [35][69/72]	Time  0.299 ( 0.621)	Data  0.175 ( 0.496)	Loss 9.3048e-02 (1.3313e-01) 
2023-05-25 22:56:26.793442: val Epoch: [35][70/72]	Time  0.910 ( 0.625)	Data  0.783 ( 0.500)	Loss 6.7124e-02 (1.3220e-01) 
2023-05-25 22:56:27.021465: val Epoch: [35][71/72]	Time  0.228 ( 0.620)	Data  0.108 ( 0.495)	Loss 1.7681e-01 (1.3282e-01) 
2023-05-25 22:56:27.206323: Epoch 35 :Val : ['ET : 0.730835497379303', 'TC : 0.7846794128417969', 'WT : 0.8507794737815857'] 
2023-05-25 22:56:27.209082: Epoch 35 :Val : ['ET : 0.730835497379303', 'TC : 0.7846794128417969', 'WT : 0.8507794737815857'] 
2023-05-25 22:56:27.210817: Saving the model with DSC 0.7955071926116943 
2023-05-25 22:56:27.890337: Val epoch done in 46.23284557599982 s 
2023-05-25 22:56:27.896012: Batches per epoch:  129 
2023-05-25 22:56:32.757078: train Epoch: [36][  0/129]	Time  4.861 ( 4.861)	Data  3.871 ( 3.871)	Loss 7.9649e-02 (7.9649e-02) 
2023-05-25 22:56:33.707069: train Epoch: [36][  1/129]	Time  0.950 ( 2.905)	Data  0.001 ( 1.936)	Loss 5.9208e-02 (6.9429e-02) 
2023-05-25 22:56:36.366223: train Epoch: [36][  2/129]	Time  2.659 ( 2.823)	Data  1.697 ( 1.856)	Loss 6.7967e-02 (6.8941e-02) 
2023-05-25 22:56:37.319508: train Epoch: [36][  3/129]	Time  0.953 ( 2.356)	Data  0.001 ( 1.392)	Loss 1.5791e-01 (9.1183e-02) 
2023-05-25 22:56:40.097239: train Epoch: [36][  4/129]	Time  2.778 ( 2.440)	Data  1.818 ( 1.478)	Loss 1.5117e-01 (1.0318e-01) 
2023-05-25 22:56:41.049988: train Epoch: [36][  5/129]	Time  0.953 ( 2.192)	Data  0.001 ( 1.232)	Loss 6.3664e-02 (9.6595e-02) 
2023-05-25 22:56:43.755019: train Epoch: [36][  6/129]	Time  2.705 ( 2.266)	Data  1.756 ( 1.306)	Loss 9.2676e-02 (9.6035e-02) 
2023-05-25 22:56:44.717513: train Epoch: [36][  7/129]	Time  0.962 ( 2.103)	Data  0.001 ( 1.143)	Loss 7.6586e-02 (9.3604e-02) 
2023-05-25 22:56:47.357452: train Epoch: [36][  8/129]	Time  2.640 ( 2.162)	Data  1.679 ( 1.203)	Loss 7.7999e-02 (9.1870e-02) 
2023-05-25 22:56:48.320833: train Epoch: [36][  9/129]	Time  0.963 ( 2.042)	Data  0.001 ( 1.083)	Loss 7.8224e-02 (9.0505e-02) 
2023-05-25 22:56:50.953792: train Epoch: [36][ 10/129]	Time  2.633 ( 2.096)	Data  1.662 ( 1.135)	Loss 6.6516e-02 (8.8325e-02) 
2023-05-25 22:56:51.915240: train Epoch: [36][ 11/129]	Time  0.961 ( 2.002)	Data  0.001 ( 1.041)	Loss 9.9031e-02 (8.9217e-02) 
2023-05-25 22:56:54.534418: train Epoch: [36][ 12/129]	Time  2.619 ( 2.049)	Data  1.659 ( 1.088)	Loss 7.7896e-02 (8.8346e-02) 
2023-05-25 22:56:55.497007: train Epoch: [36][ 13/129]	Time  0.963 ( 1.971)	Data  0.001 ( 1.011)	Loss 1.1753e-01 (9.0430e-02) 
2023-05-25 22:56:58.241358: train Epoch: [36][ 14/129]	Time  2.744 ( 2.023)	Data  1.784 ( 1.062)	Loss 1.2232e-01 (9.2556e-02) 
2023-05-25 22:56:59.204045: train Epoch: [36][ 15/129]	Time  0.963 ( 1.957)	Data  0.001 ( 0.996)	Loss 6.8953e-02 (9.1081e-02) 
2023-05-25 22:57:01.905303: train Epoch: [36][ 16/129]	Time  2.701 ( 2.001)	Data  1.741 ( 1.040)	Loss 7.5331e-02 (9.0154e-02) 
2023-05-25 22:57:02.867160: train Epoch: [36][ 17/129]	Time  0.962 ( 1.943)	Data  0.001 ( 0.982)	Loss 6.2411e-02 (8.8613e-02) 
2023-05-25 22:57:05.565180: train Epoch: [36][ 18/129]	Time  2.698 ( 1.983)	Data  1.740 ( 1.022)	Loss 1.0322e-01 (8.9382e-02) 
2023-05-25 22:57:06.527399: train Epoch: [36][ 19/129]	Time  0.962 ( 1.932)	Data  0.001 ( 0.971)	Loss 1.7440e-01 (9.3633e-02) 
2023-05-25 22:57:09.161873: train Epoch: [36][ 20/129]	Time  2.634 ( 1.965)	Data  1.676 ( 1.004)	Loss 8.6421e-02 (9.3289e-02) 
2023-05-25 22:57:10.124844: train Epoch: [36][ 21/129]	Time  0.963 ( 1.919)	Data  0.001 ( 0.959)	Loss 1.2681e-01 (9.4813e-02) 
2023-05-25 22:57:12.731113: train Epoch: [36][ 22/129]	Time  2.606 ( 1.949)	Data  1.648 ( 0.989)	Loss 1.1453e-01 (9.5670e-02) 
2023-05-25 22:57:13.692395: train Epoch: [36][ 23/129]	Time  0.961 ( 1.908)	Data  0.001 ( 0.948)	Loss 8.2378e-02 (9.5117e-02) 
2023-05-25 22:57:16.419923: train Epoch: [36][ 24/129]	Time  2.728 ( 1.941)	Data  1.769 ( 0.980)	Loss 8.5641e-02 (9.4738e-02) 
2023-05-25 22:57:17.380953: train Epoch: [36][ 25/129]	Time  0.961 ( 1.903)	Data  0.001 ( 0.943)	Loss 6.7513e-02 (9.3690e-02) 
2023-05-25 22:57:20.054736: train Epoch: [36][ 26/129]	Time  2.674 ( 1.932)	Data  1.714 ( 0.971)	Loss 1.2338e-01 (9.4790e-02) 
2023-05-25 22:57:21.018083: train Epoch: [36][ 27/129]	Time  0.963 ( 1.897)	Data  0.001 ( 0.937)	Loss 9.0234e-02 (9.4627e-02) 
2023-05-25 22:57:23.648832: train Epoch: [36][ 28/129]	Time  2.631 ( 1.922)	Data  1.672 ( 0.962)	Loss 1.0103e-01 (9.4848e-02) 
2023-05-25 22:57:24.609815: train Epoch: [36][ 29/129]	Time  0.961 ( 1.890)	Data  0.001 ( 0.930)	Loss 8.5997e-02 (9.4553e-02) 
2023-05-25 22:57:27.221447: train Epoch: [36][ 30/129]	Time  2.612 ( 1.914)	Data  1.651 ( 0.953)	Loss 7.5947e-02 (9.3953e-02) 
2023-05-25 22:57:28.182905: train Epoch: [36][ 31/129]	Time  0.961 ( 1.884)	Data  0.001 ( 0.924)	Loss 7.8709e-02 (9.3477e-02) 
2023-05-25 22:57:30.854889: train Epoch: [36][ 32/129]	Time  2.672 ( 1.908)	Data  1.712 ( 0.947)	Loss 7.2781e-02 (9.2849e-02) 
2023-05-25 22:57:31.816106: train Epoch: [36][ 33/129]	Time  0.961 ( 1.880)	Data  0.001 ( 0.920)	Loss 9.2773e-02 (9.2847e-02) 
2023-05-25 22:57:34.688478: train Epoch: [36][ 34/129]	Time  2.872 ( 1.908)	Data  1.916 ( 0.948)	Loss 1.2093e-01 (9.3650e-02) 
2023-05-25 22:57:35.636834: train Epoch: [36][ 35/129]	Time  0.948 ( 1.882)	Data  0.001 ( 0.922)	Loss 9.3582e-02 (9.3648e-02) 
2023-05-25 22:57:38.221053: train Epoch: [36][ 36/129]	Time  2.584 ( 1.901)	Data  1.637 ( 0.941)	Loss 6.9942e-02 (9.3007e-02) 
2023-05-25 22:57:39.171720: train Epoch: [36][ 37/129]	Time  0.951 ( 1.876)	Data  0.001 ( 0.916)	Loss 1.1494e-01 (9.3584e-02) 
2023-05-25 22:57:41.896389: train Epoch: [36][ 38/129]	Time  2.725 ( 1.897)	Data  1.780 ( 0.938)	Loss 1.1591e-01 (9.4157e-02) 
2023-05-25 22:57:42.847399: train Epoch: [36][ 39/129]	Time  0.951 ( 1.874)	Data  0.001 ( 0.915)	Loss 1.3365e-01 (9.5144e-02) 
2023-05-25 22:57:45.658589: train Epoch: [36][ 40/129]	Time  2.811 ( 1.897)	Data  1.867 ( 0.938)	Loss 6.3404e-02 (9.4370e-02) 
2023-05-25 22:57:46.606021: train Epoch: [36][ 41/129]	Time  0.947 ( 1.874)	Data  0.001 ( 0.916)	Loss 7.7252e-02 (9.3962e-02) 
2023-05-25 22:57:49.276911: train Epoch: [36][ 42/129]	Time  2.671 ( 1.893)	Data  1.727 ( 0.935)	Loss 7.6338e-02 (9.3552e-02) 
2023-05-25 22:57:50.227547: train Epoch: [36][ 43/129]	Time  0.951 ( 1.871)	Data  0.001 ( 0.914)	Loss 6.7132e-02 (9.2952e-02) 
2023-05-25 22:57:52.913928: train Epoch: [36][ 44/129]	Time  2.686 ( 1.889)	Data  1.741 ( 0.932)	Loss 6.4685e-02 (9.2324e-02) 
2023-05-25 22:57:53.864592: train Epoch: [36][ 45/129]	Time  0.951 ( 1.869)	Data  0.001 ( 0.912)	Loss 7.3296e-02 (9.1910e-02) 
2023-05-25 22:57:56.503099: train Epoch: [36][ 46/129]	Time  2.639 ( 1.885)	Data  1.682 ( 0.928)	Loss 6.3102e-02 (9.1297e-02) 
2023-05-25 22:57:57.464269: train Epoch: [36][ 47/129]	Time  0.961 ( 1.866)	Data  0.001 ( 0.909)	Loss 5.4387e-02 (9.0528e-02) 
2023-05-25 22:58:00.049866: train Epoch: [36][ 48/129]	Time  2.586 ( 1.881)	Data  1.631 ( 0.924)	Loss 7.0466e-02 (9.0119e-02) 
2023-05-25 22:58:01.011263: train Epoch: [36][ 49/129]	Time  0.961 ( 1.862)	Data  0.001 ( 0.905)	Loss 3.4899e-02 (8.9014e-02) 
2023-05-25 22:58:03.742106: train Epoch: [36][ 50/129]	Time  2.731 ( 1.879)	Data  1.785 ( 0.922)	Loss 5.5204e-02 (8.8351e-02) 
2023-05-25 22:58:04.692657: train Epoch: [36][ 51/129]	Time  0.951 ( 1.861)	Data  0.001 ( 0.905)	Loss 7.3328e-02 (8.8062e-02) 
2023-05-25 22:58:07.392035: train Epoch: [36][ 52/129]	Time  2.699 ( 1.877)	Data  1.753 ( 0.921)	Loss 1.2222e-01 (8.8707e-02) 
2023-05-25 22:58:08.342561: train Epoch: [36][ 53/129]	Time  0.951 ( 1.860)	Data  0.001 ( 0.904)	Loss 1.0341e-01 (8.8979e-02) 
2023-05-25 22:58:11.028162: train Epoch: [36][ 54/129]	Time  2.686 ( 1.875)	Data  1.740 ( 0.919)	Loss 8.9303e-02 (8.8985e-02) 
2023-05-25 22:58:11.977872: train Epoch: [36][ 55/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.902)	Loss 7.0715e-02 (8.8659e-02) 
2023-05-25 22:58:14.620914: train Epoch: [36][ 56/129]	Time  2.643 ( 1.872)	Data  1.689 ( 0.916)	Loss 8.7599e-02 (8.8640e-02) 
2023-05-25 22:58:15.583322: train Epoch: [36][ 57/129]	Time  0.962 ( 1.857)	Data  0.001 ( 0.900)	Loss 1.5848e-01 (8.9844e-02) 
2023-05-25 22:58:18.271238: train Epoch: [36][ 58/129]	Time  2.688 ( 1.871)	Data  1.733 ( 0.915)	Loss 1.0799e-01 (9.0152e-02) 
2023-05-25 22:58:19.232460: train Epoch: [36][ 59/129]	Time  0.961 ( 1.856)	Data  0.001 ( 0.899)	Loss 7.1196e-02 (8.9836e-02) 
2023-05-25 22:58:21.878811: train Epoch: [36][ 60/129]	Time  2.646 ( 1.869)	Data  1.694 ( 0.912)	Loss 6.0711e-02 (8.9359e-02) 
2023-05-25 22:58:22.828501: train Epoch: [36][ 61/129]	Time  0.950 ( 1.854)	Data  0.001 ( 0.898)	Loss 7.6458e-02 (8.9150e-02) 
2023-05-25 22:58:25.387313: train Epoch: [36][ 62/129]	Time  2.559 ( 1.865)	Data  1.611 ( 0.909)	Loss 6.9519e-02 (8.8839e-02) 
2023-05-25 22:58:26.337124: train Epoch: [36][ 63/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.895)	Loss 1.7357e-01 (9.0163e-02) 
2023-05-25 22:58:28.957193: train Epoch: [36][ 64/129]	Time  2.620 ( 1.862)	Data  1.672 ( 0.907)	Loss 1.5565e-01 (9.1170e-02) 
2023-05-25 22:58:29.907157: train Epoch: [36][ 65/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.893)	Loss 5.9903e-02 (9.0697e-02) 
2023-05-25 22:58:32.590595: train Epoch: [36][ 66/129]	Time  2.683 ( 1.861)	Data  1.734 ( 0.906)	Loss 9.1170e-02 (9.0704e-02) 
2023-05-25 22:58:33.542511: train Epoch: [36][ 67/129]	Time  0.952 ( 1.848)	Data  0.001 ( 0.892)	Loss 6.3747e-02 (9.0307e-02) 
2023-05-25 22:58:36.225220: train Epoch: [36][ 68/129]	Time  2.683 ( 1.860)	Data  1.734 ( 0.904)	Loss 1.0815e-01 (9.0566e-02) 
2023-05-25 22:58:37.176553: train Epoch: [36][ 69/129]	Time  0.951 ( 1.847)	Data  0.001 ( 0.892)	Loss 8.1708e-02 (9.0439e-02) 
2023-05-25 22:58:39.855397: train Epoch: [36][ 70/129]	Time  2.679 ( 1.859)	Data  1.732 ( 0.903)	Loss 5.3084e-02 (8.9913e-02) 
2023-05-25 22:58:40.805408: train Epoch: [36][ 71/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.891)	Loss 8.9214e-02 (8.9903e-02) 
2023-05-25 22:58:43.485239: train Epoch: [36][ 72/129]	Time  2.680 ( 1.857)	Data  1.727 ( 0.902)	Loss 7.6392e-02 (8.9718e-02) 
2023-05-25 22:58:44.435113: train Epoch: [36][ 73/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.890)	Loss 8.6051e-02 (8.9669e-02) 
2023-05-25 22:58:47.049283: train Epoch: [36][ 74/129]	Time  2.614 ( 1.855)	Data  1.665 ( 0.900)	Loss 4.5497e-02 (8.9080e-02) 
2023-05-25 22:58:47.999392: train Epoch: [36][ 75/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.889)	Loss 1.0993e-01 (8.9354e-02) 
2023-05-25 22:58:50.721248: train Epoch: [36][ 76/129]	Time  2.722 ( 1.855)	Data  1.772 ( 0.900)	Loss 1.4790e-01 (9.0115e-02) 
2023-05-25 22:58:51.671418: train Epoch: [36][ 77/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.889)	Loss 9.6797e-02 (9.0200e-02) 
2023-05-25 22:58:54.223820: train Epoch: [36][ 78/129]	Time  2.552 ( 1.852)	Data  1.601 ( 0.898)	Loss 6.5248e-02 (8.9884e-02) 
2023-05-25 22:58:55.184863: train Epoch: [36][ 79/129]	Time  0.961 ( 1.841)	Data  0.001 ( 0.886)	Loss 1.1326e-01 (9.0177e-02) 
2023-05-25 22:58:57.811872: train Epoch: [36][ 80/129]	Time  2.627 ( 1.851)	Data  1.668 ( 0.896)	Loss 7.8981e-02 (9.0038e-02) 
2023-05-25 22:58:58.773109: train Epoch: [36][ 81/129]	Time  0.961 ( 1.840)	Data  0.001 ( 0.885)	Loss 5.8840e-02 (8.9658e-02) 
2023-05-25 22:59:01.493509: train Epoch: [36][ 82/129]	Time  2.720 ( 1.851)	Data  1.755 ( 0.896)	Loss 9.1463e-02 (8.9680e-02) 
2023-05-25 22:59:02.455039: train Epoch: [36][ 83/129]	Time  0.962 ( 1.840)	Data  0.001 ( 0.885)	Loss 5.5332e-02 (8.9271e-02) 
2023-05-25 22:59:05.086104: train Epoch: [36][ 84/129]	Time  2.631 ( 1.849)	Data  1.676 ( 0.894)	Loss 8.1080e-02 (8.9174e-02) 
2023-05-25 22:59:06.036737: train Epoch: [36][ 85/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.884)	Loss 1.1476e-01 (8.9472e-02) 
2023-05-25 22:59:08.746138: train Epoch: [36][ 86/129]	Time  2.709 ( 1.849)	Data  1.760 ( 0.894)	Loss 6.9475e-02 (8.9242e-02) 
2023-05-25 22:59:09.696574: train Epoch: [36][ 87/129]	Time  0.950 ( 1.839)	Data  0.001 ( 0.884)	Loss 7.7032e-02 (8.9103e-02) 
2023-05-25 22:59:12.403454: train Epoch: [36][ 88/129]	Time  2.707 ( 1.848)	Data  1.755 ( 0.894)	Loss 7.1380e-02 (8.8904e-02) 
2023-05-25 22:59:13.353075: train Epoch: [36][ 89/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.884)	Loss 9.4376e-02 (8.8965e-02) 
2023-05-25 22:59:16.089551: train Epoch: [36][ 90/129]	Time  2.736 ( 1.848)	Data  1.789 ( 0.894)	Loss 1.1681e-01 (8.9271e-02) 
2023-05-25 22:59:17.040759: train Epoch: [36][ 91/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.884)	Loss 1.2166e-01 (8.9623e-02) 
2023-05-25 22:59:19.616815: train Epoch: [36][ 92/129]	Time  2.576 ( 1.846)	Data  1.616 ( 0.892)	Loss 1.0858e-01 (8.9827e-02) 
2023-05-25 22:59:20.578639: train Epoch: [36][ 93/129]	Time  0.962 ( 1.837)	Data  0.001 ( 0.882)	Loss 7.4010e-02 (8.9659e-02) 
2023-05-25 22:59:23.226050: train Epoch: [36][ 94/129]	Time  2.647 ( 1.846)	Data  1.683 ( 0.891)	Loss 8.3348e-02 (8.9592e-02) 
2023-05-25 22:59:24.187376: train Epoch: [36][ 95/129]	Time  0.961 ( 1.836)	Data  0.001 ( 0.881)	Loss 1.0838e-01 (8.9788e-02) 
2023-05-25 22:59:26.835308: train Epoch: [36][ 96/129]	Time  2.648 ( 1.845)	Data  1.688 ( 0.890)	Loss 1.1229e-01 (9.0020e-02) 
2023-05-25 22:59:27.796362: train Epoch: [36][ 97/129]	Time  0.961 ( 1.836)	Data  0.001 ( 0.881)	Loss 6.8693e-02 (8.9802e-02) 
2023-05-25 22:59:30.499415: train Epoch: [36][ 98/129]	Time  2.703 ( 1.844)	Data  1.735 ( 0.889)	Loss 1.0240e-01 (8.9930e-02) 
2023-05-25 22:59:31.460259: train Epoch: [36][ 99/129]	Time  0.961 ( 1.836)	Data  0.001 ( 0.880)	Loss 8.5017e-02 (8.9880e-02) 
2023-05-25 22:59:34.100536: train Epoch: [36][100/129]	Time  2.640 ( 1.844)	Data  1.680 ( 0.888)	Loss 1.0540e-01 (9.0034e-02) 
2023-05-25 22:59:35.062664: train Epoch: [36][101/129]	Time  0.962 ( 1.835)	Data  0.001 ( 0.880)	Loss 7.1177e-02 (8.9849e-02) 
2023-05-25 22:59:37.807071: train Epoch: [36][102/129]	Time  2.744 ( 1.844)	Data  1.784 ( 0.888)	Loss 7.7882e-02 (8.9733e-02) 
2023-05-25 22:59:38.768893: train Epoch: [36][103/129]	Time  0.962 ( 1.835)	Data  0.001 ( 0.880)	Loss 1.4292e-01 (9.0244e-02) 
2023-05-25 22:59:41.414982: train Epoch: [36][104/129]	Time  2.646 ( 1.843)	Data  1.684 ( 0.888)	Loss 6.2999e-02 (8.9985e-02) 
2023-05-25 22:59:42.375328: train Epoch: [36][105/129]	Time  0.960 ( 1.835)	Data  0.001 ( 0.879)	Loss 5.0113e-02 (8.9609e-02) 
2023-05-25 22:59:45.026033: train Epoch: [36][106/129]	Time  2.651 ( 1.842)	Data  1.688 ( 0.887)	Loss 4.8177e-02 (8.9222e-02) 
2023-05-25 22:59:45.985577: train Epoch: [36][107/129]	Time  0.960 ( 1.834)	Data  0.001 ( 0.879)	Loss 2.0462e-01 (9.0290e-02) 
2023-05-25 22:59:48.613213: train Epoch: [36][108/129]	Time  2.628 ( 1.841)	Data  1.668 ( 0.886)	Loss 1.0441e-01 (9.0420e-02) 
2023-05-25 22:59:49.575565: train Epoch: [36][109/129]	Time  0.962 ( 1.833)	Data  0.001 ( 0.878)	Loss 1.1756e-01 (9.0666e-02) 
2023-05-25 22:59:52.241583: train Epoch: [36][110/129]	Time  2.666 ( 1.841)	Data  1.701 ( 0.885)	Loss 7.0178e-02 (9.0482e-02) 
2023-05-25 22:59:53.202997: train Epoch: [36][111/129]	Time  0.961 ( 1.833)	Data  0.001 ( 0.877)	Loss 8.9321e-02 (9.0471e-02) 
2023-05-25 22:59:55.951637: train Epoch: [36][112/129]	Time  2.749 ( 1.841)	Data  1.778 ( 0.885)	Loss 9.3314e-02 (9.0497e-02) 
2023-05-25 22:59:56.912355: train Epoch: [36][113/129]	Time  0.961 ( 1.833)	Data  0.001 ( 0.877)	Loss 9.7360e-02 (9.0557e-02) 
2023-05-25 22:59:59.594678: train Epoch: [36][114/129]	Time  2.682 ( 1.841)	Data  1.732 ( 0.885)	Loss 5.4409e-02 (9.0243e-02) 
2023-05-25 23:00:00.545635: train Epoch: [36][115/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.877)	Loss 7.9556e-02 (9.0150e-02) 
2023-05-25 23:00:03.306635: train Epoch: [36][116/129]	Time  2.761 ( 1.841)	Data  1.807 ( 0.885)	Loss 6.3098e-02 (8.9919e-02) 
2023-05-25 23:00:04.257174: train Epoch: [36][117/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.878)	Loss 7.1833e-02 (8.9766e-02) 
2023-05-25 23:00:06.896073: train Epoch: [36][118/129]	Time  2.639 ( 1.840)	Data  1.687 ( 0.885)	Loss 7.2875e-02 (8.9624e-02) 
2023-05-25 23:00:07.846162: train Epoch: [36][119/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.877)	Loss 1.0825e-01 (8.9779e-02) 
2023-05-25 23:00:10.516554: train Epoch: [36][120/129]	Time  2.670 ( 1.840)	Data  1.722 ( 0.884)	Loss 6.1798e-02 (8.9548e-02) 
2023-05-25 23:00:11.467846: train Epoch: [36][121/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.877)	Loss 9.5723e-02 (8.9599e-02) 
2023-05-25 23:00:14.214810: train Epoch: [36][122/129]	Time  2.747 ( 1.840)	Data  1.798 ( 0.884)	Loss 6.7698e-02 (8.9420e-02) 
2023-05-25 23:00:15.169111: train Epoch: [36][123/129]	Time  0.954 ( 1.833)	Data  0.001 ( 0.877)	Loss 5.1975e-02 (8.9118e-02) 
2023-05-25 23:00:17.898111: train Epoch: [36][124/129]	Time  2.729 ( 1.840)	Data  1.772 ( 0.884)	Loss 1.1010e-01 (8.9286e-02) 
2023-05-25 23:00:18.856832: train Epoch: [36][125/129]	Time  0.959 ( 1.833)	Data  0.001 ( 0.877)	Loss 1.0250e-01 (8.9391e-02) 
2023-05-25 23:00:21.426127: train Epoch: [36][126/129]	Time  2.569 ( 1.839)	Data  1.611 ( 0.883)	Loss 8.6788e-02 (8.9371e-02) 
2023-05-25 23:00:22.381654: train Epoch: [36][127/129]	Time  0.956 ( 1.832)	Data  0.001 ( 0.876)	Loss 8.2330e-02 (8.9316e-02) 
2023-05-25 23:00:23.872486: train Epoch: [36][128/129]	Time  1.491 ( 1.829)	Data  0.536 ( 0.874)	Loss 7.0841e-02 (8.9172e-02) 
2023-05-25 23:00:23.903714: Train Epoch done in 236.007743047001 s 
2023-05-25 23:00:26.216007: val Epoch: [36][ 0/72]	Time  1.553 ( 1.553)	Data  1.340 ( 1.340)	Loss 9.5330e-02 (9.5330e-02) 
2023-05-25 23:00:26.341775: val Epoch: [36][ 1/72]	Time  0.126 ( 0.839)	Data  0.001 ( 0.671)	Loss 1.6449e-01 (1.2991e-01) 
2023-05-25 23:00:27.282830: val Epoch: [36][ 2/72]	Time  0.941 ( 0.873)	Data  0.810 ( 0.717)	Loss 7.1812e-02 (1.1054e-01) 
2023-05-25 23:00:27.408901: val Epoch: [36][ 3/72]	Time  0.126 ( 0.686)	Data  0.001 ( 0.538)	Loss 7.3717e-02 (1.0134e-01) 
2023-05-25 23:00:28.481735: val Epoch: [36][ 4/72]	Time  1.073 ( 0.764)	Data  0.946 ( 0.620)	Loss 2.2597e-01 (1.2626e-01) 
2023-05-25 23:00:28.670222: val Epoch: [36][ 5/72]	Time  0.188 ( 0.668)	Data  0.063 ( 0.527)	Loss 5.5182e-02 (1.1442e-01) 
2023-05-25 23:00:29.713653: val Epoch: [36][ 6/72]	Time  1.043 ( 0.721)	Data  0.917 ( 0.583)	Loss 2.4152e-01 (1.3257e-01) 
2023-05-25 23:00:29.913178: val Epoch: [36][ 7/72]	Time  0.200 ( 0.656)	Data  0.075 ( 0.519)	Loss 8.5962e-02 (1.2675e-01) 
2023-05-25 23:00:30.905504: val Epoch: [36][ 8/72]	Time  0.992 ( 0.694)	Data  0.866 ( 0.558)	Loss 6.7588e-02 (1.2017e-01) 
2023-05-25 23:00:31.182543: val Epoch: [36][ 9/72]	Time  0.277 ( 0.652)	Data  0.152 ( 0.517)	Loss 5.3634e-02 (1.1352e-01) 
2023-05-25 23:00:32.125385: val Epoch: [36][10/72]	Time  0.943 ( 0.678)	Data  0.817 ( 0.544)	Loss 2.1652e-01 (1.2288e-01) 
2023-05-25 23:00:32.390659: val Epoch: [36][11/72]	Time  0.265 ( 0.644)	Data  0.141 ( 0.511)	Loss 6.8580e-02 (1.1836e-01) 
2023-05-25 23:00:33.338065: val Epoch: [36][12/72]	Time  0.947 ( 0.667)	Data  0.822 ( 0.535)	Loss 9.9368e-02 (1.1690e-01) 
2023-05-25 23:00:33.615747: val Epoch: [36][13/72]	Time  0.278 ( 0.639)	Data  0.153 ( 0.507)	Loss 1.5367e-01 (1.1952e-01) 
2023-05-25 23:00:34.590086: val Epoch: [36][14/72]	Time  0.974 ( 0.662)	Data  0.849 ( 0.530)	Loss 1.3897e-01 (1.2082e-01) 
2023-05-25 23:00:34.848039: val Epoch: [36][15/72]	Time  0.258 ( 0.637)	Data  0.133 ( 0.505)	Loss 5.2892e-02 (1.1658e-01) 
2023-05-25 23:00:35.795235: val Epoch: [36][16/72]	Time  0.947 ( 0.655)	Data  0.821 ( 0.524)	Loss 8.0280e-02 (1.1444e-01) 
2023-05-25 23:00:36.098814: val Epoch: [36][17/72]	Time  0.304 ( 0.635)	Data  0.180 ( 0.505)	Loss 1.1442e-01 (1.1444e-01) 
2023-05-25 23:00:37.058040: val Epoch: [36][18/72]	Time  0.959 ( 0.652)	Data  0.834 ( 0.522)	Loss 7.8331e-02 (1.1254e-01) 
2023-05-25 23:00:37.345061: val Epoch: [36][19/72]	Time  0.287 ( 0.634)	Data  0.163 ( 0.504)	Loss 5.6948e-02 (1.0976e-01) 
2023-05-25 23:00:38.275727: val Epoch: [36][20/72]	Time  0.931 ( 0.648)	Data  0.804 ( 0.518)	Loss 1.1331e-01 (1.0993e-01) 
2023-05-25 23:00:38.549105: val Epoch: [36][21/72]	Time  0.273 ( 0.631)	Data  0.153 ( 0.502)	Loss 5.5050e-02 (1.0743e-01) 
2023-05-25 23:00:39.544912: val Epoch: [36][22/72]	Time  0.996 ( 0.647)	Data  0.870 ( 0.518)	Loss 7.5006e-02 (1.0602e-01) 
2023-05-25 23:00:39.765578: val Epoch: [36][23/72]	Time  0.221 ( 0.629)	Data  0.096 ( 0.500)	Loss 3.5940e-02 (1.0310e-01) 
2023-05-25 23:00:40.789929: val Epoch: [36][24/72]	Time  1.024 ( 0.645)	Data  0.901 ( 0.516)	Loss 6.1007e-02 (1.0142e-01) 
2023-05-25 23:00:41.008468: val Epoch: [36][25/72]	Time  0.219 ( 0.629)	Data  0.099 ( 0.500)	Loss 3.1937e-01 (1.0980e-01) 
2023-05-25 23:00:41.994317: val Epoch: [36][26/72]	Time  0.986 ( 0.642)	Data  0.868 ( 0.514)	Loss 6.3363e-02 (1.0808e-01) 
2023-05-25 23:00:42.275868: val Epoch: [36][27/72]	Time  0.282 ( 0.629)	Data  0.157 ( 0.501)	Loss 6.8786e-02 (1.0668e-01) 
2023-05-25 23:00:43.219336: val Epoch: [36][28/72]	Time  0.943 ( 0.640)	Data  0.820 ( 0.512)	Loss 8.1088e-02 (1.0580e-01) 
2023-05-25 23:00:43.485856: val Epoch: [36][29/72]	Time  0.267 ( 0.627)	Data  0.142 ( 0.500)	Loss 5.2689e-02 (1.0403e-01) 
2023-05-25 23:00:44.452801: val Epoch: [36][30/72]	Time  0.967 ( 0.638)	Data  0.840 ( 0.511)	Loss 1.4446e-01 (1.0533e-01) 
2023-05-25 23:00:44.730339: val Epoch: [36][31/72]	Time  0.278 ( 0.627)	Data  0.153 ( 0.500)	Loss 4.1738e-01 (1.1508e-01) 
2023-05-25 23:00:45.686020: val Epoch: [36][32/72]	Time  0.956 ( 0.637)	Data  0.833 ( 0.510)	Loss 5.2842e-02 (1.1320e-01) 
2023-05-25 23:00:45.980986: val Epoch: [36][33/72]	Time  0.295 ( 0.627)	Data  0.174 ( 0.500)	Loss 3.3840e-01 (1.1982e-01) 
2023-05-25 23:00:46.913604: val Epoch: [36][34/72]	Time  0.933 ( 0.636)	Data  0.810 ( 0.509)	Loss 9.0846e-02 (1.1899e-01) 
2023-05-25 23:00:47.203907: val Epoch: [36][35/72]	Time  0.290 ( 0.626)	Data  0.169 ( 0.499)	Loss 3.4023e-01 (1.2514e-01) 
2023-05-25 23:00:48.188546: val Epoch: [36][36/72]	Time  0.985 ( 0.636)	Data  0.862 ( 0.509)	Loss 3.6359e-01 (1.3158e-01) 
2023-05-25 23:00:48.403358: val Epoch: [36][37/72]	Time  0.215 ( 0.625)	Data  0.090 ( 0.498)	Loss 1.2322e-01 (1.3136e-01) 
2023-05-25 23:00:49.434966: val Epoch: [36][38/72]	Time  1.032 ( 0.635)	Data  0.910 ( 0.509)	Loss 3.4640e-01 (1.3688e-01) 
2023-05-25 23:00:49.640248: val Epoch: [36][39/72]	Time  0.205 ( 0.624)	Data  0.081 ( 0.498)	Loss 2.6093e-01 (1.3998e-01) 
2023-05-25 23:00:50.618881: val Epoch: [36][40/72]	Time  0.979 ( 0.633)	Data  0.852 ( 0.507)	Loss 5.6219e-02 (1.3793e-01) 
2023-05-25 23:00:50.884209: val Epoch: [36][41/72]	Time  0.265 ( 0.624)	Data  0.140 ( 0.498)	Loss 1.1883e-01 (1.3748e-01) 
2023-05-25 23:00:51.847747: val Epoch: [36][42/72]	Time  0.964 ( 0.632)	Data  0.838 ( 0.506)	Loss 9.5558e-02 (1.3650e-01) 
2023-05-25 23:00:52.073723: val Epoch: [36][43/72]	Time  0.226 ( 0.623)	Data  0.101 ( 0.496)	Loss 8.9437e-02 (1.3543e-01) 
2023-05-25 23:00:53.053138: val Epoch: [36][44/72]	Time  0.979 ( 0.631)	Data  0.853 ( 0.504)	Loss 1.8347e-01 (1.3650e-01) 
2023-05-25 23:00:53.285008: val Epoch: [36][45/72]	Time  0.232 ( 0.622)	Data  0.108 ( 0.496)	Loss 6.2292e-02 (1.3489e-01) 
2023-05-25 23:00:54.247431: val Epoch: [36][46/72]	Time  0.962 ( 0.629)	Data  0.840 ( 0.503)	Loss 8.7652e-02 (1.3388e-01) 
2023-05-25 23:00:54.530900: val Epoch: [36][47/72]	Time  0.283 ( 0.622)	Data  0.159 ( 0.496)	Loss 1.4173e-01 (1.3405e-01) 
2023-05-25 23:00:55.468753: val Epoch: [36][48/72]	Time  0.938 ( 0.629)	Data  0.817 ( 0.503)	Loss 1.2519e-01 (1.3387e-01) 
2023-05-25 23:00:55.735088: val Epoch: [36][49/72]	Time  0.266 ( 0.621)	Data  0.147 ( 0.495)	Loss 7.0758e-02 (1.3260e-01) 
2023-05-25 23:00:56.709773: val Epoch: [36][50/72]	Time  0.975 ( 0.628)	Data  0.857 ( 0.502)	Loss 1.5415e-01 (1.3303e-01) 
2023-05-25 23:00:56.910691: val Epoch: [36][51/72]	Time  0.201 ( 0.620)	Data  0.082 ( 0.494)	Loss 5.0395e-02 (1.3144e-01) 
2023-05-25 23:00:57.933590: val Epoch: [36][52/72]	Time  1.023 ( 0.628)	Data  0.904 ( 0.502)	Loss 4.3236e-01 (1.3712e-01) 
2023-05-25 23:00:58.117701: val Epoch: [36][53/72]	Time  0.184 ( 0.620)	Data  0.065 ( 0.494)	Loss 1.9208e-01 (1.3813e-01) 
2023-05-25 23:00:59.182572: val Epoch: [36][54/72]	Time  1.065 ( 0.628)	Data  0.947 ( 0.502)	Loss 1.6556e-01 (1.3863e-01) 
2023-05-25 23:00:59.337794: val Epoch: [36][55/72]	Time  0.155 ( 0.619)	Data  0.038 ( 0.494)	Loss 3.5644e-01 (1.4252e-01) 
2023-05-25 23:01:00.324909: val Epoch: [36][56/72]	Time  0.987 ( 0.626)	Data  0.866 ( 0.500)	Loss 6.2747e-02 (1.4112e-01) 
2023-05-25 23:01:00.582832: val Epoch: [36][57/72]	Time  0.258 ( 0.619)	Data  0.139 ( 0.494)	Loss 1.1354e-01 (1.4065e-01) 
2023-05-25 23:01:01.550678: val Epoch: [36][58/72]	Time  0.968 ( 0.625)	Data  0.845 ( 0.500)	Loss 5.5246e-02 (1.3920e-01) 
2023-05-25 23:01:01.848516: val Epoch: [36][59/72]	Time  0.298 ( 0.620)	Data  0.176 ( 0.495)	Loss 1.3190e-01 (1.3908e-01) 
2023-05-25 23:01:02.789068: val Epoch: [36][60/72]	Time  0.941 ( 0.625)	Data  0.814 ( 0.500)	Loss 1.4589e-01 (1.3919e-01) 
2023-05-25 23:01:03.090845: val Epoch: [36][61/72]	Time  0.302 ( 0.620)	Data  0.178 ( 0.495)	Loss 5.8614e-02 (1.3789e-01) 
2023-05-25 23:01:03.981863: val Epoch: [36][62/72]	Time  0.891 ( 0.624)	Data  0.765 ( 0.499)	Loss 6.2843e-02 (1.3670e-01) 
2023-05-25 23:01:04.347539: val Epoch: [36][63/72]	Time  0.366 ( 0.620)	Data  0.241 ( 0.495)	Loss 1.0497e-01 (1.3620e-01) 
2023-05-25 23:01:05.232959: val Epoch: [36][64/72]	Time  0.885 ( 0.624)	Data  0.759 ( 0.499)	Loss 3.7908e-02 (1.3469e-01) 
2023-05-25 23:01:05.615486: val Epoch: [36][65/72]	Time  0.383 ( 0.620)	Data  0.259 ( 0.496)	Loss 7.4563e-02 (1.3378e-01) 
2023-05-25 23:01:06.534349: val Epoch: [36][66/72]	Time  0.919 ( 0.625)	Data  0.796 ( 0.500)	Loss 3.5147e-01 (1.3703e-01) 
2023-05-25 23:01:06.861218: val Epoch: [36][67/72]	Time  0.327 ( 0.621)	Data  0.203 ( 0.496)	Loss 3.9945e-01 (1.4089e-01) 
2023-05-25 23:01:07.749328: val Epoch: [36][68/72]	Time  0.888 ( 0.624)	Data  0.765 ( 0.500)	Loss 6.1515e-02 (1.3974e-01) 
2023-05-25 23:01:08.124955: val Epoch: [36][69/72]	Time  0.376 ( 0.621)	Data  0.254 ( 0.496)	Loss 8.9553e-02 (1.3902e-01) 
2023-05-25 23:01:09.007057: val Epoch: [36][70/72]	Time  0.882 ( 0.625)	Data  0.759 ( 0.500)	Loss 6.8974e-02 (1.3803e-01) 
2023-05-25 23:01:09.273660: val Epoch: [36][71/72]	Time  0.267 ( 0.620)	Data  0.146 ( 0.495)	Loss 1.4033e-01 (1.3807e-01) 
2023-05-25 23:01:09.460552: Epoch 36 :Val : ['ET : 0.6947440505027771', 'TC : 0.7748309373855591', 'WT : 0.8620646595954895'] 
2023-05-25 23:01:09.463309: Epoch 36 :Val : ['ET : 0.6947440505027771', 'TC : 0.7748309373855591', 'WT : 0.8620646595954895'] 
2023-05-25 23:01:09.465137: Val epoch done in 45.56142647199886 s 
2023-05-25 23:01:09.470541: Batches per epoch:  129 
2023-05-25 23:01:14.400077: train Epoch: [37][  0/129]	Time  4.929 ( 4.929)	Data  3.946 ( 3.946)	Loss 9.3901e-02 (9.3901e-02) 
2023-05-25 23:01:15.350251: train Epoch: [37][  1/129]	Time  0.950 ( 2.940)	Data  0.001 ( 1.974)	Loss 8.3687e-02 (8.8794e-02) 
2023-05-25 23:01:17.988930: train Epoch: [37][  2/129]	Time  2.639 ( 2.839)	Data  1.682 ( 1.877)	Loss 9.4526e-02 (9.0705e-02) 
2023-05-25 23:01:18.937239: train Epoch: [37][  3/129]	Time  0.948 ( 2.367)	Data  0.001 ( 1.408)	Loss 6.4178e-02 (8.4073e-02) 
2023-05-25 23:01:21.882763: train Epoch: [37][  4/129]	Time  2.946 ( 2.482)	Data  2.001 ( 1.526)	Loss 1.1436e-01 (9.0130e-02) 
2023-05-25 23:01:22.828583: train Epoch: [37][  5/129]	Time  0.946 ( 2.226)	Data  0.001 ( 1.272)	Loss 1.1284e-01 (9.3915e-02) 
2023-05-25 23:01:25.517212: train Epoch: [37][  6/129]	Time  2.689 ( 2.292)	Data  1.745 ( 1.340)	Loss 1.2468e-01 (9.8310e-02) 
2023-05-25 23:01:26.465743: train Epoch: [37][  7/129]	Time  0.949 ( 2.124)	Data  0.001 ( 1.172)	Loss 1.1363e-01 (1.0023e-01) 
2023-05-25 23:01:29.136356: train Epoch: [37][  8/129]	Time  2.671 ( 2.185)	Data  1.724 ( 1.234)	Loss 8.1236e-02 (9.8115e-02) 
2023-05-25 23:01:30.087955: train Epoch: [37][  9/129]	Time  0.952 ( 2.062)	Data  0.001 ( 1.110)	Loss 9.2574e-02 (9.7561e-02) 
2023-05-25 23:01:32.857219: train Epoch: [37][ 10/129]	Time  2.769 ( 2.126)	Data  1.813 ( 1.174)	Loss 5.4967e-02 (9.3689e-02) 
2023-05-25 23:01:33.805167: train Epoch: [37][ 11/129]	Time  0.948 ( 2.028)	Data  0.001 ( 1.076)	Loss 9.8084e-02 (9.4055e-02) 
2023-05-25 23:01:36.423779: train Epoch: [37][ 12/129]	Time  2.619 ( 2.073)	Data  1.663 ( 1.122)	Loss 5.4298e-02 (9.0997e-02) 
2023-05-25 23:01:37.374819: train Epoch: [37][ 13/129]	Time  0.951 ( 1.993)	Data  0.001 ( 1.042)	Loss 1.2896e-01 (9.3708e-02) 
2023-05-25 23:01:40.102818: train Epoch: [37][ 14/129]	Time  2.728 ( 2.042)	Data  1.771 ( 1.090)	Loss 7.4987e-02 (9.2460e-02) 
2023-05-25 23:01:41.051815: train Epoch: [37][ 15/129]	Time  0.949 ( 1.974)	Data  0.001 ( 1.022)	Loss 7.3800e-02 (9.1294e-02) 
2023-05-25 23:01:43.757094: train Epoch: [37][ 16/129]	Time  2.705 ( 2.017)	Data  1.759 ( 1.065)	Loss 5.9204e-02 (8.9406e-02) 
2023-05-25 23:01:44.707329: train Epoch: [37][ 17/129]	Time  0.950 ( 1.958)	Data  0.001 ( 1.006)	Loss 8.7989e-02 (8.9328e-02) 
2023-05-25 23:01:47.340904: train Epoch: [37][ 18/129]	Time  2.634 ( 1.993)	Data  1.689 ( 1.042)	Loss 6.0176e-02 (8.7793e-02) 
2023-05-25 23:01:48.287672: train Epoch: [37][ 19/129]	Time  0.947 ( 1.941)	Data  0.001 ( 0.990)	Loss 8.5318e-02 (8.7670e-02) 
2023-05-25 23:01:50.857225: train Epoch: [37][ 20/129]	Time  2.570 ( 1.971)	Data  1.624 ( 1.020)	Loss 7.1104e-02 (8.6881e-02) 
2023-05-25 23:01:51.805465: train Epoch: [37][ 21/129]	Time  0.948 ( 1.924)	Data  0.001 ( 0.974)	Loss 8.1950e-02 (8.6657e-02) 
2023-05-25 23:01:54.296756: train Epoch: [37][ 22/129]	Time  2.491 ( 1.949)	Data  1.547 ( 0.999)	Loss 6.5619e-02 (8.5742e-02) 
2023-05-25 23:01:55.246444: train Epoch: [37][ 23/129]	Time  0.950 ( 1.907)	Data  0.001 ( 0.957)	Loss 6.5256e-02 (8.4888e-02) 
2023-05-25 23:01:57.869522: train Epoch: [37][ 24/129]	Time  2.623 ( 1.936)	Data  1.678 ( 0.986)	Loss 3.8532e-02 (8.3034e-02) 
2023-05-25 23:01:58.818120: train Epoch: [37][ 25/129]	Time  0.949 ( 1.898)	Data  0.001 ( 0.948)	Loss 4.7068e-02 (8.1651e-02) 
2023-05-25 23:02:01.460891: train Epoch: [37][ 26/129]	Time  2.643 ( 1.926)	Data  1.697 ( 0.976)	Loss 1.4136e-01 (8.3862e-02) 
2023-05-25 23:02:02.409252: train Epoch: [37][ 27/129]	Time  0.948 ( 1.891)	Data  0.001 ( 0.941)	Loss 9.2091e-02 (8.4156e-02) 
2023-05-25 23:02:04.920972: train Epoch: [37][ 28/129]	Time  2.512 ( 1.912)	Data  1.566 ( 0.963)	Loss 1.1148e-01 (8.5098e-02) 
2023-05-25 23:02:05.867779: train Epoch: [37][ 29/129]	Time  0.947 ( 1.880)	Data  0.001 ( 0.931)	Loss 7.1224e-02 (8.4636e-02) 
2023-05-25 23:02:08.510360: train Epoch: [37][ 30/129]	Time  2.643 ( 1.905)	Data  1.699 ( 0.955)	Loss 7.3172e-02 (8.4266e-02) 
2023-05-25 23:02:09.458112: train Epoch: [37][ 31/129]	Time  0.948 ( 1.875)	Data  0.001 ( 0.926)	Loss 9.7717e-02 (8.4686e-02) 
2023-05-25 23:02:12.040820: train Epoch: [37][ 32/129]	Time  2.583 ( 1.896)	Data  1.638 ( 0.947)	Loss 4.5985e-02 (8.3514e-02) 
2023-05-25 23:02:12.988072: train Epoch: [37][ 33/129]	Time  0.947 ( 1.868)	Data  0.001 ( 0.919)	Loss 1.2801e-01 (8.4822e-02) 
2023-05-25 23:02:15.603148: train Epoch: [37][ 34/129]	Time  2.615 ( 1.889)	Data  1.670 ( 0.941)	Loss 7.4862e-02 (8.4538e-02) 
2023-05-25 23:02:16.553118: train Epoch: [37][ 35/129]	Time  0.950 ( 1.863)	Data  0.001 ( 0.915)	Loss 2.4706e-01 (8.9052e-02) 
2023-05-25 23:02:19.155935: train Epoch: [37][ 36/129]	Time  2.603 ( 1.883)	Data  1.657 ( 0.935)	Loss 9.3300e-02 (8.9167e-02) 
2023-05-25 23:02:20.102846: train Epoch: [37][ 37/129]	Time  0.947 ( 1.859)	Data  0.001 ( 0.910)	Loss 9.7803e-02 (8.9394e-02) 
2023-05-25 23:02:22.671648: train Epoch: [37][ 38/129]	Time  2.569 ( 1.877)	Data  1.625 ( 0.929)	Loss 5.8219e-02 (8.8595e-02) 
2023-05-25 23:02:23.617599: train Epoch: [37][ 39/129]	Time  0.946 ( 1.854)	Data  0.001 ( 0.905)	Loss 1.0768e-01 (8.9072e-02) 
2023-05-25 23:02:26.161809: train Epoch: [37][ 40/129]	Time  2.544 ( 1.871)	Data  1.602 ( 0.922)	Loss 1.2430e-01 (8.9931e-02) 
2023-05-25 23:02:27.109516: train Epoch: [37][ 41/129]	Time  0.948 ( 1.849)	Data  0.001 ( 0.900)	Loss 8.7500e-02 (8.9873e-02) 
2023-05-25 23:02:29.907895: train Epoch: [37][ 42/129]	Time  2.798 ( 1.871)	Data  1.855 ( 0.923)	Loss 1.8430e-01 (9.2069e-02) 
2023-05-25 23:02:30.857571: train Epoch: [37][ 43/129]	Time  0.950 ( 1.850)	Data  0.001 ( 0.902)	Loss 1.1917e-01 (9.2685e-02) 
2023-05-25 23:02:33.436718: train Epoch: [37][ 44/129]	Time  2.579 ( 1.866)	Data  1.636 ( 0.918)	Loss 8.2097e-02 (9.2450e-02) 
2023-05-25 23:02:34.382567: train Epoch: [37][ 45/129]	Time  0.946 ( 1.846)	Data  0.001 ( 0.898)	Loss 6.0773e-02 (9.1761e-02) 
2023-05-25 23:02:36.982788: train Epoch: [37][ 46/129]	Time  2.600 ( 1.862)	Data  1.656 ( 0.914)	Loss 8.0159e-02 (9.1515e-02) 
2023-05-25 23:02:37.931502: train Epoch: [37][ 47/129]	Time  0.949 ( 1.843)	Data  0.001 ( 0.895)	Loss 8.9315e-02 (9.1469e-02) 
2023-05-25 23:02:40.473553: train Epoch: [37][ 48/129]	Time  2.542 ( 1.857)	Data  1.598 ( 0.909)	Loss 1.1714e-01 (9.1993e-02) 
2023-05-25 23:02:41.420834: train Epoch: [37][ 49/129]	Time  0.947 ( 1.839)	Data  0.001 ( 0.891)	Loss 1.1122e-01 (9.2377e-02) 
2023-05-25 23:02:43.955738: train Epoch: [37][ 50/129]	Time  2.535 ( 1.853)	Data  1.589 ( 0.905)	Loss 1.0665e-01 (9.2657e-02) 
2023-05-25 23:02:44.902384: train Epoch: [37][ 51/129]	Time  0.947 ( 1.835)	Data  0.001 ( 0.888)	Loss 5.0824e-02 (9.1853e-02) 
2023-05-25 23:02:47.407348: train Epoch: [37][ 52/129]	Time  2.505 ( 1.848)	Data  1.560 ( 0.900)	Loss 6.9629e-02 (9.1433e-02) 
2023-05-25 23:02:48.354711: train Epoch: [37][ 53/129]	Time  0.947 ( 1.831)	Data  0.001 ( 0.884)	Loss 1.0688e-01 (9.1719e-02) 
2023-05-25 23:02:50.848726: train Epoch: [37][ 54/129]	Time  2.494 ( 1.843)	Data  1.549 ( 0.896)	Loss 5.6459e-02 (9.1078e-02) 
2023-05-25 23:02:51.798028: train Epoch: [37][ 55/129]	Time  0.949 ( 1.827)	Data  0.001 ( 0.880)	Loss 9.4816e-02 (9.1145e-02) 
2023-05-25 23:02:54.405072: train Epoch: [37][ 56/129]	Time  2.607 ( 1.841)	Data  1.662 ( 0.893)	Loss 8.3949e-02 (9.1019e-02) 
2023-05-25 23:02:55.353339: train Epoch: [37][ 57/129]	Time  0.948 ( 1.826)	Data  0.001 ( 0.878)	Loss 7.4088e-02 (9.0727e-02) 
2023-05-25 23:02:57.989223: train Epoch: [37][ 58/129]	Time  2.636 ( 1.839)	Data  1.689 ( 0.892)	Loss 7.2852e-02 (9.0424e-02) 
2023-05-25 23:02:58.937396: train Epoch: [37][ 59/129]	Time  0.948 ( 1.824)	Data  0.001 ( 0.877)	Loss 1.0964e-01 (9.0744e-02) 
2023-05-25 23:03:01.529202: train Epoch: [37][ 60/129]	Time  2.592 ( 1.837)	Data  1.649 ( 0.890)	Loss 9.1360e-02 (9.0754e-02) 
2023-05-25 23:03:02.478060: train Epoch: [37][ 61/129]	Time  0.949 ( 1.823)	Data  0.001 ( 0.875)	Loss 8.1934e-02 (9.0612e-02) 
2023-05-25 23:03:05.062003: train Epoch: [37][ 62/129]	Time  2.584 ( 1.835)	Data  1.640 ( 0.887)	Loss 2.9429e-02 (8.9641e-02) 
2023-05-25 23:03:06.010421: train Epoch: [37][ 63/129]	Time  0.948 ( 1.821)	Data  0.001 ( 0.874)	Loss 9.6250e-02 (8.9744e-02) 
2023-05-25 23:03:08.588632: train Epoch: [37][ 64/129]	Time  2.578 ( 1.833)	Data  1.634 ( 0.885)	Loss 1.1233e-01 (9.0091e-02) 
2023-05-25 23:03:09.539136: train Epoch: [37][ 65/129]	Time  0.950 ( 1.819)	Data  0.001 ( 0.872)	Loss 9.7583e-02 (9.0205e-02) 
2023-05-25 23:03:12.086768: train Epoch: [37][ 66/129]	Time  2.548 ( 1.830)	Data  1.604 ( 0.883)	Loss 8.3017e-02 (9.0098e-02) 
2023-05-25 23:03:13.036495: train Epoch: [37][ 67/129]	Time  0.950 ( 1.817)	Data  0.001 ( 0.870)	Loss 1.3040e-01 (9.0690e-02) 
2023-05-25 23:03:15.614130: train Epoch: [37][ 68/129]	Time  2.578 ( 1.828)	Data  1.632 ( 0.881)	Loss 1.0022e-01 (9.0828e-02) 
2023-05-25 23:03:16.563051: train Epoch: [37][ 69/129]	Time  0.949 ( 1.816)	Data  0.001 ( 0.868)	Loss 1.0372e-01 (9.1013e-02) 
2023-05-25 23:03:19.107119: train Epoch: [37][ 70/129]	Time  2.544 ( 1.826)	Data  1.598 ( 0.879)	Loss 5.8419e-02 (9.0554e-02) 
2023-05-25 23:03:20.056228: train Epoch: [37][ 71/129]	Time  0.949 ( 1.814)	Data  0.001 ( 0.866)	Loss 7.3927e-02 (9.0323e-02) 
2023-05-25 23:03:22.635226: train Epoch: [37][ 72/129]	Time  2.579 ( 1.824)	Data  1.633 ( 0.877)	Loss 6.8959e-02 (9.0030e-02) 
2023-05-25 23:03:23.583587: train Epoch: [37][ 73/129]	Time  0.948 ( 1.812)	Data  0.001 ( 0.865)	Loss 8.2404e-02 (8.9927e-02) 
2023-05-25 23:03:26.204206: train Epoch: [37][ 74/129]	Time  2.621 ( 1.823)	Data  1.676 ( 0.876)	Loss 1.0387e-01 (9.0113e-02) 
2023-05-25 23:03:27.154096: train Epoch: [37][ 75/129]	Time  0.950 ( 1.812)	Data  0.001 ( 0.864)	Loss 6.5161e-02 (8.9784e-02) 
2023-05-25 23:03:29.773996: train Epoch: [37][ 76/129]	Time  2.620 ( 1.822)	Data  1.674 ( 0.875)	Loss 1.3773e-01 (9.0407e-02) 
2023-05-25 23:03:30.725038: train Epoch: [37][ 77/129]	Time  0.951 ( 1.811)	Data  0.001 ( 0.864)	Loss 6.1901e-02 (9.0042e-02) 
2023-05-25 23:03:33.313755: train Epoch: [37][ 78/129]	Time  2.589 ( 1.821)	Data  1.644 ( 0.874)	Loss 9.8106e-02 (9.0144e-02) 
2023-05-25 23:03:34.262088: train Epoch: [37][ 79/129]	Time  0.948 ( 1.810)	Data  0.001 ( 0.863)	Loss 1.4296e-01 (9.0804e-02) 
2023-05-25 23:03:36.845921: train Epoch: [37][ 80/129]	Time  2.584 ( 1.819)	Data  1.640 ( 0.872)	Loss 8.5371e-02 (9.0737e-02) 
2023-05-25 23:03:37.792944: train Epoch: [37][ 81/129]	Time  0.947 ( 1.809)	Data  0.001 ( 0.862)	Loss 9.4735e-02 (9.0786e-02) 
2023-05-25 23:03:40.344577: train Epoch: [37][ 82/129]	Time  2.552 ( 1.818)	Data  1.605 ( 0.871)	Loss 1.1084e-01 (9.1027e-02) 
2023-05-25 23:03:41.297364: train Epoch: [37][ 83/129]	Time  0.953 ( 1.807)	Data  0.001 ( 0.860)	Loss 6.5733e-02 (9.0726e-02) 
2023-05-25 23:03:43.822613: train Epoch: [37][ 84/129]	Time  2.525 ( 1.816)	Data  1.578 ( 0.869)	Loss 1.0828e-01 (9.0933e-02) 
2023-05-25 23:03:44.771400: train Epoch: [37][ 85/129]	Time  0.949 ( 1.806)	Data  0.001 ( 0.859)	Loss 7.2805e-02 (9.0722e-02) 
2023-05-25 23:03:47.352198: train Epoch: [37][ 86/129]	Time  2.581 ( 1.815)	Data  1.636 ( 0.867)	Loss 1.1021e-01 (9.0946e-02) 
2023-05-25 23:03:48.300383: train Epoch: [37][ 87/129]	Time  0.948 ( 1.805)	Data  0.001 ( 0.858)	Loss 1.2542e-01 (9.1338e-02) 
2023-05-25 23:03:50.852732: train Epoch: [37][ 88/129]	Time  2.552 ( 1.813)	Data  1.608 ( 0.866)	Loss 7.6692e-02 (9.1173e-02) 
2023-05-25 23:03:51.801349: train Epoch: [37][ 89/129]	Time  0.949 ( 1.804)	Data  0.001 ( 0.856)	Loss 8.4088e-02 (9.1094e-02) 
2023-05-25 23:03:54.488330: train Epoch: [37][ 90/129]	Time  2.687 ( 1.813)	Data  1.741 ( 0.866)	Loss 1.0496e-01 (9.1247e-02) 
2023-05-25 23:03:55.436153: train Epoch: [37][ 91/129]	Time  0.948 ( 1.804)	Data  0.001 ( 0.857)	Loss 7.2884e-02 (9.1047e-02) 
2023-05-25 23:03:58.012077: train Epoch: [37][ 92/129]	Time  2.576 ( 1.812)	Data  1.631 ( 0.865)	Loss 8.8431e-02 (9.1019e-02) 
2023-05-25 23:03:58.970775: train Epoch: [37][ 93/129]	Time  0.959 ( 1.803)	Data  0.001 ( 0.856)	Loss 1.0322e-01 (9.1149e-02) 
2023-05-25 23:04:01.543846: train Epoch: [37][ 94/129]	Time  2.573 ( 1.811)	Data  1.619 ( 0.864)	Loss 7.4615e-02 (9.0975e-02) 
2023-05-25 23:04:02.501108: train Epoch: [37][ 95/129]	Time  0.957 ( 1.802)	Data  0.001 ( 0.855)	Loss 8.2788e-02 (9.0889e-02) 
2023-05-25 23:04:05.090262: train Epoch: [37][ 96/129]	Time  2.589 ( 1.811)	Data  1.644 ( 0.863)	Loss 5.3617e-02 (9.0505e-02) 
2023-05-25 23:04:06.038543: train Epoch: [37][ 97/129]	Time  0.948 ( 1.802)	Data  0.001 ( 0.854)	Loss 6.5523e-02 (9.0250e-02) 
2023-05-25 23:04:08.546393: train Epoch: [37][ 98/129]	Time  2.508 ( 1.809)	Data  1.564 ( 0.861)	Loss 6.4885e-02 (8.9994e-02) 
2023-05-25 23:04:09.495588: train Epoch: [37][ 99/129]	Time  0.949 ( 1.800)	Data  0.001 ( 0.853)	Loss 7.3657e-02 (8.9831e-02) 
2023-05-25 23:04:12.095819: train Epoch: [37][100/129]	Time  2.600 ( 1.808)	Data  1.655 ( 0.861)	Loss 8.5918e-02 (8.9792e-02) 
2023-05-25 23:04:13.044004: train Epoch: [37][101/129]	Time  0.948 ( 1.800)	Data  0.001 ( 0.852)	Loss 5.8496e-02 (8.9485e-02) 
2023-05-25 23:04:15.637379: train Epoch: [37][102/129]	Time  2.593 ( 1.807)	Data  1.650 ( 0.860)	Loss 6.2173e-02 (8.9220e-02) 
2023-05-25 23:04:16.585355: train Epoch: [37][103/129]	Time  0.948 ( 1.799)	Data  0.001 ( 0.852)	Loss 6.0723e-02 (8.8946e-02) 
2023-05-25 23:04:19.149461: train Epoch: [37][104/129]	Time  2.564 ( 1.806)	Data  1.619 ( 0.859)	Loss 6.4164e-02 (8.8710e-02) 
2023-05-25 23:04:20.098670: train Epoch: [37][105/129]	Time  0.949 ( 1.798)	Data  0.001 ( 0.851)	Loss 7.2813e-02 (8.8560e-02) 
2023-05-25 23:04:22.664504: train Epoch: [37][106/129]	Time  2.566 ( 1.806)	Data  1.620 ( 0.858)	Loss 5.5060e-02 (8.8247e-02) 
2023-05-25 23:04:23.613514: train Epoch: [37][107/129]	Time  0.949 ( 1.798)	Data  0.001 ( 0.850)	Loss 6.2712e-02 (8.8010e-02) 
2023-05-25 23:04:26.198443: train Epoch: [37][108/129]	Time  2.585 ( 1.805)	Data  1.639 ( 0.858)	Loss 9.1114e-02 (8.8039e-02) 
2023-05-25 23:04:27.149187: train Epoch: [37][109/129]	Time  0.951 ( 1.797)	Data  0.001 ( 0.850)	Loss 5.0854e-02 (8.7701e-02) 
2023-05-25 23:04:29.657064: train Epoch: [37][110/129]	Time  2.508 ( 1.803)	Data  1.562 ( 0.856)	Loss 1.1274e-01 (8.7926e-02) 
2023-05-25 23:04:30.605315: train Epoch: [37][111/129]	Time  0.948 ( 1.796)	Data  0.001 ( 0.849)	Loss 6.4799e-02 (8.7720e-02) 
2023-05-25 23:04:33.218393: train Epoch: [37][112/129]	Time  2.613 ( 1.803)	Data  1.667 ( 0.856)	Loss 1.2974e-01 (8.8092e-02) 
2023-05-25 23:04:34.167067: train Epoch: [37][113/129]	Time  0.949 ( 1.796)	Data  0.001 ( 0.848)	Loss 7.0394e-02 (8.7937e-02) 
2023-05-25 23:04:36.836363: train Epoch: [37][114/129]	Time  2.669 ( 1.803)	Data  1.725 ( 0.856)	Loss 7.9901e-02 (8.7867e-02) 
2023-05-25 23:04:37.785091: train Epoch: [37][115/129]	Time  0.949 ( 1.796)	Data  0.001 ( 0.849)	Loss 1.0451e-01 (8.8010e-02) 
2023-05-25 23:04:40.368747: train Epoch: [37][116/129]	Time  2.584 ( 1.803)	Data  1.638 ( 0.855)	Loss 7.9212e-02 (8.7935e-02) 
2023-05-25 23:04:41.317287: train Epoch: [37][117/129]	Time  0.949 ( 1.795)	Data  0.001 ( 0.848)	Loss 1.2239e-01 (8.8227e-02) 
2023-05-25 23:04:43.947619: train Epoch: [37][118/129]	Time  2.630 ( 1.802)	Data  1.686 ( 0.855)	Loss 1.2140e-01 (8.8506e-02) 
2023-05-25 23:04:44.896075: train Epoch: [37][119/129]	Time  0.948 ( 1.795)	Data  0.001 ( 0.848)	Loss 1.3038e-01 (8.8855e-02) 
2023-05-25 23:04:47.533432: train Epoch: [37][120/129]	Time  2.637 ( 1.802)	Data  1.691 ( 0.855)	Loss 8.5626e-02 (8.8828e-02) 
2023-05-25 23:04:48.483052: train Epoch: [37][121/129]	Time  0.950 ( 1.795)	Data  0.001 ( 0.848)	Loss 5.0736e-02 (8.8516e-02) 
2023-05-25 23:04:51.104172: train Epoch: [37][122/129]	Time  2.621 ( 1.802)	Data  1.666 ( 0.855)	Loss 6.3785e-02 (8.8315e-02) 
2023-05-25 23:04:52.061959: train Epoch: [37][123/129]	Time  0.958 ( 1.795)	Data  0.001 ( 0.848)	Loss 8.7242e-02 (8.8306e-02) 
2023-05-25 23:04:54.665481: train Epoch: [37][124/129]	Time  2.604 ( 1.802)	Data  1.649 ( 0.854)	Loss 8.7250e-02 (8.8298e-02) 
2023-05-25 23:04:55.622906: train Epoch: [37][125/129]	Time  0.957 ( 1.795)	Data  0.001 ( 0.847)	Loss 1.0590e-01 (8.8437e-02) 
2023-05-25 23:04:58.122940: train Epoch: [37][126/129]	Time  2.500 ( 1.800)	Data  1.543 ( 0.853)	Loss 6.9326e-02 (8.8287e-02) 
2023-05-25 23:04:59.076812: train Epoch: [37][127/129]	Time  0.954 ( 1.794)	Data  0.001 ( 0.846)	Loss 5.9243e-02 (8.8060e-02) 
2023-05-25 23:05:00.513634: train Epoch: [37][128/129]	Time  1.437 ( 1.791)	Data  0.484 ( 0.843)	Loss 7.1971e-02 (8.7935e-02) 
2023-05-25 23:05:00.560704: Train Epoch done in 231.09018650299913 s 
2023-05-25 23:05:02.959818: val Epoch: [37][ 0/72]	Time  1.658 ( 1.658)	Data  1.454 ( 1.454)	Loss 4.3055e-01 (4.3055e-01) 
2023-05-25 23:05:03.089695: val Epoch: [37][ 1/72]	Time  0.130 ( 0.894)	Data  0.002 ( 0.728)	Loss 6.1687e-02 (2.4612e-01) 
2023-05-25 23:05:04.078981: val Epoch: [37][ 2/72]	Time  0.989 ( 0.926)	Data  0.865 ( 0.774)	Loss 9.5040e-02 (1.9576e-01) 
2023-05-25 23:05:04.204090: val Epoch: [37][ 3/72]	Time  0.125 ( 0.725)	Data  0.001 ( 0.580)	Loss 2.3101e-01 (2.0457e-01) 
2023-05-25 23:05:05.328085: val Epoch: [37][ 4/72]	Time  1.124 ( 0.805)	Data  0.999 ( 0.664)	Loss 8.4337e-02 (1.8053e-01) 
2023-05-25 23:05:05.452902: val Epoch: [37][ 5/72]	Time  0.125 ( 0.692)	Data  0.001 ( 0.554)	Loss 6.3562e-02 (1.6103e-01) 
2023-05-25 23:05:06.561580: val Epoch: [37][ 6/72]	Time  1.109 ( 0.751)	Data  0.983 ( 0.615)	Loss 8.8639e-02 (1.5069e-01) 
2023-05-25 23:05:06.686588: val Epoch: [37][ 7/72]	Time  0.125 ( 0.673)	Data  0.001 ( 0.538)	Loss 2.7502e-01 (1.6623e-01) 
2023-05-25 23:05:07.742623: val Epoch: [37][ 8/72]	Time  1.056 ( 0.716)	Data  0.931 ( 0.582)	Loss 4.2704e-02 (1.5251e-01) 
2023-05-25 23:05:07.868273: val Epoch: [37][ 9/72]	Time  0.126 ( 0.657)	Data  0.001 ( 0.524)	Loss 4.1088e-02 (1.4136e-01) 
2023-05-25 23:05:08.983239: val Epoch: [37][10/72]	Time  1.115 ( 0.698)	Data  0.994 ( 0.566)	Loss 1.8476e-01 (1.4531e-01) 
2023-05-25 23:05:09.108284: val Epoch: [37][11/72]	Time  0.125 ( 0.651)	Data  0.001 ( 0.519)	Loss 4.1233e-02 (1.3664e-01) 
2023-05-25 23:05:10.155735: val Epoch: [37][12/72]	Time  1.047 ( 0.681)	Data  0.926 ( 0.551)	Loss 5.5716e-02 (1.3041e-01) 
2023-05-25 23:05:10.276651: val Epoch: [37][13/72]	Time  0.121 ( 0.641)	Data  0.001 ( 0.511)	Loss 5.4981e-02 (1.2502e-01) 
2023-05-25 23:05:11.378567: val Epoch: [37][14/72]	Time  1.102 ( 0.672)	Data  0.980 ( 0.543)	Loss 3.2591e-01 (1.3842e-01) 
2023-05-25 23:05:11.499619: val Epoch: [37][15/72]	Time  0.121 ( 0.637)	Data  0.001 ( 0.509)	Loss 6.5151e-02 (1.3384e-01) 
2023-05-25 23:05:12.617762: val Epoch: [37][16/72]	Time  1.118 ( 0.666)	Data  0.997 ( 0.537)	Loss 8.5048e-02 (1.3097e-01) 
2023-05-25 23:05:12.739032: val Epoch: [37][17/72]	Time  0.121 ( 0.635)	Data  0.001 ( 0.508)	Loss 5.2102e-02 (1.2659e-01) 
2023-05-25 23:05:13.839332: val Epoch: [37][18/72]	Time  1.100 ( 0.660)	Data  0.976 ( 0.532)	Loss 1.0658e-01 (1.2553e-01) 
2023-05-25 23:05:13.963886: val Epoch: [37][19/72]	Time  0.125 ( 0.633)	Data  0.001 ( 0.506)	Loss 5.1576e-02 (1.2184e-01) 
2023-05-25 23:05:15.075057: val Epoch: [37][20/72]	Time  1.111 ( 0.656)	Data  0.990 ( 0.529)	Loss 3.7684e-01 (1.3398e-01) 
2023-05-25 23:05:15.196326: val Epoch: [37][21/72]	Time  0.121 ( 0.632)	Data  0.001 ( 0.505)	Loss 5.0892e-02 (1.3020e-01) 
2023-05-25 23:05:16.280484: val Epoch: [37][22/72]	Time  1.084 ( 0.651)	Data  0.963 ( 0.525)	Loss 3.1751e-01 (1.3835e-01) 
2023-05-25 23:05:16.402091: val Epoch: [37][23/72]	Time  0.122 ( 0.629)	Data  0.001 ( 0.503)	Loss 6.3605e-02 (1.3523e-01) 
2023-05-25 23:05:17.493796: val Epoch: [37][24/72]	Time  1.092 ( 0.648)	Data  0.971 ( 0.522)	Loss 3.4937e-01 (1.4380e-01) 
2023-05-25 23:05:17.615124: val Epoch: [37][25/72]	Time  0.121 ( 0.627)	Data  0.001 ( 0.502)	Loss 7.3587e-02 (1.4110e-01) 
2023-05-25 23:05:18.709952: val Epoch: [37][26/72]	Time  1.095 ( 0.645)	Data  0.973 ( 0.519)	Loss 9.7891e-02 (1.3950e-01) 
2023-05-25 23:05:18.834980: val Epoch: [37][27/72]	Time  0.125 ( 0.626)	Data  0.001 ( 0.500)	Loss 4.9070e-02 (1.3627e-01) 
2023-05-25 23:05:19.876874: val Epoch: [37][28/72]	Time  1.042 ( 0.641)	Data  0.920 ( 0.515)	Loss 1.9380e-01 (1.3825e-01) 
2023-05-25 23:05:19.999032: val Epoch: [37][29/72]	Time  0.122 ( 0.623)	Data  0.001 ( 0.498)	Loss 1.4325e-01 (1.3842e-01) 
2023-05-25 23:05:21.059066: val Epoch: [37][30/72]	Time  1.060 ( 0.637)	Data  0.939 ( 0.512)	Loss 5.6011e-02 (1.3576e-01) 
2023-05-25 23:05:21.181703: val Epoch: [37][31/72]	Time  0.123 ( 0.621)	Data  0.001 ( 0.496)	Loss 1.1857e-01 (1.3522e-01) 
2023-05-25 23:05:22.295654: val Epoch: [37][32/72]	Time  1.114 ( 0.636)	Data  0.991 ( 0.511)	Loss 1.7924e-01 (1.3656e-01) 
2023-05-25 23:05:22.418795: val Epoch: [37][33/72]	Time  0.123 ( 0.621)	Data  0.001 ( 0.496)	Loss 4.0921e-02 (1.3374e-01) 
2023-05-25 23:05:23.473210: val Epoch: [37][34/72]	Time  1.054 ( 0.633)	Data  0.931 ( 0.508)	Loss 5.2978e-02 (1.3144e-01) 
2023-05-25 23:05:23.596191: val Epoch: [37][35/72]	Time  0.123 ( 0.619)	Data  0.001 ( 0.494)	Loss 4.8078e-02 (1.2912e-01) 
2023-05-25 23:05:24.604442: val Epoch: [37][36/72]	Time  1.008 ( 0.630)	Data  0.886 ( 0.505)	Loss 4.0614e-02 (1.2673e-01) 
2023-05-25 23:05:24.727176: val Epoch: [37][37/72]	Time  0.123 ( 0.616)	Data  0.000 ( 0.492)	Loss 8.5170e-02 (1.2563e-01) 
2023-05-25 23:05:25.870871: val Epoch: [37][38/72]	Time  1.144 ( 0.630)	Data  1.021 ( 0.505)	Loss 3.3128e-01 (1.3091e-01) 
2023-05-25 23:05:25.993410: val Epoch: [37][39/72]	Time  0.123 ( 0.617)	Data  0.001 ( 0.493)	Loss 8.6886e-02 (1.2981e-01) 
2023-05-25 23:05:27.172377: val Epoch: [37][40/72]	Time  1.179 ( 0.631)	Data  1.056 ( 0.506)	Loss 8.6666e-02 (1.2875e-01) 
2023-05-25 23:05:27.298711: val Epoch: [37][41/72]	Time  0.126 ( 0.619)	Data  0.001 ( 0.494)	Loss 5.7315e-02 (1.2705e-01) 
2023-05-25 23:05:28.405887: val Epoch: [37][42/72]	Time  1.107 ( 0.630)	Data  0.985 ( 0.506)	Loss 9.3865e-02 (1.2628e-01) 
2023-05-25 23:05:28.527963: val Epoch: [37][43/72]	Time  0.122 ( 0.619)	Data  0.001 ( 0.494)	Loss 6.6788e-02 (1.2493e-01) 
2023-05-25 23:05:29.568977: val Epoch: [37][44/72]	Time  1.041 ( 0.628)	Data  0.918 ( 0.504)	Loss 3.9432e-02 (1.2303e-01) 
2023-05-25 23:05:29.694317: val Epoch: [37][45/72]	Time  0.125 ( 0.617)	Data  0.001 ( 0.493)	Loss 5.0554e-02 (1.2145e-01) 
2023-05-25 23:05:30.752664: val Epoch: [37][46/72]	Time  1.058 ( 0.627)	Data  0.936 ( 0.502)	Loss 5.1995e-02 (1.1998e-01) 
2023-05-25 23:05:30.874653: val Epoch: [37][47/72]	Time  0.122 ( 0.616)	Data  0.001 ( 0.492)	Loss 3.8146e-01 (1.2542e-01) 
2023-05-25 23:05:31.950514: val Epoch: [37][48/72]	Time  1.076 ( 0.625)	Data  0.950 ( 0.501)	Loss 3.8214e-02 (1.2364e-01) 
2023-05-25 23:05:32.073173: val Epoch: [37][49/72]	Time  0.123 ( 0.615)	Data  0.001 ( 0.491)	Loss 1.3299e-01 (1.2383e-01) 
2023-05-25 23:05:33.163305: val Epoch: [37][50/72]	Time  1.090 ( 0.625)	Data  0.964 ( 0.500)	Loss 1.2404e-01 (1.2383e-01) 
2023-05-25 23:05:33.288130: val Epoch: [37][51/72]	Time  0.125 ( 0.615)	Data  0.001 ( 0.491)	Loss 1.4679e-01 (1.2428e-01) 
2023-05-25 23:05:34.356645: val Epoch: [37][52/72]	Time  1.069 ( 0.624)	Data  0.943 ( 0.499)	Loss 1.5882e-01 (1.2493e-01) 
2023-05-25 23:05:34.481820: val Epoch: [37][53/72]	Time  0.125 ( 0.614)	Data  0.001 ( 0.490)	Loss 1.1821e-01 (1.2480e-01) 
2023-05-25 23:05:35.510442: val Epoch: [37][54/72]	Time  1.029 ( 0.622)	Data  0.902 ( 0.497)	Loss 4.5674e-02 (1.2336e-01) 
2023-05-25 23:05:35.636237: val Epoch: [37][55/72]	Time  0.126 ( 0.613)	Data  0.001 ( 0.489)	Loss 9.4272e-02 (1.2285e-01) 
2023-05-25 23:05:36.680015: val Epoch: [37][56/72]	Time  1.044 ( 0.621)	Data  0.918 ( 0.496)	Loss 6.4500e-02 (1.2182e-01) 
2023-05-25 23:05:36.802216: val Epoch: [37][57/72]	Time  0.122 ( 0.612)	Data  0.001 ( 0.488)	Loss 3.1716e-01 (1.2519e-01) 
2023-05-25 23:05:37.911788: val Epoch: [37][58/72]	Time  1.110 ( 0.620)	Data  0.983 ( 0.496)	Loss 1.2323e-01 (1.2516e-01) 
2023-05-25 23:05:38.036665: val Epoch: [37][59/72]	Time  0.125 ( 0.612)	Data  0.001 ( 0.488)	Loss 1.1007e-01 (1.2491e-01) 
2023-05-25 23:05:39.132430: val Epoch: [37][60/72]	Time  1.096 ( 0.620)	Data  0.973 ( 0.496)	Loss 2.2167e-01 (1.2649e-01) 
2023-05-25 23:05:39.258023: val Epoch: [37][61/72]	Time  0.126 ( 0.612)	Data  0.001 ( 0.488)	Loss 9.7982e-02 (1.2603e-01) 
2023-05-25 23:05:40.326253: val Epoch: [37][62/72]	Time  1.068 ( 0.619)	Data  0.942 ( 0.495)	Loss 5.2273e-02 (1.2486e-01) 
2023-05-25 23:05:40.451943: val Epoch: [37][63/72]	Time  0.126 ( 0.612)	Data  0.001 ( 0.487)	Loss 6.0985e-01 (1.3244e-01) 
2023-05-25 23:05:41.492818: val Epoch: [37][64/72]	Time  1.041 ( 0.618)	Data  0.918 ( 0.494)	Loss 1.4633e-01 (1.3265e-01) 
2023-05-25 23:05:41.618192: val Epoch: [37][65/72]	Time  0.125 ( 0.611)	Data  0.001 ( 0.486)	Loss 7.5419e-02 (1.3179e-01) 
2023-05-25 23:05:42.709316: val Epoch: [37][66/72]	Time  1.091 ( 0.618)	Data  0.968 ( 0.494)	Loss 3.5900e-01 (1.3518e-01) 
2023-05-25 23:05:42.831205: val Epoch: [37][67/72]	Time  0.122 ( 0.611)	Data  0.001 ( 0.486)	Loss 8.6992e-02 (1.3447e-01) 
2023-05-25 23:05:43.897697: val Epoch: [37][68/72]	Time  1.066 ( 0.617)	Data  0.945 ( 0.493)	Loss 8.2468e-02 (1.3371e-01) 
2023-05-25 23:05:44.023508: val Epoch: [37][69/72]	Time  0.126 ( 0.610)	Data  0.000 ( 0.486)	Loss 5.4991e-02 (1.3259e-01) 
2023-05-25 23:05:44.787080: val Epoch: [37][70/72]	Time  0.764 ( 0.612)	Data  0.643 ( 0.488)	Loss 8.6280e-02 (1.3194e-01) 
2023-05-25 23:05:44.903901: val Epoch: [37][71/72]	Time  0.117 ( 0.606)	Data  0.000 ( 0.481)	Loss 8.8190e-02 (1.3133e-01) 
2023-05-25 23:05:45.086678: Epoch 37 :Val : ['ET : 0.735204815864563', 'TC : 0.7857745289802551', 'WT : 0.8599563241004944'] 
2023-05-25 23:05:45.089524: Epoch 37 :Val : ['ET : 0.735204815864563', 'TC : 0.7857745289802551', 'WT : 0.8599563241004944'] 
2023-05-25 23:05:45.091292: Val epoch done in 44.53059456900155 s 
2023-05-25 23:05:45.096530: Batches per epoch:  129 
2023-05-25 23:05:49.906984: train Epoch: [38][  0/129]	Time  4.810 ( 4.810)	Data  3.803 ( 3.803)	Loss 6.0985e-02 (6.0985e-02) 
2023-05-25 23:05:50.867779: train Epoch: [38][  1/129]	Time  0.961 ( 2.886)	Data  0.001 ( 1.902)	Loss 9.7499e-02 (7.9242e-02) 
2023-05-25 23:05:53.581651: train Epoch: [38][  2/129]	Time  2.714 ( 2.828)	Data  1.745 ( 1.850)	Loss 4.4628e-02 (6.7704e-02) 
2023-05-25 23:05:54.535447: train Epoch: [38][  3/129]	Time  0.954 ( 2.360)	Data  0.001 ( 1.388)	Loss 9.9126e-02 (7.5559e-02) 
2023-05-25 23:05:57.286637: train Epoch: [38][  4/129]	Time  2.751 ( 2.438)	Data  1.800 ( 1.470)	Loss 9.0724e-02 (7.8592e-02) 
2023-05-25 23:05:58.230996: train Epoch: [38][  5/129]	Time  0.944 ( 2.189)	Data  0.001 ( 1.225)	Loss 1.4008e-01 (8.8840e-02) 
2023-05-25 23:06:00.945952: train Epoch: [38][  6/129]	Time  2.715 ( 2.264)	Data  1.772 ( 1.303)	Loss 7.0316e-02 (8.6194e-02) 
2023-05-25 23:06:01.892881: train Epoch: [38][  7/129]	Time  0.947 ( 2.100)	Data  0.001 ( 1.140)	Loss 9.0024e-02 (8.6673e-02) 
2023-05-25 23:06:04.667102: train Epoch: [38][  8/129]	Time  2.774 ( 2.174)	Data  1.818 ( 1.216)	Loss 6.3848e-02 (8.4137e-02) 
2023-05-25 23:06:05.621360: train Epoch: [38][  9/129]	Time  0.954 ( 2.052)	Data  0.001 ( 1.094)	Loss 5.9026e-02 (8.1626e-02) 
2023-05-25 23:06:08.341725: train Epoch: [38][ 10/129]	Time  2.720 ( 2.113)	Data  1.769 ( 1.156)	Loss 4.7979e-02 (7.8567e-02) 
2023-05-25 23:06:09.286334: train Epoch: [38][ 11/129]	Time  0.945 ( 2.016)	Data  0.001 ( 1.059)	Loss 6.0580e-02 (7.7068e-02) 
2023-05-25 23:06:12.086087: train Epoch: [38][ 12/129]	Time  2.800 ( 2.076)	Data  1.859 ( 1.121)	Loss 6.4505e-02 (7.6102e-02) 
2023-05-25 23:06:13.031882: train Epoch: [38][ 13/129]	Time  0.946 ( 1.995)	Data  0.001 ( 1.041)	Loss 9.9877e-02 (7.7800e-02) 
2023-05-25 23:06:15.891442: train Epoch: [38][ 14/129]	Time  2.860 ( 2.053)	Data  1.916 ( 1.099)	Loss 6.4754e-02 (7.6930e-02) 
2023-05-25 23:06:16.835351: train Epoch: [38][ 15/129]	Time  0.944 ( 1.984)	Data  0.001 ( 1.031)	Loss 6.2897e-02 (7.6053e-02) 
2023-05-25 23:06:19.583341: train Epoch: [38][ 16/129]	Time  2.748 ( 2.029)	Data  1.807 ( 1.076)	Loss 8.0770e-02 (7.6331e-02) 
2023-05-25 23:06:20.527814: train Epoch: [38][ 17/129]	Time  0.944 ( 1.968)	Data  0.001 ( 1.017)	Loss 6.9241e-02 (7.5937e-02) 
2023-05-25 23:06:23.214643: train Epoch: [38][ 18/129]	Time  2.687 ( 2.006)	Data  1.747 ( 1.055)	Loss 1.5554e-01 (8.0126e-02) 
2023-05-25 23:06:24.157572: train Epoch: [38][ 19/129]	Time  0.943 ( 1.953)	Data  0.001 ( 1.002)	Loss 6.0301e-02 (7.9135e-02) 
2023-05-25 23:06:26.890286: train Epoch: [38][ 20/129]	Time  2.733 ( 1.990)	Data  1.792 ( 1.040)	Loss 5.8977e-02 (7.8175e-02) 
2023-05-25 23:06:27.832980: train Epoch: [38][ 21/129]	Time  0.943 ( 1.943)	Data  0.001 ( 0.993)	Loss 1.6212e-01 (8.1991e-02) 
2023-05-25 23:06:30.514414: train Epoch: [38][ 22/129]	Time  2.681 ( 1.975)	Data  1.741 ( 1.025)	Loss 8.8405e-02 (8.2270e-02) 
2023-05-25 23:06:31.458019: train Epoch: [38][ 23/129]	Time  0.944 ( 1.932)	Data  0.001 ( 0.983)	Loss 8.8865e-02 (8.2545e-02) 
2023-05-25 23:06:34.124535: train Epoch: [38][ 24/129]	Time  2.667 ( 1.961)	Data  1.726 ( 1.012)	Loss 6.1957e-02 (8.1721e-02) 
2023-05-25 23:06:35.067598: train Epoch: [38][ 25/129]	Time  0.943 ( 1.922)	Data  0.001 ( 0.973)	Loss 4.9637e-02 (8.0487e-02) 
2023-05-25 23:06:37.732902: train Epoch: [38][ 26/129]	Time  2.665 ( 1.949)	Data  1.725 ( 1.001)	Loss 5.2880e-02 (7.9465e-02) 
2023-05-25 23:06:38.675134: train Epoch: [38][ 27/129]	Time  0.942 ( 1.914)	Data  0.001 ( 0.966)	Loss 6.9811e-02 (7.9120e-02) 
2023-05-25 23:06:41.228100: train Epoch: [38][ 28/129]	Time  2.553 ( 1.936)	Data  1.612 ( 0.988)	Loss 9.0173e-02 (7.9501e-02) 
2023-05-25 23:06:42.171297: train Epoch: [38][ 29/129]	Time  0.943 ( 1.902)	Data  0.001 ( 0.955)	Loss 6.8332e-02 (7.9129e-02) 
2023-05-25 23:06:44.839943: train Epoch: [38][ 30/129]	Time  2.669 ( 1.927)	Data  1.726 ( 0.980)	Loss 6.3534e-02 (7.8626e-02) 
2023-05-25 23:06:45.785438: train Epoch: [38][ 31/129]	Time  0.945 ( 1.897)	Data  0.001 ( 0.949)	Loss 6.2235e-02 (7.8113e-02) 
2023-05-25 23:06:48.566995: train Epoch: [38][ 32/129]	Time  2.782 ( 1.923)	Data  1.832 ( 0.976)	Loss 9.8537e-02 (7.8732e-02) 
2023-05-25 23:06:49.511935: train Epoch: [38][ 33/129]	Time  0.945 ( 1.895)	Data  0.001 ( 0.947)	Loss 1.1921e-01 (7.9923e-02) 
2023-05-25 23:06:52.287908: train Epoch: [38][ 34/129]	Time  2.776 ( 1.920)	Data  1.825 ( 0.972)	Loss 2.0775e-01 (8.3575e-02) 
2023-05-25 23:06:53.231768: train Epoch: [38][ 35/129]	Time  0.944 ( 1.893)	Data  0.001 ( 0.945)	Loss 9.4840e-02 (8.3888e-02) 
2023-05-25 23:06:55.900329: train Epoch: [38][ 36/129]	Time  2.669 ( 1.914)	Data  1.728 ( 0.967)	Loss 8.2344e-02 (8.3846e-02) 
2023-05-25 23:06:56.844924: train Epoch: [38][ 37/129]	Time  0.945 ( 1.888)	Data  0.001 ( 0.941)	Loss 9.0954e-02 (8.4033e-02) 
2023-05-25 23:06:59.544341: train Epoch: [38][ 38/129]	Time  2.699 ( 1.909)	Data  1.758 ( 0.962)	Loss 1.1511e-01 (8.4830e-02) 
2023-05-25 23:07:00.488119: train Epoch: [38][ 39/129]	Time  0.944 ( 1.885)	Data  0.001 ( 0.938)	Loss 1.0883e-01 (8.5430e-02) 
2023-05-25 23:07:03.178893: train Epoch: [38][ 40/129]	Time  2.691 ( 1.904)	Data  1.748 ( 0.958)	Loss 5.8925e-02 (8.4784e-02) 
2023-05-25 23:07:04.121325: train Epoch: [38][ 41/129]	Time  0.942 ( 1.882)	Data  0.001 ( 0.935)	Loss 7.8966e-02 (8.4645e-02) 
2023-05-25 23:07:06.774911: train Epoch: [38][ 42/129]	Time  2.654 ( 1.899)	Data  1.712 ( 0.953)	Loss 6.8268e-02 (8.4264e-02) 
2023-05-25 23:07:07.719590: train Epoch: [38][ 43/129]	Time  0.945 ( 1.878)	Data  0.001 ( 0.931)	Loss 7.2704e-02 (8.4002e-02) 
2023-05-25 23:07:10.456740: train Epoch: [38][ 44/129]	Time  2.737 ( 1.897)	Data  1.791 ( 0.951)	Loss 6.3123e-02 (8.3538e-02) 
2023-05-25 23:07:11.409608: train Epoch: [38][ 45/129]	Time  0.953 ( 1.876)	Data  0.001 ( 0.930)	Loss 6.8292e-02 (8.3206e-02) 
2023-05-25 23:07:13.943848: train Epoch: [38][ 46/129]	Time  2.534 ( 1.890)	Data  1.586 ( 0.944)	Loss 8.2401e-02 (8.3189e-02) 
2023-05-25 23:07:14.887846: train Epoch: [38][ 47/129]	Time  0.944 ( 1.871)	Data  0.001 ( 0.924)	Loss 2.3270e-01 (8.6304e-02) 
2023-05-25 23:07:17.571408: train Epoch: [38][ 48/129]	Time  2.684 ( 1.887)	Data  1.735 ( 0.941)	Loss 1.7871e-01 (8.8190e-02) 
2023-05-25 23:07:18.515200: train Epoch: [38][ 49/129]	Time  0.944 ( 1.868)	Data  0.001 ( 0.922)	Loss 1.0632e-01 (8.8552e-02) 
2023-05-25 23:07:21.174285: train Epoch: [38][ 50/129]	Time  2.659 ( 1.884)	Data  1.713 ( 0.937)	Loss 8.2500e-02 (8.8434e-02) 
2023-05-25 23:07:22.119484: train Epoch: [38][ 51/129]	Time  0.945 ( 1.866)	Data  0.001 ( 0.919)	Loss 9.0053e-02 (8.8465e-02) 
2023-05-25 23:07:24.735604: train Epoch: [38][ 52/129]	Time  2.616 ( 1.880)	Data  1.661 ( 0.933)	Loss 5.8089e-02 (8.7892e-02) 
2023-05-25 23:07:25.679681: train Epoch: [38][ 53/129]	Time  0.944 ( 1.863)	Data  0.001 ( 0.916)	Loss 6.3097e-02 (8.7433e-02) 
2023-05-25 23:07:28.301600: train Epoch: [38][ 54/129]	Time  2.622 ( 1.876)	Data  1.676 ( 0.930)	Loss 7.5844e-02 (8.7222e-02) 
2023-05-25 23:07:29.244116: train Epoch: [38][ 55/129]	Time  0.942 ( 1.860)	Data  0.001 ( 0.913)	Loss 7.9677e-02 (8.7087e-02) 
2023-05-25 23:07:31.866111: train Epoch: [38][ 56/129]	Time  2.622 ( 1.873)	Data  1.674 ( 0.927)	Loss 7.7050e-02 (8.6911e-02) 
2023-05-25 23:07:32.812899: train Epoch: [38][ 57/129]	Time  0.947 ( 1.857)	Data  0.001 ( 0.911)	Loss 1.2250e-01 (8.7525e-02) 
2023-05-25 23:07:35.499355: train Epoch: [38][ 58/129]	Time  2.686 ( 1.871)	Data  1.734 ( 0.925)	Loss 7.0841e-02 (8.7242e-02) 
2023-05-25 23:07:36.443051: train Epoch: [38][ 59/129]	Time  0.944 ( 1.856)	Data  0.001 ( 0.909)	Loss 8.1925e-02 (8.7153e-02) 
2023-05-25 23:07:39.096591: train Epoch: [38][ 60/129]	Time  2.654 ( 1.869)	Data  1.711 ( 0.922)	Loss 7.4842e-02 (8.6951e-02) 
2023-05-25 23:07:40.041079: train Epoch: [38][ 61/129]	Time  0.944 ( 1.854)	Data  0.001 ( 0.908)	Loss 8.7895e-02 (8.6967e-02) 
2023-05-25 23:07:42.663821: train Epoch: [38][ 62/129]	Time  2.623 ( 1.866)	Data  1.668 ( 0.920)	Loss 6.8114e-02 (8.6667e-02) 
2023-05-25 23:07:43.608732: train Epoch: [38][ 63/129]	Time  0.945 ( 1.852)	Data  0.001 ( 0.905)	Loss 6.2208e-02 (8.6285e-02) 
2023-05-25 23:07:46.240417: train Epoch: [38][ 64/129]	Time  2.632 ( 1.864)	Data  1.683 ( 0.917)	Loss 6.1511e-02 (8.5904e-02) 
2023-05-25 23:07:47.191659: train Epoch: [38][ 65/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.903)	Loss 6.1425e-02 (8.5533e-02) 
2023-05-25 23:07:49.929813: train Epoch: [38][ 66/129]	Time  2.738 ( 1.863)	Data  1.781 ( 0.917)	Loss 7.7031e-02 (8.5406e-02) 
2023-05-25 23:07:50.882479: train Epoch: [38][ 67/129]	Time  0.953 ( 1.850)	Data  0.001 ( 0.903)	Loss 5.9401e-02 (8.5024e-02) 
2023-05-25 23:07:53.476367: train Epoch: [38][ 68/129]	Time  2.594 ( 1.861)	Data  1.645 ( 0.914)	Loss 5.8139e-02 (8.4634e-02) 
2023-05-25 23:07:54.429674: train Epoch: [38][ 69/129]	Time  0.953 ( 1.848)	Data  0.001 ( 0.901)	Loss 9.1163e-02 (8.4728e-02) 
2023-05-25 23:07:57.167192: train Epoch: [38][ 70/129]	Time  2.738 ( 1.860)	Data  1.776 ( 0.913)	Loss 8.5849e-02 (8.4743e-02) 
2023-05-25 23:07:58.121316: train Epoch: [38][ 71/129]	Time  0.954 ( 1.848)	Data  0.001 ( 0.900)	Loss 8.8100e-02 (8.4790e-02) 
2023-05-25 23:08:00.746871: train Epoch: [38][ 72/129]	Time  2.626 ( 1.858)	Data  1.668 ( 0.911)	Loss 8.9430e-02 (8.4854e-02) 
2023-05-25 23:08:01.700649: train Epoch: [38][ 73/129]	Time  0.954 ( 1.846)	Data  0.001 ( 0.899)	Loss 7.2732e-02 (8.4690e-02) 
2023-05-25 23:08:04.370508: train Epoch: [38][ 74/129]	Time  2.670 ( 1.857)	Data  1.718 ( 0.910)	Loss 5.8389e-02 (8.4339e-02) 
2023-05-25 23:08:05.313137: train Epoch: [38][ 75/129]	Time  0.943 ( 1.845)	Data  0.001 ( 0.898)	Loss 8.0477e-02 (8.4288e-02) 
2023-05-25 23:08:07.938355: train Epoch: [38][ 76/129]	Time  2.625 ( 1.855)	Data  1.673 ( 0.908)	Loss 8.9729e-02 (8.4359e-02) 
2023-05-25 23:08:08.882301: train Epoch: [38][ 77/129]	Time  0.944 ( 1.843)	Data  0.001 ( 0.896)	Loss 5.3045e-02 (8.3957e-02) 
2023-05-25 23:08:11.492967: train Epoch: [38][ 78/129]	Time  2.611 ( 1.853)	Data  1.669 ( 0.906)	Loss 5.6649e-02 (8.3612e-02) 
2023-05-25 23:08:12.437235: train Epoch: [38][ 79/129]	Time  0.944 ( 1.842)	Data  0.001 ( 0.895)	Loss 1.2452e-01 (8.4123e-02) 
2023-05-25 23:08:15.190589: train Epoch: [38][ 80/129]	Time  2.753 ( 1.853)	Data  1.803 ( 0.906)	Loss 6.2801e-02 (8.3860e-02) 
2023-05-25 23:08:16.133552: train Epoch: [38][ 81/129]	Time  0.943 ( 1.842)	Data  0.001 ( 0.895)	Loss 4.9209e-02 (8.3437e-02) 
2023-05-25 23:08:18.836980: train Epoch: [38][ 82/129]	Time  2.703 ( 1.852)	Data  1.754 ( 0.905)	Loss 5.8613e-02 (8.3138e-02) 
2023-05-25 23:08:19.780955: train Epoch: [38][ 83/129]	Time  0.944 ( 1.841)	Data  0.001 ( 0.894)	Loss 4.7040e-02 (8.2708e-02) 
2023-05-25 23:08:22.451893: train Epoch: [38][ 84/129]	Time  2.671 ( 1.851)	Data  1.727 ( 0.904)	Loss 6.6740e-02 (8.2521e-02) 
2023-05-25 23:08:23.395836: train Epoch: [38][ 85/129]	Time  0.944 ( 1.841)	Data  0.001 ( 0.894)	Loss 7.7172e-02 (8.2458e-02) 
2023-05-25 23:08:26.028126: train Epoch: [38][ 86/129]	Time  2.632 ( 1.850)	Data  1.684 ( 0.903)	Loss 1.0557e-01 (8.2724e-02) 
2023-05-25 23:08:26.971566: train Epoch: [38][ 87/129]	Time  0.943 ( 1.839)	Data  0.001 ( 0.892)	Loss 9.5432e-02 (8.2869e-02) 
2023-05-25 23:08:29.694067: train Epoch: [38][ 88/129]	Time  2.722 ( 1.849)	Data  1.770 ( 0.902)	Loss 9.2914e-02 (8.2981e-02) 
2023-05-25 23:08:30.637837: train Epoch: [38][ 89/129]	Time  0.944 ( 1.839)	Data  0.001 ( 0.892)	Loss 1.1848e-01 (8.3376e-02) 
2023-05-25 23:08:33.260648: train Epoch: [38][ 90/129]	Time  2.623 ( 1.848)	Data  1.672 ( 0.901)	Loss 8.4506e-02 (8.3388e-02) 
2023-05-25 23:08:34.205100: train Epoch: [38][ 91/129]	Time  0.944 ( 1.838)	Data  0.001 ( 0.891)	Loss 9.7292e-02 (8.3539e-02) 
2023-05-25 23:08:36.834870: train Epoch: [38][ 92/129]	Time  2.630 ( 1.847)	Data  1.689 ( 0.900)	Loss 5.9639e-02 (8.3282e-02) 
2023-05-25 23:08:37.778083: train Epoch: [38][ 93/129]	Time  0.943 ( 1.837)	Data  0.001 ( 0.890)	Loss 7.2780e-02 (8.3171e-02) 
2023-05-25 23:08:40.579504: train Epoch: [38][ 94/129]	Time  2.801 ( 1.847)	Data  1.849 ( 0.900)	Loss 6.5592e-02 (8.2986e-02) 
2023-05-25 23:08:41.523221: train Epoch: [38][ 95/129]	Time  0.944 ( 1.838)	Data  0.001 ( 0.891)	Loss 8.4733e-02 (8.3004e-02) 
2023-05-25 23:08:44.154606: train Epoch: [38][ 96/129]	Time  2.631 ( 1.846)	Data  1.689 ( 0.899)	Loss 6.5818e-02 (8.2827e-02) 
2023-05-25 23:08:45.096611: train Epoch: [38][ 97/129]	Time  0.942 ( 1.837)	Data  0.001 ( 0.890)	Loss 8.8239e-02 (8.2882e-02) 
2023-05-25 23:08:47.770813: train Epoch: [38][ 98/129]	Time  2.674 ( 1.845)	Data  1.724 ( 0.898)	Loss 7.5226e-02 (8.2805e-02) 
2023-05-25 23:08:48.713250: train Epoch: [38][ 99/129]	Time  0.942 ( 1.836)	Data  0.001 ( 0.889)	Loss 7.0294e-02 (8.2679e-02) 
2023-05-25 23:08:51.339534: train Epoch: [38][100/129]	Time  2.626 ( 1.844)	Data  1.684 ( 0.897)	Loss 1.1578e-01 (8.3007e-02) 
2023-05-25 23:08:52.283458: train Epoch: [38][101/129]	Time  0.944 ( 1.835)	Data  0.001 ( 0.888)	Loss 7.6430e-02 (8.2943e-02) 
2023-05-25 23:08:54.900899: train Epoch: [38][102/129]	Time  2.617 ( 1.843)	Data  1.673 ( 0.896)	Loss 5.5234e-02 (8.2674e-02) 
2023-05-25 23:08:55.844238: train Epoch: [38][103/129]	Time  0.943 ( 1.834)	Data  0.001 ( 0.887)	Loss 7.9791e-02 (8.2646e-02) 
2023-05-25 23:08:58.460217: train Epoch: [38][104/129]	Time  2.616 ( 1.842)	Data  1.674 ( 0.895)	Loss 6.9771e-02 (8.2523e-02) 
2023-05-25 23:08:59.405020: train Epoch: [38][105/129]	Time  0.945 ( 1.833)	Data  0.001 ( 0.886)	Loss 7.7227e-02 (8.2473e-02) 
2023-05-25 23:09:02.008868: train Epoch: [38][106/129]	Time  2.604 ( 1.840)	Data  1.662 ( 0.894)	Loss 6.5329e-02 (8.2313e-02) 
2023-05-25 23:09:02.952349: train Epoch: [38][107/129]	Time  0.943 ( 1.832)	Data  0.001 ( 0.885)	Loss 8.4072e-02 (8.2329e-02) 
2023-05-25 23:09:05.730812: train Epoch: [38][108/129]	Time  2.778 ( 1.841)	Data  1.836 ( 0.894)	Loss 1.3013e-01 (8.2768e-02) 
2023-05-25 23:09:06.675682: train Epoch: [38][109/129]	Time  0.945 ( 1.833)	Data  0.001 ( 0.886)	Loss 1.1422e-01 (8.3054e-02) 
2023-05-25 23:09:09.483093: train Epoch: [38][110/129]	Time  2.807 ( 1.841)	Data  1.863 ( 0.895)	Loss 4.9339e-02 (8.2750e-02) 
2023-05-25 23:09:10.429868: train Epoch: [38][111/129]	Time  0.947 ( 1.833)	Data  0.001 ( 0.887)	Loss 9.4013e-02 (8.2851e-02) 
2023-05-25 23:09:13.143199: train Epoch: [38][112/129]	Time  2.713 ( 1.841)	Data  1.761 ( 0.895)	Loss 1.0100e-01 (8.3011e-02) 
2023-05-25 23:09:14.088160: train Epoch: [38][113/129]	Time  0.945 ( 1.833)	Data  0.001 ( 0.887)	Loss 7.1359e-02 (8.2909e-02) 
2023-05-25 23:09:16.756795: train Epoch: [38][114/129]	Time  2.669 ( 1.841)	Data  1.718 ( 0.894)	Loss 7.4569e-02 (8.2837e-02) 
2023-05-25 23:09:17.700528: train Epoch: [38][115/129]	Time  0.944 ( 1.833)	Data  0.001 ( 0.886)	Loss 6.3301e-02 (8.2668e-02) 
2023-05-25 23:09:20.377156: train Epoch: [38][116/129]	Time  2.677 ( 1.840)	Data  1.724 ( 0.893)	Loss 7.2519e-02 (8.2581e-02) 
2023-05-25 23:09:21.321038: train Epoch: [38][117/129]	Time  0.944 ( 1.832)	Data  0.001 ( 0.886)	Loss 8.6079e-02 (8.2611e-02) 
2023-05-25 23:09:23.981677: train Epoch: [38][118/129]	Time  2.661 ( 1.839)	Data  1.715 ( 0.893)	Loss 1.1018e-01 (8.2843e-02) 
2023-05-25 23:09:24.955390: train Epoch: [38][119/129]	Time  0.974 ( 1.832)	Data  0.001 ( 0.885)	Loss 6.6632e-02 (8.2708e-02) 
2023-05-25 23:09:27.620786: train Epoch: [38][120/129]	Time  2.665 ( 1.839)	Data  1.708 ( 0.892)	Loss 9.6740e-02 (8.2824e-02) 
2023-05-25 23:09:28.574155: train Epoch: [38][121/129]	Time  0.953 ( 1.832)	Data  0.001 ( 0.885)	Loss 6.9190e-02 (8.2712e-02) 
2023-05-25 23:09:31.367191: train Epoch: [38][122/129]	Time  2.793 ( 1.840)	Data  1.841 ( 0.893)	Loss 7.8335e-02 (8.2676e-02) 
2023-05-25 23:09:32.320744: train Epoch: [38][123/129]	Time  0.954 ( 1.832)	Data  0.001 ( 0.885)	Loss 4.5840e-02 (8.2379e-02) 
2023-05-25 23:09:34.991920: train Epoch: [38][124/129]	Time  2.671 ( 1.839)	Data  1.721 ( 0.892)	Loss 8.0203e-02 (8.2362e-02) 
2023-05-25 23:09:35.944448: train Epoch: [38][125/129]	Time  0.953 ( 1.832)	Data  0.001 ( 0.885)	Loss 6.4852e-02 (8.2223e-02) 
2023-05-25 23:09:38.781112: train Epoch: [38][126/129]	Time  2.837 ( 1.840)	Data  1.886 ( 0.893)	Loss 8.7254e-02 (8.2263e-02) 
2023-05-25 23:09:39.728775: train Epoch: [38][127/129]	Time  0.948 ( 1.833)	Data  0.001 ( 0.886)	Loss 9.6401e-02 (8.2373e-02) 
2023-05-25 23:09:41.187124: train Epoch: [38][128/129]	Time  1.458 ( 1.830)	Data  0.510 ( 0.883)	Loss 4.0461e-02 (8.2048e-02) 
2023-05-25 23:09:41.218845: Train Epoch done in 236.1223394970002 s 
2023-05-25 23:09:43.559496: val Epoch: [38][ 0/72]	Time  1.641 ( 1.641)	Data  1.437 ( 1.437)	Loss 3.1738e-01 (3.1738e-01) 
2023-05-25 23:09:43.688776: val Epoch: [38][ 1/72]	Time  0.130 ( 0.885)	Data  0.001 ( 0.719)	Loss 1.2095e-01 (2.1916e-01) 
2023-05-25 23:09:44.661934: val Epoch: [38][ 2/72]	Time  0.973 ( 0.915)	Data  0.848 ( 0.762)	Loss 9.3927e-02 (1.7742e-01) 
2023-05-25 23:09:44.786641: val Epoch: [38][ 3/72]	Time  0.125 ( 0.717)	Data  0.001 ( 0.572)	Loss 1.1824e-01 (1.6262e-01) 
2023-05-25 23:09:45.935836: val Epoch: [38][ 4/72]	Time  1.149 ( 0.804)	Data  1.024 ( 0.662)	Loss 1.4906e-01 (1.5991e-01) 
2023-05-25 23:09:46.060828: val Epoch: [38][ 5/72]	Time  0.125 ( 0.690)	Data  0.001 ( 0.552)	Loss 3.3485e-02 (1.3884e-01) 
2023-05-25 23:09:47.170115: val Epoch: [38][ 6/72]	Time  1.109 ( 0.750)	Data  0.987 ( 0.614)	Loss 1.3849e-01 (1.3879e-01) 
2023-05-25 23:09:47.294786: val Epoch: [38][ 7/72]	Time  0.125 ( 0.672)	Data  0.001 ( 0.538)	Loss 9.4335e-02 (1.3323e-01) 
2023-05-25 23:09:48.346702: val Epoch: [38][ 8/72]	Time  1.052 ( 0.714)	Data  0.930 ( 0.581)	Loss 1.1161e-01 (1.3083e-01) 
2023-05-25 23:09:48.470935: val Epoch: [38][ 9/72]	Time  0.124 ( 0.655)	Data  0.001 ( 0.523)	Loss 1.4754e-01 (1.3250e-01) 
2023-05-25 23:09:49.565161: val Epoch: [38][10/72]	Time  1.094 ( 0.695)	Data  0.969 ( 0.564)	Loss 8.3445e-02 (1.2804e-01) 
2023-05-25 23:09:49.689455: val Epoch: [38][11/72]	Time  0.124 ( 0.648)	Data  0.001 ( 0.517)	Loss 5.1393e-02 (1.2165e-01) 
2023-05-25 23:09:50.776150: val Epoch: [38][12/72]	Time  1.087 ( 0.681)	Data  0.963 ( 0.551)	Loss 2.3728e-01 (1.3055e-01) 
2023-05-25 23:09:50.900904: val Epoch: [38][13/72]	Time  0.125 ( 0.642)	Data  0.001 ( 0.512)	Loss 1.2242e-01 (1.2997e-01) 
2023-05-25 23:09:51.941168: val Epoch: [38][14/72]	Time  1.040 ( 0.668)	Data  0.919 ( 0.539)	Loss 9.7041e-02 (1.2777e-01) 
2023-05-25 23:09:52.062459: val Epoch: [38][15/72]	Time  0.121 ( 0.634)	Data  0.001 ( 0.505)	Loss 4.0126e-01 (1.4487e-01) 
2023-05-25 23:09:53.156122: val Epoch: [38][16/72]	Time  1.094 ( 0.661)	Data  0.973 ( 0.533)	Loss 3.3530e-01 (1.5607e-01) 
2023-05-25 23:09:53.277366: val Epoch: [38][17/72]	Time  0.121 ( 0.631)	Data  0.001 ( 0.503)	Loss 6.0153e-02 (1.5074e-01) 
2023-05-25 23:09:54.341764: val Epoch: [38][18/72]	Time  1.064 ( 0.654)	Data  0.943 ( 0.526)	Loss 5.8640e-02 (1.4589e-01) 
2023-05-25 23:09:54.463220: val Epoch: [38][19/72]	Time  0.121 ( 0.627)	Data  0.001 ( 0.500)	Loss 1.6172e-01 (1.4668e-01) 
2023-05-25 23:09:55.561006: val Epoch: [38][20/72]	Time  1.098 ( 0.650)	Data  0.977 ( 0.523)	Loss 9.2174e-02 (1.4409e-01) 
2023-05-25 23:09:55.685181: val Epoch: [38][21/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.499)	Loss 5.3951e-02 (1.3999e-01) 
2023-05-25 23:09:56.777364: val Epoch: [38][22/72]	Time  1.092 ( 0.646)	Data  0.971 ( 0.519)	Loss 1.1401e-01 (1.3886e-01) 
2023-05-25 23:09:56.898581: val Epoch: [38][23/72]	Time  0.121 ( 0.624)	Data  0.001 ( 0.498)	Loss 3.1416e-01 (1.4617e-01) 
2023-05-25 23:09:57.944940: val Epoch: [38][24/72]	Time  1.046 ( 0.641)	Data  0.925 ( 0.515)	Loss 6.6129e-02 (1.4296e-01) 
2023-05-25 23:09:58.066654: val Epoch: [38][25/72]	Time  0.122 ( 0.621)	Data  0.001 ( 0.495)	Loss 1.1120e-01 (1.4174e-01) 
2023-05-25 23:09:59.083614: val Epoch: [38][26/72]	Time  1.017 ( 0.636)	Data  0.896 ( 0.510)	Loss 4.2789e-02 (1.3808e-01) 
2023-05-25 23:09:59.204778: val Epoch: [38][27/72]	Time  0.121 ( 0.617)	Data  0.001 ( 0.492)	Loss 3.9156e-02 (1.3454e-01) 
2023-05-25 23:10:00.316754: val Epoch: [38][28/72]	Time  1.112 ( 0.634)	Data  0.988 ( 0.509)	Loss 1.0692e-01 (1.3359e-01) 
2023-05-25 23:10:00.442198: val Epoch: [38][29/72]	Time  0.125 ( 0.617)	Data  0.001 ( 0.492)	Loss 1.7638e-01 (1.3502e-01) 
2023-05-25 23:10:01.500462: val Epoch: [38][30/72]	Time  1.058 ( 0.632)	Data  0.937 ( 0.506)	Loss 4.2448e-02 (1.3203e-01) 
2023-05-25 23:10:01.628496: val Epoch: [38][31/72]	Time  0.128 ( 0.616)	Data  0.001 ( 0.491)	Loss 3.0164e-01 (1.3733e-01) 
2023-05-25 23:10:02.672858: val Epoch: [38][32/72]	Time  1.044 ( 0.629)	Data  0.920 ( 0.504)	Loss 5.9829e-02 (1.3498e-01) 
2023-05-25 23:10:02.797822: val Epoch: [38][33/72]	Time  0.125 ( 0.614)	Data  0.001 ( 0.489)	Loss 4.8690e-02 (1.3245e-01) 
2023-05-25 23:10:03.820773: val Epoch: [38][34/72]	Time  1.023 ( 0.626)	Data  0.898 ( 0.500)	Loss 6.2957e-02 (1.3046e-01) 
2023-05-25 23:10:03.945323: val Epoch: [38][35/72]	Time  0.125 ( 0.612)	Data  0.001 ( 0.487)	Loss 6.3006e-02 (1.2859e-01) 
2023-05-25 23:10:05.022734: val Epoch: [38][36/72]	Time  1.077 ( 0.624)	Data  0.954 ( 0.499)	Loss 3.8782e-01 (1.3559e-01) 
2023-05-25 23:10:05.147322: val Epoch: [38][37/72]	Time  0.125 ( 0.611)	Data  0.001 ( 0.486)	Loss 8.4084e-02 (1.3424e-01) 
2023-05-25 23:10:06.222159: val Epoch: [38][38/72]	Time  1.075 ( 0.623)	Data  0.953 ( 0.498)	Loss 5.6198e-02 (1.3224e-01) 
2023-05-25 23:10:06.343563: val Epoch: [38][39/72]	Time  0.121 ( 0.611)	Data  0.001 ( 0.486)	Loss 2.1648e-01 (1.3434e-01) 
2023-05-25 23:10:07.438351: val Epoch: [38][40/72]	Time  1.095 ( 0.622)	Data  0.971 ( 0.497)	Loss 3.8532e-01 (1.4046e-01) 
2023-05-25 23:10:07.562684: val Epoch: [38][41/72]	Time  0.124 ( 0.611)	Data  0.001 ( 0.486)	Loss 7.1097e-02 (1.3881e-01) 
2023-05-25 23:10:08.603606: val Epoch: [38][42/72]	Time  1.041 ( 0.621)	Data  0.917 ( 0.496)	Loss 4.0212e-02 (1.3652e-01) 
2023-05-25 23:10:08.727928: val Epoch: [38][43/72]	Time  0.124 ( 0.609)	Data  0.001 ( 0.484)	Loss 9.0546e-02 (1.3547e-01) 
2023-05-25 23:10:09.806964: val Epoch: [38][44/72]	Time  1.079 ( 0.620)	Data  0.955 ( 0.495)	Loss 4.8954e-02 (1.3355e-01) 
2023-05-25 23:10:09.931048: val Epoch: [38][45/72]	Time  0.124 ( 0.609)	Data  0.001 ( 0.484)	Loss 1.0580e-01 (1.3295e-01) 
2023-05-25 23:10:11.000787: val Epoch: [38][46/72]	Time  1.070 ( 0.619)	Data  0.946 ( 0.494)	Loss 3.9180e-02 (1.3095e-01) 
2023-05-25 23:10:11.124886: val Epoch: [38][47/72]	Time  0.124 ( 0.608)	Data  0.001 ( 0.484)	Loss 1.0192e-01 (1.3035e-01) 
2023-05-25 23:10:12.195575: val Epoch: [38][48/72]	Time  1.071 ( 0.618)	Data  0.946 ( 0.493)	Loss 7.3925e-02 (1.2920e-01) 
2023-05-25 23:10:12.319465: val Epoch: [38][49/72]	Time  0.124 ( 0.608)	Data  0.001 ( 0.483)	Loss 5.8091e-02 (1.2778e-01) 
2023-05-25 23:10:13.342820: val Epoch: [38][50/72]	Time  1.023 ( 0.616)	Data  0.899 ( 0.491)	Loss 5.6559e-02 (1.2638e-01) 
2023-05-25 23:10:13.467746: val Epoch: [38][51/72]	Time  0.125 ( 0.607)	Data  0.001 ( 0.482)	Loss 2.9908e-01 (1.2970e-01) 
2023-05-25 23:10:14.493627: val Epoch: [38][52/72]	Time  1.026 ( 0.615)	Data  0.904 ( 0.490)	Loss 5.0220e-02 (1.2820e-01) 
2023-05-25 23:10:14.617710: val Epoch: [38][53/72]	Time  0.124 ( 0.606)	Data  0.001 ( 0.481)	Loss 5.5437e-02 (1.2685e-01) 
2023-05-25 23:10:15.689159: val Epoch: [38][54/72]	Time  1.071 ( 0.614)	Data  0.947 ( 0.489)	Loss 1.4254e-01 (1.2714e-01) 
2023-05-25 23:10:15.809911: val Epoch: [38][55/72]	Time  0.121 ( 0.605)	Data  0.001 ( 0.481)	Loss 7.5934e-02 (1.2622e-01) 
2023-05-25 23:10:16.880873: val Epoch: [38][56/72]	Time  1.071 ( 0.613)	Data  0.947 ( 0.489)	Loss 8.6024e-02 (1.2552e-01) 
2023-05-25 23:10:17.005789: val Epoch: [38][57/72]	Time  0.125 ( 0.605)	Data  0.001 ( 0.480)	Loss 7.3101e-02 (1.2461e-01) 
2023-05-25 23:10:18.083397: val Epoch: [38][58/72]	Time  1.078 ( 0.613)	Data  0.952 ( 0.488)	Loss 6.1251e-02 (1.2354e-01) 
2023-05-25 23:10:18.204964: val Epoch: [38][59/72]	Time  0.122 ( 0.605)	Data  0.001 ( 0.480)	Loss 5.5604e-02 (1.2241e-01) 
2023-05-25 23:10:19.296047: val Epoch: [38][60/72]	Time  1.091 ( 0.613)	Data  0.966 ( 0.488)	Loss 1.7294e-01 (1.2324e-01) 
2023-05-25 23:10:19.417238: val Epoch: [38][61/72]	Time  0.121 ( 0.605)	Data  0.001 ( 0.480)	Loss 1.2177e-01 (1.2321e-01) 
2023-05-25 23:10:20.630268: val Epoch: [38][62/72]	Time  1.213 ( 0.614)	Data  1.092 ( 0.490)	Loss 7.7413e-02 (1.2249e-01) 
2023-05-25 23:10:20.751341: val Epoch: [38][63/72]	Time  0.121 ( 0.607)	Data  0.001 ( 0.482)	Loss 7.9064e-02 (1.2181e-01) 
2023-05-25 23:10:21.829695: val Epoch: [38][64/72]	Time  1.078 ( 0.614)	Data  0.952 ( 0.490)	Loss 5.3158e-02 (1.2075e-01) 
2023-05-25 23:10:21.951098: val Epoch: [38][65/72]	Time  0.121 ( 0.607)	Data  0.001 ( 0.482)	Loss 6.0376e-01 (1.2807e-01) 
2023-05-25 23:10:22.955247: val Epoch: [38][66/72]	Time  1.004 ( 0.612)	Data  0.882 ( 0.488)	Loss 4.5712e-02 (1.2684e-01) 
2023-05-25 23:10:23.097208: val Epoch: [38][67/72]	Time  0.142 ( 0.606)	Data  0.025 ( 0.481)	Loss 4.3568e-02 (1.2562e-01) 
2023-05-25 23:10:24.120265: val Epoch: [38][68/72]	Time  1.023 ( 0.612)	Data  0.906 ( 0.488)	Loss 4.0500e-02 (1.2438e-01) 
2023-05-25 23:10:24.287167: val Epoch: [38][69/72]	Time  0.167 ( 0.605)	Data  0.050 ( 0.481)	Loss 4.1394e-01 (1.2852e-01) 
2023-05-25 23:10:25.311100: val Epoch: [38][70/72]	Time  1.024 ( 0.611)	Data  0.901 ( 0.487)	Loss 9.1827e-02 (1.2800e-01) 
2023-05-25 23:10:25.427606: val Epoch: [38][71/72]	Time  0.117 ( 0.604)	Data  0.000 ( 0.480)	Loss 9.6492e-02 (1.2756e-01) 
2023-05-25 23:10:25.617245: Epoch 38 :Val : ['ET : 0.7603530287742615', 'TC : 0.7849870324134827', 'WT : 0.8651764392852783'] 
2023-05-25 23:10:25.620172: Epoch 38 :Val : ['ET : 0.7603530287742615', 'TC : 0.7849870324134827', 'WT : 0.8651764392852783'] 
2023-05-25 23:10:25.622018: Saving the model with DSC 0.7995040416717529 
2023-05-25 23:10:26.228272: Val epoch done in 45.00940934400205 s 
2023-05-25 23:10:26.233506: Batches per epoch:  129 
2023-05-25 23:10:31.229044: train Epoch: [39][  0/129]	Time  4.995 ( 4.995)	Data  3.940 ( 3.940)	Loss 7.9554e-02 (7.9554e-02) 
2023-05-25 23:10:32.188806: train Epoch: [39][  1/129]	Time  0.960 ( 2.978)	Data  0.001 ( 1.970)	Loss 4.9832e-02 (6.4693e-02) 
2023-05-25 23:10:34.938674: train Epoch: [39][  2/129]	Time  2.750 ( 2.902)	Data  1.794 ( 1.912)	Loss 8.4245e-02 (7.1210e-02) 
2023-05-25 23:10:35.925759: train Epoch: [39][  3/129]	Time  0.987 ( 2.423)	Data  0.001 ( 1.434)	Loss 5.8094e-02 (6.7931e-02) 
2023-05-25 23:10:38.635803: train Epoch: [39][  4/129]	Time  2.710 ( 2.480)	Data  1.752 ( 1.497)	Loss 2.3049e-01 (1.0044e-01) 
2023-05-25 23:10:39.594879: train Epoch: [39][  5/129]	Time  0.959 ( 2.227)	Data  0.001 ( 1.248)	Loss 9.6464e-02 (9.9780e-02) 
2023-05-25 23:10:42.315912: train Epoch: [39][  6/129]	Time  2.721 ( 2.297)	Data  1.765 ( 1.322)	Loss 9.0724e-02 (9.8487e-02) 
2023-05-25 23:10:43.279352: train Epoch: [39][  7/129]	Time  0.963 ( 2.131)	Data  0.001 ( 1.157)	Loss 8.0835e-02 (9.6280e-02) 
2023-05-25 23:10:46.055593: train Epoch: [39][  8/129]	Time  2.776 ( 2.202)	Data  1.821 ( 1.231)	Loss 8.0578e-02 (9.4535e-02) 
2023-05-25 23:10:47.017724: train Epoch: [39][  9/129]	Time  0.962 ( 2.078)	Data  0.001 ( 1.108)	Loss 6.8930e-02 (9.1975e-02) 
2023-05-25 23:10:49.673442: train Epoch: [39][ 10/129]	Time  2.656 ( 2.131)	Data  1.699 ( 1.161)	Loss 9.8892e-02 (9.2604e-02) 
2023-05-25 23:10:50.634808: train Epoch: [39][ 11/129]	Time  0.961 ( 2.033)	Data  0.001 ( 1.065)	Loss 8.8575e-02 (9.2268e-02) 
2023-05-25 23:10:53.329216: train Epoch: [39][ 12/129]	Time  2.694 ( 2.084)	Data  1.734 ( 1.116)	Loss 5.2738e-02 (8.9227e-02) 
2023-05-25 23:10:54.288983: train Epoch: [39][ 13/129]	Time  0.960 ( 2.004)	Data  0.001 ( 1.036)	Loss 5.4690e-02 (8.6760e-02) 
2023-05-25 23:10:56.884229: train Epoch: [39][ 14/129]	Time  2.595 ( 2.043)	Data  1.644 ( 1.077)	Loss 6.9584e-02 (8.5615e-02) 
2023-05-25 23:10:57.834254: train Epoch: [39][ 15/129]	Time  0.950 ( 1.975)	Data  0.001 ( 1.010)	Loss 6.0854e-02 (8.4068e-02) 
2023-05-25 23:11:00.484357: train Epoch: [39][ 16/129]	Time  2.650 ( 2.015)	Data  1.703 ( 1.051)	Loss 8.3964e-02 (8.4061e-02) 
2023-05-25 23:11:01.434456: train Epoch: [39][ 17/129]	Time  0.950 ( 1.956)	Data  0.001 ( 0.992)	Loss 8.4143e-02 (8.4066e-02) 
2023-05-25 23:11:04.219232: train Epoch: [39][ 18/129]	Time  2.785 ( 1.999)	Data  1.836 ( 1.037)	Loss 7.8429e-02 (8.3769e-02) 
2023-05-25 23:11:05.169412: train Epoch: [39][ 19/129]	Time  0.950 ( 1.947)	Data  0.001 ( 0.985)	Loss 8.2353e-02 (8.3698e-02) 
2023-05-25 23:11:07.781151: train Epoch: [39][ 20/129]	Time  2.612 ( 1.978)	Data  1.651 ( 1.017)	Loss 1.3982e-01 (8.6371e-02) 
2023-05-25 23:11:08.731050: train Epoch: [39][ 21/129]	Time  0.950 ( 1.932)	Data  0.001 ( 0.970)	Loss 6.6813e-02 (8.5482e-02) 
2023-05-25 23:11:11.393033: train Epoch: [39][ 22/129]	Time  2.662 ( 1.963)	Data  1.706 ( 1.002)	Loss 1.0395e-01 (8.6285e-02) 
2023-05-25 23:11:12.343709: train Epoch: [39][ 23/129]	Time  0.951 ( 1.921)	Data  0.001 ( 0.961)	Loss 1.0613e-01 (8.7112e-02) 
2023-05-25 23:11:14.962825: train Epoch: [39][ 24/129]	Time  2.619 ( 1.949)	Data  1.660 ( 0.989)	Loss 7.9607e-02 (8.6812e-02) 
2023-05-25 23:11:15.924228: train Epoch: [39][ 25/129]	Time  0.961 ( 1.911)	Data  0.001 ( 0.951)	Loss 6.3493e-02 (8.5915e-02) 
2023-05-25 23:11:18.594516: train Epoch: [39][ 26/129]	Time  2.670 ( 1.939)	Data  1.711 ( 0.979)	Loss 6.4818e-02 (8.5133e-02) 
2023-05-25 23:11:19.553939: train Epoch: [39][ 27/129]	Time  0.959 ( 1.904)	Data  0.001 ( 0.944)	Loss 5.5603e-02 (8.4079e-02) 
2023-05-25 23:11:22.177554: train Epoch: [39][ 28/129]	Time  2.624 ( 1.929)	Data  1.663 ( 0.969)	Loss 9.9854e-02 (8.4623e-02) 
2023-05-25 23:11:23.141613: train Epoch: [39][ 29/129]	Time  0.964 ( 1.897)	Data  0.001 ( 0.936)	Loss 6.0778e-02 (8.3828e-02) 
2023-05-25 23:11:25.850652: train Epoch: [39][ 30/129]	Time  2.709 ( 1.923)	Data  1.739 ( 0.962)	Loss 7.0895e-02 (8.3411e-02) 
2023-05-25 23:11:26.811768: train Epoch: [39][ 31/129]	Time  0.961 ( 1.893)	Data  0.001 ( 0.932)	Loss 7.0942e-02 (8.3021e-02) 
2023-05-25 23:11:29.545145: train Epoch: [39][ 32/129]	Time  2.733 ( 1.919)	Data  1.769 ( 0.958)	Loss 6.9777e-02 (8.2620e-02) 
2023-05-25 23:11:30.506132: train Epoch: [39][ 33/129]	Time  0.961 ( 1.890)	Data  0.001 ( 0.929)	Loss 8.0624e-02 (8.2561e-02) 
2023-05-25 23:11:33.138902: train Epoch: [39][ 34/129]	Time  2.633 ( 1.912)	Data  1.673 ( 0.951)	Loss 5.9735e-02 (8.1909e-02) 
2023-05-25 23:11:34.102623: train Epoch: [39][ 35/129]	Time  0.964 ( 1.885)	Data  0.001 ( 0.924)	Loss 6.3692e-02 (8.1403e-02) 
2023-05-25 23:11:36.714672: train Epoch: [39][ 36/129]	Time  2.612 ( 1.905)	Data  1.651 ( 0.944)	Loss 4.4947e-02 (8.0418e-02) 
2023-05-25 23:11:37.675544: train Epoch: [39][ 37/129]	Time  0.961 ( 1.880)	Data  0.001 ( 0.919)	Loss 5.6322e-02 (7.9783e-02) 
2023-05-25 23:11:40.293990: train Epoch: [39][ 38/129]	Time  2.618 ( 1.899)	Data  1.649 ( 0.938)	Loss 4.2260e-02 (7.8821e-02) 
2023-05-25 23:11:41.254514: train Epoch: [39][ 39/129]	Time  0.961 ( 1.876)	Data  0.001 ( 0.914)	Loss 1.1115e-01 (7.9629e-02) 
2023-05-25 23:11:43.856359: train Epoch: [39][ 40/129]	Time  2.602 ( 1.893)	Data  1.643 ( 0.932)	Loss 6.1676e-02 (7.9192e-02) 
2023-05-25 23:11:44.818723: train Epoch: [39][ 41/129]	Time  0.962 ( 1.871)	Data  0.001 ( 0.910)	Loss 1.0568e-01 (7.9822e-02) 
2023-05-25 23:11:47.555081: train Epoch: [39][ 42/129]	Time  2.736 ( 1.891)	Data  1.769 ( 0.930)	Loss 6.9496e-02 (7.9582e-02) 
2023-05-25 23:11:48.516963: train Epoch: [39][ 43/129]	Time  0.962 ( 1.870)	Data  0.001 ( 0.909)	Loss 8.4312e-02 (7.9690e-02) 
2023-05-25 23:11:51.061391: train Epoch: [39][ 44/129]	Time  2.544 ( 1.885)	Data  1.586 ( 0.924)	Loss 1.0215e-01 (8.0189e-02) 
2023-05-25 23:11:52.023920: train Epoch: [39][ 45/129]	Time  0.963 ( 1.865)	Data  0.001 ( 0.904)	Loss 5.9336e-02 (7.9735e-02) 
2023-05-25 23:11:54.664084: train Epoch: [39][ 46/129]	Time  2.640 ( 1.881)	Data  1.682 ( 0.920)	Loss 1.0933e-01 (8.0365e-02) 
2023-05-25 23:11:55.616940: train Epoch: [39][ 47/129]	Time  0.953 ( 1.862)	Data  0.001 ( 0.901)	Loss 7.9076e-02 (8.0338e-02) 
2023-05-25 23:11:58.257823: train Epoch: [39][ 48/129]	Time  2.641 ( 1.878)	Data  1.694 ( 0.917)	Loss 8.1554e-02 (8.0363e-02) 
2023-05-25 23:11:59.206196: train Epoch: [39][ 49/129]	Time  0.948 ( 1.859)	Data  0.001 ( 0.899)	Loss 9.3897e-02 (8.0634e-02) 
2023-05-25 23:12:01.903574: train Epoch: [39][ 50/129]	Time  2.697 ( 1.876)	Data  1.749 ( 0.916)	Loss 1.6151e-01 (8.2219e-02) 
2023-05-25 23:12:02.854739: train Epoch: [39][ 51/129]	Time  0.951 ( 1.858)	Data  0.001 ( 0.898)	Loss 6.7692e-02 (8.1940e-02) 
2023-05-25 23:12:05.744965: train Epoch: [39][ 52/129]	Time  2.890 ( 1.878)	Data  1.942 ( 0.918)	Loss 1.1217e-01 (8.2510e-02) 
2023-05-25 23:12:06.703730: train Epoch: [39][ 53/129]	Time  0.959 ( 1.861)	Data  0.001 ( 0.901)	Loss 7.7504e-02 (8.2418e-02) 
2023-05-25 23:12:09.441257: train Epoch: [39][ 54/129]	Time  2.738 ( 1.876)	Data  1.780 ( 0.917)	Loss 6.2574e-02 (8.2057e-02) 
2023-05-25 23:12:10.402126: train Epoch: [39][ 55/129]	Time  0.961 ( 1.860)	Data  0.001 ( 0.901)	Loss 9.2761e-02 (8.2248e-02) 
2023-05-25 23:12:13.049518: train Epoch: [39][ 56/129]	Time  2.647 ( 1.874)	Data  1.681 ( 0.914)	Loss 8.6462e-02 (8.2322e-02) 
2023-05-25 23:12:14.011908: train Epoch: [39][ 57/129]	Time  0.962 ( 1.858)	Data  0.001 ( 0.898)	Loss 7.3024e-02 (8.2162e-02) 
2023-05-25 23:12:16.838608: train Epoch: [39][ 58/129]	Time  2.827 ( 1.875)	Data  1.869 ( 0.915)	Loss 7.8969e-02 (8.2108e-02) 
2023-05-25 23:12:17.800627: train Epoch: [39][ 59/129]	Time  0.962 ( 1.859)	Data  0.001 ( 0.900)	Loss 5.5747e-02 (8.1668e-02) 
2023-05-25 23:12:20.401654: train Epoch: [39][ 60/129]	Time  2.601 ( 1.872)	Data  1.644 ( 0.912)	Loss 6.8947e-02 (8.1460e-02) 
2023-05-25 23:12:21.361484: train Epoch: [39][ 61/129]	Time  0.960 ( 1.857)	Data  0.001 ( 0.897)	Loss 4.3664e-02 (8.0850e-02) 
2023-05-25 23:12:23.955116: train Epoch: [39][ 62/129]	Time  2.594 ( 1.869)	Data  1.645 ( 0.909)	Loss 4.4626e-02 (8.0275e-02) 
2023-05-25 23:12:24.905905: train Epoch: [39][ 63/129]	Time  0.951 ( 1.854)	Data  0.001 ( 0.895)	Loss 8.3128e-02 (8.0320e-02) 
2023-05-25 23:12:27.758906: train Epoch: [39][ 64/129]	Time  2.853 ( 1.870)	Data  1.892 ( 0.910)	Loss 7.8125e-02 (8.0286e-02) 
2023-05-25 23:12:28.708573: train Epoch: [39][ 65/129]	Time  0.950 ( 1.856)	Data  0.001 ( 0.896)	Loss 9.0193e-02 (8.0436e-02) 
2023-05-25 23:12:31.415037: train Epoch: [39][ 66/129]	Time  2.706 ( 1.868)	Data  1.759 ( 0.909)	Loss 5.2081e-02 (8.0013e-02) 
2023-05-25 23:12:32.366367: train Epoch: [39][ 67/129]	Time  0.951 ( 1.855)	Data  0.001 ( 0.896)	Loss 8.1685e-02 (8.0037e-02) 
2023-05-25 23:12:35.110312: train Epoch: [39][ 68/129]	Time  2.744 ( 1.868)	Data  1.795 ( 0.909)	Loss 9.4644e-02 (8.0249e-02) 
2023-05-25 23:12:36.059922: train Epoch: [39][ 69/129]	Time  0.950 ( 1.855)	Data  0.001 ( 0.896)	Loss 8.8881e-02 (8.0372e-02) 
2023-05-25 23:12:38.692165: train Epoch: [39][ 70/129]	Time  2.632 ( 1.866)	Data  1.672 ( 0.907)	Loss 6.8826e-02 (8.0210e-02) 
2023-05-25 23:12:39.642385: train Epoch: [39][ 71/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.894)	Loss 6.4822e-02 (7.9996e-02) 
2023-05-25 23:12:42.422418: train Epoch: [39][ 72/129]	Time  2.780 ( 1.866)	Data  1.821 ( 0.907)	Loss 6.5622e-02 (7.9799e-02) 
2023-05-25 23:12:43.373248: train Epoch: [39][ 73/129]	Time  0.951 ( 1.853)	Data  0.001 ( 0.895)	Loss 5.3465e-02 (7.9443e-02) 
2023-05-25 23:12:46.104228: train Epoch: [39][ 74/129]	Time  2.731 ( 1.865)	Data  1.777 ( 0.907)	Loss 7.5345e-02 (7.9389e-02) 
2023-05-25 23:12:47.055123: train Epoch: [39][ 75/129]	Time  0.951 ( 1.853)	Data  0.001 ( 0.895)	Loss 1.0724e-01 (7.9755e-02) 
2023-05-25 23:12:49.816890: train Epoch: [39][ 76/129]	Time  2.762 ( 1.865)	Data  1.814 ( 0.907)	Loss 1.2873e-01 (8.0391e-02) 
2023-05-25 23:12:50.767459: train Epoch: [39][ 77/129]	Time  0.951 ( 1.853)	Data  0.001 ( 0.895)	Loss 7.4612e-02 (8.0317e-02) 
2023-05-25 23:12:53.354047: train Epoch: [39][ 78/129]	Time  2.587 ( 1.862)	Data  1.633 ( 0.904)	Loss 4.9610e-02 (7.9928e-02) 
2023-05-25 23:12:54.304188: train Epoch: [39][ 79/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.893)	Loss 5.0831e-02 (7.9565e-02) 
2023-05-25 23:12:56.946471: train Epoch: [39][ 80/129]	Time  2.642 ( 1.861)	Data  1.683 ( 0.903)	Loss 8.3107e-02 (7.9608e-02) 
2023-05-25 23:12:57.898008: train Epoch: [39][ 81/129]	Time  0.952 ( 1.850)	Data  0.001 ( 0.892)	Loss 7.7757e-02 (7.9586e-02) 
2023-05-25 23:13:00.600950: train Epoch: [39][ 82/129]	Time  2.703 ( 1.860)	Data  1.741 ( 0.902)	Loss 7.8666e-02 (7.9575e-02) 
2023-05-25 23:13:01.562204: train Epoch: [39][ 83/129]	Time  0.961 ( 1.849)	Data  0.001 ( 0.891)	Loss 8.1018e-02 (7.9592e-02) 
2023-05-25 23:13:04.168248: train Epoch: [39][ 84/129]	Time  2.606 ( 1.858)	Data  1.647 ( 0.900)	Loss 7.1890e-02 (7.9501e-02) 
2023-05-25 23:13:05.116873: train Epoch: [39][ 85/129]	Time  0.949 ( 1.847)	Data  0.001 ( 0.890)	Loss 3.1572e-02 (7.8944e-02) 
2023-05-25 23:13:07.836333: train Epoch: [39][ 86/129]	Time  2.719 ( 1.857)	Data  1.771 ( 0.900)	Loss 6.4582e-02 (7.8779e-02) 
2023-05-25 23:13:08.786633: train Epoch: [39][ 87/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.890)	Loss 1.0466e-01 (7.9073e-02) 
2023-05-25 23:13:11.504391: train Epoch: [39][ 88/129]	Time  2.718 ( 1.857)	Data  1.770 ( 0.900)	Loss 7.9890e-02 (7.9082e-02) 
2023-05-25 23:13:12.454379: train Epoch: [39][ 89/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.890)	Loss 7.3937e-02 (7.9025e-02) 
2023-05-25 23:13:15.176463: train Epoch: [39][ 90/129]	Time  2.722 ( 1.857)	Data  1.756 ( 0.899)	Loss 8.0305e-02 (7.9039e-02) 
2023-05-25 23:13:16.129983: train Epoch: [39][ 91/129]	Time  0.954 ( 1.847)	Data  0.001 ( 0.889)	Loss 3.7608e-02 (7.8589e-02) 
2023-05-25 23:13:18.754390: train Epoch: [39][ 92/129]	Time  2.624 ( 1.855)	Data  1.676 ( 0.898)	Loss 6.4624e-02 (7.8439e-02) 
2023-05-25 23:13:19.704464: train Epoch: [39][ 93/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.888)	Loss 8.2815e-02 (7.8485e-02) 
2023-05-25 23:13:22.584895: train Epoch: [39][ 94/129]	Time  2.880 ( 1.856)	Data  1.919 ( 0.899)	Loss 1.0949e-01 (7.8812e-02) 
2023-05-25 23:13:23.543464: train Epoch: [39][ 95/129]	Time  0.959 ( 1.847)	Data  0.001 ( 0.890)	Loss 8.5614e-02 (7.8882e-02) 
2023-05-25 23:13:26.246314: train Epoch: [39][ 96/129]	Time  2.703 ( 1.856)	Data  1.741 ( 0.899)	Loss 1.0021e-01 (7.9102e-02) 
2023-05-25 23:13:27.209109: train Epoch: [39][ 97/129]	Time  0.963 ( 1.847)	Data  0.001 ( 0.889)	Loss 1.1783e-01 (7.9497e-02) 
2023-05-25 23:13:29.914097: train Epoch: [39][ 98/129]	Time  2.705 ( 1.855)	Data  1.740 ( 0.898)	Loss 7.6613e-02 (7.9468e-02) 
2023-05-25 23:13:30.865757: train Epoch: [39][ 99/129]	Time  0.952 ( 1.846)	Data  0.001 ( 0.889)	Loss 5.2161e-02 (7.9195e-02) 
2023-05-25 23:13:33.457276: train Epoch: [39][100/129]	Time  2.592 ( 1.854)	Data  1.638 ( 0.896)	Loss 8.6066e-02 (7.9263e-02) 
2023-05-25 23:13:34.408712: train Epoch: [39][101/129]	Time  0.951 ( 1.845)	Data  0.001 ( 0.888)	Loss 8.1074e-02 (7.9281e-02) 
2023-05-25 23:13:37.023837: train Epoch: [39][102/129]	Time  2.615 ( 1.852)	Data  1.660 ( 0.895)	Loss 9.1843e-02 (7.9403e-02) 
2023-05-25 23:13:37.973331: train Epoch: [39][103/129]	Time  0.949 ( 1.844)	Data  0.001 ( 0.887)	Loss 1.5895e-01 (8.0168e-02) 
2023-05-25 23:13:40.584996: train Epoch: [39][104/129]	Time  2.612 ( 1.851)	Data  1.661 ( 0.894)	Loss 1.3853e-01 (8.0724e-02) 
2023-05-25 23:13:41.533451: train Epoch: [39][105/129]	Time  0.948 ( 1.842)	Data  0.001 ( 0.885)	Loss 1.0596e-01 (8.0962e-02) 
2023-05-25 23:13:44.211997: train Epoch: [39][106/129]	Time  2.679 ( 1.850)	Data  1.729 ( 0.893)	Loss 7.1069e-02 (8.0869e-02) 
2023-05-25 23:13:45.163025: train Epoch: [39][107/129]	Time  0.951 ( 1.842)	Data  0.001 ( 0.885)	Loss 9.6727e-02 (8.1016e-02) 
2023-05-25 23:13:47.738899: train Epoch: [39][108/129]	Time  2.576 ( 1.849)	Data  1.624 ( 0.892)	Loss 7.7683e-02 (8.0986e-02) 
2023-05-25 23:13:48.688627: train Epoch: [39][109/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.884)	Loss 1.4739e-01 (8.1589e-02) 
2023-05-25 23:13:51.284129: train Epoch: [39][110/129]	Time  2.595 ( 1.847)	Data  1.641 ( 0.891)	Loss 1.0445e-01 (8.1795e-02) 
2023-05-25 23:13:52.234639: train Epoch: [39][111/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.883)	Loss 8.0854e-02 (8.1787e-02) 
2023-05-25 23:13:54.780285: train Epoch: [39][112/129]	Time  2.546 ( 1.846)	Data  1.596 ( 0.889)	Loss 5.5590e-02 (8.1555e-02) 
2023-05-25 23:13:55.730059: train Epoch: [39][113/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.881)	Loss 7.5256e-02 (8.1500e-02) 
2023-05-25 23:13:58.396362: train Epoch: [39][114/129]	Time  2.666 ( 1.845)	Data  1.719 ( 0.888)	Loss 9.2180e-02 (8.1593e-02) 
2023-05-25 23:13:59.346687: train Epoch: [39][115/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.881)	Loss 5.9412e-02 (8.1401e-02) 
2023-05-25 23:14:02.110620: train Epoch: [39][116/129]	Time  2.764 ( 1.845)	Data  1.812 ( 0.889)	Loss 2.2481e-01 (8.2627e-02) 
2023-05-25 23:14:03.061712: train Epoch: [39][117/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.881)	Loss 5.9193e-02 (8.2429e-02) 
2023-05-25 23:14:05.768327: train Epoch: [39][118/129]	Time  2.707 ( 1.845)	Data  1.757 ( 0.889)	Loss 6.4275e-02 (8.2276e-02) 
2023-05-25 23:14:06.717187: train Epoch: [39][119/129]	Time  0.949 ( 1.837)	Data  0.001 ( 0.881)	Loss 1.5692e-01 (8.2898e-02) 
2023-05-25 23:14:09.298404: train Epoch: [39][120/129]	Time  2.581 ( 1.844)	Data  1.633 ( 0.887)	Loss 9.6204e-02 (8.3008e-02) 
2023-05-25 23:14:10.248205: train Epoch: [39][121/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.880)	Loss 6.9638e-02 (8.2898e-02) 
2023-05-25 23:14:12.965454: train Epoch: [39][122/129]	Time  2.717 ( 1.843)	Data  1.761 ( 0.887)	Loss 5.2792e-02 (8.2654e-02) 
2023-05-25 23:14:13.915009: train Epoch: [39][123/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.880)	Loss 8.4452e-02 (8.2668e-02) 
2023-05-25 23:14:16.527922: train Epoch: [39][124/129]	Time  2.613 ( 1.842)	Data  1.661 ( 0.886)	Loss 7.7139e-02 (8.2624e-02) 
2023-05-25 23:14:17.476036: train Epoch: [39][125/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.879)	Loss 9.1973e-02 (8.2698e-02) 
2023-05-25 23:14:20.083411: train Epoch: [39][126/129]	Time  2.607 ( 1.841)	Data  1.660 ( 0.886)	Loss 5.2577e-02 (8.2461e-02) 
2023-05-25 23:14:21.030525: train Epoch: [39][127/129]	Time  0.947 ( 1.834)	Data  0.001 ( 0.879)	Loss 5.5792e-02 (8.2253e-02) 
2023-05-25 23:14:22.560784: train Epoch: [39][128/129]	Time  1.530 ( 1.832)	Data  0.585 ( 0.876)	Loss 4.9648e-02 (8.2000e-02) 
2023-05-25 23:14:22.592194: Train Epoch done in 236.35872457599908 s 
2023-05-25 23:14:24.816119: val Epoch: [39][ 0/72]	Time  1.524 ( 1.524)	Data  1.340 ( 1.340)	Loss 5.2798e-02 (5.2798e-02) 
2023-05-25 23:14:24.936812: val Epoch: [39][ 1/72]	Time  0.121 ( 0.823)	Data  0.001 ( 0.671)	Loss 1.1127e-01 (8.2036e-02) 
2023-05-25 23:14:26.009759: val Epoch: [39][ 2/72]	Time  1.073 ( 0.906)	Data  0.947 ( 0.763)	Loss 6.2285e-02 (7.5453e-02) 
2023-05-25 23:14:26.130323: val Epoch: [39][ 3/72]	Time  0.121 ( 0.710)	Data  0.000 ( 0.572)	Loss 1.0591e-01 (8.3067e-02) 
2023-05-25 23:14:27.289245: val Epoch: [39][ 4/72]	Time  1.159 ( 0.800)	Data  1.035 ( 0.665)	Loss 3.7001e-01 (1.4046e-01) 
2023-05-25 23:14:27.409560: val Epoch: [39][ 5/72]	Time  0.120 ( 0.686)	Data  0.001 ( 0.554)	Loss 5.0922e-02 (1.2553e-01) 
2023-05-25 23:14:28.534477: val Epoch: [39][ 6/72]	Time  1.125 ( 0.749)	Data  1.000 ( 0.618)	Loss 3.8911e-02 (1.1316e-01) 
2023-05-25 23:14:28.656297: val Epoch: [39][ 7/72]	Time  0.122 ( 0.671)	Data  0.001 ( 0.541)	Loss 1.8522e-01 (1.2217e-01) 
2023-05-25 23:14:29.816699: val Epoch: [39][ 8/72]	Time  1.160 ( 0.725)	Data  1.040 ( 0.596)	Loss 3.4585e-01 (1.4702e-01) 
2023-05-25 23:14:29.935983: val Epoch: [39][ 9/72]	Time  0.119 ( 0.664)	Data  0.000 ( 0.537)	Loss 7.2592e-02 (1.3958e-01) 
2023-05-25 23:14:31.115158: val Epoch: [39][10/72]	Time  1.179 ( 0.711)	Data  1.054 ( 0.584)	Loss 7.8465e-02 (1.3402e-01) 
2023-05-25 23:14:31.240404: val Epoch: [39][11/72]	Time  0.125 ( 0.662)	Data  0.001 ( 0.535)	Loss 1.5903e-01 (1.3611e-01) 
2023-05-25 23:14:32.397440: val Epoch: [39][12/72]	Time  1.157 ( 0.700)	Data  1.026 ( 0.573)	Loss 1.1372e-01 (1.3438e-01) 
2023-05-25 23:14:32.522519: val Epoch: [39][13/72]	Time  0.125 ( 0.659)	Data  0.001 ( 0.532)	Loss 1.0100e-01 (1.3200e-01) 
2023-05-25 23:14:33.672288: val Epoch: [39][14/72]	Time  1.150 ( 0.692)	Data  1.019 ( 0.564)	Loss 1.0523e-01 (1.3021e-01) 
2023-05-25 23:14:33.797093: val Epoch: [39][15/72]	Time  0.125 ( 0.657)	Data  0.001 ( 0.529)	Loss 5.1765e-02 (1.2531e-01) 
2023-05-25 23:14:34.887071: val Epoch: [39][16/72]	Time  1.090 ( 0.682)	Data  0.962 ( 0.555)	Loss 6.0891e-02 (1.2152e-01) 
2023-05-25 23:14:35.012020: val Epoch: [39][17/72]	Time  0.125 ( 0.651)	Data  0.001 ( 0.524)	Loss 4.4523e-02 (1.1724e-01) 
2023-05-25 23:14:36.119723: val Epoch: [39][18/72]	Time  1.108 ( 0.675)	Data  0.983 ( 0.548)	Loss 1.2969e-01 (1.1790e-01) 
2023-05-25 23:14:36.244148: val Epoch: [39][19/72]	Time  0.124 ( 0.648)	Data  0.001 ( 0.521)	Loss 5.7115e-02 (1.1486e-01) 
2023-05-25 23:14:37.308838: val Epoch: [39][20/72]	Time  1.065 ( 0.667)	Data  0.940 ( 0.541)	Loss 5.0336e-02 (1.1179e-01) 
2023-05-25 23:14:37.529314: val Epoch: [39][21/72]	Time  0.220 ( 0.647)	Data  0.096 ( 0.520)	Loss 6.1288e-02 (1.0949e-01) 
2023-05-25 23:14:38.505594: val Epoch: [39][22/72]	Time  0.976 ( 0.661)	Data  0.851 ( 0.535)	Loss 2.0076e-01 (1.1346e-01) 
2023-05-25 23:14:38.762861: val Epoch: [39][23/72]	Time  0.257 ( 0.645)	Data  0.133 ( 0.518)	Loss 7.9803e-02 (1.1206e-01) 
2023-05-25 23:14:39.764651: val Epoch: [39][24/72]	Time  1.002 ( 0.659)	Data  0.879 ( 0.532)	Loss 6.7966e-02 (1.1029e-01) 
2023-05-25 23:14:40.007571: val Epoch: [39][25/72]	Time  0.243 ( 0.643)	Data  0.118 ( 0.517)	Loss 4.8316e-02 (1.0791e-01) 
2023-05-25 23:14:40.994341: val Epoch: [39][26/72]	Time  0.987 ( 0.656)	Data  0.867 ( 0.529)	Loss 5.3521e-02 (1.0590e-01) 
2023-05-25 23:14:41.185754: val Epoch: [39][27/72]	Time  0.191 ( 0.639)	Data  0.073 ( 0.513)	Loss 4.1008e-02 (1.0358e-01) 
2023-05-25 23:14:42.212482: val Epoch: [39][28/72]	Time  1.027 ( 0.652)	Data  0.907 ( 0.527)	Loss 5.7377e-02 (1.0199e-01) 
2023-05-25 23:14:42.403258: val Epoch: [39][29/72]	Time  0.191 ( 0.637)	Data  0.070 ( 0.512)	Loss 5.1372e-02 (1.0030e-01) 
2023-05-25 23:14:43.466144: val Epoch: [39][30/72]	Time  1.063 ( 0.651)	Data  0.938 ( 0.525)	Loss 5.0774e-02 (9.8701e-02) 
2023-05-25 23:14:43.625913: val Epoch: [39][31/72]	Time  0.160 ( 0.635)	Data  0.036 ( 0.510)	Loss 4.2533e-02 (9.6945e-02) 
2023-05-25 23:14:44.734740: val Epoch: [39][32/72]	Time  1.109 ( 0.650)	Data  0.984 ( 0.524)	Loss 9.0159e-02 (9.6740e-02) 
2023-05-25 23:14:44.898739: val Epoch: [39][33/72]	Time  0.164 ( 0.635)	Data  0.040 ( 0.510)	Loss 3.5009e-01 (1.0419e-01) 
2023-05-25 23:14:45.935110: val Epoch: [39][34/72]	Time  1.036 ( 0.647)	Data  0.912 ( 0.522)	Loss 9.0774e-02 (1.0381e-01) 
2023-05-25 23:14:46.108604: val Epoch: [39][35/72]	Time  0.173 ( 0.634)	Data  0.050 ( 0.508)	Loss 1.5323e-01 (1.0518e-01) 
2023-05-25 23:14:47.145997: val Epoch: [39][36/72]	Time  1.037 ( 0.645)	Data  0.912 ( 0.519)	Loss 4.2312e-01 (1.1377e-01) 
2023-05-25 23:14:47.323965: val Epoch: [39][37/72]	Time  0.178 ( 0.632)	Data  0.054 ( 0.507)	Loss 6.1757e-02 (1.1240e-01) 
2023-05-25 23:14:48.375499: val Epoch: [39][38/72]	Time  1.052 ( 0.643)	Data  0.927 ( 0.518)	Loss 6.4030e-02 (1.1116e-01) 
2023-05-25 23:14:48.585175: val Epoch: [39][39/72]	Time  0.210 ( 0.632)	Data  0.086 ( 0.507)	Loss 1.0042e-01 (1.1090e-01) 
2023-05-25 23:14:49.591772: val Epoch: [39][40/72]	Time  1.007 ( 0.641)	Data  0.881 ( 0.516)	Loss 6.0544e-02 (1.0967e-01) 
2023-05-25 23:14:49.780791: val Epoch: [39][41/72]	Time  0.189 ( 0.631)	Data  0.064 ( 0.505)	Loss 5.3078e-02 (1.0832e-01) 
2023-05-25 23:14:50.813028: val Epoch: [39][42/72]	Time  1.032 ( 0.640)	Data  0.907 ( 0.515)	Loss 7.6858e-02 (1.0759e-01) 
2023-05-25 23:14:51.014396: val Epoch: [39][43/72]	Time  0.201 ( 0.630)	Data  0.077 ( 0.505)	Loss 1.3179e-01 (1.0814e-01) 
2023-05-25 23:14:52.005759: val Epoch: [39][44/72]	Time  0.991 ( 0.638)	Data  0.866 ( 0.513)	Loss 5.8593e-02 (1.0704e-01) 
2023-05-25 23:14:52.292480: val Epoch: [39][45/72]	Time  0.287 ( 0.630)	Data  0.163 ( 0.505)	Loss 6.7290e-02 (1.0617e-01) 
2023-05-25 23:14:53.216615: val Epoch: [39][46/72]	Time  0.924 ( 0.637)	Data  0.799 ( 0.511)	Loss 6.7905e-02 (1.0536e-01) 
2023-05-25 23:14:53.519790: val Epoch: [39][47/72]	Time  0.303 ( 0.630)	Data  0.179 ( 0.505)	Loss 4.6778e-02 (1.0414e-01) 
2023-05-25 23:14:54.482687: val Epoch: [39][48/72]	Time  0.963 ( 0.637)	Data  0.837 ( 0.511)	Loss 6.4214e-01 (1.1512e-01) 
2023-05-25 23:14:54.749696: val Epoch: [39][49/72]	Time  0.267 ( 0.629)	Data  0.143 ( 0.504)	Loss 2.0275e-01 (1.1687e-01) 
2023-05-25 23:14:55.714775: val Epoch: [39][50/72]	Time  0.965 ( 0.636)	Data  0.840 ( 0.511)	Loss 6.4046e-02 (1.1584e-01) 
2023-05-25 23:14:55.949771: val Epoch: [39][51/72]	Time  0.235 ( 0.628)	Data  0.111 ( 0.503)	Loss 5.9460e-02 (1.1475e-01) 
2023-05-25 23:14:56.992145: val Epoch: [39][52/72]	Time  1.042 ( 0.636)	Data  0.917 ( 0.511)	Loss 3.4620e-01 (1.1912e-01) 
2023-05-25 23:14:57.165122: val Epoch: [39][53/72]	Time  0.173 ( 0.627)	Data  0.049 ( 0.502)	Loss 1.0532e-01 (1.1886e-01) 
2023-05-25 23:14:58.210260: val Epoch: [39][54/72]	Time  1.045 ( 0.635)	Data  0.920 ( 0.510)	Loss 5.4553e-02 (1.1769e-01) 
2023-05-25 23:14:58.398378: val Epoch: [39][55/72]	Time  0.188 ( 0.627)	Data  0.064 ( 0.502)	Loss 8.2568e-02 (1.1707e-01) 
2023-05-25 23:14:59.407709: val Epoch: [39][56/72]	Time  1.009 ( 0.634)	Data  0.883 ( 0.508)	Loss 1.3931e-01 (1.1746e-01) 
2023-05-25 23:14:59.658249: val Epoch: [39][57/72]	Time  0.251 ( 0.627)	Data  0.126 ( 0.502)	Loss 1.1004e-01 (1.1733e-01) 
2023-05-25 23:15:00.641162: val Epoch: [39][58/72]	Time  0.983 ( 0.633)	Data  0.858 ( 0.508)	Loss 4.4719e-01 (1.2292e-01) 
2023-05-25 23:15:00.923035: val Epoch: [39][59/72]	Time  0.282 ( 0.627)	Data  0.158 ( 0.502)	Loss 2.3095e-01 (1.2472e-01) 
2023-05-25 23:15:01.856032: val Epoch: [39][60/72]	Time  0.933 ( 0.632)	Data  0.808 ( 0.507)	Loss 5.2678e-02 (1.2354e-01) 
2023-05-25 23:15:02.147398: val Epoch: [39][61/72]	Time  0.291 ( 0.627)	Data  0.168 ( 0.502)	Loss 4.6408e-02 (1.2229e-01) 
2023-05-25 23:15:03.121132: val Epoch: [39][62/72]	Time  0.974 ( 0.632)	Data  0.848 ( 0.507)	Loss 3.7169e-01 (1.2625e-01) 
2023-05-25 23:15:03.399306: val Epoch: [39][63/72]	Time  0.278 ( 0.627)	Data  0.154 ( 0.502)	Loss 1.3606e-01 (1.2641e-01) 
2023-05-25 23:15:04.344504: val Epoch: [39][64/72]	Time  0.945 ( 0.632)	Data  0.819 ( 0.507)	Loss 2.1717e-01 (1.2780e-01) 
2023-05-25 23:15:04.657585: val Epoch: [39][65/72]	Time  0.313 ( 0.627)	Data  0.190 ( 0.502)	Loss 2.4217e-01 (1.2954e-01) 
2023-05-25 23:15:05.624917: val Epoch: [39][66/72]	Time  0.967 ( 0.632)	Data  0.842 ( 0.507)	Loss 1.5310e-01 (1.2989e-01) 
2023-05-25 23:15:05.892496: val Epoch: [39][67/72]	Time  0.268 ( 0.626)	Data  0.143 ( 0.501)	Loss 9.2200e-02 (1.2933e-01) 
2023-05-25 23:15:06.817602: val Epoch: [39][68/72]	Time  0.925 ( 0.631)	Data  0.800 ( 0.506)	Loss 8.7650e-02 (1.2873e-01) 
2023-05-25 23:15:07.085665: val Epoch: [39][69/72]	Time  0.268 ( 0.626)	Data  0.144 ( 0.501)	Loss 3.2474e-02 (1.2735e-01) 
2023-05-25 23:15:08.060914: val Epoch: [39][70/72]	Time  0.975 ( 0.631)	Data  0.850 ( 0.506)	Loss 2.8507e-01 (1.2958e-01) 
2023-05-25 23:15:08.246441: val Epoch: [39][71/72]	Time  0.186 ( 0.624)	Data  0.062 ( 0.499)	Loss 1.3246e-01 (1.2962e-01) 
2023-05-25 23:15:08.442818: Epoch 39 :Val : ['ET : 0.7397940158843994', 'TC : 0.7926433086395264', 'WT : 0.8620283007621765'] 
2023-05-25 23:15:08.445560: Epoch 39 :Val : ['ET : 0.7397940158843994', 'TC : 0.7926433086395264', 'WT : 0.8620283007621765'] 
2023-05-25 23:15:08.447370: Saving the model with DSC 0.7998655438423157 
2023-05-25 23:15:09.094943: Val epoch done in 46.50273234500128 s 
2023-05-25 23:15:09.100255: Batches per epoch:  129 
2023-05-25 23:15:13.831190: train Epoch: [40][  0/129]	Time  4.731 ( 4.731)	Data  3.731 ( 3.731)	Loss 7.4717e-02 (7.4717e-02) 
2023-05-25 23:15:14.781852: train Epoch: [40][  1/129]	Time  0.951 ( 2.841)	Data  0.001 ( 1.866)	Loss 7.5133e-02 (7.4925e-02) 
2023-05-25 23:15:17.400656: train Epoch: [40][  2/129]	Time  2.619 ( 2.767)	Data  1.664 ( 1.798)	Loss 6.7265e-02 (7.2372e-02) 
2023-05-25 23:15:18.351746: train Epoch: [40][  3/129]	Time  0.951 ( 2.313)	Data  0.001 ( 1.349)	Loss 8.5564e-02 (7.5670e-02) 
2023-05-25 23:15:20.982489: train Epoch: [40][  4/129]	Time  2.631 ( 2.376)	Data  1.668 ( 1.413)	Loss 1.0005e-01 (8.0545e-02) 
2023-05-25 23:15:21.932788: train Epoch: [40][  5/129]	Time  0.950 ( 2.139)	Data  0.001 ( 1.178)	Loss 4.7095e-02 (7.4970e-02) 
2023-05-25 23:15:24.486888: train Epoch: [40][  6/129]	Time  2.554 ( 2.198)	Data  1.605 ( 1.239)	Loss 6.3135e-02 (7.3279e-02) 
2023-05-25 23:15:25.446920: train Epoch: [40][  7/129]	Time  0.960 ( 2.043)	Data  0.001 ( 1.084)	Loss 1.0407e-01 (7.7128e-02) 
2023-05-25 23:15:28.102311: train Epoch: [40][  8/129]	Time  2.655 ( 2.111)	Data  1.699 ( 1.152)	Loss 8.2534e-02 (7.7728e-02) 
2023-05-25 23:15:29.062992: train Epoch: [40][  9/129]	Time  0.961 ( 1.996)	Data  0.001 ( 1.037)	Loss 5.0046e-02 (7.4960e-02) 
2023-05-25 23:15:31.753042: train Epoch: [40][ 10/129]	Time  2.690 ( 2.059)	Data  1.731 ( 1.100)	Loss 9.4321e-02 (7.6720e-02) 
2023-05-25 23:15:32.703477: train Epoch: [40][ 11/129]	Time  0.950 ( 1.967)	Data  0.001 ( 1.009)	Loss 1.2763e-01 (8.0963e-02) 
2023-05-25 23:15:35.399228: train Epoch: [40][ 12/129]	Time  2.696 ( 2.023)	Data  1.748 ( 1.065)	Loss 6.4270e-02 (7.9678e-02) 
2023-05-25 23:15:36.349666: train Epoch: [40][ 13/129]	Time  0.950 ( 1.946)	Data  0.001 ( 0.989)	Loss 6.2915e-02 (7.8481e-02) 
2023-05-25 23:15:39.003416: train Epoch: [40][ 14/129]	Time  2.654 ( 1.994)	Data  1.704 ( 1.037)	Loss 5.9498e-02 (7.7216e-02) 
2023-05-25 23:15:39.953103: train Epoch: [40][ 15/129]	Time  0.950 ( 1.928)	Data  0.001 ( 0.972)	Loss 5.5281e-02 (7.5845e-02) 
2023-05-25 23:15:42.668281: train Epoch: [40][ 16/129]	Time  2.715 ( 1.975)	Data  1.766 ( 1.019)	Loss 8.1658e-02 (7.6187e-02) 
2023-05-25 23:15:43.618540: train Epoch: [40][ 17/129]	Time  0.950 ( 1.918)	Data  0.001 ( 0.962)	Loss 7.3179e-02 (7.6019e-02) 
2023-05-25 23:15:46.311379: train Epoch: [40][ 18/129]	Time  2.693 ( 1.958)	Data  1.733 ( 1.003)	Loss 1.8328e-01 (8.1665e-02) 
2023-05-25 23:15:47.260814: train Epoch: [40][ 19/129]	Time  0.949 ( 1.908)	Data  0.001 ( 0.953)	Loss 5.5892e-02 (8.0376e-02) 
2023-05-25 23:15:49.917411: train Epoch: [40][ 20/129]	Time  2.657 ( 1.944)	Data  1.709 ( 0.989)	Loss 5.8154e-02 (7.9318e-02) 
2023-05-25 23:15:50.867564: train Epoch: [40][ 21/129]	Time  0.950 ( 1.898)	Data  0.001 ( 0.944)	Loss 6.8146e-02 (7.8810e-02) 
2023-05-25 23:15:53.599252: train Epoch: [40][ 22/129]	Time  2.732 ( 1.935)	Data  1.784 ( 0.980)	Loss 1.2717e-01 (8.0913e-02) 
2023-05-25 23:15:54.549172: train Epoch: [40][ 23/129]	Time  0.950 ( 1.894)	Data  0.001 ( 0.940)	Loss 6.8051e-02 (8.0377e-02) 
2023-05-25 23:15:57.275046: train Epoch: [40][ 24/129]	Time  2.726 ( 1.927)	Data  1.765 ( 0.973)	Loss 8.0649e-02 (8.0388e-02) 
2023-05-25 23:15:58.234131: train Epoch: [40][ 25/129]	Time  0.959 ( 1.890)	Data  0.001 ( 0.935)	Loss 9.7895e-02 (8.1061e-02) 
2023-05-25 23:16:00.845622: train Epoch: [40][ 26/129]	Time  2.611 ( 1.916)	Data  1.654 ( 0.962)	Loss 6.2196e-02 (8.0363e-02) 
2023-05-25 23:16:01.795627: train Epoch: [40][ 27/129]	Time  0.950 ( 1.882)	Data  0.001 ( 0.928)	Loss 8.0308e-02 (8.0361e-02) 
2023-05-25 23:16:04.458801: train Epoch: [40][ 28/129]	Time  2.663 ( 1.909)	Data  1.714 ( 0.955)	Loss 8.5037e-02 (8.0522e-02) 
2023-05-25 23:16:05.408337: train Epoch: [40][ 29/129]	Time  0.950 ( 1.877)	Data  0.001 ( 0.923)	Loss 8.3881e-02 (8.0634e-02) 
2023-05-25 23:16:08.142653: train Epoch: [40][ 30/129]	Time  2.734 ( 1.905)	Data  1.786 ( 0.951)	Loss 6.4956e-02 (8.0128e-02) 
2023-05-25 23:16:09.095451: train Epoch: [40][ 31/129]	Time  0.953 ( 1.875)	Data  0.001 ( 0.921)	Loss 5.0070e-02 (7.9189e-02) 
2023-05-25 23:16:11.774879: train Epoch: [40][ 32/129]	Time  2.679 ( 1.899)	Data  1.720 ( 0.945)	Loss 1.3831e-01 (8.0980e-02) 
2023-05-25 23:16:12.725573: train Epoch: [40][ 33/129]	Time  0.951 ( 1.871)	Data  0.001 ( 0.918)	Loss 1.0249e-01 (8.1613e-02) 
2023-05-25 23:16:15.379753: train Epoch: [40][ 34/129]	Time  2.654 ( 1.894)	Data  1.706 ( 0.940)	Loss 4.5739e-02 (8.0588e-02) 
2023-05-25 23:16:16.330762: train Epoch: [40][ 35/129]	Time  0.951 ( 1.868)	Data  0.001 ( 0.914)	Loss 7.4086e-02 (8.0407e-02) 
2023-05-25 23:16:18.975489: train Epoch: [40][ 36/129]	Time  2.645 ( 1.889)	Data  1.696 ( 0.935)	Loss 4.3383e-02 (7.9407e-02) 
2023-05-25 23:16:19.926371: train Epoch: [40][ 37/129]	Time  0.951 ( 1.864)	Data  0.001 ( 0.911)	Loss 3.9213e-02 (7.8349e-02) 
2023-05-25 23:16:22.743837: train Epoch: [40][ 38/129]	Time  2.817 ( 1.888)	Data  1.858 ( 0.935)	Loss 8.8975e-02 (7.8622e-02) 
2023-05-25 23:16:23.704148: train Epoch: [40][ 39/129]	Time  0.960 ( 1.865)	Data  0.001 ( 0.911)	Loss 6.0703e-02 (7.8174e-02) 
2023-05-25 23:16:26.454006: train Epoch: [40][ 40/129]	Time  2.750 ( 1.887)	Data  1.789 ( 0.933)	Loss 9.4943e-02 (7.8583e-02) 
2023-05-25 23:16:27.414595: train Epoch: [40][ 41/129]	Time  0.961 ( 1.865)	Data  0.001 ( 0.911)	Loss 7.7094e-02 (7.8547e-02) 
2023-05-25 23:16:30.313939: train Epoch: [40][ 42/129]	Time  2.899 ( 1.889)	Data  1.930 ( 0.934)	Loss 8.7650e-02 (7.8759e-02) 
2023-05-25 23:16:31.274833: train Epoch: [40][ 43/129]	Time  0.961 ( 1.868)	Data  0.001 ( 0.913)	Loss 9.4683e-02 (7.9121e-02) 
2023-05-25 23:16:34.143456: train Epoch: [40][ 44/129]	Time  2.869 ( 1.890)	Data  1.900 ( 0.935)	Loss 6.1805e-02 (7.8736e-02) 
2023-05-25 23:16:35.103501: train Epoch: [40][ 45/129]	Time  0.960 ( 1.870)	Data  0.001 ( 0.915)	Loss 8.1190e-02 (7.8789e-02) 
2023-05-25 23:16:37.882601: train Epoch: [40][ 46/129]	Time  2.779 ( 1.889)	Data  1.819 ( 0.934)	Loss 8.8704e-02 (7.9000e-02) 
2023-05-25 23:16:38.831837: train Epoch: [40][ 47/129]	Time  0.949 ( 1.869)	Data  0.001 ( 0.915)	Loss 7.7140e-02 (7.8961e-02) 
2023-05-25 23:16:41.595526: train Epoch: [40][ 48/129]	Time  2.764 ( 1.888)	Data  1.818 ( 0.933)	Loss 7.3508e-02 (7.8850e-02) 
2023-05-25 23:16:42.544221: train Epoch: [40][ 49/129]	Time  0.949 ( 1.869)	Data  0.001 ( 0.914)	Loss 7.3322e-02 (7.8740e-02) 
2023-05-25 23:16:45.165244: train Epoch: [40][ 50/129]	Time  2.621 ( 1.884)	Data  1.676 ( 0.929)	Loss 1.0559e-01 (7.9266e-02) 
2023-05-25 23:16:46.113565: train Epoch: [40][ 51/129]	Time  0.948 ( 1.866)	Data  0.001 ( 0.911)	Loss 8.5393e-02 (7.9384e-02) 
2023-05-25 23:16:48.717282: train Epoch: [40][ 52/129]	Time  2.604 ( 1.880)	Data  1.658 ( 0.926)	Loss 8.9615e-02 (7.9577e-02) 
2023-05-25 23:16:49.667448: train Epoch: [40][ 53/129]	Time  0.950 ( 1.862)	Data  0.001 ( 0.908)	Loss 4.7099e-02 (7.8976e-02) 
2023-05-25 23:16:52.277567: train Epoch: [40][ 54/129]	Time  2.610 ( 1.876)	Data  1.664 ( 0.922)	Loss 7.3031e-02 (7.8867e-02) 
2023-05-25 23:16:53.227529: train Epoch: [40][ 55/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.906)	Loss 1.5631e-01 (8.0250e-02) 
2023-05-25 23:16:55.813496: train Epoch: [40][ 56/129]	Time  2.586 ( 1.872)	Data  1.637 ( 0.919)	Loss 8.1513e-02 (8.0272e-02) 
2023-05-25 23:16:56.773809: train Epoch: [40][ 57/129]	Time  0.960 ( 1.856)	Data  0.001 ( 0.903)	Loss 8.6693e-02 (8.0383e-02) 
2023-05-25 23:16:59.475016: train Epoch: [40][ 58/129]	Time  2.701 ( 1.871)	Data  1.746 ( 0.917)	Loss 8.7012e-02 (8.0496e-02) 
2023-05-25 23:17:00.434222: train Epoch: [40][ 59/129]	Time  0.959 ( 1.856)	Data  0.001 ( 0.902)	Loss 9.4975e-02 (8.0737e-02) 
2023-05-25 23:17:03.085667: train Epoch: [40][ 60/129]	Time  2.651 ( 1.869)	Data  1.694 ( 0.915)	Loss 7.0591e-02 (8.0571e-02) 
2023-05-25 23:17:04.046568: train Epoch: [40][ 61/129]	Time  0.961 ( 1.854)	Data  0.001 ( 0.900)	Loss 6.4784e-02 (8.0316e-02) 
2023-05-25 23:17:06.773003: train Epoch: [40][ 62/129]	Time  2.726 ( 1.868)	Data  1.772 ( 0.914)	Loss 1.1028e-01 (8.0791e-02) 
2023-05-25 23:17:07.734725: train Epoch: [40][ 63/129]	Time  0.962 ( 1.854)	Data  0.001 ( 0.900)	Loss 5.9540e-02 (8.0459e-02) 
2023-05-25 23:17:10.424639: train Epoch: [40][ 64/129]	Time  2.690 ( 1.867)	Data  1.735 ( 0.912)	Loss 8.3129e-02 (8.0500e-02) 
2023-05-25 23:17:11.383239: train Epoch: [40][ 65/129]	Time  0.959 ( 1.853)	Data  0.001 ( 0.899)	Loss 9.1325e-02 (8.0665e-02) 
2023-05-25 23:17:14.017749: train Epoch: [40][ 66/129]	Time  2.635 ( 1.864)	Data  1.678 ( 0.910)	Loss 9.6579e-02 (8.0902e-02) 
2023-05-25 23:17:14.978144: train Epoch: [40][ 67/129]	Time  0.960 ( 1.851)	Data  0.001 ( 0.897)	Loss 6.6432e-02 (8.0689e-02) 
2023-05-25 23:17:17.619716: train Epoch: [40][ 68/129]	Time  2.642 ( 1.863)	Data  1.684 ( 0.908)	Loss 5.0903e-02 (8.0258e-02) 
2023-05-25 23:17:18.579220: train Epoch: [40][ 69/129]	Time  0.959 ( 1.850)	Data  0.001 ( 0.895)	Loss 1.0029e-01 (8.0544e-02) 
2023-05-25 23:17:21.179923: train Epoch: [40][ 70/129]	Time  2.601 ( 1.860)	Data  1.642 ( 0.906)	Loss 5.9216e-02 (8.0243e-02) 
2023-05-25 23:17:22.141168: train Epoch: [40][ 71/129]	Time  0.961 ( 1.848)	Data  0.001 ( 0.893)	Loss 7.1444e-02 (8.0121e-02) 
2023-05-25 23:17:24.765660: train Epoch: [40][ 72/129]	Time  2.624 ( 1.858)	Data  1.667 ( 0.904)	Loss 8.6490e-02 (8.0208e-02) 
2023-05-25 23:17:25.726430: train Epoch: [40][ 73/129]	Time  0.961 ( 1.846)	Data  0.001 ( 0.892)	Loss 7.3904e-02 (8.0123e-02) 
2023-05-25 23:17:28.415452: train Epoch: [40][ 74/129]	Time  2.689 ( 1.858)	Data  1.732 ( 0.903)	Loss 5.9138e-02 (7.9843e-02) 
2023-05-25 23:17:29.376564: train Epoch: [40][ 75/129]	Time  0.961 ( 1.846)	Data  0.001 ( 0.891)	Loss 5.5740e-02 (7.9526e-02) 
2023-05-25 23:17:32.025817: train Epoch: [40][ 76/129]	Time  2.649 ( 1.856)	Data  1.692 ( 0.901)	Loss 6.0572e-02 (7.9280e-02) 
2023-05-25 23:17:32.987707: train Epoch: [40][ 77/129]	Time  0.962 ( 1.845)	Data  0.001 ( 0.890)	Loss 9.5764e-02 (7.9491e-02) 
2023-05-25 23:17:35.590185: train Epoch: [40][ 78/129]	Time  2.602 ( 1.854)	Data  1.646 ( 0.899)	Loss 1.2399e-01 (8.0055e-02) 
2023-05-25 23:17:36.551349: train Epoch: [40][ 79/129]	Time  0.961 ( 1.843)	Data  0.001 ( 0.888)	Loss 8.3175e-02 (8.0094e-02) 
2023-05-25 23:17:39.267983: train Epoch: [40][ 80/129]	Time  2.717 ( 1.854)	Data  1.759 ( 0.899)	Loss 6.1905e-02 (7.9869e-02) 
2023-05-25 23:17:40.226350: train Epoch: [40][ 81/129]	Time  0.958 ( 1.843)	Data  0.001 ( 0.888)	Loss 1.0453e-01 (8.0170e-02) 
2023-05-25 23:17:42.910235: train Epoch: [40][ 82/129]	Time  2.684 ( 1.853)	Data  1.727 ( 0.898)	Loss 6.7328e-02 (8.0015e-02) 
2023-05-25 23:17:43.867203: train Epoch: [40][ 83/129]	Time  0.957 ( 1.842)	Data  0.001 ( 0.887)	Loss 1.0967e-01 (8.0368e-02) 
2023-05-25 23:17:46.431718: train Epoch: [40][ 84/129]	Time  2.565 ( 1.851)	Data  1.608 ( 0.896)	Loss 5.7849e-02 (8.0103e-02) 
2023-05-25 23:17:47.390967: train Epoch: [40][ 85/129]	Time  0.959 ( 1.841)	Data  0.001 ( 0.886)	Loss 5.3634e-02 (7.9795e-02) 
2023-05-25 23:17:50.258476: train Epoch: [40][ 86/129]	Time  2.868 ( 1.852)	Data  1.900 ( 0.897)	Loss 6.7227e-02 (7.9651e-02) 
2023-05-25 23:17:51.219081: train Epoch: [40][ 87/129]	Time  0.961 ( 1.842)	Data  0.001 ( 0.887)	Loss 6.8844e-02 (7.9528e-02) 
2023-05-25 23:17:53.888742: train Epoch: [40][ 88/129]	Time  2.670 ( 1.852)	Data  1.711 ( 0.896)	Loss 9.1123e-02 (7.9658e-02) 
2023-05-25 23:17:54.847165: train Epoch: [40][ 89/129]	Time  0.958 ( 1.842)	Data  0.001 ( 0.886)	Loss 8.7242e-02 (7.9743e-02) 
2023-05-25 23:17:57.445092: train Epoch: [40][ 90/129]	Time  2.598 ( 1.850)	Data  1.632 ( 0.894)	Loss 1.0492e-01 (8.0019e-02) 
2023-05-25 23:17:58.405299: train Epoch: [40][ 91/129]	Time  0.960 ( 1.840)	Data  0.001 ( 0.885)	Loss 5.7281e-02 (7.9772e-02) 
2023-05-25 23:18:01.045762: train Epoch: [40][ 92/129]	Time  2.640 ( 1.849)	Data  1.669 ( 0.893)	Loss 7.1774e-02 (7.9686e-02) 
2023-05-25 23:18:02.006086: train Epoch: [40][ 93/129]	Time  0.960 ( 1.839)	Data  0.001 ( 0.884)	Loss 8.5710e-02 (7.9750e-02) 
2023-05-25 23:18:04.674784: train Epoch: [40][ 94/129]	Time  2.669 ( 1.848)	Data  1.711 ( 0.892)	Loss 6.2356e-02 (7.9567e-02) 
2023-05-25 23:18:05.622631: train Epoch: [40][ 95/129]	Time  0.948 ( 1.839)	Data  0.001 ( 0.883)	Loss 8.0520e-02 (7.9577e-02) 
2023-05-25 23:18:08.171075: train Epoch: [40][ 96/129]	Time  2.548 ( 1.846)	Data  1.599 ( 0.891)	Loss 6.4441e-02 (7.9421e-02) 
2023-05-25 23:18:09.123415: train Epoch: [40][ 97/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.881)	Loss 5.4838e-02 (7.9170e-02) 
2023-05-25 23:18:11.764401: train Epoch: [40][ 98/129]	Time  2.641 ( 1.845)	Data  1.695 ( 0.890)	Loss 6.9543e-02 (7.9073e-02) 
2023-05-25 23:18:12.714651: train Epoch: [40][ 99/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.881)	Loss 9.1849e-02 (7.9201e-02) 
2023-05-25 23:18:15.385868: train Epoch: [40][100/129]	Time  2.671 ( 1.844)	Data  1.723 ( 0.889)	Loss 5.4521e-02 (7.8956e-02) 
2023-05-25 23:18:16.333716: train Epoch: [40][101/129]	Time  0.948 ( 1.836)	Data  0.001 ( 0.880)	Loss 9.5655e-02 (7.9120e-02) 
2023-05-25 23:18:19.269700: train Epoch: [40][102/129]	Time  2.936 ( 1.846)	Data  1.989 ( 0.891)	Loss 1.1811e-01 (7.9499e-02) 
2023-05-25 23:18:20.217442: train Epoch: [40][103/129]	Time  0.948 ( 1.838)	Data  0.001 ( 0.883)	Loss 8.6259e-02 (7.9564e-02) 
2023-05-25 23:18:22.916313: train Epoch: [40][104/129]	Time  2.699 ( 1.846)	Data  1.739 ( 0.891)	Loss 1.0298e-01 (7.9787e-02) 
2023-05-25 23:18:23.867788: train Epoch: [40][105/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.882)	Loss 6.1422e-02 (7.9613e-02) 
2023-05-25 23:18:26.593345: train Epoch: [40][106/129]	Time  2.726 ( 1.846)	Data  1.766 ( 0.891)	Loss 7.5904e-02 (7.9579e-02) 
2023-05-25 23:18:27.543895: train Epoch: [40][107/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.882)	Loss 1.1331e-01 (7.9891e-02) 
2023-05-25 23:18:30.163358: train Epoch: [40][108/129]	Time  2.619 ( 1.845)	Data  1.672 ( 0.890)	Loss 1.0587e-01 (8.0129e-02) 
2023-05-25 23:18:31.114026: train Epoch: [40][109/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.882)	Loss 7.1602e-02 (8.0052e-02) 
2023-05-25 23:18:33.926552: train Epoch: [40][110/129]	Time  2.813 ( 1.845)	Data  1.853 ( 0.890)	Loss 7.1355e-02 (7.9973e-02) 
2023-05-25 23:18:34.877017: train Epoch: [40][111/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.882)	Loss 9.3554e-02 (8.0095e-02) 
2023-05-25 23:18:37.699584: train Epoch: [40][112/129]	Time  2.823 ( 1.846)	Data  1.861 ( 0.891)	Loss 1.3488e-01 (8.0580e-02) 
2023-05-25 23:18:38.649740: train Epoch: [40][113/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.883)	Loss 7.8838e-02 (8.0564e-02) 
2023-05-25 23:18:41.369848: train Epoch: [40][114/129]	Time  2.720 ( 1.846)	Data  1.772 ( 0.891)	Loss 5.4648e-02 (8.0339e-02) 
2023-05-25 23:18:42.320904: train Epoch: [40][115/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.883)	Loss 9.2447e-02 (8.0443e-02) 
2023-05-25 23:18:45.158833: train Epoch: [40][116/129]	Time  2.838 ( 1.847)	Data  1.878 ( 0.892)	Loss 1.1630e-01 (8.0750e-02) 
2023-05-25 23:18:46.110113: train Epoch: [40][117/129]	Time  0.951 ( 1.839)	Data  0.001 ( 0.884)	Loss 6.3830e-02 (8.0606e-02) 
2023-05-25 23:18:48.716910: train Epoch: [40][118/129]	Time  2.607 ( 1.846)	Data  1.646 ( 0.891)	Loss 9.9791e-02 (8.0768e-02) 
2023-05-25 23:18:49.667220: train Epoch: [40][119/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.883)	Loss 1.9895e-01 (8.1753e-02) 
2023-05-25 23:18:52.275504: train Epoch: [40][120/129]	Time  2.608 ( 1.844)	Data  1.661 ( 0.890)	Loss 7.5402e-02 (8.1700e-02) 
2023-05-25 23:18:53.226346: train Epoch: [40][121/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.882)	Loss 6.0007e-02 (8.1522e-02) 
2023-05-25 23:18:55.811727: train Epoch: [40][122/129]	Time  2.585 ( 1.843)	Data  1.634 ( 0.888)	Loss 7.1534e-02 (8.1441e-02) 
2023-05-25 23:18:56.763505: train Epoch: [40][123/129]	Time  0.952 ( 1.836)	Data  0.001 ( 0.881)	Loss 8.8698e-02 (8.1500e-02) 
2023-05-25 23:18:59.412240: train Epoch: [40][124/129]	Time  2.649 ( 1.842)	Data  1.688 ( 0.888)	Loss 9.8434e-02 (8.1635e-02) 
2023-05-25 23:19:00.362235: train Epoch: [40][125/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.881)	Loss 9.9098e-02 (8.1774e-02) 
2023-05-25 23:19:03.031462: train Epoch: [40][126/129]	Time  2.669 ( 1.842)	Data  1.720 ( 0.887)	Loss 6.5801e-02 (8.1648e-02) 
2023-05-25 23:19:03.988365: train Epoch: [40][127/129]	Time  0.957 ( 1.835)	Data  0.001 ( 0.880)	Loss 1.7316e-01 (8.2363e-02) 
2023-05-25 23:19:05.535446: train Epoch: [40][128/129]	Time  1.547 ( 1.833)	Data  0.602 ( 0.878)	Loss 9.8531e-02 (8.2488e-02) 
2023-05-25 23:19:05.567516: Train Epoch done in 236.46730420899985 s 
2023-05-25 23:19:07.815403: val Epoch: [40][ 0/72]	Time  1.546 ( 1.546)	Data  1.371 ( 1.371)	Loss 2.8056e-01 (2.8056e-01) 
2023-05-25 23:19:07.934688: val Epoch: [40][ 1/72]	Time  0.120 ( 0.833)	Data  0.001 ( 0.686)	Loss 3.8206e-02 (1.5938e-01) 
2023-05-25 23:19:09.013646: val Epoch: [40][ 2/72]	Time  1.079 ( 0.915)	Data  0.958 ( 0.776)	Loss 1.0041e-01 (1.3973e-01) 
2023-05-25 23:19:09.133290: val Epoch: [40][ 3/72]	Time  0.120 ( 0.716)	Data  0.001 ( 0.582)	Loss 1.2856e-01 (1.3694e-01) 
2023-05-25 23:19:10.253884: val Epoch: [40][ 4/72]	Time  1.121 ( 0.797)	Data  1.000 ( 0.666)	Loss 5.0375e-02 (1.1962e-01) 
2023-05-25 23:19:10.373651: val Epoch: [40][ 5/72]	Time  0.120 ( 0.684)	Data  0.000 ( 0.555)	Loss 5.2093e-02 (1.0837e-01) 
2023-05-25 23:19:11.521610: val Epoch: [40][ 6/72]	Time  1.148 ( 0.750)	Data  1.028 ( 0.623)	Loss 3.4523e-01 (1.4221e-01) 
2023-05-25 23:19:11.641073: val Epoch: [40][ 7/72]	Time  0.119 ( 0.672)	Data  0.001 ( 0.545)	Loss 2.5684e-01 (1.5654e-01) 
2023-05-25 23:19:12.782431: val Epoch: [40][ 8/72]	Time  1.141 ( 0.724)	Data  1.021 ( 0.598)	Loss 3.2170e-01 (1.7489e-01) 
2023-05-25 23:19:12.902157: val Epoch: [40][ 9/72]	Time  0.120 ( 0.663)	Data  0.000 ( 0.538)	Loss 1.3829e-01 (1.7123e-01) 
2023-05-25 23:19:14.034021: val Epoch: [40][10/72]	Time  1.132 ( 0.706)	Data  1.010 ( 0.581)	Loss 1.2295e-01 (1.6684e-01) 
2023-05-25 23:19:14.153424: val Epoch: [40][11/72]	Time  0.119 ( 0.657)	Data  0.001 ( 0.533)	Loss 4.8730e-01 (1.9354e-01) 
2023-05-25 23:19:15.253877: val Epoch: [40][12/72]	Time  1.100 ( 0.691)	Data  0.981 ( 0.567)	Loss 5.8467e-02 (1.8315e-01) 
2023-05-25 23:19:15.373398: val Epoch: [40][13/72]	Time  0.120 ( 0.650)	Data  0.001 ( 0.527)	Loss 1.1149e-01 (1.7803e-01) 
2023-05-25 23:19:16.442960: val Epoch: [40][14/72]	Time  1.070 ( 0.678)	Data  0.949 ( 0.555)	Loss 5.2239e-02 (1.6965e-01) 
2023-05-25 23:19:16.562523: val Epoch: [40][15/72]	Time  0.120 ( 0.643)	Data  0.001 ( 0.520)	Loss 6.3872e-02 (1.6304e-01) 
2023-05-25 23:19:17.662684: val Epoch: [40][16/72]	Time  1.100 ( 0.670)	Data  0.980 ( 0.547)	Loss 1.3307e-01 (1.6127e-01) 
2023-05-25 23:19:17.782290: val Epoch: [40][17/72]	Time  0.120 ( 0.640)	Data  0.001 ( 0.517)	Loss 5.8932e-02 (1.5559e-01) 
2023-05-25 23:19:18.864450: val Epoch: [40][18/72]	Time  1.082 ( 0.663)	Data  0.962 ( 0.540)	Loss 9.9690e-02 (1.5265e-01) 
2023-05-25 23:19:18.983688: val Epoch: [40][19/72]	Time  0.119 ( 0.636)	Data  0.001 ( 0.513)	Loss 7.0232e-02 (1.4853e-01) 
2023-05-25 23:19:20.156465: val Epoch: [40][20/72]	Time  1.173 ( 0.661)	Data  1.053 ( 0.539)	Loss 8.7873e-02 (1.4564e-01) 
2023-05-25 23:19:20.276223: val Epoch: [40][21/72]	Time  0.120 ( 0.637)	Data  0.000 ( 0.515)	Loss 5.8611e-02 (1.4168e-01) 
2023-05-25 23:19:21.348215: val Epoch: [40][22/72]	Time  1.072 ( 0.656)	Data  0.952 ( 0.534)	Loss 5.2934e-02 (1.3782e-01) 
2023-05-25 23:19:21.467668: val Epoch: [40][23/72]	Time  0.119 ( 0.633)	Data  0.001 ( 0.511)	Loss 5.5654e-02 (1.3440e-01) 
2023-05-25 23:19:22.595544: val Epoch: [40][24/72]	Time  1.128 ( 0.653)	Data  1.008 ( 0.531)	Loss 3.4599e-01 (1.4286e-01) 
2023-05-25 23:19:22.714791: val Epoch: [40][25/72]	Time  0.119 ( 0.633)	Data  0.000 ( 0.511)	Loss 2.1931e-01 (1.4580e-01) 
2023-05-25 23:19:23.814043: val Epoch: [40][26/72]	Time  1.099 ( 0.650)	Data  0.979 ( 0.528)	Loss 4.8916e-01 (1.5852e-01) 
2023-05-25 23:19:23.933774: val Epoch: [40][27/72]	Time  0.120 ( 0.631)	Data  0.000 ( 0.509)	Loss 1.0808e-01 (1.5672e-01) 
2023-05-25 23:19:25.098251: val Epoch: [40][28/72]	Time  1.164 ( 0.649)	Data  1.045 ( 0.528)	Loss 1.6415e-01 (1.5697e-01) 
2023-05-25 23:19:25.217659: val Epoch: [40][29/72]	Time  0.119 ( 0.632)	Data  0.000 ( 0.510)	Loss 1.2448e-01 (1.5589e-01) 
2023-05-25 23:19:26.331544: val Epoch: [40][30/72]	Time  1.114 ( 0.647)	Data  0.994 ( 0.526)	Loss 9.2074e-02 (1.5383e-01) 
2023-05-25 23:19:26.451032: val Epoch: [40][31/72]	Time  0.119 ( 0.631)	Data  0.000 ( 0.509)	Loss 9.0295e-02 (1.5185e-01) 
2023-05-25 23:19:27.590717: val Epoch: [40][32/72]	Time  1.140 ( 0.646)	Data  1.020 ( 0.525)	Loss 9.0202e-02 (1.4998e-01) 
2023-05-25 23:19:27.711672: val Epoch: [40][33/72]	Time  0.121 ( 0.631)	Data  0.001 ( 0.509)	Loss 6.3067e-02 (1.4742e-01) 
2023-05-25 23:19:28.825195: val Epoch: [40][34/72]	Time  1.114 ( 0.644)	Data  0.987 ( 0.523)	Loss 1.0576e-01 (1.4623e-01) 
2023-05-25 23:19:28.951067: val Epoch: [40][35/72]	Time  0.126 ( 0.630)	Data  0.001 ( 0.509)	Loss 1.8901e-01 (1.4742e-01) 
2023-05-25 23:19:30.071773: val Epoch: [40][36/72]	Time  1.121 ( 0.643)	Data  0.996 ( 0.522)	Loss 9.7223e-02 (1.4606e-01) 
2023-05-25 23:19:30.197389: val Epoch: [40][37/72]	Time  0.126 ( 0.630)	Data  0.001 ( 0.508)	Loss 5.3889e-02 (1.4364e-01) 
2023-05-25 23:19:31.313297: val Epoch: [40][38/72]	Time  1.116 ( 0.642)	Data  0.992 ( 0.520)	Loss 9.7201e-02 (1.4245e-01) 
2023-05-25 23:19:31.439240: val Epoch: [40][39/72]	Time  0.126 ( 0.629)	Data  0.001 ( 0.507)	Loss 5.5863e-02 (1.4028e-01) 
2023-05-25 23:19:32.545326: val Epoch: [40][40/72]	Time  1.106 ( 0.641)	Data  0.981 ( 0.519)	Loss 1.5013e-01 (1.4052e-01) 
2023-05-25 23:19:32.671220: val Epoch: [40][41/72]	Time  0.126 ( 0.629)	Data  0.001 ( 0.507)	Loss 6.4309e-02 (1.3871e-01) 
2023-05-25 23:19:33.760914: val Epoch: [40][42/72]	Time  1.090 ( 0.639)	Data  0.964 ( 0.517)	Loss 2.9447e-01 (1.4233e-01) 
2023-05-25 23:19:33.887619: val Epoch: [40][43/72]	Time  0.127 ( 0.628)	Data  0.001 ( 0.506)	Loss 5.5544e-02 (1.4036e-01) 
2023-05-25 23:19:34.998483: val Epoch: [40][44/72]	Time  1.111 ( 0.638)	Data  0.985 ( 0.516)	Loss 8.7254e-02 (1.3918e-01) 
2023-05-25 23:19:35.125453: val Epoch: [40][45/72]	Time  0.127 ( 0.627)	Data  0.001 ( 0.505)	Loss 7.1662e-02 (1.3771e-01) 
2023-05-25 23:19:36.277331: val Epoch: [40][46/72]	Time  1.152 ( 0.638)	Data  1.026 ( 0.516)	Loss 1.0635e-01 (1.3704e-01) 
2023-05-25 23:19:36.403960: val Epoch: [40][47/72]	Time  0.127 ( 0.628)	Data  0.001 ( 0.505)	Loss 1.2822e-01 (1.3686e-01) 
2023-05-25 23:19:37.576985: val Epoch: [40][48/72]	Time  1.173 ( 0.639)	Data  1.047 ( 0.516)	Loss 7.7155e-02 (1.3564e-01) 
2023-05-25 23:19:37.702114: val Epoch: [40][49/72]	Time  0.125 ( 0.629)	Data  0.001 ( 0.506)	Loss 5.2176e-02 (1.3397e-01) 
2023-05-25 23:19:38.833959: val Epoch: [40][50/72]	Time  1.132 ( 0.639)	Data  1.006 ( 0.516)	Loss 7.0498e-02 (1.3273e-01) 
2023-05-25 23:19:38.958937: val Epoch: [40][51/72]	Time  0.125 ( 0.629)	Data  0.001 ( 0.506)	Loss 7.6456e-02 (1.3165e-01) 
2023-05-25 23:19:40.081810: val Epoch: [40][52/72]	Time  1.123 ( 0.638)	Data  0.997 ( 0.515)	Loss 4.0492e-01 (1.3680e-01) 
2023-05-25 23:19:40.210554: val Epoch: [40][53/72]	Time  0.129 ( 0.629)	Data  0.001 ( 0.506)	Loss 7.2043e-02 (1.3560e-01) 
2023-05-25 23:19:41.255412: val Epoch: [40][54/72]	Time  1.045 ( 0.636)	Data  0.924 ( 0.513)	Loss 8.4656e-02 (1.3468e-01) 
2023-05-25 23:19:41.376259: val Epoch: [40][55/72]	Time  0.121 ( 0.627)	Data  0.001 ( 0.504)	Loss 2.6930e-01 (1.3708e-01) 
2023-05-25 23:19:42.539227: val Epoch: [40][56/72]	Time  1.163 ( 0.636)	Data  1.042 ( 0.514)	Loss 1.3424e-01 (1.3703e-01) 
2023-05-25 23:19:42.659033: val Epoch: [40][57/72]	Time  0.120 ( 0.627)	Data  0.000 ( 0.505)	Loss 1.2586e-01 (1.3684e-01) 
2023-05-25 23:19:43.755002: val Epoch: [40][58/72]	Time  1.096 ( 0.635)	Data  0.972 ( 0.513)	Loss 6.1708e-02 (1.3556e-01) 
2023-05-25 23:19:43.881946: val Epoch: [40][59/72]	Time  0.127 ( 0.627)	Data  0.001 ( 0.504)	Loss 1.0272e-01 (1.3502e-01) 
2023-05-25 23:19:44.996811: val Epoch: [40][60/72]	Time  1.115 ( 0.635)	Data  0.995 ( 0.512)	Loss 5.0282e-01 (1.4105e-01) 
2023-05-25 23:19:45.119135: val Epoch: [40][61/72]	Time  0.122 ( 0.627)	Data  0.001 ( 0.504)	Loss 2.4117e-01 (1.4266e-01) 
2023-05-25 23:19:46.190618: val Epoch: [40][62/72]	Time  1.071 ( 0.634)	Data  0.951 ( 0.511)	Loss 5.7104e-02 (1.4130e-01) 
2023-05-25 23:19:46.311458: val Epoch: [40][63/72]	Time  0.121 ( 0.626)	Data  0.001 ( 0.503)	Loss 5.7043e-02 (1.3999e-01) 
2023-05-25 23:19:47.376238: val Epoch: [40][64/72]	Time  1.065 ( 0.632)	Data  0.944 ( 0.510)	Loss 1.4875e-01 (1.4012e-01) 
2023-05-25 23:19:47.496328: val Epoch: [40][65/72]	Time  0.120 ( 0.625)	Data  0.001 ( 0.502)	Loss 1.3881e-01 (1.4010e-01) 
2023-05-25 23:19:48.628678: val Epoch: [40][66/72]	Time  1.132 ( 0.632)	Data  1.012 ( 0.510)	Loss 5.0683e-02 (1.3877e-01) 
2023-05-25 23:19:48.749207: val Epoch: [40][67/72]	Time  0.121 ( 0.625)	Data  0.001 ( 0.502)	Loss 5.2623e-02 (1.3750e-01) 
2023-05-25 23:19:49.844643: val Epoch: [40][68/72]	Time  1.095 ( 0.632)	Data  0.974 ( 0.509)	Loss 6.2887e-02 (1.3642e-01) 
2023-05-25 23:19:49.970111: val Epoch: [40][69/72]	Time  0.125 ( 0.624)	Data  0.000 ( 0.502)	Loss 5.7427e-02 (1.3529e-01) 
2023-05-25 23:19:50.772190: val Epoch: [40][70/72]	Time  0.802 ( 0.627)	Data  0.683 ( 0.504)	Loss 1.5927e-01 (1.3563e-01) 
2023-05-25 23:19:50.891260: val Epoch: [40][71/72]	Time  0.119 ( 0.620)	Data  0.000 ( 0.497)	Loss 4.6584e-02 (1.3439e-01) 
2023-05-25 23:19:51.079015: Epoch 40 :Val : ['ET : 0.7288909554481506', 'TC : 0.7843514680862427', 'WT : 0.8398592472076416'] 
2023-05-25 23:19:51.081836: Epoch 40 :Val : ['ET : 0.7288909554481506', 'TC : 0.7843514680862427', 'WT : 0.8398592472076416'] 
2023-05-25 23:19:51.083657: Val epoch done in 45.516143937999004 s 
2023-05-25 23:19:51.088870: Batches per epoch:  129 
2023-05-25 23:19:55.723603: train Epoch: [41][  0/129]	Time  4.634 ( 4.634)	Data  3.634 ( 3.634)	Loss 8.8191e-02 (8.8191e-02) 
2023-05-25 23:19:56.673792: train Epoch: [41][  1/129]	Time  0.950 ( 2.792)	Data  0.001 ( 1.817)	Loss 8.7649e-02 (8.7920e-02) 
2023-05-25 23:19:59.471575: train Epoch: [41][  2/129]	Time  2.798 ( 2.794)	Data  1.850 ( 1.828)	Loss 1.1925e-01 (9.8365e-02) 
2023-05-25 23:20:00.419315: train Epoch: [41][  3/129]	Time  0.948 ( 2.333)	Data  0.001 ( 1.371)	Loss 7.2090e-02 (9.1796e-02) 
2023-05-25 23:20:03.096823: train Epoch: [41][  4/129]	Time  2.678 ( 2.402)	Data  1.730 ( 1.443)	Loss 9.3887e-02 (9.2214e-02) 
2023-05-25 23:20:04.045919: train Epoch: [41][  5/129]	Time  0.949 ( 2.159)	Data  0.001 ( 1.203)	Loss 7.5904e-02 (8.9496e-02) 
2023-05-25 23:20:06.794986: train Epoch: [41][  6/129]	Time  2.749 ( 2.244)	Data  1.803 ( 1.288)	Loss 1.0614e-01 (9.1873e-02) 
2023-05-25 23:20:07.745416: train Epoch: [41][  7/129]	Time  0.950 ( 2.082)	Data  0.001 ( 1.127)	Loss 5.5031e-02 (8.7268e-02) 
2023-05-25 23:20:10.496413: train Epoch: [41][  8/129]	Time  2.751 ( 2.156)	Data  1.806 ( 1.203)	Loss 1.0686e-01 (8.9445e-02) 
2023-05-25 23:20:11.443846: train Epoch: [41][  9/129]	Time  0.947 ( 2.035)	Data  0.001 ( 1.083)	Loss 9.4957e-02 (8.9996e-02) 
2023-05-25 23:20:14.034597: train Epoch: [41][ 10/129]	Time  2.591 ( 2.086)	Data  1.645 ( 1.134)	Loss 4.5925e-02 (8.5990e-02) 
2023-05-25 23:20:14.984059: train Epoch: [41][ 11/129]	Time  0.949 ( 1.991)	Data  0.001 ( 1.039)	Loss 9.7882e-02 (8.6981e-02) 
2023-05-25 23:20:17.679583: train Epoch: [41][ 12/129]	Time  2.696 ( 2.045)	Data  1.751 ( 1.094)	Loss 5.9541e-02 (8.4870e-02) 
2023-05-25 23:20:18.631055: train Epoch: [41][ 13/129]	Time  0.951 ( 1.967)	Data  0.001 ( 1.016)	Loss 1.0057e-01 (8.5991e-02) 
2023-05-25 23:20:21.313363: train Epoch: [41][ 14/129]	Time  2.682 ( 2.015)	Data  1.736 ( 1.064)	Loss 9.9543e-02 (8.6895e-02) 
2023-05-25 23:20:22.262698: train Epoch: [41][ 15/129]	Time  0.949 ( 1.948)	Data  0.001 ( 0.998)	Loss 6.1134e-02 (8.5284e-02) 
2023-05-25 23:20:24.893685: train Epoch: [41][ 16/129]	Time  2.631 ( 1.988)	Data  1.686 ( 1.038)	Loss 1.0858e-01 (8.6655e-02) 
2023-05-25 23:20:25.847231: train Epoch: [41][ 17/129]	Time  0.954 ( 1.931)	Data  0.001 ( 0.981)	Loss 1.0104e-01 (8.7454e-02) 
2023-05-25 23:20:28.535327: train Epoch: [41][ 18/129]	Time  2.688 ( 1.971)	Data  1.744 ( 1.021)	Loss 1.0135e-01 (8.8185e-02) 
2023-05-25 23:20:29.484185: train Epoch: [41][ 19/129]	Time  0.949 ( 1.920)	Data  0.001 ( 0.970)	Loss 5.8761e-02 (8.6714e-02) 
2023-05-25 23:20:32.163621: train Epoch: [41][ 20/129]	Time  2.679 ( 1.956)	Data  1.735 ( 1.006)	Loss 1.0664e-01 (8.7663e-02) 
2023-05-25 23:20:33.112274: train Epoch: [41][ 21/129]	Time  0.949 ( 1.910)	Data  0.001 ( 0.960)	Loss 7.0956e-02 (8.6903e-02) 
2023-05-25 23:20:35.736475: train Epoch: [41][ 22/129]	Time  2.624 ( 1.941)	Data  1.678 ( 0.992)	Loss 8.1776e-02 (8.6680e-02) 
2023-05-25 23:20:36.684592: train Epoch: [41][ 23/129]	Time  0.948 ( 1.900)	Data  0.001 ( 0.950)	Loss 8.0918e-02 (8.6440e-02) 
2023-05-25 23:20:39.295675: train Epoch: [41][ 24/129]	Time  2.611 ( 1.928)	Data  1.666 ( 0.979)	Loss 1.0016e-01 (8.6989e-02) 
2023-05-25 23:20:40.245651: train Epoch: [41][ 25/129]	Time  0.950 ( 1.891)	Data  0.001 ( 0.941)	Loss 1.0583e-01 (8.7714e-02) 
2023-05-25 23:20:42.834370: train Epoch: [41][ 26/129]	Time  2.589 ( 1.916)	Data  1.642 ( 0.967)	Loss 5.6349e-02 (8.6552e-02) 
2023-05-25 23:20:43.789500: train Epoch: [41][ 27/129]	Time  0.955 ( 1.882)	Data  0.001 ( 0.933)	Loss 9.1083e-02 (8.6714e-02) 
2023-05-25 23:20:46.422505: train Epoch: [41][ 28/129]	Time  2.633 ( 1.908)	Data  1.688 ( 0.959)	Loss 7.4797e-02 (8.6303e-02) 
2023-05-25 23:20:47.370525: train Epoch: [41][ 29/129]	Time  0.948 ( 1.876)	Data  0.001 ( 0.927)	Loss 8.3660e-02 (8.6215e-02) 
2023-05-25 23:20:49.987400: train Epoch: [41][ 30/129]	Time  2.617 ( 1.900)	Data  1.672 ( 0.951)	Loss 9.4652e-02 (8.6487e-02) 
2023-05-25 23:20:50.937488: train Epoch: [41][ 31/129]	Time  0.950 ( 1.870)	Data  0.001 ( 0.921)	Loss 6.6291e-02 (8.5856e-02) 
2023-05-25 23:20:53.589663: train Epoch: [41][ 32/129]	Time  2.652 ( 1.894)	Data  1.707 ( 0.945)	Loss 6.2390e-02 (8.5145e-02) 
2023-05-25 23:20:54.537824: train Epoch: [41][ 33/129]	Time  0.948 ( 1.866)	Data  0.001 ( 0.917)	Loss 1.5011e-01 (8.7055e-02) 
2023-05-25 23:20:57.083481: train Epoch: [41][ 34/129]	Time  2.546 ( 1.886)	Data  1.602 ( 0.937)	Loss 8.6356e-02 (8.7035e-02) 
2023-05-25 23:20:58.031980: train Epoch: [41][ 35/129]	Time  0.949 ( 1.860)	Data  0.001 ( 0.911)	Loss 7.9998e-02 (8.6840e-02) 
2023-05-25 23:21:00.677894: train Epoch: [41][ 36/129]	Time  2.646 ( 1.881)	Data  1.699 ( 0.932)	Loss 7.0616e-02 (8.6401e-02) 
2023-05-25 23:21:01.631175: train Epoch: [41][ 37/129]	Time  0.953 ( 1.856)	Data  0.001 ( 0.908)	Loss 1.0358e-01 (8.6853e-02) 
2023-05-25 23:21:04.224405: train Epoch: [41][ 38/129]	Time  2.593 ( 1.875)	Data  1.647 ( 0.927)	Loss 6.6794e-02 (8.6339e-02) 
2023-05-25 23:21:05.174097: train Epoch: [41][ 39/129]	Time  0.950 ( 1.852)	Data  0.001 ( 0.903)	Loss 6.6393e-02 (8.5840e-02) 
2023-05-25 23:21:07.831283: train Epoch: [41][ 40/129]	Time  2.657 ( 1.872)	Data  1.708 ( 0.923)	Loss 1.1996e-01 (8.6673e-02) 
2023-05-25 23:21:08.780289: train Epoch: [41][ 41/129]	Time  0.949 ( 1.850)	Data  0.001 ( 0.901)	Loss 1.0602e-01 (8.7133e-02) 
2023-05-25 23:21:11.497929: train Epoch: [41][ 42/129]	Time  2.718 ( 1.870)	Data  1.775 ( 0.921)	Loss 6.2583e-02 (8.6562e-02) 
2023-05-25 23:21:12.446335: train Epoch: [41][ 43/129]	Time  0.948 ( 1.849)	Data  0.001 ( 0.901)	Loss 4.9999e-02 (8.5731e-02) 
2023-05-25 23:21:15.148164: train Epoch: [41][ 44/129]	Time  2.702 ( 1.868)	Data  1.757 ( 0.920)	Loss 1.1721e-01 (8.6431e-02) 
2023-05-25 23:21:16.095309: train Epoch: [41][ 45/129]	Time  0.947 ( 1.848)	Data  0.001 ( 0.900)	Loss 8.0396e-02 (8.6300e-02) 
2023-05-25 23:21:18.735066: train Epoch: [41][ 46/129]	Time  2.640 ( 1.865)	Data  1.695 ( 0.917)	Loss 1.9523e-01 (8.8617e-02) 
2023-05-25 23:21:19.683601: train Epoch: [41][ 47/129]	Time  0.949 ( 1.846)	Data  0.001 ( 0.897)	Loss 7.4319e-02 (8.8319e-02) 
2023-05-25 23:21:22.323520: train Epoch: [41][ 48/129]	Time  2.640 ( 1.862)	Data  1.694 ( 0.914)	Loss 4.3811e-02 (8.7411e-02) 
2023-05-25 23:21:23.274377: train Epoch: [41][ 49/129]	Time  0.951 ( 1.844)	Data  0.001 ( 0.895)	Loss 1.5134e-01 (8.8690e-02) 
2023-05-25 23:21:25.980962: train Epoch: [41][ 50/129]	Time  2.707 ( 1.861)	Data  1.762 ( 0.912)	Loss 6.2489e-02 (8.8176e-02) 
2023-05-25 23:21:26.929992: train Epoch: [41][ 51/129]	Time  0.949 ( 1.843)	Data  0.001 ( 0.895)	Loss 1.1302e-01 (8.8654e-02) 
2023-05-25 23:21:29.724084: train Epoch: [41][ 52/129]	Time  2.794 ( 1.861)	Data  1.849 ( 0.913)	Loss 8.0830e-02 (8.8506e-02) 
2023-05-25 23:21:30.671083: train Epoch: [41][ 53/129]	Time  0.947 ( 1.844)	Data  0.001 ( 0.896)	Loss 7.8658e-02 (8.8324e-02) 
2023-05-25 23:21:33.446975: train Epoch: [41][ 54/129]	Time  2.776 ( 1.861)	Data  1.829 ( 0.913)	Loss 6.3825e-02 (8.7878e-02) 
2023-05-25 23:21:34.395628: train Epoch: [41][ 55/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.897)	Loss 6.6788e-02 (8.7502e-02) 
2023-05-25 23:21:37.054160: train Epoch: [41][ 56/129]	Time  2.659 ( 1.859)	Data  1.715 ( 0.911)	Loss 5.6285e-02 (8.6954e-02) 
2023-05-25 23:21:38.003816: train Epoch: [41][ 57/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.895)	Loss 1.4577e-01 (8.7968e-02) 
2023-05-25 23:21:40.594184: train Epoch: [41][ 58/129]	Time  2.590 ( 1.856)	Data  1.647 ( 0.908)	Loss 6.7548e-02 (8.7622e-02) 
2023-05-25 23:21:41.542360: train Epoch: [41][ 59/129]	Time  0.948 ( 1.841)	Data  0.001 ( 0.893)	Loss 1.2926e-01 (8.8316e-02) 
2023-05-25 23:21:44.195259: train Epoch: [41][ 60/129]	Time  2.653 ( 1.854)	Data  1.707 ( 0.906)	Loss 6.8388e-02 (8.7989e-02) 
2023-05-25 23:21:45.144271: train Epoch: [41][ 61/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.892)	Loss 6.0766e-02 (8.7550e-02) 
2023-05-25 23:21:47.850061: train Epoch: [41][ 62/129]	Time  2.706 ( 1.853)	Data  1.761 ( 0.906)	Loss 6.6530e-02 (8.7217e-02) 
2023-05-25 23:21:48.798047: train Epoch: [41][ 63/129]	Time  0.948 ( 1.839)	Data  0.001 ( 0.891)	Loss 1.3063e-01 (8.7895e-02) 
2023-05-25 23:21:51.489392: train Epoch: [41][ 64/129]	Time  2.691 ( 1.852)	Data  1.745 ( 0.905)	Loss 7.2079e-02 (8.7652e-02) 
2023-05-25 23:21:52.436825: train Epoch: [41][ 65/129]	Time  0.947 ( 1.839)	Data  0.001 ( 0.891)	Loss 8.2382e-02 (8.7572e-02) 
2023-05-25 23:21:55.060222: train Epoch: [41][ 66/129]	Time  2.623 ( 1.850)	Data  1.678 ( 0.903)	Loss 1.4855e-01 (8.8482e-02) 
2023-05-25 23:21:56.010438: train Epoch: [41][ 67/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.889)	Loss 1.0495e-01 (8.8724e-02) 
2023-05-25 23:21:58.721733: train Epoch: [41][ 68/129]	Time  2.711 ( 1.850)	Data  1.767 ( 0.902)	Loss 8.3116e-02 (8.8643e-02) 
2023-05-25 23:21:59.669653: train Epoch: [41][ 69/129]	Time  0.948 ( 1.837)	Data  0.001 ( 0.889)	Loss 7.1550e-02 (8.8399e-02) 
2023-05-25 23:22:02.243966: train Epoch: [41][ 70/129]	Time  2.574 ( 1.847)	Data  1.629 ( 0.900)	Loss 9.1071e-02 (8.8436e-02) 
2023-05-25 23:22:03.192242: train Epoch: [41][ 71/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.887)	Loss 1.0989e-01 (8.8734e-02) 
2023-05-25 23:22:05.858967: train Epoch: [41][ 72/129]	Time  2.667 ( 1.846)	Data  1.720 ( 0.899)	Loss 8.0746e-02 (8.8625e-02) 
2023-05-25 23:22:06.807784: train Epoch: [41][ 73/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.886)	Loss 6.7749e-02 (8.8343e-02) 
2023-05-25 23:22:09.467343: train Epoch: [41][ 74/129]	Time  2.660 ( 1.845)	Data  1.704 ( 0.897)	Loss 7.6163e-02 (8.8180e-02) 
2023-05-25 23:22:10.426471: train Epoch: [41][ 75/129]	Time  0.959 ( 1.833)	Data  0.001 ( 0.885)	Loss 8.7113e-02 (8.8166e-02) 
2023-05-25 23:22:12.968984: train Epoch: [41][ 76/129]	Time  2.543 ( 1.843)	Data  1.596 ( 0.895)	Loss 7.3648e-02 (8.7978e-02) 
2023-05-25 23:22:13.918002: train Epoch: [41][ 77/129]	Time  0.949 ( 1.831)	Data  0.001 ( 0.883)	Loss 1.0844e-01 (8.8240e-02) 
2023-05-25 23:22:16.533990: train Epoch: [41][ 78/129]	Time  2.616 ( 1.841)	Data  1.670 ( 0.893)	Loss 6.0768e-02 (8.7892e-02) 
2023-05-25 23:22:17.483423: train Epoch: [41][ 79/129]	Time  0.949 ( 1.830)	Data  0.001 ( 0.882)	Loss 5.9581e-02 (8.7538e-02) 
2023-05-25 23:22:20.178932: train Epoch: [41][ 80/129]	Time  2.696 ( 1.841)	Data  1.749 ( 0.893)	Loss 4.2893e-02 (8.6987e-02) 
2023-05-25 23:22:21.127811: train Epoch: [41][ 81/129]	Time  0.949 ( 1.830)	Data  0.001 ( 0.882)	Loss 6.5906e-02 (8.6730e-02) 
2023-05-25 23:22:23.822292: train Epoch: [41][ 82/129]	Time  2.694 ( 1.840)	Data  1.750 ( 0.892)	Loss 6.6043e-02 (8.6481e-02) 
2023-05-25 23:22:24.773796: train Epoch: [41][ 83/129]	Time  0.951 ( 1.830)	Data  0.001 ( 0.882)	Loss 8.4500e-02 (8.6457e-02) 
2023-05-25 23:22:27.446956: train Epoch: [41][ 84/129]	Time  2.673 ( 1.839)	Data  1.728 ( 0.892)	Loss 1.1495e-01 (8.6793e-02) 
2023-05-25 23:22:28.397852: train Epoch: [41][ 85/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.881)	Loss 9.6881e-02 (8.6910e-02) 
2023-05-25 23:22:31.086863: train Epoch: [41][ 86/129]	Time  2.689 ( 1.839)	Data  1.741 ( 0.891)	Loss 8.7438e-02 (8.6916e-02) 
2023-05-25 23:22:32.036648: train Epoch: [41][ 87/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.881)	Loss 8.6928e-02 (8.6916e-02) 
2023-05-25 23:22:34.714965: train Epoch: [41][ 88/129]	Time  2.678 ( 1.838)	Data  1.732 ( 0.891)	Loss 3.8593e-02 (8.6373e-02) 
2023-05-25 23:22:35.666479: train Epoch: [41][ 89/129]	Time  0.952 ( 1.829)	Data  0.001 ( 0.881)	Loss 8.1162e-02 (8.6315e-02) 
2023-05-25 23:22:38.359053: train Epoch: [41][ 90/129]	Time  2.693 ( 1.838)	Data  1.747 ( 0.890)	Loss 9.1160e-02 (8.6368e-02) 
2023-05-25 23:22:39.310326: train Epoch: [41][ 91/129]	Time  0.951 ( 1.828)	Data  0.001 ( 0.881)	Loss 1.1264e-01 (8.6654e-02) 
2023-05-25 23:22:42.007570: train Epoch: [41][ 92/129]	Time  2.697 ( 1.838)	Data  1.751 ( 0.890)	Loss 1.9634e-01 (8.7834e-02) 
2023-05-25 23:22:42.959846: train Epoch: [41][ 93/129]	Time  0.952 ( 1.828)	Data  0.001 ( 0.881)	Loss 1.0173e-01 (8.7981e-02) 
2023-05-25 23:22:45.781263: train Epoch: [41][ 94/129]	Time  2.821 ( 1.839)	Data  1.875 ( 0.891)	Loss 5.7276e-02 (8.7658e-02) 
2023-05-25 23:22:46.730466: train Epoch: [41][ 95/129]	Time  0.949 ( 1.830)	Data  0.001 ( 0.882)	Loss 9.6770e-02 (8.7753e-02) 
2023-05-25 23:22:49.423383: train Epoch: [41][ 96/129]	Time  2.693 ( 1.838)	Data  1.742 ( 0.891)	Loss 5.6546e-02 (8.7431e-02) 
2023-05-25 23:22:50.372835: train Epoch: [41][ 97/129]	Time  0.949 ( 1.829)	Data  0.001 ( 0.882)	Loss 7.3733e-02 (8.7292e-02) 
2023-05-25 23:22:52.998330: train Epoch: [41][ 98/129]	Time  2.625 ( 1.837)	Data  1.664 ( 0.889)	Loss 5.9499e-02 (8.7011e-02) 
2023-05-25 23:22:53.957330: train Epoch: [41][ 99/129]	Time  0.959 ( 1.829)	Data  0.001 ( 0.881)	Loss 1.6450e-01 (8.7786e-02) 
2023-05-25 23:22:56.605404: train Epoch: [41][100/129]	Time  2.648 ( 1.837)	Data  1.696 ( 0.889)	Loss 1.2316e-01 (8.8136e-02) 
2023-05-25 23:22:57.556281: train Epoch: [41][101/129]	Time  0.951 ( 1.828)	Data  0.001 ( 0.880)	Loss 7.5174e-02 (8.8009e-02) 
2023-05-25 23:23:00.284693: train Epoch: [41][102/129]	Time  2.728 ( 1.837)	Data  1.781 ( 0.889)	Loss 8.0450e-02 (8.7935e-02) 
2023-05-25 23:23:01.233499: train Epoch: [41][103/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.880)	Loss 7.8213e-02 (8.7842e-02) 
2023-05-25 23:23:04.022198: train Epoch: [41][104/129]	Time  2.789 ( 1.837)	Data  1.842 ( 0.889)	Loss 9.8015e-02 (8.7939e-02) 
2023-05-25 23:23:04.971821: train Epoch: [41][105/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.881)	Loss 1.0250e-01 (8.8076e-02) 
2023-05-25 23:23:07.768383: train Epoch: [41][106/129]	Time  2.797 ( 1.838)	Data  1.849 ( 0.890)	Loss 1.3493e-01 (8.8514e-02) 
2023-05-25 23:23:08.719956: train Epoch: [41][107/129]	Time  0.952 ( 1.830)	Data  0.001 ( 0.882)	Loss 8.2620e-02 (8.8460e-02) 
2023-05-25 23:23:11.445046: train Epoch: [41][108/129]	Time  2.725 ( 1.838)	Data  1.777 ( 0.890)	Loss 2.0658e-01 (8.9543e-02) 
2023-05-25 23:23:12.405983: train Epoch: [41][109/129]	Time  0.961 ( 1.830)	Data  0.001 ( 0.882)	Loss 1.1070e-01 (8.9736e-02) 
2023-05-25 23:23:15.179538: train Epoch: [41][110/129]	Time  2.774 ( 1.839)	Data  1.816 ( 0.890)	Loss 6.7166e-02 (8.9532e-02) 
2023-05-25 23:23:16.140200: train Epoch: [41][111/129]	Time  0.961 ( 1.831)	Data  0.001 ( 0.882)	Loss 1.3469e-01 (8.9935e-02) 
2023-05-25 23:23:18.814786: train Epoch: [41][112/129]	Time  2.675 ( 1.838)	Data  1.710 ( 0.890)	Loss 1.1549e-01 (9.0162e-02) 
2023-05-25 23:23:19.775383: train Epoch: [41][113/129]	Time  0.961 ( 1.831)	Data  0.001 ( 0.882)	Loss 7.8429e-02 (9.0059e-02) 
2023-05-25 23:23:22.632943: train Epoch: [41][114/129]	Time  2.858 ( 1.840)	Data  1.900 ( 0.891)	Loss 7.3453e-02 (8.9914e-02) 
2023-05-25 23:23:23.594337: train Epoch: [41][115/129]	Time  0.961 ( 1.832)	Data  0.001 ( 0.883)	Loss 6.3697e-02 (8.9688e-02) 
2023-05-25 23:23:26.338503: train Epoch: [41][116/129]	Time  2.744 ( 1.840)	Data  1.786 ( 0.891)	Loss 6.3814e-02 (8.9467e-02) 
2023-05-25 23:23:27.298987: train Epoch: [41][117/129]	Time  0.960 ( 1.832)	Data  0.001 ( 0.883)	Loss 1.5989e-01 (9.0064e-02) 
2023-05-25 23:23:30.060336: train Epoch: [41][118/129]	Time  2.761 ( 1.840)	Data  1.808 ( 0.891)	Loss 1.2312e-01 (9.0342e-02) 
2023-05-25 23:23:31.018810: train Epoch: [41][119/129]	Time  0.958 ( 1.833)	Data  0.001 ( 0.884)	Loss 5.9681e-02 (9.0086e-02) 
2023-05-25 23:23:33.687532: train Epoch: [41][120/129]	Time  2.669 ( 1.840)	Data  1.723 ( 0.891)	Loss 7.6826e-02 (8.9977e-02) 
2023-05-25 23:23:34.635746: train Epoch: [41][121/129]	Time  0.948 ( 1.832)	Data  0.001 ( 0.883)	Loss 1.5229e-01 (9.0487e-02) 
2023-05-25 23:23:37.184352: train Epoch: [41][122/129]	Time  2.549 ( 1.838)	Data  1.602 ( 0.889)	Loss 7.6000e-02 (9.0370e-02) 
2023-05-25 23:23:38.132284: train Epoch: [41][123/129]	Time  0.948 ( 1.831)	Data  0.001 ( 0.882)	Loss 1.4212e-01 (9.0787e-02) 
2023-05-25 23:23:40.806026: train Epoch: [41][124/129]	Time  2.674 ( 1.838)	Data  1.728 ( 0.889)	Loss 8.5801e-02 (9.0747e-02) 
2023-05-25 23:23:41.755991: train Epoch: [41][125/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.882)	Loss 7.1124e-02 (9.0591e-02) 
2023-05-25 23:23:44.356090: train Epoch: [41][126/129]	Time  2.600 ( 1.837)	Data  1.652 ( 0.888)	Loss 8.5662e-02 (9.0552e-02) 
2023-05-25 23:23:45.302105: train Epoch: [41][127/129]	Time  0.946 ( 1.830)	Data  0.001 ( 0.881)	Loss 4.9339e-02 (9.0230e-02) 
2023-05-25 23:23:46.810571: train Epoch: [41][128/129]	Time  1.508 ( 1.827)	Data  0.562 ( 0.878)	Loss 1.2074e-01 (9.0467e-02) 
2023-05-25 23:23:46.842462: Train Epoch done in 235.75361237199832 s 
2023-05-25 23:23:49.177609: val Epoch: [41][ 0/72]	Time  1.613 ( 1.613)	Data  1.409 ( 1.409)	Loss 3.9148e-01 (3.9148e-01) 
2023-05-25 23:23:49.303356: val Epoch: [41][ 1/72]	Time  0.126 ( 0.869)	Data  0.001 ( 0.705)	Loss 1.2949e-01 (2.6048e-01) 
2023-05-25 23:23:50.317897: val Epoch: [41][ 2/72]	Time  1.015 ( 0.918)	Data  0.890 ( 0.767)	Loss 4.5925e-02 (1.8896e-01) 
2023-05-25 23:23:50.442878: val Epoch: [41][ 3/72]	Time  0.125 ( 0.720)	Data  0.001 ( 0.575)	Loss 1.1129e-01 (1.6955e-01) 
2023-05-25 23:23:51.583781: val Epoch: [41][ 4/72]	Time  1.141 ( 0.804)	Data  1.016 ( 0.663)	Loss 9.0622e-02 (1.5376e-01) 
2023-05-25 23:23:51.708975: val Epoch: [41][ 5/72]	Time  0.125 ( 0.691)	Data  0.001 ( 0.553)	Loss 2.3270e-01 (1.6692e-01) 
2023-05-25 23:23:52.875401: val Epoch: [41][ 6/72]	Time  1.166 ( 0.759)	Data  1.042 ( 0.623)	Loss 3.6051e-01 (1.9457e-01) 
2023-05-25 23:23:53.000261: val Epoch: [41][ 7/72]	Time  0.125 ( 0.679)	Data  0.001 ( 0.545)	Loss 4.4557e-01 (2.2595e-01) 
2023-05-25 23:23:54.102138: val Epoch: [41][ 8/72]	Time  1.102 ( 0.726)	Data  0.977 ( 0.593)	Loss 5.5353e-02 (2.0699e-01) 
2023-05-25 23:23:54.226919: val Epoch: [41][ 9/72]	Time  0.125 ( 0.666)	Data  0.001 ( 0.534)	Loss 6.2256e-02 (1.9252e-01) 
2023-05-25 23:23:55.386769: val Epoch: [41][10/72]	Time  1.160 ( 0.711)	Data  1.034 ( 0.579)	Loss 9.8693e-02 (1.8399e-01) 
2023-05-25 23:23:55.511344: val Epoch: [41][11/72]	Time  0.125 ( 0.662)	Data  0.001 ( 0.531)	Loss 6.0529e-02 (1.7370e-01) 
2023-05-25 23:23:56.596996: val Epoch: [41][12/72]	Time  1.086 ( 0.695)	Data  0.961 ( 0.564)	Loss 1.1653e-01 (1.6930e-01) 
2023-05-25 23:23:56.721343: val Epoch: [41][13/72]	Time  0.124 ( 0.654)	Data  0.001 ( 0.524)	Loss 3.3616e-01 (1.8122e-01) 
2023-05-25 23:23:57.814491: val Epoch: [41][14/72]	Time  1.093 ( 0.683)	Data  0.968 ( 0.553)	Loss 3.5250e-02 (1.7149e-01) 
2023-05-25 23:23:57.939542: val Epoch: [41][15/72]	Time  0.125 ( 0.648)	Data  0.001 ( 0.519)	Loss 1.0763e-01 (1.6750e-01) 
2023-05-25 23:23:59.071869: val Epoch: [41][16/72]	Time  1.132 ( 0.677)	Data  1.008 ( 0.548)	Loss 1.0242e-01 (1.6367e-01) 
2023-05-25 23:23:59.196793: val Epoch: [41][17/72]	Time  0.125 ( 0.646)	Data  0.001 ( 0.517)	Loss 1.1853e-01 (1.6116e-01) 
2023-05-25 23:24:00.275928: val Epoch: [41][18/72]	Time  1.079 ( 0.669)	Data  0.955 ( 0.540)	Loss 4.4845e-02 (1.5504e-01) 
2023-05-25 23:24:00.401062: val Epoch: [41][19/72]	Time  0.125 ( 0.642)	Data  0.001 ( 0.513)	Loss 3.6206e-01 (1.6539e-01) 
2023-05-25 23:24:01.525373: val Epoch: [41][20/72]	Time  1.124 ( 0.665)	Data  1.000 ( 0.536)	Loss 3.7891e-01 (1.7556e-01) 
2023-05-25 23:24:01.649503: val Epoch: [41][21/72]	Time  0.124 ( 0.640)	Data  0.000 ( 0.512)	Loss 4.5284e-02 (1.6964e-01) 
2023-05-25 23:24:02.782273: val Epoch: [41][22/72]	Time  1.133 ( 0.662)	Data  1.008 ( 0.534)	Loss 1.0877e-01 (1.6699e-01) 
2023-05-25 23:24:02.906343: val Epoch: [41][23/72]	Time  0.124 ( 0.639)	Data  0.000 ( 0.511)	Loss 1.3524e-01 (1.6567e-01) 
2023-05-25 23:24:03.946274: val Epoch: [41][24/72]	Time  1.040 ( 0.655)	Data  0.915 ( 0.528)	Loss 4.2251e-02 (1.6073e-01) 
2023-05-25 23:24:04.070587: val Epoch: [41][25/72]	Time  0.124 ( 0.635)	Data  0.001 ( 0.507)	Loss 5.8601e-02 (1.5680e-01) 
2023-05-25 23:24:05.162692: val Epoch: [41][26/72]	Time  1.092 ( 0.652)	Data  0.968 ( 0.524)	Loss 3.9569e-02 (1.5246e-01) 
2023-05-25 23:24:05.287158: val Epoch: [41][27/72]	Time  0.124 ( 0.633)	Data  0.001 ( 0.506)	Loss 3.1673e-01 (1.5833e-01) 
2023-05-25 23:24:06.353329: val Epoch: [41][28/72]	Time  1.066 ( 0.648)	Data  0.941 ( 0.521)	Loss 9.2069e-02 (1.5604e-01) 
2023-05-25 23:24:06.478163: val Epoch: [41][29/72]	Time  0.125 ( 0.630)	Data  0.001 ( 0.503)	Loss 2.4231e-01 (1.5892e-01) 
2023-05-25 23:24:07.565992: val Epoch: [41][30/72]	Time  1.088 ( 0.645)	Data  0.963 ( 0.518)	Loss 2.2134e-01 (1.6093e-01) 
2023-05-25 23:24:07.690191: val Epoch: [41][31/72]	Time  0.124 ( 0.629)	Data  0.001 ( 0.502)	Loss 6.9002e-02 (1.5806e-01) 
2023-05-25 23:24:08.805360: val Epoch: [41][32/72]	Time  1.115 ( 0.644)	Data  0.990 ( 0.517)	Loss 1.1439e-01 (1.5674e-01) 
2023-05-25 23:24:08.931178: val Epoch: [41][33/72]	Time  0.126 ( 0.628)	Data  0.002 ( 0.502)	Loss 2.0370e-01 (1.5812e-01) 
2023-05-25 23:24:10.070717: val Epoch: [41][34/72]	Time  1.140 ( 0.643)	Data  1.015 ( 0.516)	Loss 9.7087e-02 (1.5637e-01) 
2023-05-25 23:24:10.194856: val Epoch: [41][35/72]	Time  0.124 ( 0.629)	Data  0.001 ( 0.502)	Loss 6.5451e-02 (1.5385e-01) 
2023-05-25 23:24:11.316356: val Epoch: [41][36/72]	Time  1.121 ( 0.642)	Data  0.997 ( 0.515)	Loss 1.0856e-01 (1.5262e-01) 
2023-05-25 23:24:11.441318: val Epoch: [41][37/72]	Time  0.125 ( 0.628)	Data  0.001 ( 0.502)	Loss 5.1773e-02 (1.4997e-01) 
2023-05-25 23:24:12.507546: val Epoch: [41][38/72]	Time  1.066 ( 0.640)	Data  0.942 ( 0.513)	Loss 9.6020e-02 (1.4859e-01) 
2023-05-25 23:24:12.631747: val Epoch: [41][39/72]	Time  0.124 ( 0.627)	Data  0.001 ( 0.500)	Loss 6.1629e-02 (1.4641e-01) 
2023-05-25 23:24:13.734206: val Epoch: [41][40/72]	Time  1.102 ( 0.638)	Data  0.978 ( 0.512)	Loss 1.3876e-01 (1.4623e-01) 
2023-05-25 23:24:13.858488: val Epoch: [41][41/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.500)	Loss 1.2469e-01 (1.4571e-01) 
2023-05-25 23:24:14.986058: val Epoch: [41][42/72]	Time  1.128 ( 0.638)	Data  1.003 ( 0.512)	Loss 1.0559e-01 (1.4478e-01) 
2023-05-25 23:24:15.110895: val Epoch: [41][43/72]	Time  0.125 ( 0.626)	Data  0.001 ( 0.500)	Loss 5.5140e-02 (1.4274e-01) 
2023-05-25 23:24:16.171977: val Epoch: [41][44/72]	Time  1.061 ( 0.636)	Data  0.937 ( 0.510)	Loss 6.3219e-02 (1.4098e-01) 
2023-05-25 23:24:16.296276: val Epoch: [41][45/72]	Time  0.124 ( 0.625)	Data  0.001 ( 0.499)	Loss 4.7680e-01 (1.4828e-01) 
2023-05-25 23:24:17.365972: val Epoch: [41][46/72]	Time  1.070 ( 0.634)	Data  0.944 ( 0.508)	Loss 6.0849e-02 (1.4642e-01) 
2023-05-25 23:24:17.490417: val Epoch: [41][47/72]	Time  0.124 ( 0.623)	Data  0.001 ( 0.497)	Loss 9.2887e-02 (1.4530e-01) 
2023-05-25 23:24:18.546691: val Epoch: [41][48/72]	Time  1.056 ( 0.632)	Data  0.931 ( 0.506)	Loss 2.1784e-01 (1.4678e-01) 
2023-05-25 23:24:18.671624: val Epoch: [41][49/72]	Time  0.125 ( 0.622)	Data  0.001 ( 0.496)	Loss 4.1899e-01 (1.5223e-01) 
2023-05-25 23:24:19.757876: val Epoch: [41][50/72]	Time  1.086 ( 0.631)	Data  0.962 ( 0.505)	Loss 9.6924e-02 (1.5114e-01) 
2023-05-25 23:24:19.882004: val Epoch: [41][51/72]	Time  0.124 ( 0.621)	Data  0.001 ( 0.496)	Loss 7.2293e-02 (1.4962e-01) 
2023-05-25 23:24:21.012949: val Epoch: [41][52/72]	Time  1.131 ( 0.631)	Data  1.007 ( 0.505)	Loss 6.7563e-02 (1.4808e-01) 
2023-05-25 23:24:21.136804: val Epoch: [41][53/72]	Time  0.124 ( 0.622)	Data  0.001 ( 0.496)	Loss 5.2723e-02 (1.4631e-01) 
2023-05-25 23:24:22.231983: val Epoch: [41][54/72]	Time  1.095 ( 0.630)	Data  0.971 ( 0.505)	Loss 5.8462e-02 (1.4471e-01) 
2023-05-25 23:24:22.356168: val Epoch: [41][55/72]	Time  0.124 ( 0.621)	Data  0.001 ( 0.496)	Loss 5.5134e-02 (1.4311e-01) 
2023-05-25 23:24:23.440220: val Epoch: [41][56/72]	Time  1.084 ( 0.629)	Data  0.960 ( 0.504)	Loss 3.2332e-01 (1.4628e-01) 
2023-05-25 23:24:23.564514: val Epoch: [41][57/72]	Time  0.124 ( 0.621)	Data  0.001 ( 0.495)	Loss 1.7591e-01 (1.4679e-01) 
2023-05-25 23:24:24.628711: val Epoch: [41][58/72]	Time  1.064 ( 0.628)	Data  0.940 ( 0.503)	Loss 5.2846e-02 (1.4519e-01) 
2023-05-25 23:24:24.752614: val Epoch: [41][59/72]	Time  0.124 ( 0.620)	Data  0.001 ( 0.494)	Loss 8.4160e-02 (1.4418e-01) 
2023-05-25 23:24:25.851478: val Epoch: [41][60/72]	Time  1.099 ( 0.628)	Data  0.975 ( 0.502)	Loss 1.2493e-01 (1.4386e-01) 
2023-05-25 23:24:25.976347: val Epoch: [41][61/72]	Time  0.125 ( 0.620)	Data  0.001 ( 0.494)	Loss 5.0921e-02 (1.4236e-01) 
2023-05-25 23:24:27.102144: val Epoch: [41][62/72]	Time  1.126 ( 0.628)	Data  1.002 ( 0.502)	Loss 1.9656e-01 (1.4322e-01) 
2023-05-25 23:24:27.226382: val Epoch: [41][63/72]	Time  0.124 ( 0.620)	Data  0.001 ( 0.494)	Loss 1.0186e-01 (1.4258e-01) 
2023-05-25 23:24:28.316883: val Epoch: [41][64/72]	Time  1.090 ( 0.627)	Data  0.965 ( 0.501)	Loss 7.1258e-02 (1.4148e-01) 
2023-05-25 23:24:28.441150: val Epoch: [41][65/72]	Time  0.124 ( 0.619)	Data  0.001 ( 0.494)	Loss 3.8673e-02 (1.3992e-01) 
2023-05-25 23:24:29.515446: val Epoch: [41][66/72]	Time  1.074 ( 0.626)	Data  0.949 ( 0.501)	Loss 4.8611e-02 (1.3856e-01) 
2023-05-25 23:24:29.639912: val Epoch: [41][67/72]	Time  0.124 ( 0.619)	Data  0.001 ( 0.493)	Loss 7.2366e-02 (1.3759e-01) 
2023-05-25 23:24:30.724982: val Epoch: [41][68/72]	Time  1.085 ( 0.626)	Data  0.961 ( 0.500)	Loss 1.4824e-01 (1.3774e-01) 
2023-05-25 23:24:30.848602: val Epoch: [41][69/72]	Time  0.124 ( 0.618)	Data  0.000 ( 0.493)	Loss 3.6309e-02 (1.3629e-01) 
2023-05-25 23:24:31.859813: val Epoch: [41][70/72]	Time  1.011 ( 0.624)	Data  0.887 ( 0.498)	Loss 1.2596e-01 (1.3615e-01) 
2023-05-25 23:24:31.982732: val Epoch: [41][71/72]	Time  0.123 ( 0.617)	Data  0.000 ( 0.492)	Loss 5.7499e-02 (1.3505e-01) 
2023-05-25 23:24:32.170087: Epoch 41 :Val : ['ET : 0.7442495822906494', 'TC : 0.7608782649040222', 'WT : 0.8508987426757812'] 
2023-05-25 23:24:32.172761: Epoch 41 :Val : ['ET : 0.7442495822906494', 'TC : 0.7608782649040222', 'WT : 0.8508987426757812'] 
2023-05-25 23:24:32.174589: Val epoch done in 45.332131674000266 s 
2023-05-25 23:24:32.179891: Batches per epoch:  129 
2023-05-25 23:24:37.080468: train Epoch: [42][  0/129]	Time  4.900 ( 4.900)	Data  3.890 ( 3.890)	Loss 5.1202e-02 (5.1202e-02) 
2023-05-25 23:24:38.039610: train Epoch: [42][  1/129]	Time  0.959 ( 2.930)	Data  0.001 ( 1.946)	Loss 6.9854e-02 (6.0528e-02) 
2023-05-25 23:24:40.750534: train Epoch: [42][  2/129]	Time  2.711 ( 2.857)	Data  1.754 ( 1.882)	Loss 9.5477e-02 (7.2178e-02) 
2023-05-25 23:24:41.710505: train Epoch: [42][  3/129]	Time  0.960 ( 2.383)	Data  0.001 ( 1.411)	Loss 6.8936e-02 (7.1367e-02) 
2023-05-25 23:24:44.318511: train Epoch: [42][  4/129]	Time  2.608 ( 2.428)	Data  1.652 ( 1.459)	Loss 1.1914e-01 (8.0921e-02) 
2023-05-25 23:24:45.280204: train Epoch: [42][  5/129]	Time  0.962 ( 2.183)	Data  0.001 ( 1.216)	Loss 8.6268e-02 (8.1812e-02) 
2023-05-25 23:24:47.974912: train Epoch: [42][  6/129]	Time  2.695 ( 2.256)	Data  1.735 ( 1.290)	Loss 8.1803e-02 (8.1811e-02) 
2023-05-25 23:24:48.936257: train Epoch: [42][  7/129]	Time  0.961 ( 2.095)	Data  0.001 ( 1.129)	Loss 1.0677e-01 (8.4931e-02) 
2023-05-25 23:24:51.672542: train Epoch: [42][  8/129]	Time  2.736 ( 2.166)	Data  1.779 ( 1.202)	Loss 1.1704e-01 (8.8499e-02) 
2023-05-25 23:24:52.633586: train Epoch: [42][  9/129]	Time  0.961 ( 2.045)	Data  0.001 ( 1.081)	Loss 9.9118e-02 (8.9560e-02) 
2023-05-25 23:24:55.280880: train Epoch: [42][ 10/129]	Time  2.647 ( 2.100)	Data  1.678 ( 1.136)	Loss 1.6028e-01 (9.5990e-02) 
2023-05-25 23:24:56.242081: train Epoch: [42][ 11/129]	Time  0.961 ( 2.005)	Data  0.001 ( 1.041)	Loss 7.0871e-02 (9.3897e-02) 
2023-05-25 23:24:59.053643: train Epoch: [42][ 12/129]	Time  2.812 ( 2.067)	Data  1.854 ( 1.104)	Loss 6.8909e-02 (9.1974e-02) 
2023-05-25 23:25:00.012948: train Epoch: [42][ 13/129]	Time  0.959 ( 1.988)	Data  0.001 ( 1.025)	Loss 1.4594e-01 (9.5829e-02) 
2023-05-25 23:25:02.767697: train Epoch: [42][ 14/129]	Time  2.755 ( 2.039)	Data  1.799 ( 1.077)	Loss 9.9725e-02 (9.6089e-02) 
2023-05-25 23:25:03.728201: train Epoch: [42][ 15/129]	Time  0.960 ( 1.972)	Data  0.001 ( 1.009)	Loss 7.7232e-02 (9.4911e-02) 
2023-05-25 23:25:06.345913: train Epoch: [42][ 16/129]	Time  2.618 ( 2.010)	Data  1.660 ( 1.048)	Loss 7.1329e-02 (9.3523e-02) 
2023-05-25 23:25:07.305201: train Epoch: [42][ 17/129]	Time  0.959 ( 1.951)	Data  0.001 ( 0.989)	Loss 1.2927e-01 (9.5510e-02) 
2023-05-25 23:25:09.906757: train Epoch: [42][ 18/129]	Time  2.602 ( 1.986)	Data  1.640 ( 1.024)	Loss 8.0373e-02 (9.4713e-02) 
2023-05-25 23:25:10.869885: train Epoch: [42][ 19/129]	Time  0.963 ( 1.934)	Data  0.001 ( 0.973)	Loss 1.0506e-01 (9.5230e-02) 
2023-05-25 23:25:13.591955: train Epoch: [42][ 20/129]	Time  2.722 ( 1.972)	Data  1.757 ( 1.010)	Loss 1.4286e-01 (9.7499e-02) 
2023-05-25 23:25:14.552627: train Epoch: [42][ 21/129]	Time  0.961 ( 1.926)	Data  0.001 ( 0.964)	Loss 9.0989e-02 (9.7203e-02) 
2023-05-25 23:25:17.410044: train Epoch: [42][ 22/129]	Time  2.857 ( 1.967)	Data  1.899 ( 1.005)	Loss 6.0203e-02 (9.5594e-02) 
2023-05-25 23:25:18.370062: train Epoch: [42][ 23/129]	Time  0.960 ( 1.925)	Data  0.001 ( 0.963)	Loss 1.1725e-01 (9.6496e-02) 
2023-05-25 23:25:21.222024: train Epoch: [42][ 24/129]	Time  2.852 ( 1.962)	Data  1.895 ( 1.000)	Loss 7.7318e-02 (9.5729e-02) 
2023-05-25 23:25:22.183003: train Epoch: [42][ 25/129]	Time  0.961 ( 1.923)	Data  0.001 ( 0.962)	Loss 1.1120e-01 (9.6324e-02) 
2023-05-25 23:25:24.946315: train Epoch: [42][ 26/129]	Time  2.763 ( 1.954)	Data  1.806 ( 0.993)	Loss 1.1760e-01 (9.7112e-02) 
2023-05-25 23:25:25.905306: train Epoch: [42][ 27/129]	Time  0.959 ( 1.919)	Data  0.001 ( 0.958)	Loss 8.5074e-02 (9.6682e-02) 
2023-05-25 23:25:28.642749: train Epoch: [42][ 28/129]	Time  2.737 ( 1.947)	Data  1.769 ( 0.986)	Loss 7.7227e-02 (9.6011e-02) 
2023-05-25 23:25:29.603997: train Epoch: [42][ 29/129]	Time  0.961 ( 1.914)	Data  0.001 ( 0.953)	Loss 7.3768e-02 (9.5270e-02) 
2023-05-25 23:25:32.438300: train Epoch: [42][ 30/129]	Time  2.834 ( 1.944)	Data  1.879 ( 0.983)	Loss 7.5799e-02 (9.4642e-02) 
2023-05-25 23:25:33.397444: train Epoch: [42][ 31/129]	Time  0.959 ( 1.913)	Data  0.001 ( 0.952)	Loss 9.1654e-02 (9.4549e-02) 
2023-05-25 23:25:36.052870: train Epoch: [42][ 32/129]	Time  2.655 ( 1.936)	Data  1.707 ( 0.975)	Loss 1.1335e-01 (9.5118e-02) 
2023-05-25 23:25:37.004012: train Epoch: [42][ 33/129]	Time  0.951 ( 1.907)	Data  0.001 ( 0.946)	Loss 7.0704e-02 (9.4400e-02) 
2023-05-25 23:25:39.700189: train Epoch: [42][ 34/129]	Time  2.696 ( 1.929)	Data  1.751 ( 0.969)	Loss 7.7636e-02 (9.3921e-02) 
2023-05-25 23:25:40.660334: train Epoch: [42][ 35/129]	Time  0.960 ( 1.902)	Data  0.001 ( 0.942)	Loss 7.5090e-02 (9.3398e-02) 
2023-05-25 23:25:43.245999: train Epoch: [42][ 36/129]	Time  2.586 ( 1.921)	Data  1.631 ( 0.961)	Loss 5.4242e-02 (9.2340e-02) 
2023-05-25 23:25:44.206763: train Epoch: [42][ 37/129]	Time  0.961 ( 1.895)	Data  0.001 ( 0.936)	Loss 6.8709e-02 (9.1718e-02) 
2023-05-25 23:25:46.872429: train Epoch: [42][ 38/129]	Time  2.666 ( 1.915)	Data  1.709 ( 0.955)	Loss 5.9690e-02 (9.0897e-02) 
2023-05-25 23:25:47.827541: train Epoch: [42][ 39/129]	Time  0.955 ( 1.891)	Data  0.001 ( 0.932)	Loss 9.5390e-02 (9.1009e-02) 
2023-05-25 23:25:50.509162: train Epoch: [42][ 40/129]	Time  2.682 ( 1.910)	Data  1.734 ( 0.951)	Loss 9.4845e-02 (9.1103e-02) 
2023-05-25 23:25:51.457455: train Epoch: [42][ 41/129]	Time  0.948 ( 1.888)	Data  0.001 ( 0.929)	Loss 9.2736e-02 (9.1142e-02) 
2023-05-25 23:25:54.094444: train Epoch: [42][ 42/129]	Time  2.637 ( 1.905)	Data  1.691 ( 0.946)	Loss 6.5605e-02 (9.0548e-02) 
2023-05-25 23:25:55.044060: train Epoch: [42][ 43/129]	Time  0.950 ( 1.883)	Data  0.001 ( 0.925)	Loss 7.4704e-02 (9.0188e-02) 
2023-05-25 23:25:57.793208: train Epoch: [42][ 44/129]	Time  2.749 ( 1.903)	Data  1.804 ( 0.944)	Loss 7.8481e-02 (8.9928e-02) 
2023-05-25 23:25:58.742105: train Epoch: [42][ 45/129]	Time  0.949 ( 1.882)	Data  0.001 ( 0.924)	Loss 5.3046e-02 (8.9126e-02) 
2023-05-25 23:26:01.355968: train Epoch: [42][ 46/129]	Time  2.614 ( 1.897)	Data  1.669 ( 0.940)	Loss 5.6809e-02 (8.8438e-02) 
2023-05-25 23:26:02.307620: train Epoch: [42][ 47/129]	Time  0.952 ( 1.878)	Data  0.001 ( 0.920)	Loss 1.0357e-01 (8.8753e-02) 
2023-05-25 23:26:04.910014: train Epoch: [42][ 48/129]	Time  2.602 ( 1.892)	Data  1.655 ( 0.935)	Loss 8.7395e-02 (8.8726e-02) 
2023-05-25 23:26:05.861925: train Epoch: [42][ 49/129]	Time  0.952 ( 1.874)	Data  0.001 ( 0.916)	Loss 6.0118e-02 (8.8154e-02) 
2023-05-25 23:26:08.632002: train Epoch: [42][ 50/129]	Time  2.770 ( 1.891)	Data  1.814 ( 0.934)	Loss 7.0749e-02 (8.7812e-02) 
2023-05-25 23:26:09.592893: train Epoch: [42][ 51/129]	Time  0.961 ( 1.873)	Data  0.001 ( 0.916)	Loss 7.2364e-02 (8.7515e-02) 
2023-05-25 23:26:12.170800: train Epoch: [42][ 52/129]	Time  2.578 ( 1.887)	Data  1.631 ( 0.930)	Loss 9.9769e-02 (8.7746e-02) 
2023-05-25 23:26:13.120283: train Epoch: [42][ 53/129]	Time  0.949 ( 1.869)	Data  0.001 ( 0.912)	Loss 1.0014e-01 (8.7976e-02) 
2023-05-25 23:26:15.784024: train Epoch: [42][ 54/129]	Time  2.664 ( 1.884)	Data  1.718 ( 0.927)	Loss 8.2975e-02 (8.7885e-02) 
2023-05-25 23:26:16.734127: train Epoch: [42][ 55/129]	Time  0.950 ( 1.867)	Data  0.001 ( 0.910)	Loss 9.3335e-02 (8.7982e-02) 
2023-05-25 23:26:19.333194: train Epoch: [42][ 56/129]	Time  2.599 ( 1.880)	Data  1.652 ( 0.923)	Loss 8.9830e-02 (8.8015e-02) 
2023-05-25 23:26:20.284975: train Epoch: [42][ 57/129]	Time  0.952 ( 1.864)	Data  0.001 ( 0.908)	Loss 8.1771e-02 (8.7907e-02) 
2023-05-25 23:26:23.056389: train Epoch: [42][ 58/129]	Time  2.771 ( 1.879)	Data  1.813 ( 0.923)	Loss 8.4224e-02 (8.7845e-02) 
2023-05-25 23:26:24.008191: train Epoch: [42][ 59/129]	Time  0.952 ( 1.864)	Data  0.001 ( 0.908)	Loss 5.6766e-02 (8.7327e-02) 
2023-05-25 23:26:26.887918: train Epoch: [42][ 60/129]	Time  2.880 ( 1.880)	Data  1.919 ( 0.924)	Loss 7.8976e-02 (8.7190e-02) 
2023-05-25 23:26:27.839733: train Epoch: [42][ 61/129]	Time  0.952 ( 1.865)	Data  0.001 ( 0.909)	Loss 1.1726e-01 (8.7675e-02) 
2023-05-25 23:26:30.569139: train Epoch: [42][ 62/129]	Time  2.729 ( 1.879)	Data  1.768 ( 0.923)	Loss 7.8548e-02 (8.7530e-02) 
2023-05-25 23:26:31.519756: train Epoch: [42][ 63/129]	Time  0.951 ( 1.865)	Data  0.001 ( 0.908)	Loss 1.7992e-01 (8.8974e-02) 
2023-05-25 23:26:34.396961: train Epoch: [42][ 64/129]	Time  2.877 ( 1.880)	Data  1.916 ( 0.924)	Loss 7.7580e-02 (8.8798e-02) 
2023-05-25 23:26:35.347144: train Epoch: [42][ 65/129]	Time  0.950 ( 1.866)	Data  0.001 ( 0.910)	Loss 5.0963e-02 (8.8225e-02) 
2023-05-25 23:26:38.121143: train Epoch: [42][ 66/129]	Time  2.774 ( 1.880)	Data  1.827 ( 0.924)	Loss 8.6376e-02 (8.8197e-02) 
2023-05-25 23:26:39.071246: train Epoch: [42][ 67/129]	Time  0.950 ( 1.866)	Data  0.001 ( 0.910)	Loss 9.0034e-02 (8.8224e-02) 
2023-05-25 23:26:41.818277: train Epoch: [42][ 68/129]	Time  2.747 ( 1.879)	Data  1.801 ( 0.923)	Loss 6.9264e-02 (8.7950e-02) 
2023-05-25 23:26:42.767753: train Epoch: [42][ 69/129]	Time  0.949 ( 1.866)	Data  0.001 ( 0.910)	Loss 4.4750e-02 (8.7332e-02) 
2023-05-25 23:26:45.470091: train Epoch: [42][ 70/129]	Time  2.702 ( 1.877)	Data  1.756 ( 0.922)	Loss 6.5719e-02 (8.7028e-02) 
2023-05-25 23:26:46.428554: train Epoch: [42][ 71/129]	Time  0.958 ( 1.865)	Data  0.001 ( 0.909)	Loss 8.1872e-02 (8.6956e-02) 
2023-05-25 23:26:49.140783: train Epoch: [42][ 72/129]	Time  2.712 ( 1.876)	Data  1.765 ( 0.921)	Loss 1.0418e-01 (8.7192e-02) 
2023-05-25 23:26:50.089598: train Epoch: [42][ 73/129]	Time  0.949 ( 1.864)	Data  0.001 ( 0.908)	Loss 7.0781e-02 (8.6971e-02) 
2023-05-25 23:26:52.739177: train Epoch: [42][ 74/129]	Time  2.650 ( 1.874)	Data  1.704 ( 0.919)	Loss 1.3955e-01 (8.7672e-02) 
2023-05-25 23:26:53.689072: train Epoch: [42][ 75/129]	Time  0.950 ( 1.862)	Data  0.001 ( 0.907)	Loss 4.4366e-02 (8.7102e-02) 
2023-05-25 23:26:56.292577: train Epoch: [42][ 76/129]	Time  2.604 ( 1.872)	Data  1.657 ( 0.917)	Loss 5.7487e-02 (8.6717e-02) 
2023-05-25 23:26:57.244109: train Epoch: [42][ 77/129]	Time  0.952 ( 1.860)	Data  0.001 ( 0.905)	Loss 5.7637e-02 (8.6344e-02) 
2023-05-25 23:26:59.863338: train Epoch: [42][ 78/129]	Time  2.619 ( 1.869)	Data  1.672 ( 0.914)	Loss 1.1097e-01 (8.6656e-02) 
2023-05-25 23:27:00.811965: train Epoch: [42][ 79/129]	Time  0.949 ( 1.858)	Data  0.001 ( 0.903)	Loss 5.3648e-02 (8.6244e-02) 
2023-05-25 23:27:03.410558: train Epoch: [42][ 80/129]	Time  2.599 ( 1.867)	Data  1.651 ( 0.912)	Loss 1.0341e-01 (8.6455e-02) 
2023-05-25 23:27:04.360518: train Epoch: [42][ 81/129]	Time  0.950 ( 1.856)	Data  0.001 ( 0.901)	Loss 1.2018e-01 (8.6867e-02) 
2023-05-25 23:27:07.052588: train Epoch: [42][ 82/129]	Time  2.692 ( 1.866)	Data  1.747 ( 0.911)	Loss 6.8254e-02 (8.6642e-02) 
2023-05-25 23:27:08.001428: train Epoch: [42][ 83/129]	Time  0.949 ( 1.855)	Data  0.001 ( 0.901)	Loss 6.1129e-02 (8.6339e-02) 
2023-05-25 23:27:10.625813: train Epoch: [42][ 84/129]	Time  2.624 ( 1.864)	Data  1.680 ( 0.910)	Loss 9.1094e-02 (8.6395e-02) 
2023-05-25 23:27:11.576487: train Epoch: [42][ 85/129]	Time  0.951 ( 1.853)	Data  0.001 ( 0.899)	Loss 4.6742e-02 (8.5934e-02) 
2023-05-25 23:27:14.315907: train Epoch: [42][ 86/129]	Time  2.739 ( 1.864)	Data  1.795 ( 0.909)	Loss 6.2163e-02 (8.5660e-02) 
2023-05-25 23:27:15.265125: train Epoch: [42][ 87/129]	Time  0.949 ( 1.853)	Data  0.001 ( 0.899)	Loss 8.8352e-02 (8.5691e-02) 
2023-05-25 23:27:17.906655: train Epoch: [42][ 88/129]	Time  2.642 ( 1.862)	Data  1.696 ( 0.908)	Loss 1.0401e-01 (8.5897e-02) 
2023-05-25 23:27:18.856129: train Epoch: [42][ 89/129]	Time  0.949 ( 1.852)	Data  0.001 ( 0.898)	Loss 9.0319e-02 (8.5946e-02) 
2023-05-25 23:27:21.513167: train Epoch: [42][ 90/129]	Time  2.657 ( 1.861)	Data  1.712 ( 0.907)	Loss 9.6808e-02 (8.6065e-02) 
2023-05-25 23:27:22.462996: train Epoch: [42][ 91/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.897)	Loss 6.8316e-02 (8.5872e-02) 
2023-05-25 23:27:25.055018: train Epoch: [42][ 92/129]	Time  2.592 ( 1.859)	Data  1.647 ( 0.905)	Loss 6.7342e-02 (8.5673e-02) 
2023-05-25 23:27:26.004225: train Epoch: [42][ 93/129]	Time  0.949 ( 1.849)	Data  0.001 ( 0.896)	Loss 9.4531e-02 (8.5767e-02) 
2023-05-25 23:27:28.780877: train Epoch: [42][ 94/129]	Time  2.777 ( 1.859)	Data  1.831 ( 0.905)	Loss 7.6063e-02 (8.5665e-02) 
2023-05-25 23:27:29.730989: train Epoch: [42][ 95/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.896)	Loss 6.1141e-02 (8.5410e-02) 
2023-05-25 23:27:32.522652: train Epoch: [42][ 96/129]	Time  2.792 ( 1.859)	Data  1.846 ( 0.906)	Loss 5.7894e-02 (8.5126e-02) 
2023-05-25 23:27:33.473522: train Epoch: [42][ 97/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.897)	Loss 5.8307e-02 (8.4852e-02) 
2023-05-25 23:27:36.225849: train Epoch: [42][ 98/129]	Time  2.752 ( 1.859)	Data  1.805 ( 0.906)	Loss 1.0556e-01 (8.5062e-02) 
2023-05-25 23:27:37.177020: train Epoch: [42][ 99/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.897)	Loss 4.5238e-02 (8.4663e-02) 
2023-05-25 23:27:39.961897: train Epoch: [42][100/129]	Time  2.785 ( 1.859)	Data  1.837 ( 0.906)	Loss 7.8068e-02 (8.4598e-02) 
2023-05-25 23:27:40.912141: train Epoch: [42][101/129]	Time  0.950 ( 1.850)	Data  0.001 ( 0.897)	Loss 6.4131e-02 (8.4397e-02) 
2023-05-25 23:27:43.583261: train Epoch: [42][102/129]	Time  2.671 ( 1.858)	Data  1.723 ( 0.905)	Loss 6.2096e-02 (8.4181e-02) 
2023-05-25 23:27:44.535333: train Epoch: [42][103/129]	Time  0.952 ( 1.850)	Data  0.001 ( 0.896)	Loss 5.4276e-02 (8.3893e-02) 
2023-05-25 23:27:47.173379: train Epoch: [42][104/129]	Time  2.638 ( 1.857)	Data  1.685 ( 0.904)	Loss 1.4257e-01 (8.4452e-02) 
2023-05-25 23:27:48.125543: train Epoch: [42][105/129]	Time  0.952 ( 1.849)	Data  0.001 ( 0.895)	Loss 8.3627e-02 (8.4444e-02) 
2023-05-25 23:27:50.668010: train Epoch: [42][106/129]	Time  2.542 ( 1.855)	Data  1.592 ( 0.902)	Loss 7.6890e-02 (8.4374e-02) 
2023-05-25 23:27:51.617312: train Epoch: [42][107/129]	Time  0.949 ( 1.847)	Data  0.001 ( 0.894)	Loss 7.0617e-02 (8.4246e-02) 
2023-05-25 23:27:54.309433: train Epoch: [42][108/129]	Time  2.692 ( 1.854)	Data  1.734 ( 0.901)	Loss 3.9787e-02 (8.3839e-02) 
2023-05-25 23:27:55.259044: train Epoch: [42][109/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.893)	Loss 9.5770e-02 (8.3947e-02) 
2023-05-25 23:27:57.930029: train Epoch: [42][110/129]	Time  2.671 ( 1.854)	Data  1.716 ( 0.901)	Loss 6.9050e-02 (8.3813e-02) 
2023-05-25 23:27:58.879142: train Epoch: [42][111/129]	Time  0.949 ( 1.846)	Data  0.001 ( 0.892)	Loss 1.2640e-01 (8.4193e-02) 
2023-05-25 23:28:01.515656: train Epoch: [42][112/129]	Time  2.637 ( 1.853)	Data  1.690 ( 0.900)	Loss 1.2482e-01 (8.4553e-02) 
2023-05-25 23:28:02.466597: train Epoch: [42][113/129]	Time  0.951 ( 1.845)	Data  0.001 ( 0.892)	Loss 9.6654e-02 (8.4659e-02) 
2023-05-25 23:28:05.208706: train Epoch: [42][114/129]	Time  2.742 ( 1.852)	Data  1.781 ( 0.899)	Loss 9.5739e-02 (8.4755e-02) 
2023-05-25 23:28:06.159175: train Epoch: [42][115/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.892)	Loss 5.8223e-02 (8.4526e-02) 
2023-05-25 23:28:08.718727: train Epoch: [42][116/129]	Time  2.560 ( 1.851)	Data  1.612 ( 0.898)	Loss 7.7045e-02 (8.4462e-02) 
2023-05-25 23:28:09.668507: train Epoch: [42][117/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.890)	Loss 5.1925e-02 (8.4187e-02) 
2023-05-25 23:28:12.317654: train Epoch: [42][118/129]	Time  2.649 ( 1.850)	Data  1.700 ( 0.897)	Loss 4.8172e-02 (8.3884e-02) 
2023-05-25 23:28:13.267690: train Epoch: [42][119/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.890)	Loss 1.0422e-01 (8.4053e-02) 
2023-05-25 23:28:15.986480: train Epoch: [42][120/129]	Time  2.719 ( 1.850)	Data  1.761 ( 0.897)	Loss 1.1629e-01 (8.4320e-02) 
2023-05-25 23:28:16.936718: train Epoch: [42][121/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.889)	Loss 8.6158e-02 (8.4335e-02) 
2023-05-25 23:28:19.651549: train Epoch: [42][122/129]	Time  2.715 ( 1.849)	Data  1.766 ( 0.897)	Loss 1.1946e-01 (8.4621e-02) 
2023-05-25 23:28:20.601361: train Epoch: [42][123/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.889)	Loss 7.5589e-02 (8.4548e-02) 
2023-05-25 23:28:23.270703: train Epoch: [42][124/129]	Time  2.669 ( 1.849)	Data  1.716 ( 0.896)	Loss 9.2317e-02 (8.4610e-02) 
2023-05-25 23:28:24.221525: train Epoch: [42][125/129]	Time  0.951 ( 1.842)	Data  0.001 ( 0.889)	Loss 8.9550e-02 (8.4649e-02) 
2023-05-25 23:28:26.898586: train Epoch: [42][126/129]	Time  2.677 ( 1.848)	Data  1.732 ( 0.895)	Loss 8.2101e-02 (8.4629e-02) 
2023-05-25 23:28:27.843742: train Epoch: [42][127/129]	Time  0.945 ( 1.841)	Data  0.001 ( 0.888)	Loss 1.3694e-01 (8.5038e-02) 
2023-05-25 23:28:29.365695: train Epoch: [42][128/129]	Time  1.522 ( 1.839)	Data  0.577 ( 0.886)	Loss 1.0752e-01 (8.5212e-02) 
2023-05-25 23:28:29.396640: Train Epoch done in 237.2167685289969 s 
2023-05-25 23:28:31.722285: val Epoch: [42][ 0/72]	Time  1.585 ( 1.585)	Data  1.383 ( 1.383)	Loss 1.0288e-01 (1.0288e-01) 
2023-05-25 23:28:31.841785: val Epoch: [42][ 1/72]	Time  0.120 ( 0.853)	Data  0.001 ( 0.692)	Loss 1.3392e-01 (1.1840e-01) 
2023-05-25 23:28:32.837307: val Epoch: [42][ 2/72]	Time  0.996 ( 0.900)	Data  0.876 ( 0.753)	Loss 3.4628e-02 (9.0475e-02) 
2023-05-25 23:28:32.957829: val Epoch: [42][ 3/72]	Time  0.121 ( 0.705)	Data  0.000 ( 0.565)	Loss 4.6595e-02 (7.9505e-02) 
2023-05-25 23:28:34.097924: val Epoch: [42][ 4/72]	Time  1.140 ( 0.792)	Data  1.020 ( 0.656)	Loss 5.5156e-02 (7.4635e-02) 
2023-05-25 23:28:34.217980: val Epoch: [42][ 5/72]	Time  0.120 ( 0.680)	Data  0.001 ( 0.547)	Loss 1.5397e-01 (8.7857e-02) 
2023-05-25 23:28:35.367326: val Epoch: [42][ 6/72]	Time  1.149 ( 0.747)	Data  1.028 ( 0.616)	Loss 1.3436e-01 (9.4501e-02) 
2023-05-25 23:28:35.487301: val Epoch: [42][ 7/72]	Time  0.120 ( 0.669)	Data  0.000 ( 0.539)	Loss 1.1633e-01 (9.7229e-02) 
2023-05-25 23:28:36.603786: val Epoch: [42][ 8/72]	Time  1.116 ( 0.719)	Data  0.994 ( 0.589)	Loss 8.0932e-02 (9.5418e-02) 
2023-05-25 23:28:36.723403: val Epoch: [42][ 9/72]	Time  0.120 ( 0.659)	Data  0.001 ( 0.530)	Loss 9.5843e-02 (9.5461e-02) 
2023-05-25 23:28:37.856407: val Epoch: [42][10/72]	Time  1.133 ( 0.702)	Data  1.009 ( 0.574)	Loss 4.8903e-02 (9.1228e-02) 
2023-05-25 23:28:37.976514: val Epoch: [42][11/72]	Time  0.120 ( 0.653)	Data  0.000 ( 0.526)	Loss 2.2339e-01 (1.0224e-01) 
2023-05-25 23:28:39.117633: val Epoch: [42][12/72]	Time  1.141 ( 0.691)	Data  1.017 ( 0.564)	Loss 4.5535e-02 (9.7880e-02) 
2023-05-25 23:28:39.238010: val Epoch: [42][13/72]	Time  0.120 ( 0.650)	Data  0.000 ( 0.524)	Loss 4.0564e-01 (1.1986e-01) 
2023-05-25 23:28:40.395118: val Epoch: [42][14/72]	Time  1.157 ( 0.684)	Data  1.033 ( 0.558)	Loss 1.0217e-01 (1.1868e-01) 
2023-05-25 23:28:40.514768: val Epoch: [42][15/72]	Time  0.120 ( 0.649)	Data  0.001 ( 0.523)	Loss 1.6800e-01 (1.2177e-01) 
2023-05-25 23:28:41.626396: val Epoch: [42][16/72]	Time  1.112 ( 0.676)	Data  0.987 ( 0.550)	Loss 1.1357e-01 (1.2128e-01) 
2023-05-25 23:28:41.746843: val Epoch: [42][17/72]	Time  0.120 ( 0.645)	Data  0.000 ( 0.520)	Loss 6.2120e-02 (1.1800e-01) 
2023-05-25 23:28:42.836490: val Epoch: [42][18/72]	Time  1.090 ( 0.668)	Data  0.964 ( 0.543)	Loss 1.3521e-01 (1.1890e-01) 
2023-05-25 23:28:42.956462: val Epoch: [42][19/72]	Time  0.120 ( 0.641)	Data  0.001 ( 0.516)	Loss 5.6914e-02 (1.1580e-01) 
2023-05-25 23:28:44.146023: val Epoch: [42][20/72]	Time  1.190 ( 0.667)	Data  1.067 ( 0.542)	Loss 4.9810e-01 (1.3401e-01) 
2023-05-25 23:28:44.268126: val Epoch: [42][21/72]	Time  0.122 ( 0.642)	Data  0.000 ( 0.517)	Loss 4.8797e-02 (1.3013e-01) 
2023-05-25 23:28:45.454814: val Epoch: [42][22/72]	Time  1.187 ( 0.666)	Data  1.063 ( 0.541)	Loss 5.1074e-02 (1.2670e-01) 
2023-05-25 23:28:45.579195: val Epoch: [42][23/72]	Time  0.124 ( 0.643)	Data  0.001 ( 0.519)	Loss 9.1011e-02 (1.2521e-01) 
2023-05-25 23:28:46.747447: val Epoch: [42][24/72]	Time  1.168 ( 0.664)	Data  1.043 ( 0.540)	Loss 8.6624e-02 (1.2367e-01) 
2023-05-25 23:28:46.872341: val Epoch: [42][25/72]	Time  0.125 ( 0.644)	Data  0.001 ( 0.519)	Loss 5.7568e-02 (1.2112e-01) 
2023-05-25 23:28:48.003339: val Epoch: [42][26/72]	Time  1.131 ( 0.662)	Data  1.006 ( 0.537)	Loss 7.0137e-02 (1.1924e-01) 
2023-05-25 23:28:48.127587: val Epoch: [42][27/72]	Time  0.124 ( 0.643)	Data  0.001 ( 0.518)	Loss 1.9599e-01 (1.2198e-01) 
2023-05-25 23:28:49.237605: val Epoch: [42][28/72]	Time  1.110 ( 0.659)	Data  0.986 ( 0.534)	Loss 8.6686e-02 (1.2076e-01) 
2023-05-25 23:28:49.362379: val Epoch: [42][29/72]	Time  0.125 ( 0.641)	Data  0.001 ( 0.516)	Loss 8.4053e-02 (1.1954e-01) 
2023-05-25 23:28:50.440638: val Epoch: [42][30/72]	Time  1.078 ( 0.655)	Data  0.954 ( 0.530)	Loss 6.2709e-02 (1.1770e-01) 
2023-05-25 23:28:50.564443: val Epoch: [42][31/72]	Time  0.124 ( 0.638)	Data  0.001 ( 0.514)	Loss 4.0346e-02 (1.1529e-01) 
2023-05-25 23:28:51.643321: val Epoch: [42][32/72]	Time  1.079 ( 0.652)	Data  0.954 ( 0.527)	Loss 6.5500e-02 (1.1378e-01) 
2023-05-25 23:28:51.767755: val Epoch: [42][33/72]	Time  0.124 ( 0.636)	Data  0.001 ( 0.512)	Loss 4.7363e-02 (1.1182e-01) 
2023-05-25 23:28:52.880103: val Epoch: [42][34/72]	Time  1.112 ( 0.650)	Data  0.989 ( 0.525)	Loss 1.3778e-01 (1.1257e-01) 
2023-05-25 23:28:53.003994: val Epoch: [42][35/72]	Time  0.124 ( 0.635)	Data  0.001 ( 0.511)	Loss 3.8991e-02 (1.1052e-01) 
2023-05-25 23:28:54.092971: val Epoch: [42][36/72]	Time  1.089 ( 0.647)	Data  0.965 ( 0.523)	Loss 1.2930e-01 (1.1103e-01) 
2023-05-25 23:28:54.217681: val Epoch: [42][37/72]	Time  0.125 ( 0.634)	Data  0.001 ( 0.509)	Loss 1.1390e-01 (1.1110e-01) 
2023-05-25 23:28:55.296364: val Epoch: [42][38/72]	Time  1.079 ( 0.645)	Data  0.955 ( 0.521)	Loss 5.9417e-02 (1.0978e-01) 
2023-05-25 23:28:55.419997: val Epoch: [42][39/72]	Time  0.124 ( 0.632)	Data  0.001 ( 0.508)	Loss 3.3543e-01 (1.1542e-01) 
2023-05-25 23:28:56.479830: val Epoch: [42][40/72]	Time  1.060 ( 0.643)	Data  0.935 ( 0.518)	Loss 4.8141e-02 (1.1378e-01) 
2023-05-25 23:28:56.604191: val Epoch: [42][41/72]	Time  0.124 ( 0.630)	Data  0.001 ( 0.506)	Loss 9.0945e-02 (1.1324e-01) 
2023-05-25 23:28:57.665373: val Epoch: [42][42/72]	Time  1.061 ( 0.640)	Data  0.937 ( 0.516)	Loss 6.8355e-02 (1.1219e-01) 
2023-05-25 23:28:57.789488: val Epoch: [42][43/72]	Time  0.124 ( 0.628)	Data  0.001 ( 0.504)	Loss 4.2053e-02 (1.1060e-01) 
2023-05-25 23:28:58.897357: val Epoch: [42][44/72]	Time  1.108 ( 0.639)	Data  0.983 ( 0.515)	Loss 3.8567e-01 (1.1671e-01) 
2023-05-25 23:28:59.021662: val Epoch: [42][45/72]	Time  0.124 ( 0.628)	Data  0.000 ( 0.503)	Loss 4.0090e-01 (1.2289e-01) 
2023-05-25 23:29:00.107807: val Epoch: [42][46/72]	Time  1.086 ( 0.638)	Data  0.962 ( 0.513)	Loss 2.6850e-01 (1.2599e-01) 
2023-05-25 23:29:00.231575: val Epoch: [42][47/72]	Time  0.124 ( 0.627)	Data  0.000 ( 0.503)	Loss 2.5661e-01 (1.2871e-01) 
2023-05-25 23:29:01.336423: val Epoch: [42][48/72]	Time  1.105 ( 0.637)	Data  0.981 ( 0.512)	Loss 3.3417e-01 (1.3290e-01) 
2023-05-25 23:29:01.460634: val Epoch: [42][49/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.502)	Loss 8.8247e-02 (1.3201e-01) 
2023-05-25 23:29:02.568779: val Epoch: [42][50/72]	Time  1.108 ( 0.636)	Data  0.984 ( 0.512)	Loss 4.6035e-01 (1.3845e-01) 
2023-05-25 23:29:02.692640: val Epoch: [42][51/72]	Time  0.124 ( 0.626)	Data  0.000 ( 0.502)	Loss 3.3569e-01 (1.4224e-01) 
2023-05-25 23:29:03.838415: val Epoch: [42][52/72]	Time  1.146 ( 0.636)	Data  1.022 ( 0.512)	Loss 5.3980e-02 (1.4057e-01) 
2023-05-25 23:29:03.962992: val Epoch: [42][53/72]	Time  0.125 ( 0.626)	Data  0.001 ( 0.502)	Loss 4.4990e-02 (1.3880e-01) 
2023-05-25 23:29:05.092502: val Epoch: [42][54/72]	Time  1.130 ( 0.636)	Data  1.005 ( 0.511)	Loss 9.6608e-02 (1.3804e-01) 
2023-05-25 23:29:05.216519: val Epoch: [42][55/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.502)	Loss 4.3248e-02 (1.3634e-01) 
2023-05-25 23:29:06.357369: val Epoch: [42][56/72]	Time  1.141 ( 0.635)	Data  1.017 ( 0.511)	Loss 2.5013e-01 (1.3834e-01) 
2023-05-25 23:29:06.480941: val Epoch: [42][57/72]	Time  0.124 ( 0.627)	Data  0.001 ( 0.502)	Loss 1.0105e-01 (1.3770e-01) 
2023-05-25 23:29:07.595464: val Epoch: [42][58/72]	Time  1.115 ( 0.635)	Data  0.991 ( 0.511)	Loss 9.6622e-02 (1.3700e-01) 
2023-05-25 23:29:07.719337: val Epoch: [42][59/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.502)	Loss 1.2754e-01 (1.3684e-01) 
2023-05-25 23:29:08.873971: val Epoch: [42][60/72]	Time  1.155 ( 0.635)	Data  1.030 ( 0.511)	Loss 7.6220e-02 (1.3585e-01) 
2023-05-25 23:29:09.001471: val Epoch: [42][61/72]	Time  0.127 ( 0.627)	Data  0.001 ( 0.503)	Loss 7.5651e-02 (1.3488e-01) 
2023-05-25 23:29:10.054898: val Epoch: [42][62/72]	Time  1.053 ( 0.634)	Data  0.929 ( 0.509)	Loss 6.4539e-02 (1.3376e-01) 
2023-05-25 23:29:10.178842: val Epoch: [42][63/72]	Time  0.124 ( 0.626)	Data  0.001 ( 0.501)	Loss 2.0788e-01 (1.3492e-01) 
2023-05-25 23:29:11.293914: val Epoch: [42][64/72]	Time  1.115 ( 0.633)	Data  0.990 ( 0.509)	Loss 7.0327e-02 (1.3393e-01) 
2023-05-25 23:29:11.419629: val Epoch: [42][65/72]	Time  0.126 ( 0.625)	Data  0.001 ( 0.501)	Loss 6.2251e-02 (1.3284e-01) 
2023-05-25 23:29:12.526670: val Epoch: [42][66/72]	Time  1.107 ( 0.633)	Data  0.982 ( 0.508)	Loss 5.6853e-02 (1.3171e-01) 
2023-05-25 23:29:12.652430: val Epoch: [42][67/72]	Time  0.126 ( 0.625)	Data  0.001 ( 0.501)	Loss 3.2133e-02 (1.3024e-01) 
2023-05-25 23:29:13.768870: val Epoch: [42][68/72]	Time  1.116 ( 0.632)	Data  0.992 ( 0.508)	Loss 5.4913e-02 (1.2915e-01) 
2023-05-25 23:29:13.894985: val Epoch: [42][69/72]	Time  0.126 ( 0.625)	Data  0.000 ( 0.501)	Loss 6.9720e-02 (1.2830e-01) 
2023-05-25 23:29:14.886329: val Epoch: [42][70/72]	Time  0.991 ( 0.630)	Data  0.867 ( 0.506)	Loss 7.6292e-02 (1.2757e-01) 
2023-05-25 23:29:15.009461: val Epoch: [42][71/72]	Time  0.123 ( 0.623)	Data  0.000 ( 0.499)	Loss 3.7691e-02 (1.2632e-01) 
2023-05-25 23:29:15.204004: Epoch 42 :Val : ['ET : 0.7594649791717529', 'TC : 0.7815685272216797', 'WT : 0.8627220988273621'] 
2023-05-25 23:29:15.206748: Epoch 42 :Val : ['ET : 0.7594649791717529', 'TC : 0.7815685272216797', 'WT : 0.8627220988273621'] 
2023-05-25 23:29:15.208573: Val epoch done in 45.81194197700097 s 
2023-05-25 23:29:15.213894: Batches per epoch:  129 
2023-05-25 23:29:19.934322: train Epoch: [43][  0/129]	Time  4.720 ( 4.720)	Data  3.708 ( 3.708)	Loss 9.2926e-02 (9.2926e-02) 
2023-05-25 23:29:20.886177: train Epoch: [43][  1/129]	Time  0.952 ( 2.836)	Data  0.001 ( 1.854)	Loss 8.9928e-02 (9.1427e-02) 
2023-05-25 23:29:23.425303: train Epoch: [43][  2/129]	Time  2.539 ( 2.737)	Data  1.591 ( 1.767)	Loss 5.6260e-02 (7.9704e-02) 
2023-05-25 23:29:24.375471: train Epoch: [43][  3/129]	Time  0.950 ( 2.290)	Data  0.001 ( 1.325)	Loss 8.0940e-02 (8.0013e-02) 
2023-05-25 23:29:26.992908: train Epoch: [43][  4/129]	Time  2.617 ( 2.356)	Data  1.669 ( 1.394)	Loss 6.7828e-02 (7.7576e-02) 
2023-05-25 23:29:27.943523: train Epoch: [43][  5/129]	Time  0.951 ( 2.122)	Data  0.001 ( 1.162)	Loss 8.7053e-02 (7.9156e-02) 
2023-05-25 23:29:30.501948: train Epoch: [43][  6/129]	Time  2.558 ( 2.184)	Data  1.610 ( 1.226)	Loss 1.3942e-01 (8.7765e-02) 
2023-05-25 23:29:31.453497: train Epoch: [43][  7/129]	Time  0.952 ( 2.030)	Data  0.001 ( 1.073)	Loss 8.2247e-02 (8.7075e-02) 
2023-05-25 23:29:34.046888: train Epoch: [43][  8/129]	Time  2.593 ( 2.093)	Data  1.634 ( 1.135)	Loss 4.3529e-02 (8.2237e-02) 
2023-05-25 23:29:34.997491: train Epoch: [43][  9/129]	Time  0.951 ( 1.978)	Data  0.001 ( 1.022)	Loss 5.2158e-02 (7.9229e-02) 
2023-05-25 23:29:37.721961: train Epoch: [43][ 10/129]	Time  2.724 ( 2.046)	Data  1.777 ( 1.090)	Loss 5.7738e-02 (7.7275e-02) 
2023-05-25 23:29:38.673250: train Epoch: [43][ 11/129]	Time  0.951 ( 1.955)	Data  0.001 ( 1.000)	Loss 5.2916e-02 (7.5245e-02) 
2023-05-25 23:29:41.305649: train Epoch: [43][ 12/129]	Time  2.632 ( 2.007)	Data  1.674 ( 1.051)	Loss 5.8578e-02 (7.3963e-02) 
2023-05-25 23:29:42.256199: train Epoch: [43][ 13/129]	Time  0.951 ( 1.932)	Data  0.001 ( 0.976)	Loss 6.0108e-02 (7.2973e-02) 
2023-05-25 23:29:44.862558: train Epoch: [43][ 14/129]	Time  2.606 ( 1.977)	Data  1.647 ( 1.021)	Loss 5.4243e-02 (7.1725e-02) 
2023-05-25 23:29:45.821961: train Epoch: [43][ 15/129]	Time  0.959 ( 1.913)	Data  0.001 ( 0.957)	Loss 9.2363e-02 (7.3015e-02) 
2023-05-25 23:29:48.469426: train Epoch: [43][ 16/129]	Time  2.647 ( 1.956)	Data  1.690 ( 1.000)	Loss 8.9398e-02 (7.3978e-02) 
2023-05-25 23:29:49.421467: train Epoch: [43][ 17/129]	Time  0.952 ( 1.900)	Data  0.001 ( 0.945)	Loss 6.8120e-02 (7.3653e-02) 
2023-05-25 23:29:51.989916: train Epoch: [43][ 18/129]	Time  2.568 ( 1.936)	Data  1.618 ( 0.980)	Loss 1.5368e-01 (7.7865e-02) 
2023-05-25 23:29:52.943398: train Epoch: [43][ 19/129]	Time  0.953 ( 1.886)	Data  0.001 ( 0.931)	Loss 1.5158e-01 (8.1551e-02) 
2023-05-25 23:29:55.645719: train Epoch: [43][ 20/129]	Time  2.702 ( 1.925)	Data  1.751 ( 0.970)	Loss 4.0075e-02 (7.9576e-02) 
2023-05-25 23:29:56.597450: train Epoch: [43][ 21/129]	Time  0.952 ( 1.881)	Data  0.001 ( 0.926)	Loss 1.2714e-01 (8.1738e-02) 
2023-05-25 23:29:59.289975: train Epoch: [43][ 22/129]	Time  2.693 ( 1.916)	Data  1.743 ( 0.962)	Loss 9.1741e-02 (8.2173e-02) 
2023-05-25 23:30:00.240019: train Epoch: [43][ 23/129]	Time  0.950 ( 1.876)	Data  0.001 ( 0.922)	Loss 6.8162e-02 (8.1589e-02) 
2023-05-25 23:30:03.002272: train Epoch: [43][ 24/129]	Time  2.762 ( 1.912)	Data  1.815 ( 0.958)	Loss 1.1366e-01 (8.2872e-02) 
2023-05-25 23:30:03.951600: train Epoch: [43][ 25/129]	Time  0.949 ( 1.875)	Data  0.001 ( 0.921)	Loss 7.9109e-02 (8.2727e-02) 
2023-05-25 23:30:06.669641: train Epoch: [43][ 26/129]	Time  2.718 ( 1.906)	Data  1.764 ( 0.952)	Loss 9.7783e-02 (8.3285e-02) 
2023-05-25 23:30:07.620448: train Epoch: [43][ 27/129]	Time  0.951 ( 1.872)	Data  0.001 ( 0.918)	Loss 7.2696e-02 (8.2907e-02) 
2023-05-25 23:30:10.338812: train Epoch: [43][ 28/129]	Time  2.718 ( 1.901)	Data  1.760 ( 0.947)	Loss 1.0879e-01 (8.3799e-02) 
2023-05-25 23:30:11.289010: train Epoch: [43][ 29/129]	Time  0.950 ( 1.869)	Data  0.001 ( 0.915)	Loss 9.9714e-02 (8.4330e-02) 
2023-05-25 23:30:14.128407: train Epoch: [43][ 30/129]	Time  2.839 ( 1.900)	Data  1.895 ( 0.947)	Loss 8.1608e-02 (8.4242e-02) 
2023-05-25 23:30:15.077796: train Epoch: [43][ 31/129]	Time  0.949 ( 1.871)	Data  0.001 ( 0.917)	Loss 5.6350e-02 (8.3370e-02) 
2023-05-25 23:30:17.814983: train Epoch: [43][ 32/129]	Time  2.737 ( 1.897)	Data  1.782 ( 0.944)	Loss 9.9267e-02 (8.3852e-02) 
2023-05-25 23:30:18.765912: train Epoch: [43][ 33/129]	Time  0.951 ( 1.869)	Data  0.001 ( 0.916)	Loss 8.6243e-02 (8.3922e-02) 
2023-05-25 23:30:21.448425: train Epoch: [43][ 34/129]	Time  2.683 ( 1.892)	Data  1.736 ( 0.939)	Loss 1.0480e-01 (8.4519e-02) 
2023-05-25 23:30:22.399255: train Epoch: [43][ 35/129]	Time  0.951 ( 1.866)	Data  0.001 ( 0.913)	Loss 1.1617e-01 (8.5398e-02) 
2023-05-25 23:30:25.237641: train Epoch: [43][ 36/129]	Time  2.838 ( 1.893)	Data  1.873 ( 0.939)	Loss 7.4327e-02 (8.5099e-02) 
2023-05-25 23:30:26.197148: train Epoch: [43][ 37/129]	Time  0.959 ( 1.868)	Data  0.001 ( 0.915)	Loss 1.1538e-01 (8.5896e-02) 
2023-05-25 23:30:28.963024: train Epoch: [43][ 38/129]	Time  2.766 ( 1.891)	Data  1.820 ( 0.938)	Loss 6.7744e-02 (8.5430e-02) 
2023-05-25 23:30:29.918070: train Epoch: [43][ 39/129]	Time  0.955 ( 1.868)	Data  0.001 ( 0.914)	Loss 7.8557e-02 (8.5258e-02) 
2023-05-25 23:30:32.709459: train Epoch: [43][ 40/129]	Time  2.791 ( 1.890)	Data  1.833 ( 0.937)	Loss 5.0269e-02 (8.4405e-02) 
2023-05-25 23:30:33.669614: train Epoch: [43][ 41/129]	Time  0.960 ( 1.868)	Data  0.001 ( 0.914)	Loss 5.6603e-02 (8.3743e-02) 
2023-05-25 23:30:36.461258: train Epoch: [43][ 42/129]	Time  2.792 ( 1.889)	Data  1.836 ( 0.936)	Loss 8.0806e-02 (8.3675e-02) 
2023-05-25 23:30:37.420772: train Epoch: [43][ 43/129]	Time  0.960 ( 1.868)	Data  0.001 ( 0.915)	Loss 8.4018e-02 (8.3683e-02) 
2023-05-25 23:30:40.033501: train Epoch: [43][ 44/129]	Time  2.613 ( 1.885)	Data  1.655 ( 0.931)	Loss 4.7406e-02 (8.2876e-02) 
2023-05-25 23:30:40.983361: train Epoch: [43][ 45/129]	Time  0.950 ( 1.865)	Data  0.001 ( 0.911)	Loss 6.1719e-02 (8.2416e-02) 
2023-05-25 23:30:43.684643: train Epoch: [43][ 46/129]	Time  2.701 ( 1.882)	Data  1.755 ( 0.929)	Loss 7.0270e-02 (8.2158e-02) 
2023-05-25 23:30:44.634533: train Epoch: [43][ 47/129]	Time  0.950 ( 1.863)	Data  0.001 ( 0.910)	Loss 5.7420e-02 (8.1643e-02) 
2023-05-25 23:30:47.412905: train Epoch: [43][ 48/129]	Time  2.778 ( 1.882)	Data  1.832 ( 0.928)	Loss 5.7875e-02 (8.1158e-02) 
2023-05-25 23:30:48.365110: train Epoch: [43][ 49/129]	Time  0.952 ( 1.863)	Data  0.001 ( 0.910)	Loss 9.7404e-02 (8.1483e-02) 
2023-05-25 23:30:51.147173: train Epoch: [43][ 50/129]	Time  2.782 ( 1.881)	Data  1.823 ( 0.928)	Loss 1.1030e-01 (8.2048e-02) 
2023-05-25 23:30:52.108570: train Epoch: [43][ 51/129]	Time  0.961 ( 1.863)	Data  0.001 ( 0.910)	Loss 7.2489e-02 (8.1864e-02) 
2023-05-25 23:30:54.885111: train Epoch: [43][ 52/129]	Time  2.777 ( 1.881)	Data  1.819 ( 0.927)	Loss 9.4956e-02 (8.2111e-02) 
2023-05-25 23:30:55.847199: train Epoch: [43][ 53/129]	Time  0.962 ( 1.864)	Data  0.001 ( 0.910)	Loss 6.4593e-02 (8.1786e-02) 
2023-05-25 23:30:58.607010: train Epoch: [43][ 54/129]	Time  2.760 ( 1.880)	Data  1.805 ( 0.926)	Loss 8.5509e-02 (8.1854e-02) 
2023-05-25 23:30:59.567264: train Epoch: [43][ 55/129]	Time  0.960 ( 1.863)	Data  0.001 ( 0.910)	Loss 9.5123e-02 (8.2091e-02) 
2023-05-25 23:31:02.217518: train Epoch: [43][ 56/129]	Time  2.650 ( 1.877)	Data  1.694 ( 0.923)	Loss 6.2756e-02 (8.1752e-02) 
2023-05-25 23:31:03.176770: train Epoch: [43][ 57/129]	Time  0.959 ( 1.861)	Data  0.001 ( 0.907)	Loss 9.2772e-02 (8.1942e-02) 
2023-05-25 23:31:05.817342: train Epoch: [43][ 58/129]	Time  2.641 ( 1.875)	Data  1.684 ( 0.921)	Loss 5.7984e-02 (8.1536e-02) 
2023-05-25 23:31:06.779262: train Epoch: [43][ 59/129]	Time  0.962 ( 1.859)	Data  0.001 ( 0.905)	Loss 6.9686e-02 (8.1338e-02) 
2023-05-25 23:31:09.525909: train Epoch: [43][ 60/129]	Time  2.747 ( 1.874)	Data  1.792 ( 0.920)	Loss 6.8895e-02 (8.1134e-02) 
2023-05-25 23:31:10.484854: train Epoch: [43][ 61/129]	Time  0.959 ( 1.859)	Data  0.001 ( 0.905)	Loss 7.8625e-02 (8.1094e-02) 
2023-05-25 23:31:13.108719: train Epoch: [43][ 62/129]	Time  2.624 ( 1.871)	Data  1.665 ( 0.917)	Loss 7.4852e-02 (8.0995e-02) 
2023-05-25 23:31:14.070524: train Epoch: [43][ 63/129]	Time  0.962 ( 1.857)	Data  0.001 ( 0.903)	Loss 4.2812e-02 (8.0398e-02) 
2023-05-25 23:31:16.773417: train Epoch: [43][ 64/129]	Time  2.703 ( 1.870)	Data  1.743 ( 0.916)	Loss 6.8115e-02 (8.0209e-02) 
2023-05-25 23:31:17.723929: train Epoch: [43][ 65/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.902)	Loss 6.9178e-02 (8.0042e-02) 
2023-05-25 23:31:20.450166: train Epoch: [43][ 66/129]	Time  2.726 ( 1.869)	Data  1.779 ( 0.915)	Loss 8.7734e-02 (8.0157e-02) 
2023-05-25 23:31:21.401649: train Epoch: [43][ 67/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.901)	Loss 4.6842e-02 (7.9667e-02) 
2023-05-25 23:31:24.256711: train Epoch: [43][ 68/129]	Time  2.855 ( 1.870)	Data  1.894 ( 0.916)	Loss 9.0107e-02 (7.9818e-02) 
2023-05-25 23:31:25.218637: train Epoch: [43][ 69/129]	Time  0.962 ( 1.857)	Data  0.001 ( 0.903)	Loss 6.6129e-02 (7.9623e-02) 
2023-05-25 23:31:27.925681: train Epoch: [43][ 70/129]	Time  2.707 ( 1.869)	Data  1.749 ( 0.915)	Loss 1.1930e-01 (8.0182e-02) 
2023-05-25 23:31:28.887376: train Epoch: [43][ 71/129]	Time  0.962 ( 1.857)	Data  0.001 ( 0.902)	Loss 8.8935e-02 (8.0303e-02) 
2023-05-25 23:31:31.562363: train Epoch: [43][ 72/129]	Time  2.675 ( 1.868)	Data  1.706 ( 0.913)	Loss 7.8226e-02 (8.0275e-02) 
2023-05-25 23:31:32.523513: train Epoch: [43][ 73/129]	Time  0.961 ( 1.856)	Data  0.001 ( 0.901)	Loss 6.4379e-02 (8.0060e-02) 
2023-05-25 23:31:35.084730: train Epoch: [43][ 74/129]	Time  2.561 ( 1.865)	Data  1.593 ( 0.910)	Loss 5.5512e-02 (7.9733e-02) 
2023-05-25 23:31:36.045980: train Epoch: [43][ 75/129]	Time  0.961 ( 1.853)	Data  0.001 ( 0.898)	Loss 1.1705e-01 (8.0224e-02) 
2023-05-25 23:31:38.727329: train Epoch: [43][ 76/129]	Time  2.681 ( 1.864)	Data  1.722 ( 0.909)	Loss 8.3617e-02 (8.0268e-02) 
2023-05-25 23:31:39.687564: train Epoch: [43][ 77/129]	Time  0.960 ( 1.852)	Data  0.001 ( 0.897)	Loss 3.2852e-01 (8.3450e-02) 
2023-05-25 23:31:42.319863: train Epoch: [43][ 78/129]	Time  2.632 ( 1.862)	Data  1.667 ( 0.907)	Loss 7.3672e-02 (8.3327e-02) 
2023-05-25 23:31:43.281170: train Epoch: [43][ 79/129]	Time  0.961 ( 1.851)	Data  0.001 ( 0.895)	Loss 9.5943e-02 (8.3484e-02) 
2023-05-25 23:31:45.907013: train Epoch: [43][ 80/129]	Time  2.626 ( 1.860)	Data  1.657 ( 0.905)	Loss 8.7697e-02 (8.3536e-02) 
2023-05-25 23:31:46.867094: train Epoch: [43][ 81/129]	Time  0.960 ( 1.849)	Data  0.001 ( 0.894)	Loss 3.1996e-02 (8.2908e-02) 
2023-05-25 23:31:49.471998: train Epoch: [43][ 82/129]	Time  2.605 ( 1.859)	Data  1.645 ( 0.903)	Loss 1.0514e-01 (8.3176e-02) 
2023-05-25 23:31:50.432707: train Epoch: [43][ 83/129]	Time  0.961 ( 1.848)	Data  0.001 ( 0.892)	Loss 7.8289e-02 (8.3118e-02) 
2023-05-25 23:31:52.938232: train Epoch: [43][ 84/129]	Time  2.506 ( 1.856)	Data  1.544 ( 0.900)	Loss 6.5515e-02 (8.2911e-02) 
2023-05-25 23:31:53.901519: train Epoch: [43][ 85/129]	Time  0.963 ( 1.845)	Data  0.001 ( 0.889)	Loss 6.4141e-02 (8.2692e-02) 
2023-05-25 23:31:56.629009: train Epoch: [43][ 86/129]	Time  2.727 ( 1.855)	Data  1.768 ( 0.899)	Loss 7.8799e-02 (8.2648e-02) 
2023-05-25 23:31:57.591913: train Epoch: [43][ 87/129]	Time  0.963 ( 1.845)	Data  0.001 ( 0.889)	Loss 8.8273e-02 (8.2711e-02) 
2023-05-25 23:32:00.261669: train Epoch: [43][ 88/129]	Time  2.670 ( 1.854)	Data  1.714 ( 0.899)	Loss 5.4751e-02 (8.2397e-02) 
2023-05-25 23:32:01.211705: train Epoch: [43][ 89/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.889)	Loss 9.1900e-02 (8.2503e-02) 
2023-05-25 23:32:03.900728: train Epoch: [43][ 90/129]	Time  2.689 ( 1.854)	Data  1.739 ( 0.898)	Loss 4.2992e-02 (8.2069e-02) 
2023-05-25 23:32:04.852789: train Epoch: [43][ 91/129]	Time  0.952 ( 1.844)	Data  0.001 ( 0.888)	Loss 9.7249e-02 (8.2234e-02) 
2023-05-25 23:32:07.450782: train Epoch: [43][ 92/129]	Time  2.598 ( 1.852)	Data  1.650 ( 0.896)	Loss 6.9609e-02 (8.2098e-02) 
2023-05-25 23:32:08.400552: train Epoch: [43][ 93/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.887)	Loss 7.2631e-02 (8.1997e-02) 
2023-05-25 23:32:11.143641: train Epoch: [43][ 94/129]	Time  2.743 ( 1.852)	Data  1.783 ( 0.896)	Loss 7.4997e-02 (8.1924e-02) 
2023-05-25 23:32:12.093494: train Epoch: [43][ 95/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.887)	Loss 9.7897e-02 (8.2090e-02) 
2023-05-25 23:32:14.639748: train Epoch: [43][ 96/129]	Time  2.546 ( 1.850)	Data  1.595 ( 0.894)	Loss 6.7230e-02 (8.1937e-02) 
2023-05-25 23:32:15.590494: train Epoch: [43][ 97/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.885)	Loss 6.2914e-02 (8.1743e-02) 
2023-05-25 23:32:18.185264: train Epoch: [43][ 98/129]	Time  2.595 ( 1.848)	Data  1.644 ( 0.893)	Loss 4.4250e-02 (8.1364e-02) 
2023-05-25 23:32:19.137885: train Epoch: [43][ 99/129]	Time  0.953 ( 1.839)	Data  0.001 ( 0.884)	Loss 1.1120e-01 (8.1662e-02) 
2023-05-25 23:32:21.851476: train Epoch: [43][100/129]	Time  2.714 ( 1.848)	Data  1.766 ( 0.893)	Loss 1.1203e-01 (8.1963e-02) 
2023-05-25 23:32:22.812541: train Epoch: [43][101/129]	Time  0.961 ( 1.839)	Data  0.001 ( 0.884)	Loss 7.1513e-02 (8.1860e-02) 
2023-05-25 23:32:25.353892: train Epoch: [43][102/129]	Time  2.541 ( 1.846)	Data  1.580 ( 0.891)	Loss 1.1727e-01 (8.2204e-02) 
2023-05-25 23:32:26.313914: train Epoch: [43][103/129]	Time  0.960 ( 1.837)	Data  0.001 ( 0.882)	Loss 5.4945e-02 (8.1942e-02) 
2023-05-25 23:32:28.866935: train Epoch: [43][104/129]	Time  2.553 ( 1.844)	Data  1.593 ( 0.889)	Loss 8.1391e-02 (8.1937e-02) 
2023-05-25 23:32:29.828439: train Epoch: [43][105/129]	Time  0.962 ( 1.836)	Data  0.001 ( 0.880)	Loss 5.8862e-02 (8.1719e-02) 
2023-05-25 23:32:32.393682: train Epoch: [43][106/129]	Time  2.565 ( 1.843)	Data  1.607 ( 0.887)	Loss 8.4515e-02 (8.1745e-02) 
2023-05-25 23:32:33.354324: train Epoch: [43][107/129]	Time  0.961 ( 1.835)	Data  0.001 ( 0.879)	Loss 1.0826e-01 (8.1991e-02) 
2023-05-25 23:32:35.963635: train Epoch: [43][108/129]	Time  2.609 ( 1.842)	Data  1.650 ( 0.886)	Loss 7.4792e-02 (8.1925e-02) 
2023-05-25 23:32:36.925429: train Epoch: [43][109/129]	Time  0.962 ( 1.834)	Data  0.001 ( 0.878)	Loss 6.4940e-02 (8.1770e-02) 
2023-05-25 23:32:39.635216: train Epoch: [43][110/129]	Time  2.710 ( 1.842)	Data  1.750 ( 0.886)	Loss 5.8477e-02 (8.1560e-02) 
2023-05-25 23:32:40.595420: train Epoch: [43][111/129]	Time  0.960 ( 1.834)	Data  0.001 ( 0.878)	Loss 8.0362e-02 (8.1550e-02) 
2023-05-25 23:32:43.252140: train Epoch: [43][112/129]	Time  2.657 ( 1.841)	Data  1.693 ( 0.885)	Loss 6.8753e-02 (8.1437e-02) 
2023-05-25 23:32:44.214769: train Epoch: [43][113/129]	Time  0.963 ( 1.833)	Data  0.001 ( 0.877)	Loss 7.4237e-02 (8.1373e-02) 
2023-05-25 23:32:46.782547: train Epoch: [43][114/129]	Time  2.568 ( 1.840)	Data  1.618 ( 0.884)	Loss 6.7811e-02 (8.1255e-02) 
2023-05-25 23:32:47.731472: train Epoch: [43][115/129]	Time  0.949 ( 1.832)	Data  0.001 ( 0.876)	Loss 5.6657e-02 (8.1043e-02) 
2023-05-25 23:32:50.469099: train Epoch: [43][116/129]	Time  2.738 ( 1.840)	Data  1.789 ( 0.884)	Loss 1.1889e-01 (8.1367e-02) 
2023-05-25 23:32:51.419767: train Epoch: [43][117/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.877)	Loss 5.7764e-02 (8.1167e-02) 
2023-05-25 23:32:54.097714: train Epoch: [43][118/129]	Time  2.678 ( 1.839)	Data  1.732 ( 0.884)	Loss 8.2772e-02 (8.1180e-02) 
2023-05-25 23:32:55.050987: train Epoch: [43][119/129]	Time  0.953 ( 1.832)	Data  0.001 ( 0.876)	Loss 1.5201e-01 (8.1771e-02) 
2023-05-25 23:32:57.744970: train Epoch: [43][120/129]	Time  2.694 ( 1.839)	Data  1.742 ( 0.884)	Loss 5.1268e-02 (8.1518e-02) 
2023-05-25 23:32:58.704650: train Epoch: [43][121/129]	Time  0.960 ( 1.832)	Data  0.001 ( 0.876)	Loss 5.2620e-02 (8.1282e-02) 
2023-05-25 23:33:01.399046: train Epoch: [43][122/129]	Time  2.694 ( 1.839)	Data  1.736 ( 0.883)	Loss 8.1826e-02 (8.1286e-02) 
2023-05-25 23:33:02.349787: train Epoch: [43][123/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.876)	Loss 9.2463e-02 (8.1376e-02) 
2023-05-25 23:33:05.035908: train Epoch: [43][124/129]	Time  2.686 ( 1.839)	Data  1.739 ( 0.883)	Loss 4.7336e-02 (8.1104e-02) 
2023-05-25 23:33:05.984328: train Epoch: [43][125/129]	Time  0.948 ( 1.832)	Data  0.001 ( 0.876)	Loss 1.0084e-01 (8.1260e-02) 
2023-05-25 23:33:08.611083: train Epoch: [43][126/129]	Time  2.627 ( 1.838)	Data  1.680 ( 0.882)	Loss 7.8359e-02 (8.1238e-02) 
2023-05-25 23:33:09.558780: train Epoch: [43][127/129]	Time  0.948 ( 1.831)	Data  0.001 ( 0.876)	Loss 5.8205e-02 (8.1058e-02) 
2023-05-25 23:33:11.230111: train Epoch: [43][128/129]	Time  1.671 ( 1.830)	Data  0.727 ( 0.874)	Loss 8.8893e-02 (8.1118e-02) 
2023-05-25 23:33:11.272401: Train Epoch done in 236.0585301639985 s 
2023-05-25 23:33:13.516345: val Epoch: [43][ 0/72]	Time  1.525 ( 1.525)	Data  1.344 ( 1.344)	Loss 6.6379e-02 (6.6379e-02) 
2023-05-25 23:33:13.636306: val Epoch: [43][ 1/72]	Time  0.120 ( 0.823)	Data  0.001 ( 0.672)	Loss 8.1416e-02 (7.3897e-02) 
2023-05-25 23:33:14.632639: val Epoch: [43][ 2/72]	Time  0.996 ( 0.881)	Data  0.871 ( 0.739)	Loss 5.9543e-02 (6.9113e-02) 
2023-05-25 23:33:14.752418: val Epoch: [43][ 3/72]	Time  0.120 ( 0.690)	Data  0.000 ( 0.554)	Loss 4.1851e-02 (6.2297e-02) 
2023-05-25 23:33:15.856962: val Epoch: [43][ 4/72]	Time  1.105 ( 0.773)	Data  0.979 ( 0.639)	Loss 8.4185e-02 (6.6675e-02) 
2023-05-25 23:33:15.977241: val Epoch: [43][ 5/72]	Time  0.120 ( 0.664)	Data  0.000 ( 0.533)	Loss 9.3406e-02 (7.1130e-02) 
2023-05-25 23:33:17.135505: val Epoch: [43][ 6/72]	Time  1.158 ( 0.735)	Data  1.035 ( 0.604)	Loss 6.7013e-02 (7.0542e-02) 
2023-05-25 23:33:17.256014: val Epoch: [43][ 7/72]	Time  0.121 ( 0.658)	Data  0.000 ( 0.529)	Loss 8.9420e-02 (7.2902e-02) 
2023-05-25 23:33:18.409231: val Epoch: [43][ 8/72]	Time  1.153 ( 0.713)	Data  1.028 ( 0.584)	Loss 1.1987e-01 (7.8120e-02) 
2023-05-25 23:33:18.528915: val Epoch: [43][ 9/72]	Time  0.120 ( 0.654)	Data  0.000 ( 0.526)	Loss 8.5306e-02 (7.8839e-02) 
2023-05-25 23:33:19.672464: val Epoch: [43][10/72]	Time  1.144 ( 0.698)	Data  1.018 ( 0.571)	Loss 4.6759e-02 (7.5922e-02) 
2023-05-25 23:33:19.792841: val Epoch: [43][11/72]	Time  0.120 ( 0.650)	Data  0.000 ( 0.523)	Loss 2.2121e-01 (8.8030e-02) 
2023-05-25 23:33:20.912820: val Epoch: [43][12/72]	Time  1.120 ( 0.686)	Data  0.997 ( 0.560)	Loss 1.1027e-01 (8.9741e-02) 
2023-05-25 23:33:21.030022: val Epoch: [43][13/72]	Time  0.117 ( 0.646)	Data  0.000 ( 0.520)	Loss 3.9928e-01 (1.1185e-01) 
2023-05-25 23:33:22.211822: val Epoch: [43][14/72]	Time  1.182 ( 0.681)	Data  1.060 ( 0.556)	Loss 4.0062e-02 (1.0706e-01) 
2023-05-25 23:33:22.332261: val Epoch: [43][15/72]	Time  0.120 ( 0.646)	Data  0.001 ( 0.521)	Loss 4.8149e-02 (1.0338e-01) 
2023-05-25 23:33:23.544445: val Epoch: [43][16/72]	Time  1.212 ( 0.680)	Data  1.092 ( 0.555)	Loss 7.6528e-02 (1.0180e-01) 
2023-05-25 23:33:23.663598: val Epoch: [43][17/72]	Time  0.119 ( 0.648)	Data  0.000 ( 0.524)	Loss 1.0935e-01 (1.0222e-01) 
2023-05-25 23:33:24.848464: val Epoch: [43][18/72]	Time  1.185 ( 0.677)	Data  1.064 ( 0.552)	Loss 7.5410e-02 (1.0081e-01) 
2023-05-25 23:33:24.968128: val Epoch: [43][19/72]	Time  0.120 ( 0.649)	Data  0.000 ( 0.525)	Loss 2.3126e-01 (1.0733e-01) 
2023-05-25 23:33:26.106969: val Epoch: [43][20/72]	Time  1.139 ( 0.672)	Data  1.021 ( 0.548)	Loss 2.9179e-01 (1.1612e-01) 
2023-05-25 23:33:26.226497: val Epoch: [43][21/72]	Time  0.120 ( 0.647)	Data  0.000 ( 0.524)	Loss 2.8391e-01 (1.2374e-01) 
2023-05-25 23:33:27.353476: val Epoch: [43][22/72]	Time  1.127 ( 0.668)	Data  1.010 ( 0.545)	Loss 8.0492e-02 (1.2186e-01) 
2023-05-25 23:33:27.470991: val Epoch: [43][23/72]	Time  0.118 ( 0.645)	Data  0.000 ( 0.522)	Loss 9.7290e-02 (1.2084e-01) 
2023-05-25 23:33:28.607360: val Epoch: [43][24/72]	Time  1.136 ( 0.665)	Data  1.019 ( 0.542)	Loss 5.3870e-02 (1.1816e-01) 
2023-05-25 23:33:28.727373: val Epoch: [43][25/72]	Time  0.120 ( 0.644)	Data  0.000 ( 0.521)	Loss 1.1872e-01 (1.1818e-01) 
2023-05-25 23:33:29.882541: val Epoch: [43][26/72]	Time  1.155 ( 0.663)	Data  1.029 ( 0.540)	Loss 1.4072e-01 (1.1902e-01) 
2023-05-25 23:33:30.007278: val Epoch: [43][27/72]	Time  0.125 ( 0.643)	Data  0.001 ( 0.521)	Loss 3.8633e-02 (1.1615e-01) 
2023-05-25 23:33:31.114723: val Epoch: [43][28/72]	Time  1.107 ( 0.659)	Data  0.982 ( 0.536)	Loss 6.0562e-02 (1.1423e-01) 
2023-05-25 23:33:31.239289: val Epoch: [43][29/72]	Time  0.125 ( 0.642)	Data  0.001 ( 0.519)	Loss 6.9113e-02 (1.1273e-01) 
2023-05-25 23:33:32.383397: val Epoch: [43][30/72]	Time  1.144 ( 0.658)	Data  1.021 ( 0.535)	Loss 3.8807e-01 (1.2161e-01) 
2023-05-25 23:33:32.508017: val Epoch: [43][31/72]	Time  0.125 ( 0.641)	Data  0.001 ( 0.518)	Loss 3.8198e-02 (1.1900e-01) 
2023-05-25 23:33:33.644406: val Epoch: [43][32/72]	Time  1.136 ( 0.656)	Data  1.008 ( 0.533)	Loss 7.8448e-02 (1.1777e-01) 
2023-05-25 23:33:33.768771: val Epoch: [43][33/72]	Time  0.124 ( 0.641)	Data  0.001 ( 0.517)	Loss 3.5871e-01 (1.2486e-01) 
2023-05-25 23:33:34.863904: val Epoch: [43][34/72]	Time  1.095 ( 0.654)	Data  0.969 ( 0.530)	Loss 4.9630e-02 (1.2271e-01) 
2023-05-25 23:33:34.983433: val Epoch: [43][35/72]	Time  0.120 ( 0.639)	Data  0.000 ( 0.516)	Loss 4.8348e-02 (1.2064e-01) 
2023-05-25 23:33:36.159893: val Epoch: [43][36/72]	Time  1.176 ( 0.653)	Data  1.053 ( 0.530)	Loss 5.0071e-02 (1.1874e-01) 
2023-05-25 23:33:36.279214: val Epoch: [43][37/72]	Time  0.119 ( 0.639)	Data  0.001 ( 0.516)	Loss 4.3221e-01 (1.2699e-01) 
2023-05-25 23:33:37.376666: val Epoch: [43][38/72]	Time  1.097 ( 0.651)	Data  0.973 ( 0.528)	Loss 5.9073e-02 (1.2524e-01) 
2023-05-25 23:33:37.496146: val Epoch: [43][39/72]	Time  0.119 ( 0.638)	Data  0.001 ( 0.515)	Loss 1.8089e-01 (1.2663e-01) 
2023-05-25 23:33:38.711491: val Epoch: [43][40/72]	Time  1.215 ( 0.652)	Data  1.096 ( 0.529)	Loss 1.6784e-01 (1.2764e-01) 
2023-05-25 23:33:38.828459: val Epoch: [43][41/72]	Time  0.117 ( 0.639)	Data  0.000 ( 0.516)	Loss 3.8376e-02 (1.2551e-01) 
2023-05-25 23:33:39.965883: val Epoch: [43][42/72]	Time  1.137 ( 0.651)	Data  1.018 ( 0.528)	Loss 5.6653e-02 (1.2391e-01) 
2023-05-25 23:33:40.082614: val Epoch: [43][43/72]	Time  0.117 ( 0.638)	Data  0.000 ( 0.516)	Loss 6.8151e-02 (1.2265e-01) 
2023-05-25 23:33:41.236434: val Epoch: [43][44/72]	Time  1.154 ( 0.650)	Data  1.034 ( 0.527)	Loss 1.4676e-01 (1.2318e-01) 
2023-05-25 23:33:41.355697: val Epoch: [43][45/72]	Time  0.119 ( 0.638)	Data  0.000 ( 0.516)	Loss 6.3588e-02 (1.2189e-01) 
2023-05-25 23:33:42.515821: val Epoch: [43][46/72]	Time  1.160 ( 0.649)	Data  1.043 ( 0.527)	Loss 3.5126e-01 (1.2677e-01) 
2023-05-25 23:33:42.636083: val Epoch: [43][47/72]	Time  0.120 ( 0.638)	Data  0.000 ( 0.516)	Loss 9.2570e-02 (1.2605e-01) 
2023-05-25 23:33:43.793875: val Epoch: [43][48/72]	Time  1.158 ( 0.649)	Data  1.041 ( 0.527)	Loss 6.1793e-02 (1.2474e-01) 
2023-05-25 23:33:43.910669: val Epoch: [43][49/72]	Time  0.117 ( 0.638)	Data  0.000 ( 0.516)	Loss 2.3022e-01 (1.2685e-01) 
2023-05-25 23:33:45.097159: val Epoch: [43][50/72]	Time  1.186 ( 0.649)	Data  1.062 ( 0.527)	Loss 3.9519e-02 (1.2514e-01) 
2023-05-25 23:33:45.217119: val Epoch: [43][51/72]	Time  0.120 ( 0.639)	Data  0.001 ( 0.517)	Loss 1.9956e-01 (1.2657e-01) 
2023-05-25 23:33:46.359625: val Epoch: [43][52/72]	Time  1.142 ( 0.648)	Data  1.022 ( 0.527)	Loss 5.2526e-02 (1.2517e-01) 
2023-05-25 23:33:46.479045: val Epoch: [43][53/72]	Time  0.119 ( 0.639)	Data  0.001 ( 0.517)	Loss 4.6187e-02 (1.2371e-01) 
2023-05-25 23:33:47.557822: val Epoch: [43][54/72]	Time  1.079 ( 0.647)	Data  0.957 ( 0.525)	Loss 4.7953e-02 (1.2233e-01) 
2023-05-25 23:33:47.677265: val Epoch: [43][55/72]	Time  0.119 ( 0.637)	Data  0.000 ( 0.515)	Loss 5.5405e-02 (1.2114e-01) 
2023-05-25 23:33:48.877324: val Epoch: [43][56/72]	Time  1.200 ( 0.647)	Data  1.076 ( 0.525)	Loss 1.5012e-01 (1.2165e-01) 
2023-05-25 23:33:48.997050: val Epoch: [43][57/72]	Time  0.120 ( 0.638)	Data  0.001 ( 0.516)	Loss 2.6775e-01 (1.2417e-01) 
2023-05-25 23:33:50.097546: val Epoch: [43][58/72]	Time  1.100 ( 0.646)	Data  0.976 ( 0.524)	Loss 1.1575e-01 (1.2402e-01) 
2023-05-25 23:33:50.217034: val Epoch: [43][59/72]	Time  0.119 ( 0.637)	Data  0.001 ( 0.515)	Loss 4.4871e-02 (1.2270e-01) 
2023-05-25 23:33:51.360831: val Epoch: [43][60/72]	Time  1.144 ( 0.645)	Data  1.021 ( 0.524)	Loss 3.3617e-01 (1.2620e-01) 
2023-05-25 23:33:51.480350: val Epoch: [43][61/72]	Time  0.120 ( 0.637)	Data  0.000 ( 0.515)	Loss 3.5402e-01 (1.2988e-01) 
2023-05-25 23:33:52.575819: val Epoch: [43][62/72]	Time  1.095 ( 0.644)	Data  0.970 ( 0.522)	Loss 3.9802e-02 (1.2845e-01) 
2023-05-25 23:33:52.696442: val Epoch: [43][63/72]	Time  0.121 ( 0.636)	Data  0.001 ( 0.514)	Loss 4.9431e-02 (1.2721e-01) 
2023-05-25 23:33:53.849797: val Epoch: [43][64/72]	Time  1.153 ( 0.644)	Data  1.023 ( 0.522)	Loss 2.9584e-01 (1.2981e-01) 
2023-05-25 23:33:53.974794: val Epoch: [43][65/72]	Time  0.125 ( 0.636)	Data  0.001 ( 0.514)	Loss 9.0997e-02 (1.2922e-01) 
2023-05-25 23:33:55.146683: val Epoch: [43][66/72]	Time  1.172 ( 0.644)	Data  1.045 ( 0.522)	Loss 7.5163e-02 (1.2841e-01) 
2023-05-25 23:33:55.272348: val Epoch: [43][67/72]	Time  0.126 ( 0.636)	Data  0.001 ( 0.514)	Loss 1.1833e-01 (1.2826e-01) 
2023-05-25 23:33:56.371820: val Epoch: [43][68/72]	Time  1.099 ( 0.643)	Data  0.969 ( 0.521)	Loss 8.3284e-02 (1.2761e-01) 
2023-05-25 23:33:56.496993: val Epoch: [43][69/72]	Time  0.125 ( 0.636)	Data  0.001 ( 0.514)	Loss 9.4111e-02 (1.2713e-01) 
2023-05-25 23:33:57.629647: val Epoch: [43][70/72]	Time  1.133 ( 0.643)	Data  1.007 ( 0.520)	Loss 9.7126e-02 (1.2671e-01) 
2023-05-25 23:33:57.751825: val Epoch: [43][71/72]	Time  0.122 ( 0.636)	Data  0.000 ( 0.513)	Loss 1.2977e-01 (1.2675e-01) 
2023-05-25 23:33:57.948027: Epoch 43 :Val : ['ET : 0.759090006351471', 'TC : 0.783664345741272', 'WT : 0.8717333674430847'] 
2023-05-25 23:33:57.950881: Epoch 43 :Val : ['ET : 0.759090006351471', 'TC : 0.783664345741272', 'WT : 0.8717333674430847'] 
2023-05-25 23:33:57.952690: Saving the model with DSC 0.8012077808380127 
2023-05-25 23:33:58.641240: Val epoch done in 47.36883135400058 s 
2023-05-25 23:33:58.646499: Batches per epoch:  129 
2023-05-25 23:34:03.595307: train Epoch: [44][  0/129]	Time  4.948 ( 4.948)	Data  3.955 ( 3.955)	Loss 7.1683e-02 (7.1683e-02) 
2023-05-25 23:34:04.548377: train Epoch: [44][  1/129]	Time  0.953 ( 2.951)	Data  0.001 ( 1.978)	Loss 1.1752e-01 (9.4602e-02) 
2023-05-25 23:34:07.193266: train Epoch: [44][  2/129]	Time  2.645 ( 2.849)	Data  1.694 ( 1.883)	Loss 7.5936e-02 (8.8380e-02) 
2023-05-25 23:34:08.148027: train Epoch: [44][  3/129]	Time  0.955 ( 2.375)	Data  0.001 ( 1.413)	Loss 8.7034e-02 (8.8043e-02) 
2023-05-25 23:34:10.945103: train Epoch: [44][  4/129]	Time  2.797 ( 2.460)	Data  1.833 ( 1.497)	Loss 1.0359e-01 (9.1152e-02) 
2023-05-25 23:34:11.898782: train Epoch: [44][  5/129]	Time  0.954 ( 2.209)	Data  0.001 ( 1.247)	Loss 4.6977e-02 (8.3789e-02) 
2023-05-25 23:34:14.668962: train Epoch: [44][  6/129]	Time  2.770 ( 2.289)	Data  1.807 ( 1.327)	Loss 6.4825e-02 (8.1080e-02) 
2023-05-25 23:34:15.621229: train Epoch: [44][  7/129]	Time  0.952 ( 2.122)	Data  0.001 ( 1.162)	Loss 1.1967e-01 (8.5904e-02) 
2023-05-25 23:34:18.526421: train Epoch: [44][  8/129]	Time  2.905 ( 2.209)	Data  1.942 ( 1.248)	Loss 6.7358e-02 (8.3843e-02) 
2023-05-25 23:34:19.479649: train Epoch: [44][  9/129]	Time  0.953 ( 2.083)	Data  0.001 ( 1.124)	Loss 6.5180e-02 (8.1977e-02) 
2023-05-25 23:34:22.415031: train Epoch: [44][ 10/129]	Time  2.935 ( 2.161)	Data  1.986 ( 1.202)	Loss 2.0779e-01 (9.3414e-02) 
2023-05-25 23:34:23.367253: train Epoch: [44][ 11/129]	Time  0.952 ( 2.060)	Data  0.001 ( 1.102)	Loss 9.9614e-02 (9.3931e-02) 
2023-05-25 23:34:26.143707: train Epoch: [44][ 12/129]	Time  2.776 ( 2.115)	Data  1.826 ( 1.158)	Loss 7.7675e-02 (9.2680e-02) 
2023-05-25 23:34:27.098372: train Epoch: [44][ 13/129]	Time  0.955 ( 2.032)	Data  0.001 ( 1.075)	Loss 1.1543e-01 (9.4305e-02) 
2023-05-25 23:34:29.816423: train Epoch: [44][ 14/129]	Time  2.718 ( 2.078)	Data  1.769 ( 1.121)	Loss 2.2101e-01 (1.0275e-01) 
2023-05-25 23:34:30.768732: train Epoch: [44][ 15/129]	Time  0.952 ( 2.008)	Data  0.001 ( 1.051)	Loss 9.8649e-02 (1.0250e-01) 
2023-05-25 23:34:33.412872: train Epoch: [44][ 16/129]	Time  2.644 ( 2.045)	Data  1.695 ( 1.089)	Loss 6.4807e-02 (1.0028e-01) 
2023-05-25 23:34:34.367793: train Epoch: [44][ 17/129]	Time  0.955 ( 1.984)	Data  0.001 ( 1.029)	Loss 5.2682e-02 (9.7634e-02) 
2023-05-25 23:34:37.124179: train Epoch: [44][ 18/129]	Time  2.756 ( 2.025)	Data  1.796 ( 1.069)	Loss 6.8343e-02 (9.6093e-02) 
2023-05-25 23:34:38.088393: train Epoch: [44][ 19/129]	Time  0.964 ( 1.972)	Data  0.001 ( 1.016)	Loss 9.4600e-02 (9.6018e-02) 
2023-05-25 23:34:40.739398: train Epoch: [44][ 20/129]	Time  2.651 ( 2.004)	Data  1.698 ( 1.048)	Loss 8.5674e-02 (9.5525e-02) 
2023-05-25 23:34:41.692459: train Epoch: [44][ 21/129]	Time  0.953 ( 1.957)	Data  0.001 ( 1.000)	Loss 7.8749e-02 (9.4763e-02) 
2023-05-25 23:34:44.337537: train Epoch: [44][ 22/129]	Time  2.645 ( 1.987)	Data  1.695 ( 1.031)	Loss 5.3489e-02 (9.2968e-02) 
2023-05-25 23:34:45.301430: train Epoch: [44][ 23/129]	Time  0.964 ( 1.944)	Data  0.001 ( 0.988)	Loss 6.6396e-02 (9.1861e-02) 
2023-05-25 23:34:48.049348: train Epoch: [44][ 24/129]	Time  2.748 ( 1.976)	Data  1.789 ( 1.020)	Loss 7.9990e-02 (9.1386e-02) 
2023-05-25 23:34:49.012538: train Epoch: [44][ 25/129]	Time  0.963 ( 1.937)	Data  0.001 ( 0.981)	Loss 7.5867e-02 (9.0789e-02) 
2023-05-25 23:34:51.693902: train Epoch: [44][ 26/129]	Time  2.681 ( 1.965)	Data  1.722 ( 1.008)	Loss 6.0855e-02 (8.9681e-02) 
2023-05-25 23:34:52.655987: train Epoch: [44][ 27/129]	Time  0.962 ( 1.929)	Data  0.001 ( 0.972)	Loss 1.2058e-01 (9.0784e-02) 
2023-05-25 23:34:55.254323: train Epoch: [44][ 28/129]	Time  2.598 ( 1.952)	Data  1.650 ( 0.995)	Loss 7.6104e-02 (9.0278e-02) 
2023-05-25 23:34:56.206300: train Epoch: [44][ 29/129]	Time  0.952 ( 1.919)	Data  0.001 ( 0.962)	Loss 9.1394e-02 (9.0315e-02) 
2023-05-25 23:34:58.859879: train Epoch: [44][ 30/129]	Time  2.654 ( 1.942)	Data  1.705 ( 0.986)	Loss 4.1772e-02 (8.8749e-02) 
2023-05-25 23:34:59.811821: train Epoch: [44][ 31/129]	Time  0.952 ( 1.911)	Data  0.001 ( 0.955)	Loss 8.3158e-02 (8.8575e-02) 
2023-05-25 23:35:02.470096: train Epoch: [44][ 32/129]	Time  2.658 ( 1.934)	Data  1.707 ( 0.978)	Loss 6.3007e-02 (8.7800e-02) 
2023-05-25 23:35:03.422595: train Epoch: [44][ 33/129]	Time  0.952 ( 1.905)	Data  0.001 ( 0.950)	Loss 6.4887e-02 (8.7126e-02) 
2023-05-25 23:35:06.085013: train Epoch: [44][ 34/129]	Time  2.662 ( 1.927)	Data  1.715 ( 0.971)	Loss 7.5636e-02 (8.6798e-02) 
2023-05-25 23:35:07.037504: train Epoch: [44][ 35/129]	Time  0.952 ( 1.900)	Data  0.001 ( 0.944)	Loss 9.4184e-02 (8.7003e-02) 
2023-05-25 23:35:09.753936: train Epoch: [44][ 36/129]	Time  2.716 ( 1.922)	Data  1.768 ( 0.967)	Loss 8.9987e-02 (8.7083e-02) 
2023-05-25 23:35:10.705935: train Epoch: [44][ 37/129]	Time  0.952 ( 1.896)	Data  0.001 ( 0.941)	Loss 9.2765e-02 (8.7233e-02) 
2023-05-25 23:35:13.320279: train Epoch: [44][ 38/129]	Time  2.614 ( 1.915)	Data  1.667 ( 0.960)	Loss 7.9244e-02 (8.7028e-02) 
2023-05-25 23:35:14.272583: train Epoch: [44][ 39/129]	Time  0.952 ( 1.891)	Data  0.001 ( 0.936)	Loss 6.9370e-02 (8.6587e-02) 
2023-05-25 23:35:17.028661: train Epoch: [44][ 40/129]	Time  2.756 ( 1.912)	Data  1.809 ( 0.957)	Loss 1.4177e-01 (8.7933e-02) 
2023-05-25 23:35:17.979409: train Epoch: [44][ 41/129]	Time  0.951 ( 1.889)	Data  0.001 ( 0.934)	Loss 7.5087e-02 (8.7627e-02) 
2023-05-25 23:35:20.699795: train Epoch: [44][ 42/129]	Time  2.720 ( 1.908)	Data  1.772 ( 0.954)	Loss 1.1020e-01 (8.8152e-02) 
2023-05-25 23:35:21.651568: train Epoch: [44][ 43/129]	Time  0.952 ( 1.886)	Data  0.001 ( 0.932)	Loss 7.7355e-02 (8.7906e-02) 
2023-05-25 23:35:24.282077: train Epoch: [44][ 44/129]	Time  2.631 ( 1.903)	Data  1.683 ( 0.949)	Loss 9.4840e-02 (8.8060e-02) 
2023-05-25 23:35:25.232723: train Epoch: [44][ 45/129]	Time  0.951 ( 1.882)	Data  0.001 ( 0.928)	Loss 1.2907e-01 (8.8952e-02) 
2023-05-25 23:35:27.853061: train Epoch: [44][ 46/129]	Time  2.620 ( 1.898)	Data  1.670 ( 0.944)	Loss 7.4958e-02 (8.8654e-02) 
2023-05-25 23:35:28.805170: train Epoch: [44][ 47/129]	Time  0.952 ( 1.878)	Data  0.001 ( 0.924)	Loss 6.4826e-02 (8.8158e-02) 
2023-05-25 23:35:31.489224: train Epoch: [44][ 48/129]	Time  2.684 ( 1.895)	Data  1.735 ( 0.941)	Loss 6.6583e-02 (8.7717e-02) 
2023-05-25 23:35:32.454766: train Epoch: [44][ 49/129]	Time  0.966 ( 1.876)	Data  0.001 ( 0.922)	Loss 6.5518e-02 (8.7273e-02) 
2023-05-25 23:35:35.249141: train Epoch: [44][ 50/129]	Time  2.794 ( 1.894)	Data  1.835 ( 0.940)	Loss 6.7988e-02 (8.6895e-02) 
2023-05-25 23:35:36.211735: train Epoch: [44][ 51/129]	Time  0.963 ( 1.876)	Data  0.001 ( 0.922)	Loss 6.7497e-02 (8.6522e-02) 
2023-05-25 23:35:38.812847: train Epoch: [44][ 52/129]	Time  2.601 ( 1.890)	Data  1.638 ( 0.936)	Loss 4.0808e-02 (8.5660e-02) 
2023-05-25 23:35:39.774816: train Epoch: [44][ 53/129]	Time  0.962 ( 1.873)	Data  0.001 ( 0.918)	Loss 6.1631e-02 (8.5215e-02) 
2023-05-25 23:35:42.543003: train Epoch: [44][ 54/129]	Time  2.768 ( 1.889)	Data  1.819 ( 0.935)	Loss 7.4022e-02 (8.5011e-02) 
2023-05-25 23:35:43.495519: train Epoch: [44][ 55/129]	Time  0.953 ( 1.872)	Data  0.001 ( 0.918)	Loss 5.2606e-02 (8.4433e-02) 
2023-05-25 23:35:46.198724: train Epoch: [44][ 56/129]	Time  2.703 ( 1.887)	Data  1.754 ( 0.933)	Loss 7.9065e-02 (8.4338e-02) 
2023-05-25 23:35:47.150547: train Epoch: [44][ 57/129]	Time  0.952 ( 1.871)	Data  0.001 ( 0.917)	Loss 9.5827e-02 (8.4536e-02) 
2023-05-25 23:35:49.757254: train Epoch: [44][ 58/129]	Time  2.607 ( 1.883)	Data  1.658 ( 0.929)	Loss 5.2772e-02 (8.3998e-02) 
2023-05-25 23:35:50.708258: train Epoch: [44][ 59/129]	Time  0.951 ( 1.868)	Data  0.001 ( 0.914)	Loss 7.2306e-02 (8.3803e-02) 
2023-05-25 23:35:53.332164: train Epoch: [44][ 60/129]	Time  2.624 ( 1.880)	Data  1.675 ( 0.926)	Loss 4.4613e-02 (8.3161e-02) 
2023-05-25 23:35:54.283550: train Epoch: [44][ 61/129]	Time  0.951 ( 1.865)	Data  0.001 ( 0.911)	Loss 6.6745e-02 (8.2896e-02) 
2023-05-25 23:35:56.982716: train Epoch: [44][ 62/129]	Time  2.699 ( 1.878)	Data  1.751 ( 0.925)	Loss 7.0555e-02 (8.2700e-02) 
2023-05-25 23:35:57.932930: train Epoch: [44][ 63/129]	Time  0.950 ( 1.864)	Data  0.001 ( 0.910)	Loss 8.3806e-02 (8.2717e-02) 
2023-05-25 23:36:00.669687: train Epoch: [44][ 64/129]	Time  2.737 ( 1.877)	Data  1.789 ( 0.924)	Loss 7.6613e-02 (8.2623e-02) 
2023-05-25 23:36:01.620997: train Epoch: [44][ 65/129]	Time  0.951 ( 1.863)	Data  0.001 ( 0.910)	Loss 7.9930e-02 (8.2583e-02) 
2023-05-25 23:36:04.256483: train Epoch: [44][ 66/129]	Time  2.635 ( 1.875)	Data  1.680 ( 0.921)	Loss 7.6608e-02 (8.2493e-02) 
2023-05-25 23:36:05.209806: train Epoch: [44][ 67/129]	Time  0.953 ( 1.861)	Data  0.001 ( 0.908)	Loss 5.1324e-02 (8.2035e-02) 
2023-05-25 23:36:07.830472: train Epoch: [44][ 68/129]	Time  2.621 ( 1.872)	Data  1.672 ( 0.919)	Loss 6.0883e-02 (8.1729e-02) 
2023-05-25 23:36:08.780673: train Epoch: [44][ 69/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.906)	Loss 7.0634e-02 (8.1570e-02) 
2023-05-25 23:36:11.610687: train Epoch: [44][ 70/129]	Time  2.830 ( 1.873)	Data  1.881 ( 0.919)	Loss 6.6956e-02 (8.1364e-02) 
2023-05-25 23:36:12.561780: train Epoch: [44][ 71/129]	Time  0.951 ( 1.860)	Data  0.001 ( 0.907)	Loss 9.2209e-02 (8.1515e-02) 
2023-05-25 23:36:15.319044: train Epoch: [44][ 72/129]	Time  2.757 ( 1.872)	Data  1.806 ( 0.919)	Loss 7.7956e-02 (8.1466e-02) 
2023-05-25 23:36:16.267145: train Epoch: [44][ 73/129]	Time  0.948 ( 1.860)	Data  0.001 ( 0.906)	Loss 5.3174e-02 (8.1084e-02) 
2023-05-25 23:36:18.975489: train Epoch: [44][ 74/129]	Time  2.708 ( 1.871)	Data  1.750 ( 0.918)	Loss 5.8829e-02 (8.0787e-02) 
2023-05-25 23:36:19.925202: train Epoch: [44][ 75/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.906)	Loss 7.7425e-02 (8.0743e-02) 
2023-05-25 23:36:22.637812: train Epoch: [44][ 76/129]	Time  2.713 ( 1.870)	Data  1.752 ( 0.917)	Loss 6.2340e-02 (8.0504e-02) 
2023-05-25 23:36:23.587351: train Epoch: [44][ 77/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.905)	Loss 6.8534e-02 (8.0350e-02) 
2023-05-25 23:36:26.274787: train Epoch: [44][ 78/129]	Time  2.687 ( 1.869)	Data  1.740 ( 0.915)	Loss 6.7795e-02 (8.0191e-02) 
2023-05-25 23:36:27.226579: train Epoch: [44][ 79/129]	Time  0.952 ( 1.857)	Data  0.001 ( 0.904)	Loss 1.1156e-01 (8.0584e-02) 
2023-05-25 23:36:29.885892: train Epoch: [44][ 80/129]	Time  2.659 ( 1.867)	Data  1.703 ( 0.914)	Loss 6.0288e-02 (8.0333e-02) 
2023-05-25 23:36:30.836609: train Epoch: [44][ 81/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.903)	Loss 4.0073e-02 (7.9842e-02) 
2023-05-25 23:36:33.603245: train Epoch: [44][ 82/129]	Time  2.767 ( 1.867)	Data  1.818 ( 0.914)	Loss 4.9693e-02 (7.9479e-02) 
2023-05-25 23:36:34.553481: train Epoch: [44][ 83/129]	Time  0.950 ( 1.856)	Data  0.001 ( 0.903)	Loss 8.3496e-02 (7.9527e-02) 
2023-05-25 23:36:37.246410: train Epoch: [44][ 84/129]	Time  2.693 ( 1.866)	Data  1.743 ( 0.913)	Loss 8.5012e-02 (7.9591e-02) 
2023-05-25 23:36:38.199479: train Epoch: [44][ 85/129]	Time  0.953 ( 1.855)	Data  0.001 ( 0.902)	Loss 7.3212e-02 (7.9517e-02) 
2023-05-25 23:36:41.003908: train Epoch: [44][ 86/129]	Time  2.804 ( 1.866)	Data  1.855 ( 0.913)	Loss 1.7415e-01 (8.0605e-02) 
2023-05-25 23:36:41.955139: train Epoch: [44][ 87/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.903)	Loss 8.1945e-02 (8.0620e-02) 
2023-05-25 23:36:44.686076: train Epoch: [44][ 88/129]	Time  2.731 ( 1.866)	Data  1.783 ( 0.913)	Loss 6.2316e-02 (8.0414e-02) 
2023-05-25 23:36:45.638389: train Epoch: [44][ 89/129]	Time  0.952 ( 1.855)	Data  0.001 ( 0.903)	Loss 1.5699e-01 (8.1265e-02) 
2023-05-25 23:36:48.296419: train Epoch: [44][ 90/129]	Time  2.658 ( 1.864)	Data  1.710 ( 0.911)	Loss 8.5573e-02 (8.1313e-02) 
2023-05-25 23:36:49.247093: train Epoch: [44][ 91/129]	Time  0.951 ( 1.854)	Data  0.001 ( 0.902)	Loss 1.1218e-01 (8.1648e-02) 
2023-05-25 23:36:51.948304: train Epoch: [44][ 92/129]	Time  2.701 ( 1.863)	Data  1.742 ( 0.911)	Loss 8.2125e-02 (8.1653e-02) 
2023-05-25 23:36:52.900137: train Epoch: [44][ 93/129]	Time  0.952 ( 1.854)	Data  0.001 ( 0.901)	Loss 6.7998e-02 (8.1508e-02) 
2023-05-25 23:36:55.568389: train Epoch: [44][ 94/129]	Time  2.668 ( 1.862)	Data  1.720 ( 0.910)	Loss 1.3041e-01 (8.2023e-02) 
2023-05-25 23:36:56.518876: train Epoch: [44][ 95/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.900)	Loss 9.4893e-02 (8.2157e-02) 
2023-05-25 23:36:59.190598: train Epoch: [44][ 96/129]	Time  2.672 ( 1.861)	Data  1.725 ( 0.909)	Loss 1.1541e-01 (8.2499e-02) 
2023-05-25 23:37:00.143889: train Epoch: [44][ 97/129]	Time  0.953 ( 1.852)	Data  0.001 ( 0.899)	Loss 1.0545e-01 (8.2734e-02) 
2023-05-25 23:37:02.831711: train Epoch: [44][ 98/129]	Time  2.688 ( 1.860)	Data  1.739 ( 0.908)	Loss 5.0954e-02 (8.2413e-02) 
2023-05-25 23:37:03.781314: train Epoch: [44][ 99/129]	Time  0.950 ( 1.851)	Data  0.001 ( 0.899)	Loss 5.9137e-02 (8.2180e-02) 
2023-05-25 23:37:06.334188: train Epoch: [44][100/129]	Time  2.553 ( 1.858)	Data  1.606 ( 0.906)	Loss 4.6508e-02 (8.1827e-02) 
2023-05-25 23:37:07.284767: train Epoch: [44][101/129]	Time  0.951 ( 1.849)	Data  0.001 ( 0.897)	Loss 7.1883e-02 (8.1729e-02) 
2023-05-25 23:37:09.982000: train Epoch: [44][102/129]	Time  2.697 ( 1.858)	Data  1.750 ( 0.905)	Loss 8.1824e-02 (8.1730e-02) 
2023-05-25 23:37:10.932384: train Epoch: [44][103/129]	Time  0.950 ( 1.849)	Data  0.001 ( 0.896)	Loss 7.8111e-02 (8.1695e-02) 
2023-05-25 23:37:13.621127: train Epoch: [44][104/129]	Time  2.689 ( 1.857)	Data  1.741 ( 0.904)	Loss 9.8585e-02 (8.1856e-02) 
2023-05-25 23:37:14.571777: train Epoch: [44][105/129]	Time  0.951 ( 1.848)	Data  0.001 ( 0.896)	Loss 7.6864e-02 (8.1809e-02) 
2023-05-25 23:37:17.350667: train Epoch: [44][106/129]	Time  2.779 ( 1.857)	Data  1.831 ( 0.905)	Loss 7.1685e-02 (8.1715e-02) 
2023-05-25 23:37:18.301437: train Epoch: [44][107/129]	Time  0.951 ( 1.849)	Data  0.001 ( 0.896)	Loss 6.0514e-02 (8.1518e-02) 
2023-05-25 23:37:20.925040: train Epoch: [44][108/129]	Time  2.624 ( 1.856)	Data  1.675 ( 0.903)	Loss 7.3290e-02 (8.1443e-02) 
2023-05-25 23:37:21.875797: train Epoch: [44][109/129]	Time  0.951 ( 1.848)	Data  0.001 ( 0.895)	Loss 4.8467e-02 (8.1143e-02) 
2023-05-25 23:37:24.499680: train Epoch: [44][110/129]	Time  2.624 ( 1.855)	Data  1.677 ( 0.902)	Loss 7.3969e-02 (8.1078e-02) 
2023-05-25 23:37:25.452517: train Epoch: [44][111/129]	Time  0.953 ( 1.846)	Data  0.001 ( 0.894)	Loss 7.1041e-02 (8.0989e-02) 
2023-05-25 23:37:28.227464: train Epoch: [44][112/129]	Time  2.775 ( 1.855)	Data  1.827 ( 0.903)	Loss 5.9965e-02 (8.0803e-02) 
2023-05-25 23:37:29.177925: train Epoch: [44][113/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.895)	Loss 1.2940e-01 (8.1229e-02) 
2023-05-25 23:37:31.777485: train Epoch: [44][114/129]	Time  2.600 ( 1.853)	Data  1.651 ( 0.901)	Loss 5.7922e-02 (8.1026e-02) 
2023-05-25 23:37:32.729371: train Epoch: [44][115/129]	Time  0.952 ( 1.846)	Data  0.001 ( 0.893)	Loss 6.5683e-02 (8.0894e-02) 
2023-05-25 23:37:35.409463: train Epoch: [44][116/129]	Time  2.680 ( 1.853)	Data  1.730 ( 0.901)	Loss 8.3758e-02 (8.0918e-02) 
2023-05-25 23:37:36.362683: train Epoch: [44][117/129]	Time  0.953 ( 1.845)	Data  0.001 ( 0.893)	Loss 6.7998e-02 (8.0809e-02) 
2023-05-25 23:37:39.090424: train Epoch: [44][118/129]	Time  2.728 ( 1.852)	Data  1.778 ( 0.900)	Loss 5.8723e-02 (8.0623e-02) 
2023-05-25 23:37:40.040563: train Epoch: [44][119/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.893)	Loss 6.8741e-02 (8.0524e-02) 
2023-05-25 23:37:42.742598: train Epoch: [44][120/129]	Time  2.702 ( 1.852)	Data  1.743 ( 0.900)	Loss 6.9524e-02 (8.0433e-02) 
2023-05-25 23:37:43.694005: train Epoch: [44][121/129]	Time  0.951 ( 1.845)	Data  0.001 ( 0.893)	Loss 9.3879e-02 (8.0544e-02) 
2023-05-25 23:37:46.445580: train Epoch: [44][122/129]	Time  2.752 ( 1.852)	Data  1.802 ( 0.900)	Loss 6.9799e-02 (8.0456e-02) 
2023-05-25 23:37:47.397125: train Epoch: [44][123/129]	Time  0.952 ( 1.845)	Data  0.001 ( 0.893)	Loss 9.3705e-02 (8.0563e-02) 
2023-05-25 23:37:50.240974: train Epoch: [44][124/129]	Time  2.844 ( 1.853)	Data  1.883 ( 0.901)	Loss 4.7815e-02 (8.0301e-02) 
2023-05-25 23:37:51.193668: train Epoch: [44][125/129]	Time  0.953 ( 1.846)	Data  0.001 ( 0.893)	Loss 9.3990e-02 (8.0410e-02) 
2023-05-25 23:37:53.918461: train Epoch: [44][126/129]	Time  2.725 ( 1.853)	Data  1.768 ( 0.900)	Loss 5.9728e-02 (8.0247e-02) 
2023-05-25 23:37:54.865122: train Epoch: [44][127/129]	Time  0.947 ( 1.845)	Data  0.001 ( 0.893)	Loss 8.4413e-02 (8.0279e-02) 
2023-05-25 23:37:56.410495: train Epoch: [44][128/129]	Time  1.545 ( 1.843)	Data  0.599 ( 0.891)	Loss 5.7489e-02 (8.0103e-02) 
2023-05-25 23:37:56.441495: Train Epoch done in 237.79500761700183 s 
2023-05-25 23:37:58.863791: val Epoch: [44][ 0/72]	Time  1.686 ( 1.686)	Data  1.483 ( 1.483)	Loss 4.0669e-01 (4.0669e-01) 
2023-05-25 23:37:58.993061: val Epoch: [44][ 1/72]	Time  0.129 ( 0.908)	Data  0.001 ( 0.742)	Loss 4.7562e-02 (2.2713e-01) 
2023-05-25 23:37:59.971236: val Epoch: [44][ 2/72]	Time  0.978 ( 0.931)	Data  0.853 ( 0.779)	Loss 1.7391e-01 (2.0939e-01) 
2023-05-25 23:38:00.096826: val Epoch: [44][ 3/72]	Time  0.126 ( 0.730)	Data  0.001 ( 0.585)	Loss 4.9317e-02 (1.6937e-01) 
2023-05-25 23:38:01.252865: val Epoch: [44][ 4/72]	Time  1.156 ( 0.815)	Data  1.031 ( 0.674)	Loss 7.1084e-02 (1.4971e-01) 
2023-05-25 23:38:01.378613: val Epoch: [44][ 5/72]	Time  0.126 ( 0.700)	Data  0.001 ( 0.562)	Loss 4.7567e-02 (1.3269e-01) 
2023-05-25 23:38:02.488043: val Epoch: [44][ 6/72]	Time  1.109 ( 0.759)	Data  0.983 ( 0.622)	Loss 9.6103e-02 (1.2746e-01) 
2023-05-25 23:38:02.614001: val Epoch: [44][ 7/72]	Time  0.126 ( 0.679)	Data  0.001 ( 0.544)	Loss 1.2403e-01 (1.2703e-01) 
2023-05-25 23:38:03.718396: val Epoch: [44][ 8/72]	Time  1.104 ( 0.727)	Data  0.979 ( 0.593)	Loss 9.5580e-02 (1.2354e-01) 
2023-05-25 23:38:03.843261: val Epoch: [44][ 9/72]	Time  0.125 ( 0.667)	Data  0.001 ( 0.533)	Loss 5.1383e-02 (1.1632e-01) 
2023-05-25 23:38:04.934130: val Epoch: [44][10/72]	Time  1.091 ( 0.705)	Data  0.966 ( 0.573)	Loss 1.5336e-01 (1.1969e-01) 
2023-05-25 23:38:05.059211: val Epoch: [44][11/72]	Time  0.125 ( 0.657)	Data  0.001 ( 0.525)	Loss 4.1453e-02 (1.1317e-01) 
2023-05-25 23:38:06.099700: val Epoch: [44][12/72]	Time  1.040 ( 0.686)	Data  0.916 ( 0.555)	Loss 2.3683e-01 (1.2268e-01) 
2023-05-25 23:38:06.225055: val Epoch: [44][13/72]	Time  0.125 ( 0.646)	Data  0.001 ( 0.515)	Loss 4.8012e-02 (1.1735e-01) 
2023-05-25 23:38:07.263598: val Epoch: [44][14/72]	Time  1.039 ( 0.672)	Data  0.914 ( 0.542)	Loss 5.3977e-02 (1.1312e-01) 
2023-05-25 23:38:07.388012: val Epoch: [44][15/72]	Time  0.124 ( 0.638)	Data  0.001 ( 0.508)	Loss 5.9197e-02 (1.0975e-01) 
2023-05-25 23:38:08.454442: val Epoch: [44][16/72]	Time  1.066 ( 0.663)	Data  0.942 ( 0.534)	Loss 1.0016e-01 (1.0919e-01) 
2023-05-25 23:38:08.579094: val Epoch: [44][17/72]	Time  0.125 ( 0.633)	Data  0.001 ( 0.504)	Loss 8.3736e-02 (1.0778e-01) 
2023-05-25 23:38:09.644819: val Epoch: [44][18/72]	Time  1.066 ( 0.656)	Data  0.941 ( 0.527)	Loss 7.6967e-02 (1.0615e-01) 
2023-05-25 23:38:09.769091: val Epoch: [44][19/72]	Time  0.124 ( 0.630)	Data  0.001 ( 0.501)	Loss 8.8559e-02 (1.0527e-01) 
2023-05-25 23:38:10.827750: val Epoch: [44][20/72]	Time  1.059 ( 0.650)	Data  0.933 ( 0.521)	Loss 5.7514e-02 (1.0300e-01) 
2023-05-25 23:38:10.952404: val Epoch: [44][21/72]	Time  0.125 ( 0.626)	Data  0.001 ( 0.498)	Loss 9.6805e-02 (1.0272e-01) 
2023-05-25 23:38:12.010694: val Epoch: [44][22/72]	Time  1.058 ( 0.645)	Data  0.934 ( 0.517)	Loss 4.1745e-02 (1.0007e-01) 
2023-05-25 23:38:12.135363: val Epoch: [44][23/72]	Time  0.125 ( 0.623)	Data  0.001 ( 0.495)	Loss 3.5137e-01 (1.1054e-01) 
2023-05-25 23:38:13.214874: val Epoch: [44][24/72]	Time  1.080 ( 0.641)	Data  0.955 ( 0.514)	Loss 5.5291e-02 (1.0833e-01) 
2023-05-25 23:38:13.341185: val Epoch: [44][25/72]	Time  0.126 ( 0.622)	Data  0.001 ( 0.494)	Loss 1.2367e-01 (1.0892e-01) 
2023-05-25 23:38:14.363906: val Epoch: [44][26/72]	Time  1.023 ( 0.637)	Data  0.897 ( 0.509)	Loss 5.6985e-02 (1.0699e-01) 
2023-05-25 23:38:14.489052: val Epoch: [44][27/72]	Time  0.125 ( 0.618)	Data  0.001 ( 0.491)	Loss 3.3760e-01 (1.1523e-01) 
2023-05-25 23:38:15.551536: val Epoch: [44][28/72]	Time  1.062 ( 0.634)	Data  0.938 ( 0.506)	Loss 1.9730e-01 (1.1806e-01) 
2023-05-25 23:38:15.676273: val Epoch: [44][29/72]	Time  0.125 ( 0.617)	Data  0.001 ( 0.489)	Loss 5.3992e-02 (1.1593e-01) 
2023-05-25 23:38:16.721346: val Epoch: [44][30/72]	Time  1.045 ( 0.630)	Data  0.921 ( 0.503)	Loss 2.6862e-01 (1.2085e-01) 
2023-05-25 23:38:16.845882: val Epoch: [44][31/72]	Time  0.125 ( 0.615)	Data  0.001 ( 0.487)	Loss 3.2494e-01 (1.2723e-01) 
2023-05-25 23:38:17.962306: val Epoch: [44][32/72]	Time  1.116 ( 0.630)	Data  0.993 ( 0.503)	Loss 7.1230e-02 (1.2553e-01) 
2023-05-25 23:38:18.086550: val Epoch: [44][33/72]	Time  0.124 ( 0.615)	Data  0.001 ( 0.488)	Loss 7.0110e-02 (1.2390e-01) 
2023-05-25 23:38:19.170884: val Epoch: [44][34/72]	Time  1.084 ( 0.628)	Data  0.959 ( 0.501)	Loss 8.6446e-02 (1.2283e-01) 
2023-05-25 23:38:19.296306: val Epoch: [44][35/72]	Time  0.125 ( 0.614)	Data  0.001 ( 0.487)	Loss 3.2652e-01 (1.2849e-01) 
2023-05-25 23:38:20.359884: val Epoch: [44][36/72]	Time  1.064 ( 0.627)	Data  0.939 ( 0.500)	Loss 5.4993e-02 (1.2650e-01) 
2023-05-25 23:38:20.484781: val Epoch: [44][37/72]	Time  0.125 ( 0.613)	Data  0.001 ( 0.487)	Loss 5.9754e-02 (1.2475e-01) 
2023-05-25 23:38:21.620638: val Epoch: [44][38/72]	Time  1.136 ( 0.627)	Data  1.012 ( 0.500)	Loss 5.3452e-02 (1.2292e-01) 
2023-05-25 23:38:21.745167: val Epoch: [44][39/72]	Time  0.125 ( 0.614)	Data  0.000 ( 0.488)	Loss 4.8175e-02 (1.2105e-01) 
2023-05-25 23:38:22.863363: val Epoch: [44][40/72]	Time  1.118 ( 0.626)	Data  0.994 ( 0.500)	Loss 1.9250e-01 (1.2279e-01) 
2023-05-25 23:38:22.987661: val Epoch: [44][41/72]	Time  0.124 ( 0.615)	Data  0.001 ( 0.488)	Loss 1.1249e-01 (1.2255e-01) 
2023-05-25 23:38:24.052473: val Epoch: [44][42/72]	Time  1.065 ( 0.625)	Data  0.940 ( 0.499)	Loss 6.4580e-02 (1.2120e-01) 
2023-05-25 23:38:24.176893: val Epoch: [44][43/72]	Time  0.124 ( 0.614)	Data  0.000 ( 0.487)	Loss 1.4330e-01 (1.2170e-01) 
2023-05-25 23:38:25.291667: val Epoch: [44][44/72]	Time  1.115 ( 0.625)	Data  0.992 ( 0.498)	Loss 1.0809e-01 (1.2140e-01) 
2023-05-25 23:38:25.410880: val Epoch: [44][45/72]	Time  0.119 ( 0.614)	Data  0.000 ( 0.488)	Loss 9.6007e-02 (1.2085e-01) 
2023-05-25 23:38:26.540828: val Epoch: [44][46/72]	Time  1.130 ( 0.625)	Data  1.011 ( 0.499)	Loss 7.8791e-02 (1.1995e-01) 
2023-05-25 23:38:26.660561: val Epoch: [44][47/72]	Time  0.120 ( 0.614)	Data  0.000 ( 0.488)	Loss 9.8128e-02 (1.1950e-01) 
2023-05-25 23:38:27.710927: val Epoch: [44][48/72]	Time  1.050 ( 0.623)	Data  0.931 ( 0.497)	Loss 3.3350e-02 (1.1774e-01) 
2023-05-25 23:38:27.830064: val Epoch: [44][49/72]	Time  0.119 ( 0.613)	Data  0.000 ( 0.487)	Loss 4.6732e-02 (1.1632e-01) 
2023-05-25 23:38:28.895045: val Epoch: [44][50/72]	Time  1.065 ( 0.622)	Data  0.946 ( 0.496)	Loss 1.4683e-01 (1.1692e-01) 
2023-05-25 23:38:29.014453: val Epoch: [44][51/72]	Time  0.119 ( 0.612)	Data  0.000 ( 0.487)	Loss 3.9820e-01 (1.2233e-01) 
2023-05-25 23:38:30.133256: val Epoch: [44][52/72]	Time  1.119 ( 0.622)	Data  0.999 ( 0.497)	Loss 6.4658e-02 (1.2124e-01) 
2023-05-25 23:38:30.253057: val Epoch: [44][53/72]	Time  0.120 ( 0.612)	Data  0.000 ( 0.487)	Loss 5.2114e-02 (1.1996e-01) 
2023-05-25 23:38:31.295841: val Epoch: [44][54/72]	Time  1.043 ( 0.620)	Data  0.923 ( 0.495)	Loss 1.0782e-01 (1.1974e-01) 
2023-05-25 23:38:31.415559: val Epoch: [44][55/72]	Time  0.120 ( 0.611)	Data  0.001 ( 0.486)	Loss 1.3051e-01 (1.1993e-01) 
2023-05-25 23:38:32.530124: val Epoch: [44][56/72]	Time  1.115 ( 0.620)	Data  0.995 ( 0.495)	Loss 3.5149e-01 (1.2399e-01) 
2023-05-25 23:38:32.649878: val Epoch: [44][57/72]	Time  0.120 ( 0.612)	Data  0.001 ( 0.487)	Loss 4.2026e-02 (1.2258e-01) 
2023-05-25 23:38:33.714630: val Epoch: [44][58/72]	Time  1.065 ( 0.619)	Data  0.945 ( 0.495)	Loss 6.8456e-02 (1.2166e-01) 
2023-05-25 23:38:33.834038: val Epoch: [44][59/72]	Time  0.119 ( 0.611)	Data  0.000 ( 0.486)	Loss 7.9208e-02 (1.2095e-01) 
2023-05-25 23:38:34.915344: val Epoch: [44][60/72]	Time  1.081 ( 0.619)	Data  0.961 ( 0.494)	Loss 3.5804e-02 (1.1956e-01) 
2023-05-25 23:38:35.035486: val Epoch: [44][61/72]	Time  0.120 ( 0.611)	Data  0.001 ( 0.486)	Loss 4.9143e-02 (1.1842e-01) 
2023-05-25 23:38:36.050814: val Epoch: [44][62/72]	Time  1.015 ( 0.617)	Data  0.896 ( 0.493)	Loss 3.9903e-02 (1.1718e-01) 
2023-05-25 23:38:36.169982: val Epoch: [44][63/72]	Time  0.119 ( 0.609)	Data  0.001 ( 0.485)	Loss 2.5698e-01 (1.1936e-01) 
2023-05-25 23:38:37.236391: val Epoch: [44][64/72]	Time  1.066 ( 0.616)	Data  0.946 ( 0.492)	Loss 7.3187e-02 (1.1865e-01) 
2023-05-25 23:38:37.356310: val Epoch: [44][65/72]	Time  0.120 ( 0.609)	Data  0.001 ( 0.485)	Loss 4.1573e-02 (1.1748e-01) 
2023-05-25 23:38:38.477653: val Epoch: [44][66/72]	Time  1.121 ( 0.616)	Data  1.000 ( 0.492)	Loss 2.4534e-01 (1.1939e-01) 
2023-05-25 23:38:38.602746: val Epoch: [44][67/72]	Time  0.125 ( 0.609)	Data  0.001 ( 0.485)	Loss 1.1420e-01 (1.1932e-01) 
2023-05-25 23:38:39.721225: val Epoch: [44][68/72]	Time  1.118 ( 0.617)	Data  0.994 ( 0.492)	Loss 1.7732e-01 (1.2016e-01) 
2023-05-25 23:38:39.846288: val Epoch: [44][69/72]	Time  0.125 ( 0.610)	Data  0.000 ( 0.485)	Loss 4.6041e-01 (1.2502e-01) 
2023-05-25 23:38:40.823579: val Epoch: [44][70/72]	Time  0.977 ( 0.615)	Data  0.853 ( 0.491)	Loss 7.7042e-02 (1.2434e-01) 
2023-05-25 23:38:40.948498: val Epoch: [44][71/72]	Time  0.125 ( 0.608)	Data  0.000 ( 0.484)	Loss 5.5835e-02 (1.2339e-01) 
2023-05-25 23:38:41.149445: Epoch 44 :Val : ['ET : 0.7534275650978088', 'TC : 0.7969837188720703', 'WT : 0.8699005842208862'] 
2023-05-25 23:38:41.156433: Epoch 44 :Val : ['ET : 0.7534275650978088', 'TC : 0.7969837188720703', 'WT : 0.8699005842208862'] 
2023-05-25 23:38:41.160025: Saving the model with DSC 0.8089377284049988 
2023-05-25 23:38:41.829886: Val epoch done in 45.388393779998296 s 
2023-05-25 23:38:41.835543: Batches per epoch:  129 
2023-05-25 23:38:46.655981: train Epoch: [45][  0/129]	Time  4.820 ( 4.820)	Data  3.810 ( 3.810)	Loss 1.2797e-01 (1.2797e-01) 
2023-05-25 23:38:47.605265: train Epoch: [45][  1/129]	Time  0.949 ( 2.885)	Data  0.001 ( 1.906)	Loss 9.8252e-02 (1.1311e-01) 
2023-05-25 23:38:50.174870: train Epoch: [45][  2/129]	Time  2.570 ( 2.780)	Data  1.613 ( 1.808)	Loss 4.1480e-02 (8.9233e-02) 
2023-05-25 23:38:51.126039: train Epoch: [45][  3/129]	Time  0.951 ( 2.323)	Data  0.001 ( 1.356)	Loss 4.6256e-02 (7.8489e-02) 
2023-05-25 23:38:53.672442: train Epoch: [45][  4/129]	Time  2.546 ( 2.367)	Data  1.598 ( 1.405)	Loss 6.1275e-02 (7.5046e-02) 
2023-05-25 23:38:54.624873: train Epoch: [45][  5/129]	Time  0.952 ( 2.132)	Data  0.001 ( 1.171)	Loss 1.1565e-01 (8.1813e-02) 
2023-05-25 23:38:57.332003: train Epoch: [45][  6/129]	Time  2.707 ( 2.214)	Data  1.759 ( 1.255)	Loss 5.6383e-02 (7.8180e-02) 
2023-05-25 23:38:58.283091: train Epoch: [45][  7/129]	Time  0.951 ( 2.056)	Data  0.001 ( 1.098)	Loss 1.0606e-01 (8.1665e-02) 
2023-05-25 23:39:00.931999: train Epoch: [45][  8/129]	Time  2.649 ( 2.122)	Data  1.698 ( 1.165)	Loss 5.0039e-02 (7.8151e-02) 
2023-05-25 23:39:01.882609: train Epoch: [45][  9/129]	Time  0.951 ( 2.005)	Data  0.001 ( 1.048)	Loss 6.4233e-02 (7.6759e-02) 
2023-05-25 23:39:04.651936: train Epoch: [45][ 10/129]	Time  2.769 ( 2.074)	Data  1.814 ( 1.118)	Loss 9.8841e-02 (7.8766e-02) 
2023-05-25 23:39:05.602604: train Epoch: [45][ 11/129]	Time  0.951 ( 1.981)	Data  0.001 ( 1.025)	Loss 7.1881e-02 (7.8193e-02) 
2023-05-25 23:39:08.308650: train Epoch: [45][ 12/129]	Time  2.706 ( 2.036)	Data  1.757 ( 1.081)	Loss 6.5363e-02 (7.7206e-02) 
2023-05-25 23:39:09.259822: train Epoch: [45][ 13/129]	Time  0.951 ( 1.959)	Data  0.001 ( 1.004)	Loss 6.4448e-02 (7.6294e-02) 
2023-05-25 23:39:11.935736: train Epoch: [45][ 14/129]	Time  2.676 ( 2.007)	Data  1.721 ( 1.052)	Loss 8.9777e-02 (7.7193e-02) 
2023-05-25 23:39:12.886094: train Epoch: [45][ 15/129]	Time  0.950 ( 1.941)	Data  0.001 ( 0.986)	Loss 7.4076e-02 (7.6998e-02) 
2023-05-25 23:39:15.456354: train Epoch: [45][ 16/129]	Time  2.570 ( 1.978)	Data  1.621 ( 1.023)	Loss 5.4326e-02 (7.5665e-02) 
2023-05-25 23:39:16.408114: train Epoch: [45][ 17/129]	Time  0.952 ( 1.921)	Data  0.001 ( 0.967)	Loss 8.9455e-02 (7.6431e-02) 
2023-05-25 23:39:19.089187: train Epoch: [45][ 18/129]	Time  2.681 ( 1.961)	Data  1.721 ( 1.006)	Loss 6.7273e-02 (7.5949e-02) 
2023-05-25 23:39:20.051813: train Epoch: [45][ 19/129]	Time  0.963 ( 1.911)	Data  0.001 ( 0.956)	Loss 8.6861e-02 (7.6494e-02) 
2023-05-25 23:39:22.733160: train Epoch: [45][ 20/129]	Time  2.681 ( 1.947)	Data  1.721 ( 0.992)	Loss 1.1216e-01 (7.8193e-02) 
2023-05-25 23:39:23.694468: train Epoch: [45][ 21/129]	Time  0.961 ( 1.903)	Data  0.001 ( 0.947)	Loss 5.5995e-02 (7.7184e-02) 
2023-05-25 23:39:26.399684: train Epoch: [45][ 22/129]	Time  2.705 ( 1.938)	Data  1.746 ( 0.982)	Loss 5.9733e-02 (7.6425e-02) 
2023-05-25 23:39:27.361166: train Epoch: [45][ 23/129]	Time  0.961 ( 1.897)	Data  0.001 ( 0.941)	Loss 9.1946e-02 (7.7072e-02) 
2023-05-25 23:39:30.080909: train Epoch: [45][ 24/129]	Time  2.720 ( 1.930)	Data  1.749 ( 0.973)	Loss 1.3425e-01 (7.9359e-02) 
2023-05-25 23:39:31.042263: train Epoch: [45][ 25/129]	Time  0.961 ( 1.893)	Data  0.001 ( 0.936)	Loss 7.1900e-02 (7.9072e-02) 
2023-05-25 23:39:33.671036: train Epoch: [45][ 26/129]	Time  2.629 ( 1.920)	Data  1.670 ( 0.963)	Loss 4.6746e-02 (7.7875e-02) 
2023-05-25 23:39:34.622049: train Epoch: [45][ 27/129]	Time  0.951 ( 1.885)	Data  0.001 ( 0.929)	Loss 8.7719e-02 (7.8226e-02) 
2023-05-25 23:39:37.338135: train Epoch: [45][ 28/129]	Time  2.716 ( 1.914)	Data  1.769 ( 0.958)	Loss 8.1087e-02 (7.8325e-02) 
2023-05-25 23:39:38.290993: train Epoch: [45][ 29/129]	Time  0.953 ( 1.882)	Data  0.001 ( 0.926)	Loss 8.2131e-02 (7.8452e-02) 
2023-05-25 23:39:40.870046: train Epoch: [45][ 30/129]	Time  2.579 ( 1.904)	Data  1.628 ( 0.949)	Loss 8.2530e-02 (7.8583e-02) 
2023-05-25 23:39:41.831827: train Epoch: [45][ 31/129]	Time  0.962 ( 1.875)	Data  0.001 ( 0.919)	Loss 5.6585e-02 (7.7896e-02) 
2023-05-25 23:39:44.592032: train Epoch: [45][ 32/129]	Time  2.760 ( 1.902)	Data  1.795 ( 0.946)	Loss 1.4262e-01 (7.9857e-02) 
2023-05-25 23:39:45.554252: train Epoch: [45][ 33/129]	Time  0.962 ( 1.874)	Data  0.001 ( 0.918)	Loss 7.5523e-02 (7.9730e-02) 
2023-05-25 23:39:48.207769: train Epoch: [45][ 34/129]	Time  2.654 ( 1.896)	Data  1.683 ( 0.940)	Loss 5.3978e-02 (7.8994e-02) 
2023-05-25 23:39:49.168248: train Epoch: [45][ 35/129]	Time  0.960 ( 1.870)	Data  0.001 ( 0.914)	Loss 1.1844e-01 (8.0090e-02) 
2023-05-25 23:39:51.829349: train Epoch: [45][ 36/129]	Time  2.661 ( 1.892)	Data  1.699 ( 0.935)	Loss 5.9458e-02 (7.9532e-02) 
2023-05-25 23:39:52.790428: train Epoch: [45][ 37/129]	Time  0.961 ( 1.867)	Data  0.001 ( 0.910)	Loss 6.3818e-02 (7.9119e-02) 
2023-05-25 23:39:55.524179: train Epoch: [45][ 38/129]	Time  2.734 ( 1.889)	Data  1.768 ( 0.932)	Loss 5.7893e-02 (7.8574e-02) 
2023-05-25 23:39:56.475667: train Epoch: [45][ 39/129]	Time  0.951 ( 1.866)	Data  0.001 ( 0.909)	Loss 8.4805e-02 (7.8730e-02) 
2023-05-25 23:39:59.001403: train Epoch: [45][ 40/129]	Time  2.526 ( 1.882)	Data  1.571 ( 0.925)	Loss 7.8014e-02 (7.8713e-02) 
2023-05-25 23:39:59.952543: train Epoch: [45][ 41/129]	Time  0.951 ( 1.860)	Data  0.001 ( 0.903)	Loss 6.4071e-02 (7.8364e-02) 
2023-05-25 23:40:02.604195: train Epoch: [45][ 42/129]	Time  2.652 ( 1.878)	Data  1.695 ( 0.921)	Loss 7.4886e-02 (7.8283e-02) 
2023-05-25 23:40:03.555429: train Epoch: [45][ 43/129]	Time  0.951 ( 1.857)	Data  0.001 ( 0.901)	Loss 1.0561e-01 (7.8904e-02) 
2023-05-25 23:40:06.464028: train Epoch: [45][ 44/129]	Time  2.909 ( 1.881)	Data  1.959 ( 0.924)	Loss 6.4475e-02 (7.8584e-02) 
2023-05-25 23:40:07.414326: train Epoch: [45][ 45/129]	Time  0.950 ( 1.860)	Data  0.001 ( 0.904)	Loss 7.7490e-02 (7.8560e-02) 
2023-05-25 23:40:10.104510: train Epoch: [45][ 46/129]	Time  2.690 ( 1.878)	Data  1.744 ( 0.922)	Loss 1.0447e-01 (7.9111e-02) 
2023-05-25 23:40:11.054688: train Epoch: [45][ 47/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.903)	Loss 5.3371e-02 (7.8575e-02) 
2023-05-25 23:40:13.759660: train Epoch: [45][ 48/129]	Time  2.705 ( 1.876)	Data  1.760 ( 0.920)	Loss 7.5508e-02 (7.8512e-02) 
2023-05-25 23:40:14.710140: train Epoch: [45][ 49/129]	Time  0.950 ( 1.857)	Data  0.001 ( 0.902)	Loss 8.0148e-02 (7.8545e-02) 
2023-05-25 23:40:17.348037: train Epoch: [45][ 50/129]	Time  2.638 ( 1.873)	Data  1.692 ( 0.917)	Loss 6.2427e-02 (7.8229e-02) 
2023-05-25 23:40:18.301427: train Epoch: [45][ 51/129]	Time  0.953 ( 1.855)	Data  0.001 ( 0.900)	Loss 1.1215e-01 (7.8881e-02) 
2023-05-25 23:40:20.951087: train Epoch: [45][ 52/129]	Time  2.650 ( 1.870)	Data  1.703 ( 0.915)	Loss 5.9163e-02 (7.8509e-02) 
2023-05-25 23:40:21.900617: train Epoch: [45][ 53/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.898)	Loss 8.0558e-02 (7.8547e-02) 
2023-05-25 23:40:24.640226: train Epoch: [45][ 54/129]	Time  2.740 ( 1.869)	Data  1.793 ( 0.914)	Loss 1.2582e-01 (7.9407e-02) 
2023-05-25 23:40:25.589559: train Epoch: [45][ 55/129]	Time  0.949 ( 1.853)	Data  0.001 ( 0.898)	Loss 8.9099e-02 (7.9580e-02) 
2023-05-25 23:40:28.219432: train Epoch: [45][ 56/129]	Time  2.630 ( 1.866)	Data  1.683 ( 0.912)	Loss 4.7559e-02 (7.9018e-02) 
2023-05-25 23:40:29.168509: train Epoch: [45][ 57/129]	Time  0.949 ( 1.851)	Data  0.001 ( 0.896)	Loss 6.0367e-02 (7.8697e-02) 
2023-05-25 23:40:31.701286: train Epoch: [45][ 58/129]	Time  2.533 ( 1.862)	Data  1.585 ( 0.908)	Loss 7.7299e-02 (7.8673e-02) 
2023-05-25 23:40:32.652466: train Epoch: [45][ 59/129]	Time  0.951 ( 1.847)	Data  0.001 ( 0.892)	Loss 1.0254e-01 (7.9071e-02) 
2023-05-25 23:40:35.267303: train Epoch: [45][ 60/129]	Time  2.615 ( 1.860)	Data  1.666 ( 0.905)	Loss 9.0717e-02 (7.9262e-02) 
2023-05-25 23:40:36.219035: train Epoch: [45][ 61/129]	Time  0.952 ( 1.845)	Data  0.001 ( 0.891)	Loss 6.3846e-02 (7.9013e-02) 
2023-05-25 23:40:38.843056: train Epoch: [45][ 62/129]	Time  2.624 ( 1.857)	Data  1.677 ( 0.903)	Loss 6.6262e-02 (7.8811e-02) 
2023-05-25 23:40:39.793459: train Epoch: [45][ 63/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.889)	Loss 9.0619e-02 (7.8995e-02) 
2023-05-25 23:40:42.477581: train Epoch: [45][ 64/129]	Time  2.684 ( 1.856)	Data  1.738 ( 0.902)	Loss 1.0838e-01 (7.9447e-02) 
2023-05-25 23:40:43.427489: train Epoch: [45][ 65/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.888)	Loss 8.2943e-02 (7.9500e-02) 
2023-05-25 23:40:46.109024: train Epoch: [45][ 66/129]	Time  2.682 ( 1.855)	Data  1.735 ( 0.901)	Loss 6.5191e-02 (7.9286e-02) 
2023-05-25 23:40:47.057856: train Epoch: [45][ 67/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.888)	Loss 9.8508e-02 (7.9569e-02) 
2023-05-25 23:40:49.686190: train Epoch: [45][ 68/129]	Time  2.628 ( 1.853)	Data  1.681 ( 0.899)	Loss 7.1944e-02 (7.9459e-02) 
2023-05-25 23:40:50.636315: train Epoch: [45][ 69/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.886)	Loss 7.1745e-02 (7.9348e-02) 
2023-05-25 23:40:53.212200: train Epoch: [45][ 70/129]	Time  2.576 ( 1.850)	Data  1.628 ( 0.897)	Loss 1.0505e-01 (7.9710e-02) 
2023-05-25 23:40:54.162822: train Epoch: [45][ 71/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.884)	Loss 8.5382e-02 (7.9789e-02) 
2023-05-25 23:40:56.891445: train Epoch: [45][ 72/129]	Time  2.729 ( 1.850)	Data  1.781 ( 0.897)	Loss 1.0053e-01 (8.0073e-02) 
2023-05-25 23:40:57.840623: train Epoch: [45][ 73/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.885)	Loss 9.3055e-02 (8.0249e-02) 
2023-05-25 23:41:00.548429: train Epoch: [45][ 74/129]	Time  2.708 ( 1.849)	Data  1.760 ( 0.896)	Loss 9.0785e-02 (8.0389e-02) 
2023-05-25 23:41:01.499612: train Epoch: [45][ 75/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.884)	Loss 8.7187e-02 (8.0479e-02) 
2023-05-25 23:41:04.148670: train Epoch: [45][ 76/129]	Time  2.649 ( 1.848)	Data  1.703 ( 0.895)	Loss 8.1131e-02 (8.0487e-02) 
2023-05-25 23:41:05.100490: train Epoch: [45][ 77/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.884)	Loss 5.2318e-02 (8.0126e-02) 
2023-05-25 23:41:07.786628: train Epoch: [45][ 78/129]	Time  2.686 ( 1.847)	Data  1.739 ( 0.894)	Loss 1.4360e-01 (8.0929e-02) 
2023-05-25 23:41:08.735556: train Epoch: [45][ 79/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.883)	Loss 6.0105e-02 (8.0669e-02) 
2023-05-25 23:41:11.435889: train Epoch: [45][ 80/129]	Time  2.700 ( 1.847)	Data  1.754 ( 0.894)	Loss 9.2957e-02 (8.0821e-02) 
2023-05-25 23:41:12.386305: train Epoch: [45][ 81/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.883)	Loss 7.0117e-02 (8.0690e-02) 
2023-05-25 23:41:15.006288: train Epoch: [45][ 82/129]	Time  2.620 ( 1.845)	Data  1.672 ( 0.893)	Loss 9.7464e-02 (8.0892e-02) 
2023-05-25 23:41:15.954498: train Epoch: [45][ 83/129]	Time  0.948 ( 1.835)	Data  0.001 ( 0.882)	Loss 9.0100e-02 (8.1002e-02) 
2023-05-25 23:41:18.628055: train Epoch: [45][ 84/129]	Time  2.674 ( 1.845)	Data  1.726 ( 0.892)	Loss 7.3446e-02 (8.0913e-02) 
2023-05-25 23:41:19.577234: train Epoch: [45][ 85/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.882)	Loss 1.3679e-01 (8.1563e-02) 
2023-05-25 23:41:22.262778: train Epoch: [45][ 86/129]	Time  2.686 ( 1.844)	Data  1.739 ( 0.891)	Loss 5.2929e-02 (8.1234e-02) 
2023-05-25 23:41:23.215877: train Epoch: [45][ 87/129]	Time  0.953 ( 1.834)	Data  0.001 ( 0.881)	Loss 9.6498e-02 (8.1407e-02) 
2023-05-25 23:41:25.935824: train Epoch: [45][ 88/129]	Time  2.720 ( 1.844)	Data  1.768 ( 0.891)	Loss 1.0824e-01 (8.1709e-02) 
2023-05-25 23:41:26.885509: train Epoch: [45][ 89/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.881)	Loss 1.1761e-01 (8.2108e-02) 
2023-05-25 23:41:29.647471: train Epoch: [45][ 90/129]	Time  2.762 ( 1.844)	Data  1.815 ( 0.892)	Loss 8.7589e-02 (8.2168e-02) 
2023-05-25 23:41:30.594640: train Epoch: [45][ 91/129]	Time  0.947 ( 1.834)	Data  0.001 ( 0.882)	Loss 8.9030e-02 (8.2242e-02) 
2023-05-25 23:41:33.205637: train Epoch: [45][ 92/129]	Time  2.611 ( 1.843)	Data  1.666 ( 0.890)	Loss 7.7265e-02 (8.2189e-02) 
2023-05-25 23:41:34.154632: train Epoch: [45][ 93/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.881)	Loss 1.2286e-01 (8.2621e-02) 
2023-05-25 23:41:36.836149: train Epoch: [45][ 94/129]	Time  2.682 ( 1.842)	Data  1.733 ( 0.890)	Loss 7.2339e-02 (8.2513e-02) 
2023-05-25 23:41:37.786207: train Epoch: [45][ 95/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.881)	Loss 7.6932e-02 (8.2455e-02) 
2023-05-25 23:41:40.336129: train Epoch: [45][ 96/129]	Time  2.550 ( 1.840)	Data  1.604 ( 0.888)	Loss 3.1895e-02 (8.1934e-02) 
2023-05-25 23:41:41.285104: train Epoch: [45][ 97/129]	Time  0.949 ( 1.831)	Data  0.001 ( 0.879)	Loss 1.0517e-01 (8.2171e-02) 
2023-05-25 23:41:43.969521: train Epoch: [45][ 98/129]	Time  2.684 ( 1.840)	Data  1.737 ( 0.888)	Loss 5.9027e-02 (8.1937e-02) 
2023-05-25 23:41:44.916971: train Epoch: [45][ 99/129]	Time  0.947 ( 1.831)	Data  0.001 ( 0.879)	Loss 1.1611e-01 (8.2279e-02) 
2023-05-25 23:41:47.522694: train Epoch: [45][100/129]	Time  2.606 ( 1.838)	Data  1.661 ( 0.887)	Loss 8.3574e-02 (8.2292e-02) 
2023-05-25 23:41:48.477508: train Epoch: [45][101/129]	Time  0.955 ( 1.830)	Data  0.001 ( 0.878)	Loss 7.0237e-02 (8.2174e-02) 
2023-05-25 23:41:51.127565: train Epoch: [45][102/129]	Time  2.650 ( 1.838)	Data  1.702 ( 0.886)	Loss 8.9515e-02 (8.2245e-02) 
2023-05-25 23:41:52.077697: train Epoch: [45][103/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.877)	Loss 1.0687e-01 (8.2482e-02) 
2023-05-25 23:41:54.784029: train Epoch: [45][104/129]	Time  2.706 ( 1.838)	Data  1.761 ( 0.886)	Loss 1.1482e-01 (8.2790e-02) 
2023-05-25 23:41:55.732158: train Epoch: [45][105/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.877)	Loss 3.8135e-02 (8.2368e-02) 
2023-05-25 23:41:58.359461: train Epoch: [45][106/129]	Time  2.627 ( 1.837)	Data  1.681 ( 0.885)	Loss 1.3844e-01 (8.2892e-02) 
2023-05-25 23:41:59.308413: train Epoch: [45][107/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.877)	Loss 1.4088e-01 (8.3429e-02) 
2023-05-25 23:42:01.941229: train Epoch: [45][108/129]	Time  2.633 ( 1.836)	Data  1.686 ( 0.884)	Loss 7.5078e-02 (8.3353e-02) 
2023-05-25 23:42:02.890530: train Epoch: [45][109/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.876)	Loss 9.7034e-02 (8.3477e-02) 
2023-05-25 23:42:05.512599: train Epoch: [45][110/129]	Time  2.622 ( 1.835)	Data  1.676 ( 0.883)	Loss 8.5180e-02 (8.3492e-02) 
2023-05-25 23:42:06.463676: train Epoch: [45][111/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.876)	Loss 9.5175e-02 (8.3597e-02) 
2023-05-25 23:42:09.141006: train Epoch: [45][112/129]	Time  2.677 ( 1.835)	Data  1.729 ( 0.883)	Loss 6.0313e-02 (8.3391e-02) 
2023-05-25 23:42:10.093983: train Epoch: [45][113/129]	Time  0.953 ( 1.827)	Data  0.001 ( 0.875)	Loss 4.9843e-02 (8.3096e-02) 
2023-05-25 23:42:12.875153: train Epoch: [45][114/129]	Time  2.781 ( 1.835)	Data  1.829 ( 0.884)	Loss 1.2362e-01 (8.3449e-02) 
2023-05-25 23:42:13.826114: train Epoch: [45][115/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.876)	Loss 7.4414e-02 (8.3371e-02) 
2023-05-25 23:42:16.509832: train Epoch: [45][116/129]	Time  2.684 ( 1.835)	Data  1.735 ( 0.883)	Loss 8.2421e-02 (8.3363e-02) 
2023-05-25 23:42:17.460991: train Epoch: [45][117/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.876)	Loss 1.1739e-01 (8.3651e-02) 
2023-05-25 23:42:19.975340: train Epoch: [45][118/129]	Time  2.514 ( 1.833)	Data  1.564 ( 0.882)	Loss 5.5549e-02 (8.3415e-02) 
2023-05-25 23:42:20.926396: train Epoch: [45][119/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.874)	Loss 7.3870e-02 (8.3336e-02) 
2023-05-25 23:42:23.584629: train Epoch: [45][120/129]	Time  2.658 ( 1.833)	Data  1.709 ( 0.881)	Loss 1.4643e-01 (8.3857e-02) 
2023-05-25 23:42:24.535040: train Epoch: [45][121/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.874)	Loss 6.9134e-02 (8.3736e-02) 
2023-05-25 23:42:27.150248: train Epoch: [45][122/129]	Time  2.615 ( 1.832)	Data  1.668 ( 0.880)	Loss 9.6622e-02 (8.3841e-02) 
2023-05-25 23:42:28.100448: train Epoch: [45][123/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.873)	Loss 4.5296e-02 (8.3530e-02) 
2023-05-25 23:42:30.818894: train Epoch: [45][124/129]	Time  2.718 ( 1.832)	Data  1.770 ( 0.881)	Loss 1.4342e-01 (8.4009e-02) 
2023-05-25 23:42:31.768549: train Epoch: [45][125/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.874)	Loss 9.2263e-02 (8.4075e-02) 
2023-05-25 23:42:34.381622: train Epoch: [45][126/129]	Time  2.613 ( 1.831)	Data  1.662 ( 0.880)	Loss 1.0892e-01 (8.4271e-02) 
2023-05-25 23:42:35.341081: train Epoch: [45][127/129]	Time  0.959 ( 1.824)	Data  0.001 ( 0.873)	Loss 7.4628e-02 (8.4195e-02) 
2023-05-25 23:42:37.011071: train Epoch: [45][128/129]	Time  1.670 ( 1.823)	Data  0.714 ( 0.872)	Loss 1.5904e-01 (8.4775e-02) 
2023-05-25 23:42:37.042711: Train Epoch done in 235.20721379500173 s 
2023-05-25 23:42:39.287193: val Epoch: [45][ 0/72]	Time  1.528 ( 1.528)	Data  1.339 ( 1.339)	Loss 6.4554e-02 (6.4554e-02) 
2023-05-25 23:42:39.407494: val Epoch: [45][ 1/72]	Time  0.120 ( 0.824)	Data  0.001 ( 0.670)	Loss 3.4562e-01 (2.0509e-01) 
2023-05-25 23:42:40.457711: val Epoch: [45][ 2/72]	Time  1.050 ( 0.900)	Data  0.924 ( 0.755)	Loss 9.8793e-02 (1.6966e-01) 
2023-05-25 23:42:40.578171: val Epoch: [45][ 3/72]	Time  0.120 ( 0.705)	Data  0.001 ( 0.566)	Loss 3.8959e-02 (1.3698e-01) 
2023-05-25 23:42:41.631457: val Epoch: [45][ 4/72]	Time  1.053 ( 0.775)	Data  0.932 ( 0.639)	Loss 5.8549e-02 (1.2129e-01) 
2023-05-25 23:42:41.826476: val Epoch: [45][ 5/72]	Time  0.195 ( 0.678)	Data  0.069 ( 0.544)	Loss 7.2858e-02 (1.1322e-01) 
2023-05-25 23:42:42.828268: val Epoch: [45][ 6/72]	Time  1.002 ( 0.724)	Data  0.875 ( 0.592)	Loss 1.3080e-01 (1.1573e-01) 
2023-05-25 23:42:43.084954: val Epoch: [45][ 7/72]	Time  0.257 ( 0.666)	Data  0.130 ( 0.534)	Loss 3.7466e-01 (1.4810e-01) 
2023-05-25 23:42:44.054508: val Epoch: [45][ 8/72]	Time  0.970 ( 0.700)	Data  0.843 ( 0.568)	Loss 1.4846e-01 (1.4814e-01) 
2023-05-25 23:42:44.308378: val Epoch: [45][ 9/72]	Time  0.254 ( 0.655)	Data  0.129 ( 0.524)	Loss 1.9805e-01 (1.5313e-01) 
2023-05-25 23:42:45.295116: val Epoch: [45][10/72]	Time  0.987 ( 0.685)	Data  0.860 ( 0.555)	Loss 3.1605e-01 (1.6794e-01) 
2023-05-25 23:42:45.470540: val Epoch: [45][11/72]	Time  0.175 ( 0.643)	Data  0.050 ( 0.513)	Loss 4.0945e-02 (1.5736e-01) 
2023-05-25 23:42:46.540679: val Epoch: [45][12/72]	Time  1.070 ( 0.676)	Data  0.944 ( 0.546)	Loss 3.9921e-01 (1.7596e-01) 
2023-05-25 23:42:46.712660: val Epoch: [45][13/72]	Time  0.172 ( 0.640)	Data  0.047 ( 0.510)	Loss 4.1838e-01 (1.9328e-01) 
2023-05-25 23:42:47.813597: val Epoch: [45][14/72]	Time  1.101 ( 0.670)	Data  0.969 ( 0.541)	Loss 7.1493e-02 (1.8516e-01) 
2023-05-25 23:42:47.939533: val Epoch: [45][15/72]	Time  0.126 ( 0.636)	Data  0.001 ( 0.507)	Loss 6.6708e-02 (1.7776e-01) 
2023-05-25 23:42:49.093034: val Epoch: [45][16/72]	Time  1.153 ( 0.667)	Data  1.025 ( 0.538)	Loss 7.6440e-02 (1.7180e-01) 
2023-05-25 23:42:49.218511: val Epoch: [45][17/72]	Time  0.125 ( 0.637)	Data  0.001 ( 0.508)	Loss 2.5424e-01 (1.7638e-01) 
2023-05-25 23:42:50.317666: val Epoch: [45][18/72]	Time  1.099 ( 0.661)	Data  0.968 ( 0.532)	Loss 6.3518e-02 (1.7044e-01) 
2023-05-25 23:42:50.442983: val Epoch: [45][19/72]	Time  0.125 ( 0.634)	Data  0.001 ( 0.505)	Loss 5.4256e-02 (1.6463e-01) 
2023-05-25 23:42:51.561731: val Epoch: [45][20/72]	Time  1.119 ( 0.657)	Data  0.992 ( 0.529)	Loss 7.1733e-02 (1.6020e-01) 
2023-05-25 23:42:51.687007: val Epoch: [45][21/72]	Time  0.125 ( 0.633)	Data  0.001 ( 0.505)	Loss 3.3917e-01 (1.6834e-01) 
2023-05-25 23:42:52.772297: val Epoch: [45][22/72]	Time  1.085 ( 0.653)	Data  0.960 ( 0.524)	Loss 5.6910e-02 (1.6349e-01) 
2023-05-25 23:42:52.902249: val Epoch: [45][23/72]	Time  0.130 ( 0.631)	Data  0.006 ( 0.503)	Loss 4.0185e-01 (1.7343e-01) 
2023-05-25 23:42:54.004693: val Epoch: [45][24/72]	Time  1.102 ( 0.650)	Data  0.977 ( 0.522)	Loss 3.6505e-02 (1.6795e-01) 
2023-05-25 23:42:54.170106: val Epoch: [45][25/72]	Time  0.165 ( 0.631)	Data  0.041 ( 0.503)	Loss 5.8535e-02 (1.6374e-01) 
2023-05-25 23:42:55.207080: val Epoch: [45][26/72]	Time  1.037 ( 0.646)	Data  0.911 ( 0.518)	Loss 5.7539e-02 (1.5981e-01) 
2023-05-25 23:42:55.397414: val Epoch: [45][27/72]	Time  0.190 ( 0.630)	Data  0.066 ( 0.502)	Loss 3.6082e-02 (1.5539e-01) 
2023-05-25 23:42:56.401745: val Epoch: [45][28/72]	Time  1.004 ( 0.643)	Data  0.879 ( 0.515)	Loss 5.7514e-02 (1.5201e-01) 
2023-05-25 23:42:56.641310: val Epoch: [45][29/72]	Time  0.240 ( 0.629)	Data  0.116 ( 0.502)	Loss 1.3667e-01 (1.5150e-01) 
2023-05-25 23:42:57.604417: val Epoch: [45][30/72]	Time  0.963 ( 0.640)	Data  0.840 ( 0.513)	Loss 6.2351e-02 (1.4863e-01) 
2023-05-25 23:42:57.835243: val Epoch: [45][31/72]	Time  0.231 ( 0.627)	Data  0.112 ( 0.500)	Loss 6.7250e-02 (1.4608e-01) 
2023-05-25 23:42:58.834918: val Epoch: [45][32/72]	Time  1.000 ( 0.639)	Data  0.880 ( 0.512)	Loss 1.0195e-01 (1.4475e-01) 
2023-05-25 23:42:59.050752: val Epoch: [45][33/72]	Time  0.216 ( 0.626)	Data  0.095 ( 0.500)	Loss 3.9906e-02 (1.4166e-01) 
2023-05-25 23:43:00.100462: val Epoch: [45][34/72]	Time  1.050 ( 0.638)	Data  0.930 ( 0.512)	Loss 1.3869e-01 (1.4158e-01) 
2023-05-25 23:43:00.279399: val Epoch: [45][35/72]	Time  0.179 ( 0.626)	Data  0.060 ( 0.499)	Loss 8.8093e-02 (1.4009e-01) 
2023-05-25 23:43:01.320550: val Epoch: [45][36/72]	Time  1.041 ( 0.637)	Data  0.921 ( 0.511)	Loss 4.2107e-01 (1.4769e-01) 
2023-05-25 23:43:01.491825: val Epoch: [45][37/72]	Time  0.171 ( 0.625)	Data  0.051 ( 0.499)	Loss 2.9177e-01 (1.5148e-01) 
2023-05-25 23:43:02.552580: val Epoch: [45][38/72]	Time  1.061 ( 0.636)	Data  0.934 ( 0.510)	Loss 9.5902e-02 (1.5005e-01) 
2023-05-25 23:43:02.720616: val Epoch: [45][39/72]	Time  0.168 ( 0.624)	Data  0.043 ( 0.498)	Loss 2.1739e-01 (1.5174e-01) 
2023-05-25 23:43:03.813051: val Epoch: [45][40/72]	Time  1.092 ( 0.635)	Data  0.967 ( 0.509)	Loss 8.6365e-02 (1.5014e-01) 
2023-05-25 23:43:03.996824: val Epoch: [45][41/72]	Time  0.184 ( 0.625)	Data  0.059 ( 0.499)	Loss 5.7630e-02 (1.4794e-01) 
2023-05-25 23:43:05.047258: val Epoch: [45][42/72]	Time  1.050 ( 0.635)	Data  0.925 ( 0.509)	Loss 7.2829e-02 (1.4619e-01) 
2023-05-25 23:43:05.226888: val Epoch: [45][43/72]	Time  0.180 ( 0.624)	Data  0.055 ( 0.498)	Loss 5.7234e-02 (1.4417e-01) 
2023-05-25 23:43:06.202075: val Epoch: [45][44/72]	Time  0.975 ( 0.632)	Data  0.849 ( 0.506)	Loss 4.0216e-02 (1.4186e-01) 
2023-05-25 23:43:06.459038: val Epoch: [45][45/72]	Time  0.257 ( 0.624)	Data  0.133 ( 0.498)	Loss 5.1539e-02 (1.3990e-01) 
2023-05-25 23:43:07.424431: val Epoch: [45][46/72]	Time  0.965 ( 0.631)	Data  0.840 ( 0.505)	Loss 1.3214e-01 (1.3973e-01) 
2023-05-25 23:43:07.716106: val Epoch: [45][47/72]	Time  0.292 ( 0.624)	Data  0.168 ( 0.498)	Loss 2.3138e-01 (1.4164e-01) 
2023-05-25 23:43:08.698435: val Epoch: [45][48/72]	Time  0.982 ( 0.631)	Data  0.856 ( 0.506)	Loss 3.4860e-01 (1.4586e-01) 
2023-05-25 23:43:08.978014: val Epoch: [45][49/72]	Time  0.280 ( 0.624)	Data  0.155 ( 0.499)	Loss 1.0376e-01 (1.4502e-01) 
2023-05-25 23:43:09.929076: val Epoch: [45][50/72]	Time  0.951 ( 0.631)	Data  0.824 ( 0.505)	Loss 9.3178e-02 (1.4401e-01) 
2023-05-25 23:43:10.201345: val Epoch: [45][51/72]	Time  0.272 ( 0.624)	Data  0.148 ( 0.498)	Loss 1.3677e-01 (1.4387e-01) 
2023-05-25 23:43:11.141847: val Epoch: [45][52/72]	Time  0.940 ( 0.630)	Data  0.814 ( 0.504)	Loss 1.8568e-01 (1.4466e-01) 
2023-05-25 23:43:11.441453: val Epoch: [45][53/72]	Time  0.300 ( 0.624)	Data  0.176 ( 0.498)	Loss 8.6497e-02 (1.4358e-01) 
2023-05-25 23:43:12.383279: val Epoch: [45][54/72]	Time  0.942 ( 0.630)	Data  0.815 ( 0.504)	Loss 3.9854e-02 (1.4169e-01) 
2023-05-25 23:43:12.688636: val Epoch: [45][55/72]	Time  0.305 ( 0.624)	Data  0.181 ( 0.498)	Loss 3.4166e-01 (1.4526e-01) 
2023-05-25 23:43:13.624860: val Epoch: [45][56/72]	Time  0.936 ( 0.629)	Data  0.810 ( 0.503)	Loss 1.2034e-01 (1.4483e-01) 
2023-05-25 23:43:13.900394: val Epoch: [45][57/72]	Time  0.276 ( 0.623)	Data  0.151 ( 0.497)	Loss 4.6401e-02 (1.4313e-01) 
2023-05-25 23:43:14.890511: val Epoch: [45][58/72]	Time  0.990 ( 0.629)	Data  0.864 ( 0.504)	Loss 5.1770e-02 (1.4158e-01) 
2023-05-25 23:43:15.149697: val Epoch: [45][59/72]	Time  0.259 ( 0.623)	Data  0.135 ( 0.497)	Loss 1.0015e-01 (1.4089e-01) 
2023-05-25 23:43:16.157021: val Epoch: [45][60/72]	Time  1.007 ( 0.629)	Data  0.881 ( 0.504)	Loss 9.7189e-02 (1.4017e-01) 
2023-05-25 23:43:16.369117: val Epoch: [45][61/72]	Time  0.212 ( 0.623)	Data  0.088 ( 0.497)	Loss 7.0512e-02 (1.3905e-01) 
2023-05-25 23:43:17.349352: val Epoch: [45][62/72]	Time  0.980 ( 0.628)	Data  0.854 ( 0.503)	Loss 1.0799e-01 (1.3856e-01) 
2023-05-25 23:43:17.588608: val Epoch: [45][63/72]	Time  0.239 ( 0.622)	Data  0.115 ( 0.497)	Loss 4.7967e-02 (1.3714e-01) 
2023-05-25 23:43:18.516792: val Epoch: [45][64/72]	Time  0.928 ( 0.627)	Data  0.802 ( 0.501)	Loss 6.4631e-02 (1.3603e-01) 
2023-05-25 23:43:18.846278: val Epoch: [45][65/72]	Time  0.329 ( 0.623)	Data  0.205 ( 0.497)	Loss 8.6588e-02 (1.3528e-01) 
2023-05-25 23:43:19.746641: val Epoch: [45][66/72]	Time  0.900 ( 0.627)	Data  0.774 ( 0.501)	Loss 9.2113e-02 (1.3463e-01) 
2023-05-25 23:43:20.112617: val Epoch: [45][67/72]	Time  0.366 ( 0.623)	Data  0.241 ( 0.497)	Loss 1.0204e-01 (1.3415e-01) 
2023-05-25 23:43:21.059695: val Epoch: [45][68/72]	Time  0.947 ( 0.628)	Data  0.820 ( 0.502)	Loss 2.1659e-01 (1.3535e-01) 
2023-05-25 23:43:21.319703: val Epoch: [45][69/72]	Time  0.260 ( 0.622)	Data  0.135 ( 0.497)	Loss 3.8854e-02 (1.3397e-01) 
2023-05-25 23:43:22.272970: val Epoch: [45][70/72]	Time  0.953 ( 0.627)	Data  0.826 ( 0.501)	Loss 1.1335e-01 (1.3368e-01) 
2023-05-25 23:43:22.470161: val Epoch: [45][71/72]	Time  0.197 ( 0.621)	Data  0.073 ( 0.495)	Loss 4.8783e-02 (1.3250e-01) 
2023-05-25 23:43:22.658440: Epoch 45 :Val : ['ET : 0.7373762726783752', 'TC : 0.7637547850608826', 'WT : 0.872499406337738'] 
2023-05-25 23:43:22.661713: Epoch 45 :Val : ['ET : 0.7373762726783752', 'TC : 0.7637547850608826', 'WT : 0.872499406337738'] 
2023-05-25 23:43:22.664883: Val epoch done in 45.62216911499854 s 
2023-05-25 23:43:22.673335: Batches per epoch:  129 
2023-05-25 23:43:27.575492: train Epoch: [46][  0/129]	Time  4.902 ( 4.902)	Data  3.913 ( 3.913)	Loss 6.7936e-02 (6.7936e-02) 
2023-05-25 23:43:28.524902: train Epoch: [46][  1/129]	Time  0.949 ( 2.926)	Data  0.001 ( 1.957)	Loss 2.3135e-01 (1.4964e-01) 
2023-05-25 23:43:31.105737: train Epoch: [46][  2/129]	Time  2.581 ( 2.811)	Data  1.635 ( 1.849)	Loss 6.0852e-02 (1.2004e-01) 
2023-05-25 23:43:32.055409: train Epoch: [46][  3/129]	Time  0.950 ( 2.345)	Data  0.001 ( 1.387)	Loss 1.0438e-01 (1.1613e-01) 
2023-05-25 23:43:34.709742: train Epoch: [46][  4/129]	Time  2.654 ( 2.407)	Data  1.708 ( 1.451)	Loss 9.6612e-02 (1.1223e-01) 
2023-05-25 23:43:35.659130: train Epoch: [46][  5/129]	Time  0.949 ( 2.164)	Data  0.001 ( 1.210)	Loss 8.8295e-02 (1.0824e-01) 
2023-05-25 23:43:38.294260: train Epoch: [46][  6/129]	Time  2.635 ( 2.232)	Data  1.689 ( 1.278)	Loss 1.0151e-01 (1.0728e-01) 
2023-05-25 23:43:39.244644: train Epoch: [46][  7/129]	Time  0.950 ( 2.071)	Data  0.001 ( 1.118)	Loss 5.6414e-02 (1.0092e-01) 
2023-05-25 23:43:41.925093: train Epoch: [46][  8/129]	Time  2.680 ( 2.139)	Data  1.733 ( 1.187)	Loss 6.8459e-02 (9.7312e-02) 
2023-05-25 23:43:42.875078: train Epoch: [46][  9/129]	Time  0.950 ( 2.020)	Data  0.001 ( 1.068)	Loss 1.0877e-01 (9.8457e-02) 
2023-05-25 23:43:45.566757: train Epoch: [46][ 10/129]	Time  2.692 ( 2.081)	Data  1.744 ( 1.130)	Loss 1.0066e-01 (9.8658e-02) 
2023-05-25 23:43:46.516800: train Epoch: [46][ 11/129]	Time  0.950 ( 1.987)	Data  0.001 ( 1.036)	Loss 6.0569e-02 (9.5484e-02) 
2023-05-25 23:43:49.212963: train Epoch: [46][ 12/129]	Time  2.696 ( 2.041)	Data  1.749 ( 1.090)	Loss 9.1594e-02 (9.5185e-02) 
2023-05-25 23:43:50.163288: train Epoch: [46][ 13/129]	Time  0.950 ( 1.964)	Data  0.001 ( 1.013)	Loss 8.1363e-02 (9.4197e-02) 
2023-05-25 23:43:52.862157: train Epoch: [46][ 14/129]	Time  2.699 ( 2.013)	Data  1.750 ( 1.062)	Loss 9.7726e-02 (9.4433e-02) 
2023-05-25 23:43:53.812801: train Epoch: [46][ 15/129]	Time  0.951 ( 1.946)	Data  0.001 ( 0.995)	Loss 7.8165e-02 (9.3416e-02) 
2023-05-25 23:43:56.678702: train Epoch: [46][ 16/129]	Time  2.866 ( 2.000)	Data  1.917 ( 1.050)	Loss 7.8336e-02 (9.2529e-02) 
2023-05-25 23:43:57.630015: train Epoch: [46][ 17/129]	Time  0.951 ( 1.942)	Data  0.001 ( 0.991)	Loss 9.1357e-02 (9.2464e-02) 
2023-05-25 23:44:00.406013: train Epoch: [46][ 18/129]	Time  2.776 ( 1.986)	Data  1.829 ( 1.035)	Loss 5.3306e-02 (9.0403e-02) 
2023-05-25 23:44:01.363142: train Epoch: [46][ 19/129]	Time  0.957 ( 1.934)	Data  0.001 ( 0.984)	Loss 9.2899e-02 (9.0528e-02) 
2023-05-25 23:44:04.055820: train Epoch: [46][ 20/129]	Time  2.693 ( 1.971)	Data  1.746 ( 1.020)	Loss 1.2507e-01 (9.2173e-02) 
2023-05-25 23:44:05.005466: train Epoch: [46][ 21/129]	Time  0.950 ( 1.924)	Data  0.001 ( 0.974)	Loss 6.9801e-02 (9.1156e-02) 
2023-05-25 23:44:07.604357: train Epoch: [46][ 22/129]	Time  2.599 ( 1.954)	Data  1.652 ( 1.003)	Loss 5.3088e-02 (8.9501e-02) 
2023-05-25 23:44:08.553838: train Epoch: [46][ 23/129]	Time  0.949 ( 1.912)	Data  0.001 ( 0.961)	Loss 6.3287e-02 (8.8408e-02) 
2023-05-25 23:44:11.166512: train Epoch: [46][ 24/129]	Time  2.613 ( 1.940)	Data  1.664 ( 0.990)	Loss 8.2886e-02 (8.8187e-02) 
2023-05-25 23:44:12.117510: train Epoch: [46][ 25/129]	Time  0.951 ( 1.902)	Data  0.001 ( 0.952)	Loss 7.4682e-02 (8.7668e-02) 
2023-05-25 23:44:14.851002: train Epoch: [46][ 26/129]	Time  2.733 ( 1.932)	Data  1.786 ( 0.982)	Loss 2.3151e-01 (9.2996e-02) 
2023-05-25 23:44:15.802583: train Epoch: [46][ 27/129]	Time  0.952 ( 1.897)	Data  0.001 ( 0.947)	Loss 5.8306e-02 (9.1757e-02) 
2023-05-25 23:44:18.619190: train Epoch: [46][ 28/129]	Time  2.817 ( 1.929)	Data  1.868 ( 0.979)	Loss 9.0150e-02 (9.1701e-02) 
2023-05-25 23:44:19.569164: train Epoch: [46][ 29/129]	Time  0.950 ( 1.897)	Data  0.001 ( 0.947)	Loss 8.2716e-02 (9.1402e-02) 
2023-05-25 23:44:22.192261: train Epoch: [46][ 30/129]	Time  2.623 ( 1.920)	Data  1.675 ( 0.970)	Loss 9.7083e-02 (9.1585e-02) 
2023-05-25 23:44:23.144322: train Epoch: [46][ 31/129]	Time  0.952 ( 1.890)	Data  0.001 ( 0.940)	Loss 9.3484e-02 (9.1644e-02) 
2023-05-25 23:44:25.896966: train Epoch: [46][ 32/129]	Time  2.753 ( 1.916)	Data  1.805 ( 0.966)	Loss 1.0329e-01 (9.1997e-02) 
2023-05-25 23:44:26.848057: train Epoch: [46][ 33/129]	Time  0.951 ( 1.887)	Data  0.001 ( 0.938)	Loss 7.3439e-02 (9.1451e-02) 
2023-05-25 23:44:29.510563: train Epoch: [46][ 34/129]	Time  2.662 ( 1.910)	Data  1.714 ( 0.960)	Loss 1.4048e-01 (9.2852e-02) 
2023-05-25 23:44:30.462647: train Epoch: [46][ 35/129]	Time  0.952 ( 1.883)	Data  0.001 ( 0.933)	Loss 1.1641e-01 (9.3507e-02) 
2023-05-25 23:44:33.158310: train Epoch: [46][ 36/129]	Time  2.696 ( 1.905)	Data  1.748 ( 0.955)	Loss 6.3486e-02 (9.2695e-02) 
2023-05-25 23:44:34.110028: train Epoch: [46][ 37/129]	Time  0.952 ( 1.880)	Data  0.001 ( 0.930)	Loss 8.4264e-02 (9.2473e-02) 
2023-05-25 23:44:36.928792: train Epoch: [46][ 38/129]	Time  2.819 ( 1.904)	Data  1.858 ( 0.954)	Loss 1.0572e-01 (9.2813e-02) 
2023-05-25 23:44:37.879845: train Epoch: [46][ 39/129]	Time  0.951 ( 1.880)	Data  0.001 ( 0.930)	Loss 8.3260e-02 (9.2574e-02) 
2023-05-25 23:44:40.619302: train Epoch: [46][ 40/129]	Time  2.739 ( 1.901)	Data  1.791 ( 0.951)	Loss 1.1435e-01 (9.3105e-02) 
2023-05-25 23:44:41.569879: train Epoch: [46][ 41/129]	Time  0.951 ( 1.878)	Data  0.001 ( 0.928)	Loss 5.4578e-02 (9.2188e-02) 
2023-05-25 23:44:44.272845: train Epoch: [46][ 42/129]	Time  2.703 ( 1.898)	Data  1.742 ( 0.947)	Loss 6.0451e-02 (9.1450e-02) 
2023-05-25 23:44:45.224747: train Epoch: [46][ 43/129]	Time  0.952 ( 1.876)	Data  0.001 ( 0.926)	Loss 1.3401e-01 (9.2417e-02) 
2023-05-25 23:44:47.865135: train Epoch: [46][ 44/129]	Time  2.640 ( 1.893)	Data  1.692 ( 0.943)	Loss 1.1016e-01 (9.2811e-02) 
2023-05-25 23:44:48.817274: train Epoch: [46][ 45/129]	Time  0.952 ( 1.873)	Data  0.001 ( 0.922)	Loss 1.1423e-01 (9.3277e-02) 
2023-05-25 23:44:51.458382: train Epoch: [46][ 46/129]	Time  2.641 ( 1.889)	Data  1.693 ( 0.939)	Loss 1.0807e-01 (9.3592e-02) 
2023-05-25 23:44:52.409094: train Epoch: [46][ 47/129]	Time  0.951 ( 1.869)	Data  0.001 ( 0.919)	Loss 8.4720e-02 (9.3407e-02) 
2023-05-25 23:44:55.043358: train Epoch: [46][ 48/129]	Time  2.634 ( 1.885)	Data  1.680 ( 0.935)	Loss 1.1894e-01 (9.3928e-02) 
2023-05-25 23:44:55.993679: train Epoch: [46][ 49/129]	Time  0.950 ( 1.866)	Data  0.001 ( 0.916)	Loss 9.3671e-02 (9.3923e-02) 
2023-05-25 23:44:58.568991: train Epoch: [46][ 50/129]	Time  2.575 ( 1.880)	Data  1.626 ( 0.930)	Loss 7.4463e-02 (9.3541e-02) 
2023-05-25 23:44:59.520618: train Epoch: [46][ 51/129]	Time  0.952 ( 1.862)	Data  0.001 ( 0.912)	Loss 9.6221e-02 (9.3593e-02) 
2023-05-25 23:45:02.226948: train Epoch: [46][ 52/129]	Time  2.706 ( 1.878)	Data  1.747 ( 0.928)	Loss 8.4192e-02 (9.3415e-02) 
2023-05-25 23:45:03.177834: train Epoch: [46][ 53/129]	Time  0.951 ( 1.861)	Data  0.001 ( 0.911)	Loss 6.2737e-02 (9.2847e-02) 
2023-05-25 23:45:05.754722: train Epoch: [46][ 54/129]	Time  2.577 ( 1.874)	Data  1.629 ( 0.924)	Loss 8.8810e-02 (9.2774e-02) 
2023-05-25 23:45:06.707167: train Epoch: [46][ 55/129]	Time  0.952 ( 1.858)	Data  0.001 ( 0.907)	Loss 1.0102e-01 (9.2921e-02) 
2023-05-25 23:45:09.444259: train Epoch: [46][ 56/129]	Time  2.737 ( 1.873)	Data  1.776 ( 0.923)	Loss 8.7868e-02 (9.2832e-02) 
2023-05-25 23:45:10.394980: train Epoch: [46][ 57/129]	Time  0.951 ( 1.857)	Data  0.001 ( 0.907)	Loss 7.5873e-02 (9.2540e-02) 
2023-05-25 23:45:13.045503: train Epoch: [46][ 58/129]	Time  2.651 ( 1.871)	Data  1.702 ( 0.920)	Loss 1.1181e-01 (9.2867e-02) 
2023-05-25 23:45:13.996526: train Epoch: [46][ 59/129]	Time  0.951 ( 1.855)	Data  0.001 ( 0.905)	Loss 8.6911e-02 (9.2767e-02) 
2023-05-25 23:45:16.674392: train Epoch: [46][ 60/129]	Time  2.678 ( 1.869)	Data  1.725 ( 0.918)	Loss 5.9647e-02 (9.2225e-02) 
2023-05-25 23:45:17.623594: train Epoch: [46][ 61/129]	Time  0.949 ( 1.854)	Data  0.001 ( 0.903)	Loss 1.3820e-01 (9.2966e-02) 
2023-05-25 23:45:20.300672: train Epoch: [46][ 62/129]	Time  2.677 ( 1.867)	Data  1.726 ( 0.917)	Loss 6.5317e-02 (9.2527e-02) 
2023-05-25 23:45:21.250731: train Epoch: [46][ 63/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.902)	Loss 8.3427e-02 (9.2385e-02) 
2023-05-25 23:45:24.001636: train Epoch: [46][ 64/129]	Time  2.751 ( 1.867)	Data  1.801 ( 0.916)	Loss 7.8826e-02 (9.2176e-02) 
2023-05-25 23:45:24.952226: train Epoch: [46][ 65/129]	Time  0.951 ( 1.853)	Data  0.001 ( 0.902)	Loss 7.9607e-02 (9.1986e-02) 
2023-05-25 23:45:27.682476: train Epoch: [46][ 66/129]	Time  2.730 ( 1.866)	Data  1.771 ( 0.915)	Loss 4.6826e-02 (9.1312e-02) 
2023-05-25 23:45:28.643413: train Epoch: [46][ 67/129]	Time  0.961 ( 1.852)	Data  0.001 ( 0.902)	Loss 7.3957e-02 (9.1057e-02) 
2023-05-25 23:45:31.290840: train Epoch: [46][ 68/129]	Time  2.647 ( 1.864)	Data  1.688 ( 0.913)	Loss 7.8631e-02 (9.0877e-02) 
2023-05-25 23:45:32.253327: train Epoch: [46][ 69/129]	Time  0.962 ( 1.851)	Data  0.001 ( 0.900)	Loss 9.6590e-02 (9.0958e-02) 
2023-05-25 23:45:34.926197: train Epoch: [46][ 70/129]	Time  2.673 ( 1.863)	Data  1.713 ( 0.912)	Loss 4.7986e-02 (9.0353e-02) 
2023-05-25 23:45:35.889668: train Epoch: [46][ 71/129]	Time  0.963 ( 1.850)	Data  0.001 ( 0.899)	Loss 9.0663e-02 (9.0357e-02) 
2023-05-25 23:45:38.602793: train Epoch: [46][ 72/129]	Time  2.713 ( 1.862)	Data  1.740 ( 0.910)	Loss 4.8811e-02 (8.9788e-02) 
2023-05-25 23:45:39.565687: train Epoch: [46][ 73/129]	Time  0.963 ( 1.850)	Data  0.001 ( 0.898)	Loss 5.6750e-02 (8.9342e-02) 
2023-05-25 23:45:42.223303: train Epoch: [46][ 74/129]	Time  2.658 ( 1.861)	Data  1.686 ( 0.909)	Loss 7.6664e-02 (8.9173e-02) 
2023-05-25 23:45:43.185894: train Epoch: [46][ 75/129]	Time  0.963 ( 1.849)	Data  0.001 ( 0.897)	Loss 8.5532e-02 (8.9125e-02) 
2023-05-25 23:45:45.848083: train Epoch: [46][ 76/129]	Time  2.662 ( 1.859)	Data  1.702 ( 0.907)	Loss 1.0780e-01 (8.9367e-02) 
2023-05-25 23:45:46.809490: train Epoch: [46][ 77/129]	Time  0.961 ( 1.848)	Data  0.001 ( 0.895)	Loss 1.7493e-01 (9.0464e-02) 
2023-05-25 23:45:49.393893: train Epoch: [46][ 78/129]	Time  2.584 ( 1.857)	Data  1.613 ( 0.905)	Loss 7.8608e-02 (9.0314e-02) 
2023-05-25 23:45:50.357111: train Epoch: [46][ 79/129]	Time  0.963 ( 1.846)	Data  0.001 ( 0.893)	Loss 6.2942e-02 (8.9972e-02) 
2023-05-25 23:45:52.916917: train Epoch: [46][ 80/129]	Time  2.560 ( 1.855)	Data  1.598 ( 0.902)	Loss 1.3011e-01 (9.0468e-02) 
2023-05-25 23:45:53.877752: train Epoch: [46][ 81/129]	Time  0.961 ( 1.844)	Data  0.001 ( 0.891)	Loss 7.0592e-02 (9.0225e-02) 
2023-05-25 23:45:56.596853: train Epoch: [46][ 82/129]	Time  2.719 ( 1.854)	Data  1.758 ( 0.901)	Loss 7.6869e-02 (9.0064e-02) 
2023-05-25 23:45:57.558167: train Epoch: [46][ 83/129]	Time  0.961 ( 1.844)	Data  0.001 ( 0.891)	Loss 1.1516e-01 (9.0363e-02) 
2023-05-25 23:46:00.365634: train Epoch: [46][ 84/129]	Time  2.807 ( 1.855)	Data  1.843 ( 0.902)	Loss 1.1080e-01 (9.0603e-02) 
2023-05-25 23:46:01.326859: train Epoch: [46][ 85/129]	Time  0.961 ( 1.845)	Data  0.001 ( 0.891)	Loss 6.5251e-02 (9.0309e-02) 
2023-05-25 23:46:03.996822: train Epoch: [46][ 86/129]	Time  2.670 ( 1.854)	Data  1.711 ( 0.901)	Loss 1.0296e-01 (9.0454e-02) 
2023-05-25 23:46:04.958081: train Epoch: [46][ 87/129]	Time  0.961 ( 1.844)	Data  0.001 ( 0.891)	Loss 8.0478e-02 (9.0341e-02) 
2023-05-25 23:46:07.620647: train Epoch: [46][ 88/129]	Time  2.663 ( 1.853)	Data  1.690 ( 0.900)	Loss 8.7986e-02 (9.0314e-02) 
2023-05-25 23:46:08.577455: train Epoch: [46][ 89/129]	Time  0.957 ( 1.843)	Data  0.001 ( 0.890)	Loss 7.8941e-02 (9.0188e-02) 
2023-05-25 23:46:11.171065: train Epoch: [46][ 90/129]	Time  2.594 ( 1.852)	Data  1.635 ( 0.898)	Loss 7.7928e-02 (9.0053e-02) 
2023-05-25 23:46:12.124154: train Epoch: [46][ 91/129]	Time  0.953 ( 1.842)	Data  0.001 ( 0.888)	Loss 1.2712e-01 (9.0456e-02) 
2023-05-25 23:46:14.753069: train Epoch: [46][ 92/129]	Time  2.629 ( 1.850)	Data  1.680 ( 0.897)	Loss 1.0617e-01 (9.0625e-02) 
2023-05-25 23:46:15.704572: train Epoch: [46][ 93/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.887)	Loss 4.6167e-02 (9.0152e-02) 
2023-05-25 23:46:18.447104: train Epoch: [46][ 94/129]	Time  2.743 ( 1.850)	Data  1.794 ( 0.897)	Loss 7.4262e-02 (8.9985e-02) 
2023-05-25 23:46:19.398338: train Epoch: [46][ 95/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.887)	Loss 6.1211e-02 (8.9685e-02) 
2023-05-25 23:46:22.031364: train Epoch: [46][ 96/129]	Time  2.633 ( 1.849)	Data  1.683 ( 0.895)	Loss 4.3926e-02 (8.9213e-02) 
2023-05-25 23:46:22.980799: train Epoch: [46][ 97/129]	Time  0.949 ( 1.840)	Data  0.001 ( 0.886)	Loss 1.2818e-01 (8.9611e-02) 
2023-05-25 23:46:25.552308: train Epoch: [46][ 98/129]	Time  2.572 ( 1.847)	Data  1.622 ( 0.894)	Loss 7.4889e-02 (8.9462e-02) 
2023-05-25 23:46:26.504266: train Epoch: [46][ 99/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.885)	Loss 5.1625e-02 (8.9084e-02) 
2023-05-25 23:46:29.251090: train Epoch: [46][100/129]	Time  2.747 ( 1.847)	Data  1.798 ( 0.894)	Loss 8.3519e-02 (8.9029e-02) 
2023-05-25 23:46:30.204602: train Epoch: [46][101/129]	Time  0.954 ( 1.839)	Data  0.001 ( 0.885)	Loss 1.1025e-01 (8.9237e-02) 
2023-05-25 23:46:32.829297: train Epoch: [46][102/129]	Time  2.625 ( 1.846)	Data  1.667 ( 0.893)	Loss 2.0838e-01 (9.0394e-02) 
2023-05-25 23:46:33.780591: train Epoch: [46][103/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.884)	Loss 8.8813e-02 (9.0378e-02) 
2023-05-25 23:46:36.468697: train Epoch: [46][104/129]	Time  2.688 ( 1.846)	Data  1.734 ( 0.892)	Loss 1.2457e-01 (9.0704e-02) 
2023-05-25 23:46:37.420947: train Epoch: [46][105/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.884)	Loss 5.8060e-02 (9.0396e-02) 
2023-05-25 23:46:40.108302: train Epoch: [46][106/129]	Time  2.687 ( 1.845)	Data  1.735 ( 0.892)	Loss 8.9061e-02 (9.0384e-02) 
2023-05-25 23:46:41.058025: train Epoch: [46][107/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.884)	Loss 7.2841e-02 (9.0221e-02) 
2023-05-25 23:46:43.632806: train Epoch: [46][108/129]	Time  2.575 ( 1.844)	Data  1.622 ( 0.890)	Loss 1.7821e-01 (9.1028e-02) 
2023-05-25 23:46:44.584703: train Epoch: [46][109/129]	Time  0.952 ( 1.836)	Data  0.001 ( 0.882)	Loss 8.5758e-02 (9.0980e-02) 
2023-05-25 23:46:47.304536: train Epoch: [46][110/129]	Time  2.720 ( 1.844)	Data  1.759 ( 0.890)	Loss 7.2777e-02 (9.0816e-02) 
2023-05-25 23:46:48.255719: train Epoch: [46][111/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.882)	Loss 7.4070e-02 (9.0667e-02) 
2023-05-25 23:46:50.919099: train Epoch: [46][112/129]	Time  2.663 ( 1.843)	Data  1.702 ( 0.889)	Loss 1.0531e-01 (9.0797e-02) 
2023-05-25 23:46:51.869282: train Epoch: [46][113/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.882)	Loss 6.7977e-02 (9.0596e-02) 
2023-05-25 23:46:54.534629: train Epoch: [46][114/129]	Time  2.665 ( 1.842)	Data  1.704 ( 0.889)	Loss 1.1092e-01 (9.0773e-02) 
2023-05-25 23:46:55.484261: train Epoch: [46][115/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.881)	Loss 9.9180e-02 (9.0846e-02) 
2023-05-25 23:46:58.093732: train Epoch: [46][116/129]	Time  2.609 ( 1.841)	Data  1.661 ( 0.888)	Loss 6.0905e-02 (9.0590e-02) 
2023-05-25 23:46:59.044616: train Epoch: [46][117/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.880)	Loss 6.5857e-02 (9.0380e-02) 
2023-05-25 23:47:01.680040: train Epoch: [46][118/129]	Time  2.635 ( 1.840)	Data  1.679 ( 0.887)	Loss 8.0421e-02 (9.0296e-02) 
2023-05-25 23:47:02.631478: train Epoch: [46][119/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.880)	Loss 9.1477e-02 (9.0306e-02) 
2023-05-25 23:47:05.482017: train Epoch: [46][120/129]	Time  2.851 ( 1.841)	Data  1.889 ( 0.888)	Loss 7.4432e-02 (9.0175e-02) 
2023-05-25 23:47:06.432731: train Epoch: [46][121/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.881)	Loss 9.5466e-02 (9.0218e-02) 
2023-05-25 23:47:09.339025: train Epoch: [46][122/129]	Time  2.906 ( 1.843)	Data  1.946 ( 0.889)	Loss 8.8188e-02 (9.0202e-02) 
2023-05-25 23:47:10.289769: train Epoch: [46][123/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.882)	Loss 9.8905e-02 (9.0272e-02) 
2023-05-25 23:47:13.069148: train Epoch: [46][124/129]	Time  2.779 ( 1.843)	Data  1.826 ( 0.890)	Loss 1.2829e-01 (9.0576e-02) 
2023-05-25 23:47:14.020105: train Epoch: [46][125/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.883)	Loss 1.0838e-01 (9.0718e-02) 
2023-05-25 23:47:16.803247: train Epoch: [46][126/129]	Time  2.783 ( 1.844)	Data  1.825 ( 0.890)	Loss 7.7823e-02 (9.0616e-02) 
2023-05-25 23:47:17.748058: train Epoch: [46][127/129]	Time  0.945 ( 1.837)	Data  0.001 ( 0.883)	Loss 8.5318e-02 (9.0575e-02) 
2023-05-25 23:47:19.239789: train Epoch: [46][128/129]	Time  1.492 ( 1.834)	Data  0.546 ( 0.881)	Loss 9.2426e-02 (9.0589e-02) 
2023-05-25 23:47:19.270531: Train Epoch done in 236.59722165400308 s 
2023-05-25 23:47:21.769114: val Epoch: [46][ 0/72]	Time  1.610 ( 1.610)	Data  1.404 ( 1.404)	Loss 5.8864e-02 (5.8864e-02) 
2023-05-25 23:47:21.894759: val Epoch: [46][ 1/72]	Time  0.126 ( 0.868)	Data  0.001 ( 0.703)	Loss 5.5507e-02 (5.7186e-02) 
2023-05-25 23:47:22.896940: val Epoch: [46][ 2/72]	Time  1.002 ( 0.913)	Data  0.877 ( 0.761)	Loss 2.0294e-01 (1.0577e-01) 
2023-05-25 23:47:23.022120: val Epoch: [46][ 3/72]	Time  0.125 ( 0.716)	Data  0.001 ( 0.571)	Loss 7.7047e-02 (9.8588e-02) 
2023-05-25 23:47:24.133933: val Epoch: [46][ 4/72]	Time  1.112 ( 0.795)	Data  0.987 ( 0.654)	Loss 9.0783e-02 (9.7027e-02) 
2023-05-25 23:47:24.259121: val Epoch: [46][ 5/72]	Time  0.125 ( 0.683)	Data  0.001 ( 0.545)	Loss 1.5323e-01 (1.0639e-01) 
2023-05-25 23:47:25.381268: val Epoch: [46][ 6/72]	Time  1.122 ( 0.746)	Data  0.997 ( 0.610)	Loss 5.0375e-02 (9.8391e-02) 
2023-05-25 23:47:25.506829: val Epoch: [46][ 7/72]	Time  0.126 ( 0.668)	Data  0.001 ( 0.533)	Loss 6.1212e-02 (9.3744e-02) 
2023-05-25 23:47:26.634451: val Epoch: [46][ 8/72]	Time  1.128 ( 0.719)	Data  1.003 ( 0.586)	Loss 1.5997e-01 (1.0110e-01) 
2023-05-25 23:47:26.759068: val Epoch: [46][ 9/72]	Time  0.125 ( 0.660)	Data  0.001 ( 0.527)	Loss 8.4734e-02 (9.9465e-02) 
2023-05-25 23:47:27.845204: val Epoch: [46][10/72]	Time  1.086 ( 0.699)	Data  0.961 ( 0.567)	Loss 1.3874e-01 (1.0304e-01) 
2023-05-25 23:47:27.970630: val Epoch: [46][11/72]	Time  0.125 ( 0.651)	Data  0.001 ( 0.519)	Loss 4.0726e-01 (1.2839e-01) 
2023-05-25 23:47:29.070805: val Epoch: [46][12/72]	Time  1.100 ( 0.685)	Data  0.975 ( 0.555)	Loss 5.3840e-02 (1.2265e-01) 
2023-05-25 23:47:29.196790: val Epoch: [46][13/72]	Time  0.126 ( 0.646)	Data  0.001 ( 0.515)	Loss 7.0642e-02 (1.1894e-01) 
2023-05-25 23:47:30.368945: val Epoch: [46][14/72]	Time  1.172 ( 0.681)	Data  1.047 ( 0.550)	Loss 6.6081e-02 (1.1541e-01) 
2023-05-25 23:47:30.493799: val Epoch: [46][15/72]	Time  0.125 ( 0.646)	Data  0.001 ( 0.516)	Loss 1.5250e-01 (1.1773e-01) 
2023-05-25 23:47:31.606653: val Epoch: [46][16/72]	Time  1.113 ( 0.673)	Data  0.987 ( 0.544)	Loss 8.4616e-02 (1.1578e-01) 
2023-05-25 23:47:31.731894: val Epoch: [46][17/72]	Time  0.125 ( 0.643)	Data  0.001 ( 0.514)	Loss 1.4544e-01 (1.1743e-01) 
2023-05-25 23:47:32.867518: val Epoch: [46][18/72]	Time  1.136 ( 0.669)	Data  1.010 ( 0.540)	Loss 2.6811e-01 (1.2536e-01) 
2023-05-25 23:47:32.991948: val Epoch: [46][19/72]	Time  0.124 ( 0.642)	Data  0.001 ( 0.513)	Loss 9.8816e-02 (1.2404e-01) 
2023-05-25 23:47:34.115948: val Epoch: [46][20/72]	Time  1.124 ( 0.665)	Data  0.999 ( 0.536)	Loss 3.2044e-01 (1.3339e-01) 
2023-05-25 23:47:34.240711: val Epoch: [46][21/72]	Time  0.125 ( 0.640)	Data  0.001 ( 0.512)	Loss 3.9007e-01 (1.4506e-01) 
2023-05-25 23:47:35.362301: val Epoch: [46][22/72]	Time  1.122 ( 0.661)	Data  0.997 ( 0.533)	Loss 3.5252e-01 (1.5408e-01) 
2023-05-25 23:47:35.486633: val Epoch: [46][23/72]	Time  0.124 ( 0.639)	Data  0.001 ( 0.511)	Loss 6.7545e-02 (1.5047e-01) 
2023-05-25 23:47:36.559681: val Epoch: [46][24/72]	Time  1.073 ( 0.656)	Data  0.949 ( 0.528)	Loss 7.1480e-02 (1.4731e-01) 
2023-05-25 23:47:36.684106: val Epoch: [46][25/72]	Time  0.124 ( 0.636)	Data  0.001 ( 0.508)	Loss 3.4289e-02 (1.4296e-01) 
2023-05-25 23:47:37.766403: val Epoch: [46][26/72]	Time  1.082 ( 0.652)	Data  0.957 ( 0.524)	Loss 1.9856e-01 (1.4502e-01) 
2023-05-25 23:47:37.891195: val Epoch: [46][27/72]	Time  0.125 ( 0.633)	Data  0.001 ( 0.506)	Loss 4.9613e-02 (1.4162e-01) 
2023-05-25 23:47:39.004240: val Epoch: [46][28/72]	Time  1.113 ( 0.650)	Data  0.989 ( 0.522)	Loss 1.3386e-01 (1.4135e-01) 
2023-05-25 23:47:39.128947: val Epoch: [46][29/72]	Time  0.125 ( 0.632)	Data  0.000 ( 0.505)	Loss 8.9427e-02 (1.3962e-01) 
2023-05-25 23:47:40.225511: val Epoch: [46][30/72]	Time  1.097 ( 0.647)	Data  0.975 ( 0.520)	Loss 6.1743e-02 (1.3711e-01) 
2023-05-25 23:47:40.344237: val Epoch: [46][31/72]	Time  0.119 ( 0.631)	Data  0.000 ( 0.504)	Loss 3.1305e-01 (1.4260e-01) 
2023-05-25 23:47:41.444239: val Epoch: [46][32/72]	Time  1.100 ( 0.645)	Data  0.981 ( 0.518)	Loss 4.5279e-02 (1.3965e-01) 
2023-05-25 23:47:41.562772: val Epoch: [46][33/72]	Time  0.119 ( 0.630)	Data  0.000 ( 0.503)	Loss 4.7341e-02 (1.3694e-01) 
2023-05-25 23:47:42.693968: val Epoch: [46][34/72]	Time  1.131 ( 0.644)	Data  1.013 ( 0.518)	Loss 2.0517e-01 (1.3889e-01) 
2023-05-25 23:47:42.813795: val Epoch: [46][35/72]	Time  0.120 ( 0.629)	Data  0.000 ( 0.503)	Loss 6.8213e-02 (1.3693e-01) 
2023-05-25 23:47:43.904424: val Epoch: [46][36/72]	Time  1.091 ( 0.642)	Data  0.971 ( 0.516)	Loss 9.7575e-02 (1.3586e-01) 
2023-05-25 23:47:44.024626: val Epoch: [46][37/72]	Time  0.120 ( 0.628)	Data  0.000 ( 0.502)	Loss 1.2878e-01 (1.3568e-01) 
2023-05-25 23:47:45.144848: val Epoch: [46][38/72]	Time  1.120 ( 0.641)	Data  1.001 ( 0.515)	Loss 1.2583e-01 (1.3542e-01) 
2023-05-25 23:47:45.265073: val Epoch: [46][39/72]	Time  0.120 ( 0.628)	Data  0.000 ( 0.502)	Loss 5.6056e-02 (1.3344e-01) 
2023-05-25 23:47:46.406114: val Epoch: [46][40/72]	Time  1.141 ( 0.640)	Data  1.022 ( 0.515)	Loss 6.7617e-02 (1.3183e-01) 
2023-05-25 23:47:46.526691: val Epoch: [46][41/72]	Time  0.121 ( 0.628)	Data  0.000 ( 0.503)	Loss 4.8165e-02 (1.2984e-01) 
2023-05-25 23:47:47.634603: val Epoch: [46][42/72]	Time  1.108 ( 0.639)	Data  0.988 ( 0.514)	Loss 8.2713e-02 (1.2875e-01) 
2023-05-25 23:47:47.754434: val Epoch: [46][43/72]	Time  0.120 ( 0.627)	Data  0.000 ( 0.502)	Loss 1.1946e-01 (1.2853e-01) 
2023-05-25 23:47:48.927533: val Epoch: [46][44/72]	Time  1.173 ( 0.639)	Data  1.053 ( 0.515)	Loss 1.3104e-01 (1.2859e-01) 
2023-05-25 23:47:49.047661: val Epoch: [46][45/72]	Time  0.120 ( 0.628)	Data  0.000 ( 0.503)	Loss 1.1272e-01 (1.2824e-01) 
2023-05-25 23:47:50.185970: val Epoch: [46][46/72]	Time  1.138 ( 0.639)	Data  1.019 ( 0.514)	Loss 3.1057e-01 (1.3212e-01) 
2023-05-25 23:47:50.306599: val Epoch: [46][47/72]	Time  0.121 ( 0.628)	Data  0.000 ( 0.504)	Loss 7.9241e-02 (1.3102e-01) 
2023-05-25 23:47:51.401812: val Epoch: [46][48/72]	Time  1.095 ( 0.638)	Data  0.975 ( 0.513)	Loss 5.3772e-02 (1.2945e-01) 
2023-05-25 23:47:51.521011: val Epoch: [46][49/72]	Time  0.119 ( 0.627)	Data  0.000 ( 0.503)	Loss 1.1268e-01 (1.2911e-01) 
2023-05-25 23:47:52.592327: val Epoch: [46][50/72]	Time  1.071 ( 0.636)	Data  0.952 ( 0.512)	Loss 1.8417e-01 (1.3019e-01) 
2023-05-25 23:47:52.711608: val Epoch: [46][51/72]	Time  0.119 ( 0.626)	Data  0.000 ( 0.502)	Loss 1.3489e-01 (1.3028e-01) 
2023-05-25 23:47:53.819294: val Epoch: [46][52/72]	Time  1.108 ( 0.635)	Data  0.988 ( 0.511)	Loss 4.3497e-01 (1.3603e-01) 
2023-05-25 23:47:53.938749: val Epoch: [46][53/72]	Time  0.119 ( 0.626)	Data  0.001 ( 0.502)	Loss 7.8773e-02 (1.3497e-01) 
2023-05-25 23:47:55.037438: val Epoch: [46][54/72]	Time  1.099 ( 0.634)	Data  0.979 ( 0.510)	Loss 2.4104e-01 (1.3690e-01) 
2023-05-25 23:47:55.156537: val Epoch: [46][55/72]	Time  0.119 ( 0.625)	Data  0.000 ( 0.501)	Loss 5.2695e-02 (1.3539e-01) 
2023-05-25 23:47:56.274568: val Epoch: [46][56/72]	Time  1.118 ( 0.634)	Data  0.998 ( 0.510)	Loss 3.4709e-01 (1.3911e-01) 
2023-05-25 23:47:56.394072: val Epoch: [46][57/72]	Time  0.119 ( 0.625)	Data  0.000 ( 0.501)	Loss 1.3553e-01 (1.3905e-01) 
2023-05-25 23:47:57.495492: val Epoch: [46][58/72]	Time  1.101 ( 0.633)	Data  0.977 ( 0.509)	Loss 1.7645e-01 (1.3968e-01) 
2023-05-25 23:47:57.619968: val Epoch: [46][59/72]	Time  0.124 ( 0.624)	Data  0.001 ( 0.501)	Loss 1.2419e-01 (1.3942e-01) 
2023-05-25 23:47:58.742955: val Epoch: [46][60/72]	Time  1.123 ( 0.633)	Data  0.998 ( 0.509)	Loss 1.4362e-01 (1.3949e-01) 
2023-05-25 23:47:58.867880: val Epoch: [46][61/72]	Time  0.125 ( 0.624)	Data  0.000 ( 0.501)	Loss 3.2884e-01 (1.4254e-01) 
2023-05-25 23:47:59.947334: val Epoch: [46][62/72]	Time  1.079 ( 0.632)	Data  0.955 ( 0.508)	Loss 1.2106e-01 (1.4220e-01) 
2023-05-25 23:48:00.072395: val Epoch: [46][63/72]	Time  0.125 ( 0.624)	Data  0.001 ( 0.500)	Loss 1.0824e-01 (1.4167e-01) 
2023-05-25 23:48:01.142340: val Epoch: [46][64/72]	Time  1.070 ( 0.631)	Data  0.945 ( 0.507)	Loss 4.9893e-02 (1.4026e-01) 
2023-05-25 23:48:01.266630: val Epoch: [46][65/72]	Time  0.124 ( 0.623)	Data  0.001 ( 0.499)	Loss 5.6887e-02 (1.3900e-01) 
2023-05-25 23:48:02.371948: val Epoch: [46][66/72]	Time  1.105 ( 0.630)	Data  0.972 ( 0.506)	Loss 4.5563e-02 (1.3760e-01) 
2023-05-25 23:48:02.496265: val Epoch: [46][67/72]	Time  0.124 ( 0.623)	Data  0.001 ( 0.499)	Loss 5.8695e-02 (1.3644e-01) 
2023-05-25 23:48:03.602587: val Epoch: [46][68/72]	Time  1.106 ( 0.630)	Data  0.982 ( 0.506)	Loss 7.0916e-02 (1.3549e-01) 
2023-05-25 23:48:03.727219: val Epoch: [46][69/72]	Time  0.125 ( 0.622)	Data  0.000 ( 0.499)	Loss 1.2469e-01 (1.3534e-01) 
2023-05-25 23:48:04.725302: val Epoch: [46][70/72]	Time  0.998 ( 0.628)	Data  0.874 ( 0.504)	Loss 7.4043e-02 (1.3448e-01) 
2023-05-25 23:48:04.847792: val Epoch: [46][71/72]	Time  0.122 ( 0.621)	Data  0.000 ( 0.497)	Loss 5.1134e-02 (1.3332e-01) 
2023-05-25 23:48:05.048460: Epoch 46 :Val : ['ET : 0.7403374314308167', 'TC : 0.7804098129272461', 'WT : 0.8582932353019714'] 
2023-05-25 23:48:05.051126: Epoch 46 :Val : ['ET : 0.7403374314308167', 'TC : 0.7804098129272461', 'WT : 0.8582932353019714'] 
2023-05-25 23:48:05.053001: Val epoch done in 45.78247399399697 s 
2023-05-25 23:48:05.058353: Batches per epoch:  129 
2023-05-25 23:48:09.926091: train Epoch: [47][  0/129]	Time  4.867 ( 4.867)	Data  3.880 ( 3.880)	Loss 8.7360e-02 (8.7360e-02) 
2023-05-25 23:48:10.876765: train Epoch: [47][  1/129]	Time  0.951 ( 2.909)	Data  0.001 ( 1.941)	Loss 5.0653e-02 (6.9006e-02) 
2023-05-25 23:48:13.580716: train Epoch: [47][  2/129]	Time  2.704 ( 2.841)	Data  1.756 ( 1.879)	Loss 6.5904e-02 (6.7972e-02) 
2023-05-25 23:48:14.530000: train Epoch: [47][  3/129]	Time  0.949 ( 2.368)	Data  0.001 ( 1.410)	Loss 8.0315e-02 (7.1058e-02) 
2023-05-25 23:48:17.192221: train Epoch: [47][  4/129]	Time  2.662 ( 2.427)	Data  1.715 ( 1.471)	Loss 5.8699e-02 (6.8586e-02) 
2023-05-25 23:48:18.143384: train Epoch: [47][  5/129]	Time  0.951 ( 2.181)	Data  0.001 ( 1.226)	Loss 5.3071e-02 (6.6000e-02) 
2023-05-25 23:48:20.890410: train Epoch: [47][  6/129]	Time  2.747 ( 2.262)	Data  1.789 ( 1.306)	Loss 7.2445e-02 (6.6921e-02) 
2023-05-25 23:48:21.842735: train Epoch: [47][  7/129]	Time  0.952 ( 2.098)	Data  0.001 ( 1.143)	Loss 8.4900e-02 (6.9168e-02) 
2023-05-25 23:48:24.583194: train Epoch: [47][  8/129]	Time  2.740 ( 2.169)	Data  1.790 ( 1.215)	Loss 5.3179e-02 (6.7392e-02) 
2023-05-25 23:48:25.534702: train Epoch: [47][  9/129]	Time  0.952 ( 2.048)	Data  0.001 ( 1.094)	Loss 1.0192e-01 (7.0844e-02) 
2023-05-25 23:48:28.247419: train Epoch: [47][ 10/129]	Time  2.713 ( 2.108)	Data  1.761 ( 1.154)	Loss 5.0428e-02 (6.8988e-02) 
2023-05-25 23:48:29.200104: train Epoch: [47][ 11/129]	Time  0.953 ( 2.012)	Data  0.001 ( 1.058)	Loss 7.4631e-02 (6.9459e-02) 
2023-05-25 23:48:31.822377: train Epoch: [47][ 12/129]	Time  2.622 ( 2.059)	Data  1.661 ( 1.104)	Loss 1.1064e-01 (7.2627e-02) 
2023-05-25 23:48:32.772489: train Epoch: [47][ 13/129]	Time  0.950 ( 1.980)	Data  0.001 ( 1.026)	Loss 1.3910e-01 (7.7375e-02) 
2023-05-25 23:48:35.496454: train Epoch: [47][ 14/129]	Time  2.724 ( 2.029)	Data  1.765 ( 1.075)	Loss 1.1405e-01 (7.9820e-02) 
2023-05-25 23:48:36.446731: train Epoch: [47][ 15/129]	Time  0.950 ( 1.962)	Data  0.001 ( 1.008)	Loss 5.8281e-02 (7.8473e-02) 
2023-05-25 23:48:39.061515: train Epoch: [47][ 16/129]	Time  2.615 ( 2.000)	Data  1.665 ( 1.046)	Loss 7.0179e-02 (7.7985e-02) 
2023-05-25 23:48:40.013390: train Epoch: [47][ 17/129]	Time  0.952 ( 1.942)	Data  0.001 ( 0.988)	Loss 4.4293e-02 (7.6114e-02) 
2023-05-25 23:48:42.726139: train Epoch: [47][ 18/129]	Time  2.713 ( 1.982)	Data  1.764 ( 1.029)	Loss 7.2971e-02 (7.5948e-02) 
2023-05-25 23:48:43.676719: train Epoch: [47][ 19/129]	Time  0.951 ( 1.931)	Data  0.001 ( 0.978)	Loss 7.8173e-02 (7.6060e-02) 
2023-05-25 23:48:46.316410: train Epoch: [47][ 20/129]	Time  2.640 ( 1.965)	Data  1.683 ( 1.011)	Loss 7.0569e-02 (7.5798e-02) 
2023-05-25 23:48:47.268256: train Epoch: [47][ 21/129]	Time  0.952 ( 1.919)	Data  0.001 ( 0.965)	Loss 9.3099e-02 (7.6584e-02) 
2023-05-25 23:48:49.799867: train Epoch: [47][ 22/129]	Time  2.532 ( 1.945)	Data  1.581 ( 0.992)	Loss 9.9939e-02 (7.7600e-02) 
2023-05-25 23:48:50.747221: train Epoch: [47][ 23/129]	Time  0.947 ( 1.904)	Data  0.001 ( 0.951)	Loss 6.4727e-02 (7.7064e-02) 
2023-05-25 23:48:53.558385: train Epoch: [47][ 24/129]	Time  2.811 ( 1.940)	Data  1.862 ( 0.987)	Loss 7.1966e-02 (7.6860e-02) 
2023-05-25 23:48:54.509810: train Epoch: [47][ 25/129]	Time  0.951 ( 1.902)	Data  0.001 ( 0.949)	Loss 8.9421e-02 (7.7343e-02) 
2023-05-25 23:48:57.230689: train Epoch: [47][ 26/129]	Time  2.721 ( 1.932)	Data  1.771 ( 0.980)	Loss 9.2887e-02 (7.7918e-02) 
2023-05-25 23:48:58.180950: train Epoch: [47][ 27/129]	Time  0.950 ( 1.897)	Data  0.001 ( 0.945)	Loss 8.0308e-02 (7.8004e-02) 
2023-05-25 23:49:00.790492: train Epoch: [47][ 28/129]	Time  2.610 ( 1.922)	Data  1.661 ( 0.970)	Loss 7.8994e-02 (7.8038e-02) 
2023-05-25 23:49:01.740801: train Epoch: [47][ 29/129]	Time  0.950 ( 1.889)	Data  0.001 ( 0.937)	Loss 1.4782e-01 (8.0364e-02) 
2023-05-25 23:49:04.412514: train Epoch: [47][ 30/129]	Time  2.672 ( 1.915)	Data  1.710 ( 0.962)	Loss 1.1632e-01 (8.1524e-02) 
2023-05-25 23:49:05.362845: train Epoch: [47][ 31/129]	Time  0.950 ( 1.885)	Data  0.001 ( 0.932)	Loss 5.3765e-02 (8.0657e-02) 
2023-05-25 23:49:08.114013: train Epoch: [47][ 32/129]	Time  2.751 ( 1.911)	Data  1.803 ( 0.959)	Loss 1.1018e-01 (8.1551e-02) 
2023-05-25 23:49:09.069658: train Epoch: [47][ 33/129]	Time  0.956 ( 1.883)	Data  0.001 ( 0.930)	Loss 7.4122e-02 (8.1333e-02) 
2023-05-25 23:49:11.814685: train Epoch: [47][ 34/129]	Time  2.745 ( 1.907)	Data  1.787 ( 0.955)	Loss 1.4548e-01 (8.3165e-02) 
2023-05-25 23:49:12.764491: train Epoch: [47][ 35/129]	Time  0.950 ( 1.881)	Data  0.001 ( 0.928)	Loss 8.0901e-02 (8.3102e-02) 
2023-05-25 23:49:15.345064: train Epoch: [47][ 36/129]	Time  2.581 ( 1.900)	Data  1.631 ( 0.947)	Loss 4.5855e-02 (8.2096e-02) 
2023-05-25 23:49:16.296338: train Epoch: [47][ 37/129]	Time  0.951 ( 1.875)	Data  0.001 ( 0.922)	Loss 6.7385e-02 (8.1709e-02) 
2023-05-25 23:49:18.992038: train Epoch: [47][ 38/129]	Time  2.696 ( 1.896)	Data  1.746 ( 0.944)	Loss 6.7572e-02 (8.1346e-02) 
2023-05-25 23:49:19.943840: train Epoch: [47][ 39/129]	Time  0.952 ( 1.872)	Data  0.001 ( 0.920)	Loss 9.1915e-02 (8.1610e-02) 
2023-05-25 23:49:22.650145: train Epoch: [47][ 40/129]	Time  2.706 ( 1.892)	Data  1.758 ( 0.940)	Loss 6.6563e-02 (8.1243e-02) 
2023-05-25 23:49:23.601624: train Epoch: [47][ 41/129]	Time  0.951 ( 1.870)	Data  0.001 ( 0.918)	Loss 6.2873e-02 (8.0806e-02) 
2023-05-25 23:49:26.344178: train Epoch: [47][ 42/129]	Time  2.743 ( 1.890)	Data  1.783 ( 0.938)	Loss 6.3945e-02 (8.0414e-02) 
2023-05-25 23:49:27.297592: train Epoch: [47][ 43/129]	Time  0.953 ( 1.869)	Data  0.001 ( 0.917)	Loss 9.3481e-02 (8.0711e-02) 
2023-05-25 23:49:29.971232: train Epoch: [47][ 44/129]	Time  2.674 ( 1.887)	Data  1.717 ( 0.935)	Loss 9.3813e-02 (8.1002e-02) 
2023-05-25 23:49:30.921059: train Epoch: [47][ 45/129]	Time  0.950 ( 1.867)	Data  0.001 ( 0.914)	Loss 1.1749e-01 (8.1795e-02) 
2023-05-25 23:49:33.574454: train Epoch: [47][ 46/129]	Time  2.653 ( 1.883)	Data  1.702 ( 0.931)	Loss 6.9329e-02 (8.1530e-02) 
2023-05-25 23:49:34.523959: train Epoch: [47][ 47/129]	Time  0.950 ( 1.864)	Data  0.001 ( 0.912)	Loss 8.3509e-02 (8.1571e-02) 
2023-05-25 23:49:37.173939: train Epoch: [47][ 48/129]	Time  2.650 ( 1.880)	Data  1.699 ( 0.928)	Loss 6.7144e-02 (8.1277e-02) 
2023-05-25 23:49:38.124616: train Epoch: [47][ 49/129]	Time  0.951 ( 1.861)	Data  0.001 ( 0.909)	Loss 1.2796e-01 (8.2211e-02) 
2023-05-25 23:49:40.759336: train Epoch: [47][ 50/129]	Time  2.635 ( 1.876)	Data  1.681 ( 0.924)	Loss 5.0209e-02 (8.1583e-02) 
2023-05-25 23:49:41.711540: train Epoch: [47][ 51/129]	Time  0.952 ( 1.859)	Data  0.001 ( 0.907)	Loss 8.1996e-02 (8.1591e-02) 
2023-05-25 23:49:44.360335: train Epoch: [47][ 52/129]	Time  2.649 ( 1.874)	Data  1.701 ( 0.922)	Loss 7.9278e-02 (8.1547e-02) 
2023-05-25 23:49:45.310988: train Epoch: [47][ 53/129]	Time  0.951 ( 1.857)	Data  0.001 ( 0.905)	Loss 1.2329e-01 (8.2320e-02) 
2023-05-25 23:49:48.030937: train Epoch: [47][ 54/129]	Time  2.720 ( 1.872)	Data  1.772 ( 0.920)	Loss 1.2195e-01 (8.3041e-02) 
2023-05-25 23:49:48.979819: train Epoch: [47][ 55/129]	Time  0.949 ( 1.856)	Data  0.001 ( 0.904)	Loss 9.0354e-02 (8.3172e-02) 
2023-05-25 23:49:51.713142: train Epoch: [47][ 56/129]	Time  2.733 ( 1.871)	Data  1.775 ( 0.919)	Loss 5.6024e-02 (8.2695e-02) 
2023-05-25 23:49:52.664657: train Epoch: [47][ 57/129]	Time  0.952 ( 1.855)	Data  0.001 ( 0.903)	Loss 6.7128e-02 (8.2427e-02) 
2023-05-25 23:49:55.328042: train Epoch: [47][ 58/129]	Time  2.663 ( 1.869)	Data  1.715 ( 0.917)	Loss 5.5105e-02 (8.1964e-02) 
2023-05-25 23:49:56.280421: train Epoch: [47][ 59/129]	Time  0.952 ( 1.854)	Data  0.001 ( 0.902)	Loss 7.1464e-02 (8.1789e-02) 
2023-05-25 23:49:58.982627: train Epoch: [47][ 60/129]	Time  2.702 ( 1.868)	Data  1.743 ( 0.916)	Loss 6.1755e-02 (8.1460e-02) 
2023-05-25 23:49:59.932893: train Epoch: [47][ 61/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.901)	Loss 6.6886e-02 (8.1225e-02) 
2023-05-25 23:50:02.570729: train Epoch: [47][ 62/129]	Time  2.638 ( 1.865)	Data  1.663 ( 0.913)	Loss 9.1873e-02 (8.1394e-02) 
2023-05-25 23:50:03.527248: train Epoch: [47][ 63/129]	Time  0.957 ( 1.851)	Data  0.001 ( 0.899)	Loss 7.1213e-02 (8.1235e-02) 
2023-05-25 23:50:06.105451: train Epoch: [47][ 64/129]	Time  2.578 ( 1.862)	Data  1.617 ( 0.910)	Loss 9.4760e-02 (8.1443e-02) 
2023-05-25 23:50:07.066899: train Epoch: [47][ 65/129]	Time  0.961 ( 1.849)	Data  0.001 ( 0.896)	Loss 8.3949e-02 (8.1481e-02) 
2023-05-25 23:50:09.739212: train Epoch: [47][ 66/129]	Time  2.672 ( 1.861)	Data  1.711 ( 0.908)	Loss 7.0592e-02 (8.1319e-02) 
2023-05-25 23:50:10.700142: train Epoch: [47][ 67/129]	Time  0.961 ( 1.848)	Data  0.001 ( 0.895)	Loss 1.1605e-01 (8.1830e-02) 
2023-05-25 23:50:13.242729: train Epoch: [47][ 68/129]	Time  2.543 ( 1.858)	Data  1.585 ( 0.905)	Loss 1.1156e-01 (8.2260e-02) 
2023-05-25 23:50:14.191943: train Epoch: [47][ 69/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.892)	Loss 6.9815e-02 (8.2083e-02) 
2023-05-25 23:50:17.004128: train Epoch: [47][ 70/129]	Time  2.812 ( 1.858)	Data  1.863 ( 0.906)	Loss 8.7834e-02 (8.2164e-02) 
2023-05-25 23:50:17.965531: train Epoch: [47][ 71/129]	Time  0.961 ( 1.846)	Data  0.001 ( 0.893)	Loss 5.8090e-02 (8.1829e-02) 
2023-05-25 23:50:20.548272: train Epoch: [47][ 72/129]	Time  2.583 ( 1.856)	Data  1.623 ( 0.903)	Loss 6.4510e-02 (8.1592e-02) 
2023-05-25 23:50:21.498567: train Epoch: [47][ 73/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.891)	Loss 5.3560e-02 (8.1213e-02) 
2023-05-25 23:50:24.166381: train Epoch: [47][ 74/129]	Time  2.668 ( 1.855)	Data  1.718 ( 0.902)	Loss 6.6592e-02 (8.1018e-02) 
2023-05-25 23:50:25.115739: train Epoch: [47][ 75/129]	Time  0.949 ( 1.843)	Data  0.001 ( 0.890)	Loss 9.4964e-02 (8.1202e-02) 
2023-05-25 23:50:27.824224: train Epoch: [47][ 76/129]	Time  2.708 ( 1.854)	Data  1.759 ( 0.901)	Loss 7.0026e-02 (8.1057e-02) 
2023-05-25 23:50:28.773314: train Epoch: [47][ 77/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.890)	Loss 6.8876e-02 (8.0900e-02) 
2023-05-25 23:50:31.479048: train Epoch: [47][ 78/129]	Time  2.706 ( 1.853)	Data  1.747 ( 0.901)	Loss 6.0655e-02 (8.0644e-02) 
2023-05-25 23:50:32.428930: train Epoch: [47][ 79/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.889)	Loss 7.8191e-02 (8.0613e-02) 
2023-05-25 23:50:35.163900: train Epoch: [47][ 80/129]	Time  2.735 ( 1.853)	Data  1.780 ( 0.900)	Loss 7.2581e-02 (8.0514e-02) 
2023-05-25 23:50:36.120377: train Epoch: [47][ 81/129]	Time  0.956 ( 1.842)	Data  0.001 ( 0.889)	Loss 7.3486e-02 (8.0429e-02) 
2023-05-25 23:50:38.830968: train Epoch: [47][ 82/129]	Time  2.711 ( 1.853)	Data  1.752 ( 0.900)	Loss 1.0726e-01 (8.0752e-02) 
2023-05-25 23:50:39.779655: train Epoch: [47][ 83/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.889)	Loss 6.5176e-02 (8.0566e-02) 
2023-05-25 23:50:42.384857: train Epoch: [47][ 84/129]	Time  2.605 ( 1.851)	Data  1.657 ( 0.898)	Loss 4.0582e-02 (8.0096e-02) 
2023-05-25 23:50:43.335145: train Epoch: [47][ 85/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.888)	Loss 1.1555e-01 (8.0508e-02) 
2023-05-25 23:50:45.933455: train Epoch: [47][ 86/129]	Time  2.598 ( 1.849)	Data  1.641 ( 0.896)	Loss 6.9490e-02 (8.0382e-02) 
2023-05-25 23:50:46.893749: train Epoch: [47][ 87/129]	Time  0.960 ( 1.839)	Data  0.001 ( 0.886)	Loss 8.1583e-02 (8.0395e-02) 
2023-05-25 23:50:49.522557: train Epoch: [47][ 88/129]	Time  2.629 ( 1.848)	Data  1.667 ( 0.895)	Loss 6.7392e-02 (8.0249e-02) 
2023-05-25 23:50:50.473081: train Epoch: [47][ 89/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.885)	Loss 9.0064e-02 (8.0358e-02) 
2023-05-25 23:50:53.168261: train Epoch: [47][ 90/129]	Time  2.695 ( 1.847)	Data  1.749 ( 0.895)	Loss 5.1297e-02 (8.0039e-02) 
2023-05-25 23:50:54.118291: train Epoch: [47][ 91/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.885)	Loss 9.6791e-02 (8.0221e-02) 
2023-05-25 23:50:56.704157: train Epoch: [47][ 92/129]	Time  2.586 ( 1.846)	Data  1.627 ( 0.893)	Loss 8.7797e-02 (8.0302e-02) 
2023-05-25 23:50:57.654990: train Epoch: [47][ 93/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.883)	Loss 8.2631e-02 (8.0327e-02) 
2023-05-25 23:51:00.228229: train Epoch: [47][ 94/129]	Time  2.573 ( 1.844)	Data  1.624 ( 0.891)	Loss 7.4670e-02 (8.0268e-02) 
2023-05-25 23:51:01.180602: train Epoch: [47][ 95/129]	Time  0.952 ( 1.835)	Data  0.001 ( 0.882)	Loss 7.2925e-02 (8.0191e-02) 
2023-05-25 23:51:03.910336: train Epoch: [47][ 96/129]	Time  2.730 ( 1.844)	Data  1.771 ( 0.891)	Loss 7.5394e-02 (8.0142e-02) 
2023-05-25 23:51:04.859800: train Epoch: [47][ 97/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.882)	Loss 8.1283e-02 (8.0153e-02) 
2023-05-25 23:51:07.536571: train Epoch: [47][ 98/129]	Time  2.677 ( 1.843)	Data  1.727 ( 0.890)	Loss 4.0556e-02 (7.9753e-02) 
2023-05-25 23:51:08.487926: train Epoch: [47][ 99/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.882)	Loss 4.9224e-02 (7.9448e-02) 
2023-05-25 23:51:11.114556: train Epoch: [47][100/129]	Time  2.627 ( 1.842)	Data  1.674 ( 0.889)	Loss 9.9065e-02 (7.9642e-02) 
2023-05-25 23:51:12.066726: train Epoch: [47][101/129]	Time  0.952 ( 1.833)	Data  0.001 ( 0.881)	Loss 1.0591e-01 (7.9900e-02) 
2023-05-25 23:51:14.774785: train Epoch: [47][102/129]	Time  2.708 ( 1.842)	Data  1.748 ( 0.889)	Loss 1.1048e-01 (8.0197e-02) 
2023-05-25 23:51:15.725260: train Epoch: [47][103/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.881)	Loss 9.3434e-02 (8.0324e-02) 
2023-05-25 23:51:18.296169: train Epoch: [47][104/129]	Time  2.571 ( 1.840)	Data  1.621 ( 0.888)	Loss 6.2630e-02 (8.0156e-02) 
2023-05-25 23:51:19.248116: train Epoch: [47][105/129]	Time  0.952 ( 1.832)	Data  0.001 ( 0.879)	Loss 1.0671e-01 (8.0406e-02) 
2023-05-25 23:51:21.973893: train Epoch: [47][106/129]	Time  2.726 ( 1.840)	Data  1.766 ( 0.888)	Loss 1.1180e-01 (8.0700e-02) 
2023-05-25 23:51:22.928008: train Epoch: [47][107/129]	Time  0.954 ( 1.832)	Data  0.001 ( 0.879)	Loss 9.8364e-02 (8.0863e-02) 
2023-05-25 23:51:25.548275: train Epoch: [47][108/129]	Time  2.620 ( 1.839)	Data  1.671 ( 0.887)	Loss 4.2041e-02 (8.0507e-02) 
2023-05-25 23:51:26.500092: train Epoch: [47][109/129]	Time  0.952 ( 1.831)	Data  0.001 ( 0.879)	Loss 7.3721e-02 (8.0445e-02) 
2023-05-25 23:51:29.171453: train Epoch: [47][110/129]	Time  2.671 ( 1.839)	Data  1.721 ( 0.886)	Loss 8.0251e-02 (8.0443e-02) 
2023-05-25 23:51:30.121092: train Epoch: [47][111/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.878)	Loss 5.9976e-02 (8.0261e-02) 
2023-05-25 23:51:32.810490: train Epoch: [47][112/129]	Time  2.689 ( 1.839)	Data  1.741 ( 0.886)	Loss 8.5612e-02 (8.0308e-02) 
2023-05-25 23:51:33.759628: train Epoch: [47][113/129]	Time  0.949 ( 1.831)	Data  0.001 ( 0.878)	Loss 5.7444e-02 (8.0108e-02) 
2023-05-25 23:51:36.489079: train Epoch: [47][114/129]	Time  2.729 ( 1.839)	Data  1.780 ( 0.886)	Loss 1.1582e-01 (8.0418e-02) 
2023-05-25 23:51:37.440227: train Epoch: [47][115/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.878)	Loss 4.7277e-02 (8.0132e-02) 
2023-05-25 23:51:40.097395: train Epoch: [47][116/129]	Time  2.657 ( 1.838)	Data  1.709 ( 0.885)	Loss 6.8170e-02 (8.0030e-02) 
2023-05-25 23:51:41.048671: train Epoch: [47][117/129]	Time  0.951 ( 1.830)	Data  0.001 ( 0.878)	Loss 8.7520e-02 (8.0094e-02) 
2023-05-25 23:51:43.798351: train Epoch: [47][118/129]	Time  2.750 ( 1.838)	Data  1.792 ( 0.886)	Loss 5.6013e-02 (7.9891e-02) 
2023-05-25 23:51:44.748475: train Epoch: [47][119/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.878)	Loss 8.8488e-02 (7.9963e-02) 
2023-05-25 23:51:47.361906: train Epoch: [47][120/129]	Time  2.613 ( 1.837)	Data  1.667 ( 0.885)	Loss 7.2724e-02 (7.9903e-02) 
2023-05-25 23:51:48.311678: train Epoch: [47][121/129]	Time  0.950 ( 1.830)	Data  0.001 ( 0.878)	Loss 8.3772e-02 (7.9935e-02) 
2023-05-25 23:51:50.906028: train Epoch: [47][122/129]	Time  2.594 ( 1.836)	Data  1.635 ( 0.884)	Loss 6.6994e-02 (7.9830e-02) 
2023-05-25 23:51:51.856097: train Epoch: [47][123/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.877)	Loss 6.6968e-02 (7.9726e-02) 
2023-05-25 23:51:54.513674: train Epoch: [47][124/129]	Time  2.658 ( 1.836)	Data  1.709 ( 0.883)	Loss 9.3303e-02 (7.9834e-02) 
2023-05-25 23:51:55.463469: train Epoch: [47][125/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.876)	Loss 5.6155e-02 (7.9647e-02) 
2023-05-25 23:51:58.097560: train Epoch: [47][126/129]	Time  2.634 ( 1.835)	Data  1.687 ( 0.883)	Loss 7.2309e-02 (7.9589e-02) 
2023-05-25 23:51:59.042372: train Epoch: [47][127/129]	Time  0.945 ( 1.828)	Data  0.001 ( 0.876)	Loss 7.4055e-02 (7.9546e-02) 
2023-05-25 23:52:00.474669: train Epoch: [47][128/129]	Time  1.432 ( 1.825)	Data  0.485 ( 0.873)	Loss 4.2586e-02 (7.9259e-02) 
2023-05-25 23:52:00.505495: Train Epoch done in 235.44716285299728 s 
2023-05-25 23:52:02.919278: val Epoch: [47][ 0/72]	Time  1.677 ( 1.677)	Data  1.470 ( 1.470)	Loss 9.6561e-02 (9.6561e-02) 
2023-05-25 23:52:03.044650: val Epoch: [47][ 1/72]	Time  0.126 ( 0.901)	Data  0.002 ( 0.736)	Loss 4.1620e-01 (2.5638e-01) 
2023-05-25 23:52:04.063985: val Epoch: [47][ 2/72]	Time  1.019 ( 0.941)	Data  0.894 ( 0.788)	Loss 4.3072e-01 (3.1449e-01) 
2023-05-25 23:52:04.189387: val Epoch: [47][ 3/72]	Time  0.125 ( 0.737)	Data  0.001 ( 0.591)	Loss 7.1574e-02 (2.5376e-01) 
2023-05-25 23:52:05.338496: val Epoch: [47][ 4/72]	Time  1.149 ( 0.819)	Data  1.023 ( 0.678)	Loss 1.0256e-01 (2.2352e-01) 
2023-05-25 23:52:05.464461: val Epoch: [47][ 5/72]	Time  0.126 ( 0.704)	Data  0.001 ( 0.565)	Loss 3.1144e-01 (2.3818e-01) 
2023-05-25 23:52:06.616464: val Epoch: [47][ 6/72]	Time  1.152 ( 0.768)	Data  1.030 ( 0.631)	Loss 1.3086e-01 (2.2284e-01) 
2023-05-25 23:52:06.735863: val Epoch: [47][ 7/72]	Time  0.119 ( 0.687)	Data  0.000 ( 0.553)	Loss 6.6592e-02 (2.0331e-01) 
2023-05-25 23:52:07.861222: val Epoch: [47][ 8/72]	Time  1.125 ( 0.735)	Data  1.003 ( 0.603)	Loss 4.3294e-02 (1.8553e-01) 
2023-05-25 23:52:07.980957: val Epoch: [47][ 9/72]	Time  0.120 ( 0.674)	Data  0.000 ( 0.542)	Loss 9.1485e-02 (1.7613e-01) 
2023-05-25 23:52:09.100872: val Epoch: [47][10/72]	Time  1.120 ( 0.714)	Data  0.994 ( 0.583)	Loss 7.2323e-02 (1.6669e-01) 
2023-05-25 23:52:09.225906: val Epoch: [47][11/72]	Time  0.125 ( 0.665)	Data  0.001 ( 0.535)	Loss 2.2295e-01 (1.7138e-01) 
2023-05-25 23:52:10.398522: val Epoch: [47][12/72]	Time  1.173 ( 0.704)	Data  1.050 ( 0.575)	Loss 2.2340e-01 (1.7538e-01) 
2023-05-25 23:52:10.517855: val Epoch: [47][13/72]	Time  0.119 ( 0.663)	Data  0.000 ( 0.534)	Loss 1.2218e-01 (1.7158e-01) 
2023-05-25 23:52:11.639372: val Epoch: [47][14/72]	Time  1.122 ( 0.693)	Data  0.996 ( 0.564)	Loss 3.5009e-02 (1.6248e-01) 
2023-05-25 23:52:11.758654: val Epoch: [47][15/72]	Time  0.119 ( 0.657)	Data  0.000 ( 0.529)	Loss 5.6667e-02 (1.5586e-01) 
2023-05-25 23:52:12.833976: val Epoch: [47][16/72]	Time  1.075 ( 0.682)	Data  0.955 ( 0.554)	Loss 5.7753e-02 (1.5009e-01) 
2023-05-25 23:52:12.976254: val Epoch: [47][17/72]	Time  0.142 ( 0.652)	Data  0.023 ( 0.525)	Loss 2.9110e-01 (1.5793e-01) 
2023-05-25 23:52:14.029086: val Epoch: [47][18/72]	Time  1.053 ( 0.673)	Data  0.932 ( 0.546)	Loss 3.9555e-02 (1.5170e-01) 
2023-05-25 23:52:14.227302: val Epoch: [47][19/72]	Time  0.198 ( 0.649)	Data  0.079 ( 0.523)	Loss 1.3416e-01 (1.5082e-01) 
2023-05-25 23:52:15.290652: val Epoch: [47][20/72]	Time  1.063 ( 0.669)	Data  0.939 ( 0.543)	Loss 3.7577e-01 (1.6153e-01) 
2023-05-25 23:52:15.410733: val Epoch: [47][21/72]	Time  0.120 ( 0.644)	Data  0.000 ( 0.518)	Loss 7.2327e-02 (1.5748e-01) 
2023-05-25 23:52:16.492334: val Epoch: [47][22/72]	Time  1.082 ( 0.663)	Data  0.961 ( 0.537)	Loss 5.9204e-02 (1.5320e-01) 
2023-05-25 23:52:16.682422: val Epoch: [47][23/72]	Time  0.190 ( 0.643)	Data  0.070 ( 0.518)	Loss 8.0305e-02 (1.5017e-01) 
2023-05-25 23:52:17.741844: val Epoch: [47][24/72]	Time  1.059 ( 0.660)	Data  0.939 ( 0.535)	Loss 3.2784e-01 (1.5727e-01) 
2023-05-25 23:52:17.929236: val Epoch: [47][25/72]	Time  0.187 ( 0.642)	Data  0.068 ( 0.517)	Loss 6.2205e-02 (1.5362e-01) 
2023-05-25 23:52:18.975493: val Epoch: [47][26/72]	Time  1.046 ( 0.657)	Data  0.926 ( 0.532)	Loss 9.8596e-02 (1.5158e-01) 
2023-05-25 23:52:19.149783: val Epoch: [47][27/72]	Time  0.174 ( 0.640)	Data  0.055 ( 0.515)	Loss 1.0703e-01 (1.4999e-01) 
2023-05-25 23:52:20.201933: val Epoch: [47][28/72]	Time  1.052 ( 0.654)	Data  0.931 ( 0.529)	Loss 6.3191e-02 (1.4699e-01) 
2023-05-25 23:52:20.367904: val Epoch: [47][29/72]	Time  0.166 ( 0.638)	Data  0.046 ( 0.513)	Loss 3.7761e-02 (1.4335e-01) 
2023-05-25 23:52:21.423212: val Epoch: [47][30/72]	Time  1.055 ( 0.651)	Data  0.935 ( 0.527)	Loss 3.4273e-01 (1.4978e-01) 
2023-05-25 23:52:21.575543: val Epoch: [47][31/72]	Time  0.152 ( 0.635)	Data  0.033 ( 0.511)	Loss 7.6504e-02 (1.4749e-01) 
2023-05-25 23:52:22.631575: val Epoch: [47][32/72]	Time  1.056 ( 0.648)	Data  0.936 ( 0.524)	Loss 5.4337e-02 (1.4467e-01) 
2023-05-25 23:52:22.837395: val Epoch: [47][33/72]	Time  0.206 ( 0.635)	Data  0.082 ( 0.511)	Loss 4.3407e-02 (1.4169e-01) 
2023-05-25 23:52:23.951907: val Epoch: [47][34/72]	Time  1.115 ( 0.649)	Data  0.985 ( 0.525)	Loss 5.7331e-02 (1.3928e-01) 
2023-05-25 23:52:24.071373: val Epoch: [47][35/72]	Time  0.119 ( 0.634)	Data  0.000 ( 0.510)	Loss 4.2859e-02 (1.3660e-01) 
2023-05-25 23:52:25.211980: val Epoch: [47][36/72]	Time  1.141 ( 0.648)	Data  1.016 ( 0.524)	Loss 3.7853e-01 (1.4314e-01) 
2023-05-25 23:52:25.331525: val Epoch: [47][37/72]	Time  0.120 ( 0.634)	Data  0.000 ( 0.510)	Loss 8.7223e-02 (1.4167e-01) 
2023-05-25 23:52:26.451601: val Epoch: [47][38/72]	Time  1.120 ( 0.646)	Data  0.995 ( 0.522)	Loss 5.4179e-02 (1.3943e-01) 
2023-05-25 23:52:26.571219: val Epoch: [47][39/72]	Time  0.120 ( 0.633)	Data  0.000 ( 0.509)	Loss 4.7399e-02 (1.3713e-01) 
2023-05-25 23:52:27.624130: val Epoch: [47][40/72]	Time  1.053 ( 0.643)	Data  0.932 ( 0.520)	Loss 4.7410e-02 (1.3494e-01) 
2023-05-25 23:52:27.799037: val Epoch: [47][41/72]	Time  0.175 ( 0.632)	Data  0.054 ( 0.509)	Loss 1.8857e-01 (1.3622e-01) 
2023-05-25 23:52:28.829216: val Epoch: [47][42/72]	Time  1.030 ( 0.642)	Data  0.910 ( 0.518)	Loss 2.7140e-01 (1.3936e-01) 
2023-05-25 23:52:28.988620: val Epoch: [47][43/72]	Time  0.159 ( 0.631)	Data  0.040 ( 0.507)	Loss 1.0292e-01 (1.3853e-01) 
2023-05-25 23:52:30.058670: val Epoch: [47][44/72]	Time  1.070 ( 0.640)	Data  0.948 ( 0.517)	Loss 1.1093e-01 (1.3792e-01) 
2023-05-25 23:52:30.193032: val Epoch: [47][45/72]	Time  0.134 ( 0.629)	Data  0.015 ( 0.506)	Loss 8.1146e-02 (1.3668e-01) 
2023-05-25 23:52:31.276268: val Epoch: [47][46/72]	Time  1.083 ( 0.639)	Data  0.963 ( 0.516)	Loss 5.5711e-02 (1.3496e-01) 
2023-05-25 23:52:31.470523: val Epoch: [47][47/72]	Time  0.194 ( 0.630)	Data  0.075 ( 0.506)	Loss 5.1308e-02 (1.3322e-01) 
2023-05-25 23:52:32.453681: val Epoch: [47][48/72]	Time  0.983 ( 0.637)	Data  0.862 ( 0.514)	Loss 1.4316e-01 (1.3342e-01) 
2023-05-25 23:52:32.712444: val Epoch: [47][49/72]	Time  0.259 ( 0.629)	Data  0.140 ( 0.506)	Loss 7.9882e-02 (1.3235e-01) 
2023-05-25 23:52:33.666965: val Epoch: [47][50/72]	Time  0.955 ( 0.636)	Data  0.834 ( 0.513)	Loss 3.8289e-02 (1.3051e-01) 
2023-05-25 23:52:33.913576: val Epoch: [47][51/72]	Time  0.247 ( 0.628)	Data  0.128 ( 0.505)	Loss 1.2636e-01 (1.3043e-01) 
2023-05-25 23:52:34.884045: val Epoch: [47][52/72]	Time  0.970 ( 0.635)	Data  0.850 ( 0.512)	Loss 3.7107e-02 (1.2867e-01) 
2023-05-25 23:52:35.159237: val Epoch: [47][53/72]	Time  0.275 ( 0.628)	Data  0.156 ( 0.505)	Loss 1.3330e-01 (1.2875e-01) 
2023-05-25 23:52:36.095538: val Epoch: [47][54/72]	Time  0.936 ( 0.634)	Data  0.815 ( 0.511)	Loss 5.7659e-02 (1.2746e-01) 
2023-05-25 23:52:36.366541: val Epoch: [47][55/72]	Time  0.271 ( 0.627)	Data  0.151 ( 0.504)	Loss 6.3437e-02 (1.2632e-01) 
2023-05-25 23:52:37.341972: val Epoch: [47][56/72]	Time  0.975 ( 0.633)	Data  0.855 ( 0.511)	Loss 1.2380e-01 (1.2627e-01) 
2023-05-25 23:52:37.575931: val Epoch: [47][57/72]	Time  0.234 ( 0.626)	Data  0.115 ( 0.504)	Loss 5.2722e-02 (1.2500e-01) 
2023-05-25 23:52:38.615970: val Epoch: [47][58/72]	Time  1.040 ( 0.633)	Data  0.919 ( 0.511)	Loss 7.2296e-02 (1.2411e-01) 
2023-05-25 23:52:38.812122: val Epoch: [47][59/72]	Time  0.196 ( 0.626)	Data  0.077 ( 0.504)	Loss 7.6844e-02 (1.2332e-01) 
2023-05-25 23:52:39.800596: val Epoch: [47][60/72]	Time  0.988 ( 0.632)	Data  0.868 ( 0.510)	Loss 4.7862e-02 (1.2209e-01) 
2023-05-25 23:52:40.022191: val Epoch: [47][61/72]	Time  0.222 ( 0.625)	Data  0.103 ( 0.503)	Loss 4.6426e-02 (1.2086e-01) 
2023-05-25 23:52:41.036017: val Epoch: [47][62/72]	Time  1.014 ( 0.632)	Data  0.894 ( 0.509)	Loss 9.3463e-02 (1.2043e-01) 
2023-05-25 23:52:41.211418: val Epoch: [47][63/72]	Time  0.175 ( 0.625)	Data  0.051 ( 0.502)	Loss 1.4107e-01 (1.2075e-01) 
2023-05-25 23:52:42.318907: val Epoch: [47][64/72]	Time  1.107 ( 0.632)	Data  0.977 ( 0.509)	Loss 4.1946e-01 (1.2535e-01) 
2023-05-25 23:52:42.443913: val Epoch: [47][65/72]	Time  0.125 ( 0.624)	Data  0.001 ( 0.502)	Loss 4.1784e-02 (1.2408e-01) 
2023-05-25 23:52:43.539210: val Epoch: [47][66/72]	Time  1.095 ( 0.631)	Data  0.966 ( 0.509)	Loss 3.8292e-02 (1.2280e-01) 
2023-05-25 23:52:43.663957: val Epoch: [47][67/72]	Time  0.125 ( 0.624)	Data  0.001 ( 0.501)	Loss 7.0210e-02 (1.2203e-01) 
2023-05-25 23:52:44.716691: val Epoch: [47][68/72]	Time  1.053 ( 0.630)	Data  0.927 ( 0.507)	Loss 7.8846e-02 (1.2140e-01) 
2023-05-25 23:52:44.876519: val Epoch: [47][69/72]	Time  0.160 ( 0.623)	Data  0.036 ( 0.500)	Loss 3.3543e-01 (1.2446e-01) 
2023-05-25 23:52:45.897100: val Epoch: [47][70/72]	Time  1.021 ( 0.629)	Data  0.893 ( 0.506)	Loss 6.7605e-02 (1.2366e-01) 
2023-05-25 23:52:46.032966: val Epoch: [47][71/72]	Time  0.136 ( 0.622)	Data  0.012 ( 0.499)	Loss 1.8389e-01 (1.2450e-01) 
2023-05-25 23:52:46.217197: Epoch 47 :Val : ['ET : 0.7365138530731201', 'TC : 0.7907060384750366', 'WT : 0.873108983039856'] 
2023-05-25 23:52:46.220193: Epoch 47 :Val : ['ET : 0.7365138530731201', 'TC : 0.7907060384750366', 'WT : 0.873108983039856'] 
2023-05-25 23:52:46.222055: Val epoch done in 45.71656612000152 s 
2023-05-25 23:52:46.227382: Batches per epoch:  129 
2023-05-25 23:52:51.004500: train Epoch: [48][  0/129]	Time  4.777 ( 4.777)	Data  3.778 ( 3.778)	Loss 6.6718e-02 (6.6718e-02) 
2023-05-25 23:52:51.955969: train Epoch: [48][  1/129]	Time  0.951 ( 2.864)	Data  0.001 ( 1.890)	Loss 6.3327e-02 (6.5022e-02) 
2023-05-25 23:52:54.550176: train Epoch: [48][  2/129]	Time  2.594 ( 2.774)	Data  1.646 ( 1.809)	Loss 9.2989e-02 (7.4345e-02) 
2023-05-25 23:52:55.501544: train Epoch: [48][  3/129]	Time  0.951 ( 2.318)	Data  0.001 ( 1.357)	Loss 8.2167e-02 (7.6300e-02) 
2023-05-25 23:52:58.268758: train Epoch: [48][  4/129]	Time  2.767 ( 2.408)	Data  1.811 ( 1.447)	Loss 8.5366e-02 (7.8113e-02) 
2023-05-25 23:52:59.218941: train Epoch: [48][  5/129]	Time  0.950 ( 2.165)	Data  0.001 ( 1.206)	Loss 8.1570e-02 (7.8690e-02) 
2023-05-25 23:53:02.121955: train Epoch: [48][  6/129]	Time  2.903 ( 2.271)	Data  1.958 ( 1.314)	Loss 1.0775e-01 (8.2841e-02) 
2023-05-25 23:53:03.072762: train Epoch: [48][  7/129]	Time  0.951 ( 2.106)	Data  0.001 ( 1.150)	Loss 5.7286e-02 (7.9647e-02) 
2023-05-25 23:53:05.751898: train Epoch: [48][  8/129]	Time  2.679 ( 2.169)	Data  1.732 ( 1.214)	Loss 6.6975e-02 (7.8239e-02) 
2023-05-25 23:53:06.702521: train Epoch: [48][  9/129]	Time  0.951 ( 2.047)	Data  0.001 ( 1.093)	Loss 8.3451e-02 (7.8760e-02) 
2023-05-25 23:53:09.464900: train Epoch: [48][ 10/129]	Time  2.762 ( 2.112)	Data  1.815 ( 1.159)	Loss 5.1601e-02 (7.6291e-02) 
2023-05-25 23:53:10.414210: train Epoch: [48][ 11/129]	Time  0.949 ( 2.016)	Data  0.001 ( 1.062)	Loss 1.0201e-01 (7.8435e-02) 
2023-05-25 23:53:13.159804: train Epoch: [48][ 12/129]	Time  2.746 ( 2.072)	Data  1.799 ( 1.119)	Loss 6.3891e-02 (7.7316e-02) 
2023-05-25 23:53:14.110133: train Epoch: [48][ 13/129]	Time  0.950 ( 1.992)	Data  0.001 ( 1.039)	Loss 1.1036e-01 (7.9676e-02) 
2023-05-25 23:53:16.741104: train Epoch: [48][ 14/129]	Time  2.631 ( 2.034)	Data  1.686 ( 1.082)	Loss 8.8476e-02 (8.0263e-02) 
2023-05-25 23:53:17.691338: train Epoch: [48][ 15/129]	Time  0.950 ( 1.966)	Data  0.001 ( 1.014)	Loss 7.3200e-02 (7.9821e-02) 
2023-05-25 23:53:20.288112: train Epoch: [48][ 16/129]	Time  2.597 ( 2.004)	Data  1.650 ( 1.052)	Loss 7.3165e-02 (7.9430e-02) 
2023-05-25 23:53:21.237883: train Epoch: [48][ 17/129]	Time  0.950 ( 1.945)	Data  0.001 ( 0.994)	Loss 1.1541e-01 (8.1429e-02) 
2023-05-25 23:53:23.864872: train Epoch: [48][ 18/129]	Time  2.627 ( 1.981)	Data  1.681 ( 1.030)	Loss 5.5968e-02 (8.0089e-02) 
2023-05-25 23:53:24.815289: train Epoch: [48][ 19/129]	Time  0.950 ( 1.929)	Data  0.001 ( 0.978)	Loss 7.0854e-02 (7.9627e-02) 
2023-05-25 23:53:27.455720: train Epoch: [48][ 20/129]	Time  2.640 ( 1.963)	Data  1.693 ( 1.012)	Loss 9.5444e-02 (8.0380e-02) 
2023-05-25 23:53:28.404966: train Epoch: [48][ 21/129]	Time  0.949 ( 1.917)	Data  0.001 ( 0.966)	Loss 5.5122e-02 (7.9232e-02) 
2023-05-25 23:53:31.043408: train Epoch: [48][ 22/129]	Time  2.638 ( 1.949)	Data  1.691 ( 0.998)	Loss 1.0110e-01 (8.0183e-02) 
2023-05-25 23:53:31.993290: train Epoch: [48][ 23/129]	Time  0.950 ( 1.907)	Data  0.001 ( 0.956)	Loss 1.0800e-01 (8.1342e-02) 
2023-05-25 23:53:34.663437: train Epoch: [48][ 24/129]	Time  2.670 ( 1.937)	Data  1.722 ( 0.987)	Loss 7.4134e-02 (8.1054e-02) 
2023-05-25 23:53:35.613662: train Epoch: [48][ 25/129]	Time  0.950 ( 1.899)	Data  0.001 ( 0.949)	Loss 6.6133e-02 (8.0480e-02) 
2023-05-25 23:53:38.407623: train Epoch: [48][ 26/129]	Time  2.794 ( 1.933)	Data  1.835 ( 0.982)	Loss 8.3124e-02 (8.0578e-02) 
2023-05-25 23:53:39.358461: train Epoch: [48][ 27/129]	Time  0.951 ( 1.898)	Data  0.001 ( 0.947)	Loss 4.2852e-02 (7.9230e-02) 
2023-05-25 23:53:42.026353: train Epoch: [48][ 28/129]	Time  2.668 ( 1.924)	Data  1.713 ( 0.973)	Loss 5.7822e-02 (7.8492e-02) 
2023-05-25 23:53:42.977015: train Epoch: [48][ 29/129]	Time  0.951 ( 1.892)	Data  0.001 ( 0.941)	Loss 8.1367e-02 (7.8588e-02) 
2023-05-25 23:53:45.721118: train Epoch: [48][ 30/129]	Time  2.744 ( 1.919)	Data  1.798 ( 0.968)	Loss 7.0994e-02 (7.8343e-02) 
2023-05-25 23:53:46.672102: train Epoch: [48][ 31/129]	Time  0.951 ( 1.889)	Data  0.001 ( 0.938)	Loss 7.8731e-02 (7.8355e-02) 
2023-05-25 23:53:49.320669: train Epoch: [48][ 32/129]	Time  2.649 ( 1.912)	Data  1.696 ( 0.961)	Loss 7.5327e-02 (7.8263e-02) 
2023-05-25 23:53:50.270606: train Epoch: [48][ 33/129]	Time  0.950 ( 1.884)	Data  0.001 ( 0.933)	Loss 9.0639e-02 (7.8627e-02) 
2023-05-25 23:53:52.908605: train Epoch: [48][ 34/129]	Time  2.638 ( 1.905)	Data  1.688 ( 0.955)	Loss 6.1256e-02 (7.8131e-02) 
2023-05-25 23:53:53.857358: train Epoch: [48][ 35/129]	Time  0.949 ( 1.879)	Data  0.001 ( 0.928)	Loss 6.2036e-02 (7.7684e-02) 
2023-05-25 23:53:56.543235: train Epoch: [48][ 36/129]	Time  2.686 ( 1.900)	Data  1.727 ( 0.950)	Loss 8.8692e-02 (7.7981e-02) 
2023-05-25 23:53:57.492756: train Epoch: [48][ 37/129]	Time  0.950 ( 1.875)	Data  0.001 ( 0.925)	Loss 8.4246e-02 (7.8146e-02) 
2023-05-25 23:54:00.305939: train Epoch: [48][ 38/129]	Time  2.813 ( 1.899)	Data  1.854 ( 0.948)	Loss 7.5074e-02 (7.8068e-02) 
2023-05-25 23:54:01.255621: train Epoch: [48][ 39/129]	Time  0.950 ( 1.876)	Data  0.001 ( 0.925)	Loss 9.5638e-02 (7.8507e-02) 
2023-05-25 23:54:03.950772: train Epoch: [48][ 40/129]	Time  2.695 ( 1.896)	Data  1.747 ( 0.945)	Loss 8.9480e-02 (7.8774e-02) 
2023-05-25 23:54:04.901141: train Epoch: [48][ 41/129]	Time  0.950 ( 1.873)	Data  0.001 ( 0.922)	Loss 6.0175e-02 (7.8332e-02) 
2023-05-25 23:54:07.575040: train Epoch: [48][ 42/129]	Time  2.674 ( 1.892)	Data  1.721 ( 0.941)	Loss 8.5237e-02 (7.8492e-02) 
2023-05-25 23:54:08.523754: train Epoch: [48][ 43/129]	Time  0.949 ( 1.870)	Data  0.001 ( 0.920)	Loss 9.8733e-02 (7.8952e-02) 
2023-05-25 23:54:11.105222: train Epoch: [48][ 44/129]	Time  2.581 ( 1.886)	Data  1.630 ( 0.935)	Loss 6.3723e-02 (7.8614e-02) 
2023-05-25 23:54:12.056189: train Epoch: [48][ 45/129]	Time  0.951 ( 1.866)	Data  0.001 ( 0.915)	Loss 9.2691e-02 (7.8920e-02) 
2023-05-25 23:54:14.562292: train Epoch: [48][ 46/129]	Time  2.506 ( 1.879)	Data  1.556 ( 0.929)	Loss 6.4983e-02 (7.8623e-02) 
2023-05-25 23:54:15.511121: train Epoch: [48][ 47/129]	Time  0.949 ( 1.860)	Data  0.001 ( 0.909)	Loss 6.2842e-02 (7.8294e-02) 
2023-05-25 23:54:18.326125: train Epoch: [48][ 48/129]	Time  2.815 ( 1.880)	Data  1.856 ( 0.929)	Loss 5.0975e-02 (7.7737e-02) 
2023-05-25 23:54:19.278013: train Epoch: [48][ 49/129]	Time  0.952 ( 1.861)	Data  0.001 ( 0.910)	Loss 7.0736e-02 (7.7597e-02) 
2023-05-25 23:54:21.933889: train Epoch: [48][ 50/129]	Time  2.656 ( 1.877)	Data  1.699 ( 0.926)	Loss 3.7844e-02 (7.6817e-02) 
2023-05-25 23:54:22.882855: train Epoch: [48][ 51/129]	Time  0.949 ( 1.859)	Data  0.001 ( 0.908)	Loss 6.9341e-02 (7.6674e-02) 
2023-05-25 23:54:25.490497: train Epoch: [48][ 52/129]	Time  2.608 ( 1.873)	Data  1.657 ( 0.922)	Loss 7.4895e-02 (7.6640e-02) 
2023-05-25 23:54:26.435713: train Epoch: [48][ 53/129]	Time  0.945 ( 1.856)	Data  0.001 ( 0.905)	Loss 1.0764e-01 (7.7214e-02) 
2023-05-25 23:54:29.074954: train Epoch: [48][ 54/129]	Time  2.639 ( 1.870)	Data  1.689 ( 0.919)	Loss 6.6709e-02 (7.7023e-02) 
2023-05-25 23:54:30.025253: train Epoch: [48][ 55/129]	Time  0.950 ( 1.854)	Data  0.001 ( 0.903)	Loss 1.3427e-01 (7.8045e-02) 
2023-05-25 23:54:32.755029: train Epoch: [48][ 56/129]	Time  2.730 ( 1.869)	Data  1.777 ( 0.918)	Loss 5.0362e-02 (7.7560e-02) 
2023-05-25 23:54:33.704458: train Epoch: [48][ 57/129]	Time  0.949 ( 1.853)	Data  0.001 ( 0.902)	Loss 4.3429e-02 (7.6971e-02) 
2023-05-25 23:54:36.385834: train Epoch: [48][ 58/129]	Time  2.681 ( 1.867)	Data  1.735 ( 0.916)	Loss 9.3252e-02 (7.7247e-02) 
2023-05-25 23:54:37.337063: train Epoch: [48][ 59/129]	Time  0.951 ( 1.852)	Data  0.001 ( 0.901)	Loss 4.6282e-02 (7.6731e-02) 
2023-05-25 23:54:40.016009: train Epoch: [48][ 60/129]	Time  2.679 ( 1.865)	Data  1.725 ( 0.915)	Loss 5.7385e-02 (7.6414e-02) 
2023-05-25 23:54:40.977458: train Epoch: [48][ 61/129]	Time  0.961 ( 1.851)	Data  0.001 ( 0.900)	Loss 4.9222e-02 (7.5975e-02) 
2023-05-25 23:54:43.714535: train Epoch: [48][ 62/129]	Time  2.737 ( 1.865)	Data  1.770 ( 0.914)	Loss 1.1622e-01 (7.6614e-02) 
2023-05-25 23:54:44.677117: train Epoch: [48][ 63/129]	Time  0.963 ( 1.851)	Data  0.001 ( 0.899)	Loss 9.1803e-02 (7.6852e-02) 
2023-05-25 23:54:47.240212: train Epoch: [48][ 64/129]	Time  2.563 ( 1.862)	Data  1.595 ( 0.910)	Loss 5.9130e-02 (7.6579e-02) 
2023-05-25 23:54:48.201290: train Epoch: [48][ 65/129]	Time  0.961 ( 1.848)	Data  0.001 ( 0.896)	Loss 4.0905e-02 (7.6038e-02) 
2023-05-25 23:54:50.821657: train Epoch: [48][ 66/129]	Time  2.620 ( 1.860)	Data  1.651 ( 0.908)	Loss 4.7102e-02 (7.5607e-02) 
2023-05-25 23:54:51.771904: train Epoch: [48][ 67/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.894)	Loss 1.8486e-01 (7.7213e-02) 
2023-05-25 23:54:54.403106: train Epoch: [48][ 68/129]	Time  2.631 ( 1.858)	Data  1.671 ( 0.906)	Loss 9.7367e-02 (7.7505e-02) 
2023-05-25 23:54:55.352743: train Epoch: [48][ 69/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.893)	Loss 7.9213e-02 (7.7530e-02) 
2023-05-25 23:54:58.046123: train Epoch: [48][ 70/129]	Time  2.693 ( 1.857)	Data  1.747 ( 0.905)	Loss 6.0431e-02 (7.7289e-02) 
2023-05-25 23:54:58.996385: train Epoch: [48][ 71/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.892)	Loss 5.6137e-02 (7.6995e-02) 
2023-05-25 23:55:01.650784: train Epoch: [48][ 72/129]	Time  2.654 ( 1.855)	Data  1.707 ( 0.903)	Loss 6.0692e-02 (7.6772e-02) 
2023-05-25 23:55:02.602279: train Epoch: [48][ 73/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.891)	Loss 9.4251e-02 (7.7008e-02) 
2023-05-25 23:55:05.298794: train Epoch: [48][ 74/129]	Time  2.697 ( 1.854)	Data  1.744 ( 0.902)	Loss 7.3073e-02 (7.6956e-02) 
2023-05-25 23:55:06.249794: train Epoch: [48][ 75/129]	Time  0.951 ( 1.842)	Data  0.001 ( 0.891)	Loss 6.4667e-02 (7.6794e-02) 
2023-05-25 23:55:08.925978: train Epoch: [48][ 76/129]	Time  2.676 ( 1.853)	Data  1.729 ( 0.901)	Loss 5.2086e-02 (7.6473e-02) 
2023-05-25 23:55:09.876323: train Epoch: [48][ 77/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.890)	Loss 6.7158e-02 (7.6354e-02) 
2023-05-25 23:55:12.567469: train Epoch: [48][ 78/129]	Time  2.691 ( 1.852)	Data  1.744 ( 0.901)	Loss 5.3166e-02 (7.6060e-02) 
2023-05-25 23:55:13.517297: train Epoch: [48][ 79/129]	Time  0.950 ( 1.841)	Data  0.001 ( 0.889)	Loss 1.0766e-01 (7.6455e-02) 
2023-05-25 23:55:16.238791: train Epoch: [48][ 80/129]	Time  2.722 ( 1.852)	Data  1.769 ( 0.900)	Loss 6.1716e-02 (7.6273e-02) 
2023-05-25 23:55:17.189973: train Epoch: [48][ 81/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.889)	Loss 1.0482e-01 (7.6621e-02) 
2023-05-25 23:55:19.886479: train Epoch: [48][ 82/129]	Time  2.696 ( 1.851)	Data  1.747 ( 0.900)	Loss 1.2530e-01 (7.7208e-02) 
2023-05-25 23:55:20.836797: train Epoch: [48][ 83/129]	Time  0.950 ( 1.841)	Data  0.001 ( 0.889)	Loss 5.4264e-02 (7.6935e-02) 
2023-05-25 23:55:23.509452: train Epoch: [48][ 84/129]	Time  2.673 ( 1.850)	Data  1.725 ( 0.899)	Loss 7.4489e-02 (7.6906e-02) 
2023-05-25 23:55:24.459911: train Epoch: [48][ 85/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.888)	Loss 9.7436e-02 (7.7145e-02) 
2023-05-25 23:55:27.141983: train Epoch: [48][ 86/129]	Time  2.682 ( 1.850)	Data  1.733 ( 0.898)	Loss 8.1221e-02 (7.7191e-02) 
2023-05-25 23:55:28.091391: train Epoch: [48][ 87/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.888)	Loss 7.4654e-02 (7.7163e-02) 
2023-05-25 23:55:30.696892: train Epoch: [48][ 88/129]	Time  2.605 ( 1.848)	Data  1.657 ( 0.897)	Loss 7.5002e-02 (7.7138e-02) 
2023-05-25 23:55:31.648517: train Epoch: [48][ 89/129]	Time  0.952 ( 1.838)	Data  0.001 ( 0.887)	Loss 9.9209e-02 (7.7384e-02) 
2023-05-25 23:55:34.334861: train Epoch: [48][ 90/129]	Time  2.686 ( 1.847)	Data  1.735 ( 0.896)	Loss 7.1580e-02 (7.7320e-02) 
2023-05-25 23:55:35.296119: train Epoch: [48][ 91/129]	Time  0.961 ( 1.838)	Data  0.001 ( 0.886)	Loss 8.4255e-02 (7.7395e-02) 
2023-05-25 23:55:37.900800: train Epoch: [48][ 92/129]	Time  2.605 ( 1.846)	Data  1.647 ( 0.894)	Loss 4.0364e-02 (7.6997e-02) 
2023-05-25 23:55:38.851629: train Epoch: [48][ 93/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.885)	Loss 7.2440e-02 (7.6948e-02) 
2023-05-25 23:55:41.470105: train Epoch: [48][ 94/129]	Time  2.618 ( 1.845)	Data  1.664 ( 0.893)	Loss 7.4005e-02 (7.6918e-02) 
2023-05-25 23:55:42.420987: train Epoch: [48][ 95/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.884)	Loss 5.0500e-02 (7.6642e-02) 
2023-05-25 23:55:45.169559: train Epoch: [48][ 96/129]	Time  2.749 ( 1.845)	Data  1.792 ( 0.893)	Loss 5.7666e-02 (7.6447e-02) 
2023-05-25 23:55:46.118134: train Epoch: [48][ 97/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.884)	Loss 1.1002e-01 (7.6789e-02) 
2023-05-25 23:55:48.788943: train Epoch: [48][ 98/129]	Time  2.671 ( 1.844)	Data  1.723 ( 0.893)	Loss 7.0155e-02 (7.6722e-02) 
2023-05-25 23:55:49.740031: train Epoch: [48][ 99/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.884)	Loss 6.5159e-02 (7.6607e-02) 
2023-05-25 23:55:52.492634: train Epoch: [48][100/129]	Time  2.753 ( 1.844)	Data  1.793 ( 0.893)	Loss 6.9906e-02 (7.6540e-02) 
2023-05-25 23:55:53.443024: train Epoch: [48][101/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.884)	Loss 5.0138e-02 (7.6281e-02) 
2023-05-25 23:55:56.225042: train Epoch: [48][102/129]	Time  2.782 ( 1.845)	Data  1.835 ( 0.893)	Loss 5.6528e-02 (7.6090e-02) 
2023-05-25 23:55:57.174364: train Epoch: [48][103/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.885)	Loss 8.7378e-02 (7.6198e-02) 
2023-05-25 23:55:59.811290: train Epoch: [48][104/129]	Time  2.637 ( 1.844)	Data  1.690 ( 0.892)	Loss 4.7600e-02 (7.5926e-02) 
2023-05-25 23:56:00.760848: train Epoch: [48][105/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.884)	Loss 5.8529e-02 (7.5762e-02) 
2023-05-25 23:56:03.540478: train Epoch: [48][106/129]	Time  2.780 ( 1.844)	Data  1.835 ( 0.893)	Loss 6.6786e-02 (7.5678e-02) 
2023-05-25 23:56:04.488357: train Epoch: [48][107/129]	Time  0.948 ( 1.836)	Data  0.001 ( 0.884)	Loss 5.8259e-02 (7.5517e-02) 
2023-05-25 23:56:07.164380: train Epoch: [48][108/129]	Time  2.676 ( 1.843)	Data  1.731 ( 0.892)	Loss 6.2351e-02 (7.5396e-02) 
2023-05-25 23:56:08.113159: train Epoch: [48][109/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.884)	Loss 9.4078e-02 (7.5566e-02) 
2023-05-25 23:56:10.769006: train Epoch: [48][110/129]	Time  2.656 ( 1.843)	Data  1.709 ( 0.892)	Loss 7.5776e-02 (7.5567e-02) 
2023-05-25 23:56:11.719845: train Epoch: [48][111/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.884)	Loss 5.9730e-02 (7.5426e-02) 
2023-05-25 23:56:14.352867: train Epoch: [48][112/129]	Time  2.633 ( 1.842)	Data  1.687 ( 0.891)	Loss 7.3545e-02 (7.5409e-02) 
2023-05-25 23:56:15.303391: train Epoch: [48][113/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.883)	Loss 6.0962e-02 (7.5283e-02) 
2023-05-25 23:56:17.965356: train Epoch: [48][114/129]	Time  2.662 ( 1.841)	Data  1.716 ( 0.890)	Loss 5.4463e-02 (7.5102e-02) 
2023-05-25 23:56:18.915521: train Epoch: [48][115/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.882)	Loss 1.1775e-01 (7.5469e-02) 
2023-05-25 23:56:21.635170: train Epoch: [48][116/129]	Time  2.720 ( 1.841)	Data  1.774 ( 0.890)	Loss 9.9070e-02 (7.5671e-02) 
2023-05-25 23:56:22.586286: train Epoch: [48][117/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.883)	Loss 6.4577e-02 (7.5577e-02) 
2023-05-25 23:56:25.197416: train Epoch: [48][118/129]	Time  2.611 ( 1.840)	Data  1.657 ( 0.889)	Loss 9.1211e-02 (7.5708e-02) 
2023-05-25 23:56:26.158095: train Epoch: [48][119/129]	Time  0.961 ( 1.833)	Data  0.001 ( 0.882)	Loss 5.5689e-02 (7.5542e-02) 
2023-05-25 23:56:28.783378: train Epoch: [48][120/129]	Time  2.625 ( 1.839)	Data  1.670 ( 0.888)	Loss 6.6535e-02 (7.5467e-02) 
2023-05-25 23:56:29.743986: train Epoch: [48][121/129]	Time  0.961 ( 1.832)	Data  0.001 ( 0.881)	Loss 9.7922e-02 (7.5651e-02) 
2023-05-25 23:56:32.326391: train Epoch: [48][122/129]	Time  2.582 ( 1.838)	Data  1.627 ( 0.887)	Loss 7.7169e-02 (7.5664e-02) 
2023-05-25 23:56:33.285380: train Epoch: [48][123/129]	Time  0.959 ( 1.831)	Data  0.001 ( 0.880)	Loss 9.3754e-02 (7.5809e-02) 
2023-05-25 23:56:35.945192: train Epoch: [48][124/129]	Time  2.660 ( 1.838)	Data  1.705 ( 0.886)	Loss 5.8036e-02 (7.5667e-02) 
2023-05-25 23:56:36.906021: train Epoch: [48][125/129]	Time  0.961 ( 1.831)	Data  0.001 ( 0.879)	Loss 7.3417e-02 (7.5649e-02) 
2023-05-25 23:56:39.512175: train Epoch: [48][126/129]	Time  2.606 ( 1.837)	Data  1.645 ( 0.885)	Loss 9.6484e-02 (7.5813e-02) 
2023-05-25 23:56:40.457037: train Epoch: [48][127/129]	Time  0.945 ( 1.830)	Data  0.001 ( 0.878)	Loss 8.0969e-02 (7.5854e-02) 
2023-05-25 23:56:41.891672: train Epoch: [48][128/129]	Time  1.435 ( 1.827)	Data  0.489 ( 0.875)	Loss 6.3570e-02 (7.5759e-02) 
2023-05-25 23:56:41.923088: Train Epoch done in 235.69570373199895 s 
2023-05-25 23:56:44.184646: val Epoch: [48][ 0/72]	Time  1.590 ( 1.590)	Data  1.384 ( 1.384)	Loss 4.1773e-02 (4.1773e-02) 
2023-05-25 23:56:44.309932: val Epoch: [48][ 1/72]	Time  0.125 ( 0.858)	Data  0.001 ( 0.693)	Loss 4.3842e-02 (4.2807e-02) 
2023-05-25 23:56:45.312113: val Epoch: [48][ 2/72]	Time  1.002 ( 0.906)	Data  0.877 ( 0.754)	Loss 4.6491e-02 (4.4035e-02) 
2023-05-25 23:56:45.437326: val Epoch: [48][ 3/72]	Time  0.125 ( 0.711)	Data  0.001 ( 0.566)	Loss 6.3704e-02 (4.8952e-02) 
2023-05-25 23:56:46.623771: val Epoch: [48][ 4/72]	Time  1.186 ( 0.806)	Data  1.059 ( 0.664)	Loss 6.8928e-02 (5.2948e-02) 
2023-05-25 23:56:46.749180: val Epoch: [48][ 5/72]	Time  0.125 ( 0.692)	Data  0.001 ( 0.554)	Loss 5.7078e-02 (5.3636e-02) 
2023-05-25 23:56:47.914390: val Epoch: [48][ 6/72]	Time  1.165 ( 0.760)	Data  1.038 ( 0.623)	Loss 1.1795e-01 (6.2823e-02) 
2023-05-25 23:56:48.040731: val Epoch: [48][ 7/72]	Time  0.126 ( 0.681)	Data  0.001 ( 0.545)	Loss 3.8918e-01 (1.0362e-01) 
2023-05-25 23:56:49.155049: val Epoch: [48][ 8/72]	Time  1.114 ( 0.729)	Data  0.986 ( 0.594)	Loss 5.2948e-02 (9.7988e-02) 
2023-05-25 23:56:49.281073: val Epoch: [48][ 9/72]	Time  0.126 ( 0.669)	Data  0.001 ( 0.535)	Loss 4.3154e-02 (9.2504e-02) 
2023-05-25 23:56:50.426271: val Epoch: [48][10/72]	Time  1.145 ( 0.712)	Data  1.019 ( 0.579)	Loss 9.4382e-02 (9.2675e-02) 
2023-05-25 23:56:50.551425: val Epoch: [48][11/72]	Time  0.125 ( 0.663)	Data  0.001 ( 0.531)	Loss 4.6913e-02 (8.8861e-02) 
2023-05-25 23:56:51.663087: val Epoch: [48][12/72]	Time  1.112 ( 0.698)	Data  0.986 ( 0.566)	Loss 1.3040e-01 (9.2056e-02) 
2023-05-25 23:56:51.788328: val Epoch: [48][13/72]	Time  0.125 ( 0.657)	Data  0.001 ( 0.525)	Loss 7.6808e-02 (9.0967e-02) 
2023-05-25 23:56:52.903566: val Epoch: [48][14/72]	Time  1.115 ( 0.687)	Data  0.987 ( 0.556)	Loss 5.2760e-01 (1.2008e-01) 
2023-05-25 23:56:53.043986: val Epoch: [48][15/72]	Time  0.140 ( 0.653)	Data  0.015 ( 0.522)	Loss 4.8101e-02 (1.1558e-01) 
2023-05-25 23:56:54.127538: val Epoch: [48][16/72]	Time  1.084 ( 0.678)	Data  0.957 ( 0.548)	Loss 8.4879e-02 (1.1377e-01) 
2023-05-25 23:56:54.318001: val Epoch: [48][17/72]	Time  0.190 ( 0.651)	Data  0.063 ( 0.521)	Loss 1.5368e-01 (1.1599e-01) 
2023-05-25 23:56:55.362624: val Epoch: [48][18/72]	Time  1.045 ( 0.672)	Data  0.919 ( 0.542)	Loss 3.8580e-01 (1.3019e-01) 
2023-05-25 23:56:55.508241: val Epoch: [48][19/72]	Time  0.146 ( 0.646)	Data  0.021 ( 0.516)	Loss 7.8732e-02 (1.2762e-01) 
2023-05-25 23:56:56.566257: val Epoch: [48][20/72]	Time  1.058 ( 0.665)	Data  0.933 ( 0.536)	Loss 1.2476e-01 (1.2748e-01) 
2023-05-25 23:56:56.712995: val Epoch: [48][21/72]	Time  0.147 ( 0.642)	Data  0.021 ( 0.512)	Loss 3.4918e-02 (1.2327e-01) 
2023-05-25 23:56:57.744318: val Epoch: [48][22/72]	Time  1.031 ( 0.659)	Data  0.906 ( 0.529)	Loss 6.2910e-02 (1.2065e-01) 
2023-05-25 23:56:57.956836: val Epoch: [48][23/72]	Time  0.213 ( 0.640)	Data  0.088 ( 0.511)	Loss 5.9333e-02 (1.1809e-01) 
2023-05-25 23:56:59.010439: val Epoch: [48][24/72]	Time  1.054 ( 0.657)	Data  0.928 ( 0.528)	Loss 8.6399e-02 (1.1683e-01) 
2023-05-25 23:56:59.174489: val Epoch: [48][25/72]	Time  0.164 ( 0.638)	Data  0.039 ( 0.509)	Loss 4.7033e-02 (1.1414e-01) 
2023-05-25 23:57:00.217269: val Epoch: [48][26/72]	Time  1.043 ( 0.653)	Data  0.917 ( 0.524)	Loss 1.2649e-01 (1.1460e-01) 
2023-05-25 23:57:00.403471: val Epoch: [48][27/72]	Time  0.186 ( 0.636)	Data  0.061 ( 0.507)	Loss 1.5538e-01 (1.1606e-01) 
2023-05-25 23:57:01.457770: val Epoch: [48][28/72]	Time  1.054 ( 0.650)	Data  0.928 ( 0.522)	Loss 3.2941e-01 (1.2341e-01) 
2023-05-25 23:57:01.632981: val Epoch: [48][29/72]	Time  0.175 ( 0.635)	Data  0.051 ( 0.506)	Loss 1.3431e-01 (1.2378e-01) 
2023-05-25 23:57:02.685244: val Epoch: [48][30/72]	Time  1.052 ( 0.648)	Data  0.927 ( 0.520)	Loss 2.6270e-01 (1.2826e-01) 
2023-05-25 23:57:02.853859: val Epoch: [48][31/72]	Time  0.169 ( 0.633)	Data  0.044 ( 0.505)	Loss 3.7245e-02 (1.2541e-01) 
2023-05-25 23:57:03.881209: val Epoch: [48][32/72]	Time  1.027 ( 0.645)	Data  0.901 ( 0.517)	Loss 8.4880e-02 (1.2418e-01) 
2023-05-25 23:57:04.105288: val Epoch: [48][33/72]	Time  0.224 ( 0.633)	Data  0.100 ( 0.505)	Loss 4.9975e-02 (1.2200e-01) 
2023-05-25 23:57:05.115727: val Epoch: [48][34/72]	Time  1.010 ( 0.643)	Data  0.885 ( 0.516)	Loss 3.4296e-01 (1.2832e-01) 
2023-05-25 23:57:05.319124: val Epoch: [48][35/72]	Time  0.203 ( 0.631)	Data  0.079 ( 0.503)	Loss 6.7975e-02 (1.2664e-01) 
2023-05-25 23:57:06.308048: val Epoch: [48][36/72]	Time  0.989 ( 0.641)	Data  0.863 ( 0.513)	Loss 4.8465e-02 (1.2453e-01) 
2023-05-25 23:57:06.575183: val Epoch: [48][37/72]	Time  0.267 ( 0.631)	Data  0.143 ( 0.503)	Loss 9.0909e-02 (1.2364e-01) 
2023-05-25 23:57:07.541533: val Epoch: [48][38/72]	Time  0.966 ( 0.640)	Data  0.841 ( 0.512)	Loss 9.4581e-02 (1.2290e-01) 
2023-05-25 23:57:07.815928: val Epoch: [48][39/72]	Time  0.274 ( 0.631)	Data  0.150 ( 0.503)	Loss 5.4626e-02 (1.2119e-01) 
2023-05-25 23:57:08.776477: val Epoch: [48][40/72]	Time  0.961 ( 0.639)	Data  0.834 ( 0.511)	Loss 7.6277e-02 (1.2009e-01) 
2023-05-25 23:57:09.033969: val Epoch: [48][41/72]	Time  0.257 ( 0.630)	Data  0.133 ( 0.502)	Loss 4.4094e-01 (1.2773e-01) 
2023-05-25 23:57:09.940796: val Epoch: [48][42/72]	Time  0.907 ( 0.636)	Data  0.779 ( 0.509)	Loss 4.2124e-02 (1.2574e-01) 
2023-05-25 23:57:10.280762: val Epoch: [48][43/72]	Time  0.340 ( 0.629)	Data  0.216 ( 0.502)	Loss 4.3565e-01 (1.3279e-01) 
2023-05-25 23:57:11.137605: val Epoch: [48][44/72]	Time  0.857 ( 0.634)	Data  0.730 ( 0.507)	Loss 6.1912e-02 (1.3121e-01) 
2023-05-25 23:57:11.487845: val Epoch: [48][45/72]	Time  0.350 ( 0.628)	Data  0.226 ( 0.501)	Loss 1.0390e-01 (1.3062e-01) 
2023-05-25 23:57:12.380992: val Epoch: [48][46/72]	Time  0.893 ( 0.634)	Data  0.766 ( 0.506)	Loss 5.8302e-02 (1.2908e-01) 
2023-05-25 23:57:12.735720: val Epoch: [48][47/72]	Time  0.355 ( 0.628)	Data  0.230 ( 0.501)	Loss 6.3001e-02 (1.2770e-01) 
2023-05-25 23:57:13.689604: val Epoch: [48][48/72]	Time  0.954 ( 0.635)	Data  0.826 ( 0.507)	Loss 8.4029e-02 (1.2681e-01) 
2023-05-25 23:57:13.991648: val Epoch: [48][49/72]	Time  0.302 ( 0.628)	Data  0.177 ( 0.501)	Loss 2.8994e-01 (1.3007e-01) 
2023-05-25 23:57:14.912364: val Epoch: [48][50/72]	Time  0.921 ( 0.634)	Data  0.793 ( 0.506)	Loss 4.8648e-02 (1.2848e-01) 
2023-05-25 23:57:15.216369: val Epoch: [48][51/72]	Time  0.304 ( 0.627)	Data  0.179 ( 0.500)	Loss 1.0176e-01 (1.2796e-01) 
2023-05-25 23:57:16.142585: val Epoch: [48][52/72]	Time  0.926 ( 0.633)	Data  0.799 ( 0.506)	Loss 3.5591e-02 (1.2622e-01) 
2023-05-25 23:57:16.415018: val Epoch: [48][53/72]	Time  0.272 ( 0.626)	Data  0.148 ( 0.499)	Loss 6.2690e-02 (1.2504e-01) 
2023-05-25 23:57:17.368607: val Epoch: [48][54/72]	Time  0.954 ( 0.632)	Data  0.826 ( 0.505)	Loss 1.8113e-01 (1.2606e-01) 
2023-05-25 23:57:17.639734: val Epoch: [48][55/72]	Time  0.271 ( 0.626)	Data  0.147 ( 0.499)	Loss 2.3714e-01 (1.2805e-01) 
2023-05-25 23:57:18.605631: val Epoch: [48][56/72]	Time  0.966 ( 0.632)	Data  0.839 ( 0.505)	Loss 1.1237e-01 (1.2777e-01) 
2023-05-25 23:57:18.861783: val Epoch: [48][57/72]	Time  0.256 ( 0.625)	Data  0.131 ( 0.498)	Loss 1.2056e-01 (1.2765e-01) 
2023-05-25 23:57:19.860600: val Epoch: [48][58/72]	Time  0.999 ( 0.632)	Data  0.873 ( 0.505)	Loss 1.0028e-01 (1.2718e-01) 
2023-05-25 23:57:20.073286: val Epoch: [48][59/72]	Time  0.213 ( 0.625)	Data  0.087 ( 0.498)	Loss 5.2637e-02 (1.2594e-01) 
2023-05-25 23:57:21.053796: val Epoch: [48][60/72]	Time  0.981 ( 0.630)	Data  0.854 ( 0.504)	Loss 7.2822e-02 (1.2507e-01) 
2023-05-25 23:57:21.326134: val Epoch: [48][61/72]	Time  0.272 ( 0.625)	Data  0.148 ( 0.498)	Loss 1.2062e-01 (1.2500e-01) 
2023-05-25 23:57:22.277816: val Epoch: [48][62/72]	Time  0.952 ( 0.630)	Data  0.825 ( 0.503)	Loss 8.6875e-02 (1.2439e-01) 
2023-05-25 23:57:22.542403: val Epoch: [48][63/72]	Time  0.265 ( 0.624)	Data  0.140 ( 0.497)	Loss 3.6083e-02 (1.2301e-01) 
2023-05-25 23:57:23.496561: val Epoch: [48][64/72]	Time  0.954 ( 0.629)	Data  0.827 ( 0.502)	Loss 2.3032e-01 (1.2466e-01) 
2023-05-25 23:57:23.764896: val Epoch: [48][65/72]	Time  0.268 ( 0.624)	Data  0.143 ( 0.497)	Loss 6.0986e-02 (1.2370e-01) 
2023-05-25 23:57:24.731700: val Epoch: [48][66/72]	Time  0.967 ( 0.629)	Data  0.841 ( 0.502)	Loss 2.8684e-01 (1.2613e-01) 
2023-05-25 23:57:24.992999: val Epoch: [48][67/72]	Time  0.261 ( 0.624)	Data  0.137 ( 0.497)	Loss 5.4576e-02 (1.2508e-01) 
2023-05-25 23:57:26.019557: val Epoch: [48][68/72]	Time  1.027 ( 0.629)	Data  0.899 ( 0.503)	Loss 2.0061e-01 (1.2618e-01) 
2023-05-25 23:57:26.207042: val Epoch: [48][69/72]	Time  0.187 ( 0.623)	Data  0.063 ( 0.496)	Loss 5.4380e-02 (1.2515e-01) 
2023-05-25 23:57:27.209919: val Epoch: [48][70/72]	Time  1.003 ( 0.628)	Data  0.876 ( 0.502)	Loss 5.7949e-02 (1.2420e-01) 
2023-05-25 23:57:27.381270: val Epoch: [48][71/72]	Time  0.171 ( 0.622)	Data  0.047 ( 0.495)	Loss 7.0447e-02 (1.2346e-01) 
2023-05-25 23:57:27.559946: Epoch 48 :Val : ['ET : 0.7525843977928162', 'TC : 0.7913231253623962', 'WT : 0.8686054944992065'] 
2023-05-25 23:57:27.563044: Epoch 48 :Val : ['ET : 0.7525843977928162', 'TC : 0.7913231253623962', 'WT : 0.8686054944992065'] 
2023-05-25 23:57:27.565523: Val epoch done in 45.64246362099948 s 
2023-05-25 23:57:27.571206: Batches per epoch:  129 
2023-05-25 23:57:32.396147: train Epoch: [49][  0/129]	Time  4.825 ( 4.825)	Data  3.829 ( 3.829)	Loss 5.7304e-02 (5.7304e-02) 
2023-05-25 23:57:33.347373: train Epoch: [49][  1/129]	Time  0.951 ( 2.888)	Data  0.001 ( 1.915)	Loss 8.3374e-02 (7.0339e-02) 
2023-05-25 23:57:35.965878: train Epoch: [49][  2/129]	Time  2.618 ( 2.798)	Data  1.670 ( 1.833)	Loss 1.1708e-01 (8.5920e-02) 
2023-05-25 23:57:36.918182: train Epoch: [49][  3/129]	Time  0.952 ( 2.337)	Data  0.001 ( 1.375)	Loss 6.4441e-02 (8.0550e-02) 
2023-05-25 23:57:39.849338: train Epoch: [49][  4/129]	Time  2.931 ( 2.456)	Data  1.983 ( 1.497)	Loss 9.1559e-02 (8.2752e-02) 
2023-05-25 23:57:40.797787: train Epoch: [49][  5/129]	Time  0.948 ( 2.204)	Data  0.001 ( 1.248)	Loss 9.4718e-02 (8.4746e-02) 
2023-05-25 23:57:43.451136: train Epoch: [49][  6/129]	Time  2.653 ( 2.269)	Data  1.706 ( 1.313)	Loss 7.7029e-02 (8.3644e-02) 
2023-05-25 23:57:44.399728: train Epoch: [49][  7/129]	Time  0.949 ( 2.104)	Data  0.001 ( 1.149)	Loss 6.5529e-02 (8.1380e-02) 
2023-05-25 23:57:47.173652: train Epoch: [49][  8/129]	Time  2.774 ( 2.178)	Data  1.827 ( 1.224)	Loss 7.5248e-02 (8.0698e-02) 
2023-05-25 23:57:48.125095: train Epoch: [49][  9/129]	Time  0.951 ( 2.055)	Data  0.001 ( 1.102)	Loss 8.2368e-02 (8.0865e-02) 
2023-05-25 23:57:50.857375: train Epoch: [49][ 10/129]	Time  2.732 ( 2.117)	Data  1.785 ( 1.164)	Loss 7.7368e-02 (8.0547e-02) 
2023-05-25 23:57:51.808338: train Epoch: [49][ 11/129]	Time  0.951 ( 2.020)	Data  0.001 ( 1.067)	Loss 1.1029e-01 (8.3026e-02) 
2023-05-25 23:57:54.687929: train Epoch: [49][ 12/129]	Time  2.880 ( 2.086)	Data  1.934 ( 1.134)	Loss 8.0056e-02 (8.2797e-02) 
2023-05-25 23:57:55.637846: train Epoch: [49][ 13/129]	Time  0.950 ( 2.005)	Data  0.001 ( 1.053)	Loss 5.8317e-02 (8.1049e-02) 
2023-05-25 23:57:58.293678: train Epoch: [49][ 14/129]	Time  2.656 ( 2.048)	Data  1.711 ( 1.097)	Loss 5.2121e-02 (7.9120e-02) 
2023-05-25 23:57:59.243306: train Epoch: [49][ 15/129]	Time  0.950 ( 1.979)	Data  0.001 ( 1.028)	Loss 6.4394e-02 (7.8200e-02) 
2023-05-25 23:58:01.838346: train Epoch: [49][ 16/129]	Time  2.595 ( 2.016)	Data  1.649 ( 1.065)	Loss 1.8424e-01 (8.4437e-02) 
2023-05-25 23:58:02.787484: train Epoch: [49][ 17/129]	Time  0.949 ( 1.956)	Data  0.001 ( 1.006)	Loss 7.0145e-02 (8.3643e-02) 
2023-05-25 23:58:05.395124: train Epoch: [49][ 18/129]	Time  2.608 ( 1.991)	Data  1.661 ( 1.040)	Loss 4.9615e-02 (8.1852e-02) 
2023-05-25 23:58:06.345035: train Epoch: [49][ 19/129]	Time  0.950 ( 1.939)	Data  0.001 ( 0.988)	Loss 1.1019e-01 (8.3269e-02) 
2023-05-25 23:58:08.987703: train Epoch: [49][ 20/129]	Time  2.643 ( 1.972)	Data  1.696 ( 1.022)	Loss 1.1552e-01 (8.4805e-02) 
2023-05-25 23:58:09.938957: train Epoch: [49][ 21/129]	Time  0.951 ( 1.926)	Data  0.001 ( 0.976)	Loss 7.7125e-02 (8.4456e-02) 
2023-05-25 23:58:12.630436: train Epoch: [49][ 22/129]	Time  2.691 ( 1.959)	Data  1.735 ( 1.009)	Loss 5.4328e-02 (8.3146e-02) 
2023-05-25 23:58:13.581524: train Epoch: [49][ 23/129]	Time  0.951 ( 1.917)	Data  0.001 ( 0.967)	Loss 8.4819e-02 (8.3216e-02) 
2023-05-25 23:58:16.212818: train Epoch: [49][ 24/129]	Time  2.631 ( 1.946)	Data  1.680 ( 0.995)	Loss 6.6599e-02 (8.2551e-02) 
2023-05-25 23:58:17.163577: train Epoch: [49][ 25/129]	Time  0.951 ( 1.907)	Data  0.001 ( 0.957)	Loss 6.7028e-02 (8.1954e-02) 
2023-05-25 23:58:19.851413: train Epoch: [49][ 26/129]	Time  2.688 ( 1.936)	Data  1.738 ( 0.986)	Loss 6.4700e-02 (8.1315e-02) 
2023-05-25 23:58:20.804199: train Epoch: [49][ 27/129]	Time  0.953 ( 1.901)	Data  0.001 ( 0.951)	Loss 7.1294e-02 (8.0957e-02) 
2023-05-25 23:58:23.418081: train Epoch: [49][ 28/129]	Time  2.614 ( 1.926)	Data  1.665 ( 0.975)	Loss 8.4869e-02 (8.1092e-02) 
2023-05-25 23:58:24.377963: train Epoch: [49][ 29/129]	Time  0.960 ( 1.894)	Data  0.001 ( 0.943)	Loss 5.1802e-02 (8.0116e-02) 
2023-05-25 23:58:27.018808: train Epoch: [49][ 30/129]	Time  2.641 ( 1.918)	Data  1.692 ( 0.967)	Loss 7.0213e-02 (7.9796e-02) 
2023-05-25 23:58:27.979469: train Epoch: [49][ 31/129]	Time  0.961 ( 1.888)	Data  0.001 ( 0.937)	Loss 6.0114e-02 (7.9181e-02) 
2023-05-25 23:58:30.700253: train Epoch: [49][ 32/129]	Time  2.721 ( 1.913)	Data  1.762 ( 0.962)	Loss 1.3719e-01 (8.0939e-02) 
2023-05-25 23:58:31.650624: train Epoch: [49][ 33/129]	Time  0.950 ( 1.885)	Data  0.001 ( 0.933)	Loss 7.3712e-02 (8.0726e-02) 
2023-05-25 23:58:34.156830: train Epoch: [49][ 34/129]	Time  2.506 ( 1.902)	Data  1.551 ( 0.951)	Loss 5.9116e-02 (8.0109e-02) 
2023-05-25 23:58:35.108220: train Epoch: [49][ 35/129]	Time  0.951 ( 1.876)	Data  0.001 ( 0.925)	Loss 6.3904e-02 (7.9659e-02) 
2023-05-25 23:58:37.857456: train Epoch: [49][ 36/129]	Time  2.749 ( 1.900)	Data  1.800 ( 0.948)	Loss 5.8833e-02 (7.9096e-02) 
2023-05-25 23:58:38.807073: train Epoch: [49][ 37/129]	Time  0.950 ( 1.875)	Data  0.001 ( 0.923)	Loss 8.7780e-02 (7.9325e-02) 
2023-05-25 23:58:41.660311: train Epoch: [49][ 38/129]	Time  2.853 ( 1.900)	Data  1.906 ( 0.949)	Loss 1.0684e-01 (8.0030e-02) 
2023-05-25 23:58:42.610132: train Epoch: [49][ 39/129]	Time  0.950 ( 1.876)	Data  0.001 ( 0.925)	Loss 8.2290e-02 (8.0087e-02) 
2023-05-25 23:58:45.286378: train Epoch: [49][ 40/129]	Time  2.676 ( 1.895)	Data  1.730 ( 0.945)	Loss 6.7641e-02 (7.9783e-02) 
2023-05-25 23:58:46.242480: train Epoch: [49][ 41/129]	Time  0.956 ( 1.873)	Data  0.001 ( 0.922)	Loss 1.0116e-01 (8.0292e-02) 
2023-05-25 23:58:48.931870: train Epoch: [49][ 42/129]	Time  2.689 ( 1.892)	Data  1.744 ( 0.941)	Loss 1.1694e-01 (8.1144e-02) 
2023-05-25 23:58:49.884437: train Epoch: [49][ 43/129]	Time  0.953 ( 1.871)	Data  0.001 ( 0.920)	Loss 1.0334e-01 (8.1649e-02) 
2023-05-25 23:58:52.616461: train Epoch: [49][ 44/129]	Time  2.732 ( 1.890)	Data  1.785 ( 0.939)	Loss 4.8681e-02 (8.0916e-02) 
2023-05-25 23:58:53.565341: train Epoch: [49][ 45/129]	Time  0.949 ( 1.869)	Data  0.001 ( 0.919)	Loss 1.1761e-01 (8.1714e-02) 
2023-05-25 23:58:56.275160: train Epoch: [49][ 46/129]	Time  2.710 ( 1.887)	Data  1.764 ( 0.937)	Loss 6.4611e-02 (8.1350e-02) 
2023-05-25 23:58:57.234558: train Epoch: [49][ 47/129]	Time  0.959 ( 1.868)	Data  0.001 ( 0.917)	Loss 6.7895e-02 (8.1070e-02) 
2023-05-25 23:58:59.829448: train Epoch: [49][ 48/129]	Time  2.595 ( 1.883)	Data  1.639 ( 0.932)	Loss 8.5212e-02 (8.1154e-02) 
2023-05-25 23:59:00.788337: train Epoch: [49][ 49/129]	Time  0.959 ( 1.864)	Data  0.001 ( 0.913)	Loss 9.7170e-02 (8.1474e-02) 
2023-05-25 23:59:03.374889: train Epoch: [49][ 50/129]	Time  2.587 ( 1.878)	Data  1.632 ( 0.927)	Loss 6.8519e-02 (8.1220e-02) 
2023-05-25 23:59:04.333481: train Epoch: [49][ 51/129]	Time  0.959 ( 1.861)	Data  0.001 ( 0.910)	Loss 6.3975e-02 (8.0889e-02) 
2023-05-25 23:59:06.979750: train Epoch: [49][ 52/129]	Time  2.646 ( 1.876)	Data  1.692 ( 0.924)	Loss 1.1737e-01 (8.1577e-02) 
2023-05-25 23:59:07.939894: train Epoch: [49][ 53/129]	Time  0.960 ( 1.859)	Data  0.001 ( 0.907)	Loss 8.2973e-02 (8.1603e-02) 
2023-05-25 23:59:10.615257: train Epoch: [49][ 54/129]	Time  2.675 ( 1.874)	Data  1.730 ( 0.922)	Loss 8.1024e-02 (8.1592e-02) 
2023-05-25 23:59:11.566116: train Epoch: [49][ 55/129]	Time  0.951 ( 1.857)	Data  0.001 ( 0.906)	Loss 8.9107e-02 (8.1727e-02) 
2023-05-25 23:59:14.153626: train Epoch: [49][ 56/129]	Time  2.588 ( 1.870)	Data  1.643 ( 0.919)	Loss 8.1231e-02 (8.1718e-02) 
2023-05-25 23:59:15.103602: train Epoch: [49][ 57/129]	Time  0.950 ( 1.854)	Data  0.001 ( 0.903)	Loss 8.0052e-02 (8.1689e-02) 
2023-05-25 23:59:17.825514: train Epoch: [49][ 58/129]	Time  2.722 ( 1.869)	Data  1.777 ( 0.918)	Loss 5.3163e-02 (8.1206e-02) 
2023-05-25 23:59:18.775865: train Epoch: [49][ 59/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.902)	Loss 7.4893e-02 (8.1101e-02) 
2023-05-25 23:59:21.525777: train Epoch: [49][ 60/129]	Time  2.750 ( 1.868)	Data  1.806 ( 0.917)	Loss 9.2699e-02 (8.1291e-02) 
2023-05-25 23:59:22.474505: train Epoch: [49][ 61/129]	Time  0.949 ( 1.853)	Data  0.001 ( 0.902)	Loss 6.7933e-02 (8.1075e-02) 
2023-05-25 23:59:25.100835: train Epoch: [49][ 62/129]	Time  2.626 ( 1.866)	Data  1.683 ( 0.915)	Loss 7.8106e-02 (8.1028e-02) 
2023-05-25 23:59:26.049746: train Epoch: [49][ 63/129]	Time  0.949 ( 1.851)	Data  0.001 ( 0.901)	Loss 1.7807e-01 (8.2544e-02) 
2023-05-25 23:59:28.736945: train Epoch: [49][ 64/129]	Time  2.687 ( 1.864)	Data  1.744 ( 0.913)	Loss 5.7057e-02 (8.2152e-02) 
2023-05-25 23:59:29.687044: train Epoch: [49][ 65/129]	Time  0.950 ( 1.850)	Data  0.001 ( 0.900)	Loss 8.3571e-02 (8.2174e-02) 
2023-05-25 23:59:32.358016: train Epoch: [49][ 66/129]	Time  2.671 ( 1.862)	Data  1.726 ( 0.912)	Loss 1.0014e-01 (8.2442e-02) 
2023-05-25 23:59:33.307481: train Epoch: [49][ 67/129]	Time  0.949 ( 1.849)	Data  0.001 ( 0.899)	Loss 1.2640e-01 (8.3088e-02) 
2023-05-25 23:59:36.004894: train Epoch: [49][ 68/129]	Time  2.697 ( 1.861)	Data  1.752 ( 0.911)	Loss 8.7586e-02 (8.3154e-02) 
2023-05-25 23:59:36.952997: train Epoch: [49][ 69/129]	Time  0.948 ( 1.848)	Data  0.001 ( 0.898)	Loss 1.1995e-01 (8.3679e-02) 
2023-05-25 23:59:39.541333: train Epoch: [49][ 70/129]	Time  2.588 ( 1.859)	Data  1.642 ( 0.908)	Loss 7.3461e-02 (8.3535e-02) 
2023-05-25 23:59:40.491700: train Epoch: [49][ 71/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.896)	Loss 7.9224e-02 (8.3476e-02) 
2023-05-25 23:59:43.223744: train Epoch: [49][ 72/129]	Time  2.732 ( 1.858)	Data  1.787 ( 0.908)	Loss 8.9823e-02 (8.3562e-02) 
2023-05-25 23:59:44.172650: train Epoch: [49][ 73/129]	Time  0.949 ( 1.846)	Data  0.001 ( 0.896)	Loss 6.8985e-02 (8.3365e-02) 
2023-05-25 23:59:46.819382: train Epoch: [49][ 74/129]	Time  2.647 ( 1.857)	Data  1.702 ( 0.907)	Loss 5.3819e-02 (8.2972e-02) 
2023-05-25 23:59:47.769864: train Epoch: [49][ 75/129]	Time  0.950 ( 1.845)	Data  0.001 ( 0.895)	Loss 8.6142e-02 (8.3013e-02) 
2023-05-25 23:59:50.456528: train Epoch: [49][ 76/129]	Time  2.687 ( 1.856)	Data  1.741 ( 0.906)	Loss 6.5436e-02 (8.2785e-02) 
2023-05-25 23:59:51.405701: train Epoch: [49][ 77/129]	Time  0.949 ( 1.844)	Data  0.001 ( 0.894)	Loss 6.3936e-02 (8.2543e-02) 
2023-05-25 23:59:54.095135: train Epoch: [49][ 78/129]	Time  2.689 ( 1.855)	Data  1.744 ( 0.905)	Loss 1.0994e-01 (8.2890e-02) 
2023-05-25 23:59:55.046105: train Epoch: [49][ 79/129]	Time  0.951 ( 1.843)	Data  0.001 ( 0.893)	Loss 9.5773e-02 (8.3051e-02) 
2023-05-25 23:59:57.668521: train Epoch: [49][ 80/129]	Time  2.622 ( 1.853)	Data  1.676 ( 0.903)	Loss 6.9020e-02 (8.2878e-02) 
2023-05-25 23:59:58.618873: train Epoch: [49][ 81/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.892)	Loss 9.0234e-02 (8.2968e-02) 
2023-05-26 00:00:01.233763: train Epoch: [49][ 82/129]	Time  2.615 ( 1.851)	Data  1.668 ( 0.901)	Loss 6.7534e-02 (8.2782e-02) 
2023-05-26 00:00:02.182881: train Epoch: [49][ 83/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.891)	Loss 6.0597e-02 (8.2518e-02) 
2023-05-26 00:00:04.781740: train Epoch: [49][ 84/129]	Time  2.599 ( 1.850)	Data  1.652 ( 0.900)	Loss 9.1957e-02 (8.2629e-02) 
2023-05-26 00:00:05.731609: train Epoch: [49][ 85/129]	Time  0.950 ( 1.839)	Data  0.001 ( 0.889)	Loss 8.7722e-02 (8.2688e-02) 
2023-05-26 00:00:08.346993: train Epoch: [49][ 86/129]	Time  2.615 ( 1.848)	Data  1.666 ( 0.898)	Loss 1.3173e-01 (8.3252e-02) 
2023-05-26 00:00:09.297026: train Epoch: [49][ 87/129]	Time  0.950 ( 1.838)	Data  0.001 ( 0.888)	Loss 8.1455e-02 (8.3231e-02) 
2023-05-26 00:00:11.958145: train Epoch: [49][ 88/129]	Time  2.661 ( 1.847)	Data  1.712 ( 0.897)	Loss 6.0660e-02 (8.2977e-02) 
2023-05-26 00:00:12.909064: train Epoch: [49][ 89/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.887)	Loss 6.2727e-02 (8.2752e-02) 
2023-05-26 00:00:15.609395: train Epoch: [49][ 90/129]	Time  2.700 ( 1.847)	Data  1.753 ( 0.897)	Loss 5.0881e-02 (8.2402e-02) 
2023-05-26 00:00:16.559922: train Epoch: [49][ 91/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.887)	Loss 4.4649e-02 (8.1992e-02) 
2023-05-26 00:00:19.184674: train Epoch: [49][ 92/129]	Time  2.625 ( 1.845)	Data  1.677 ( 0.896)	Loss 6.5700e-02 (8.1817e-02) 
2023-05-26 00:00:20.136297: train Epoch: [49][ 93/129]	Time  0.952 ( 1.836)	Data  0.001 ( 0.886)	Loss 6.1775e-02 (8.1604e-02) 
2023-05-26 00:00:22.808113: train Epoch: [49][ 94/129]	Time  2.672 ( 1.845)	Data  1.726 ( 0.895)	Loss 8.2870e-02 (8.1617e-02) 
2023-05-26 00:00:23.758403: train Epoch: [49][ 95/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.886)	Loss 7.2542e-02 (8.1522e-02) 
2023-05-26 00:00:26.444228: train Epoch: [49][ 96/129]	Time  2.686 ( 1.844)	Data  1.740 ( 0.894)	Loss 7.7213e-02 (8.1478e-02) 
2023-05-26 00:00:27.396878: train Epoch: [49][ 97/129]	Time  0.953 ( 1.835)	Data  0.001 ( 0.885)	Loss 3.1939e-02 (8.0972e-02) 
2023-05-26 00:00:30.124546: train Epoch: [49][ 98/129]	Time  2.728 ( 1.844)	Data  1.782 ( 0.894)	Loss 5.5321e-02 (8.0713e-02) 
2023-05-26 00:00:31.073791: train Epoch: [49][ 99/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.885)	Loss 6.9634e-02 (8.0602e-02) 
2023-05-26 00:00:33.734137: train Epoch: [49][100/129]	Time  2.660 ( 1.843)	Data  1.713 ( 0.894)	Loss 8.9781e-02 (8.0693e-02) 
2023-05-26 00:00:34.683080: train Epoch: [49][101/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.885)	Loss 9.3218e-02 (8.0816e-02) 
2023-05-26 00:00:37.341059: train Epoch: [49][102/129]	Time  2.658 ( 1.842)	Data  1.712 ( 0.893)	Loss 3.8880e-02 (8.0409e-02) 
2023-05-26 00:00:38.290207: train Epoch: [49][103/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.884)	Loss 4.7376e-02 (8.0091e-02) 
2023-05-26 00:00:40.964593: train Epoch: [49][104/129]	Time  2.674 ( 1.842)	Data  1.728 ( 0.892)	Loss 5.1411e-02 (7.9818e-02) 
2023-05-26 00:00:41.913882: train Epoch: [49][105/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.884)	Loss 5.7606e-02 (7.9609e-02) 
2023-05-26 00:00:44.531734: train Epoch: [49][106/129]	Time  2.618 ( 1.841)	Data  1.670 ( 0.891)	Loss 4.4436e-02 (7.9280e-02) 
2023-05-26 00:00:45.482023: train Epoch: [49][107/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.883)	Loss 8.4526e-02 (7.9329e-02) 
2023-05-26 00:00:48.053166: train Epoch: [49][108/129]	Time  2.571 ( 1.839)	Data  1.625 ( 0.890)	Loss 6.4734e-02 (7.9195e-02) 
2023-05-26 00:00:49.002398: train Epoch: [49][109/129]	Time  0.949 ( 1.831)	Data  0.001 ( 0.882)	Loss 7.1899e-02 (7.9128e-02) 
2023-05-26 00:00:51.617116: train Epoch: [49][110/129]	Time  2.615 ( 1.838)	Data  1.667 ( 0.889)	Loss 5.6938e-02 (7.8928e-02) 
2023-05-26 00:00:52.567647: train Epoch: [49][111/129]	Time  0.951 ( 1.830)	Data  0.001 ( 0.881)	Loss 5.2693e-02 (7.8694e-02) 
2023-05-26 00:00:55.174508: train Epoch: [49][112/129]	Time  2.607 ( 1.837)	Data  1.659 ( 0.888)	Loss 9.1736e-02 (7.8810e-02) 
2023-05-26 00:00:56.126649: train Epoch: [49][113/129]	Time  0.952 ( 1.829)	Data  0.001 ( 0.880)	Loss 6.1505e-02 (7.8658e-02) 
2023-05-26 00:00:58.849485: train Epoch: [49][114/129]	Time  2.723 ( 1.837)	Data  1.775 ( 0.888)	Loss 5.5776e-02 (7.8459e-02) 
2023-05-26 00:00:59.803763: train Epoch: [49][115/129]	Time  0.954 ( 1.830)	Data  0.001 ( 0.880)	Loss 4.9419e-02 (7.8208e-02) 
2023-05-26 00:01:02.474096: train Epoch: [49][116/129]	Time  2.670 ( 1.837)	Data  1.723 ( 0.887)	Loss 6.8638e-02 (7.8127e-02) 
2023-05-26 00:01:03.424768: train Epoch: [49][117/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.880)	Loss 9.0392e-02 (7.8231e-02) 
2023-05-26 00:01:06.014767: train Epoch: [49][118/129]	Time  2.590 ( 1.836)	Data  1.643 ( 0.886)	Loss 7.0502e-02 (7.8166e-02) 
2023-05-26 00:01:06.963920: train Epoch: [49][119/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.879)	Loss 4.5908e-02 (7.7897e-02) 
2023-05-26 00:01:09.676134: train Epoch: [49][120/129]	Time  2.712 ( 1.836)	Data  1.764 ( 0.886)	Loss 5.8617e-02 (7.7738e-02) 
2023-05-26 00:01:10.628024: train Epoch: [49][121/129]	Time  0.952 ( 1.828)	Data  0.001 ( 0.879)	Loss 6.6521e-02 (7.7646e-02) 
2023-05-26 00:01:13.383990: train Epoch: [49][122/129]	Time  2.756 ( 1.836)	Data  1.807 ( 0.886)	Loss 4.7922e-02 (7.7404e-02) 
2023-05-26 00:01:14.333657: train Epoch: [49][123/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.879)	Loss 7.0396e-02 (7.7347e-02) 
2023-05-26 00:01:16.999690: train Epoch: [49][124/129]	Time  2.666 ( 1.835)	Data  1.719 ( 0.886)	Loss 8.7567e-02 (7.7429e-02) 
2023-05-26 00:01:17.950595: train Epoch: [49][125/129]	Time  0.951 ( 1.828)	Data  0.001 ( 0.879)	Loss 7.1118e-02 (7.7379e-02) 
2023-05-26 00:01:20.628685: train Epoch: [49][126/129]	Time  2.678 ( 1.835)	Data  1.730 ( 0.886)	Loss 8.3231e-02 (7.7425e-02) 
2023-05-26 00:01:21.574773: train Epoch: [49][127/129]	Time  0.946 ( 1.828)	Data  0.001 ( 0.879)	Loss 8.8852e-02 (7.7514e-02) 
2023-05-26 00:01:23.037232: train Epoch: [49][128/129]	Time  1.462 ( 1.825)	Data  0.516 ( 0.876)	Loss 5.9270e-02 (7.7373e-02) 
2023-05-26 00:01:23.068610: Train Epoch done in 235.4974840820032 s 
2023-05-26 00:01:25.441753: val Epoch: [49][ 0/72]	Time  1.584 ( 1.584)	Data  1.372 ( 1.372)	Loss 3.1414e-01 (3.1414e-01) 
2023-05-26 00:01:25.566970: val Epoch: [49][ 1/72]	Time  0.125 ( 0.855)	Data  0.001 ( 0.687)	Loss 2.7820e-01 (2.9617e-01) 
2023-05-26 00:01:26.594017: val Epoch: [49][ 2/72]	Time  1.027 ( 0.912)	Data  0.902 ( 0.758)	Loss 9.6085e-02 (2.2947e-01) 
2023-05-26 00:01:26.719129: val Epoch: [49][ 3/72]	Time  0.125 ( 0.715)	Data  0.001 ( 0.569)	Loss 6.9038e-02 (1.8937e-01) 
2023-05-26 00:01:27.884805: val Epoch: [49][ 4/72]	Time  1.166 ( 0.805)	Data  1.040 ( 0.663)	Loss 2.2968e-01 (1.9743e-01) 
2023-05-26 00:01:28.009941: val Epoch: [49][ 5/72]	Time  0.125 ( 0.692)	Data  0.001 ( 0.553)	Loss 1.4982e-01 (1.8950e-01) 
2023-05-26 00:01:29.169538: val Epoch: [49][ 6/72]	Time  1.160 ( 0.759)	Data  1.034 ( 0.621)	Loss 1.5406e-01 (1.8443e-01) 
2023-05-26 00:01:29.294518: val Epoch: [49][ 7/72]	Time  0.125 ( 0.680)	Data  0.001 ( 0.544)	Loss 3.3388e-01 (2.0311e-01) 
2023-05-26 00:01:30.447656: val Epoch: [49][ 8/72]	Time  1.153 ( 0.732)	Data  1.028 ( 0.598)	Loss 6.6723e-02 (1.8796e-01) 
2023-05-26 00:01:30.572397: val Epoch: [49][ 9/72]	Time  0.125 ( 0.671)	Data  0.001 ( 0.538)	Loss 1.6929e-01 (1.8609e-01) 
2023-05-26 00:01:31.732753: val Epoch: [49][10/72]	Time  1.160 ( 0.716)	Data  1.035 ( 0.583)	Loss 4.6565e-02 (1.7341e-01) 
2023-05-26 00:01:31.857532: val Epoch: [49][11/72]	Time  0.125 ( 0.667)	Data  0.001 ( 0.535)	Loss 1.5130e-01 (1.7157e-01) 
2023-05-26 00:01:32.965276: val Epoch: [49][12/72]	Time  1.108 ( 0.701)	Data  0.982 ( 0.569)	Loss 7.9868e-02 (1.6451e-01) 
2023-05-26 00:01:33.090259: val Epoch: [49][13/72]	Time  0.125 ( 0.659)	Data  0.001 ( 0.528)	Loss 4.0592e-02 (1.5566e-01) 
2023-05-26 00:01:34.243492: val Epoch: [49][14/72]	Time  1.153 ( 0.692)	Data  1.028 ( 0.562)	Loss 1.0795e-01 (1.5248e-01) 
2023-05-26 00:01:34.369164: val Epoch: [49][15/72]	Time  0.126 ( 0.657)	Data  0.001 ( 0.527)	Loss 5.6312e-01 (1.7815e-01) 
2023-05-26 00:01:35.494481: val Epoch: [49][16/72]	Time  1.125 ( 0.685)	Data  1.000 ( 0.555)	Loss 5.1891e-02 (1.7072e-01) 
2023-05-26 00:01:35.619603: val Epoch: [49][17/72]	Time  0.125 ( 0.653)	Data  0.001 ( 0.524)	Loss 1.0045e-01 (1.6682e-01) 
2023-05-26 00:01:36.698064: val Epoch: [49][18/72]	Time  1.078 ( 0.676)	Data  0.954 ( 0.546)	Loss 6.8680e-02 (1.6165e-01) 
2023-05-26 00:01:36.822397: val Epoch: [49][19/72]	Time  0.124 ( 0.648)	Data  0.001 ( 0.519)	Loss 2.0763e-01 (1.6395e-01) 
2023-05-26 00:01:37.973775: val Epoch: [49][20/72]	Time  1.151 ( 0.672)	Data  1.027 ( 0.543)	Loss 8.1838e-02 (1.6004e-01) 
2023-05-26 00:01:38.097956: val Epoch: [49][21/72]	Time  0.124 ( 0.647)	Data  0.001 ( 0.519)	Loss 1.0337e-01 (1.5746e-01) 
2023-05-26 00:01:39.213444: val Epoch: [49][22/72]	Time  1.115 ( 0.668)	Data  0.991 ( 0.539)	Loss 1.0647e-01 (1.5525e-01) 
2023-05-26 00:01:39.338264: val Epoch: [49][23/72]	Time  0.125 ( 0.645)	Data  0.001 ( 0.517)	Loss 1.0434e-01 (1.5313e-01) 
2023-05-26 00:01:40.428653: val Epoch: [49][24/72]	Time  1.090 ( 0.663)	Data  0.966 ( 0.535)	Loss 8.1472e-02 (1.5026e-01) 
2023-05-26 00:01:40.553486: val Epoch: [49][25/72]	Time  0.125 ( 0.642)	Data  0.001 ( 0.514)	Loss 5.2656e-02 (1.4651e-01) 
2023-05-26 00:01:41.671986: val Epoch: [49][26/72]	Time  1.118 ( 0.660)	Data  0.994 ( 0.532)	Loss 3.4740e-01 (1.5395e-01) 
2023-05-26 00:01:41.796932: val Epoch: [49][27/72]	Time  0.125 ( 0.641)	Data  0.001 ( 0.513)	Loss 6.3060e-02 (1.5070e-01) 
2023-05-26 00:01:42.942408: val Epoch: [49][28/72]	Time  1.145 ( 0.658)	Data  1.021 ( 0.530)	Loss 7.0748e-02 (1.4794e-01) 
2023-05-26 00:01:43.066711: val Epoch: [49][29/72]	Time  0.124 ( 0.640)	Data  0.000 ( 0.513)	Loss 4.7574e-02 (1.4460e-01) 
2023-05-26 00:01:44.212651: val Epoch: [49][30/72]	Time  1.146 ( 0.657)	Data  1.022 ( 0.529)	Loss 8.3058e-02 (1.4261e-01) 
2023-05-26 00:01:44.338635: val Epoch: [49][31/72]	Time  0.126 ( 0.640)	Data  0.001 ( 0.513)	Loss 7.8331e-02 (1.4060e-01) 
2023-05-26 00:01:45.477219: val Epoch: [49][32/72]	Time  1.139 ( 0.655)	Data  1.014 ( 0.528)	Loss 8.5261e-02 (1.3893e-01) 
2023-05-26 00:01:45.602802: val Epoch: [49][33/72]	Time  0.126 ( 0.640)	Data  0.001 ( 0.512)	Loss 1.8436e-01 (1.4026e-01) 
2023-05-26 00:01:46.682151: val Epoch: [49][34/72]	Time  1.079 ( 0.652)	Data  0.955 ( 0.525)	Loss 2.1825e-01 (1.4249e-01) 
2023-05-26 00:01:46.807937: val Epoch: [49][35/72]	Time  0.126 ( 0.638)	Data  0.001 ( 0.510)	Loss 4.1847e-02 (1.3969e-01) 
2023-05-26 00:01:47.880724: val Epoch: [49][36/72]	Time  1.073 ( 0.649)	Data  0.948 ( 0.522)	Loss 6.0707e-02 (1.3756e-01) 
2023-05-26 00:01:48.007565: val Epoch: [49][37/72]	Time  0.127 ( 0.636)	Data  0.001 ( 0.509)	Loss 1.2359e-01 (1.3719e-01) 
2023-05-26 00:01:49.072524: val Epoch: [49][38/72]	Time  1.065 ( 0.647)	Data  0.941 ( 0.520)	Loss 5.4768e-02 (1.3508e-01) 
2023-05-26 00:01:49.198248: val Epoch: [49][39/72]	Time  0.126 ( 0.634)	Data  0.001 ( 0.507)	Loss 3.9826e-02 (1.3270e-01) 
2023-05-26 00:01:50.251459: val Epoch: [49][40/72]	Time  1.053 ( 0.644)	Data  0.928 ( 0.517)	Loss 7.3784e-02 (1.3126e-01) 
2023-05-26 00:01:50.377622: val Epoch: [49][41/72]	Time  0.126 ( 0.631)	Data  0.000 ( 0.505)	Loss 1.4771e-01 (1.3165e-01) 
2023-05-26 00:01:51.428097: val Epoch: [49][42/72]	Time  1.050 ( 0.641)	Data  0.925 ( 0.514)	Loss 9.4937e-02 (1.3080e-01) 
2023-05-26 00:01:51.554234: val Epoch: [49][43/72]	Time  0.126 ( 0.629)	Data  0.001 ( 0.503)	Loss 6.4805e-02 (1.2930e-01) 
2023-05-26 00:01:52.644834: val Epoch: [49][44/72]	Time  1.091 ( 0.640)	Data  0.965 ( 0.513)	Loss 5.1850e-02 (1.2758e-01) 
2023-05-26 00:01:52.771715: val Epoch: [49][45/72]	Time  0.127 ( 0.629)	Data  0.001 ( 0.502)	Loss 6.7254e-02 (1.2627e-01) 
2023-05-26 00:01:53.877307: val Epoch: [49][46/72]	Time  1.106 ( 0.639)	Data  0.980 ( 0.512)	Loss 1.0893e-01 (1.2590e-01) 
2023-05-26 00:01:54.003709: val Epoch: [49][47/72]	Time  0.126 ( 0.628)	Data  0.001 ( 0.501)	Loss 1.4860e-01 (1.2637e-01) 
2023-05-26 00:01:55.059353: val Epoch: [49][48/72]	Time  1.056 ( 0.637)	Data  0.930 ( 0.510)	Loss 4.5824e-02 (1.2473e-01) 
2023-05-26 00:01:55.186443: val Epoch: [49][49/72]	Time  0.127 ( 0.627)	Data  0.001 ( 0.500)	Loss 2.2695e-01 (1.2677e-01) 
2023-05-26 00:01:56.264461: val Epoch: [49][50/72]	Time  1.078 ( 0.635)	Data  0.952 ( 0.509)	Loss 4.1350e-02 (1.2510e-01) 
2023-05-26 00:01:56.391079: val Epoch: [49][51/72]	Time  0.127 ( 0.626)	Data  0.001 ( 0.499)	Loss 5.4121e-02 (1.2373e-01) 
2023-05-26 00:01:57.452961: val Epoch: [49][52/72]	Time  1.062 ( 0.634)	Data  0.936 ( 0.507)	Loss 1.1421e-01 (1.2355e-01) 
2023-05-26 00:01:57.580430: val Epoch: [49][53/72]	Time  0.127 ( 0.624)	Data  0.001 ( 0.498)	Loss 4.5906e-01 (1.2976e-01) 
2023-05-26 00:01:58.713920: val Epoch: [49][54/72]	Time  1.133 ( 0.634)	Data  1.007 ( 0.507)	Loss 3.3137e-01 (1.3343e-01) 
2023-05-26 00:01:58.841162: val Epoch: [49][55/72]	Time  0.127 ( 0.625)	Data  0.001 ( 0.498)	Loss 4.1395e-01 (1.3844e-01) 
2023-05-26 00:01:59.915499: val Epoch: [49][56/72]	Time  1.074 ( 0.633)	Data  0.948 ( 0.506)	Loss 4.9168e-02 (1.3687e-01) 
2023-05-26 00:02:00.042157: val Epoch: [49][57/72]	Time  0.127 ( 0.624)	Data  0.001 ( 0.497)	Loss 8.4312e-02 (1.3597e-01) 
2023-05-26 00:02:01.161651: val Epoch: [49][58/72]	Time  1.119 ( 0.632)	Data  0.993 ( 0.506)	Loss 1.0630e-01 (1.3546e-01) 
2023-05-26 00:02:01.289371: val Epoch: [49][59/72]	Time  0.128 ( 0.624)	Data  0.001 ( 0.497)	Loss 9.9853e-02 (1.3487e-01) 
2023-05-26 00:02:02.451517: val Epoch: [49][60/72]	Time  1.162 ( 0.633)	Data  1.035 ( 0.506)	Loss 1.2783e-01 (1.3476e-01) 
2023-05-26 00:02:02.577887: val Epoch: [49][61/72]	Time  0.126 ( 0.625)	Data  0.001 ( 0.498)	Loss 4.4806e-02 (1.3330e-01) 
2023-05-26 00:02:03.684421: val Epoch: [49][62/72]	Time  1.107 ( 0.632)	Data  0.985 ( 0.506)	Loss 1.6342e-01 (1.3378e-01) 
2023-05-26 00:02:03.805520: val Epoch: [49][63/72]	Time  0.121 ( 0.624)	Data  0.001 ( 0.498)	Loss 6.5999e-02 (1.3272e-01) 
2023-05-26 00:02:04.904058: val Epoch: [49][64/72]	Time  1.099 ( 0.631)	Data  0.976 ( 0.505)	Loss 3.1138e-02 (1.3116e-01) 
2023-05-26 00:02:05.025200: val Epoch: [49][65/72]	Time  0.121 ( 0.624)	Data  0.000 ( 0.497)	Loss 7.4091e-02 (1.3030e-01) 
2023-05-26 00:02:06.152027: val Epoch: [49][66/72]	Time  1.127 ( 0.631)	Data  1.005 ( 0.505)	Loss 4.6929e-02 (1.2905e-01) 
2023-05-26 00:02:06.272759: val Epoch: [49][67/72]	Time  0.121 ( 0.624)	Data  0.001 ( 0.498)	Loss 3.9443e-01 (1.3295e-01) 
2023-05-26 00:02:07.445103: val Epoch: [49][68/72]	Time  1.172 ( 0.632)	Data  1.051 ( 0.506)	Loss 5.2867e-02 (1.3179e-01) 
2023-05-26 00:02:07.565118: val Epoch: [49][69/72]	Time  0.120 ( 0.624)	Data  0.000 ( 0.498)	Loss 4.8299e-02 (1.3060e-01) 
2023-05-26 00:02:08.341070: val Epoch: [49][70/72]	Time  0.776 ( 0.627)	Data  0.656 ( 0.501)	Loss 8.9124e-02 (1.3002e-01) 
2023-05-26 00:02:08.460247: val Epoch: [49][71/72]	Time  0.119 ( 0.619)	Data  0.000 ( 0.494)	Loss 5.4639e-02 (1.2897e-01) 
2023-05-26 00:02:08.625826: Epoch 49 :Val : ['ET : 0.7228222489356995', 'TC : 0.7880824208259583', 'WT : 0.86453777551651'] 
2023-05-26 00:02:08.627007: Epoch 49 :Val : ['ET : 0.7228222489356995', 'TC : 0.7880824208259583', 'WT : 0.86453777551651'] 
2023-05-26 00:02:08.630672: Val epoch done in 45.56205943399982 s 
2023-05-26 00:02:08.638732: Batches per epoch:  129 
2023-05-26 00:02:13.566718: train Epoch: [50][  0/129]	Time  4.928 ( 4.928)	Data  3.936 ( 3.936)	Loss 6.3719e-02 (6.3719e-02) 
2023-05-26 00:02:14.518406: train Epoch: [50][  1/129]	Time  0.952 ( 2.940)	Data  0.001 ( 1.969)	Loss 4.7851e-02 (5.5785e-02) 
2023-05-26 00:02:17.234590: train Epoch: [50][  2/129]	Time  2.716 ( 2.865)	Data  1.770 ( 1.903)	Loss 8.4702e-02 (6.5424e-02) 
2023-05-26 00:02:18.185683: train Epoch: [50][  3/129]	Time  0.951 ( 2.387)	Data  0.001 ( 1.427)	Loss 7.5890e-02 (6.8040e-02) 
2023-05-26 00:02:20.891123: train Epoch: [50][  4/129]	Time  2.705 ( 2.450)	Data  1.759 ( 1.494)	Loss 8.5069e-02 (7.1446e-02) 
2023-05-26 00:02:21.840622: train Epoch: [50][  5/129]	Time  0.949 ( 2.200)	Data  0.001 ( 1.245)	Loss 6.6459e-02 (7.0615e-02) 
2023-05-26 00:02:24.463398: train Epoch: [50][  6/129]	Time  2.623 ( 2.261)	Data  1.676 ( 1.306)	Loss 8.7248e-02 (7.2991e-02) 
2023-05-26 00:02:25.413006: train Epoch: [50][  7/129]	Time  0.950 ( 2.097)	Data  0.001 ( 1.143)	Loss 3.8901e-02 (6.8730e-02) 
2023-05-26 00:02:28.053856: train Epoch: [50][  8/129]	Time  2.641 ( 2.157)	Data  1.695 ( 1.204)	Loss 6.4998e-02 (6.8315e-02) 
2023-05-26 00:02:29.003428: train Epoch: [50][  9/129]	Time  0.950 ( 2.036)	Data  0.001 ( 1.084)	Loss 5.4552e-02 (6.6939e-02) 
2023-05-26 00:02:31.569330: train Epoch: [50][ 10/129]	Time  2.566 ( 2.085)	Data  1.618 ( 1.133)	Loss 5.2622e-02 (6.5637e-02) 
2023-05-26 00:02:32.528937: train Epoch: [50][ 11/129]	Time  0.960 ( 1.991)	Data  0.001 ( 1.038)	Loss 1.0405e-01 (6.8838e-02) 
2023-05-26 00:02:35.189573: train Epoch: [50][ 12/129]	Time  2.661 ( 2.042)	Data  1.703 ( 1.089)	Loss 2.1745e-01 (8.0270e-02) 
2023-05-26 00:02:36.148811: train Epoch: [50][ 13/129]	Time  0.959 ( 1.965)	Data  0.001 ( 1.012)	Loss 8.2817e-02 (8.0452e-02) 
2023-05-26 00:02:38.849248: train Epoch: [50][ 14/129]	Time  2.700 ( 2.014)	Data  1.716 ( 1.059)	Loss 9.4759e-02 (8.1406e-02) 
2023-05-26 00:02:39.818671: train Epoch: [50][ 15/129]	Time  0.969 ( 1.949)	Data  0.001 ( 0.993)	Loss 7.5203e-02 (8.1018e-02) 
2023-05-26 00:02:42.617097: train Epoch: [50][ 16/129]	Time  2.798 ( 1.999)	Data  1.839 ( 1.042)	Loss 1.3891e-01 (8.4424e-02) 
2023-05-26 00:02:43.578457: train Epoch: [50][ 17/129]	Time  0.961 ( 1.941)	Data  0.001 ( 0.984)	Loss 4.9107e-02 (8.2461e-02) 
2023-05-26 00:02:46.287390: train Epoch: [50][ 18/129]	Time  2.709 ( 1.981)	Data  1.752 ( 1.025)	Loss 5.8048e-02 (8.1177e-02) 
2023-05-26 00:02:47.249657: train Epoch: [50][ 19/129]	Time  0.962 ( 1.931)	Data  0.001 ( 0.974)	Loss 5.4516e-02 (7.9843e-02) 
2023-05-26 00:02:50.005821: train Epoch: [50][ 20/129]	Time  2.756 ( 1.970)	Data  1.798 ( 1.013)	Loss 8.0093e-02 (7.9855e-02) 
2023-05-26 00:02:50.965693: train Epoch: [50][ 21/129]	Time  0.960 ( 1.924)	Data  0.001 ( 0.967)	Loss 9.0082e-02 (8.0320e-02) 
2023-05-26 00:02:53.553927: train Epoch: [50][ 22/129]	Time  2.588 ( 1.953)	Data  1.629 ( 0.996)	Loss 1.1478e-01 (8.1819e-02) 
2023-05-26 00:02:54.517137: train Epoch: [50][ 23/129]	Time  0.963 ( 1.912)	Data  0.001 ( 0.954)	Loss 7.6129e-02 (8.1582e-02) 
2023-05-26 00:02:57.287202: train Epoch: [50][ 24/129]	Time  2.770 ( 1.946)	Data  1.815 ( 0.989)	Loss 1.1444e-01 (8.2896e-02) 
2023-05-26 00:02:58.247082: train Epoch: [50][ 25/129]	Time  0.960 ( 1.908)	Data  0.001 ( 0.951)	Loss 1.0249e-01 (8.3650e-02) 
2023-05-26 00:03:00.983798: train Epoch: [50][ 26/129]	Time  2.737 ( 1.939)	Data  1.779 ( 0.981)	Loss 7.3379e-02 (8.3269e-02) 
2023-05-26 00:03:01.945071: train Epoch: [50][ 27/129]	Time  0.961 ( 1.904)	Data  0.001 ( 0.946)	Loss 1.4731e-01 (8.5556e-02) 
2023-05-26 00:03:04.617999: train Epoch: [50][ 28/129]	Time  2.673 ( 1.930)	Data  1.716 ( 0.973)	Loss 6.7442e-02 (8.4932e-02) 
2023-05-26 00:03:05.578472: train Epoch: [50][ 29/129]	Time  0.960 ( 1.898)	Data  0.001 ( 0.940)	Loss 6.3408e-02 (8.4214e-02) 
2023-05-26 00:03:08.137718: train Epoch: [50][ 30/129]	Time  2.559 ( 1.919)	Data  1.602 ( 0.962)	Loss 8.5836e-02 (8.4267e-02) 
2023-05-26 00:03:09.097990: train Epoch: [50][ 31/129]	Time  0.960 ( 1.889)	Data  0.001 ( 0.932)	Loss 8.0177e-02 (8.4139e-02) 
2023-05-26 00:03:11.741968: train Epoch: [50][ 32/129]	Time  2.644 ( 1.912)	Data  1.687 ( 0.955)	Loss 6.9808e-02 (8.3704e-02) 
2023-05-26 00:03:12.703948: train Epoch: [50][ 33/129]	Time  0.962 ( 1.884)	Data  0.001 ( 0.927)	Loss 1.7735e-01 (8.6459e-02) 
2023-05-26 00:03:15.288743: train Epoch: [50][ 34/129]	Time  2.585 ( 1.904)	Data  1.627 ( 0.947)	Loss 8.1357e-02 (8.6313e-02) 
2023-05-26 00:03:16.250482: train Epoch: [50][ 35/129]	Time  0.962 ( 1.878)	Data  0.001 ( 0.920)	Loss 1.0820e-01 (8.6921e-02) 
2023-05-26 00:03:18.908710: train Epoch: [50][ 36/129]	Time  2.658 ( 1.899)	Data  1.700 ( 0.941)	Loss 1.2827e-01 (8.8039e-02) 
2023-05-26 00:03:19.869448: train Epoch: [50][ 37/129]	Time  0.961 ( 1.874)	Data  0.001 ( 0.917)	Loss 1.0429e-01 (8.8466e-02) 
2023-05-26 00:03:22.531879: train Epoch: [50][ 38/129]	Time  2.662 ( 1.895)	Data  1.706 ( 0.937)	Loss 1.2067e-01 (8.9292e-02) 
2023-05-26 00:03:23.484684: train Epoch: [50][ 39/129]	Time  0.953 ( 1.871)	Data  0.001 ( 0.914)	Loss 1.6561e-01 (9.1200e-02) 
2023-05-26 00:03:26.252211: train Epoch: [50][ 40/129]	Time  2.768 ( 1.893)	Data  1.801 ( 0.935)	Loss 9.3330e-02 (9.1252e-02) 
2023-05-26 00:03:27.202689: train Epoch: [50][ 41/129]	Time  0.950 ( 1.871)	Data  0.001 ( 0.913)	Loss 8.1887e-02 (9.1029e-02) 
2023-05-26 00:03:29.966293: train Epoch: [50][ 42/129]	Time  2.764 ( 1.891)	Data  1.815 ( 0.934)	Loss 1.1576e-01 (9.1604e-02) 
2023-05-26 00:03:30.917162: train Epoch: [50][ 43/129]	Time  0.951 ( 1.870)	Data  0.001 ( 0.913)	Loss 7.8373e-02 (9.1303e-02) 
2023-05-26 00:03:33.666553: train Epoch: [50][ 44/129]	Time  2.749 ( 1.889)	Data  1.804 ( 0.933)	Loss 6.7988e-02 (9.0785e-02) 
2023-05-26 00:03:34.616035: train Epoch: [50][ 45/129]	Time  0.949 ( 1.869)	Data  0.001 ( 0.912)	Loss 1.2175e-01 (9.1458e-02) 
2023-05-26 00:03:37.270663: train Epoch: [50][ 46/129]	Time  2.655 ( 1.886)	Data  1.706 ( 0.929)	Loss 1.6111e-01 (9.2940e-02) 
2023-05-26 00:03:38.219798: train Epoch: [50][ 47/129]	Time  0.949 ( 1.866)	Data  0.001 ( 0.910)	Loss 1.0204e-01 (9.3130e-02) 
2023-05-26 00:03:40.863747: train Epoch: [50][ 48/129]	Time  2.644 ( 1.882)	Data  1.699 ( 0.926)	Loss 1.2101e-01 (9.3699e-02) 
2023-05-26 00:03:41.812453: train Epoch: [50][ 49/129]	Time  0.949 ( 1.863)	Data  0.001 ( 0.907)	Loss 9.7432e-02 (9.3774e-02) 
2023-05-26 00:03:44.478629: train Epoch: [50][ 50/129]	Time  2.666 ( 1.879)	Data  1.722 ( 0.923)	Loss 8.8853e-02 (9.3677e-02) 
2023-05-26 00:03:45.428139: train Epoch: [50][ 51/129]	Time  0.950 ( 1.861)	Data  0.001 ( 0.906)	Loss 1.1180e-01 (9.4026e-02) 
2023-05-26 00:03:48.106983: train Epoch: [50][ 52/129]	Time  2.679 ( 1.877)	Data  1.733 ( 0.921)	Loss 1.1831e-01 (9.4484e-02) 
2023-05-26 00:03:49.055685: train Epoch: [50][ 53/129]	Time  0.949 ( 1.860)	Data  0.001 ( 0.904)	Loss 6.7833e-02 (9.3990e-02) 
2023-05-26 00:03:51.748569: train Epoch: [50][ 54/129]	Time  2.693 ( 1.875)	Data  1.746 ( 0.920)	Loss 7.5572e-02 (9.3655e-02) 
2023-05-26 00:03:52.698313: train Epoch: [50][ 55/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.903)	Loss 1.0215e-01 (9.3807e-02) 
2023-05-26 00:03:55.340199: train Epoch: [50][ 56/129]	Time  2.642 ( 1.872)	Data  1.693 ( 0.917)	Loss 2.8174e-01 (9.7104e-02) 
2023-05-26 00:03:56.291110: train Epoch: [50][ 57/129]	Time  0.951 ( 1.856)	Data  0.001 ( 0.901)	Loss 6.7119e-02 (9.6587e-02) 
2023-05-26 00:03:58.932783: train Epoch: [50][ 58/129]	Time  2.642 ( 1.869)	Data  1.696 ( 0.915)	Loss 4.1041e-02 (9.5646e-02) 
2023-05-26 00:03:59.881852: train Epoch: [50][ 59/129]	Time  0.949 ( 1.854)	Data  0.001 ( 0.899)	Loss 1.1760e-01 (9.6012e-02) 
2023-05-26 00:04:02.521266: train Epoch: [50][ 60/129]	Time  2.639 ( 1.867)	Data  1.694 ( 0.912)	Loss 6.2679e-02 (9.5465e-02) 
2023-05-26 00:04:03.469825: train Epoch: [50][ 61/129]	Time  0.949 ( 1.852)	Data  0.001 ( 0.898)	Loss 8.1451e-02 (9.5239e-02) 
2023-05-26 00:04:06.064451: train Epoch: [50][ 62/129]	Time  2.595 ( 1.864)	Data  1.649 ( 0.910)	Loss 7.5516e-02 (9.4926e-02) 
2023-05-26 00:04:07.014797: train Epoch: [50][ 63/129]	Time  0.950 ( 1.850)	Data  0.001 ( 0.895)	Loss 1.3548e-01 (9.5560e-02) 
2023-05-26 00:04:09.651772: train Epoch: [50][ 64/129]	Time  2.637 ( 1.862)	Data  1.690 ( 0.908)	Loss 7.7974e-02 (9.5289e-02) 
2023-05-26 00:04:10.604712: train Epoch: [50][ 65/129]	Time  0.953 ( 1.848)	Data  0.001 ( 0.894)	Loss 1.6298e-01 (9.6315e-02) 
2023-05-26 00:04:13.284438: train Epoch: [50][ 66/129]	Time  2.680 ( 1.860)	Data  1.734 ( 0.906)	Loss 8.1729e-02 (9.6097e-02) 
2023-05-26 00:04:14.233464: train Epoch: [50][ 67/129]	Time  0.949 ( 1.847)	Data  0.001 ( 0.893)	Loss 9.3756e-02 (9.6063e-02) 
2023-05-26 00:04:16.818846: train Epoch: [50][ 68/129]	Time  2.585 ( 1.858)	Data  1.638 ( 0.904)	Loss 7.5009e-02 (9.5758e-02) 
2023-05-26 00:04:17.767812: train Epoch: [50][ 69/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.891)	Loss 9.5289e-02 (9.5751e-02) 
2023-05-26 00:04:20.445205: train Epoch: [50][ 70/129]	Time  2.677 ( 1.856)	Data  1.731 ( 0.903)	Loss 7.5131e-02 (9.5460e-02) 
2023-05-26 00:04:21.395346: train Epoch: [50][ 71/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.890)	Loss 8.3392e-02 (9.5293e-02) 
2023-05-26 00:04:24.119577: train Epoch: [50][ 72/129]	Time  2.724 ( 1.856)	Data  1.779 ( 0.903)	Loss 1.0229e-01 (9.5389e-02) 
2023-05-26 00:04:25.068323: train Epoch: [50][ 73/129]	Time  0.949 ( 1.844)	Data  0.001 ( 0.890)	Loss 1.0661e-01 (9.5540e-02) 
2023-05-26 00:04:27.674786: train Epoch: [50][ 74/129]	Time  2.606 ( 1.854)	Data  1.659 ( 0.901)	Loss 6.8261e-02 (9.5177e-02) 
2023-05-26 00:04:28.624829: train Epoch: [50][ 75/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.889)	Loss 9.4704e-02 (9.5170e-02) 
2023-05-26 00:04:31.340295: train Epoch: [50][ 76/129]	Time  2.715 ( 1.853)	Data  1.770 ( 0.900)	Loss 1.1500e-01 (9.5428e-02) 
2023-05-26 00:04:32.290408: train Epoch: [50][ 77/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.889)	Loss 8.5621e-02 (9.5302e-02) 
2023-05-26 00:04:34.965445: train Epoch: [50][ 78/129]	Time  2.675 ( 1.852)	Data  1.728 ( 0.899)	Loss 1.2793e-01 (9.5715e-02) 
2023-05-26 00:04:35.914239: train Epoch: [50][ 79/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.888)	Loss 8.9794e-02 (9.5641e-02) 
2023-05-26 00:04:38.622828: train Epoch: [50][ 80/129]	Time  2.709 ( 1.852)	Data  1.764 ( 0.899)	Loss 1.0729e-01 (9.5785e-02) 
2023-05-26 00:04:39.576506: train Epoch: [50][ 81/129]	Time  0.954 ( 1.841)	Data  0.001 ( 0.888)	Loss 1.2163e-01 (9.6100e-02) 
2023-05-26 00:04:42.251809: train Epoch: [50][ 82/129]	Time  2.675 ( 1.851)	Data  1.730 ( 0.898)	Loss 4.1078e-02 (9.5437e-02) 
2023-05-26 00:04:43.202102: train Epoch: [50][ 83/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.887)	Loss 9.5026e-02 (9.5432e-02) 
2023-05-26 00:04:45.852603: train Epoch: [50][ 84/129]	Time  2.650 ( 1.850)	Data  1.696 ( 0.897)	Loss 9.1592e-02 (9.5387e-02) 
2023-05-26 00:04:46.812215: train Epoch: [50][ 85/129]	Time  0.960 ( 1.839)	Data  0.001 ( 0.886)	Loss 7.4677e-02 (9.5146e-02) 
2023-05-26 00:04:49.481673: train Epoch: [50][ 86/129]	Time  2.669 ( 1.849)	Data  1.714 ( 0.896)	Loss 6.0104e-02 (9.4743e-02) 
2023-05-26 00:04:50.445413: train Epoch: [50][ 87/129]	Time  0.964 ( 1.839)	Data  0.001 ( 0.886)	Loss 1.3766e-01 (9.5231e-02) 
2023-05-26 00:04:53.109968: train Epoch: [50][ 88/129]	Time  2.665 ( 1.848)	Data  1.707 ( 0.895)	Loss 7.5646e-02 (9.5011e-02) 
2023-05-26 00:04:54.073532: train Epoch: [50][ 89/129]	Time  0.964 ( 1.838)	Data  0.001 ( 0.885)	Loss 7.3810e-02 (9.4776e-02) 
2023-05-26 00:04:56.690832: train Epoch: [50][ 90/129]	Time  2.617 ( 1.847)	Data  1.661 ( 0.894)	Loss 5.6668e-02 (9.4357e-02) 
2023-05-26 00:04:57.653836: train Epoch: [50][ 91/129]	Time  0.963 ( 1.837)	Data  0.001 ( 0.884)	Loss 7.6686e-02 (9.4165e-02) 
2023-05-26 00:05:00.345792: train Epoch: [50][ 92/129]	Time  2.692 ( 1.846)	Data  1.737 ( 0.893)	Loss 1.1329e-01 (9.4370e-02) 
2023-05-26 00:05:01.304723: train Epoch: [50][ 93/129]	Time  0.959 ( 1.837)	Data  0.001 ( 0.884)	Loss 7.7829e-02 (9.4194e-02) 
2023-05-26 00:05:03.996525: train Epoch: [50][ 94/129]	Time  2.692 ( 1.846)	Data  1.737 ( 0.893)	Loss 6.9156e-02 (9.3931e-02) 
2023-05-26 00:05:04.953015: train Epoch: [50][ 95/129]	Time  0.956 ( 1.837)	Data  0.001 ( 0.883)	Loss 7.2028e-02 (9.3703e-02) 
2023-05-26 00:05:07.582216: train Epoch: [50][ 96/129]	Time  2.629 ( 1.845)	Data  1.668 ( 0.891)	Loss 9.2985e-02 (9.3695e-02) 
2023-05-26 00:05:08.539408: train Epoch: [50][ 97/129]	Time  0.957 ( 1.836)	Data  0.001 ( 0.882)	Loss 4.3830e-02 (9.3186e-02) 
2023-05-26 00:05:11.151150: train Epoch: [50][ 98/129]	Time  2.612 ( 1.844)	Data  1.652 ( 0.890)	Loss 5.6541e-02 (9.2816e-02) 
2023-05-26 00:05:12.105800: train Epoch: [50][ 99/129]	Time  0.955 ( 1.835)	Data  0.001 ( 0.881)	Loss 6.5945e-02 (9.2548e-02) 
2023-05-26 00:05:14.859736: train Epoch: [50][100/129]	Time  2.754 ( 1.844)	Data  1.795 ( 0.890)	Loss 1.4071e-01 (9.3024e-02) 
2023-05-26 00:05:15.820323: train Epoch: [50][101/129]	Time  0.961 ( 1.835)	Data  0.001 ( 0.882)	Loss 6.8303e-02 (9.2782e-02) 
2023-05-26 00:05:18.545057: train Epoch: [50][102/129]	Time  2.725 ( 1.844)	Data  1.766 ( 0.890)	Loss 7.1539e-02 (9.2576e-02) 
2023-05-26 00:05:19.494433: train Epoch: [50][103/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.882)	Loss 6.4360e-02 (9.2305e-02) 
2023-05-26 00:05:22.197985: train Epoch: [50][104/129]	Time  2.704 ( 1.843)	Data  1.755 ( 0.890)	Loss 1.0444e-01 (9.2420e-02) 
2023-05-26 00:05:23.149006: train Epoch: [50][105/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.881)	Loss 9.9899e-02 (9.2491e-02) 
2023-05-26 00:05:25.856912: train Epoch: [50][106/129]	Time  2.708 ( 1.843)	Data  1.760 ( 0.890)	Loss 7.5592e-02 (9.2333e-02) 
2023-05-26 00:05:26.807731: train Epoch: [50][107/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.881)	Loss 5.6238e-02 (9.1999e-02) 
2023-05-26 00:05:29.556406: train Epoch: [50][108/129]	Time  2.749 ( 1.843)	Data  1.800 ( 0.890)	Loss 1.2471e-01 (9.2299e-02) 
2023-05-26 00:05:30.507267: train Epoch: [50][109/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.882)	Loss 1.5537e-01 (9.2872e-02) 
2023-05-26 00:05:33.154741: train Epoch: [50][110/129]	Time  2.647 ( 1.842)	Data  1.700 ( 0.889)	Loss 1.3316e-01 (9.3235e-02) 
2023-05-26 00:05:34.104250: train Epoch: [50][111/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.881)	Loss 6.8285e-02 (9.3012e-02) 
2023-05-26 00:05:36.699684: train Epoch: [50][112/129]	Time  2.595 ( 1.841)	Data  1.647 ( 0.888)	Loss 1.1765e-01 (9.3230e-02) 
2023-05-26 00:05:37.652757: train Epoch: [50][113/129]	Time  0.953 ( 1.833)	Data  0.001 ( 0.880)	Loss 8.3983e-02 (9.3149e-02) 
2023-05-26 00:05:40.326067: train Epoch: [50][114/129]	Time  2.673 ( 1.841)	Data  1.724 ( 0.888)	Loss 6.8716e-02 (9.2937e-02) 
2023-05-26 00:05:41.274870: train Epoch: [50][115/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.880)	Loss 8.6237e-02 (9.2879e-02) 
2023-05-26 00:05:43.911190: train Epoch: [50][116/129]	Time  2.636 ( 1.840)	Data  1.688 ( 0.887)	Loss 5.1379e-02 (9.2524e-02) 
2023-05-26 00:05:44.861537: train Epoch: [50][117/129]	Time  0.950 ( 1.832)	Data  0.001 ( 0.879)	Loss 7.9565e-02 (9.2414e-02) 
2023-05-26 00:05:47.506401: train Epoch: [50][118/129]	Time  2.645 ( 1.839)	Data  1.698 ( 0.886)	Loss 9.5667e-02 (9.2442e-02) 
2023-05-26 00:05:48.457557: train Epoch: [50][119/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.879)	Loss 1.2353e-01 (9.2701e-02) 
2023-05-26 00:05:51.131670: train Epoch: [50][120/129]	Time  2.674 ( 1.839)	Data  1.726 ( 0.886)	Loss 6.9083e-02 (9.2506e-02) 
2023-05-26 00:05:52.084127: train Epoch: [50][121/129]	Time  0.952 ( 1.832)	Data  0.001 ( 0.879)	Loss 9.1522e-02 (9.2498e-02) 
2023-05-26 00:05:54.701976: train Epoch: [50][122/129]	Time  2.618 ( 1.838)	Data  1.670 ( 0.885)	Loss 5.6610e-02 (9.2206e-02) 
2023-05-26 00:05:55.652668: train Epoch: [50][123/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.878)	Loss 5.5141e-02 (9.1907e-02) 
2023-05-26 00:05:58.310845: train Epoch: [50][124/129]	Time  2.658 ( 1.837)	Data  1.710 ( 0.885)	Loss 8.8324e-02 (9.1878e-02) 
2023-05-26 00:05:59.261504: train Epoch: [50][125/129]	Time  0.951 ( 1.830)	Data  0.001 ( 0.878)	Loss 6.7645e-02 (9.1686e-02) 
2023-05-26 00:06:01.562307: train Epoch: [50][126/129]	Time  2.301 ( 1.834)	Data  1.353 ( 0.881)	Loss 1.0794e-01 (9.1814e-02) 
2023-05-26 00:06:02.510034: train Epoch: [50][127/129]	Time  0.948 ( 1.827)	Data  0.001 ( 0.874)	Loss 6.9057e-02 (9.1636e-02) 
2023-05-26 00:06:04.019165: train Epoch: [50][128/129]	Time  1.509 ( 1.825)	Data  0.563 ( 0.872)	Loss 5.2589e-02 (9.1333e-02) 
2023-05-26 00:06:04.050972: Train Epoch done in 235.4122603930009 s 
2023-05-26 00:06:06.285372: val Epoch: [50][ 0/72]	Time  1.526 ( 1.526)	Data  1.339 ( 1.339)	Loss 5.0103e-02 (5.0103e-02) 
2023-05-26 00:06:06.405407: val Epoch: [50][ 1/72]	Time  0.120 ( 0.823)	Data  0.001 ( 0.670)	Loss 5.5296e-02 (5.2700e-02) 
2023-05-26 00:06:07.371437: val Epoch: [50][ 2/72]	Time  0.966 ( 0.871)	Data  0.845 ( 0.729)	Loss 2.6200e-01 (1.2247e-01) 
2023-05-26 00:06:07.530122: val Epoch: [50][ 3/72]	Time  0.159 ( 0.693)	Data  0.038 ( 0.556)	Loss 3.2938e-01 (1.7419e-01) 
2023-05-26 00:06:08.598206: val Epoch: [50][ 4/72]	Time  1.068 ( 0.768)	Data  0.946 ( 0.634)	Loss 1.0658e-01 (1.6067e-01) 
2023-05-26 00:06:08.754596: val Epoch: [50][ 5/72]	Time  0.156 ( 0.666)	Data  0.037 ( 0.535)	Loss 4.6437e-01 (2.1129e-01) 
2023-05-26 00:06:09.815032: val Epoch: [50][ 6/72]	Time  1.060 ( 0.722)	Data  0.940 ( 0.592)	Loss 9.7477e-02 (1.9503e-01) 
2023-05-26 00:06:09.977157: val Epoch: [50][ 7/72]	Time  0.162 ( 0.652)	Data  0.041 ( 0.524)	Loss 3.1957e-01 (2.1060e-01) 
2023-05-26 00:06:10.990017: val Epoch: [50][ 8/72]	Time  1.013 ( 0.692)	Data  0.892 ( 0.564)	Loss 1.0150e-01 (1.9847e-01) 
2023-05-26 00:06:11.232257: val Epoch: [50][ 9/72]	Time  0.242 ( 0.647)	Data  0.123 ( 0.520)	Loss 1.0129e-01 (1.8876e-01) 
2023-05-26 00:06:12.204499: val Epoch: [50][10/72]	Time  0.972 ( 0.677)	Data  0.851 ( 0.550)	Loss 8.8024e-02 (1.7960e-01) 
2023-05-26 00:06:12.453654: val Epoch: [50][11/72]	Time  0.249 ( 0.641)	Data  0.129 ( 0.515)	Loss 8.3876e-02 (1.7162e-01) 
2023-05-26 00:06:13.469575: val Epoch: [50][12/72]	Time  1.016 ( 0.670)	Data  0.895 ( 0.544)	Loss 3.4395e-01 (1.8488e-01) 
2023-05-26 00:06:13.678393: val Epoch: [50][13/72]	Time  0.209 ( 0.637)	Data  0.089 ( 0.512)	Loss 8.4724e-02 (1.7772e-01) 
2023-05-26 00:06:14.665600: val Epoch: [50][14/72]	Time  0.987 ( 0.660)	Data  0.866 ( 0.536)	Loss 2.7621e-01 (1.8429e-01) 
2023-05-26 00:06:14.924942: val Epoch: [50][15/72]	Time  0.259 ( 0.635)	Data  0.135 ( 0.510)	Loss 3.8641e-01 (1.9692e-01) 
2023-05-26 00:06:15.892912: val Epoch: [50][16/72]	Time  0.968 ( 0.655)	Data  0.841 ( 0.530)	Loss 4.7735e-02 (1.8815e-01) 
2023-05-26 00:06:16.169171: val Epoch: [50][17/72]	Time  0.276 ( 0.634)	Data  0.151 ( 0.509)	Loss 6.7700e-02 (1.8145e-01) 
2023-05-26 00:06:17.164045: val Epoch: [50][18/72]	Time  0.995 ( 0.653)	Data  0.869 ( 0.528)	Loss 2.9778e-01 (1.8758e-01) 
2023-05-26 00:06:17.340952: val Epoch: [50][19/72]	Time  0.177 ( 0.629)	Data  0.052 ( 0.504)	Loss 7.0159e-02 (1.8171e-01) 
2023-05-26 00:06:18.356047: val Epoch: [50][20/72]	Time  1.015 ( 0.647)	Data  0.888 ( 0.522)	Loss 5.4738e-02 (1.7566e-01) 
2023-05-26 00:06:18.626696: val Epoch: [50][21/72]	Time  0.271 ( 0.630)	Data  0.146 ( 0.505)	Loss 5.3174e-02 (1.7009e-01) 
2023-05-26 00:06:19.557807: val Epoch: [50][22/72]	Time  0.931 ( 0.643)	Data  0.804 ( 0.518)	Loss 5.5170e-02 (1.6510e-01) 
2023-05-26 00:06:19.867073: val Epoch: [50][23/72]	Time  0.309 ( 0.629)	Data  0.184 ( 0.504)	Loss 5.1503e-02 (1.6036e-01) 
2023-05-26 00:06:20.751774: val Epoch: [50][24/72]	Time  0.885 ( 0.640)	Data  0.758 ( 0.514)	Loss 4.0722e-02 (1.5558e-01) 
2023-05-26 00:06:21.072865: val Epoch: [50][25/72]	Time  0.321 ( 0.627)	Data  0.196 ( 0.502)	Loss 5.7073e-02 (1.5179e-01) 
2023-05-26 00:06:21.970551: val Epoch: [50][26/72]	Time  0.898 ( 0.637)	Data  0.770 ( 0.512)	Loss 1.6553e-01 (1.5230e-01) 
2023-05-26 00:06:22.323328: val Epoch: [50][27/72]	Time  0.353 ( 0.627)	Data  0.228 ( 0.502)	Loss 3.2980e-01 (1.5864e-01) 
2023-05-26 00:06:23.257599: val Epoch: [50][28/72]	Time  0.934 ( 0.638)	Data  0.807 ( 0.513)	Loss 1.2408e-01 (1.5745e-01) 
2023-05-26 00:06:23.541823: val Epoch: [50][29/72]	Time  0.284 ( 0.626)	Data  0.160 ( 0.501)	Loss 5.3766e-02 (1.5399e-01) 
2023-05-26 00:06:24.485115: val Epoch: [50][30/72]	Time  0.943 ( 0.636)	Data  0.816 ( 0.511)	Loss 1.8697e-01 (1.5505e-01) 
2023-05-26 00:06:24.738764: val Epoch: [50][31/72]	Time  0.254 ( 0.624)	Data  0.129 ( 0.499)	Loss 3.5353e-02 (1.5131e-01) 
2023-05-26 00:06:25.673442: val Epoch: [50][32/72]	Time  0.935 ( 0.634)	Data  0.808 ( 0.508)	Loss 4.8383e-02 (1.4819e-01) 
2023-05-26 00:06:25.970641: val Epoch: [50][33/72]	Time  0.297 ( 0.624)	Data  0.175 ( 0.499)	Loss 4.6674e-02 (1.4521e-01) 
2023-05-26 00:06:26.952732: val Epoch: [50][34/72]	Time  0.982 ( 0.634)	Data  0.855 ( 0.509)	Loss 5.7041e-02 (1.4269e-01) 
2023-05-26 00:06:27.265599: val Epoch: [50][35/72]	Time  0.313 ( 0.625)	Data  0.189 ( 0.500)	Loss 8.6253e-02 (1.4112e-01) 
2023-05-26 00:06:28.189146: val Epoch: [50][36/72]	Time  0.924 ( 0.633)	Data  0.797 ( 0.508)	Loss 1.7489e-01 (1.4203e-01) 
2023-05-26 00:06:28.507466: val Epoch: [50][37/72]	Time  0.318 ( 0.625)	Data  0.194 ( 0.500)	Loss 1.4988e-01 (1.4224e-01) 
2023-05-26 00:06:29.373567: val Epoch: [50][38/72]	Time  0.866 ( 0.631)	Data  0.739 ( 0.506)	Loss 6.2929e-02 (1.4021e-01) 
2023-05-26 00:06:29.704601: val Epoch: [50][39/72]	Time  0.331 ( 0.624)	Data  0.206 ( 0.498)	Loss 9.0751e-02 (1.3897e-01) 
2023-05-26 00:06:30.624696: val Epoch: [50][40/72]	Time  0.920 ( 0.631)	Data  0.793 ( 0.506)	Loss 3.9958e-02 (1.3656e-01) 
2023-05-26 00:06:30.944205: val Epoch: [50][41/72]	Time  0.320 ( 0.623)	Data  0.195 ( 0.498)	Loss 1.4147e-01 (1.3667e-01) 
2023-05-26 00:06:31.864040: val Epoch: [50][42/72]	Time  0.920 ( 0.630)	Data  0.793 ( 0.505)	Loss 6.1466e-02 (1.3492e-01) 
2023-05-26 00:06:32.148974: val Epoch: [50][43/72]	Time  0.285 ( 0.622)	Data  0.160 ( 0.497)	Loss 1.1585e-01 (1.3449e-01) 
2023-05-26 00:06:33.082391: val Epoch: [50][44/72]	Time  0.933 ( 0.629)	Data  0.807 ( 0.504)	Loss 7.2950e-02 (1.3312e-01) 
2023-05-26 00:06:33.366632: val Epoch: [50][45/72]	Time  0.284 ( 0.622)	Data  0.160 ( 0.497)	Loss 3.2150e-01 (1.3722e-01) 
2023-05-26 00:06:34.321075: val Epoch: [50][46/72]	Time  0.954 ( 0.629)	Data  0.828 ( 0.504)	Loss 5.0836e-02 (1.3538e-01) 
2023-05-26 00:06:34.624959: val Epoch: [50][47/72]	Time  0.304 ( 0.622)	Data  0.179 ( 0.497)	Loss 9.2711e-02 (1.3449e-01) 
2023-05-26 00:06:35.581352: val Epoch: [50][48/72]	Time  0.956 ( 0.629)	Data  0.830 ( 0.504)	Loss 1.3029e-01 (1.3440e-01) 
2023-05-26 00:06:35.855067: val Epoch: [50][49/72]	Time  0.274 ( 0.622)	Data  0.147 ( 0.497)	Loss 6.7079e-02 (1.3306e-01) 
2023-05-26 00:06:36.806813: val Epoch: [50][50/72]	Time  0.952 ( 0.628)	Data  0.825 ( 0.503)	Loss 6.1997e-02 (1.3166e-01) 
2023-05-26 00:06:37.132044: val Epoch: [50][51/72]	Time  0.325 ( 0.623)	Data  0.200 ( 0.497)	Loss 8.2704e-02 (1.3072e-01) 
2023-05-26 00:06:38.063218: val Epoch: [50][52/72]	Time  0.931 ( 0.628)	Data  0.804 ( 0.503)	Loss 3.5290e-02 (1.2892e-01) 
2023-05-26 00:06:38.370496: val Epoch: [50][53/72]	Time  0.307 ( 0.622)	Data  0.182 ( 0.497)	Loss 6.9264e-02 (1.2782e-01) 
2023-05-26 00:06:39.307046: val Epoch: [50][54/72]	Time  0.937 ( 0.628)	Data  0.810 ( 0.503)	Loss 5.5297e-02 (1.2650e-01) 
2023-05-26 00:06:39.584384: val Epoch: [50][55/72]	Time  0.277 ( 0.622)	Data  0.153 ( 0.496)	Loss 4.2459e-02 (1.2500e-01) 
2023-05-26 00:06:40.528186: val Epoch: [50][56/72]	Time  0.944 ( 0.628)	Data  0.817 ( 0.502)	Loss 1.2843e-01 (1.2506e-01) 
2023-05-26 00:06:40.822213: val Epoch: [50][57/72]	Time  0.294 ( 0.622)	Data  0.170 ( 0.496)	Loss 5.9405e-02 (1.2393e-01) 
2023-05-26 00:06:41.748120: val Epoch: [50][58/72]	Time  0.926 ( 0.627)	Data  0.799 ( 0.501)	Loss 1.3214e-01 (1.2407e-01) 
2023-05-26 00:06:42.095695: val Epoch: [50][59/72]	Time  0.348 ( 0.622)	Data  0.223 ( 0.497)	Loss 1.4743e-01 (1.2446e-01) 
2023-05-26 00:06:43.058367: val Epoch: [50][60/72]	Time  0.963 ( 0.628)	Data  0.836 ( 0.502)	Loss 9.0663e-02 (1.2390e-01) 
2023-05-26 00:06:43.353590: val Epoch: [50][61/72]	Time  0.295 ( 0.622)	Data  0.170 ( 0.497)	Loss 8.7510e-02 (1.2331e-01) 
2023-05-26 00:06:44.297548: val Epoch: [50][62/72]	Time  0.944 ( 0.628)	Data  0.817 ( 0.502)	Loss 3.0007e-01 (1.2612e-01) 
2023-05-26 00:06:44.575640: val Epoch: [50][63/72]	Time  0.278 ( 0.622)	Data  0.154 ( 0.497)	Loss 3.9882e-02 (1.2477e-01) 
2023-05-26 00:06:45.546400: val Epoch: [50][64/72]	Time  0.971 ( 0.627)	Data  0.844 ( 0.502)	Loss 3.3746e-01 (1.2804e-01) 
2023-05-26 00:06:45.782854: val Epoch: [50][65/72]	Time  0.236 ( 0.622)	Data  0.112 ( 0.496)	Loss 1.1239e-01 (1.2781e-01) 
2023-05-26 00:06:46.820836: val Epoch: [50][66/72]	Time  1.038 ( 0.628)	Data  0.912 ( 0.502)	Loss 1.3677e-01 (1.2794e-01) 
2023-05-26 00:06:47.015260: val Epoch: [50][67/72]	Time  0.194 ( 0.621)	Data  0.069 ( 0.496)	Loss 1.9427e-01 (1.2892e-01) 
2023-05-26 00:06:48.015663: val Epoch: [50][68/72]	Time  1.000 ( 0.627)	Data  0.873 ( 0.501)	Loss 5.0075e-02 (1.2777e-01) 
2023-05-26 00:06:48.281740: val Epoch: [50][69/72]	Time  0.266 ( 0.622)	Data  0.141 ( 0.496)	Loss 3.7548e-01 (1.3131e-01) 
2023-05-26 00:06:49.279063: val Epoch: [50][70/72]	Time  0.997 ( 0.627)	Data  0.871 ( 0.502)	Loss 6.6732e-02 (1.3040e-01) 
2023-05-26 00:06:49.449187: val Epoch: [50][71/72]	Time  0.170 ( 0.621)	Data  0.046 ( 0.495)	Loss 8.5339e-02 (1.2978e-01) 
2023-05-26 00:06:49.628600: Epoch 50 :Val : ['ET : 0.7354884743690491', 'TC : 0.7717108130455017', 'WT : 0.865240216255188'] 
2023-05-26 00:06:49.635407: Epoch 50 :Val : ['ET : 0.7354884743690491', 'TC : 0.7717108130455017', 'WT : 0.865240216255188'] 
2023-05-26 00:06:49.637627: Val epoch done in 45.586666305996914 s 
2023-05-26 00:06:49.642979: Batches per epoch:  129 
2023-05-26 00:06:54.485313: train Epoch: [51][  0/129]	Time  4.842 ( 4.842)	Data  3.822 ( 3.822)	Loss 9.5026e-02 (9.5026e-02) 
2023-05-26 00:06:55.446353: train Epoch: [51][  1/129]	Time  0.961 ( 2.902)	Data  0.001 ( 1.911)	Loss 6.0470e-02 (7.7748e-02) 
2023-05-26 00:06:58.123449: train Epoch: [51][  2/129]	Time  2.677 ( 2.827)	Data  1.721 ( 1.848)	Loss 5.7728e-02 (7.1074e-02) 
2023-05-26 00:06:59.082993: train Epoch: [51][  3/129]	Time  0.960 ( 2.360)	Data  0.001 ( 1.386)	Loss 4.1692e-02 (6.3729e-02) 
2023-05-26 00:07:01.743247: train Epoch: [51][  4/129]	Time  2.660 ( 2.420)	Data  1.704 ( 1.450)	Loss 1.3351e-01 (7.7684e-02) 
2023-05-26 00:07:02.711213: train Epoch: [51][  5/129]	Time  0.968 ( 2.178)	Data  0.001 ( 1.208)	Loss 6.9929e-02 (7.6392e-02) 
2023-05-26 00:07:05.442644: train Epoch: [51][  6/129]	Time  2.731 ( 2.257)	Data  1.774 ( 1.289)	Loss 1.2934e-01 (8.3955e-02) 
2023-05-26 00:07:06.402453: train Epoch: [51][  7/129]	Time  0.960 ( 2.095)	Data  0.001 ( 1.128)	Loss 6.8672e-02 (8.2045e-02) 
2023-05-26 00:07:09.066424: train Epoch: [51][  8/129]	Time  2.664 ( 2.158)	Data  1.709 ( 1.193)	Loss 8.3769e-02 (8.2236e-02) 
2023-05-26 00:07:10.028701: train Epoch: [51][  9/129]	Time  0.962 ( 2.039)	Data  0.001 ( 1.073)	Loss 8.8797e-02 (8.2892e-02) 
2023-05-26 00:07:12.733070: train Epoch: [51][ 10/129]	Time  2.704 ( 2.099)	Data  1.748 ( 1.135)	Loss 9.0903e-02 (8.3621e-02) 
2023-05-26 00:07:13.693428: train Epoch: [51][ 11/129]	Time  0.960 ( 2.004)	Data  0.001 ( 1.040)	Loss 4.6474e-02 (8.0525e-02) 
2023-05-26 00:07:16.363174: train Epoch: [51][ 12/129]	Time  2.670 ( 2.055)	Data  1.712 ( 1.092)	Loss 1.8631e-01 (8.8662e-02) 
2023-05-26 00:07:17.325971: train Epoch: [51][ 13/129]	Time  0.963 ( 1.977)	Data  0.001 ( 1.014)	Loss 1.0809e-01 (9.0050e-02) 
2023-05-26 00:07:19.993592: train Epoch: [51][ 14/129]	Time  2.668 ( 2.023)	Data  1.711 ( 1.060)	Loss 7.2822e-02 (8.8901e-02) 
2023-05-26 00:07:20.953608: train Epoch: [51][ 15/129]	Time  0.960 ( 1.957)	Data  0.001 ( 0.994)	Loss 8.1655e-02 (8.8449e-02) 
2023-05-26 00:07:23.483952: train Epoch: [51][ 16/129]	Time  2.530 ( 1.991)	Data  1.572 ( 1.028)	Loss 4.5070e-02 (8.5897e-02) 
2023-05-26 00:07:24.444120: train Epoch: [51][ 17/129]	Time  0.960 ( 1.933)	Data  0.001 ( 0.971)	Loss 8.2796e-02 (8.5725e-02) 
2023-05-26 00:07:26.986201: train Epoch: [51][ 18/129]	Time  2.542 ( 1.965)	Data  1.583 ( 1.003)	Loss 4.8597e-02 (8.3770e-02) 
2023-05-26 00:07:27.949973: train Epoch: [51][ 19/129]	Time  0.964 ( 1.915)	Data  0.001 ( 0.953)	Loss 5.5595e-02 (8.2362e-02) 
2023-05-26 00:07:30.659783: train Epoch: [51][ 20/129]	Time  2.710 ( 1.953)	Data  1.752 ( 0.991)	Loss 1.4386e-01 (8.5290e-02) 
2023-05-26 00:07:31.612727: train Epoch: [51][ 21/129]	Time  0.953 ( 1.908)	Data  0.001 ( 0.946)	Loss 6.6007e-02 (8.4414e-02) 
2023-05-26 00:07:34.264249: train Epoch: [51][ 22/129]	Time  2.652 ( 1.940)	Data  1.704 ( 0.979)	Loss 1.2067e-01 (8.5990e-02) 
2023-05-26 00:07:35.215937: train Epoch: [51][ 23/129]	Time  0.952 ( 1.899)	Data  0.001 ( 0.938)	Loss 9.0627e-02 (8.6183e-02) 
2023-05-26 00:07:38.015936: train Epoch: [51][ 24/129]	Time  2.800 ( 1.935)	Data  1.853 ( 0.975)	Loss 7.5404e-02 (8.5752e-02) 
2023-05-26 00:07:38.977206: train Epoch: [51][ 25/129]	Time  0.961 ( 1.897)	Data  0.001 ( 0.938)	Loss 1.0126e-01 (8.6349e-02) 
2023-05-26 00:07:41.607987: train Epoch: [51][ 26/129]	Time  2.631 ( 1.925)	Data  1.675 ( 0.965)	Loss 7.3994e-02 (8.5891e-02) 
2023-05-26 00:07:42.569471: train Epoch: [51][ 27/129]	Time  0.961 ( 1.890)	Data  0.001 ( 0.930)	Loss 1.4101e-01 (8.7860e-02) 
2023-05-26 00:07:45.191272: train Epoch: [51][ 28/129]	Time  2.622 ( 1.915)	Data  1.664 ( 0.956)	Loss 4.9381e-02 (8.6533e-02) 
2023-05-26 00:07:46.154045: train Epoch: [51][ 29/129]	Time  0.963 ( 1.884)	Data  0.001 ( 0.924)	Loss 6.3466e-02 (8.5764e-02) 
2023-05-26 00:07:48.725858: train Epoch: [51][ 30/129]	Time  2.572 ( 1.906)	Data  1.613 ( 0.946)	Loss 8.3003e-02 (8.5675e-02) 
2023-05-26 00:07:49.687511: train Epoch: [51][ 31/129]	Time  0.962 ( 1.876)	Data  0.001 ( 0.917)	Loss 9.6983e-02 (8.6028e-02) 
2023-05-26 00:07:52.276545: train Epoch: [51][ 32/129]	Time  2.589 ( 1.898)	Data  1.628 ( 0.938)	Loss 7.8622e-02 (8.5804e-02) 
2023-05-26 00:07:53.240172: train Epoch: [51][ 33/129]	Time  0.964 ( 1.870)	Data  0.001 ( 0.911)	Loss 7.6625e-02 (8.5534e-02) 
2023-05-26 00:07:55.960629: train Epoch: [51][ 34/129]	Time  2.720 ( 1.895)	Data  1.764 ( 0.935)	Loss 8.4373e-02 (8.5501e-02) 
2023-05-26 00:07:56.914897: train Epoch: [51][ 35/129]	Time  0.954 ( 1.869)	Data  0.001 ( 0.909)	Loss 8.9308e-02 (8.5606e-02) 
2023-05-26 00:07:59.453037: train Epoch: [51][ 36/129]	Time  2.538 ( 1.887)	Data  1.591 ( 0.927)	Loss 7.6949e-02 (8.5372e-02) 
2023-05-26 00:08:00.402447: train Epoch: [51][ 37/129]	Time  0.949 ( 1.862)	Data  0.001 ( 0.903)	Loss 4.8734e-02 (8.4408e-02) 
2023-05-26 00:08:03.031287: train Epoch: [51][ 38/129]	Time  2.629 ( 1.882)	Data  1.682 ( 0.923)	Loss 8.9353e-02 (8.4535e-02) 
2023-05-26 00:08:03.981028: train Epoch: [51][ 39/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.900)	Loss 1.1430e-01 (8.5279e-02) 
2023-05-26 00:08:06.623644: train Epoch: [51][ 40/129]	Time  2.643 ( 1.878)	Data  1.696 ( 0.919)	Loss 9.6797e-02 (8.5560e-02) 
2023-05-26 00:08:07.576217: train Epoch: [51][ 41/129]	Time  0.953 ( 1.856)	Data  0.001 ( 0.898)	Loss 6.7442e-02 (8.5129e-02) 
2023-05-26 00:08:10.256935: train Epoch: [51][ 42/129]	Time  2.681 ( 1.875)	Data  1.734 ( 0.917)	Loss 6.5053e-02 (8.4662e-02) 
2023-05-26 00:08:11.206528: train Epoch: [51][ 43/129]	Time  0.950 ( 1.854)	Data  0.001 ( 0.896)	Loss 6.2702e-02 (8.4163e-02) 
2023-05-26 00:08:13.842722: train Epoch: [51][ 44/129]	Time  2.636 ( 1.871)	Data  1.689 ( 0.914)	Loss 4.9617e-02 (8.3395e-02) 
2023-05-26 00:08:14.791728: train Epoch: [51][ 45/129]	Time  0.949 ( 1.851)	Data  0.001 ( 0.894)	Loss 6.6188e-02 (8.3021e-02) 
2023-05-26 00:08:17.402235: train Epoch: [51][ 46/129]	Time  2.611 ( 1.867)	Data  1.663 ( 0.910)	Loss 6.6334e-02 (8.2666e-02) 
2023-05-26 00:08:18.353431: train Epoch: [51][ 47/129]	Time  0.951 ( 1.848)	Data  0.001 ( 0.891)	Loss 5.4013e-02 (8.2069e-02) 
2023-05-26 00:08:21.106789: train Epoch: [51][ 48/129]	Time  2.753 ( 1.867)	Data  1.806 ( 0.910)	Loss 9.0782e-02 (8.2247e-02) 
2023-05-26 00:08:22.056899: train Epoch: [51][ 49/129]	Time  0.950 ( 1.848)	Data  0.001 ( 0.892)	Loss 1.0828e-01 (8.2767e-02) 
2023-05-26 00:08:24.751158: train Epoch: [51][ 50/129]	Time  2.694 ( 1.865)	Data  1.746 ( 0.909)	Loss 7.7591e-02 (8.2666e-02) 
2023-05-26 00:08:25.701613: train Epoch: [51][ 51/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.891)	Loss 6.7562e-02 (8.2375e-02) 
2023-05-26 00:08:28.203927: train Epoch: [51][ 52/129]	Time  2.502 ( 1.860)	Data  1.553 ( 0.904)	Loss 4.9600e-02 (8.1757e-02) 
2023-05-26 00:08:29.153715: train Epoch: [51][ 53/129]	Time  0.950 ( 1.843)	Data  0.001 ( 0.887)	Loss 1.3563e-01 (8.2755e-02) 
2023-05-26 00:08:31.807062: train Epoch: [51][ 54/129]	Time  2.653 ( 1.858)	Data  1.709 ( 0.902)	Loss 4.2346e-02 (8.2020e-02) 
2023-05-26 00:08:32.757682: train Epoch: [51][ 55/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.886)	Loss 5.7815e-02 (8.1588e-02) 
2023-05-26 00:08:35.341717: train Epoch: [51][ 56/129]	Time  2.584 ( 1.854)	Data  1.636 ( 0.899)	Loss 5.4019e-02 (8.1104e-02) 
2023-05-26 00:08:36.291312: train Epoch: [51][ 57/129]	Time  0.950 ( 1.839)	Data  0.001 ( 0.883)	Loss 9.7599e-02 (8.1389e-02) 
2023-05-26 00:08:38.984730: train Epoch: [51][ 58/129]	Time  2.693 ( 1.853)	Data  1.748 ( 0.898)	Loss 6.9398e-02 (8.1185e-02) 
2023-05-26 00:08:39.933505: train Epoch: [51][ 59/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.883)	Loss 9.2013e-02 (8.1366e-02) 
2023-05-26 00:08:42.579812: train Epoch: [51][ 60/129]	Time  2.646 ( 1.851)	Data  1.700 ( 0.897)	Loss 7.4901e-02 (8.1260e-02) 
2023-05-26 00:08:43.528773: train Epoch: [51][ 61/129]	Time  0.949 ( 1.837)	Data  0.001 ( 0.882)	Loss 8.4596e-02 (8.1314e-02) 
2023-05-26 00:08:46.258038: train Epoch: [51][ 62/129]	Time  2.729 ( 1.851)	Data  1.784 ( 0.896)	Loss 8.9778e-02 (8.1448e-02) 
2023-05-26 00:08:47.208508: train Epoch: [51][ 63/129]	Time  0.950 ( 1.837)	Data  0.001 ( 0.882)	Loss 5.9309e-02 (8.1102e-02) 
2023-05-26 00:08:49.822241: train Epoch: [51][ 64/129]	Time  2.614 ( 1.849)	Data  1.668 ( 0.894)	Loss 5.4536e-02 (8.0693e-02) 
2023-05-26 00:08:50.772446: train Epoch: [51][ 65/129]	Time  0.950 ( 1.835)	Data  0.001 ( 0.881)	Loss 6.5808e-02 (8.0468e-02) 
2023-05-26 00:08:53.454803: train Epoch: [51][ 66/129]	Time  2.682 ( 1.848)	Data  1.736 ( 0.894)	Loss 1.0365e-01 (8.0814e-02) 
2023-05-26 00:08:54.405762: train Epoch: [51][ 67/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.881)	Loss 6.9836e-02 (8.0652e-02) 
2023-05-26 00:08:57.084168: train Epoch: [51][ 68/129]	Time  2.678 ( 1.847)	Data  1.732 ( 0.893)	Loss 7.6351e-02 (8.0590e-02) 
2023-05-26 00:08:58.035077: train Epoch: [51][ 69/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.880)	Loss 5.4007e-02 (8.0210e-02) 
2023-05-26 00:09:00.626327: train Epoch: [51][ 70/129]	Time  2.591 ( 1.845)	Data  1.645 ( 0.891)	Loss 6.8644e-02 (8.0047e-02) 
2023-05-26 00:09:01.581693: train Epoch: [51][ 71/129]	Time  0.955 ( 1.832)	Data  0.001 ( 0.879)	Loss 8.7533e-02 (8.0151e-02) 
2023-05-26 00:09:04.221062: train Epoch: [51][ 72/129]	Time  2.639 ( 1.844)	Data  1.692 ( 0.890)	Loss 7.5866e-02 (8.0093e-02) 
2023-05-26 00:09:05.171717: train Epoch: [51][ 73/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.878)	Loss 8.2247e-02 (8.0122e-02) 
2023-05-26 00:09:07.810303: train Epoch: [51][ 74/129]	Time  2.639 ( 1.842)	Data  1.680 ( 0.888)	Loss 5.3320e-02 (7.9764e-02) 
2023-05-26 00:09:08.772720: train Epoch: [51][ 75/129]	Time  0.962 ( 1.831)	Data  0.001 ( 0.877)	Loss 7.3939e-02 (7.9688e-02) 
2023-05-26 00:09:11.426373: train Epoch: [51][ 76/129]	Time  2.654 ( 1.841)	Data  1.697 ( 0.887)	Loss 5.8824e-02 (7.9417e-02) 
2023-05-26 00:09:12.390337: train Epoch: [51][ 77/129]	Time  0.964 ( 1.830)	Data  0.001 ( 0.876)	Loss 1.2145e-01 (7.9956e-02) 
2023-05-26 00:09:14.989828: train Epoch: [51][ 78/129]	Time  2.599 ( 1.840)	Data  1.645 ( 0.886)	Loss 8.9556e-02 (8.0077e-02) 
2023-05-26 00:09:15.940419: train Epoch: [51][ 79/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.875)	Loss 6.1904e-02 (7.9850e-02) 
2023-05-26 00:09:18.671638: train Epoch: [51][ 80/129]	Time  2.731 ( 1.840)	Data  1.786 ( 0.886)	Loss 7.0795e-02 (7.9738e-02) 
2023-05-26 00:09:19.621149: train Epoch: [51][ 81/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.875)	Loss 6.4023e-02 (7.9546e-02) 
2023-05-26 00:09:22.333376: train Epoch: [51][ 82/129]	Time  2.712 ( 1.840)	Data  1.765 ( 0.886)	Loss 8.2510e-02 (7.9582e-02) 
2023-05-26 00:09:23.282580: train Epoch: [51][ 83/129]	Time  0.949 ( 1.829)	Data  0.001 ( 0.875)	Loss 6.0265e-02 (7.9352e-02) 
2023-05-26 00:09:25.814757: train Epoch: [51][ 84/129]	Time  2.532 ( 1.837)	Data  1.583 ( 0.884)	Loss 9.3299e-02 (7.9516e-02) 
2023-05-26 00:09:26.764261: train Epoch: [51][ 85/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.873)	Loss 1.0342e-01 (7.9794e-02) 
2023-05-26 00:09:29.534960: train Epoch: [51][ 86/129]	Time  2.771 ( 1.838)	Data  1.826 ( 0.884)	Loss 8.1223e-02 (7.9811e-02) 
2023-05-26 00:09:30.484083: train Epoch: [51][ 87/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.874)	Loss 7.1172e-02 (7.9713e-02) 
2023-05-26 00:09:33.168777: train Epoch: [51][ 88/129]	Time  2.685 ( 1.837)	Data  1.739 ( 0.884)	Loss 6.3747e-02 (7.9533e-02) 
2023-05-26 00:09:34.128271: train Epoch: [51][ 89/129]	Time  0.959 ( 1.828)	Data  0.001 ( 0.874)	Loss 9.5274e-02 (7.9708e-02) 
2023-05-26 00:09:36.734437: train Epoch: [51][ 90/129]	Time  2.606 ( 1.836)	Data  1.649 ( 0.883)	Loss 7.1776e-02 (7.9621e-02) 
2023-05-26 00:09:37.686228: train Epoch: [51][ 91/129]	Time  0.952 ( 1.827)	Data  0.001 ( 0.873)	Loss 1.0309e-01 (7.9876e-02) 
2023-05-26 00:09:40.280687: train Epoch: [51][ 92/129]	Time  2.594 ( 1.835)	Data  1.644 ( 0.881)	Loss 4.9501e-02 (7.9549e-02) 
2023-05-26 00:09:41.230969: train Epoch: [51][ 93/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.872)	Loss 1.1567e-01 (7.9934e-02) 
2023-05-26 00:09:43.869076: train Epoch: [51][ 94/129]	Time  2.638 ( 1.834)	Data  1.691 ( 0.881)	Loss 8.2309e-02 (7.9959e-02) 
2023-05-26 00:09:44.820028: train Epoch: [51][ 95/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.871)	Loss 6.5179e-02 (7.9805e-02) 
2023-05-26 00:09:47.527522: train Epoch: [51][ 96/129]	Time  2.707 ( 1.834)	Data  1.760 ( 0.881)	Loss 7.1397e-02 (7.9718e-02) 
2023-05-26 00:09:48.479334: train Epoch: [51][ 97/129]	Time  0.952 ( 1.825)	Data  0.001 ( 0.872)	Loss 7.5485e-02 (7.9675e-02) 
2023-05-26 00:09:51.182233: train Epoch: [51][ 98/129]	Time  2.703 ( 1.834)	Data  1.755 ( 0.881)	Loss 8.6453e-02 (7.9743e-02) 
2023-05-26 00:09:52.134333: train Epoch: [51][ 99/129]	Time  0.952 ( 1.825)	Data  0.001 ( 0.872)	Loss 7.8243e-02 (7.9728e-02) 
2023-05-26 00:09:54.705469: train Epoch: [51][100/129]	Time  2.571 ( 1.832)	Data  1.622 ( 0.879)	Loss 6.7656e-02 (7.9609e-02) 
2023-05-26 00:09:55.656689: train Epoch: [51][101/129]	Time  0.951 ( 1.824)	Data  0.001 ( 0.871)	Loss 6.9474e-02 (7.9509e-02) 
2023-05-26 00:09:58.304318: train Epoch: [51][102/129]	Time  2.648 ( 1.832)	Data  1.700 ( 0.879)	Loss 8.8256e-02 (7.9594e-02) 
2023-05-26 00:09:59.254718: train Epoch: [51][103/129]	Time  0.950 ( 1.823)	Data  0.001 ( 0.870)	Loss 7.4593e-02 (7.9546e-02) 
2023-05-26 00:10:02.001951: train Epoch: [51][104/129]	Time  2.747 ( 1.832)	Data  1.780 ( 0.879)	Loss 6.4566e-02 (7.9404e-02) 
2023-05-26 00:10:02.963735: train Epoch: [51][105/129]	Time  0.962 ( 1.824)	Data  0.001 ( 0.871)	Loss 1.1958e-01 (7.9783e-02) 
2023-05-26 00:10:05.679049: train Epoch: [51][106/129]	Time  2.715 ( 1.832)	Data  1.766 ( 0.879)	Loss 7.4762e-02 (7.9736e-02) 
2023-05-26 00:10:06.630806: train Epoch: [51][107/129]	Time  0.952 ( 1.824)	Data  0.001 ( 0.871)	Loss 6.2006e-02 (7.9572e-02) 
2023-05-26 00:10:09.380459: train Epoch: [51][108/129]	Time  2.750 ( 1.832)	Data  1.790 ( 0.879)	Loss 1.6190e-01 (8.0327e-02) 
2023-05-26 00:10:10.330301: train Epoch: [51][109/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.871)	Loss 6.9202e-02 (8.0226e-02) 
2023-05-26 00:10:12.939813: train Epoch: [51][110/129]	Time  2.610 ( 1.831)	Data  1.661 ( 0.878)	Loss 6.4552e-02 (8.0084e-02) 
2023-05-26 00:10:13.891645: train Epoch: [51][111/129]	Time  0.952 ( 1.824)	Data  0.001 ( 0.871)	Loss 1.1702e-01 (8.0414e-02) 
2023-05-26 00:10:16.456287: train Epoch: [51][112/129]	Time  2.565 ( 1.830)	Data  1.606 ( 0.877)	Loss 7.2919e-02 (8.0348e-02) 
2023-05-26 00:10:17.418373: train Epoch: [51][113/129]	Time  0.962 ( 1.823)	Data  0.001 ( 0.869)	Loss 7.9438e-02 (8.0340e-02) 
2023-05-26 00:10:20.074889: train Epoch: [51][114/129]	Time  2.657 ( 1.830)	Data  1.697 ( 0.877)	Loss 6.9603e-02 (8.0247e-02) 
2023-05-26 00:10:21.036318: train Epoch: [51][115/129]	Time  0.961 ( 1.822)	Data  0.001 ( 0.869)	Loss 1.1600e-01 (8.0555e-02) 
2023-05-26 00:10:23.771956: train Epoch: [51][116/129]	Time  2.736 ( 1.830)	Data  1.774 ( 0.877)	Loss 8.7453e-02 (8.0614e-02) 
2023-05-26 00:10:24.733951: train Epoch: [51][117/129]	Time  0.962 ( 1.823)	Data  0.001 ( 0.869)	Loss 7.0839e-02 (8.0531e-02) 
2023-05-26 00:10:27.173015: train Epoch: [51][118/129]	Time  2.439 ( 1.828)	Data  1.477 ( 0.874)	Loss 5.6566e-02 (8.0329e-02) 
2023-05-26 00:10:28.130775: train Epoch: [51][119/129]	Time  0.958 ( 1.821)	Data  0.001 ( 0.867)	Loss 6.1181e-02 (8.0170e-02) 
2023-05-26 00:10:30.936676: train Epoch: [51][120/129]	Time  2.806 ( 1.829)	Data  1.845 ( 0.875)	Loss 5.5652e-02 (7.9967e-02) 
2023-05-26 00:10:31.899000: train Epoch: [51][121/129]	Time  0.962 ( 1.822)	Data  0.001 ( 0.868)	Loss 1.9674e-01 (8.0924e-02) 
2023-05-26 00:10:34.555861: train Epoch: [51][122/129]	Time  2.657 ( 1.829)	Data  1.695 ( 0.875)	Loss 9.4150e-02 (8.1032e-02) 
2023-05-26 00:10:35.517796: train Epoch: [51][123/129]	Time  0.962 ( 1.822)	Data  0.001 ( 0.868)	Loss 1.5016e-01 (8.1589e-02) 
2023-05-26 00:10:38.105699: train Epoch: [51][124/129]	Time  2.588 ( 1.828)	Data  1.639 ( 0.874)	Loss 6.8744e-02 (8.1487e-02) 
2023-05-26 00:10:39.055205: train Epoch: [51][125/129]	Time  0.950 ( 1.821)	Data  0.001 ( 0.867)	Loss 1.0610e-01 (8.1682e-02) 
2023-05-26 00:10:41.761622: train Epoch: [51][126/129]	Time  2.706 ( 1.828)	Data  1.758 ( 0.874)	Loss 5.8025e-02 (8.1496e-02) 
2023-05-26 00:10:42.710200: train Epoch: [51][127/129]	Time  0.949 ( 1.821)	Data  0.001 ( 0.867)	Loss 5.5055e-02 (8.1289e-02) 
2023-05-26 00:10:44.259736: train Epoch: [51][128/129]	Time  1.550 ( 1.819)	Data  0.601 ( 0.865)	Loss 8.7929e-02 (8.1341e-02) 
2023-05-26 00:10:44.291894: Train Epoch done in 234.64894290300072 s 
2023-05-26 00:10:46.685274: val Epoch: [51][ 0/72]	Time  1.652 ( 1.652)	Data  1.445 ( 1.445)	Loss 6.3417e-02 (6.3417e-02) 
2023-05-26 00:10:46.811599: val Epoch: [51][ 1/72]	Time  0.127 ( 0.889)	Data  0.001 ( 0.723)	Loss 9.8550e-02 (8.0983e-02) 
2023-05-26 00:10:47.931680: val Epoch: [51][ 2/72]	Time  1.120 ( 0.966)	Data  0.993 ( 0.813)	Loss 8.2335e-02 (8.1434e-02) 
2023-05-26 00:10:48.056785: val Epoch: [51][ 3/72]	Time  0.125 ( 0.756)	Data  0.001 ( 0.610)	Loss 2.3357e-01 (1.1947e-01) 
2023-05-26 00:10:49.170943: val Epoch: [51][ 4/72]	Time  1.114 ( 0.828)	Data  0.985 ( 0.685)	Loss 6.1923e-02 (1.0796e-01) 
2023-05-26 00:10:49.297205: val Epoch: [51][ 5/72]	Time  0.126 ( 0.711)	Data  0.001 ( 0.571)	Loss 8.7193e-02 (1.0450e-01) 
2023-05-26 00:10:50.474879: val Epoch: [51][ 6/72]	Time  1.178 ( 0.777)	Data  1.052 ( 0.640)	Loss 8.6006e-02 (1.0186e-01) 
2023-05-26 00:10:50.600116: val Epoch: [51][ 7/72]	Time  0.125 ( 0.696)	Data  0.001 ( 0.560)	Loss 8.3078e-02 (9.9509e-02) 
2023-05-26 00:10:51.727083: val Epoch: [51][ 8/72]	Time  1.127 ( 0.744)	Data  1.002 ( 0.609)	Loss 4.0226e-02 (9.2922e-02) 
2023-05-26 00:10:51.851741: val Epoch: [51][ 9/72]	Time  0.125 ( 0.682)	Data  0.001 ( 0.548)	Loss 1.2324e-01 (9.5954e-02) 
2023-05-26 00:10:52.949425: val Epoch: [51][10/72]	Time  1.098 ( 0.720)	Data  0.973 ( 0.587)	Loss 4.8476e-02 (9.1638e-02) 
2023-05-26 00:10:53.073808: val Epoch: [51][11/72]	Time  0.124 ( 0.670)	Data  0.001 ( 0.538)	Loss 4.0104e-02 (8.7343e-02) 
2023-05-26 00:10:54.173902: val Epoch: [51][12/72]	Time  1.100 ( 0.703)	Data  0.975 ( 0.572)	Loss 1.4817e-01 (9.2023e-02) 
2023-05-26 00:10:54.298341: val Epoch: [51][13/72]	Time  0.124 ( 0.662)	Data  0.001 ( 0.531)	Loss 7.5266e-02 (9.0826e-02) 
2023-05-26 00:10:55.399582: val Epoch: [51][14/72]	Time  1.101 ( 0.691)	Data  0.974 ( 0.560)	Loss 6.8624e-02 (8.9346e-02) 
2023-05-26 00:10:55.524795: val Epoch: [51][15/72]	Time  0.125 ( 0.656)	Data  0.001 ( 0.525)	Loss 2.8356e-01 (1.0148e-01) 
2023-05-26 00:10:56.698847: val Epoch: [51][16/72]	Time  1.174 ( 0.686)	Data  1.045 ( 0.556)	Loss 7.8915e-02 (1.0016e-01) 
2023-05-26 00:10:56.823758: val Epoch: [51][17/72]	Time  0.125 ( 0.655)	Data  0.001 ( 0.525)	Loss 3.7196e-02 (9.6659e-02) 
2023-05-26 00:10:58.016988: val Epoch: [51][18/72]	Time  1.193 ( 0.683)	Data  1.068 ( 0.554)	Loss 7.7266e-02 (9.5638e-02) 
2023-05-26 00:10:58.141798: val Epoch: [51][19/72]	Time  0.125 ( 0.655)	Data  0.001 ( 0.526)	Loss 6.0233e-02 (9.3868e-02) 
2023-05-26 00:10:59.229343: val Epoch: [51][20/72]	Time  1.088 ( 0.676)	Data  0.962 ( 0.547)	Loss 6.2083e-02 (9.2354e-02) 
2023-05-26 00:10:59.354280: val Epoch: [51][21/72]	Time  0.125 ( 0.651)	Data  0.001 ( 0.522)	Loss 5.0496e-02 (9.0451e-02) 
2023-05-26 00:11:00.479439: val Epoch: [51][22/72]	Time  1.125 ( 0.672)	Data  0.999 ( 0.543)	Loss 4.6937e-02 (8.8560e-02) 
2023-05-26 00:11:00.605052: val Epoch: [51][23/72]	Time  0.126 ( 0.649)	Data  0.001 ( 0.520)	Loss 5.3999e-02 (8.7119e-02) 
2023-05-26 00:11:01.745424: val Epoch: [51][24/72]	Time  1.140 ( 0.669)	Data  1.007 ( 0.540)	Loss 2.8138e-01 (9.4890e-02) 
2023-05-26 00:11:01.871101: val Epoch: [51][25/72]	Time  0.126 ( 0.648)	Data  0.001 ( 0.519)	Loss 8.2733e-02 (9.4422e-02) 
2023-05-26 00:11:02.933881: val Epoch: [51][26/72]	Time  1.063 ( 0.663)	Data  0.937 ( 0.534)	Loss 5.1694e-02 (9.2840e-02) 
2023-05-26 00:11:03.078349: val Epoch: [51][27/72]	Time  0.144 ( 0.644)	Data  0.020 ( 0.516)	Loss 3.7284e-01 (1.0284e-01) 
2023-05-26 00:11:04.160057: val Epoch: [51][28/72]	Time  1.082 ( 0.660)	Data  0.956 ( 0.531)	Loss 9.1801e-02 (1.0246e-01) 
2023-05-26 00:11:04.310072: val Epoch: [51][29/72]	Time  0.150 ( 0.643)	Data  0.024 ( 0.514)	Loss 5.2430e-02 (1.0079e-01) 
2023-05-26 00:11:05.423285: val Epoch: [51][30/72]	Time  1.113 ( 0.658)	Data  0.983 ( 0.529)	Loss 5.6217e-02 (9.9354e-02) 
2023-05-26 00:11:05.548970: val Epoch: [51][31/72]	Time  0.126 ( 0.641)	Data  0.001 ( 0.513)	Loss 6.4991e-02 (9.8280e-02) 
2023-05-26 00:11:06.668098: val Epoch: [51][32/72]	Time  1.119 ( 0.656)	Data  0.987 ( 0.527)	Loss 1.2139e-01 (9.8980e-02) 
2023-05-26 00:11:06.793173: val Epoch: [51][33/72]	Time  0.125 ( 0.640)	Data  0.001 ( 0.512)	Loss 3.7104e-02 (9.7160e-02) 
2023-05-26 00:11:07.965261: val Epoch: [51][34/72]	Time  1.172 ( 0.655)	Data  1.045 ( 0.527)	Loss 7.6176e-02 (9.6561e-02) 
2023-05-26 00:11:08.085560: val Epoch: [51][35/72]	Time  0.120 ( 0.640)	Data  0.000 ( 0.512)	Loss 1.3993e-01 (9.7765e-02) 
2023-05-26 00:11:09.267728: val Epoch: [51][36/72]	Time  1.182 ( 0.655)	Data  1.062 ( 0.527)	Loss 9.5169e-02 (9.7695e-02) 
2023-05-26 00:11:09.387174: val Epoch: [51][37/72]	Time  0.119 ( 0.641)	Data  0.001 ( 0.513)	Loss 1.0304e-01 (9.7836e-02) 
2023-05-26 00:11:10.529838: val Epoch: [51][38/72]	Time  1.143 ( 0.654)	Data  1.022 ( 0.526)	Loss 5.2786e-02 (9.6681e-02) 
2023-05-26 00:11:10.649198: val Epoch: [51][39/72]	Time  0.119 ( 0.640)	Data  0.000 ( 0.513)	Loss 1.2168e-01 (9.7306e-02) 
2023-05-26 00:11:11.809986: val Epoch: [51][40/72]	Time  1.161 ( 0.653)	Data  1.040 ( 0.526)	Loss 3.2740e-01 (1.0292e-01) 
2023-05-26 00:11:11.929374: val Epoch: [51][41/72]	Time  0.119 ( 0.640)	Data  0.000 ( 0.514)	Loss 3.6927e-02 (1.0135e-01) 
2023-05-26 00:11:13.069677: val Epoch: [51][42/72]	Time  1.140 ( 0.652)	Data  1.020 ( 0.525)	Loss 1.0333e-01 (1.0139e-01) 
2023-05-26 00:11:13.189011: val Epoch: [51][43/72]	Time  0.119 ( 0.640)	Data  0.000 ( 0.513)	Loss 9.4935e-02 (1.0125e-01) 
2023-05-26 00:11:14.287970: val Epoch: [51][44/72]	Time  1.099 ( 0.650)	Data  0.978 ( 0.524)	Loss 4.5871e-02 (1.0002e-01) 
2023-05-26 00:11:14.411542: val Epoch: [51][45/72]	Time  0.124 ( 0.639)	Data  0.001 ( 0.512)	Loss 4.5413e-02 (9.8828e-02) 
2023-05-26 00:11:15.578036: val Epoch: [51][46/72]	Time  1.166 ( 0.650)	Data  1.046 ( 0.524)	Loss 5.1770e-02 (9.7827e-02) 
2023-05-26 00:11:15.697866: val Epoch: [51][47/72]	Time  0.120 ( 0.639)	Data  0.000 ( 0.513)	Loss 6.4451e-01 (1.0922e-01) 
2023-05-26 00:11:16.878281: val Epoch: [51][48/72]	Time  1.180 ( 0.650)	Data  1.060 ( 0.524)	Loss 1.3686e-01 (1.0978e-01) 
2023-05-26 00:11:16.997254: val Epoch: [51][49/72]	Time  0.119 ( 0.639)	Data  0.000 ( 0.513)	Loss 8.3888e-02 (1.0926e-01) 
2023-05-26 00:11:18.134641: val Epoch: [51][50/72]	Time  1.137 ( 0.649)	Data  1.018 ( 0.523)	Loss 2.5066e-01 (1.1203e-01) 
2023-05-26 00:11:18.254146: val Epoch: [51][51/72]	Time  0.120 ( 0.639)	Data  0.000 ( 0.513)	Loss 4.2330e-02 (1.1069e-01) 
2023-05-26 00:11:19.369192: val Epoch: [51][52/72]	Time  1.115 ( 0.648)	Data  0.995 ( 0.522)	Loss 1.8106e-01 (1.1202e-01) 
2023-05-26 00:11:19.489205: val Epoch: [51][53/72]	Time  0.120 ( 0.638)	Data  0.000 ( 0.513)	Loss 8.6792e-02 (1.1155e-01) 
2023-05-26 00:11:20.620665: val Epoch: [51][54/72]	Time  1.131 ( 0.647)	Data  1.012 ( 0.522)	Loss 2.4119e-01 (1.1391e-01) 
2023-05-26 00:11:20.740358: val Epoch: [51][55/72]	Time  0.120 ( 0.638)	Data  0.000 ( 0.512)	Loss 4.5010e-01 (1.1992e-01) 
2023-05-26 00:11:21.879481: val Epoch: [51][56/72]	Time  1.139 ( 0.646)	Data  1.019 ( 0.521)	Loss 4.6831e-02 (1.1863e-01) 
2023-05-26 00:11:21.998857: val Epoch: [51][57/72]	Time  0.119 ( 0.637)	Data  0.000 ( 0.512)	Loss 3.6548e-02 (1.1722e-01) 
2023-05-26 00:11:23.178283: val Epoch: [51][58/72]	Time  1.179 ( 0.647)	Data  1.059 ( 0.522)	Loss 1.5259e-01 (1.1782e-01) 
2023-05-26 00:11:23.297264: val Epoch: [51][59/72]	Time  0.119 ( 0.638)	Data  0.001 ( 0.513)	Loss 7.6357e-02 (1.1713e-01) 
2023-05-26 00:11:24.387210: val Epoch: [51][60/72]	Time  1.090 ( 0.645)	Data  0.970 ( 0.520)	Loss 5.3965e-02 (1.1609e-01) 
2023-05-26 00:11:24.506635: val Epoch: [51][61/72]	Time  0.119 ( 0.637)	Data  0.000 ( 0.512)	Loss 4.8856e-02 (1.1501e-01) 
2023-05-26 00:11:25.659979: val Epoch: [51][62/72]	Time  1.153 ( 0.645)	Data  1.034 ( 0.520)	Loss 3.8285e-01 (1.1926e-01) 
2023-05-26 00:11:25.778915: val Epoch: [51][63/72]	Time  0.119 ( 0.637)	Data  0.000 ( 0.512)	Loss 3.4190e-01 (1.2274e-01) 
2023-05-26 00:11:26.917242: val Epoch: [51][64/72]	Time  1.138 ( 0.644)	Data  1.014 ( 0.520)	Loss 5.8826e-02 (1.2175e-01) 
2023-05-26 00:11:27.043996: val Epoch: [51][65/72]	Time  0.127 ( 0.637)	Data  0.002 ( 0.512)	Loss 3.2454e-01 (1.2483e-01) 
2023-05-26 00:11:28.134100: val Epoch: [51][66/72]	Time  1.090 ( 0.643)	Data  0.961 ( 0.519)	Loss 1.0665e-01 (1.2455e-01) 
2023-05-26 00:11:28.254236: val Epoch: [51][67/72]	Time  0.120 ( 0.636)	Data  0.001 ( 0.511)	Loss 1.2127e-01 (1.2451e-01) 
2023-05-26 00:11:29.393359: val Epoch: [51][68/72]	Time  1.139 ( 0.643)	Data  1.018 ( 0.519)	Loss 4.6035e-02 (1.2337e-01) 
2023-05-26 00:11:29.513072: val Epoch: [51][69/72]	Time  0.120 ( 0.635)	Data  0.000 ( 0.511)	Loss 1.4420e-01 (1.2367e-01) 
2023-05-26 00:11:30.669724: val Epoch: [51][70/72]	Time  1.157 ( 0.643)	Data  1.037 ( 0.519)	Loss 4.3867e-01 (1.2810e-01) 
2023-05-26 00:11:30.788165: val Epoch: [51][71/72]	Time  0.118 ( 0.635)	Data  0.000 ( 0.511)	Loss 3.9074e-02 (1.2687e-01) 
2023-05-26 00:11:30.976505: Epoch 51 :Val : ['ET : 0.7368009090423584', 'TC : 0.781809389591217', 'WT : 0.8653299808502197'] 
2023-05-26 00:11:30.979286: Epoch 51 :Val : ['ET : 0.7368009090423584', 'TC : 0.781809389591217', 'WT : 0.8653299808502197'] 
2023-05-26 00:11:30.981130: Val epoch done in 46.68924343300023 s 
2023-05-26 00:11:30.986475: Batches per epoch:  129 
2023-05-26 00:11:35.782506: train Epoch: [52][  0/129]	Time  4.796 ( 4.796)	Data  3.808 ( 3.808)	Loss 7.7941e-02 (7.7941e-02) 
2023-05-26 00:11:36.732596: train Epoch: [52][  1/129]	Time  0.950 ( 2.873)	Data  0.001 ( 1.904)	Loss 8.7843e-02 (8.2892e-02) 
2023-05-26 00:11:39.378355: train Epoch: [52][  2/129]	Time  2.646 ( 2.797)	Data  1.699 ( 1.836)	Loss 6.9726e-02 (7.8503e-02) 
2023-05-26 00:11:40.328810: train Epoch: [52][  3/129]	Time  0.950 ( 2.336)	Data  0.001 ( 1.377)	Loss 1.8105e-01 (1.0414e-01) 
2023-05-26 00:11:42.966407: train Epoch: [52][  4/129]	Time  2.638 ( 2.396)	Data  1.685 ( 1.439)	Loss 4.9157e-02 (9.3144e-02) 
2023-05-26 00:11:43.917862: train Epoch: [52][  5/129]	Time  0.951 ( 2.155)	Data  0.001 ( 1.199)	Loss 8.9948e-02 (9.2611e-02) 
2023-05-26 00:11:46.727420: train Epoch: [52][  6/129]	Time  2.810 ( 2.249)	Data  1.855 ( 1.293)	Loss 1.0514e-01 (9.4400e-02) 
2023-05-26 00:11:47.679748: train Epoch: [52][  7/129]	Time  0.952 ( 2.087)	Data  0.001 ( 1.131)	Loss 1.1855e-01 (9.7420e-02) 
2023-05-26 00:11:50.313942: train Epoch: [52][  8/129]	Time  2.634 ( 2.147)	Data  1.675 ( 1.192)	Loss 4.8655e-02 (9.2001e-02) 
2023-05-26 00:11:51.263006: train Epoch: [52][  9/129]	Time  0.949 ( 2.028)	Data  0.001 ( 1.073)	Loss 7.5501e-02 (9.0351e-02) 
2023-05-26 00:11:53.847445: train Epoch: [52][ 10/129]	Time  2.584 ( 2.078)	Data  1.634 ( 1.124)	Loss 1.0718e-01 (9.1881e-02) 
2023-05-26 00:11:54.798419: train Epoch: [52][ 11/129]	Time  0.951 ( 1.984)	Data  0.001 ( 1.030)	Loss 1.2698e-01 (9.4806e-02) 
2023-05-26 00:11:57.419409: train Epoch: [52][ 12/129]	Time  2.621 ( 2.033)	Data  1.673 ( 1.080)	Loss 6.3128e-02 (9.2369e-02) 
2023-05-26 00:11:58.371051: train Epoch: [52][ 13/129]	Time  0.952 ( 1.956)	Data  0.001 ( 1.003)	Loss 6.5493e-02 (9.0449e-02) 
2023-05-26 00:12:01.093001: train Epoch: [52][ 14/129]	Time  2.722 ( 2.007)	Data  1.763 ( 1.053)	Loss 5.3568e-02 (8.7990e-02) 
2023-05-26 00:12:02.044368: train Epoch: [52][ 15/129]	Time  0.951 ( 1.941)	Data  0.001 ( 0.988)	Loss 3.7616e-02 (8.4842e-02) 
2023-05-26 00:12:04.931676: train Epoch: [52][ 16/129]	Time  2.887 ( 1.997)	Data  1.940 ( 1.044)	Loss 7.4112e-02 (8.4211e-02) 
2023-05-26 00:12:05.892892: train Epoch: [52][ 17/129]	Time  0.961 ( 1.939)	Data  0.001 ( 0.986)	Loss 6.3293e-02 (8.3049e-02) 
2023-05-26 00:12:08.574936: train Epoch: [52][ 18/129]	Time  2.682 ( 1.978)	Data  1.721 ( 1.024)	Loss 9.0109e-02 (8.3420e-02) 
2023-05-26 00:12:09.537609: train Epoch: [52][ 19/129]	Time  0.963 ( 1.928)	Data  0.001 ( 0.973)	Loss 5.9189e-02 (8.2209e-02) 
2023-05-26 00:12:12.344389: train Epoch: [52][ 20/129]	Time  2.807 ( 1.969)	Data  1.857 ( 1.015)	Loss 1.6856e-01 (8.6321e-02) 
2023-05-26 00:12:13.293739: train Epoch: [52][ 21/129]	Time  0.949 ( 1.923)	Data  0.001 ( 0.969)	Loss 7.5460e-02 (8.5827e-02) 
2023-05-26 00:12:16.002200: train Epoch: [52][ 22/129]	Time  2.708 ( 1.957)	Data  1.748 ( 1.003)	Loss 7.5398e-02 (8.5374e-02) 
2023-05-26 00:12:16.955191: train Epoch: [52][ 23/129]	Time  0.953 ( 1.915)	Data  0.001 ( 0.961)	Loss 9.6024e-02 (8.5817e-02) 
2023-05-26 00:12:19.584187: train Epoch: [52][ 24/129]	Time  2.629 ( 1.944)	Data  1.655 ( 0.989)	Loss 4.9953e-02 (8.4383e-02) 
2023-05-26 00:12:20.546487: train Epoch: [52][ 25/129]	Time  0.962 ( 1.906)	Data  0.001 ( 0.951)	Loss 7.1175e-02 (8.3875e-02) 
2023-05-26 00:12:23.200650: train Epoch: [52][ 26/129]	Time  2.654 ( 1.934)	Data  1.692 ( 0.978)	Loss 7.6444e-02 (8.3600e-02) 
2023-05-26 00:12:24.162001: train Epoch: [52][ 27/129]	Time  0.961 ( 1.899)	Data  0.001 ( 0.944)	Loss 6.9549e-02 (8.3098e-02) 
2023-05-26 00:12:26.863844: train Epoch: [52][ 28/129]	Time  2.702 ( 1.927)	Data  1.743 ( 0.971)	Loss 9.3340e-02 (8.3451e-02) 
2023-05-26 00:12:27.826420: train Epoch: [52][ 29/129]	Time  0.963 ( 1.895)	Data  0.001 ( 0.939)	Loss 6.1546e-02 (8.2721e-02) 
2023-05-26 00:12:30.495658: train Epoch: [52][ 30/129]	Time  2.669 ( 1.920)	Data  1.699 ( 0.963)	Loss 6.1303e-02 (8.2030e-02) 
2023-05-26 00:12:31.455752: train Epoch: [52][ 31/129]	Time  0.960 ( 1.890)	Data  0.001 ( 0.933)	Loss 4.4218e-02 (8.0848e-02) 
2023-05-26 00:12:34.022263: train Epoch: [52][ 32/129]	Time  2.567 ( 1.910)	Data  1.608 ( 0.954)	Loss 1.1893e-01 (8.2002e-02) 
2023-05-26 00:12:34.973322: train Epoch: [52][ 33/129]	Time  0.951 ( 1.882)	Data  0.001 ( 0.926)	Loss 7.5295e-02 (8.1805e-02) 
2023-05-26 00:12:37.550890: train Epoch: [52][ 34/129]	Time  2.578 ( 1.902)	Data  1.627 ( 0.946)	Loss 6.3574e-02 (8.1284e-02) 
2023-05-26 00:12:38.503711: train Epoch: [52][ 35/129]	Time  0.953 ( 1.875)	Data  0.001 ( 0.919)	Loss 8.9021e-02 (8.1499e-02) 
2023-05-26 00:12:41.275146: train Epoch: [52][ 36/129]	Time  2.771 ( 1.900)	Data  1.820 ( 0.944)	Loss 1.2200e-01 (8.2594e-02) 
2023-05-26 00:12:42.238195: train Epoch: [52][ 37/129]	Time  0.963 ( 1.875)	Data  0.001 ( 0.919)	Loss 5.9535e-02 (8.1987e-02) 
2023-05-26 00:12:44.776915: train Epoch: [52][ 38/129]	Time  2.539 ( 1.892)	Data  1.577 ( 0.936)	Loss 5.0066e-02 (8.1168e-02) 
2023-05-26 00:12:45.727199: train Epoch: [52][ 39/129]	Time  0.950 ( 1.869)	Data  0.001 ( 0.913)	Loss 6.0969e-02 (8.0663e-02) 
2023-05-26 00:12:48.304897: train Epoch: [52][ 40/129]	Time  2.578 ( 1.886)	Data  1.627 ( 0.930)	Loss 5.3215e-02 (7.9994e-02) 
2023-05-26 00:12:49.254949: train Epoch: [52][ 41/129]	Time  0.950 ( 1.864)	Data  0.001 ( 0.908)	Loss 5.9610e-02 (7.9509e-02) 
2023-05-26 00:12:51.865431: train Epoch: [52][ 42/129]	Time  2.610 ( 1.881)	Data  1.661 ( 0.925)	Loss 9.1381e-02 (7.9785e-02) 
2023-05-26 00:12:52.814633: train Epoch: [52][ 43/129]	Time  0.949 ( 1.860)	Data  0.001 ( 0.904)	Loss 7.4115e-02 (7.9656e-02) 
2023-05-26 00:12:55.644269: train Epoch: [52][ 44/129]	Time  2.830 ( 1.881)	Data  1.882 ( 0.926)	Loss 8.2942e-02 (7.9729e-02) 
2023-05-26 00:12:56.595315: train Epoch: [52][ 45/129]	Time  0.951 ( 1.861)	Data  0.002 ( 0.906)	Loss 5.3968e-02 (7.9169e-02) 
2023-05-26 00:12:59.273656: train Epoch: [52][ 46/129]	Time  2.678 ( 1.878)	Data  1.722 ( 0.923)	Loss 9.3594e-02 (7.9476e-02) 
2023-05-26 00:13:00.223899: train Epoch: [52][ 47/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.904)	Loss 6.1601e-02 (7.9103e-02) 
2023-05-26 00:13:02.935986: train Epoch: [52][ 48/129]	Time  2.712 ( 1.877)	Data  1.763 ( 0.922)	Loss 6.7758e-02 (7.8872e-02) 
2023-05-26 00:13:03.887300: train Epoch: [52][ 49/129]	Time  0.951 ( 1.858)	Data  0.001 ( 0.903)	Loss 3.8292e-02 (7.8060e-02) 
2023-05-26 00:13:06.518025: train Epoch: [52][ 50/129]	Time  2.631 ( 1.873)	Data  1.672 ( 0.918)	Loss 9.1862e-02 (7.8331e-02) 
2023-05-26 00:13:07.470856: train Epoch: [52][ 51/129]	Time  0.953 ( 1.855)	Data  0.001 ( 0.901)	Loss 4.1259e-02 (7.7618e-02) 
2023-05-26 00:13:10.140821: train Epoch: [52][ 52/129]	Time  2.670 ( 1.871)	Data  1.722 ( 0.916)	Loss 7.1867e-02 (7.7509e-02) 
2023-05-26 00:13:11.093055: train Epoch: [52][ 53/129]	Time  0.952 ( 1.854)	Data  0.001 ( 0.899)	Loss 5.0091e-02 (7.7002e-02) 
2023-05-26 00:13:13.631691: train Epoch: [52][ 54/129]	Time  2.539 ( 1.866)	Data  1.589 ( 0.912)	Loss 6.3482e-02 (7.6756e-02) 
2023-05-26 00:13:14.583180: train Epoch: [52][ 55/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.895)	Loss 5.6420e-02 (7.6393e-02) 
2023-05-26 00:13:17.193824: train Epoch: [52][ 56/129]	Time  2.611 ( 1.863)	Data  1.661 ( 0.909)	Loss 5.5887e-02 (7.6033e-02) 
2023-05-26 00:13:18.144632: train Epoch: [52][ 57/129]	Time  0.951 ( 1.848)	Data  0.001 ( 0.893)	Loss 4.9464e-02 (7.5575e-02) 
2023-05-26 00:13:20.846229: train Epoch: [52][ 58/129]	Time  2.702 ( 1.862)	Data  1.742 ( 0.908)	Loss 6.1456e-02 (7.5336e-02) 
2023-05-26 00:13:21.796711: train Epoch: [52][ 59/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.893)	Loss 5.9493e-02 (7.5071e-02) 
2023-05-26 00:13:24.511567: train Epoch: [52][ 60/129]	Time  2.715 ( 1.861)	Data  1.764 ( 0.907)	Loss 8.2707e-02 (7.5197e-02) 
2023-05-26 00:13:25.460646: train Epoch: [52][ 61/129]	Time  0.949 ( 1.846)	Data  0.001 ( 0.892)	Loss 2.8972e-01 (7.8657e-02) 
2023-05-26 00:13:28.171477: train Epoch: [52][ 62/129]	Time  2.711 ( 1.860)	Data  1.761 ( 0.906)	Loss 8.0826e-02 (7.8691e-02) 
2023-05-26 00:13:29.123470: train Epoch: [52][ 63/129]	Time  0.952 ( 1.846)	Data  0.001 ( 0.892)	Loss 1.1910e-01 (7.9323e-02) 
2023-05-26 00:13:31.736867: train Epoch: [52][ 64/129]	Time  2.613 ( 1.858)	Data  1.653 ( 0.904)	Loss 6.2067e-02 (7.9057e-02) 
2023-05-26 00:13:32.699970: train Epoch: [52][ 65/129]	Time  0.963 ( 1.844)	Data  0.001 ( 0.890)	Loss 6.9033e-02 (7.8905e-02) 
2023-05-26 00:13:35.338892: train Epoch: [52][ 66/129]	Time  2.639 ( 1.856)	Data  1.665 ( 0.901)	Loss 6.7583e-02 (7.8736e-02) 
2023-05-26 00:13:36.301847: train Epoch: [52][ 67/129]	Time  0.963 ( 1.843)	Data  0.001 ( 0.888)	Loss 6.0128e-02 (7.8463e-02) 
2023-05-26 00:13:38.841620: train Epoch: [52][ 68/129]	Time  2.540 ( 1.853)	Data  1.580 ( 0.898)	Loss 9.2366e-02 (7.8664e-02) 
2023-05-26 00:13:39.804009: train Epoch: [52][ 69/129]	Time  0.962 ( 1.840)	Data  0.001 ( 0.885)	Loss 5.6918e-02 (7.8353e-02) 
2023-05-26 00:13:42.495199: train Epoch: [52][ 70/129]	Time  2.691 ( 1.852)	Data  1.732 ( 0.897)	Loss 5.0667e-02 (7.7963e-02) 
2023-05-26 00:13:43.455728: train Epoch: [52][ 71/129]	Time  0.961 ( 1.840)	Data  0.001 ( 0.885)	Loss 7.1779e-02 (7.7878e-02) 
2023-05-26 00:13:46.157790: train Epoch: [52][ 72/129]	Time  2.702 ( 1.852)	Data  1.741 ( 0.897)	Loss 8.9786e-02 (7.8041e-02) 
2023-05-26 00:13:47.120126: train Epoch: [52][ 73/129]	Time  0.962 ( 1.840)	Data  0.001 ( 0.885)	Loss 1.0998e-01 (7.8472e-02) 
2023-05-26 00:13:49.803792: train Epoch: [52][ 74/129]	Time  2.684 ( 1.851)	Data  1.724 ( 0.896)	Loss 7.8006e-02 (7.8466e-02) 
2023-05-26 00:13:50.766884: train Epoch: [52][ 75/129]	Time  0.963 ( 1.839)	Data  0.001 ( 0.884)	Loss 1.0117e-01 (7.8765e-02) 
2023-05-26 00:13:53.403914: train Epoch: [52][ 76/129]	Time  2.637 ( 1.850)	Data  1.669 ( 0.894)	Loss 7.1258e-02 (7.8667e-02) 
2023-05-26 00:13:54.366415: train Epoch: [52][ 77/129]	Time  0.962 ( 1.838)	Data  0.001 ( 0.883)	Loss 8.1021e-02 (7.8697e-02) 
2023-05-26 00:13:56.938169: train Epoch: [52][ 78/129]	Time  2.572 ( 1.847)	Data  1.610 ( 0.892)	Loss 1.0861e-01 (7.9076e-02) 
2023-05-26 00:13:57.904008: train Epoch: [52][ 79/129]	Time  0.966 ( 1.836)	Data  0.001 ( 0.881)	Loss 6.6211e-02 (7.8915e-02) 
2023-05-26 00:14:00.553672: train Epoch: [52][ 80/129]	Time  2.650 ( 1.847)	Data  1.688 ( 0.891)	Loss 6.1759e-02 (7.8703e-02) 
2023-05-26 00:14:01.516303: train Epoch: [52][ 81/129]	Time  0.963 ( 1.836)	Data  0.001 ( 0.880)	Loss 8.9595e-02 (7.8836e-02) 
2023-05-26 00:14:04.067647: train Epoch: [52][ 82/129]	Time  2.551 ( 1.844)	Data  1.591 ( 0.888)	Loss 4.9582e-02 (7.8484e-02) 
2023-05-26 00:14:05.031490: train Epoch: [52][ 83/129]	Time  0.964 ( 1.834)	Data  0.001 ( 0.878)	Loss 6.1159e-02 (7.8278e-02) 
2023-05-26 00:14:07.774164: train Epoch: [52][ 84/129]	Time  2.743 ( 1.845)	Data  1.781 ( 0.888)	Loss 1.0415e-01 (7.8582e-02) 
2023-05-26 00:14:08.737854: train Epoch: [52][ 85/129]	Time  0.964 ( 1.834)	Data  0.001 ( 0.878)	Loss 8.5581e-02 (7.8663e-02) 
2023-05-26 00:14:11.332204: train Epoch: [52][ 86/129]	Time  2.594 ( 1.843)	Data  1.634 ( 0.887)	Loss 6.7730e-02 (7.8538e-02) 
2023-05-26 00:14:12.293945: train Epoch: [52][ 87/129]	Time  0.962 ( 1.833)	Data  0.001 ( 0.877)	Loss 5.9639e-02 (7.8323e-02) 
2023-05-26 00:14:14.937483: train Epoch: [52][ 88/129]	Time  2.644 ( 1.842)	Data  1.696 ( 0.886)	Loss 8.5800e-02 (7.8407e-02) 
2023-05-26 00:14:15.888608: train Epoch: [52][ 89/129]	Time  0.951 ( 1.832)	Data  0.001 ( 0.876)	Loss 7.1334e-02 (7.8328e-02) 
2023-05-26 00:14:18.718496: train Epoch: [52][ 90/129]	Time  2.830 ( 1.843)	Data  1.879 ( 0.887)	Loss 1.1617e-01 (7.8744e-02) 
2023-05-26 00:14:19.668003: train Epoch: [52][ 91/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.878)	Loss 7.0064e-02 (7.8650e-02) 
2023-05-26 00:14:22.415997: train Epoch: [52][ 92/129]	Time  2.748 ( 1.843)	Data  1.793 ( 0.887)	Loss 7.3102e-02 (7.8590e-02) 
2023-05-26 00:14:23.367876: train Epoch: [52][ 93/129]	Time  0.952 ( 1.834)	Data  0.001 ( 0.878)	Loss 9.2176e-02 (7.8735e-02) 
2023-05-26 00:14:26.145838: train Epoch: [52][ 94/129]	Time  2.778 ( 1.844)	Data  1.831 ( 0.888)	Loss 5.1222e-02 (7.8445e-02) 
2023-05-26 00:14:27.096210: train Epoch: [52][ 95/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.879)	Loss 5.3234e-02 (7.8183e-02) 
2023-05-26 00:14:29.938712: train Epoch: [52][ 96/129]	Time  2.842 ( 1.845)	Data  1.896 ( 0.889)	Loss 5.0852e-02 (7.7901e-02) 
2023-05-26 00:14:30.888983: train Epoch: [52][ 97/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.880)	Loss 6.5687e-02 (7.7776e-02) 
2023-05-26 00:14:33.656892: train Epoch: [52][ 98/129]	Time  2.768 ( 1.845)	Data  1.821 ( 0.890)	Loss 9.9125e-02 (7.7992e-02) 
2023-05-26 00:14:34.606912: train Epoch: [52][ 99/129]	Time  0.950 ( 1.836)	Data  0.001 ( 0.881)	Loss 6.6341e-02 (7.7875e-02) 
2023-05-26 00:14:37.279456: train Epoch: [52][100/129]	Time  2.673 ( 1.844)	Data  1.726 ( 0.889)	Loss 8.0242e-02 (7.7899e-02) 
2023-05-26 00:14:38.231216: train Epoch: [52][101/129]	Time  0.952 ( 1.836)	Data  0.001 ( 0.880)	Loss 1.1937e-01 (7.8305e-02) 
2023-05-26 00:14:40.798400: train Epoch: [52][102/129]	Time  2.567 ( 1.843)	Data  1.620 ( 0.888)	Loss 5.3976e-02 (7.8069e-02) 
2023-05-26 00:14:41.749839: train Epoch: [52][103/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.879)	Loss 6.7337e-02 (7.7966e-02) 
2023-05-26 00:14:44.457289: train Epoch: [52][104/129]	Time  2.707 ( 1.843)	Data  1.762 ( 0.888)	Loss 6.5365e-02 (7.7846e-02) 
2023-05-26 00:14:45.407821: train Epoch: [52][105/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.879)	Loss 1.1835e-01 (7.8228e-02) 
2023-05-26 00:14:48.086973: train Epoch: [52][106/129]	Time  2.679 ( 1.842)	Data  1.732 ( 0.887)	Loss 1.3364e-01 (7.8746e-02) 
2023-05-26 00:14:49.036994: train Epoch: [52][107/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.879)	Loss 1.3193e-01 (7.9238e-02) 
2023-05-26 00:14:51.689678: train Epoch: [52][108/129]	Time  2.653 ( 1.841)	Data  1.706 ( 0.887)	Loss 5.8024e-02 (7.9044e-02) 
2023-05-26 00:14:52.639329: train Epoch: [52][109/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.878)	Loss 8.0962e-02 (7.9061e-02) 
2023-05-26 00:14:55.162853: train Epoch: [52][110/129]	Time  2.524 ( 1.839)	Data  1.577 ( 0.885)	Loss 1.0046e-01 (7.9254e-02) 
2023-05-26 00:14:56.112939: train Epoch: [52][111/129]	Time  0.950 ( 1.831)	Data  0.001 ( 0.877)	Loss 7.9294e-02 (7.9254e-02) 
2023-05-26 00:14:58.854201: train Epoch: [52][112/129]	Time  2.741 ( 1.840)	Data  1.794 ( 0.885)	Loss 6.1653e-02 (7.9099e-02) 
2023-05-26 00:14:59.806144: train Epoch: [52][113/129]	Time  0.952 ( 1.832)	Data  0.001 ( 0.877)	Loss 8.3205e-02 (7.9135e-02) 
2023-05-26 00:15:02.571562: train Epoch: [52][114/129]	Time  2.765 ( 1.840)	Data  1.811 ( 0.885)	Loss 6.1209e-02 (7.8979e-02) 
2023-05-26 00:15:03.524359: train Epoch: [52][115/129]	Time  0.953 ( 1.832)	Data  0.001 ( 0.878)	Loss 4.5573e-02 (7.8691e-02) 
2023-05-26 00:15:06.312776: train Epoch: [52][116/129]	Time  2.788 ( 1.840)	Data  1.841 ( 0.886)	Loss 8.6082e-02 (7.8754e-02) 
2023-05-26 00:15:07.263379: train Epoch: [52][117/129]	Time  0.951 ( 1.833)	Data  0.001 ( 0.878)	Loss 6.8814e-02 (7.8670e-02) 
2023-05-26 00:15:09.911288: train Epoch: [52][118/129]	Time  2.648 ( 1.840)	Data  1.701 ( 0.885)	Loss 5.3935e-02 (7.8462e-02) 
2023-05-26 00:15:10.860406: train Epoch: [52][119/129]	Time  0.949 ( 1.832)	Data  0.001 ( 0.878)	Loss 7.7280e-02 (7.8452e-02) 
2023-05-26 00:15:13.501801: train Epoch: [52][120/129]	Time  2.641 ( 1.839)	Data  1.694 ( 0.885)	Loss 9.9582e-02 (7.8627e-02) 
2023-05-26 00:15:14.451380: train Epoch: [52][121/129]	Time  0.950 ( 1.832)	Data  0.001 ( 0.877)	Loss 4.8238e-02 (7.8377e-02) 
2023-05-26 00:15:17.120625: train Epoch: [52][122/129]	Time  2.669 ( 1.838)	Data  1.722 ( 0.884)	Loss 8.4216e-02 (7.8425e-02) 
2023-05-26 00:15:18.073316: train Epoch: [52][123/129]	Time  0.953 ( 1.831)	Data  0.001 ( 0.877)	Loss 5.3727e-02 (7.8226e-02) 
2023-05-26 00:15:20.756053: train Epoch: [52][124/129]	Time  2.683 ( 1.838)	Data  1.736 ( 0.884)	Loss 7.0850e-02 (7.8167e-02) 
2023-05-26 00:15:21.709794: train Epoch: [52][125/129]	Time  0.954 ( 1.831)	Data  0.001 ( 0.877)	Loss 8.2693e-02 (7.8203e-02) 
2023-05-26 00:15:24.373815: train Epoch: [52][126/129]	Time  2.664 ( 1.838)	Data  1.716 ( 0.884)	Loss 6.5453e-02 (7.8102e-02) 
2023-05-26 00:15:25.319318: train Epoch: [52][127/129]	Time  0.945 ( 1.831)	Data  0.001 ( 0.877)	Loss 8.6368e-02 (7.8167e-02) 
2023-05-26 00:15:26.828458: train Epoch: [52][128/129]	Time  1.509 ( 1.828)	Data  0.562 ( 0.874)	Loss 9.7069e-02 (7.8313e-02) 
2023-05-26 00:15:26.871333: Train Epoch done in 235.88488547700035 s 
2023-05-26 00:15:29.222715: val Epoch: [52][ 0/72]	Time  1.576 ( 1.576)	Data  1.368 ( 1.368)	Loss 1.8381e-01 (1.8381e-01) 
2023-05-26 00:15:29.347817: val Epoch: [52][ 1/72]	Time  0.125 ( 0.851)	Data  0.001 ( 0.685)	Loss 3.9637e-02 (1.1172e-01) 
2023-05-26 00:15:30.351516: val Epoch: [52][ 2/72]	Time  1.004 ( 0.902)	Data  0.872 ( 0.747)	Loss 2.0801e-01 (1.4382e-01) 
2023-05-26 00:15:30.477338: val Epoch: [52][ 3/72]	Time  0.126 ( 0.708)	Data  0.001 ( 0.561)	Loss 8.9409e-02 (1.3022e-01) 
2023-05-26 00:15:31.662505: val Epoch: [52][ 4/72]	Time  1.185 ( 0.803)	Data  1.060 ( 0.660)	Loss 9.3804e-02 (1.2293e-01) 
2023-05-26 00:15:31.787677: val Epoch: [52][ 5/72]	Time  0.125 ( 0.690)	Data  0.001 ( 0.550)	Loss 4.4387e-02 (1.0984e-01) 
2023-05-26 00:15:32.909358: val Epoch: [52][ 6/72]	Time  1.122 ( 0.752)	Data  0.994 ( 0.614)	Loss 4.9696e-02 (1.0125e-01) 
2023-05-26 00:15:33.034311: val Epoch: [52][ 7/72]	Time  0.125 ( 0.673)	Data  0.001 ( 0.537)	Loss 1.1036e-01 (1.0239e-01) 
2023-05-26 00:15:34.071539: val Epoch: [52][ 8/72]	Time  1.037 ( 0.714)	Data  0.910 ( 0.579)	Loss 6.1568e-02 (9.7853e-02) 
2023-05-26 00:15:34.211245: val Epoch: [52][ 9/72]	Time  0.140 ( 0.656)	Data  0.015 ( 0.522)	Loss 3.5456e-01 (1.2352e-01) 
2023-05-26 00:15:35.246596: val Epoch: [52][10/72]	Time  1.035 ( 0.691)	Data  0.910 ( 0.557)	Loss 5.9235e-02 (1.1768e-01) 
2023-05-26 00:15:35.418082: val Epoch: [52][11/72]	Time  0.171 ( 0.648)	Data  0.047 ( 0.515)	Loss 5.4762e-02 (1.1244e-01) 
2023-05-26 00:15:36.475977: val Epoch: [52][12/72]	Time  1.058 ( 0.679)	Data  0.932 ( 0.547)	Loss 7.6656e-02 (1.0968e-01) 
2023-05-26 00:15:36.668164: val Epoch: [52][13/72]	Time  0.192 ( 0.644)	Data  0.068 ( 0.513)	Loss 4.5408e-02 (1.0509e-01) 
2023-05-26 00:15:37.705655: val Epoch: [52][14/72]	Time  1.037 ( 0.671)	Data  0.912 ( 0.539)	Loss 3.1381e-01 (1.1901e-01) 
2023-05-26 00:15:37.877717: val Epoch: [52][15/72]	Time  0.172 ( 0.639)	Data  0.047 ( 0.509)	Loss 3.6565e-02 (1.1385e-01) 
2023-05-26 00:15:38.915896: val Epoch: [52][16/72]	Time  1.038 ( 0.663)	Data  0.912 ( 0.532)	Loss 1.2833e-01 (1.1471e-01) 
2023-05-26 00:15:39.098722: val Epoch: [52][17/72]	Time  0.183 ( 0.636)	Data  0.058 ( 0.506)	Loss 1.1336e-01 (1.1463e-01) 
2023-05-26 00:15:40.108464: val Epoch: [52][18/72]	Time  1.010 ( 0.656)	Data  0.884 ( 0.526)	Loss 3.4473e-02 (1.1041e-01) 
2023-05-26 00:15:40.302200: val Epoch: [52][19/72]	Time  0.194 ( 0.633)	Data  0.069 ( 0.503)	Loss 1.2780e-01 (1.1128e-01) 
2023-05-26 00:15:41.281832: val Epoch: [52][20/72]	Time  0.980 ( 0.649)	Data  0.853 ( 0.520)	Loss 4.6525e-02 (1.0820e-01) 
2023-05-26 00:15:41.541097: val Epoch: [52][21/72]	Time  0.259 ( 0.632)	Data  0.135 ( 0.502)	Loss 3.3998e-01 (1.1873e-01) 
2023-05-26 00:15:42.529419: val Epoch: [52][22/72]	Time  0.988 ( 0.647)	Data  0.862 ( 0.518)	Loss 8.5444e-02 (1.1729e-01) 
2023-05-26 00:15:42.780589: val Epoch: [52][23/72]	Time  0.251 ( 0.631)	Data  0.125 ( 0.502)	Loss 6.5726e-02 (1.1514e-01) 
2023-05-26 00:15:43.716884: val Epoch: [52][24/72]	Time  0.936 ( 0.643)	Data  0.810 ( 0.514)	Loss 4.7291e-02 (1.1242e-01) 
2023-05-26 00:15:43.982618: val Epoch: [52][25/72]	Time  0.266 ( 0.628)	Data  0.142 ( 0.500)	Loss 1.9510e-01 (1.1560e-01) 
2023-05-26 00:15:44.945969: val Epoch: [52][26/72]	Time  0.963 ( 0.641)	Data  0.837 ( 0.512)	Loss 7.5121e-02 (1.1410e-01) 
2023-05-26 00:15:45.238663: val Epoch: [52][27/72]	Time  0.293 ( 0.628)	Data  0.169 ( 0.500)	Loss 5.1026e-02 (1.1185e-01) 
2023-05-26 00:15:46.228889: val Epoch: [52][28/72]	Time  0.990 ( 0.641)	Data  0.864 ( 0.512)	Loss 6.9396e-02 (1.1039e-01) 
2023-05-26 00:15:46.521544: val Epoch: [52][29/72]	Time  0.293 ( 0.629)	Data  0.168 ( 0.501)	Loss 8.5845e-02 (1.0957e-01) 
2023-05-26 00:15:47.420479: val Epoch: [52][30/72]	Time  0.899 ( 0.638)	Data  0.776 ( 0.510)	Loss 4.1531e-02 (1.0737e-01) 
2023-05-26 00:15:47.753713: val Epoch: [52][31/72]	Time  0.333 ( 0.628)	Data  0.213 ( 0.500)	Loss 2.6843e-01 (1.1241e-01) 
2023-05-26 00:15:48.700986: val Epoch: [52][32/72]	Time  0.947 ( 0.638)	Data  0.825 ( 0.510)	Loss 9.4662e-02 (1.1187e-01) 
2023-05-26 00:15:48.983942: val Epoch: [52][33/72]	Time  0.283 ( 0.628)	Data  0.163 ( 0.500)	Loss 8.6047e-02 (1.1111e-01) 
2023-05-26 00:15:49.897044: val Epoch: [52][34/72]	Time  0.913 ( 0.636)	Data  0.791 ( 0.508)	Loss 1.3832e-01 (1.1189e-01) 
2023-05-26 00:15:50.220820: val Epoch: [52][35/72]	Time  0.324 ( 0.627)	Data  0.204 ( 0.500)	Loss 2.9130e-01 (1.1687e-01) 
2023-05-26 00:15:51.145385: val Epoch: [52][36/72]	Time  0.925 ( 0.635)	Data  0.803 ( 0.508)	Loss 1.5378e-01 (1.1787e-01) 
2023-05-26 00:15:51.445457: val Epoch: [52][37/72]	Time  0.300 ( 0.626)	Data  0.180 ( 0.500)	Loss 4.2212e-01 (1.2588e-01) 
2023-05-26 00:15:52.372625: val Epoch: [52][38/72]	Time  0.927 ( 0.634)	Data  0.800 ( 0.507)	Loss 8.7251e-02 (1.2488e-01) 
2023-05-26 00:15:52.725930: val Epoch: [52][39/72]	Time  0.353 ( 0.627)	Data  0.229 ( 0.500)	Loss 6.2971e-02 (1.2334e-01) 
2023-05-26 00:15:53.628901: val Epoch: [52][40/72]	Time  0.903 ( 0.634)	Data  0.776 ( 0.507)	Loss 3.4931e-02 (1.2118e-01) 
2023-05-26 00:15:53.966742: val Epoch: [52][41/72]	Time  0.338 ( 0.627)	Data  0.213 ( 0.500)	Loss 1.0255e-01 (1.2074e-01) 
2023-05-26 00:15:54.887070: val Epoch: [52][42/72]	Time  0.920 ( 0.633)	Data  0.794 ( 0.507)	Loss 8.2042e-02 (1.1984e-01) 
2023-05-26 00:15:55.180904: val Epoch: [52][43/72]	Time  0.294 ( 0.626)	Data  0.170 ( 0.499)	Loss 5.8327e-02 (1.1844e-01) 
2023-05-26 00:15:56.149162: val Epoch: [52][44/72]	Time  0.968 ( 0.633)	Data  0.841 ( 0.507)	Loss 1.2177e-01 (1.1851e-01) 
2023-05-26 00:15:56.434061: val Epoch: [52][45/72]	Time  0.285 ( 0.626)	Data  0.160 ( 0.499)	Loss 3.1495e-01 (1.2278e-01) 
2023-05-26 00:15:57.403157: val Epoch: [52][46/72]	Time  0.969 ( 0.633)	Data  0.842 ( 0.507)	Loss 1.3448e-01 (1.2303e-01) 
2023-05-26 00:15:57.673220: val Epoch: [52][47/72]	Time  0.270 ( 0.626)	Data  0.146 ( 0.499)	Loss 3.8583e-01 (1.2851e-01) 
2023-05-26 00:15:58.667351: val Epoch: [52][48/72]	Time  0.994 ( 0.633)	Data  0.868 ( 0.507)	Loss 3.6792e-01 (1.3339e-01) 
2023-05-26 00:15:58.965517: val Epoch: [52][49/72]	Time  0.298 ( 0.626)	Data  0.173 ( 0.500)	Loss 1.6142e-01 (1.3395e-01) 
2023-05-26 00:15:59.895704: val Epoch: [52][50/72]	Time  0.930 ( 0.632)	Data  0.803 ( 0.506)	Loss 5.5624e-02 (1.3242e-01) 
2023-05-26 00:16:00.158306: val Epoch: [52][51/72]	Time  0.263 ( 0.625)	Data  0.138 ( 0.499)	Loss 4.6568e-02 (1.3077e-01) 
2023-05-26 00:16:01.098111: val Epoch: [52][52/72]	Time  0.940 ( 0.631)	Data  0.813 ( 0.505)	Loss 1.0139e-01 (1.3021e-01) 
2023-05-26 00:16:01.411143: val Epoch: [52][53/72]	Time  0.313 ( 0.625)	Data  0.188 ( 0.499)	Loss 2.6348e-01 (1.3268e-01) 
2023-05-26 00:16:02.349749: val Epoch: [52][54/72]	Time  0.939 ( 0.631)	Data  0.812 ( 0.505)	Loss 5.3354e-02 (1.3124e-01) 
2023-05-26 00:16:02.643476: val Epoch: [52][55/72]	Time  0.294 ( 0.625)	Data  0.170 ( 0.499)	Loss 5.4535e-02 (1.2987e-01) 
2023-05-26 00:16:03.591407: val Epoch: [52][56/72]	Time  0.948 ( 0.631)	Data  0.821 ( 0.504)	Loss 3.6898e-02 (1.2824e-01) 
2023-05-26 00:16:03.854466: val Epoch: [52][57/72]	Time  0.263 ( 0.624)	Data  0.138 ( 0.498)	Loss 6.8455e-02 (1.2721e-01) 
2023-05-26 00:16:04.817582: val Epoch: [52][58/72]	Time  0.963 ( 0.630)	Data  0.837 ( 0.504)	Loss 5.5340e-02 (1.2599e-01) 
2023-05-26 00:16:05.115419: val Epoch: [52][59/72]	Time  0.298 ( 0.624)	Data  0.174 ( 0.498)	Loss 5.4674e-02 (1.2480e-01) 
2023-05-26 00:16:06.019871: val Epoch: [52][60/72]	Time  0.904 ( 0.629)	Data  0.778 ( 0.503)	Loss 8.3251e-02 (1.2412e-01) 
2023-05-26 00:16:06.284534: val Epoch: [52][61/72]	Time  0.265 ( 0.623)	Data  0.140 ( 0.497)	Loss 6.6449e-02 (1.2319e-01) 
2023-05-26 00:16:07.258132: val Epoch: [52][62/72]	Time  0.974 ( 0.629)	Data  0.847 ( 0.502)	Loss 4.3502e-02 (1.2192e-01) 
2023-05-26 00:16:07.537520: val Epoch: [52][63/72]	Time  0.279 ( 0.623)	Data  0.155 ( 0.497)	Loss 3.5237e-01 (1.2552e-01) 
2023-05-26 00:16:08.547550: val Epoch: [52][64/72]	Time  1.010 ( 0.629)	Data  0.884 ( 0.503)	Loss 1.7270e-01 (1.2625e-01) 
2023-05-26 00:16:08.761147: val Epoch: [52][65/72]	Time  0.214 ( 0.623)	Data  0.089 ( 0.497)	Loss 7.4990e-02 (1.2547e-01) 
2023-05-26 00:16:09.791291: val Epoch: [52][66/72]	Time  1.030 ( 0.629)	Data  0.904 ( 0.503)	Loss 5.7688e-02 (1.2446e-01) 
2023-05-26 00:16:09.977506: val Epoch: [52][67/72]	Time  0.186 ( 0.623)	Data  0.062 ( 0.496)	Loss 1.1436e-01 (1.2431e-01) 
2023-05-26 00:16:11.017327: val Epoch: [52][68/72]	Time  1.040 ( 0.629)	Data  0.915 ( 0.502)	Loss 4.4873e-02 (1.2316e-01) 
2023-05-26 00:16:11.176624: val Epoch: [52][69/72]	Time  0.159 ( 0.622)	Data  0.034 ( 0.496)	Loss 5.7781e-02 (1.2223e-01) 
2023-05-26 00:16:12.245676: val Epoch: [52][70/72]	Time  1.069 ( 0.628)	Data  0.939 ( 0.502)	Loss 9.2852e-02 (1.2181e-01) 
2023-05-26 00:16:12.368982: val Epoch: [52][71/72]	Time  0.123 ( 0.621)	Data  0.000 ( 0.495)	Loss 5.4023e-02 (1.2087e-01) 
2023-05-26 00:16:12.563508: Epoch 52 :Val : ['ET : 0.7462292909622192', 'TC : 0.797906219959259', 'WT : 0.877056360244751'] 
2023-05-26 00:16:12.566549: Epoch 52 :Val : ['ET : 0.7462292909622192', 'TC : 0.797906219959259', 'WT : 0.877056360244751'] 
2023-05-26 00:16:12.568462: Saving the model with DSC 0.8139522075653076 
2023-05-26 00:16:13.297627: Val epoch done in 46.42628338099894 s 
2023-05-26 00:16:13.303198: Batches per epoch:  129 
2023-05-26 00:16:18.099424: train Epoch: [53][  0/129]	Time  4.796 ( 4.796)	Data  3.811 ( 3.811)	Loss 4.8832e-02 (4.8832e-02) 
2023-05-26 00:16:19.048343: train Epoch: [53][  1/129]	Time  0.949 ( 2.872)	Data  0.001 ( 1.906)	Loss 5.8408e-02 (5.3620e-02) 
2023-05-26 00:16:21.790252: train Epoch: [53][  2/129]	Time  2.742 ( 2.829)	Data  1.795 ( 1.869)	Loss 6.3756e-02 (5.6999e-02) 
2023-05-26 00:16:22.739102: train Epoch: [53][  3/129]	Time  0.949 ( 2.359)	Data  0.001 ( 1.402)	Loss 2.7741e-02 (4.9684e-02) 
2023-05-26 00:16:25.481242: train Epoch: [53][  4/129]	Time  2.742 ( 2.436)	Data  1.796 ( 1.481)	Loss 8.5504e-02 (5.6848e-02) 
2023-05-26 00:16:26.432425: train Epoch: [53][  5/129]	Time  0.951 ( 2.188)	Data  0.001 ( 1.234)	Loss 7.8649e-02 (6.0482e-02) 
2023-05-26 00:16:29.155402: train Epoch: [53][  6/129]	Time  2.723 ( 2.265)	Data  1.779 ( 1.312)	Loss 8.4522e-02 (6.3916e-02) 
2023-05-26 00:16:30.104438: train Epoch: [53][  7/129]	Time  0.949 ( 2.100)	Data  0.001 ( 1.148)	Loss 5.8048e-02 (6.3182e-02) 
2023-05-26 00:16:32.690457: train Epoch: [53][  8/129]	Time  2.586 ( 2.154)	Data  1.640 ( 1.203)	Loss 6.5619e-02 (6.3453e-02) 
2023-05-26 00:16:33.640475: train Epoch: [53][  9/129]	Time  0.950 ( 2.034)	Data  0.001 ( 1.083)	Loss 4.4812e-02 (6.1589e-02) 
2023-05-26 00:16:36.191641: train Epoch: [53][ 10/129]	Time  2.551 ( 2.081)	Data  1.605 ( 1.130)	Loss 4.5740e-02 (6.0148e-02) 
2023-05-26 00:16:37.141595: train Epoch: [53][ 11/129]	Time  0.950 ( 1.987)	Data  0.001 ( 1.036)	Loss 5.9256e-02 (6.0074e-02) 
2023-05-26 00:16:39.810389: train Epoch: [53][ 12/129]	Time  2.669 ( 2.039)	Data  1.723 ( 1.089)	Loss 2.1825e-01 (7.2241e-02) 
2023-05-26 00:16:40.760482: train Epoch: [53][ 13/129]	Time  0.950 ( 1.961)	Data  0.001 ( 1.011)	Loss 6.6869e-02 (7.1857e-02) 
2023-05-26 00:16:43.448522: train Epoch: [53][ 14/129]	Time  2.688 ( 2.010)	Data  1.742 ( 1.060)	Loss 7.8000e-02 (7.2267e-02) 
2023-05-26 00:16:44.400278: train Epoch: [53][ 15/129]	Time  0.952 ( 1.944)	Data  0.001 ( 0.994)	Loss 1.0244e-01 (7.4153e-02) 
2023-05-26 00:16:47.043670: train Epoch: [53][ 16/129]	Time  2.643 ( 1.985)	Data  1.696 ( 1.035)	Loss 4.6664e-02 (7.2536e-02) 
2023-05-26 00:16:47.994835: train Epoch: [53][ 17/129]	Time  0.951 ( 1.927)	Data  0.001 ( 0.978)	Loss 7.6680e-02 (7.2766e-02) 
2023-05-26 00:16:50.637753: train Epoch: [53][ 18/129]	Time  2.643 ( 1.965)	Data  1.695 ( 1.015)	Loss 6.5153e-02 (7.2365e-02) 
2023-05-26 00:16:51.588729: train Epoch: [53][ 19/129]	Time  0.951 ( 1.914)	Data  0.001 ( 0.965)	Loss 7.7509e-02 (7.2622e-02) 
2023-05-26 00:16:54.197776: train Epoch: [53][ 20/129]	Time  2.609 ( 1.947)	Data  1.662 ( 0.998)	Loss 1.0027e-01 (7.3939e-02) 
2023-05-26 00:16:55.147929: train Epoch: [53][ 21/129]	Time  0.950 ( 1.902)	Data  0.001 ( 0.952)	Loss 6.0585e-02 (7.3332e-02) 
2023-05-26 00:16:57.801922: train Epoch: [53][ 22/129]	Time  2.654 ( 1.935)	Data  1.707 ( 0.985)	Loss 7.4048e-02 (7.3363e-02) 
2023-05-26 00:16:58.754492: train Epoch: [53][ 23/129]	Time  0.953 ( 1.894)	Data  0.001 ( 0.944)	Loss 8.9559e-02 (7.4038e-02) 
2023-05-26 00:17:01.507188: train Epoch: [53][ 24/129]	Time  2.753 ( 1.928)	Data  1.804 ( 0.979)	Loss 9.2871e-02 (7.4791e-02) 
2023-05-26 00:17:02.458671: train Epoch: [53][ 25/129]	Time  0.951 ( 1.891)	Data  0.001 ( 0.941)	Loss 8.4545e-02 (7.5166e-02) 
2023-05-26 00:17:05.302126: train Epoch: [53][ 26/129]	Time  2.843 ( 1.926)	Data  1.896 ( 0.976)	Loss 5.4611e-02 (7.4405e-02) 
2023-05-26 00:17:06.251630: train Epoch: [53][ 27/129]	Time  0.950 ( 1.891)	Data  0.001 ( 0.942)	Loss 5.5363e-02 (7.3725e-02) 
2023-05-26 00:17:08.945110: train Epoch: [53][ 28/129]	Time  2.693 ( 1.919)	Data  1.746 ( 0.969)	Loss 7.2486e-02 (7.3682e-02) 
2023-05-26 00:17:09.896261: train Epoch: [53][ 29/129]	Time  0.951 ( 1.886)	Data  0.001 ( 0.937)	Loss 7.4276e-02 (7.3702e-02) 
2023-05-26 00:17:12.674800: train Epoch: [53][ 30/129]	Time  2.779 ( 1.915)	Data  1.819 ( 0.965)	Loss 5.2196e-02 (7.3008e-02) 
2023-05-26 00:17:13.626330: train Epoch: [53][ 31/129]	Time  0.952 ( 1.885)	Data  0.001 ( 0.935)	Loss 6.7339e-02 (7.2831e-02) 
2023-05-26 00:17:16.276553: train Epoch: [53][ 32/129]	Time  2.650 ( 1.908)	Data  1.702 ( 0.959)	Loss 1.1436e-01 (7.4090e-02) 
2023-05-26 00:17:17.227805: train Epoch: [53][ 33/129]	Time  0.951 ( 1.880)	Data  0.001 ( 0.930)	Loss 6.9626e-02 (7.3958e-02) 
2023-05-26 00:17:20.026661: train Epoch: [53][ 34/129]	Time  2.799 ( 1.906)	Data  1.841 ( 0.956)	Loss 6.9771e-02 (7.3839e-02) 
2023-05-26 00:17:20.978477: train Epoch: [53][ 35/129]	Time  0.952 ( 1.880)	Data  0.001 ( 0.930)	Loss 5.0721e-02 (7.3197e-02) 
2023-05-26 00:17:23.720573: train Epoch: [53][ 36/129]	Time  2.742 ( 1.903)	Data  1.783 ( 0.953)	Loss 1.1424e-01 (7.4306e-02) 
2023-05-26 00:17:24.669849: train Epoch: [53][ 37/129]	Time  0.949 ( 1.878)	Data  0.001 ( 0.928)	Loss 8.5700e-02 (7.4606e-02) 
2023-05-26 00:17:27.380221: train Epoch: [53][ 38/129]	Time  2.710 ( 1.899)	Data  1.752 ( 0.949)	Loss 6.7148e-02 (7.4415e-02) 
2023-05-26 00:17:28.330858: train Epoch: [53][ 39/129]	Time  0.951 ( 1.876)	Data  0.001 ( 0.925)	Loss 4.6908e-02 (7.3727e-02) 
2023-05-26 00:17:31.021797: train Epoch: [53][ 40/129]	Time  2.691 ( 1.896)	Data  1.743 ( 0.945)	Loss 4.7170e-02 (7.3079e-02) 
2023-05-26 00:17:31.972765: train Epoch: [53][ 41/129]	Time  0.951 ( 1.873)	Data  0.001 ( 0.923)	Loss 6.1981e-02 (7.2815e-02) 
2023-05-26 00:17:34.822209: train Epoch: [53][ 42/129]	Time  2.849 ( 1.896)	Data  1.902 ( 0.946)	Loss 4.5827e-02 (7.2187e-02) 
2023-05-26 00:17:35.773285: train Epoch: [53][ 43/129]	Time  0.951 ( 1.874)	Data  0.001 ( 0.924)	Loss 6.8654e-02 (7.2107e-02) 
2023-05-26 00:17:38.614311: train Epoch: [53][ 44/129]	Time  2.841 ( 1.896)	Data  1.893 ( 0.946)	Loss 6.0006e-02 (7.1838e-02) 
2023-05-26 00:17:39.565449: train Epoch: [53][ 45/129]	Time  0.951 ( 1.875)	Data  0.001 ( 0.925)	Loss 7.0955e-02 (7.1819e-02) 
2023-05-26 00:17:42.334947: train Epoch: [53][ 46/129]	Time  2.769 ( 1.894)	Data  1.822 ( 0.944)	Loss 5.4911e-02 (7.1459e-02) 
2023-05-26 00:17:43.285497: train Epoch: [53][ 47/129]	Time  0.951 ( 1.875)	Data  0.001 ( 0.924)	Loss 6.8835e-02 (7.1405e-02) 
2023-05-26 00:17:46.000320: train Epoch: [53][ 48/129]	Time  2.715 ( 1.892)	Data  1.770 ( 0.942)	Loss 5.1524e-02 (7.0999e-02) 
2023-05-26 00:17:46.949335: train Epoch: [53][ 49/129]	Time  0.949 ( 1.873)	Data  0.001 ( 0.923)	Loss 1.0978e-01 (7.1775e-02) 
2023-05-26 00:17:49.635203: train Epoch: [53][ 50/129]	Time  2.686 ( 1.889)	Data  1.741 ( 0.939)	Loss 8.4226e-02 (7.2019e-02) 
2023-05-26 00:17:50.583252: train Epoch: [53][ 51/129]	Time  0.948 ( 1.871)	Data  0.001 ( 0.921)	Loss 4.9349e-02 (7.1583e-02) 
2023-05-26 00:17:53.189658: train Epoch: [53][ 52/129]	Time  2.606 ( 1.885)	Data  1.660 ( 0.935)	Loss 7.6462e-02 (7.1675e-02) 
2023-05-26 00:17:54.137840: train Epoch: [53][ 53/129]	Time  0.948 ( 1.867)	Data  0.001 ( 0.918)	Loss 5.4015e-02 (7.1348e-02) 
2023-05-26 00:17:56.721065: train Epoch: [53][ 54/129]	Time  2.583 ( 1.880)	Data  1.628 ( 0.930)	Loss 5.1993e-02 (7.0996e-02) 
2023-05-26 00:17:57.680573: train Epoch: [53][ 55/129]	Time  0.960 ( 1.864)	Data  0.001 ( 0.914)	Loss 9.4059e-02 (7.1408e-02) 
2023-05-26 00:18:00.333151: train Epoch: [53][ 56/129]	Time  2.653 ( 1.878)	Data  1.707 ( 0.928)	Loss 6.4717e-02 (7.1290e-02) 
2023-05-26 00:18:01.282737: train Epoch: [53][ 57/129]	Time  0.950 ( 1.862)	Data  0.001 ( 0.912)	Loss 8.3604e-02 (7.1503e-02) 
2023-05-26 00:18:03.920187: train Epoch: [53][ 58/129]	Time  2.637 ( 1.875)	Data  1.691 ( 0.925)	Loss 7.5282e-02 (7.1567e-02) 
2023-05-26 00:18:04.868001: train Epoch: [53][ 59/129]	Time  0.948 ( 1.859)	Data  0.001 ( 0.910)	Loss 4.2519e-02 (7.1083e-02) 
2023-05-26 00:18:07.509447: train Epoch: [53][ 60/129]	Time  2.641 ( 1.872)	Data  1.696 ( 0.923)	Loss 5.3714e-02 (7.0798e-02) 
2023-05-26 00:18:08.456609: train Epoch: [53][ 61/129]	Time  0.947 ( 1.857)	Data  0.001 ( 0.908)	Loss 5.9338e-02 (7.0613e-02) 
2023-05-26 00:18:11.088495: train Epoch: [53][ 62/129]	Time  2.632 ( 1.870)	Data  1.687 ( 0.920)	Loss 8.0917e-02 (7.0777e-02) 
2023-05-26 00:18:12.036739: train Epoch: [53][ 63/129]	Time  0.948 ( 1.855)	Data  0.001 ( 0.906)	Loss 4.7620e-02 (7.0415e-02) 
2023-05-26 00:18:14.683780: train Epoch: [53][ 64/129]	Time  2.647 ( 1.867)	Data  1.701 ( 0.918)	Loss 8.1068e-02 (7.0579e-02) 
2023-05-26 00:18:15.633628: train Epoch: [53][ 65/129]	Time  0.950 ( 1.853)	Data  0.001 ( 0.904)	Loss 8.0995e-02 (7.0736e-02) 
2023-05-26 00:18:18.333575: train Epoch: [53][ 66/129]	Time  2.700 ( 1.866)	Data  1.754 ( 0.917)	Loss 1.2201e-01 (7.1502e-02) 
2023-05-26 00:18:19.281457: train Epoch: [53][ 67/129]	Time  0.948 ( 1.853)	Data  0.001 ( 0.903)	Loss 8.3599e-02 (7.1680e-02) 
2023-05-26 00:18:21.980172: train Epoch: [53][ 68/129]	Time  2.699 ( 1.865)	Data  1.748 ( 0.915)	Loss 1.0220e-01 (7.2122e-02) 
2023-05-26 00:18:22.928884: train Epoch: [53][ 69/129]	Time  0.949 ( 1.852)	Data  0.001 ( 0.902)	Loss 7.9217e-02 (7.2223e-02) 
2023-05-26 00:18:25.523241: train Epoch: [53][ 70/129]	Time  2.594 ( 1.862)	Data  1.649 ( 0.913)	Loss 6.5243e-02 (7.2125e-02) 
2023-05-26 00:18:26.472003: train Epoch: [53][ 71/129]	Time  0.949 ( 1.850)	Data  0.001 ( 0.900)	Loss 7.5810e-02 (7.2176e-02) 
2023-05-26 00:18:29.059076: train Epoch: [53][ 72/129]	Time  2.587 ( 1.860)	Data  1.642 ( 0.910)	Loss 7.3378e-02 (7.2193e-02) 
2023-05-26 00:18:30.008787: train Epoch: [53][ 73/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.898)	Loss 1.2465e-01 (7.2902e-02) 
2023-05-26 00:18:32.643393: train Epoch: [53][ 74/129]	Time  2.635 ( 1.858)	Data  1.688 ( 0.909)	Loss 1.3213e-01 (7.3691e-02) 
2023-05-26 00:18:33.592944: train Epoch: [53][ 75/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.897)	Loss 6.9824e-02 (7.3640e-02) 
2023-05-26 00:18:36.267961: train Epoch: [53][ 76/129]	Time  2.675 ( 1.857)	Data  1.730 ( 0.908)	Loss 7.7586e-02 (7.3692e-02) 
2023-05-26 00:18:37.216810: train Epoch: [53][ 77/129]	Time  0.949 ( 1.845)	Data  0.001 ( 0.896)	Loss 6.0855e-02 (7.3527e-02) 
2023-05-26 00:18:39.823469: train Epoch: [53][ 78/129]	Time  2.607 ( 1.855)	Data  1.661 ( 0.906)	Loss 8.4691e-02 (7.3668e-02) 
2023-05-26 00:18:40.772792: train Epoch: [53][ 79/129]	Time  0.949 ( 1.843)	Data  0.001 ( 0.894)	Loss 8.1521e-02 (7.3767e-02) 
2023-05-26 00:18:43.369853: train Epoch: [53][ 80/129]	Time  2.597 ( 1.853)	Data  1.651 ( 0.904)	Loss 7.0040e-02 (7.3720e-02) 
2023-05-26 00:18:44.320831: train Epoch: [53][ 81/129]	Time  0.951 ( 1.842)	Data  0.001 ( 0.893)	Loss 5.2721e-02 (7.3464e-02) 
2023-05-26 00:18:46.881439: train Epoch: [53][ 82/129]	Time  2.561 ( 1.850)	Data  1.615 ( 0.901)	Loss 6.7637e-02 (7.3394e-02) 
2023-05-26 00:18:47.833863: train Epoch: [53][ 83/129]	Time  0.952 ( 1.840)	Data  0.001 ( 0.891)	Loss 7.9022e-02 (7.3461e-02) 
2023-05-26 00:18:50.512009: train Epoch: [53][ 84/129]	Time  2.678 ( 1.850)	Data  1.733 ( 0.900)	Loss 1.4947e-01 (7.4355e-02) 
2023-05-26 00:18:51.460976: train Epoch: [53][ 85/129]	Time  0.949 ( 1.839)	Data  0.001 ( 0.890)	Loss 5.2168e-02 (7.4097e-02) 
2023-05-26 00:18:54.024599: train Epoch: [53][ 86/129]	Time  2.564 ( 1.847)	Data  1.619 ( 0.898)	Loss 1.0273e-01 (7.4427e-02) 
2023-05-26 00:18:54.976861: train Epoch: [53][ 87/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.888)	Loss 6.9299e-02 (7.4368e-02) 
2023-05-26 00:18:57.573069: train Epoch: [53][ 88/129]	Time  2.596 ( 1.846)	Data  1.649 ( 0.897)	Loss 5.5319e-02 (7.4154e-02) 
2023-05-26 00:18:58.521786: train Epoch: [53][ 89/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.887)	Loss 8.5290e-02 (7.4278e-02) 
2023-05-26 00:19:01.201185: train Epoch: [53][ 90/129]	Time  2.679 ( 1.845)	Data  1.733 ( 0.896)	Loss 8.2978e-02 (7.4374e-02) 
2023-05-26 00:19:02.152045: train Epoch: [53][ 91/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.886)	Loss 7.9899e-02 (7.4434e-02) 
2023-05-26 00:19:04.772352: train Epoch: [53][ 92/129]	Time  2.620 ( 1.844)	Data  1.674 ( 0.895)	Loss 8.0831e-02 (7.4502e-02) 
2023-05-26 00:19:05.723426: train Epoch: [53][ 93/129]	Time  0.951 ( 1.834)	Data  0.001 ( 0.885)	Loss 5.2533e-02 (7.4269e-02) 
2023-05-26 00:19:08.489435: train Epoch: [53][ 94/129]	Time  2.766 ( 1.844)	Data  1.821 ( 0.895)	Loss 7.9001e-02 (7.4318e-02) 
2023-05-26 00:19:09.438044: train Epoch: [53][ 95/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.886)	Loss 1.1052e-01 (7.4696e-02) 
2023-05-26 00:19:12.073225: train Epoch: [53][ 96/129]	Time  2.635 ( 1.843)	Data  1.689 ( 0.894)	Loss 1.0469e-01 (7.5005e-02) 
2023-05-26 00:19:13.022686: train Epoch: [53][ 97/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.885)	Loss 7.3286e-02 (7.4987e-02) 
2023-05-26 00:19:15.705436: train Epoch: [53][ 98/129]	Time  2.683 ( 1.842)	Data  1.737 ( 0.894)	Loss 1.9545e-01 (7.6204e-02) 
2023-05-26 00:19:16.654773: train Epoch: [53][ 99/129]	Time  0.949 ( 1.834)	Data  0.001 ( 0.885)	Loss 7.9095e-02 (7.6233e-02) 
2023-05-26 00:19:19.330764: train Epoch: [53][100/129]	Time  2.676 ( 1.842)	Data  1.729 ( 0.893)	Loss 1.2244e-01 (7.6690e-02) 
2023-05-26 00:19:20.278535: train Epoch: [53][101/129]	Time  0.948 ( 1.833)	Data  0.001 ( 0.884)	Loss 7.2229e-02 (7.6647e-02) 
2023-05-26 00:19:22.834160: train Epoch: [53][102/129]	Time  2.556 ( 1.840)	Data  1.611 ( 0.891)	Loss 9.3701e-02 (7.6812e-02) 
2023-05-26 00:19:23.780886: train Epoch: [53][103/129]	Time  0.947 ( 1.832)	Data  0.001 ( 0.883)	Loss 1.2270e-01 (7.7254e-02) 
2023-05-26 00:19:26.436822: train Epoch: [53][104/129]	Time  2.656 ( 1.839)	Data  1.709 ( 0.891)	Loss 7.4972e-02 (7.7232e-02) 
2023-05-26 00:19:27.383806: train Epoch: [53][105/129]	Time  0.947 ( 1.831)	Data  0.001 ( 0.882)	Loss 4.6915e-02 (7.6946e-02) 
2023-05-26 00:19:30.026643: train Epoch: [53][106/129]	Time  2.643 ( 1.839)	Data  1.693 ( 0.890)	Loss 5.0061e-02 (7.6695e-02) 
2023-05-26 00:19:30.977015: train Epoch: [53][107/129]	Time  0.950 ( 1.830)	Data  0.001 ( 0.882)	Loss 7.1319e-02 (7.6645e-02) 
2023-05-26 00:19:33.642937: train Epoch: [53][108/129]	Time  2.666 ( 1.838)	Data  1.715 ( 0.889)	Loss 6.3144e-02 (7.6521e-02) 
2023-05-26 00:19:34.590646: train Epoch: [53][109/129]	Time  0.948 ( 1.830)	Data  0.001 ( 0.881)	Loss 6.8319e-02 (7.6446e-02) 
2023-05-26 00:19:37.317413: train Epoch: [53][110/129]	Time  2.727 ( 1.838)	Data  1.778 ( 0.889)	Loss 6.8954e-02 (7.6379e-02) 
2023-05-26 00:19:38.268094: train Epoch: [53][111/129]	Time  0.951 ( 1.830)	Data  0.001 ( 0.881)	Loss 7.5008e-02 (7.6367e-02) 
2023-05-26 00:19:40.912040: train Epoch: [53][112/129]	Time  2.644 ( 1.837)	Data  1.693 ( 0.889)	Loss 5.6334e-02 (7.6189e-02) 
2023-05-26 00:19:41.863210: train Epoch: [53][113/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.881)	Loss 4.8427e-02 (7.5946e-02) 
2023-05-26 00:19:44.579046: train Epoch: [53][114/129]	Time  2.716 ( 1.837)	Data  1.767 ( 0.888)	Loss 5.4056e-02 (7.5755e-02) 
2023-05-26 00:19:45.531893: train Epoch: [53][115/129]	Time  0.953 ( 1.830)	Data  0.001 ( 0.881)	Loss 5.1321e-02 (7.5545e-02) 
2023-05-26 00:19:48.272480: train Epoch: [53][116/129]	Time  2.741 ( 1.837)	Data  1.793 ( 0.889)	Loss 9.2563e-02 (7.5690e-02) 
2023-05-26 00:19:49.224003: train Epoch: [53][117/129]	Time  0.952 ( 1.830)	Data  0.001 ( 0.881)	Loss 6.2323e-02 (7.5577e-02) 
2023-05-26 00:19:51.835695: train Epoch: [53][118/129]	Time  2.612 ( 1.836)	Data  1.662 ( 0.888)	Loss 8.9964e-02 (7.5698e-02) 
2023-05-26 00:19:52.788266: train Epoch: [53][119/129]	Time  0.953 ( 1.829)	Data  0.001 ( 0.880)	Loss 1.1155e-01 (7.5997e-02) 
2023-05-26 00:19:55.553559: train Epoch: [53][120/129]	Time  2.765 ( 1.837)	Data  1.817 ( 0.888)	Loss 5.8425e-02 (7.5851e-02) 
2023-05-26 00:19:56.505127: train Epoch: [53][121/129]	Time  0.952 ( 1.830)	Data  0.001 ( 0.881)	Loss 8.5912e-02 (7.5934e-02) 
2023-05-26 00:19:59.189602: train Epoch: [53][122/129]	Time  2.684 ( 1.836)	Data  1.736 ( 0.888)	Loss 6.2282e-02 (7.5823e-02) 
2023-05-26 00:20:00.143391: train Epoch: [53][123/129]	Time  0.954 ( 1.829)	Data  0.001 ( 0.881)	Loss 8.7490e-02 (7.5917e-02) 
2023-05-26 00:20:03.015054: train Epoch: [53][124/129]	Time  2.872 ( 1.838)	Data  1.925 ( 0.889)	Loss 7.4681e-02 (7.5907e-02) 
2023-05-26 00:20:03.965679: train Epoch: [53][125/129]	Time  0.951 ( 1.831)	Data  0.001 ( 0.882)	Loss 1.2813e-01 (7.6322e-02) 
2023-05-26 00:20:06.093312: train Epoch: [53][126/129]	Time  2.128 ( 1.833)	Data  1.179 ( 0.884)	Loss 6.5542e-02 (7.6237e-02) 
2023-05-26 00:20:07.040224: train Epoch: [53][127/129]	Time  0.947 ( 1.826)	Data  0.001 ( 0.877)	Loss 9.4809e-02 (7.6382e-02) 
2023-05-26 00:20:08.558414: train Epoch: [53][128/129]	Time  1.518 ( 1.824)	Data  0.573 ( 0.875)	Loss 1.2005e-01 (7.6720e-02) 
2023-05-26 00:20:08.597088: Train Epoch done in 235.2939321269987 s 
2023-05-26 00:20:10.911358: val Epoch: [53][ 0/72]	Time  1.544 ( 1.544)	Data  1.333 ( 1.333)	Loss 1.2171e-01 (1.2171e-01) 
2023-05-26 00:20:11.037374: val Epoch: [53][ 1/72]	Time  0.126 ( 0.835)	Data  0.001 ( 0.667)	Loss 4.9470e-02 (8.5590e-02) 
2023-05-26 00:20:12.042785: val Epoch: [53][ 2/72]	Time  1.005 ( 0.892)	Data  0.873 ( 0.736)	Loss 2.1774e-01 (1.2964e-01) 
2023-05-26 00:20:12.168266: val Epoch: [53][ 3/72]	Time  0.125 ( 0.700)	Data  0.001 ( 0.552)	Loss 1.0304e-01 (1.2299e-01) 
2023-05-26 00:20:13.310793: val Epoch: [53][ 4/72]	Time  1.143 ( 0.789)	Data  1.013 ( 0.644)	Loss 5.6184e-02 (1.0963e-01) 
2023-05-26 00:20:13.435892: val Epoch: [53][ 5/72]	Time  0.125 ( 0.678)	Data  0.001 ( 0.537)	Loss 8.9016e-02 (1.0619e-01) 
2023-05-26 00:20:14.461132: val Epoch: [53][ 6/72]	Time  1.025 ( 0.728)	Data  0.899 ( 0.589)	Loss 6.4602e-02 (1.0025e-01) 
2023-05-26 00:20:14.629872: val Epoch: [53][ 7/72]	Time  0.169 ( 0.658)	Data  0.044 ( 0.521)	Loss 6.2071e-02 (9.5479e-02) 
2023-05-26 00:20:15.630118: val Epoch: [53][ 8/72]	Time  1.000 ( 0.696)	Data  0.878 ( 0.560)	Loss 2.2496e-01 (1.0987e-01) 
2023-05-26 00:20:15.894618: val Epoch: [53][ 9/72]	Time  0.265 ( 0.653)	Data  0.145 ( 0.519)	Loss 5.4876e-02 (1.0437e-01) 
2023-05-26 00:20:16.929130: val Epoch: [53][10/72]	Time  1.035 ( 0.687)	Data  0.913 ( 0.555)	Loss 7.2528e-02 (1.0147e-01) 
2023-05-26 00:20:17.153350: val Epoch: [53][11/72]	Time  0.224 ( 0.649)	Data  0.098 ( 0.517)	Loss 3.4633e-01 (1.2188e-01) 
2023-05-26 00:20:18.166042: val Epoch: [53][12/72]	Time  1.013 ( 0.677)	Data  0.887 ( 0.545)	Loss 4.5648e-02 (1.1601e-01) 
2023-05-26 00:20:18.388338: val Epoch: [53][13/72]	Time  0.222 ( 0.644)	Data  0.098 ( 0.513)	Loss 1.3424e-01 (1.1731e-01) 
2023-05-26 00:20:19.393875: val Epoch: [53][14/72]	Time  1.006 ( 0.668)	Data  0.879 ( 0.538)	Loss 8.7475e-02 (1.1533e-01) 
2023-05-26 00:20:19.652757: val Epoch: [53][15/72]	Time  0.259 ( 0.643)	Data  0.134 ( 0.512)	Loss 1.7099e-01 (1.1880e-01) 
2023-05-26 00:20:20.630817: val Epoch: [53][16/72]	Time  0.978 ( 0.663)	Data  0.852 ( 0.532)	Loss 3.7328e-01 (1.3377e-01) 
2023-05-26 00:20:20.887001: val Epoch: [53][17/72]	Time  0.256 ( 0.640)	Data  0.132 ( 0.510)	Loss 3.3126e-01 (1.4475e-01) 
2023-05-26 00:20:21.838980: val Epoch: [53][18/72]	Time  0.952 ( 0.656)	Data  0.826 ( 0.527)	Loss 6.1467e-02 (1.4036e-01) 
2023-05-26 00:20:22.098963: val Epoch: [53][19/72]	Time  0.260 ( 0.637)	Data  0.136 ( 0.507)	Loss 5.9570e-02 (1.3632e-01) 
2023-05-26 00:20:23.081237: val Epoch: [53][20/72]	Time  0.982 ( 0.653)	Data  0.856 ( 0.524)	Loss 1.0415e-01 (1.3479e-01) 
2023-05-26 00:20:23.348269: val Epoch: [53][21/72]	Time  0.267 ( 0.636)	Data  0.143 ( 0.506)	Loss 7.5572e-02 (1.3210e-01) 
2023-05-26 00:20:24.355730: val Epoch: [53][22/72]	Time  1.007 ( 0.652)	Data  0.882 ( 0.523)	Loss 7.2174e-02 (1.2949e-01) 
2023-05-26 00:20:24.545987: val Epoch: [53][23/72]	Time  0.190 ( 0.632)	Data  0.066 ( 0.504)	Loss 6.4396e-02 (1.2678e-01) 
2023-05-26 00:20:25.579206: val Epoch: [53][24/72]	Time  1.033 ( 0.648)	Data  0.908 ( 0.520)	Loss 9.7558e-02 (1.2561e-01) 
2023-05-26 00:20:25.775963: val Epoch: [53][25/72]	Time  0.197 ( 0.631)	Data  0.072 ( 0.503)	Loss 2.7511e-01 (1.3136e-01) 
2023-05-26 00:20:26.829628: val Epoch: [53][26/72]	Time  1.054 ( 0.647)	Data  0.929 ( 0.518)	Loss 1.4739e-01 (1.3196e-01) 
2023-05-26 00:20:26.983023: val Epoch: [53][27/72]	Time  0.153 ( 0.629)	Data  0.029 ( 0.501)	Loss 6.2957e-02 (1.2949e-01) 
2023-05-26 00:20:28.033282: val Epoch: [53][28/72]	Time  1.050 ( 0.644)	Data  0.923 ( 0.515)	Loss 9.6862e-02 (1.2837e-01) 
2023-05-26 00:20:28.239921: val Epoch: [53][29/72]	Time  0.207 ( 0.629)	Data  0.082 ( 0.501)	Loss 1.2924e-01 (1.2840e-01) 
2023-05-26 00:20:29.222791: val Epoch: [53][30/72]	Time  0.983 ( 0.641)	Data  0.857 ( 0.513)	Loss 4.7346e-02 (1.2578e-01) 
2023-05-26 00:20:29.459720: val Epoch: [53][31/72]	Time  0.237 ( 0.628)	Data  0.112 ( 0.500)	Loss 1.2622e-01 (1.2579e-01) 
2023-05-26 00:20:30.447080: val Epoch: [53][32/72]	Time  0.987 ( 0.639)	Data  0.861 ( 0.511)	Loss 3.3341e-01 (1.3209e-01) 
2023-05-26 00:20:30.694018: val Epoch: [53][33/72]	Time  0.247 ( 0.627)	Data  0.123 ( 0.500)	Loss 3.9725e-01 (1.3988e-01) 
2023-05-26 00:20:31.619825: val Epoch: [53][34/72]	Time  0.926 ( 0.636)	Data  0.799 ( 0.508)	Loss 4.0866e-02 (1.3706e-01) 
2023-05-26 00:20:31.935189: val Epoch: [53][35/72]	Time  0.315 ( 0.627)	Data  0.191 ( 0.499)	Loss 6.0154e-02 (1.3492e-01) 
2023-05-26 00:20:32.914333: val Epoch: [53][36/72]	Time  0.979 ( 0.636)	Data  0.853 ( 0.509)	Loss 2.0609e-01 (1.3684e-01) 
2023-05-26 00:20:33.206011: val Epoch: [53][37/72]	Time  0.292 ( 0.627)	Data  0.167 ( 0.500)	Loss 4.9241e-02 (1.3454e-01) 
2023-05-26 00:20:34.203926: val Epoch: [53][38/72]	Time  0.998 ( 0.637)	Data  0.872 ( 0.509)	Loss 7.0512e-02 (1.3290e-01) 
2023-05-26 00:20:34.421428: val Epoch: [53][39/72]	Time  0.217 ( 0.626)	Data  0.093 ( 0.499)	Loss 5.4427e-02 (1.3093e-01) 
2023-05-26 00:20:35.374870: val Epoch: [53][40/72]	Time  0.953 ( 0.634)	Data  0.827 ( 0.507)	Loss 7.9298e-02 (1.2967e-01) 
2023-05-26 00:20:35.615977: val Epoch: [53][41/72]	Time  0.241 ( 0.625)	Data  0.116 ( 0.498)	Loss 5.2524e-02 (1.2784e-01) 
2023-05-26 00:20:36.637769: val Epoch: [53][42/72]	Time  1.022 ( 0.634)	Data  0.896 ( 0.507)	Loss 6.3966e-01 (1.3974e-01) 
2023-05-26 00:20:36.829948: val Epoch: [53][43/72]	Time  0.192 ( 0.624)	Data  0.068 ( 0.497)	Loss 1.0167e-01 (1.3888e-01) 
2023-05-26 00:20:37.841830: val Epoch: [53][44/72]	Time  1.012 ( 0.633)	Data  0.886 ( 0.506)	Loss 8.1739e-02 (1.3761e-01) 
2023-05-26 00:20:38.031391: val Epoch: [53][45/72]	Time  0.190 ( 0.623)	Data  0.065 ( 0.496)	Loss 3.4077e-02 (1.3536e-01) 
2023-05-26 00:20:39.029389: val Epoch: [53][46/72]	Time  0.998 ( 0.631)	Data  0.872 ( 0.504)	Loss 4.7338e-02 (1.3348e-01) 
2023-05-26 00:20:39.251780: val Epoch: [53][47/72]	Time  0.222 ( 0.623)	Data  0.098 ( 0.496)	Loss 3.9906e-02 (1.3153e-01) 
2023-05-26 00:20:40.201869: val Epoch: [53][48/72]	Time  0.950 ( 0.629)	Data  0.824 ( 0.502)	Loss 4.6829e-02 (1.2980e-01) 
2023-05-26 00:20:40.451415: val Epoch: [53][49/72]	Time  0.250 ( 0.622)	Data  0.125 ( 0.495)	Loss 5.1757e-02 (1.2824e-01) 
2023-05-26 00:20:41.424899: val Epoch: [53][50/72]	Time  0.973 ( 0.629)	Data  0.847 ( 0.502)	Loss 4.1219e-01 (1.3381e-01) 
2023-05-26 00:20:41.662344: val Epoch: [53][51/72]	Time  0.237 ( 0.621)	Data  0.113 ( 0.494)	Loss 1.7350e-01 (1.3457e-01) 
2023-05-26 00:20:42.624835: val Epoch: [53][52/72]	Time  0.962 ( 0.628)	Data  0.836 ( 0.501)	Loss 5.4288e-02 (1.3306e-01) 
2023-05-26 00:20:42.885309: val Epoch: [53][53/72]	Time  0.260 ( 0.621)	Data  0.136 ( 0.494)	Loss 4.6036e-02 (1.3145e-01) 
2023-05-26 00:20:43.880595: val Epoch: [53][54/72]	Time  0.995 ( 0.628)	Data  0.870 ( 0.501)	Loss 8.5390e-02 (1.3061e-01) 
2023-05-26 00:20:44.078302: val Epoch: [53][55/72]	Time  0.198 ( 0.620)	Data  0.073 ( 0.493)	Loss 5.4084e-02 (1.2924e-01) 
2023-05-26 00:20:45.096918: val Epoch: [53][56/72]	Time  1.019 ( 0.627)	Data  0.898 ( 0.500)	Loss 3.5578e-02 (1.2760e-01) 
2023-05-26 00:20:45.273045: val Epoch: [53][57/72]	Time  0.176 ( 0.619)	Data  0.057 ( 0.492)	Loss 6.6289e-02 (1.2654e-01) 
2023-05-26 00:20:46.294268: val Epoch: [53][58/72]	Time  1.021 ( 0.626)	Data  0.896 ( 0.499)	Loss 5.3887e-02 (1.2531e-01) 
2023-05-26 00:20:46.450645: val Epoch: [53][59/72]	Time  0.156 ( 0.618)	Data  0.031 ( 0.492)	Loss 4.5820e-02 (1.2399e-01) 
2023-05-26 00:20:47.494657: val Epoch: [53][60/72]	Time  1.044 ( 0.625)	Data  0.918 ( 0.499)	Loss 7.6551e-02 (1.2321e-01) 
2023-05-26 00:20:47.691671: val Epoch: [53][61/72]	Time  0.197 ( 0.618)	Data  0.072 ( 0.492)	Loss 8.4484e-02 (1.2259e-01) 
2023-05-26 00:20:48.690455: val Epoch: [53][62/72]	Time  0.999 ( 0.624)	Data  0.873 ( 0.498)	Loss 3.7458e-02 (1.2123e-01) 
2023-05-26 00:20:48.888115: val Epoch: [53][63/72]	Time  0.198 ( 0.618)	Data  0.073 ( 0.491)	Loss 1.3741e-01 (1.2149e-01) 
2023-05-26 00:20:49.913998: val Epoch: [53][64/72]	Time  1.026 ( 0.624)	Data  0.900 ( 0.497)	Loss 4.1791e-02 (1.2026e-01) 
2023-05-26 00:20:50.068842: val Epoch: [53][65/72]	Time  0.155 ( 0.617)	Data  0.030 ( 0.490)	Loss 5.3892e-02 (1.1925e-01) 
2023-05-26 00:20:51.126444: val Epoch: [53][66/72]	Time  1.058 ( 0.623)	Data  0.931 ( 0.497)	Loss 1.1349e-01 (1.1917e-01) 
2023-05-26 00:20:51.321428: val Epoch: [53][67/72]	Time  0.195 ( 0.617)	Data  0.071 ( 0.491)	Loss 8.2592e-02 (1.1863e-01) 
2023-05-26 00:20:52.339685: val Epoch: [53][68/72]	Time  1.018 ( 0.623)	Data  0.893 ( 0.496)	Loss 1.4557e-01 (1.1902e-01) 
2023-05-26 00:20:52.568373: val Epoch: [53][69/72]	Time  0.229 ( 0.617)	Data  0.104 ( 0.491)	Loss 3.1075e-01 (1.2176e-01) 
2023-05-26 00:20:53.559584: val Epoch: [53][70/72]	Time  0.991 ( 0.622)	Data  0.865 ( 0.496)	Loss 8.8912e-02 (1.2130e-01) 
2023-05-26 00:20:53.703769: val Epoch: [53][71/72]	Time  0.144 ( 0.616)	Data  0.020 ( 0.489)	Loss 2.7123e-01 (1.2338e-01) 
2023-05-26 00:20:53.886853: Epoch 53 :Val : ['ET : 0.742310106754303', 'TC : 0.7978530526161194', 'WT : 0.8687384128570557'] 
2023-05-26 00:20:53.889630: Epoch 53 :Val : ['ET : 0.742310106754303', 'TC : 0.7978530526161194', 'WT : 0.8687384128570557'] 
2023-05-26 00:20:53.891640: Val epoch done in 45.29455442300241 s 
2023-05-26 00:20:53.896950: Batches per epoch:  129 
2023-05-26 00:20:58.769399: train Epoch: [54][  0/129]	Time  4.872 ( 4.872)	Data  3.885 ( 3.885)	Loss 1.0559e-01 (1.0559e-01) 
2023-05-26 00:20:59.717845: train Epoch: [54][  1/129]	Time  0.948 ( 2.910)	Data  0.001 ( 1.943)	Loss 5.8609e-02 (8.2102e-02) 
2023-05-26 00:21:02.420966: train Epoch: [54][  2/129]	Time  2.703 ( 2.841)	Data  1.757 ( 1.881)	Loss 1.1592e-01 (9.3376e-02) 
2023-05-26 00:21:03.368853: train Epoch: [54][  3/129]	Time  0.948 ( 2.368)	Data  0.001 ( 1.411)	Loss 5.5741e-02 (8.3967e-02) 
2023-05-26 00:21:06.042086: train Epoch: [54][  4/129]	Time  2.673 ( 2.429)	Data  1.728 ( 1.474)	Loss 6.7605e-02 (8.0695e-02) 
2023-05-26 00:21:06.992408: train Epoch: [54][  5/129]	Time  0.950 ( 2.183)	Data  0.001 ( 1.229)	Loss 8.0640e-02 (8.0686e-02) 
2023-05-26 00:21:09.723512: train Epoch: [54][  6/129]	Time  2.731 ( 2.261)	Data  1.786 ( 1.308)	Loss 1.0168e-01 (8.3684e-02) 
2023-05-26 00:21:10.672637: train Epoch: [54][  7/129]	Time  0.949 ( 2.097)	Data  0.001 ( 1.145)	Loss 4.9555e-02 (7.9418e-02) 
2023-05-26 00:21:13.335658: train Epoch: [54][  8/129]	Time  2.663 ( 2.160)	Data  1.719 ( 1.209)	Loss 1.2737e-01 (8.4746e-02) 
2023-05-26 00:21:14.286309: train Epoch: [54][  9/129]	Time  0.951 ( 2.039)	Data  0.001 ( 1.088)	Loss 5.3401e-02 (8.1612e-02) 
2023-05-26 00:21:16.916969: train Epoch: [54][ 10/129]	Time  2.631 ( 2.093)	Data  1.683 ( 1.142)	Loss 6.7844e-02 (8.0360e-02) 
2023-05-26 00:21:17.867096: train Epoch: [54][ 11/129]	Time  0.950 ( 1.997)	Data  0.001 ( 1.047)	Loss 5.1426e-02 (7.7949e-02) 
2023-05-26 00:21:20.476781: train Epoch: [54][ 12/129]	Time  2.610 ( 2.045)	Data  1.665 ( 1.094)	Loss 9.0308e-02 (7.8900e-02) 
2023-05-26 00:21:21.425337: train Epoch: [54][ 13/129]	Time  0.949 ( 1.966)	Data  0.001 ( 1.016)	Loss 7.4000e-02 (7.8550e-02) 
2023-05-26 00:21:23.987429: train Epoch: [54][ 14/129]	Time  2.562 ( 2.006)	Data  1.608 ( 1.056)	Loss 5.3650e-02 (7.6890e-02) 
2023-05-26 00:21:24.947298: train Epoch: [54][ 15/129]	Time  0.960 ( 1.941)	Data  0.001 ( 0.990)	Loss 6.1434e-02 (7.5924e-02) 
2023-05-26 00:21:27.574626: train Epoch: [54][ 16/129]	Time  2.627 ( 1.981)	Data  1.671 ( 1.030)	Loss 4.7457e-02 (7.4249e-02) 
2023-05-26 00:21:28.533757: train Epoch: [54][ 17/129]	Time  0.959 ( 1.924)	Data  0.001 ( 0.973)	Loss 7.9758e-02 (7.4555e-02) 
2023-05-26 00:21:31.333818: train Epoch: [54][ 18/129]	Time  2.800 ( 1.970)	Data  1.846 ( 1.019)	Loss 5.2410e-02 (7.3390e-02) 
2023-05-26 00:21:32.292356: train Epoch: [54][ 19/129]	Time  0.959 ( 1.920)	Data  0.001 ( 0.968)	Loss 9.5673e-02 (7.4504e-02) 
2023-05-26 00:21:34.950878: train Epoch: [54][ 20/129]	Time  2.659 ( 1.955)	Data  1.703 ( 1.003)	Loss 5.0383e-02 (7.3355e-02) 
2023-05-26 00:21:35.909361: train Epoch: [54][ 21/129]	Time  0.958 ( 1.910)	Data  0.001 ( 0.957)	Loss 7.6083e-02 (7.3479e-02) 
2023-05-26 00:21:38.560406: train Epoch: [54][ 22/129]	Time  2.651 ( 1.942)	Data  1.696 ( 0.989)	Loss 7.1444e-02 (7.3391e-02) 
2023-05-26 00:21:39.518791: train Epoch: [54][ 23/129]	Time  0.958 ( 1.901)	Data  0.001 ( 0.948)	Loss 1.0751e-01 (7.4813e-02) 
2023-05-26 00:21:42.185771: train Epoch: [54][ 24/129]	Time  2.667 ( 1.932)	Data  1.713 ( 0.979)	Loss 8.9115e-02 (7.5385e-02) 
2023-05-26 00:21:43.144429: train Epoch: [54][ 25/129]	Time  0.959 ( 1.894)	Data  0.001 ( 0.941)	Loss 7.8083e-02 (7.5488e-02) 
2023-05-26 00:21:45.785410: train Epoch: [54][ 26/129]	Time  2.641 ( 1.922)	Data  1.685 ( 0.969)	Loss 5.2843e-02 (7.4650e-02) 
2023-05-26 00:21:46.741874: train Epoch: [54][ 27/129]	Time  0.956 ( 1.887)	Data  0.001 ( 0.934)	Loss 9.3370e-02 (7.5318e-02) 
2023-05-26 00:21:49.313883: train Epoch: [54][ 28/129]	Time  2.572 ( 1.911)	Data  1.628 ( 0.958)	Loss 6.7552e-02 (7.5051e-02) 
2023-05-26 00:21:50.262954: train Epoch: [54][ 29/129]	Time  0.949 ( 1.879)	Data  0.001 ( 0.926)	Loss 6.5738e-02 (7.4740e-02) 
2023-05-26 00:21:52.952519: train Epoch: [54][ 30/129]	Time  2.690 ( 1.905)	Data  1.745 ( 0.953)	Loss 4.7227e-02 (7.3853e-02) 
2023-05-26 00:21:53.901214: train Epoch: [54][ 31/129]	Time  0.949 ( 1.875)	Data  0.001 ( 0.923)	Loss 5.1639e-02 (7.3158e-02) 
2023-05-26 00:21:56.507136: train Epoch: [54][ 32/129]	Time  2.606 ( 1.897)	Data  1.660 ( 0.945)	Loss 7.8150e-02 (7.3310e-02) 
2023-05-26 00:21:57.466811: train Epoch: [54][ 33/129]	Time  0.960 ( 1.870)	Data  0.001 ( 0.917)	Loss 1.1937e-01 (7.4664e-02) 
2023-05-26 00:22:00.125395: train Epoch: [54][ 34/129]	Time  2.659 ( 1.892)	Data  1.702 ( 0.940)	Loss 7.8635e-02 (7.4778e-02) 
2023-05-26 00:22:01.085562: train Epoch: [54][ 35/129]	Time  0.960 ( 1.866)	Data  0.001 ( 0.914)	Loss 1.2825e-01 (7.6263e-02) 
2023-05-26 00:22:03.752297: train Epoch: [54][ 36/129]	Time  2.667 ( 1.888)	Data  1.710 ( 0.935)	Loss 6.7833e-02 (7.6035e-02) 
2023-05-26 00:22:04.710884: train Epoch: [54][ 37/129]	Time  0.959 ( 1.864)	Data  0.001 ( 0.911)	Loss 6.4590e-02 (7.5734e-02) 
2023-05-26 00:22:07.314420: train Epoch: [54][ 38/129]	Time  2.604 ( 1.882)	Data  1.649 ( 0.930)	Loss 1.0864e-01 (7.6578e-02) 
2023-05-26 00:22:08.263985: train Epoch: [54][ 39/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.906)	Loss 8.7466e-02 (7.6850e-02) 
2023-05-26 00:22:10.975997: train Epoch: [54][ 40/129]	Time  2.712 ( 1.880)	Data  1.768 ( 0.927)	Loss 5.2986e-02 (7.6268e-02) 
2023-05-26 00:22:11.923832: train Epoch: [54][ 41/129]	Time  0.948 ( 1.858)	Data  0.001 ( 0.905)	Loss 8.4384e-02 (7.6461e-02) 
2023-05-26 00:22:14.524896: train Epoch: [54][ 42/129]	Time  2.601 ( 1.875)	Data  1.656 ( 0.923)	Loss 9.9037e-02 (7.6986e-02) 
2023-05-26 00:22:15.473787: train Epoch: [54][ 43/129]	Time  0.949 ( 1.854)	Data  0.001 ( 0.902)	Loss 1.1486e-01 (7.7847e-02) 
2023-05-26 00:22:18.120466: train Epoch: [54][ 44/129]	Time  2.647 ( 1.872)	Data  1.702 ( 0.920)	Loss 7.7581e-02 (7.7841e-02) 
2023-05-26 00:22:19.072261: train Epoch: [54][ 45/129]	Time  0.952 ( 1.852)	Data  0.001 ( 0.900)	Loss 1.2353e-01 (7.8834e-02) 
2023-05-26 00:22:21.804556: train Epoch: [54][ 46/129]	Time  2.732 ( 1.870)	Data  1.787 ( 0.919)	Loss 7.4567e-02 (7.8744e-02) 
2023-05-26 00:22:22.751680: train Epoch: [54][ 47/129]	Time  0.947 ( 1.851)	Data  0.001 ( 0.899)	Loss 6.0751e-02 (7.8369e-02) 
2023-05-26 00:22:25.399498: train Epoch: [54][ 48/129]	Time  2.648 ( 1.867)	Data  1.703 ( 0.916)	Loss 1.3351e-01 (7.9494e-02) 
2023-05-26 00:22:26.350016: train Epoch: [54][ 49/129]	Time  0.951 ( 1.849)	Data  0.001 ( 0.898)	Loss 7.9438e-02 (7.9493e-02) 
2023-05-26 00:22:29.074186: train Epoch: [54][ 50/129]	Time  2.724 ( 1.866)	Data  1.778 ( 0.915)	Loss 9.1769e-02 (7.9734e-02) 
2023-05-26 00:22:30.022443: train Epoch: [54][ 51/129]	Time  0.948 ( 1.849)	Data  0.001 ( 0.897)	Loss 8.6823e-02 (7.9870e-02) 
2023-05-26 00:22:32.721704: train Epoch: [54][ 52/129]	Time  2.699 ( 1.865)	Data  1.753 ( 0.913)	Loss 1.3846e-01 (8.0975e-02) 
2023-05-26 00:22:33.668900: train Epoch: [54][ 53/129]	Time  0.947 ( 1.848)	Data  0.001 ( 0.896)	Loss 1.3108e-01 (8.1903e-02) 
2023-05-26 00:22:36.381250: train Epoch: [54][ 54/129]	Time  2.712 ( 1.863)	Data  1.768 ( 0.912)	Loss 1.2156e-01 (8.2624e-02) 
2023-05-26 00:22:37.332268: train Epoch: [54][ 55/129]	Time  0.951 ( 1.847)	Data  0.001 ( 0.896)	Loss 7.3262e-02 (8.2457e-02) 
2023-05-26 00:22:39.999117: train Epoch: [54][ 56/129]	Time  2.667 ( 1.861)	Data  1.722 ( 0.911)	Loss 4.2660e-02 (8.1759e-02) 
2023-05-26 00:22:40.949617: train Epoch: [54][ 57/129]	Time  0.950 ( 1.846)	Data  0.001 ( 0.895)	Loss 7.0301e-02 (8.1561e-02) 
2023-05-26 00:22:43.557930: train Epoch: [54][ 58/129]	Time  2.608 ( 1.859)	Data  1.664 ( 0.908)	Loss 5.3790e-02 (8.1091e-02) 
2023-05-26 00:22:44.507662: train Epoch: [54][ 59/129]	Time  0.950 ( 1.844)	Data  0.001 ( 0.893)	Loss 7.5610e-02 (8.0999e-02) 
2023-05-26 00:22:47.227166: train Epoch: [54][ 60/129]	Time  2.720 ( 1.858)	Data  1.774 ( 0.907)	Loss 5.4003e-02 (8.0557e-02) 
2023-05-26 00:22:48.175057: train Epoch: [54][ 61/129]	Time  0.948 ( 1.843)	Data  0.001 ( 0.893)	Loss 6.6018e-02 (8.0322e-02) 
2023-05-26 00:22:50.838662: train Epoch: [54][ 62/129]	Time  2.664 ( 1.856)	Data  1.719 ( 0.906)	Loss 2.0648e-01 (8.2325e-02) 
2023-05-26 00:22:51.788271: train Epoch: [54][ 63/129]	Time  0.950 ( 1.842)	Data  0.001 ( 0.892)	Loss 7.9235e-02 (8.2276e-02) 
2023-05-26 00:22:54.421321: train Epoch: [54][ 64/129]	Time  2.633 ( 1.854)	Data  1.688 ( 0.904)	Loss 6.8745e-02 (8.2068e-02) 
2023-05-26 00:22:55.370782: train Epoch: [54][ 65/129]	Time  0.949 ( 1.841)	Data  0.001 ( 0.890)	Loss 1.3631e-01 (8.2890e-02) 
2023-05-26 00:22:58.051964: train Epoch: [54][ 66/129]	Time  2.681 ( 1.853)	Data  1.735 ( 0.903)	Loss 8.8838e-02 (8.2979e-02) 
2023-05-26 00:22:58.999774: train Epoch: [54][ 67/129]	Time  0.948 ( 1.840)	Data  0.001 ( 0.890)	Loss 6.0885e-02 (8.2654e-02) 
2023-05-26 00:23:01.580715: train Epoch: [54][ 68/129]	Time  2.581 ( 1.850)	Data  1.635 ( 0.900)	Loss 5.7124e-02 (8.2284e-02) 
2023-05-26 00:23:02.529643: train Epoch: [54][ 69/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.887)	Loss 5.5046e-02 (8.1895e-02) 
2023-05-26 00:23:05.213329: train Epoch: [54][ 70/129]	Time  2.684 ( 1.850)	Data  1.738 ( 0.899)	Loss 7.7813e-02 (8.1837e-02) 
2023-05-26 00:23:06.160750: train Epoch: [54][ 71/129]	Time  0.947 ( 1.837)	Data  0.001 ( 0.887)	Loss 5.6560e-02 (8.1486e-02) 
2023-05-26 00:23:08.742515: train Epoch: [54][ 72/129]	Time  2.582 ( 1.847)	Data  1.635 ( 0.897)	Loss 5.2936e-02 (8.1095e-02) 
2023-05-26 00:23:09.691564: train Epoch: [54][ 73/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.885)	Loss 7.0871e-02 (8.0957e-02) 
2023-05-26 00:23:12.408454: train Epoch: [54][ 74/129]	Time  2.717 ( 1.847)	Data  1.771 ( 0.897)	Loss 1.2964e-01 (8.1606e-02) 
2023-05-26 00:23:13.356962: train Epoch: [54][ 75/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.885)	Loss 4.7276e-02 (8.1154e-02) 
2023-05-26 00:23:16.008241: train Epoch: [54][ 76/129]	Time  2.651 ( 1.846)	Data  1.706 ( 0.896)	Loss 5.6448e-02 (8.0834e-02) 
2023-05-26 00:23:16.957964: train Epoch: [54][ 77/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.884)	Loss 1.3123e-01 (8.1480e-02) 
2023-05-26 00:23:19.574903: train Epoch: [54][ 78/129]	Time  2.617 ( 1.844)	Data  1.670 ( 0.894)	Loss 5.2112e-02 (8.1108e-02) 
2023-05-26 00:23:20.525231: train Epoch: [54][ 79/129]	Time  0.950 ( 1.833)	Data  0.001 ( 0.883)	Loss 1.1039e-01 (8.1474e-02) 
2023-05-26 00:23:23.214671: train Epoch: [54][ 80/129]	Time  2.689 ( 1.843)	Data  1.746 ( 0.894)	Loss 4.7243e-02 (8.1051e-02) 
2023-05-26 00:23:24.163484: train Epoch: [54][ 81/129]	Time  0.949 ( 1.833)	Data  0.001 ( 0.883)	Loss 5.2984e-02 (8.0709e-02) 
2023-05-26 00:23:26.844708: train Epoch: [54][ 82/129]	Time  2.681 ( 1.843)	Data  1.735 ( 0.893)	Loss 1.0279e-01 (8.0975e-02) 
2023-05-26 00:23:27.793513: train Epoch: [54][ 83/129]	Time  0.949 ( 1.832)	Data  0.001 ( 0.882)	Loss 7.1752e-02 (8.0865e-02) 
2023-05-26 00:23:30.382318: train Epoch: [54][ 84/129]	Time  2.589 ( 1.841)	Data  1.643 ( 0.891)	Loss 8.9449e-02 (8.0966e-02) 
2023-05-26 00:23:31.330814: train Epoch: [54][ 85/129]	Time  0.948 ( 1.831)	Data  0.001 ( 0.881)	Loss 7.8973e-02 (8.0943e-02) 
2023-05-26 00:23:34.019572: train Epoch: [54][ 86/129]	Time  2.689 ( 1.840)	Data  1.741 ( 0.891)	Loss 1.1605e-01 (8.1347e-02) 
2023-05-26 00:23:34.968147: train Epoch: [54][ 87/129]	Time  0.949 ( 1.830)	Data  0.001 ( 0.881)	Loss 9.0932e-02 (8.1455e-02) 
2023-05-26 00:23:37.620324: train Epoch: [54][ 88/129]	Time  2.652 ( 1.840)	Data  1.704 ( 0.890)	Loss 7.4464e-02 (8.1377e-02) 
2023-05-26 00:23:38.573542: train Epoch: [54][ 89/129]	Time  0.953 ( 1.830)	Data  0.001 ( 0.880)	Loss 6.4974e-02 (8.1195e-02) 
2023-05-26 00:23:41.285097: train Epoch: [54][ 90/129]	Time  2.712 ( 1.839)	Data  1.765 ( 0.890)	Loss 1.0827e-01 (8.1492e-02) 
2023-05-26 00:23:42.234187: train Epoch: [54][ 91/129]	Time  0.949 ( 1.830)	Data  0.001 ( 0.880)	Loss 7.8785e-02 (8.1463e-02) 
2023-05-26 00:23:44.862651: train Epoch: [54][ 92/129]	Time  2.628 ( 1.838)	Data  1.682 ( 0.889)	Loss 5.1775e-02 (8.1144e-02) 
2023-05-26 00:23:45.812922: train Epoch: [54][ 93/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.879)	Loss 6.5629e-02 (8.0978e-02) 
2023-05-26 00:23:48.408605: train Epoch: [54][ 94/129]	Time  2.596 ( 1.837)	Data  1.648 ( 0.888)	Loss 7.2617e-02 (8.0890e-02) 
2023-05-26 00:23:49.359513: train Epoch: [54][ 95/129]	Time  0.951 ( 1.828)	Data  0.001 ( 0.878)	Loss 7.8413e-02 (8.0865e-02) 
2023-05-26 00:23:52.141459: train Epoch: [54][ 96/129]	Time  2.782 ( 1.838)	Data  1.835 ( 0.888)	Loss 1.3870e-01 (8.1461e-02) 
2023-05-26 00:23:53.091812: train Epoch: [54][ 97/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.879)	Loss 7.4336e-02 (8.1388e-02) 
2023-05-26 00:23:55.848149: train Epoch: [54][ 98/129]	Time  2.756 ( 1.838)	Data  1.811 ( 0.889)	Loss 1.1459e-01 (8.1724e-02) 
2023-05-26 00:23:56.795737: train Epoch: [54][ 99/129]	Time  0.948 ( 1.829)	Data  0.001 ( 0.880)	Loss 8.1282e-02 (8.1719e-02) 
2023-05-26 00:23:59.372317: train Epoch: [54][100/129]	Time  2.577 ( 1.836)	Data  1.630 ( 0.887)	Loss 5.1304e-02 (8.1418e-02) 
2023-05-26 00:24:00.320957: train Epoch: [54][101/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.878)	Loss 8.6444e-02 (8.1467e-02) 
2023-05-26 00:24:02.936883: train Epoch: [54][102/129]	Time  2.616 ( 1.835)	Data  1.668 ( 0.886)	Loss 7.5949e-02 (8.1414e-02) 
2023-05-26 00:24:03.887577: train Epoch: [54][103/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.878)	Loss 5.5297e-02 (8.1163e-02) 
2023-05-26 00:24:06.574740: train Epoch: [54][104/129]	Time  2.687 ( 1.835)	Data  1.742 ( 0.886)	Loss 9.7322e-02 (8.1317e-02) 
2023-05-26 00:24:07.525380: train Epoch: [54][105/129]	Time  0.951 ( 1.827)	Data  0.001 ( 0.877)	Loss 7.0201e-02 (8.1212e-02) 
2023-05-26 00:24:10.165731: train Epoch: [54][106/129]	Time  2.640 ( 1.834)	Data  1.695 ( 0.885)	Loss 9.2025e-02 (8.1313e-02) 
2023-05-26 00:24:11.116312: train Epoch: [54][107/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.877)	Loss 7.4121e-02 (8.1246e-02) 
2023-05-26 00:24:13.667043: train Epoch: [54][108/129]	Time  2.551 ( 1.833)	Data  1.604 ( 0.884)	Loss 1.1237e-01 (8.1532e-02) 
2023-05-26 00:24:14.617350: train Epoch: [54][109/129]	Time  0.950 ( 1.825)	Data  0.001 ( 0.876)	Loss 6.8630e-02 (8.1414e-02) 
2023-05-26 00:24:17.254071: train Epoch: [54][110/129]	Time  2.637 ( 1.832)	Data  1.690 ( 0.883)	Loss 1.1184e-01 (8.1688e-02) 
2023-05-26 00:24:18.204297: train Epoch: [54][111/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.875)	Loss 4.9680e-02 (8.1403e-02) 
2023-05-26 00:24:20.967387: train Epoch: [54][112/129]	Time  2.763 ( 1.832)	Data  1.813 ( 0.883)	Loss 8.7800e-02 (8.1459e-02) 
2023-05-26 00:24:21.918768: train Epoch: [54][113/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.876)	Loss 5.9592e-02 (8.1267e-02) 
2023-05-26 00:24:24.583341: train Epoch: [54][114/129]	Time  2.665 ( 1.832)	Data  1.712 ( 0.883)	Loss 5.8086e-02 (8.1066e-02) 
2023-05-26 00:24:25.543558: train Epoch: [54][115/129]	Time  0.960 ( 1.825)	Data  0.001 ( 0.875)	Loss 8.4735e-02 (8.1097e-02) 
2023-05-26 00:24:28.330692: train Epoch: [54][116/129]	Time  2.787 ( 1.833)	Data  1.840 ( 0.883)	Loss 8.5452e-02 (8.1135e-02) 
2023-05-26 00:24:29.282764: train Epoch: [54][117/129]	Time  0.952 ( 1.825)	Data  0.001 ( 0.876)	Loss 6.2070e-02 (8.0973e-02) 
2023-05-26 00:24:32.210993: train Epoch: [54][118/129]	Time  2.928 ( 1.835)	Data  1.968 ( 0.885)	Loss 5.1699e-02 (8.0727e-02) 
2023-05-26 00:24:33.164961: train Epoch: [54][119/129]	Time  0.954 ( 1.827)	Data  0.001 ( 0.878)	Loss 7.5152e-02 (8.0681e-02) 
2023-05-26 00:24:35.972817: train Epoch: [54][120/129]	Time  2.808 ( 1.835)	Data  1.854 ( 0.886)	Loss 9.3484e-02 (8.0786e-02) 
2023-05-26 00:24:36.923260: train Epoch: [54][121/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.879)	Loss 4.5866e-02 (8.0500e-02) 
2023-05-26 00:24:39.618447: train Epoch: [54][122/129]	Time  2.695 ( 1.835)	Data  1.748 ( 0.886)	Loss 9.6617e-02 (8.0631e-02) 
2023-05-26 00:24:40.568804: train Epoch: [54][123/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.879)	Loss 7.9812e-02 (8.0625e-02) 
2023-05-26 00:24:43.184327: train Epoch: [54][124/129]	Time  2.616 ( 1.834)	Data  1.667 ( 0.885)	Loss 5.3904e-02 (8.0411e-02) 
2023-05-26 00:24:44.134826: train Epoch: [54][125/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.878)	Loss 9.0044e-02 (8.0487e-02) 
2023-05-26 00:24:46.736810: train Epoch: [54][126/129]	Time  2.602 ( 1.833)	Data  1.655 ( 0.884)	Loss 8.4949e-02 (8.0522e-02) 
2023-05-26 00:24:47.683424: train Epoch: [54][127/129]	Time  0.947 ( 1.826)	Data  0.001 ( 0.877)	Loss 5.7815e-02 (8.0345e-02) 
2023-05-26 00:24:49.216214: train Epoch: [54][128/129]	Time  1.533 ( 1.824)	Data  0.588 ( 0.875)	Loss 9.2326e-02 (8.0438e-02) 
2023-05-26 00:24:49.249469: Train Epoch done in 235.35254615500162 s 
2023-05-26 00:24:51.598439: val Epoch: [54][ 0/72]	Time  1.616 ( 1.616)	Data  1.407 ( 1.407)	Loss 4.3369e-02 (4.3369e-02) 
2023-05-26 00:24:51.724743: val Epoch: [54][ 1/72]	Time  0.127 ( 0.871)	Data  0.002 ( 0.704)	Loss 5.6207e-02 (4.9788e-02) 
2023-05-26 00:24:52.765197: val Epoch: [54][ 2/72]	Time  1.040 ( 0.928)	Data  0.916 ( 0.775)	Loss 8.9365e-02 (6.2981e-02) 
2023-05-26 00:24:52.890765: val Epoch: [54][ 3/72]	Time  0.126 ( 0.727)	Data  0.001 ( 0.581)	Loss 5.5650e-02 (6.1148e-02) 
2023-05-26 00:24:54.050975: val Epoch: [54][ 4/72]	Time  1.160 ( 0.814)	Data  1.035 ( 0.672)	Loss 8.8642e-02 (6.6647e-02) 
2023-05-26 00:24:54.175810: val Epoch: [54][ 5/72]	Time  0.125 ( 0.699)	Data  0.001 ( 0.560)	Loss 6.9557e-01 (1.7147e-01) 
2023-05-26 00:24:55.327125: val Epoch: [54][ 6/72]	Time  1.151 ( 0.764)	Data  1.026 ( 0.627)	Loss 4.6158e-02 (1.5357e-01) 
2023-05-26 00:24:55.451925: val Epoch: [54][ 7/72]	Time  0.125 ( 0.684)	Data  0.001 ( 0.548)	Loss 4.1547e-02 (1.3956e-01) 
2023-05-26 00:24:56.592382: val Epoch: [54][ 8/72]	Time  1.140 ( 0.734)	Data  1.015 ( 0.600)	Loss 2.3864e-01 (1.5057e-01) 
2023-05-26 00:24:56.717070: val Epoch: [54][ 9/72]	Time  0.125 ( 0.673)	Data  0.001 ( 0.540)	Loss 9.9259e-02 (1.4544e-01) 
2023-05-26 00:24:57.945043: val Epoch: [54][10/72]	Time  1.228 ( 0.724)	Data  1.103 ( 0.591)	Loss 8.9821e-02 (1.4038e-01) 
2023-05-26 00:24:58.069824: val Epoch: [54][11/72]	Time  0.125 ( 0.674)	Data  0.001 ( 0.542)	Loss 1.8520e-01 (1.4412e-01) 
2023-05-26 00:24:59.163495: val Epoch: [54][12/72]	Time  1.094 ( 0.706)	Data  0.966 ( 0.575)	Loss 1.4310e-01 (1.4404e-01) 
2023-05-26 00:24:59.283340: val Epoch: [54][13/72]	Time  0.120 ( 0.664)	Data  0.001 ( 0.534)	Loss 1.5007e-01 (1.4447e-01) 
2023-05-26 00:25:00.486062: val Epoch: [54][14/72]	Time  1.203 ( 0.700)	Data  1.083 ( 0.570)	Loss 5.6542e-02 (1.3861e-01) 
2023-05-26 00:25:00.605939: val Epoch: [54][15/72]	Time  0.120 ( 0.664)	Data  0.000 ( 0.535)	Loss 2.3697e-01 (1.4476e-01) 
2023-05-26 00:25:01.777008: val Epoch: [54][16/72]	Time  1.171 ( 0.694)	Data  1.050 ( 0.565)	Loss 5.8661e-02 (1.3969e-01) 
2023-05-26 00:25:01.897419: val Epoch: [54][17/72]	Time  0.120 ( 0.662)	Data  0.000 ( 0.534)	Loss 6.5269e-02 (1.3556e-01) 
2023-05-26 00:25:03.071252: val Epoch: [54][18/72]	Time  1.174 ( 0.689)	Data  1.053 ( 0.561)	Loss 1.3301e-01 (1.3542e-01) 
2023-05-26 00:25:03.191075: val Epoch: [54][19/72]	Time  0.120 ( 0.660)	Data  0.001 ( 0.533)	Loss 1.4622e-01 (1.3596e-01) 
2023-05-26 00:25:04.283854: val Epoch: [54][20/72]	Time  1.093 ( 0.681)	Data  0.973 ( 0.554)	Loss 5.4291e-02 (1.3207e-01) 
2023-05-26 00:25:04.403347: val Epoch: [54][21/72]	Time  0.119 ( 0.655)	Data  0.001 ( 0.529)	Loss 9.3349e-02 (1.3031e-01) 
2023-05-26 00:25:05.509879: val Epoch: [54][22/72]	Time  1.107 ( 0.675)	Data  0.987 ( 0.549)	Loss 4.5093e-02 (1.2661e-01) 
2023-05-26 00:25:05.629147: val Epoch: [54][23/72]	Time  0.119 ( 0.652)	Data  0.001 ( 0.526)	Loss 4.6670e-02 (1.2328e-01) 
2023-05-26 00:25:06.757798: val Epoch: [54][24/72]	Time  1.129 ( 0.671)	Data  1.009 ( 0.545)	Loss 5.7206e-02 (1.2064e-01) 
2023-05-26 00:25:06.877263: val Epoch: [54][25/72]	Time  0.119 ( 0.650)	Data  0.000 ( 0.524)	Loss 3.4202e-01 (1.2915e-01) 
2023-05-26 00:25:07.992026: val Epoch: [54][26/72]	Time  1.115 ( 0.667)	Data  0.994 ( 0.542)	Loss 1.1987e-01 (1.2881e-01) 
2023-05-26 00:25:08.112417: val Epoch: [54][27/72]	Time  0.120 ( 0.647)	Data  0.001 ( 0.522)	Loss 6.0866e-02 (1.2638e-01) 
2023-05-26 00:25:09.176272: val Epoch: [54][28/72]	Time  1.064 ( 0.662)	Data  0.944 ( 0.537)	Loss 7.4367e-02 (1.2459e-01) 
2023-05-26 00:25:09.327113: val Epoch: [54][29/72]	Time  0.151 ( 0.645)	Data  0.031 ( 0.520)	Loss 1.5397e-01 (1.2557e-01) 
2023-05-26 00:25:10.455719: val Epoch: [54][30/72]	Time  1.129 ( 0.660)	Data  1.004 ( 0.536)	Loss 1.0640e-01 (1.2495e-01) 
2023-05-26 00:25:10.575286: val Epoch: [54][31/72]	Time  0.120 ( 0.644)	Data  0.001 ( 0.519)	Loss 4.2849e-02 (1.2238e-01) 
2023-05-26 00:25:11.656539: val Epoch: [54][32/72]	Time  1.081 ( 0.657)	Data  0.961 ( 0.532)	Loss 4.6830e-02 (1.2009e-01) 
2023-05-26 00:25:11.792813: val Epoch: [54][33/72]	Time  0.136 ( 0.641)	Data  0.017 ( 0.517)	Loss 3.8506e-01 (1.2789e-01) 
2023-05-26 00:25:12.947653: val Epoch: [54][34/72]	Time  1.155 ( 0.656)	Data  1.023 ( 0.532)	Loss 5.4592e-02 (1.2579e-01) 
2023-05-26 00:25:13.072529: val Epoch: [54][35/72]	Time  0.125 ( 0.641)	Data  0.001 ( 0.517)	Loss 2.0287e-01 (1.2793e-01) 
2023-05-26 00:25:14.148336: val Epoch: [54][36/72]	Time  1.076 ( 0.653)	Data  0.950 ( 0.529)	Loss 1.2293e-01 (1.2780e-01) 
2023-05-26 00:25:14.317244: val Epoch: [54][37/72]	Time  0.169 ( 0.640)	Data  0.044 ( 0.516)	Loss 3.0472e-01 (1.3245e-01) 
2023-05-26 00:25:15.370391: val Epoch: [54][38/72]	Time  1.053 ( 0.651)	Data  0.928 ( 0.526)	Loss 3.0168e-01 (1.3679e-01) 
2023-05-26 00:25:15.527481: val Epoch: [54][39/72]	Time  0.157 ( 0.639)	Data  0.032 ( 0.514)	Loss 3.7461e-02 (1.3431e-01) 
2023-05-26 00:25:16.604123: val Epoch: [54][40/72]	Time  1.077 ( 0.649)	Data  0.951 ( 0.525)	Loss 9.9471e-02 (1.3346e-01) 
2023-05-26 00:25:16.766506: val Epoch: [54][41/72]	Time  0.162 ( 0.638)	Data  0.037 ( 0.513)	Loss 3.4125e-01 (1.3841e-01) 
2023-05-26 00:25:17.824088: val Epoch: [54][42/72]	Time  1.058 ( 0.647)	Data  0.932 ( 0.523)	Loss 2.9861e-01 (1.4213e-01) 
2023-05-26 00:25:17.995295: val Epoch: [54][43/72]	Time  0.171 ( 0.637)	Data  0.046 ( 0.512)	Loss 3.8694e-02 (1.3978e-01) 
2023-05-26 00:25:19.026162: val Epoch: [54][44/72]	Time  1.031 ( 0.645)	Data  0.905 ( 0.521)	Loss 1.4582e-01 (1.3992e-01) 
2023-05-26 00:25:19.207406: val Epoch: [54][45/72]	Time  0.181 ( 0.635)	Data  0.056 ( 0.511)	Loss 1.7337e-01 (1.4064e-01) 
2023-05-26 00:25:20.259636: val Epoch: [54][46/72]	Time  1.052 ( 0.644)	Data  0.926 ( 0.519)	Loss 6.1164e-02 (1.3895e-01) 
2023-05-26 00:25:20.439095: val Epoch: [54][47/72]	Time  0.179 ( 0.635)	Data  0.055 ( 0.510)	Loss 5.3172e-02 (1.3717e-01) 
2023-05-26 00:25:21.516244: val Epoch: [54][48/72]	Time  1.077 ( 0.644)	Data  0.951 ( 0.519)	Loss 8.5157e-02 (1.3610e-01) 
2023-05-26 00:25:21.693650: val Epoch: [54][49/72]	Time  0.177 ( 0.634)	Data  0.053 ( 0.509)	Loss 2.1023e-01 (1.3759e-01) 
2023-05-26 00:25:22.735996: val Epoch: [54][50/72]	Time  1.042 ( 0.642)	Data  0.916 ( 0.517)	Loss 2.6622e-01 (1.4011e-01) 
2023-05-26 00:25:22.920363: val Epoch: [54][51/72]	Time  0.184 ( 0.633)	Data  0.060 ( 0.509)	Loss 1.7616e-01 (1.4080e-01) 
2023-05-26 00:25:23.954070: val Epoch: [54][52/72]	Time  1.034 ( 0.641)	Data  0.908 ( 0.516)	Loss 9.1987e-02 (1.3988e-01) 
2023-05-26 00:25:24.166829: val Epoch: [54][53/72]	Time  0.213 ( 0.633)	Data  0.087 ( 0.508)	Loss 5.6302e-02 (1.3833e-01) 
2023-05-26 00:25:25.206299: val Epoch: [54][54/72]	Time  1.039 ( 0.640)	Data  0.915 ( 0.516)	Loss 2.8288e-01 (1.4096e-01) 
2023-05-26 00:25:25.360949: val Epoch: [54][55/72]	Time  0.155 ( 0.632)	Data  0.030 ( 0.507)	Loss 1.7166e-01 (1.4151e-01) 
2023-05-26 00:25:26.490844: val Epoch: [54][56/72]	Time  1.130 ( 0.640)	Data  0.999 ( 0.516)	Loss 8.1846e-02 (1.4046e-01) 
2023-05-26 00:25:26.615902: val Epoch: [54][57/72]	Time  0.125 ( 0.632)	Data  0.001 ( 0.507)	Loss 9.0599e-02 (1.3960e-01) 
2023-05-26 00:25:27.712463: val Epoch: [54][58/72]	Time  1.097 ( 0.639)	Data  0.965 ( 0.514)	Loss 5.6729e-02 (1.3820e-01) 
2023-05-26 00:25:27.837444: val Epoch: [54][59/72]	Time  0.125 ( 0.631)	Data  0.001 ( 0.506)	Loss 1.1114e-01 (1.3775e-01) 
2023-05-26 00:25:28.879477: val Epoch: [54][60/72]	Time  1.042 ( 0.638)	Data  0.917 ( 0.513)	Loss 5.0410e-02 (1.3632e-01) 
2023-05-26 00:25:29.080956: val Epoch: [54][61/72]	Time  0.201 ( 0.631)	Data  0.077 ( 0.506)	Loss 6.4958e-02 (1.3516e-01) 
2023-05-26 00:25:30.076959: val Epoch: [54][62/72]	Time  0.996 ( 0.636)	Data  0.870 ( 0.511)	Loss 4.4058e-02 (1.3372e-01) 
2023-05-26 00:25:30.346229: val Epoch: [54][63/72]	Time  0.269 ( 0.631)	Data  0.145 ( 0.506)	Loss 1.0682e-01 (1.3330e-01) 
2023-05-26 00:25:31.333687: val Epoch: [54][64/72]	Time  0.987 ( 0.636)	Data  0.861 ( 0.511)	Loss 2.8860e-01 (1.3569e-01) 
2023-05-26 00:25:31.569012: val Epoch: [54][65/72]	Time  0.235 ( 0.630)	Data  0.110 ( 0.505)	Loss 3.7457e-02 (1.3420e-01) 
2023-05-26 00:25:32.514750: val Epoch: [54][66/72]	Time  0.946 ( 0.635)	Data  0.819 ( 0.510)	Loss 5.9786e-02 (1.3309e-01) 
2023-05-26 00:25:32.791327: val Epoch: [54][67/72]	Time  0.277 ( 0.630)	Data  0.153 ( 0.504)	Loss 4.1731e-01 (1.3727e-01) 
2023-05-26 00:25:33.756399: val Epoch: [54][68/72]	Time  0.965 ( 0.634)	Data  0.839 ( 0.509)	Loss 9.0429e-02 (1.3659e-01) 
2023-05-26 00:25:34.001330: val Epoch: [54][69/72]	Time  0.245 ( 0.629)	Data  0.121 ( 0.504)	Loss 2.0972e-01 (1.3763e-01) 
2023-05-26 00:25:34.955883: val Epoch: [54][70/72]	Time  0.955 ( 0.633)	Data  0.828 ( 0.508)	Loss 3.0379e-02 (1.3612e-01) 
2023-05-26 00:25:35.110570: val Epoch: [54][71/72]	Time  0.155 ( 0.627)	Data  0.031 ( 0.502)	Loss 8.4641e-02 (1.3541e-01) 
2023-05-26 00:25:35.295994: Epoch 54 :Val : ['ET : 0.7215678095817566', 'TC : 0.7798609137535095', 'WT : 0.8678959608078003'] 
2023-05-26 00:25:35.300371: Epoch 54 :Val : ['ET : 0.7215678095817566', 'TC : 0.7798609137535095', 'WT : 0.8678959608078003'] 
2023-05-26 00:25:35.302314: Val epoch done in 46.05285261999961 s 
2023-05-26 00:25:35.307702: Batches per epoch:  129 
2023-05-26 00:25:39.988907: train Epoch: [55][  0/129]	Time  4.681 ( 4.681)	Data  3.665 ( 3.665)	Loss 8.3529e-02 (8.3529e-02) 
2023-05-26 00:25:40.950813: train Epoch: [55][  1/129]	Time  0.962 ( 2.821)	Data  0.001 ( 1.833)	Loss 7.5010e-02 (7.9269e-02) 
2023-05-26 00:25:43.460223: train Epoch: [55][  2/129]	Time  2.509 ( 2.717)	Data  1.552 ( 1.739)	Loss 4.4153e-02 (6.7564e-02) 
2023-05-26 00:25:44.409410: train Epoch: [55][  3/129]	Time  0.949 ( 2.275)	Data  0.001 ( 1.305)	Loss 1.4509e-01 (8.6946e-02) 
2023-05-26 00:25:47.099388: train Epoch: [55][  4/129]	Time  2.690 ( 2.358)	Data  1.742 ( 1.392)	Loss 6.6453e-02 (8.2847e-02) 
2023-05-26 00:25:48.060742: train Epoch: [55][  5/129]	Time  0.961 ( 2.125)	Data  0.001 ( 1.160)	Loss 8.5817e-02 (8.3342e-02) 
2023-05-26 00:25:50.645415: train Epoch: [55][  6/129]	Time  2.585 ( 2.191)	Data  1.627 ( 1.227)	Loss 7.1145e-02 (8.1600e-02) 
2023-05-26 00:25:51.606602: train Epoch: [55][  7/129]	Time  0.961 ( 2.037)	Data  0.001 ( 1.074)	Loss 5.5029e-02 (7.8279e-02) 
2023-05-26 00:25:54.291730: train Epoch: [55][  8/129]	Time  2.685 ( 2.109)	Data  1.728 ( 1.146)	Loss 8.2471e-02 (7.8744e-02) 
2023-05-26 00:25:55.251499: train Epoch: [55][  9/129]	Time  0.960 ( 1.994)	Data  0.001 ( 1.032)	Loss 9.5696e-02 (8.0440e-02) 
2023-05-26 00:25:57.957243: train Epoch: [55][ 10/129]	Time  2.706 ( 2.059)	Data  1.748 ( 1.097)	Loss 5.5805e-02 (7.8200e-02) 
2023-05-26 00:25:58.920422: train Epoch: [55][ 11/129]	Time  0.963 ( 1.968)	Data  0.001 ( 1.006)	Loss 8.8592e-02 (7.9066e-02) 
2023-05-26 00:26:01.526318: train Epoch: [55][ 12/129]	Time  2.606 ( 2.017)	Data  1.649 ( 1.055)	Loss 6.2012e-02 (7.7754e-02) 
2023-05-26 00:26:02.476594: train Epoch: [55][ 13/129]	Time  0.950 ( 1.941)	Data  0.001 ( 0.980)	Loss 1.1573e-01 (8.0467e-02) 
2023-05-26 00:26:05.212167: train Epoch: [55][ 14/129]	Time  2.736 ( 1.994)	Data  1.786 ( 1.034)	Loss 6.7613e-02 (7.9610e-02) 
2023-05-26 00:26:06.163897: train Epoch: [55][ 15/129]	Time  0.952 ( 1.928)	Data  0.001 ( 0.969)	Loss 6.5406e-02 (7.8722e-02) 
2023-05-26 00:26:08.835096: train Epoch: [55][ 16/129]	Time  2.671 ( 1.972)	Data  1.722 ( 1.013)	Loss 8.4050e-02 (7.9036e-02) 
2023-05-26 00:26:09.785636: train Epoch: [55][ 17/129]	Time  0.951 ( 1.915)	Data  0.001 ( 0.957)	Loss 7.4344e-02 (7.8775e-02) 
2023-05-26 00:26:12.431787: train Epoch: [55][ 18/129]	Time  2.646 ( 1.954)	Data  1.696 ( 0.996)	Loss 6.9687e-02 (7.8297e-02) 
2023-05-26 00:26:13.381214: train Epoch: [55][ 19/129]	Time  0.949 ( 1.904)	Data  0.001 ( 0.946)	Loss 1.4639e-01 (8.1701e-02) 
2023-05-26 00:26:16.114260: train Epoch: [55][ 20/129]	Time  2.733 ( 1.943)	Data  1.785 ( 0.986)	Loss 6.1650e-02 (8.0747e-02) 
2023-05-26 00:26:17.064002: train Epoch: [55][ 21/129]	Time  0.950 ( 1.898)	Data  0.001 ( 0.941)	Loss 7.1213e-02 (8.0313e-02) 
2023-05-26 00:26:19.694187: train Epoch: [55][ 22/129]	Time  2.630 ( 1.930)	Data  1.682 ( 0.974)	Loss 7.2216e-02 (7.9961e-02) 
2023-05-26 00:26:20.643838: train Epoch: [55][ 23/129]	Time  0.950 ( 1.889)	Data  0.001 ( 0.933)	Loss 1.0738e-01 (8.1103e-02) 
2023-05-26 00:26:23.290601: train Epoch: [55][ 24/129]	Time  2.647 ( 1.919)	Data  1.698 ( 0.964)	Loss 7.0876e-02 (8.0694e-02) 
2023-05-26 00:26:24.241175: train Epoch: [55][ 25/129]	Time  0.951 ( 1.882)	Data  0.001 ( 0.927)	Loss 5.1180e-02 (7.9559e-02) 
2023-05-26 00:26:26.897546: train Epoch: [55][ 26/129]	Time  2.656 ( 1.911)	Data  1.707 ( 0.955)	Loss 8.5170e-02 (7.9767e-02) 
2023-05-26 00:26:27.848001: train Epoch: [55][ 27/129]	Time  0.950 ( 1.876)	Data  0.001 ( 0.921)	Loss 1.5658e-01 (8.2510e-02) 
2023-05-26 00:26:30.572396: train Epoch: [55][ 28/129]	Time  2.724 ( 1.906)	Data  1.774 ( 0.951)	Loss 1.1470e-01 (8.3620e-02) 
2023-05-26 00:26:31.523927: train Epoch: [55][ 29/129]	Time  0.952 ( 1.874)	Data  0.001 ( 0.919)	Loss 1.1307e-01 (8.4602e-02) 
2023-05-26 00:26:34.177660: train Epoch: [55][ 30/129]	Time  2.654 ( 1.899)	Data  1.698 ( 0.944)	Loss 1.0381e-01 (8.5222e-02) 
2023-05-26 00:26:35.128093: train Epoch: [55][ 31/129]	Time  0.950 ( 1.869)	Data  0.001 ( 0.915)	Loss 5.3092e-02 (8.4218e-02) 
2023-05-26 00:26:37.769396: train Epoch: [55][ 32/129]	Time  2.641 ( 1.893)	Data  1.693 ( 0.938)	Loss 1.1366e-01 (8.5110e-02) 
2023-05-26 00:26:38.720227: train Epoch: [55][ 33/129]	Time  0.951 ( 1.865)	Data  0.001 ( 0.911)	Loss 7.6277e-02 (8.4850e-02) 
2023-05-26 00:26:41.487247: train Epoch: [55][ 34/129]	Time  2.767 ( 1.891)	Data  1.812 ( 0.937)	Loss 1.0460e-01 (8.5414e-02) 
2023-05-26 00:26:42.443485: train Epoch: [55][ 35/129]	Time  0.956 ( 1.865)	Data  0.001 ( 0.911)	Loss 1.4833e-01 (8.7162e-02) 
2023-05-26 00:26:45.137933: train Epoch: [55][ 36/129]	Time  2.694 ( 1.887)	Data  1.746 ( 0.933)	Loss 8.9861e-02 (8.7235e-02) 
2023-05-26 00:26:46.089541: train Epoch: [55][ 37/129]	Time  0.952 ( 1.863)	Data  0.001 ( 0.909)	Loss 7.0207e-02 (8.6787e-02) 
2023-05-26 00:26:48.701083: train Epoch: [55][ 38/129]	Time  2.612 ( 1.882)	Data  1.661 ( 0.928)	Loss 7.9972e-02 (8.6612e-02) 
2023-05-26 00:26:49.650844: train Epoch: [55][ 39/129]	Time  0.950 ( 1.859)	Data  0.001 ( 0.905)	Loss 1.7337e-01 (8.8781e-02) 
2023-05-26 00:26:52.328830: train Epoch: [55][ 40/129]	Time  2.678 ( 1.879)	Data  1.730 ( 0.925)	Loss 1.3727e-01 (8.9964e-02) 
2023-05-26 00:26:53.279104: train Epoch: [55][ 41/129]	Time  0.950 ( 1.856)	Data  0.001 ( 0.903)	Loss 6.8746e-02 (8.9458e-02) 
2023-05-26 00:26:56.023098: train Epoch: [55][ 42/129]	Time  2.744 ( 1.877)	Data  1.786 ( 0.923)	Loss 8.5325e-02 (8.9362e-02) 
2023-05-26 00:26:56.985047: train Epoch: [55][ 43/129]	Time  0.962 ( 1.856)	Data  0.001 ( 0.902)	Loss 6.9508e-02 (8.8911e-02) 
2023-05-26 00:26:59.651602: train Epoch: [55][ 44/129]	Time  2.667 ( 1.874)	Data  1.697 ( 0.920)	Loss 1.3092e-01 (8.9845e-02) 
2023-05-26 00:27:00.601211: train Epoch: [55][ 45/129]	Time  0.950 ( 1.854)	Data  0.001 ( 0.900)	Loss 1.1209e-01 (9.0328e-02) 
2023-05-26 00:27:03.168816: train Epoch: [55][ 46/129]	Time  2.568 ( 1.869)	Data  1.608 ( 0.915)	Loss 6.2412e-02 (8.9734e-02) 
2023-05-26 00:27:04.119368: train Epoch: [55][ 47/129]	Time  0.951 ( 1.850)	Data  0.001 ( 0.896)	Loss 1.6726e-01 (9.1350e-02) 
2023-05-26 00:27:06.766238: train Epoch: [55][ 48/129]	Time  2.647 ( 1.866)	Data  1.692 ( 0.912)	Loss 8.7832e-02 (9.1278e-02) 
2023-05-26 00:27:07.715801: train Epoch: [55][ 49/129]	Time  0.950 ( 1.848)	Data  0.001 ( 0.894)	Loss 8.9677e-02 (9.1246e-02) 
2023-05-26 00:27:10.392844: train Epoch: [55][ 50/129]	Time  2.677 ( 1.864)	Data  1.721 ( 0.910)	Loss 8.8945e-02 (9.1201e-02) 
2023-05-26 00:27:11.342661: train Epoch: [55][ 51/129]	Time  0.950 ( 1.847)	Data  0.001 ( 0.893)	Loss 1.1700e-01 (9.1697e-02) 
2023-05-26 00:27:13.947029: train Epoch: [55][ 52/129]	Time  2.604 ( 1.861)	Data  1.647 ( 0.907)	Loss 4.2769e-02 (9.0774e-02) 
2023-05-26 00:27:14.906589: train Epoch: [55][ 53/129]	Time  0.960 ( 1.844)	Data  0.001 ( 0.890)	Loss 5.7065e-02 (9.0149e-02) 
2023-05-26 00:27:17.472758: train Epoch: [55][ 54/129]	Time  2.566 ( 1.858)	Data  1.619 ( 0.904)	Loss 7.3535e-02 (8.9847e-02) 
2023-05-26 00:27:18.423279: train Epoch: [55][ 55/129]	Time  0.951 ( 1.841)	Data  0.001 ( 0.887)	Loss 9.3970e-02 (8.9921e-02) 
2023-05-26 00:27:21.035504: train Epoch: [55][ 56/129]	Time  2.612 ( 1.855)	Data  1.662 ( 0.901)	Loss 7.0206e-02 (8.9575e-02) 
2023-05-26 00:27:21.983723: train Epoch: [55][ 57/129]	Time  0.948 ( 1.839)	Data  0.001 ( 0.885)	Loss 6.5898e-02 (8.9167e-02) 
2023-05-26 00:27:24.636359: train Epoch: [55][ 58/129]	Time  2.653 ( 1.853)	Data  1.705 ( 0.899)	Loss 7.0911e-02 (8.8857e-02) 
2023-05-26 00:27:25.586989: train Epoch: [55][ 59/129]	Time  0.951 ( 1.838)	Data  0.001 ( 0.884)	Loss 7.7508e-02 (8.8668e-02) 
2023-05-26 00:27:28.273669: train Epoch: [55][ 60/129]	Time  2.687 ( 1.852)	Data  1.736 ( 0.898)	Loss 4.3771e-02 (8.7932e-02) 
2023-05-26 00:27:29.224931: train Epoch: [55][ 61/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.884)	Loss 1.1158e-01 (8.8314e-02) 
2023-05-26 00:27:31.921833: train Epoch: [55][ 62/129]	Time  2.697 ( 1.851)	Data  1.747 ( 0.898)	Loss 6.7863e-02 (8.7989e-02) 
2023-05-26 00:27:32.873195: train Epoch: [55][ 63/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.884)	Loss 8.7169e-02 (8.7976e-02) 
2023-05-26 00:27:35.525341: train Epoch: [55][ 64/129]	Time  2.652 ( 1.849)	Data  1.702 ( 0.896)	Loss 8.9318e-02 (8.7997e-02) 
2023-05-26 00:27:36.476511: train Epoch: [55][ 65/129]	Time  0.951 ( 1.836)	Data  0.001 ( 0.883)	Loss 4.7514e-02 (8.7384e-02) 
2023-05-26 00:27:39.252095: train Epoch: [55][ 66/129]	Time  2.776 ( 1.850)	Data  1.817 ( 0.897)	Loss 3.9985e-02 (8.6676e-02) 
2023-05-26 00:27:40.203098: train Epoch: [55][ 67/129]	Time  0.951 ( 1.837)	Data  0.001 ( 0.883)	Loss 7.7150e-02 (8.6536e-02) 
2023-05-26 00:27:42.840381: train Epoch: [55][ 68/129]	Time  2.637 ( 1.848)	Data  1.675 ( 0.895)	Loss 6.0828e-02 (8.6163e-02) 
2023-05-26 00:27:43.789064: train Epoch: [55][ 69/129]	Time  0.949 ( 1.835)	Data  0.001 ( 0.882)	Loss 6.4678e-02 (8.5857e-02) 
2023-05-26 00:27:46.470911: train Epoch: [55][ 70/129]	Time  2.682 ( 1.847)	Data  1.723 ( 0.894)	Loss 1.0392e-01 (8.6111e-02) 
2023-05-26 00:27:47.421852: train Epoch: [55][ 71/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.881)	Loss 9.3920e-02 (8.6219e-02) 
2023-05-26 00:27:50.157287: train Epoch: [55][ 72/129]	Time  2.735 ( 1.847)	Data  1.787 ( 0.894)	Loss 9.3143e-02 (8.6314e-02) 
2023-05-26 00:27:51.108219: train Epoch: [55][ 73/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.882)	Loss 4.7817e-02 (8.5794e-02) 
2023-05-26 00:27:53.751412: train Epoch: [55][ 74/129]	Time  2.643 ( 1.846)	Data  1.695 ( 0.893)	Loss 5.9102e-02 (8.5438e-02) 
2023-05-26 00:27:54.704271: train Epoch: [55][ 75/129]	Time  0.953 ( 1.834)	Data  0.001 ( 0.881)	Loss 8.6631e-02 (8.5454e-02) 
2023-05-26 00:27:57.303774: train Epoch: [55][ 76/129]	Time  2.599 ( 1.844)	Data  1.639 ( 0.891)	Loss 5.4062e-02 (8.5046e-02) 
2023-05-26 00:27:58.265545: train Epoch: [55][ 77/129]	Time  0.962 ( 1.833)	Data  0.001 ( 0.879)	Loss 7.4535e-02 (8.4911e-02) 
2023-05-26 00:28:00.864414: train Epoch: [55][ 78/129]	Time  2.599 ( 1.842)	Data  1.641 ( 0.889)	Loss 7.1525e-02 (8.4742e-02) 
2023-05-26 00:28:01.826854: train Epoch: [55][ 79/129]	Time  0.962 ( 1.831)	Data  0.001 ( 0.878)	Loss 1.1935e-01 (8.5175e-02) 
2023-05-26 00:28:04.481744: train Epoch: [55][ 80/129]	Time  2.655 ( 1.842)	Data  1.691 ( 0.888)	Loss 8.1546e-02 (8.5130e-02) 
2023-05-26 00:28:05.443810: train Epoch: [55][ 81/129]	Time  0.962 ( 1.831)	Data  0.001 ( 0.877)	Loss 5.2097e-02 (8.4727e-02) 
2023-05-26 00:28:08.095546: train Epoch: [55][ 82/129]	Time  2.652 ( 1.841)	Data  1.697 ( 0.887)	Loss 4.3699e-02 (8.4233e-02) 
2023-05-26 00:28:09.047368: train Epoch: [55][ 83/129]	Time  0.952 ( 1.830)	Data  0.001 ( 0.876)	Loss 5.4666e-02 (8.3881e-02) 
2023-05-26 00:28:11.607587: train Epoch: [55][ 84/129]	Time  2.560 ( 1.839)	Data  1.610 ( 0.885)	Loss 7.8065e-02 (8.3812e-02) 
2023-05-26 00:28:12.556609: train Epoch: [55][ 85/129]	Time  0.949 ( 1.828)	Data  0.001 ( 0.875)	Loss 8.5353e-02 (8.3830e-02) 
2023-05-26 00:28:15.220281: train Epoch: [55][ 86/129]	Time  2.664 ( 1.838)	Data  1.714 ( 0.884)	Loss 6.7906e-02 (8.3647e-02) 
2023-05-26 00:28:16.171413: train Epoch: [55][ 87/129]	Time  0.951 ( 1.828)	Data  0.001 ( 0.874)	Loss 9.1096e-02 (8.3732e-02) 
2023-05-26 00:28:18.932531: train Epoch: [55][ 88/129]	Time  2.761 ( 1.838)	Data  1.803 ( 0.885)	Loss 6.8726e-02 (8.3563e-02) 
2023-05-26 00:28:19.882676: train Epoch: [55][ 89/129]	Time  0.950 ( 1.829)	Data  0.001 ( 0.875)	Loss 1.5157e-01 (8.4319e-02) 
2023-05-26 00:28:22.503968: train Epoch: [55][ 90/129]	Time  2.621 ( 1.837)	Data  1.669 ( 0.884)	Loss 1.1814e-01 (8.4690e-02) 
2023-05-26 00:28:23.453770: train Epoch: [55][ 91/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.874)	Loss 7.6495e-02 (8.4601e-02) 
2023-05-26 00:28:26.067437: train Epoch: [55][ 92/129]	Time  2.614 ( 1.836)	Data  1.662 ( 0.883)	Loss 6.3989e-02 (8.4380e-02) 
2023-05-26 00:28:27.017837: train Epoch: [55][ 93/129]	Time  0.950 ( 1.827)	Data  0.001 ( 0.873)	Loss 1.2646e-01 (8.4827e-02) 
2023-05-26 00:28:29.658912: train Epoch: [55][ 94/129]	Time  2.641 ( 1.835)	Data  1.694 ( 0.882)	Loss 7.8858e-02 (8.4765e-02) 
2023-05-26 00:28:30.610181: train Epoch: [55][ 95/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.873)	Loss 5.7808e-02 (8.4484e-02) 
2023-05-26 00:28:33.333772: train Epoch: [55][ 96/129]	Time  2.724 ( 1.835)	Data  1.774 ( 0.882)	Loss 1.0367e-01 (8.4681e-02) 
2023-05-26 00:28:34.293553: train Epoch: [55][ 97/129]	Time  0.960 ( 1.826)	Data  0.001 ( 0.873)	Loss 7.3677e-02 (8.4569e-02) 
2023-05-26 00:28:36.940268: train Epoch: [55][ 98/129]	Time  2.647 ( 1.835)	Data  1.688 ( 0.881)	Loss 8.7363e-02 (8.4597e-02) 
2023-05-26 00:28:37.901386: train Epoch: [55][ 99/129]	Time  0.961 ( 1.826)	Data  0.001 ( 0.872)	Loss 8.0186e-02 (8.4553e-02) 
2023-05-26 00:28:40.581987: train Epoch: [55][100/129]	Time  2.681 ( 1.834)	Data  1.722 ( 0.881)	Loss 6.1464e-02 (8.4325e-02) 
2023-05-26 00:28:41.541361: train Epoch: [55][101/129]	Time  0.959 ( 1.826)	Data  0.001 ( 0.872)	Loss 7.3883e-02 (8.4222e-02) 
2023-05-26 00:28:44.239087: train Epoch: [55][102/129]	Time  2.698 ( 1.834)	Data  1.726 ( 0.881)	Loss 7.2099e-02 (8.4105e-02) 
2023-05-26 00:28:45.198326: train Epoch: [55][103/129]	Time  0.959 ( 1.826)	Data  0.001 ( 0.872)	Loss 5.6483e-02 (8.3839e-02) 
2023-05-26 00:28:47.895252: train Epoch: [55][104/129]	Time  2.697 ( 1.834)	Data  1.738 ( 0.880)	Loss 7.3854e-02 (8.3744e-02) 
2023-05-26 00:28:48.856103: train Epoch: [55][105/129]	Time  0.961 ( 1.826)	Data  0.001 ( 0.872)	Loss 6.4379e-02 (8.3561e-02) 
2023-05-26 00:28:51.609044: train Epoch: [55][106/129]	Time  2.753 ( 1.835)	Data  1.796 ( 0.881)	Loss 1.1127e-01 (8.3820e-02) 
2023-05-26 00:28:52.570233: train Epoch: [55][107/129]	Time  0.961 ( 1.826)	Data  0.001 ( 0.872)	Loss 7.6885e-02 (8.3756e-02) 
2023-05-26 00:28:55.210241: train Epoch: [55][108/129]	Time  2.640 ( 1.834)	Data  1.681 ( 0.880)	Loss 4.7104e-02 (8.3420e-02) 
2023-05-26 00:28:56.171422: train Epoch: [55][109/129]	Time  0.961 ( 1.826)	Data  0.001 ( 0.872)	Loss 6.6063e-02 (8.3262e-02) 
2023-05-26 00:28:58.823236: train Epoch: [55][110/129]	Time  2.652 ( 1.833)	Data  1.682 ( 0.879)	Loss 6.3423e-02 (8.3083e-02) 
2023-05-26 00:28:59.786428: train Epoch: [55][111/129]	Time  0.963 ( 1.826)	Data  0.001 ( 0.871)	Loss 8.1149e-02 (8.3066e-02) 
2023-05-26 00:29:02.415342: train Epoch: [55][112/129]	Time  2.629 ( 1.833)	Data  1.670 ( 0.878)	Loss 7.3929e-02 (8.2985e-02) 
2023-05-26 00:29:03.376590: train Epoch: [55][113/129]	Time  0.961 ( 1.825)	Data  0.001 ( 0.871)	Loss 6.6747e-02 (8.2843e-02) 
2023-05-26 00:29:06.003353: train Epoch: [55][114/129]	Time  2.627 ( 1.832)	Data  1.667 ( 0.878)	Loss 5.9661e-02 (8.2641e-02) 
2023-05-26 00:29:06.967831: train Epoch: [55][115/129]	Time  0.964 ( 1.825)	Data  0.001 ( 0.870)	Loss 8.0490e-02 (8.2623e-02) 
2023-05-26 00:29:09.631729: train Epoch: [55][116/129]	Time  2.664 ( 1.832)	Data  1.705 ( 0.877)	Loss 6.0855e-02 (8.2436e-02) 
2023-05-26 00:29:10.590177: train Epoch: [55][117/129]	Time  0.958 ( 1.824)	Data  0.001 ( 0.870)	Loss 1.4072e-01 (8.2930e-02) 
2023-05-26 00:29:13.287944: train Epoch: [55][118/129]	Time  2.698 ( 1.832)	Data  1.749 ( 0.877)	Loss 1.0683e-01 (8.3131e-02) 
2023-05-26 00:29:14.253505: train Epoch: [55][119/129]	Time  0.966 ( 1.825)	Data  0.001 ( 0.870)	Loss 8.0407e-02 (8.3108e-02) 
2023-05-26 00:29:17.024566: train Epoch: [55][120/129]	Time  2.771 ( 1.832)	Data  1.818 ( 0.878)	Loss 9.5306e-02 (8.3209e-02) 
2023-05-26 00:29:17.974061: train Epoch: [55][121/129]	Time  0.949 ( 1.825)	Data  0.001 ( 0.871)	Loss 9.0491e-02 (8.3269e-02) 
2023-05-26 00:29:20.657656: train Epoch: [55][122/129]	Time  2.684 ( 1.832)	Data  1.735 ( 0.878)	Loss 7.3012e-02 (8.3186e-02) 
2023-05-26 00:29:21.608427: train Epoch: [55][123/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.871)	Loss 9.0511e-02 (8.3245e-02) 
2023-05-26 00:29:24.314756: train Epoch: [55][124/129]	Time  2.706 ( 1.832)	Data  1.757 ( 0.878)	Loss 6.0478e-02 (8.3063e-02) 
2023-05-26 00:29:25.265799: train Epoch: [55][125/129]	Time  0.951 ( 1.825)	Data  0.001 ( 0.871)	Loss 6.7676e-02 (8.2940e-02) 
2023-05-26 00:29:27.978472: train Epoch: [55][126/129]	Time  2.713 ( 1.832)	Data  1.765 ( 0.878)	Loss 1.2415e-01 (8.3265e-02) 
2023-05-26 00:29:28.924160: train Epoch: [55][127/129]	Time  0.946 ( 1.825)	Data  0.001 ( 0.871)	Loss 1.7339e-01 (8.3969e-02) 
2023-05-26 00:29:30.445024: train Epoch: [55][128/129]	Time  1.521 ( 1.823)	Data  0.576 ( 0.869)	Loss 6.5797e-02 (8.3828e-02) 
2023-05-26 00:29:30.477232: Train Epoch done in 235.16956064699843 s 
2023-05-26 00:29:32.790643: val Epoch: [55][ 0/72]	Time  1.623 ( 1.623)	Data  1.424 ( 1.424)	Loss 7.1157e-02 (7.1157e-02) 
2023-05-26 00:29:32.910228: val Epoch: [55][ 1/72]	Time  0.120 ( 0.872)	Data  0.001 ( 0.713)	Loss 2.5078e-01 (1.6097e-01) 
2023-05-26 00:29:33.953283: val Epoch: [55][ 2/72]	Time  1.043 ( 0.929)	Data  0.922 ( 0.782)	Loss 3.3314e-01 (2.1836e-01) 
2023-05-26 00:29:34.077695: val Epoch: [55][ 3/72]	Time  0.124 ( 0.728)	Data  0.001 ( 0.587)	Loss 1.6964e-01 (2.0618e-01) 
2023-05-26 00:29:35.204693: val Epoch: [55][ 4/72]	Time  1.127 ( 0.808)	Data  1.002 ( 0.670)	Loss 1.0147e-01 (1.8524e-01) 
2023-05-26 00:29:35.329261: val Epoch: [55][ 5/72]	Time  0.125 ( 0.694)	Data  0.001 ( 0.558)	Loss 3.4161e-02 (1.6006e-01) 
2023-05-26 00:29:36.434098: val Epoch: [55][ 6/72]	Time  1.105 ( 0.752)	Data  0.980 ( 0.619)	Loss 4.8031e-02 (1.4406e-01) 
2023-05-26 00:29:36.559031: val Epoch: [55][ 7/72]	Time  0.125 ( 0.674)	Data  0.001 ( 0.541)	Loss 4.8243e-02 (1.3208e-01) 
2023-05-26 00:29:37.701738: val Epoch: [55][ 8/72]	Time  1.143 ( 0.726)	Data  1.017 ( 0.594)	Loss 2.2185e-01 (1.4205e-01) 
2023-05-26 00:29:37.821151: val Epoch: [55][ 9/72]	Time  0.119 ( 0.665)	Data  0.001 ( 0.535)	Loss 3.2594e-01 (1.6044e-01) 
2023-05-26 00:29:38.899857: val Epoch: [55][10/72]	Time  1.079 ( 0.703)	Data  0.953 ( 0.573)	Loss 4.7281e-02 (1.5015e-01) 
2023-05-26 00:29:39.019444: val Epoch: [55][11/72]	Time  0.120 ( 0.654)	Data  0.001 ( 0.525)	Loss 3.7922e-02 (1.4080e-01) 
2023-05-26 00:29:40.183069: val Epoch: [55][12/72]	Time  1.164 ( 0.694)	Data  1.036 ( 0.565)	Loss 4.0379e-01 (1.6103e-01) 
2023-05-26 00:29:40.303078: val Epoch: [55][13/72]	Time  0.120 ( 0.653)	Data  0.000 ( 0.524)	Loss 1.3486e-01 (1.5916e-01) 
2023-05-26 00:29:41.339689: val Epoch: [55][14/72]	Time  1.037 ( 0.678)	Data  0.916 ( 0.550)	Loss 5.0298e-02 (1.5191e-01) 
2023-05-26 00:29:41.500441: val Epoch: [55][15/72]	Time  0.161 ( 0.646)	Data  0.036 ( 0.518)	Loss 1.0845e-01 (1.4919e-01) 
2023-05-26 00:29:42.549304: val Epoch: [55][16/72]	Time  1.049 ( 0.670)	Data  0.922 ( 0.542)	Loss 6.8886e-02 (1.4447e-01) 
2023-05-26 00:29:42.766188: val Epoch: [55][17/72]	Time  0.217 ( 0.644)	Data  0.092 ( 0.517)	Loss 3.7759e-01 (1.5742e-01) 
2023-05-26 00:29:43.757402: val Epoch: [55][18/72]	Time  0.991 ( 0.663)	Data  0.865 ( 0.535)	Loss 1.6071e-01 (1.5759e-01) 
2023-05-26 00:29:43.974745: val Epoch: [55][19/72]	Time  0.217 ( 0.640)	Data  0.093 ( 0.513)	Loss 8.5633e-02 (1.5399e-01) 
2023-05-26 00:29:44.950016: val Epoch: [55][20/72]	Time  0.975 ( 0.656)	Data  0.849 ( 0.529)	Loss 5.3904e-02 (1.4923e-01) 
2023-05-26 00:29:45.201337: val Epoch: [55][21/72]	Time  0.251 ( 0.638)	Data  0.127 ( 0.511)	Loss 7.7314e-02 (1.4596e-01) 
2023-05-26 00:29:46.221738: val Epoch: [55][22/72]	Time  1.020 ( 0.655)	Data  0.894 ( 0.528)	Loss 8.0054e-02 (1.4309e-01) 
2023-05-26 00:29:46.447626: val Epoch: [55][23/72]	Time  0.226 ( 0.637)	Data  0.101 ( 0.510)	Loss 3.7605e-01 (1.5280e-01) 
2023-05-26 00:29:47.447214: val Epoch: [55][24/72]	Time  1.000 ( 0.651)	Data  0.873 ( 0.524)	Loss 9.6737e-02 (1.5056e-01) 
2023-05-26 00:29:47.708377: val Epoch: [55][25/72]	Time  0.261 ( 0.636)	Data  0.136 ( 0.509)	Loss 1.6289e-01 (1.5103e-01) 
2023-05-26 00:29:48.656941: val Epoch: [55][26/72]	Time  0.949 ( 0.648)	Data  0.822 ( 0.521)	Loss 5.6366e-02 (1.4752e-01) 
2023-05-26 00:29:48.929002: val Epoch: [55][27/72]	Time  0.272 ( 0.634)	Data  0.148 ( 0.508)	Loss 4.2508e-01 (1.5744e-01) 
2023-05-26 00:29:49.897262: val Epoch: [55][28/72]	Time  0.968 ( 0.646)	Data  0.841 ( 0.519)	Loss 1.3511e-01 (1.5667e-01) 
2023-05-26 00:29:50.172436: val Epoch: [55][29/72]	Time  0.275 ( 0.634)	Data  0.151 ( 0.507)	Loss 1.3199e-01 (1.5585e-01) 
2023-05-26 00:29:51.113109: val Epoch: [55][30/72]	Time  0.941 ( 0.643)	Data  0.814 ( 0.517)	Loss 4.8433e-02 (1.5238e-01) 
2023-05-26 00:29:51.429699: val Epoch: [55][31/72]	Time  0.317 ( 0.633)	Data  0.193 ( 0.507)	Loss 4.1606e-01 (1.6062e-01) 
2023-05-26 00:29:52.351219: val Epoch: [55][32/72]	Time  0.922 ( 0.642)	Data  0.794 ( 0.515)	Loss 1.7073e-01 (1.6093e-01) 
2023-05-26 00:29:52.693303: val Epoch: [55][33/72]	Time  0.342 ( 0.633)	Data  0.218 ( 0.507)	Loss 4.9953e-02 (1.5766e-01) 
2023-05-26 00:29:53.549401: val Epoch: [55][34/72]	Time  0.856 ( 0.639)	Data  0.730 ( 0.513)	Loss 4.9083e-02 (1.5456e-01) 
2023-05-26 00:29:53.902628: val Epoch: [55][35/72]	Time  0.353 ( 0.632)	Data  0.229 ( 0.505)	Loss 6.1413e-02 (1.5197e-01) 
2023-05-26 00:29:54.815129: val Epoch: [55][36/72]	Time  0.912 ( 0.639)	Data  0.786 ( 0.513)	Loss 4.6127e-02 (1.4911e-01) 
2023-05-26 00:29:55.148335: val Epoch: [55][37/72]	Time  0.333 ( 0.631)	Data  0.209 ( 0.505)	Loss 3.9653e-01 (1.5562e-01) 
2023-05-26 00:29:56.095411: val Epoch: [55][38/72]	Time  0.947 ( 0.639)	Data  0.821 ( 0.513)	Loss 1.0272e-01 (1.5427e-01) 
2023-05-26 00:29:56.359828: val Epoch: [55][39/72]	Time  0.264 ( 0.630)	Data  0.140 ( 0.504)	Loss 6.4330e-02 (1.5202e-01) 
2023-05-26 00:29:57.345391: val Epoch: [55][40/72]	Time  0.986 ( 0.638)	Data  0.860 ( 0.512)	Loss 6.3817e-02 (1.4987e-01) 
2023-05-26 00:29:57.575915: val Epoch: [55][41/72]	Time  0.231 ( 0.629)	Data  0.106 ( 0.503)	Loss 3.1199e-02 (1.4704e-01) 
2023-05-26 00:29:58.591998: val Epoch: [55][42/72]	Time  1.016 ( 0.638)	Data  0.890 ( 0.512)	Loss 2.1069e-01 (1.4852e-01) 
2023-05-26 00:29:58.782299: val Epoch: [55][43/72]	Time  0.190 ( 0.628)	Data  0.066 ( 0.501)	Loss 7.3212e-02 (1.4681e-01) 
2023-05-26 00:29:59.771109: val Epoch: [55][44/72]	Time  0.989 ( 0.636)	Data  0.862 ( 0.509)	Loss 5.6112e-02 (1.4479e-01) 
2023-05-26 00:30:00.050819: val Epoch: [55][45/72]	Time  0.280 ( 0.628)	Data  0.155 ( 0.502)	Loss 8.5751e-02 (1.4351e-01) 
2023-05-26 00:30:00.981941: val Epoch: [55][46/72]	Time  0.931 ( 0.634)	Data  0.804 ( 0.508)	Loss 4.6742e-02 (1.4145e-01) 
2023-05-26 00:30:01.260043: val Epoch: [55][47/72]	Time  0.278 ( 0.627)	Data  0.154 ( 0.501)	Loss 2.6608e-01 (1.4405e-01) 
2023-05-26 00:30:02.210791: val Epoch: [55][48/72]	Time  0.951 ( 0.634)	Data  0.824 ( 0.507)	Loss 1.1312e-01 (1.4342e-01) 
2023-05-26 00:30:02.483678: val Epoch: [55][49/72]	Time  0.273 ( 0.626)	Data  0.148 ( 0.500)	Loss 1.9277e-01 (1.4440e-01) 
2023-05-26 00:30:03.420563: val Epoch: [55][50/72]	Time  0.937 ( 0.632)	Data  0.810 ( 0.506)	Loss 8.9123e-02 (1.4332e-01) 
2023-05-26 00:30:03.680684: val Epoch: [55][51/72]	Time  0.260 ( 0.625)	Data  0.135 ( 0.499)	Loss 4.1890e-02 (1.4137e-01) 
2023-05-26 00:30:04.679138: val Epoch: [55][52/72]	Time  0.998 ( 0.632)	Data  0.873 ( 0.506)	Loss 9.1193e-02 (1.4042e-01) 
2023-05-26 00:30:04.862870: val Epoch: [55][53/72]	Time  0.184 ( 0.624)	Data  0.059 ( 0.498)	Loss 7.9095e-02 (1.3929e-01) 
2023-05-26 00:30:05.878794: val Epoch: [55][54/72]	Time  1.016 ( 0.631)	Data  0.890 ( 0.505)	Loss 1.5536e-01 (1.3958e-01) 
2023-05-26 00:30:06.110477: val Epoch: [55][55/72]	Time  0.232 ( 0.624)	Data  0.106 ( 0.498)	Loss 5.4414e-02 (1.3806e-01) 
2023-05-26 00:30:07.133035: val Epoch: [55][56/72]	Time  1.023 ( 0.631)	Data  0.898 ( 0.505)	Loss 6.5121e-02 (1.3678e-01) 
2023-05-26 00:30:07.292571: val Epoch: [55][57/72]	Time  0.160 ( 0.623)	Data  0.034 ( 0.497)	Loss 5.4990e-02 (1.3537e-01) 
2023-05-26 00:30:08.346264: val Epoch: [55][58/72]	Time  1.054 ( 0.630)	Data  0.928 ( 0.504)	Loss 7.9279e-02 (1.3442e-01) 
2023-05-26 00:30:08.527346: val Epoch: [55][59/72]	Time  0.181 ( 0.623)	Data  0.057 ( 0.497)	Loss 6.2079e-02 (1.3321e-01) 
2023-05-26 00:30:09.550265: val Epoch: [55][60/72]	Time  1.023 ( 0.629)	Data  0.897 ( 0.503)	Loss 5.4090e-02 (1.3192e-01) 
2023-05-26 00:30:09.753356: val Epoch: [55][61/72]	Time  0.203 ( 0.622)	Data  0.079 ( 0.496)	Loss 1.2710e-01 (1.3184e-01) 
2023-05-26 00:30:10.788594: val Epoch: [55][62/72]	Time  1.035 ( 0.629)	Data  0.910 ( 0.503)	Loss 1.8408e-01 (1.3267e-01) 
2023-05-26 00:30:10.950515: val Epoch: [55][63/72]	Time  0.162 ( 0.622)	Data  0.037 ( 0.496)	Loss 5.7472e-02 (1.3149e-01) 
2023-05-26 00:30:12.056953: val Epoch: [55][64/72]	Time  1.106 ( 0.629)	Data  0.981 ( 0.503)	Loss 1.0146e-01 (1.3103e-01) 
2023-05-26 00:30:12.213316: val Epoch: [55][65/72]	Time  0.156 ( 0.622)	Data  0.031 ( 0.496)	Loss 1.2153e-01 (1.3089e-01) 
2023-05-26 00:30:13.277179: val Epoch: [55][66/72]	Time  1.064 ( 0.629)	Data  0.938 ( 0.503)	Loss 4.4416e-02 (1.2960e-01) 
2023-05-26 00:30:13.444553: val Epoch: [55][67/72]	Time  0.167 ( 0.622)	Data  0.041 ( 0.496)	Loss 7.3097e-02 (1.2876e-01) 
2023-05-26 00:30:14.449833: val Epoch: [55][68/72]	Time  1.005 ( 0.627)	Data  0.880 ( 0.501)	Loss 4.7325e-02 (1.2758e-01) 
2023-05-26 00:30:14.629197: val Epoch: [55][69/72]	Time  0.179 ( 0.621)	Data  0.054 ( 0.495)	Loss 9.2997e-02 (1.2709e-01) 
2023-05-26 00:30:15.639041: val Epoch: [55][70/72]	Time  1.010 ( 0.626)	Data  0.880 ( 0.500)	Loss 1.1252e-01 (1.2689e-01) 
2023-05-26 00:30:15.774284: val Epoch: [55][71/72]	Time  0.135 ( 0.620)	Data  0.011 ( 0.494)	Loss 4.0017e-02 (1.2568e-01) 
2023-05-26 00:30:15.958685: Epoch 55 :Val : ['ET : 0.7230913043022156', 'TC : 0.7883528470993042', 'WT : 0.8684570789337158'] 
2023-05-26 00:30:15.961338: Epoch 55 :Val : ['ET : 0.7230913043022156', 'TC : 0.7883528470993042', 'WT : 0.8684570789337158'] 
2023-05-26 00:30:15.963232: Val epoch done in 45.486004697999306 s 
2023-05-26 00:30:15.968564: Batches per epoch:  129 
2023-05-26 00:30:20.789449: train Epoch: [56][  0/129]	Time  4.821 ( 4.821)	Data  3.828 ( 3.828)	Loss 6.7236e-02 (6.7236e-02) 
2023-05-26 00:30:21.741582: train Epoch: [56][  1/129]	Time  0.952 ( 2.886)	Data  0.001 ( 1.914)	Loss 7.3601e-02 (7.0418e-02) 
2023-05-26 00:30:24.582541: train Epoch: [56][  2/129]	Time  2.841 ( 2.871)	Data  1.894 ( 1.907)	Loss 7.5751e-02 (7.2196e-02) 
2023-05-26 00:30:25.532306: train Epoch: [56][  3/129]	Time  0.950 ( 2.391)	Data  0.001 ( 1.431)	Loss 5.2491e-02 (6.7270e-02) 
2023-05-26 00:30:28.187613: train Epoch: [56][  4/129]	Time  2.655 ( 2.444)	Data  1.703 ( 1.485)	Loss 1.1342e-01 (7.6500e-02) 
2023-05-26 00:30:29.136751: train Epoch: [56][  5/129]	Time  0.949 ( 2.195)	Data  0.001 ( 1.238)	Loss 5.5292e-02 (7.2965e-02) 
2023-05-26 00:30:31.787104: train Epoch: [56][  6/129]	Time  2.650 ( 2.260)	Data  1.704 ( 1.304)	Loss 6.5601e-02 (7.1913e-02) 
2023-05-26 00:30:32.735887: train Epoch: [56][  7/129]	Time  0.949 ( 2.096)	Data  0.001 ( 1.142)	Loss 6.7990e-02 (7.1423e-02) 
2023-05-26 00:30:35.401302: train Epoch: [56][  8/129]	Time  2.665 ( 2.159)	Data  1.718 ( 1.206)	Loss 7.7651e-02 (7.2115e-02) 
2023-05-26 00:30:36.352502: train Epoch: [56][  9/129]	Time  0.951 ( 2.038)	Data  0.001 ( 1.085)	Loss 1.0234e-01 (7.5137e-02) 
2023-05-26 00:30:39.061632: train Epoch: [56][ 10/129]	Time  2.709 ( 2.099)	Data  1.762 ( 1.147)	Loss 1.1217e-01 (7.8504e-02) 
2023-05-26 00:30:40.011066: train Epoch: [56][ 11/129]	Time  0.949 ( 2.004)	Data  0.001 ( 1.051)	Loss 5.2400e-02 (7.6329e-02) 
2023-05-26 00:30:42.724369: train Epoch: [56][ 12/129]	Time  2.713 ( 2.058)	Data  1.768 ( 1.106)	Loss 1.5088e-01 (8.2064e-02) 
2023-05-26 00:30:43.672957: train Epoch: [56][ 13/129]	Time  0.949 ( 1.979)	Data  0.001 ( 1.027)	Loss 8.3265e-02 (8.2150e-02) 
2023-05-26 00:30:46.284788: train Epoch: [56][ 14/129]	Time  2.612 ( 2.021)	Data  1.665 ( 1.070)	Loss 7.4197e-02 (8.1619e-02) 
2023-05-26 00:30:47.233213: train Epoch: [56][ 15/129]	Time  0.948 ( 1.954)	Data  0.001 ( 1.003)	Loss 7.5046e-02 (8.1209e-02) 
2023-05-26 00:30:49.906610: train Epoch: [56][ 16/129]	Time  2.673 ( 1.996)	Data  1.726 ( 1.046)	Loss 7.6543e-02 (8.0934e-02) 
2023-05-26 00:30:50.855137: train Epoch: [56][ 17/129]	Time  0.949 ( 1.938)	Data  0.001 ( 0.988)	Loss 5.6773e-02 (7.9592e-02) 
2023-05-26 00:30:53.482478: train Epoch: [56][ 18/129]	Time  2.627 ( 1.974)	Data  1.682 ( 1.024)	Loss 1.0195e-01 (8.0769e-02) 
2023-05-26 00:30:54.432072: train Epoch: [56][ 19/129]	Time  0.950 ( 1.923)	Data  0.001 ( 0.973)	Loss 5.5257e-02 (7.9493e-02) 
2023-05-26 00:30:57.102879: train Epoch: [56][ 20/129]	Time  2.671 ( 1.959)	Data  1.725 ( 1.009)	Loss 7.0775e-02 (7.9078e-02) 
2023-05-26 00:30:58.051964: train Epoch: [56][ 21/129]	Time  0.949 ( 1.913)	Data  0.001 ( 0.963)	Loss 6.4646e-02 (7.8422e-02) 
2023-05-26 00:31:00.714496: train Epoch: [56][ 22/129]	Time  2.663 ( 1.945)	Data  1.718 ( 0.996)	Loss 4.6771e-02 (7.7046e-02) 
2023-05-26 00:31:01.665371: train Epoch: [56][ 23/129]	Time  0.951 ( 1.904)	Data  0.001 ( 0.954)	Loss 6.3469e-02 (7.6480e-02) 
2023-05-26 00:31:04.337115: train Epoch: [56][ 24/129]	Time  2.672 ( 1.935)	Data  1.725 ( 0.985)	Loss 1.0226e-01 (7.7511e-02) 
2023-05-26 00:31:05.286172: train Epoch: [56][ 25/129]	Time  0.949 ( 1.897)	Data  0.001 ( 0.947)	Loss 8.4420e-02 (7.7777e-02) 
2023-05-26 00:31:07.860902: train Epoch: [56][ 26/129]	Time  2.575 ( 1.922)	Data  1.628 ( 0.972)	Loss 1.0456e-01 (7.8769e-02) 
2023-05-26 00:31:08.809705: train Epoch: [56][ 27/129]	Time  0.949 ( 1.887)	Data  0.001 ( 0.938)	Loss 7.2155e-02 (7.8533e-02) 
2023-05-26 00:31:11.461836: train Epoch: [56][ 28/129]	Time  2.652 ( 1.914)	Data  1.707 ( 0.964)	Loss 6.7168e-02 (7.8141e-02) 
2023-05-26 00:31:12.410911: train Epoch: [56][ 29/129]	Time  0.949 ( 1.881)	Data  0.001 ( 0.932)	Loss 7.5060e-02 (7.8038e-02) 
2023-05-26 00:31:15.018496: train Epoch: [56][ 30/129]	Time  2.608 ( 1.905)	Data  1.661 ( 0.956)	Loss 1.2725e-01 (7.9625e-02) 
2023-05-26 00:31:15.967719: train Epoch: [56][ 31/129]	Time  0.949 ( 1.875)	Data  0.001 ( 0.926)	Loss 4.8580e-02 (7.8655e-02) 
2023-05-26 00:31:18.610195: train Epoch: [56][ 32/129]	Time  2.642 ( 1.898)	Data  1.697 ( 0.949)	Loss 8.3059e-02 (7.8789e-02) 
2023-05-26 00:31:19.561216: train Epoch: [56][ 33/129]	Time  0.951 ( 1.870)	Data  0.001 ( 0.921)	Loss 7.6631e-02 (7.8725e-02) 
2023-05-26 00:31:22.249488: train Epoch: [56][ 34/129]	Time  2.688 ( 1.894)	Data  1.745 ( 0.945)	Loss 8.9475e-02 (7.9032e-02) 
2023-05-26 00:31:23.199887: train Epoch: [56][ 35/129]	Time  0.950 ( 1.868)	Data  0.001 ( 0.919)	Loss 5.8739e-02 (7.8469e-02) 
2023-05-26 00:31:25.805542: train Epoch: [56][ 36/129]	Time  2.606 ( 1.887)	Data  1.658 ( 0.939)	Loss 6.5535e-02 (7.8119e-02) 
2023-05-26 00:31:26.754923: train Epoch: [56][ 37/129]	Time  0.949 ( 1.863)	Data  0.001 ( 0.914)	Loss 8.1496e-02 (7.8208e-02) 
2023-05-26 00:31:29.346360: train Epoch: [56][ 38/129]	Time  2.591 ( 1.881)	Data  1.644 ( 0.933)	Loss 7.3679e-02 (7.8092e-02) 
2023-05-26 00:31:30.296772: train Epoch: [56][ 39/129]	Time  0.950 ( 1.858)	Data  0.001 ( 0.909)	Loss 1.0548e-01 (7.8777e-02) 
2023-05-26 00:31:32.902381: train Epoch: [56][ 40/129]	Time  2.606 ( 1.876)	Data  1.658 ( 0.928)	Loss 8.1255e-02 (7.8837e-02) 
2023-05-26 00:31:33.851827: train Epoch: [56][ 41/129]	Time  0.949 ( 1.854)	Data  0.001 ( 0.906)	Loss 6.9978e-02 (7.8626e-02) 
2023-05-26 00:31:36.476220: train Epoch: [56][ 42/129]	Time  2.624 ( 1.872)	Data  1.678 ( 0.924)	Loss 6.0235e-02 (7.8198e-02) 
2023-05-26 00:31:37.435877: train Epoch: [56][ 43/129]	Time  0.960 ( 1.852)	Data  0.001 ( 0.903)	Loss 9.4630e-02 (7.8572e-02) 
2023-05-26 00:31:40.145078: train Epoch: [56][ 44/129]	Time  2.709 ( 1.871)	Data  1.764 ( 0.922)	Loss 9.2989e-02 (7.8892e-02) 
2023-05-26 00:31:41.093872: train Epoch: [56][ 45/129]	Time  0.949 ( 1.851)	Data  0.001 ( 0.902)	Loss 1.0482e-01 (7.9456e-02) 
2023-05-26 00:31:43.747999: train Epoch: [56][ 46/129]	Time  2.654 ( 1.868)	Data  1.708 ( 0.919)	Loss 9.3421e-02 (7.9753e-02) 
2023-05-26 00:31:44.697056: train Epoch: [56][ 47/129]	Time  0.949 ( 1.849)	Data  0.001 ( 0.900)	Loss 1.0698e-01 (8.0320e-02) 
2023-05-26 00:31:47.370518: train Epoch: [56][ 48/129]	Time  2.673 ( 1.865)	Data  1.729 ( 0.917)	Loss 7.6292e-02 (8.0238e-02) 
2023-05-26 00:31:48.318079: train Epoch: [56][ 49/129]	Time  0.948 ( 1.847)	Data  0.001 ( 0.898)	Loss 1.2357e-01 (8.1105e-02) 
2023-05-26 00:31:50.929804: train Epoch: [56][ 50/129]	Time  2.612 ( 1.862)	Data  1.665 ( 0.913)	Loss 6.5974e-02 (8.0808e-02) 
2023-05-26 00:31:51.878193: train Epoch: [56][ 51/129]	Time  0.948 ( 1.844)	Data  0.001 ( 0.896)	Loss 1.0351e-01 (8.1245e-02) 
2023-05-26 00:31:54.466638: train Epoch: [56][ 52/129]	Time  2.588 ( 1.858)	Data  1.640 ( 0.910)	Loss 1.0271e-01 (8.1650e-02) 
2023-05-26 00:31:55.415905: train Epoch: [56][ 53/129]	Time  0.949 ( 1.842)	Data  0.001 ( 0.893)	Loss 1.0855e-01 (8.2148e-02) 
2023-05-26 00:31:58.043149: train Epoch: [56][ 54/129]	Time  2.627 ( 1.856)	Data  1.681 ( 0.907)	Loss 1.0146e-01 (8.2499e-02) 
2023-05-26 00:31:58.993399: train Epoch: [56][ 55/129]	Time  0.950 ( 1.840)	Data  0.001 ( 0.891)	Loss 7.8475e-02 (8.2427e-02) 
2023-05-26 00:32:01.612414: train Epoch: [56][ 56/129]	Time  2.619 ( 1.853)	Data  1.673 ( 0.905)	Loss 8.7216e-02 (8.2511e-02) 
2023-05-26 00:32:02.561787: train Epoch: [56][ 57/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.889)	Loss 6.7490e-02 (8.2252e-02) 
2023-05-26 00:32:05.282899: train Epoch: [56][ 58/129]	Time  2.721 ( 1.853)	Data  1.774 ( 0.904)	Loss 4.4011e-02 (8.1604e-02) 
2023-05-26 00:32:06.231523: train Epoch: [56][ 59/129]	Time  0.949 ( 1.838)	Data  0.001 ( 0.889)	Loss 7.3157e-02 (8.1463e-02) 
2023-05-26 00:32:08.899754: train Epoch: [56][ 60/129]	Time  2.668 ( 1.851)	Data  1.713 ( 0.903)	Loss 3.7740e-02 (8.0746e-02) 
2023-05-26 00:32:09.851410: train Epoch: [56][ 61/129]	Time  0.952 ( 1.837)	Data  0.001 ( 0.888)	Loss 6.8940e-02 (8.0556e-02) 
2023-05-26 00:32:12.480218: train Epoch: [56][ 62/129]	Time  2.629 ( 1.849)	Data  1.678 ( 0.901)	Loss 6.2594e-02 (8.0271e-02) 
2023-05-26 00:32:13.431056: train Epoch: [56][ 63/129]	Time  0.951 ( 1.835)	Data  0.001 ( 0.887)	Loss 1.1691e-01 (8.0843e-02) 
2023-05-26 00:32:16.187524: train Epoch: [56][ 64/129]	Time  2.756 ( 1.850)	Data  1.806 ( 0.901)	Loss 6.5465e-02 (8.0607e-02) 
2023-05-26 00:32:17.136539: train Epoch: [56][ 65/129]	Time  0.949 ( 1.836)	Data  0.001 ( 0.887)	Loss 6.6347e-02 (8.0391e-02) 
2023-05-26 00:32:19.739130: train Epoch: [56][ 66/129]	Time  2.603 ( 1.847)	Data  1.650 ( 0.899)	Loss 4.6234e-02 (7.9881e-02) 
2023-05-26 00:32:20.689494: train Epoch: [56][ 67/129]	Time  0.950 ( 1.834)	Data  0.001 ( 0.885)	Loss 6.2011e-02 (7.9618e-02) 
2023-05-26 00:32:23.323375: train Epoch: [56][ 68/129]	Time  2.634 ( 1.846)	Data  1.683 ( 0.897)	Loss 7.9825e-02 (7.9621e-02) 
2023-05-26 00:32:24.285474: train Epoch: [56][ 69/129]	Time  0.962 ( 1.833)	Data  0.001 ( 0.884)	Loss 4.9457e-02 (7.9190e-02) 
2023-05-26 00:32:26.848853: train Epoch: [56][ 70/129]	Time  2.563 ( 1.843)	Data  1.606 ( 0.894)	Loss 6.4265e-02 (7.8980e-02) 
2023-05-26 00:32:27.813890: train Epoch: [56][ 71/129]	Time  0.965 ( 1.831)	Data  0.001 ( 0.882)	Loss 1.9034e-01 (8.0527e-02) 
2023-05-26 00:32:30.659530: train Epoch: [56][ 72/129]	Time  2.846 ( 1.845)	Data  1.882 ( 0.896)	Loss 7.7107e-02 (8.0480e-02) 
2023-05-26 00:32:31.620931: train Epoch: [56][ 73/129]	Time  0.961 ( 1.833)	Data  0.001 ( 0.884)	Loss 6.1384e-02 (8.0222e-02) 
2023-05-26 00:32:34.342817: train Epoch: [56][ 74/129]	Time  2.722 ( 1.845)	Data  1.763 ( 0.895)	Loss 4.9982e-02 (7.9818e-02) 
2023-05-26 00:32:35.303842: train Epoch: [56][ 75/129]	Time  0.961 ( 1.833)	Data  0.001 ( 0.883)	Loss 7.7616e-02 (7.9789e-02) 
2023-05-26 00:32:37.866433: train Epoch: [56][ 76/129]	Time  2.563 ( 1.843)	Data  1.605 ( 0.893)	Loss 4.6738e-02 (7.9360e-02) 
2023-05-26 00:32:38.827395: train Epoch: [56][ 77/129]	Time  0.961 ( 1.832)	Data  0.001 ( 0.881)	Loss 9.0790e-02 (7.9507e-02) 
2023-05-26 00:32:41.466916: train Epoch: [56][ 78/129]	Time  2.640 ( 1.842)	Data  1.681 ( 0.892)	Loss 6.2034e-02 (7.9286e-02) 
2023-05-26 00:32:42.428631: train Epoch: [56][ 79/129]	Time  0.962 ( 1.831)	Data  0.001 ( 0.880)	Loss 8.5466e-02 (7.9363e-02) 
2023-05-26 00:32:45.050485: train Epoch: [56][ 80/129]	Time  2.622 ( 1.841)	Data  1.654 ( 0.890)	Loss 6.6148e-02 (7.9200e-02) 
2023-05-26 00:32:46.017451: train Epoch: [56][ 81/129]	Time  0.967 ( 1.830)	Data  0.001 ( 0.879)	Loss 5.8427e-02 (7.8946e-02) 
2023-05-26 00:32:48.624721: train Epoch: [56][ 82/129]	Time  2.607 ( 1.839)	Data  1.658 ( 0.888)	Loss 8.1830e-02 (7.8981e-02) 
2023-05-26 00:32:49.576179: train Epoch: [56][ 83/129]	Time  0.951 ( 1.829)	Data  0.001 ( 0.878)	Loss 6.6058e-02 (7.8827e-02) 
2023-05-26 00:32:52.282101: train Epoch: [56][ 84/129]	Time  2.706 ( 1.839)	Data  1.756 ( 0.888)	Loss 3.5667e-02 (7.8320e-02) 
2023-05-26 00:32:53.233655: train Epoch: [56][ 85/129]	Time  0.952 ( 1.829)	Data  0.001 ( 0.878)	Loss 9.2555e-02 (7.8485e-02) 
2023-05-26 00:32:55.962533: train Epoch: [56][ 86/129]	Time  2.729 ( 1.839)	Data  1.781 ( 0.888)	Loss 7.7688e-02 (7.8476e-02) 
2023-05-26 00:32:56.916599: train Epoch: [56][ 87/129]	Time  0.954 ( 1.829)	Data  0.001 ( 0.878)	Loss 1.1674e-01 (7.8911e-02) 
2023-05-26 00:32:59.584959: train Epoch: [56][ 88/129]	Time  2.668 ( 1.838)	Data  1.708 ( 0.888)	Loss 9.0821e-02 (7.9045e-02) 
2023-05-26 00:33:00.536495: train Epoch: [56][ 89/129]	Time  0.952 ( 1.829)	Data  0.001 ( 0.878)	Loss 6.7898e-02 (7.8921e-02) 
2023-05-26 00:33:03.175867: train Epoch: [56][ 90/129]	Time  2.639 ( 1.837)	Data  1.692 ( 0.887)	Loss 5.7570e-02 (7.8686e-02) 
2023-05-26 00:33:04.125687: train Epoch: [56][ 91/129]	Time  0.950 ( 1.828)	Data  0.001 ( 0.877)	Loss 9.8849e-02 (7.8905e-02) 
2023-05-26 00:33:06.816590: train Epoch: [56][ 92/129]	Time  2.691 ( 1.837)	Data  1.743 ( 0.886)	Loss 6.5294e-02 (7.8759e-02) 
2023-05-26 00:33:07.778222: train Epoch: [56][ 93/129]	Time  0.962 ( 1.828)	Data  0.001 ( 0.877)	Loss 6.9713e-02 (7.8663e-02) 
2023-05-26 00:33:10.493491: train Epoch: [56][ 94/129]	Time  2.715 ( 1.837)	Data  1.750 ( 0.886)	Loss 6.4789e-02 (7.8517e-02) 
2023-05-26 00:33:11.454638: train Epoch: [56][ 95/129]	Time  0.961 ( 1.828)	Data  0.001 ( 0.877)	Loss 1.1254e-01 (7.8871e-02) 
2023-05-26 00:33:14.026624: train Epoch: [56][ 96/129]	Time  2.572 ( 1.836)	Data  1.607 ( 0.884)	Loss 5.1600e-02 (7.8590e-02) 
2023-05-26 00:33:14.987679: train Epoch: [56][ 97/129]	Time  0.961 ( 1.827)	Data  0.001 ( 0.875)	Loss 5.2358e-02 (7.8322e-02) 
2023-05-26 00:33:17.579593: train Epoch: [56][ 98/129]	Time  2.592 ( 1.834)	Data  1.632 ( 0.883)	Loss 4.2369e-02 (7.7959e-02) 
2023-05-26 00:33:18.530260: train Epoch: [56][ 99/129]	Time  0.951 ( 1.826)	Data  0.001 ( 0.874)	Loss 7.1812e-02 (7.7898e-02) 
2023-05-26 00:33:21.154940: train Epoch: [56][100/129]	Time  2.625 ( 1.834)	Data  1.676 ( 0.882)	Loss 6.4990e-02 (7.7770e-02) 
2023-05-26 00:33:22.104192: train Epoch: [56][101/129]	Time  0.949 ( 1.825)	Data  0.001 ( 0.873)	Loss 6.4318e-02 (7.7638e-02) 
2023-05-26 00:33:24.721575: train Epoch: [56][102/129]	Time  2.617 ( 1.833)	Data  1.668 ( 0.881)	Loss 5.8300e-02 (7.7450e-02) 
2023-05-26 00:33:25.671457: train Epoch: [56][103/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.873)	Loss 7.2291e-02 (7.7401e-02) 
2023-05-26 00:33:28.348492: train Epoch: [56][104/129]	Time  2.677 ( 1.832)	Data  1.717 ( 0.881)	Loss 9.2883e-02 (7.7548e-02) 
2023-05-26 00:33:29.298886: train Epoch: [56][105/129]	Time  0.950 ( 1.824)	Data  0.001 ( 0.872)	Loss 1.8377e-01 (7.8550e-02) 
2023-05-26 00:33:31.955096: train Epoch: [56][106/129]	Time  2.656 ( 1.832)	Data  1.707 ( 0.880)	Loss 5.0527e-02 (7.8288e-02) 
2023-05-26 00:33:32.905724: train Epoch: [56][107/129]	Time  0.951 ( 1.823)	Data  0.001 ( 0.872)	Loss 4.9477e-02 (7.8021e-02) 
2023-05-26 00:33:35.587216: train Epoch: [56][108/129]	Time  2.681 ( 1.831)	Data  1.723 ( 0.880)	Loss 7.6185e-02 (7.8005e-02) 
2023-05-26 00:33:36.538308: train Epoch: [56][109/129]	Time  0.951 ( 1.823)	Data  0.001 ( 0.872)	Loss 6.3367e-02 (7.7871e-02) 
2023-05-26 00:33:39.254502: train Epoch: [56][110/129]	Time  2.716 ( 1.831)	Data  1.766 ( 0.880)	Loss 6.7951e-02 (7.7782e-02) 
2023-05-26 00:33:40.206691: train Epoch: [56][111/129]	Time  0.952 ( 1.824)	Data  0.001 ( 0.872)	Loss 7.2255e-02 (7.7733e-02) 
2023-05-26 00:33:42.894778: train Epoch: [56][112/129]	Time  2.688 ( 1.831)	Data  1.738 ( 0.880)	Loss 1.1050e-01 (7.8023e-02) 
2023-05-26 00:33:43.847012: train Epoch: [56][113/129]	Time  0.952 ( 1.823)	Data  0.001 ( 0.872)	Loss 5.7850e-02 (7.7846e-02) 
2023-05-26 00:33:46.516832: train Epoch: [56][114/129]	Time  2.670 ( 1.831)	Data  1.699 ( 0.879)	Loss 6.0626e-02 (7.7696e-02) 
2023-05-26 00:33:47.468873: train Epoch: [56][115/129]	Time  0.952 ( 1.823)	Data  0.001 ( 0.872)	Loss 9.1404e-02 (7.7814e-02) 
2023-05-26 00:33:50.108289: train Epoch: [56][116/129]	Time  2.639 ( 1.830)	Data  1.679 ( 0.879)	Loss 8.4926e-02 (7.7875e-02) 
2023-05-26 00:33:51.061888: train Epoch: [56][117/129]	Time  0.954 ( 1.823)	Data  0.001 ( 0.871)	Loss 8.7688e-02 (7.7958e-02) 
2023-05-26 00:33:53.729290: train Epoch: [56][118/129]	Time  2.667 ( 1.830)	Data  1.716 ( 0.878)	Loss 8.1565e-02 (7.7988e-02) 
2023-05-26 00:33:54.681930: train Epoch: [56][119/129]	Time  0.953 ( 1.823)	Data  0.001 ( 0.871)	Loss 6.4508e-02 (7.7876e-02) 
2023-05-26 00:33:57.402368: train Epoch: [56][120/129]	Time  2.720 ( 1.830)	Data  1.766 ( 0.878)	Loss 6.3716e-02 (7.7759e-02) 
2023-05-26 00:33:58.357109: train Epoch: [56][121/129]	Time  0.955 ( 1.823)	Data  0.001 ( 0.871)	Loss 9.2984e-02 (7.7884e-02) 
2023-05-26 00:34:01.007249: train Epoch: [56][122/129]	Time  2.650 ( 1.830)	Data  1.695 ( 0.878)	Loss 5.1168e-02 (7.7667e-02) 
2023-05-26 00:34:01.957580: train Epoch: [56][123/129]	Time  0.950 ( 1.822)	Data  0.001 ( 0.871)	Loss 6.8268e-02 (7.7591e-02) 
2023-05-26 00:34:04.665289: train Epoch: [56][124/129]	Time  2.708 ( 1.830)	Data  1.758 ( 0.878)	Loss 5.0431e-02 (7.7374e-02) 
2023-05-26 00:34:05.618135: train Epoch: [56][125/129]	Time  0.953 ( 1.823)	Data  0.001 ( 0.871)	Loss 1.0745e-01 (7.7612e-02) 
2023-05-26 00:34:08.467524: train Epoch: [56][126/129]	Time  2.849 ( 1.831)	Data  1.896 ( 0.879)	Loss 8.8828e-02 (7.7701e-02) 
2023-05-26 00:34:09.415964: train Epoch: [56][127/129]	Time  0.948 ( 1.824)	Data  0.001 ( 0.872)	Loss 9.2506e-02 (7.7816e-02) 
2023-05-26 00:34:11.060518: train Epoch: [56][128/129]	Time  1.645 ( 1.822)	Data  0.681 ( 0.871)	Loss 7.3212e-02 (7.7781e-02) 
2023-05-26 00:34:11.092635: Train Epoch done in 235.12410079599795 s 
2023-05-26 00:34:13.539193: val Epoch: [56][ 0/72]	Time  1.634 ( 1.634)	Data  1.437 ( 1.437)	Loss 5.4111e-02 (5.4111e-02) 
2023-05-26 00:34:13.663384: val Epoch: [56][ 1/72]	Time  0.124 ( 0.879)	Data  0.001 ( 0.719)	Loss 9.0161e-02 (7.2136e-02) 
2023-05-26 00:34:14.758876: val Epoch: [56][ 2/72]	Time  1.095 ( 0.951)	Data  0.966 ( 0.801)	Loss 7.9914e-02 (7.4729e-02) 
2023-05-26 00:34:14.885150: val Epoch: [56][ 3/72]	Time  0.126 ( 0.745)	Data  0.001 ( 0.601)	Loss 1.2024e-01 (8.6107e-02) 
2023-05-26 00:34:16.068384: val Epoch: [56][ 4/72]	Time  1.183 ( 0.833)	Data  1.049 ( 0.691)	Loss 5.5279e-02 (7.9941e-02) 
2023-05-26 00:34:16.196109: val Epoch: [56][ 5/72]	Time  0.128 ( 0.715)	Data  0.001 ( 0.576)	Loss 3.4343e-02 (7.2341e-02) 
2023-05-26 00:34:17.414157: val Epoch: [56][ 6/72]	Time  1.218 ( 0.787)	Data  1.082 ( 0.648)	Loss 4.4804e-02 (6.8407e-02) 
2023-05-26 00:34:17.545543: val Epoch: [56][ 7/72]	Time  0.131 ( 0.705)	Data  0.001 ( 0.567)	Loss 9.4655e-02 (7.1688e-02) 
2023-05-26 00:34:18.677582: val Epoch: [56][ 8/72]	Time  1.132 ( 0.753)	Data  0.998 ( 0.615)	Loss 1.2805e-01 (7.7951e-02) 
2023-05-26 00:34:18.809596: val Epoch: [56][ 9/72]	Time  0.132 ( 0.690)	Data  0.001 ( 0.554)	Loss 7.6568e-02 (7.7813e-02) 
2023-05-26 00:34:19.898550: val Epoch: [56][10/72]	Time  1.089 ( 0.727)	Data  0.958 ( 0.590)	Loss 3.6686e-02 (7.4074e-02) 
2023-05-26 00:34:20.089515: val Epoch: [56][11/72]	Time  0.191 ( 0.682)	Data  0.068 ( 0.547)	Loss 5.0474e-01 (1.0996e-01) 
2023-05-26 00:34:21.125051: val Epoch: [56][12/72]	Time  1.036 ( 0.709)	Data  0.915 ( 0.575)	Loss 1.1657e-01 (1.1047e-01) 
2023-05-26 00:34:21.290140: val Epoch: [56][13/72]	Time  0.165 ( 0.670)	Data  0.046 ( 0.537)	Loss 8.2602e-02 (1.0848e-01) 
2023-05-26 00:34:22.339977: val Epoch: [56][14/72]	Time  1.050 ( 0.696)	Data  0.929 ( 0.563)	Loss 9.7670e-02 (1.0776e-01) 
2023-05-26 00:34:22.489595: val Epoch: [56][15/72]	Time  0.150 ( 0.662)	Data  0.030 ( 0.530)	Loss 6.3539e-02 (1.0500e-01) 
2023-05-26 00:34:23.534764: val Epoch: [56][16/72]	Time  1.045 ( 0.684)	Data  0.925 ( 0.553)	Loss 4.8244e-02 (1.0166e-01) 
2023-05-26 00:34:23.745858: val Epoch: [56][17/72]	Time  0.211 ( 0.658)	Data  0.088 ( 0.528)	Loss 6.1471e-02 (9.9425e-02) 
2023-05-26 00:34:24.711181: val Epoch: [56][18/72]	Time  0.965 ( 0.674)	Data  0.845 ( 0.544)	Loss 4.3754e-02 (9.6495e-02) 
2023-05-26 00:34:24.969940: val Epoch: [56][19/72]	Time  0.259 ( 0.653)	Data  0.139 ( 0.524)	Loss 3.9467e-01 (1.1140e-01) 
2023-05-26 00:34:25.917568: val Epoch: [56][20/72]	Time  0.948 ( 0.667)	Data  0.827 ( 0.538)	Loss 2.3682e-01 (1.1738e-01) 
2023-05-26 00:34:26.157350: val Epoch: [56][21/72]	Time  0.240 ( 0.648)	Data  0.121 ( 0.519)	Loss 5.9517e-02 (1.1475e-01) 
2023-05-26 00:34:27.192573: val Epoch: [56][22/72]	Time  1.035 ( 0.665)	Data  0.915 ( 0.537)	Loss 6.4199e-02 (1.1255e-01) 
2023-05-26 00:34:27.397335: val Epoch: [56][23/72]	Time  0.205 ( 0.646)	Data  0.086 ( 0.518)	Loss 3.5115e-02 (1.0932e-01) 
2023-05-26 00:34:28.370615: val Epoch: [56][24/72]	Time  0.973 ( 0.659)	Data  0.853 ( 0.531)	Loss 3.6949e-02 (1.0643e-01) 
2023-05-26 00:34:28.653075: val Epoch: [56][25/72]	Time  0.282 ( 0.644)	Data  0.163 ( 0.517)	Loss 7.4209e-02 (1.0519e-01) 
2023-05-26 00:34:29.635704: val Epoch: [56][26/72]	Time  0.983 ( 0.657)	Data  0.863 ( 0.530)	Loss 7.2178e-02 (1.0396e-01) 
2023-05-26 00:34:29.840344: val Epoch: [56][27/72]	Time  0.205 ( 0.641)	Data  0.086 ( 0.514)	Loss 3.9558e-02 (1.0166e-01) 
2023-05-26 00:34:30.821685: val Epoch: [56][28/72]	Time  0.981 ( 0.652)	Data  0.860 ( 0.526)	Loss 4.6040e-02 (9.9746e-02) 
2023-05-26 00:34:31.109181: val Epoch: [56][29/72]	Time  0.287 ( 0.640)	Data  0.168 ( 0.514)	Loss 2.2426e-01 (1.0390e-01) 
2023-05-26 00:34:32.058754: val Epoch: [56][30/72]	Time  0.950 ( 0.650)	Data  0.828 ( 0.524)	Loss 7.6875e-02 (1.0303e-01) 
2023-05-26 00:34:32.325336: val Epoch: [56][31/72]	Time  0.267 ( 0.638)	Data  0.147 ( 0.512)	Loss 5.8401e-02 (1.0163e-01) 
2023-05-26 00:34:33.239813: val Epoch: [56][32/72]	Time  0.914 ( 0.647)	Data  0.794 ( 0.521)	Loss 4.2316e-02 (9.9833e-02) 
2023-05-26 00:34:33.561547: val Epoch: [56][33/72]	Time  0.322 ( 0.637)	Data  0.202 ( 0.512)	Loss 8.5644e-02 (9.9416e-02) 
2023-05-26 00:34:34.483053: val Epoch: [56][34/72]	Time  0.921 ( 0.645)	Data  0.800 ( 0.520)	Loss 3.6248e-02 (9.7611e-02) 
2023-05-26 00:34:34.824358: val Epoch: [56][35/72]	Time  0.341 ( 0.637)	Data  0.221 ( 0.511)	Loss 3.4148e-01 (1.0439e-01) 
2023-05-26 00:34:35.798341: val Epoch: [56][36/72]	Time  0.974 ( 0.646)	Data  0.852 ( 0.521)	Loss 6.0784e-02 (1.0321e-01) 
2023-05-26 00:34:36.081933: val Epoch: [56][37/72]	Time  0.284 ( 0.636)	Data  0.162 ( 0.511)	Loss 8.0295e-02 (1.0260e-01) 
2023-05-26 00:34:37.031896: val Epoch: [56][38/72]	Time  0.950 ( 0.644)	Data  0.829 ( 0.519)	Loss 2.1075e-01 (1.0538e-01) 
2023-05-26 00:34:37.301220: val Epoch: [56][39/72]	Time  0.269 ( 0.635)	Data  0.150 ( 0.510)	Loss 6.1350e-02 (1.0428e-01) 
2023-05-26 00:34:38.275829: val Epoch: [56][40/72]	Time  0.975 ( 0.643)	Data  0.851 ( 0.518)	Loss 1.3919e-01 (1.0513e-01) 
2023-05-26 00:34:38.513458: val Epoch: [56][41/72]	Time  0.238 ( 0.634)	Data  0.118 ( 0.509)	Loss 5.6987e-02 (1.0398e-01) 
2023-05-26 00:34:39.483537: val Epoch: [56][42/72]	Time  0.970 ( 0.641)	Data  0.846 ( 0.517)	Loss 1.4016e-01 (1.0482e-01) 
2023-05-26 00:34:39.743037: val Epoch: [56][43/72]	Time  0.259 ( 0.633)	Data  0.140 ( 0.508)	Loss 5.0237e-02 (1.0358e-01) 
2023-05-26 00:34:40.731151: val Epoch: [56][44/72]	Time  0.988 ( 0.641)	Data  0.867 ( 0.516)	Loss 1.7389e-01 (1.0514e-01) 
2023-05-26 00:34:41.053739: val Epoch: [56][45/72]	Time  0.323 ( 0.634)	Data  0.203 ( 0.509)	Loss 7.3499e-02 (1.0446e-01) 
2023-05-26 00:34:42.004212: val Epoch: [56][46/72]	Time  0.950 ( 0.640)	Data  0.828 ( 0.516)	Loss 9.1829e-02 (1.0419e-01) 
2023-05-26 00:34:42.344158: val Epoch: [56][47/72]	Time  0.340 ( 0.634)	Data  0.221 ( 0.510)	Loss 1.5882e-01 (1.0533e-01) 
2023-05-26 00:34:43.313487: val Epoch: [56][48/72]	Time  0.969 ( 0.641)	Data  0.848 ( 0.517)	Loss 1.7330e-01 (1.0671e-01) 
2023-05-26 00:34:43.627676: val Epoch: [56][49/72]	Time  0.314 ( 0.634)	Data  0.194 ( 0.510)	Loss 4.8463e-02 (1.0555e-01) 
2023-05-26 00:34:44.583777: val Epoch: [56][50/72]	Time  0.956 ( 0.641)	Data  0.835 ( 0.517)	Loss 3.0643e-01 (1.0949e-01) 
2023-05-26 00:34:44.885893: val Epoch: [56][51/72]	Time  0.302 ( 0.634)	Data  0.183 ( 0.510)	Loss 1.1223e-01 (1.0954e-01) 
2023-05-26 00:34:45.850422: val Epoch: [56][52/72]	Time  0.965 ( 0.640)	Data  0.843 ( 0.517)	Loss 3.7613e-01 (1.1457e-01) 
2023-05-26 00:34:46.120253: val Epoch: [56][53/72]	Time  0.270 ( 0.634)	Data  0.146 ( 0.510)	Loss 5.0409e-02 (1.1338e-01) 
2023-05-26 00:34:47.067647: val Epoch: [56][54/72]	Time  0.947 ( 0.639)	Data  0.821 ( 0.515)	Loss 1.2389e-01 (1.1357e-01) 
2023-05-26 00:34:47.331722: val Epoch: [56][55/72]	Time  0.264 ( 0.633)	Data  0.139 ( 0.509)	Loss 4.9307e-02 (1.1243e-01) 
2023-05-26 00:34:48.277621: val Epoch: [56][56/72]	Time  0.946 ( 0.638)	Data  0.819 ( 0.514)	Loss 1.0703e-01 (1.1233e-01) 
2023-05-26 00:34:48.559991: val Epoch: [56][57/72]	Time  0.282 ( 0.632)	Data  0.158 ( 0.508)	Loss 1.1644e-01 (1.1240e-01) 
2023-05-26 00:34:49.536533: val Epoch: [56][58/72]	Time  0.977 ( 0.638)	Data  0.851 ( 0.514)	Loss 3.1322e-01 (1.1581e-01) 
2023-05-26 00:34:49.764106: val Epoch: [56][59/72]	Time  0.228 ( 0.631)	Data  0.104 ( 0.507)	Loss 4.5126e-02 (1.1463e-01) 
2023-05-26 00:34:50.802064: val Epoch: [56][60/72]	Time  1.038 ( 0.638)	Data  0.912 ( 0.514)	Loss 9.5549e-02 (1.1431e-01) 
2023-05-26 00:34:50.997499: val Epoch: [56][61/72]	Time  0.195 ( 0.631)	Data  0.071 ( 0.507)	Loss 5.6193e-02 (1.1338e-01) 
2023-05-26 00:34:52.046030: val Epoch: [56][62/72]	Time  1.049 ( 0.637)	Data  0.921 ( 0.513)	Loss 3.3737e-01 (1.1693e-01) 
2023-05-26 00:34:52.186333: val Epoch: [56][63/72]	Time  0.140 ( 0.629)	Data  0.015 ( 0.505)	Loss 5.9908e-02 (1.1604e-01) 
2023-05-26 00:34:53.245684: val Epoch: [56][64/72]	Time  1.059 ( 0.636)	Data  0.933 ( 0.512)	Loss 2.5542e-01 (1.1819e-01) 
2023-05-26 00:34:53.434845: val Epoch: [56][65/72]	Time  0.189 ( 0.629)	Data  0.064 ( 0.505)	Loss 2.8704e-01 (1.2074e-01) 
2023-05-26 00:34:54.442868: val Epoch: [56][66/72]	Time  1.008 ( 0.635)	Data  0.882 ( 0.511)	Loss 6.6511e-02 (1.1993e-01) 
2023-05-26 00:34:54.665102: val Epoch: [56][67/72]	Time  0.222 ( 0.629)	Data  0.098 ( 0.505)	Loss 9.2231e-02 (1.1953e-01) 
2023-05-26 00:34:55.697621: val Epoch: [56][68/72]	Time  1.033 ( 0.635)	Data  0.907 ( 0.511)	Loss 3.1808e-01 (1.2240e-01) 
2023-05-26 00:34:55.895113: val Epoch: [56][69/72]	Time  0.197 ( 0.628)	Data  0.073 ( 0.504)	Loss 5.3932e-02 (1.2143e-01) 
2023-05-26 00:34:56.887637: val Epoch: [56][70/72]	Time  0.993 ( 0.634)	Data  0.865 ( 0.509)	Loss 8.8162e-02 (1.2096e-01) 
2023-05-26 00:34:57.063465: val Epoch: [56][71/72]	Time  0.176 ( 0.627)	Data  0.051 ( 0.503)	Loss 4.7634e-02 (1.1994e-01) 
2023-05-26 00:34:57.254895: Epoch 56 :Val : ['ET : 0.7700271606445312', 'TC : 0.7935497164726257', 'WT : 0.8785755634307861'] 
2023-05-26 00:34:57.258044: Epoch 56 :Val : ['ET : 0.7700271606445312', 'TC : 0.7935497164726257', 'WT : 0.8785755634307861'] 
2023-05-26 00:34:57.260486: Val epoch done in 46.16785864399935 s 
2023-05-26 00:34:57.265752: Batches per epoch:  129 
2023-05-26 00:35:02.308612: train Epoch: [57][  0/129]	Time  5.043 ( 5.043)	Data  4.013 ( 4.013)	Loss 6.0634e-02 (6.0634e-02) 
2023-05-26 00:35:03.271651: train Epoch: [57][  1/129]	Time  0.963 ( 3.003)	Data  0.001 ( 2.007)	Loss 1.0357e-01 (8.2103e-02) 
2023-05-26 00:35:05.985291: train Epoch: [57][  2/129]	Time  2.714 ( 2.906)	Data  1.767 ( 1.927)	Loss 8.2495e-02 (8.2234e-02) 
2023-05-26 00:35:06.936722: train Epoch: [57][  3/129]	Time  0.951 ( 2.418)	Data  0.001 ( 1.446)	Loss 6.4846e-02 (7.7887e-02) 
2023-05-26 00:35:09.687268: train Epoch: [57][  4/129]	Time  2.751 ( 2.484)	Data  1.784 ( 1.513)	Loss 6.3418e-02 (7.4993e-02) 
2023-05-26 00:35:10.648041: train Epoch: [57][  5/129]	Time  0.961 ( 2.230)	Data  0.001 ( 1.261)	Loss 5.0044e-02 (7.0835e-02) 
2023-05-26 00:35:13.457170: train Epoch: [57][  6/129]	Time  2.809 ( 2.313)	Data  1.844 ( 1.344)	Loss 5.3364e-02 (6.8339e-02) 
2023-05-26 00:35:14.413120: train Epoch: [57][  7/129]	Time  0.956 ( 2.143)	Data  0.001 ( 1.176)	Loss 3.2518e-02 (6.3862e-02) 
2023-05-26 00:35:17.313288: train Epoch: [57][  8/129]	Time  2.900 ( 2.227)	Data  1.953 ( 1.263)	Loss 4.5990e-02 (6.1876e-02) 
2023-05-26 00:35:18.275993: train Epoch: [57][  9/129]	Time  0.963 ( 2.101)	Data  0.001 ( 1.137)	Loss 1.1284e-01 (6.6972e-02) 
2023-05-26 00:35:21.048268: train Epoch: [57][ 10/129]	Time  2.772 ( 2.162)	Data  1.816 ( 1.198)	Loss 7.9041e-02 (6.8069e-02) 
2023-05-26 00:35:22.008046: train Epoch: [57][ 11/129]	Time  0.960 ( 2.062)	Data  0.001 ( 1.099)	Loss 5.4775e-02 (6.6962e-02) 
2023-05-26 00:35:24.870114: train Epoch: [57][ 12/129]	Time  2.862 ( 2.123)	Data  1.893 ( 1.160)	Loss 7.6066e-02 (6.7662e-02) 
2023-05-26 00:35:25.831195: train Epoch: [57][ 13/129]	Time  0.961 ( 2.040)	Data  0.001 ( 1.077)	Loss 7.7649e-02 (6.8375e-02) 
2023-05-26 00:35:28.463447: train Epoch: [57][ 14/129]	Time  2.632 ( 2.080)	Data  1.669 ( 1.116)	Loss 7.1370e-02 (6.8575e-02) 
2023-05-26 00:35:29.413323: train Epoch: [57][ 15/129]	Time  0.950 ( 2.009)	Data  0.001 ( 1.047)	Loss 9.5110e-02 (7.0233e-02) 
2023-05-26 00:35:32.002218: train Epoch: [57][ 16/129]	Time  2.589 ( 2.043)	Data  1.641 ( 1.082)	Loss 1.1202e-01 (7.2692e-02) 
2023-05-26 00:35:32.954471: train Epoch: [57][ 17/129]	Time  0.952 ( 1.983)	Data  0.001 ( 1.022)	Loss 5.1367e-02 (7.1507e-02) 
2023-05-26 00:35:35.541913: train Epoch: [57][ 18/129]	Time  2.587 ( 2.015)	Data  1.637 ( 1.054)	Loss 7.1761e-02 (7.1520e-02) 
2023-05-26 00:35:36.493181: train Epoch: [57][ 19/129]	Time  0.951 ( 1.961)	Data  0.001 ( 1.001)	Loss 6.9931e-02 (7.1441e-02) 
2023-05-26 00:35:39.230790: train Epoch: [57][ 20/129]	Time  2.738 ( 1.998)	Data  1.780 ( 1.038)	Loss 8.4699e-02 (7.2072e-02) 
2023-05-26 00:35:40.181448: train Epoch: [57][ 21/129]	Time  0.951 ( 1.951)	Data  0.001 ( 0.991)	Loss 5.7123e-02 (7.1393e-02) 
2023-05-26 00:35:42.763014: train Epoch: [57][ 22/129]	Time  2.582 ( 1.978)	Data  1.630 ( 1.019)	Loss 6.8316e-02 (7.1259e-02) 
2023-05-26 00:35:43.717250: train Epoch: [57][ 23/129]	Time  0.954 ( 1.935)	Data  0.001 ( 0.977)	Loss 9.6654e-02 (7.2317e-02) 
2023-05-26 00:35:46.380856: train Epoch: [57][ 24/129]	Time  2.664 ( 1.965)	Data  1.715 ( 1.006)	Loss 6.8292e-02 (7.2156e-02) 
2023-05-26 00:35:47.330147: train Epoch: [57][ 25/129]	Time  0.949 ( 1.926)	Data  0.001 ( 0.967)	Loss 6.2331e-02 (7.1778e-02) 
2023-05-26 00:35:49.969444: train Epoch: [57][ 26/129]	Time  2.639 ( 1.952)	Data  1.690 ( 0.994)	Loss 4.9090e-02 (7.0938e-02) 
2023-05-26 00:35:50.918935: train Epoch: [57][ 27/129]	Time  0.949 ( 1.916)	Data  0.001 ( 0.959)	Loss 1.2141e-01 (7.2740e-02) 
2023-05-26 00:35:53.664150: train Epoch: [57][ 28/129]	Time  2.745 ( 1.945)	Data  1.796 ( 0.988)	Loss 6.0142e-02 (7.2306e-02) 
2023-05-26 00:35:54.613216: train Epoch: [57][ 29/129]	Time  0.949 ( 1.912)	Data  0.001 ( 0.955)	Loss 6.4674e-02 (7.2051e-02) 
2023-05-26 00:35:57.204751: train Epoch: [57][ 30/129]	Time  2.592 ( 1.934)	Data  1.645 ( 0.977)	Loss 8.8953e-02 (7.2597e-02) 
2023-05-26 00:35:58.155367: train Epoch: [57][ 31/129]	Time  0.951 ( 1.903)	Data  0.001 ( 0.947)	Loss 6.9984e-02 (7.2515e-02) 
2023-05-26 00:36:00.769635: train Epoch: [57][ 32/129]	Time  2.614 ( 1.924)	Data  1.668 ( 0.968)	Loss 4.6029e-02 (7.1712e-02) 
2023-05-26 00:36:01.720006: train Epoch: [57][ 33/129]	Time  0.950 ( 1.896)	Data  0.001 ( 0.940)	Loss 6.6374e-02 (7.1555e-02) 
2023-05-26 00:36:04.436667: train Epoch: [57][ 34/129]	Time  2.717 ( 1.919)	Data  1.769 ( 0.964)	Loss 8.3554e-02 (7.1898e-02) 
2023-05-26 00:36:05.385610: train Epoch: [57][ 35/129]	Time  0.949 ( 1.892)	Data  0.001 ( 0.937)	Loss 1.0928e-01 (7.2937e-02) 
2023-05-26 00:36:08.084783: train Epoch: [57][ 36/129]	Time  2.699 ( 1.914)	Data  1.749 ( 0.959)	Loss 1.0049e-01 (7.3681e-02) 
2023-05-26 00:36:09.036610: train Epoch: [57][ 37/129]	Time  0.952 ( 1.889)	Data  0.001 ( 0.934)	Loss 4.8998e-02 (7.3032e-02) 
2023-05-26 00:36:11.638885: train Epoch: [57][ 38/129]	Time  2.602 ( 1.907)	Data  1.655 ( 0.952)	Loss 5.2074e-02 (7.2494e-02) 
2023-05-26 00:36:12.590447: train Epoch: [57][ 39/129]	Time  0.952 ( 1.883)	Data  0.001 ( 0.928)	Loss 9.1476e-02 (7.2969e-02) 
2023-05-26 00:36:15.276404: train Epoch: [57][ 40/129]	Time  2.686 ( 1.903)	Data  1.731 ( 0.948)	Loss 1.1657e-01 (7.4032e-02) 
2023-05-26 00:36:16.243775: train Epoch: [57][ 41/129]	Time  0.967 ( 1.880)	Data  0.001 ( 0.925)	Loss 4.9469e-02 (7.3447e-02) 
2023-05-26 00:36:19.029122: train Epoch: [57][ 42/129]	Time  2.785 ( 1.901)	Data  1.841 ( 0.947)	Loss 7.3717e-02 (7.3454e-02) 
2023-05-26 00:36:19.976735: train Epoch: [57][ 43/129]	Time  0.948 ( 1.880)	Data  0.001 ( 0.925)	Loss 7.6633e-02 (7.3526e-02) 
2023-05-26 00:36:22.770195: train Epoch: [57][ 44/129]	Time  2.793 ( 1.900)	Data  1.848 ( 0.946)	Loss 5.9801e-02 (7.3221e-02) 
2023-05-26 00:36:23.719855: train Epoch: [57][ 45/129]	Time  0.950 ( 1.879)	Data  0.001 ( 0.925)	Loss 1.1142e-01 (7.4051e-02) 
2023-05-26 00:36:26.442615: train Epoch: [57][ 46/129]	Time  2.723 ( 1.897)	Data  1.766 ( 0.943)	Loss 6.9527e-02 (7.3955e-02) 
2023-05-26 00:36:27.390518: train Epoch: [57][ 47/129]	Time  0.948 ( 1.878)	Data  0.001 ( 0.923)	Loss 8.5130e-02 (7.4188e-02) 
2023-05-26 00:36:30.111179: train Epoch: [57][ 48/129]	Time  2.721 ( 1.895)	Data  1.774 ( 0.941)	Loss 1.1429e-01 (7.5006e-02) 
2023-05-26 00:36:31.059433: train Epoch: [57][ 49/129]	Time  0.948 ( 1.876)	Data  0.001 ( 0.922)	Loss 6.1300e-02 (7.4732e-02) 
2023-05-26 00:36:33.794303: train Epoch: [57][ 50/129]	Time  2.735 ( 1.893)	Data  1.779 ( 0.939)	Loss 6.6508e-02 (7.4571e-02) 
2023-05-26 00:36:34.742672: train Epoch: [57][ 51/129]	Time  0.948 ( 1.875)	Data  0.001 ( 0.921)	Loss 1.0268e-01 (7.5111e-02) 
2023-05-26 00:36:37.430268: train Epoch: [57][ 52/129]	Time  2.688 ( 1.890)	Data  1.736 ( 0.936)	Loss 5.5246e-02 (7.4737e-02) 
2023-05-26 00:36:38.377245: train Epoch: [57][ 53/129]	Time  0.947 ( 1.872)	Data  0.001 ( 0.919)	Loss 6.5403e-02 (7.4564e-02) 
2023-05-26 00:36:41.137517: train Epoch: [57][ 54/129]	Time  2.760 ( 1.889)	Data  1.806 ( 0.935)	Loss 1.0894e-01 (7.5189e-02) 
2023-05-26 00:36:42.087134: train Epoch: [57][ 55/129]	Time  0.950 ( 1.872)	Data  0.001 ( 0.918)	Loss 8.8325e-02 (7.5423e-02) 
2023-05-26 00:36:44.972868: train Epoch: [57][ 56/129]	Time  2.886 ( 1.890)	Data  1.938 ( 0.936)	Loss 6.6063e-02 (7.5259e-02) 
2023-05-26 00:36:45.921601: train Epoch: [57][ 57/129]	Time  0.949 ( 1.873)	Data  0.001 ( 0.920)	Loss 6.1916e-02 (7.5029e-02) 
2023-05-26 00:36:48.761175: train Epoch: [57][ 58/129]	Time  2.840 ( 1.890)	Data  1.892 ( 0.936)	Loss 6.2555e-02 (7.4818e-02) 
2023-05-26 00:36:49.710936: train Epoch: [57][ 59/129]	Time  0.950 ( 1.874)	Data  0.001 ( 0.921)	Loss 6.7217e-02 (7.4691e-02) 
2023-05-26 00:36:52.613972: train Epoch: [57][ 60/129]	Time  2.903 ( 1.891)	Data  1.952 ( 0.938)	Loss 1.0384e-01 (7.5169e-02) 
2023-05-26 00:36:53.576412: train Epoch: [57][ 61/129]	Time  0.962 ( 1.876)	Data  0.001 ( 0.923)	Loss 5.1842e-02 (7.4793e-02) 
2023-05-26 00:36:56.389547: train Epoch: [57][ 62/129]	Time  2.813 ( 1.891)	Data  1.831 ( 0.937)	Loss 6.9031e-02 (7.4701e-02) 
2023-05-26 00:36:57.358532: train Epoch: [57][ 63/129]	Time  0.969 ( 1.876)	Data  0.002 ( 0.922)	Loss 1.2191e-01 (7.5439e-02) 
2023-05-26 00:37:00.418704: train Epoch: [57][ 64/129]	Time  3.060 ( 1.895)	Data  2.074 ( 0.940)	Loss 7.1117e-02 (7.5372e-02) 
2023-05-26 00:37:01.399248: train Epoch: [57][ 65/129]	Time  0.981 ( 1.881)	Data  0.001 ( 0.926)	Loss 6.4571e-02 (7.5209e-02) 
2023-05-26 00:37:04.696796: train Epoch: [57][ 66/129]	Time  3.298 ( 1.902)	Data  2.325 ( 0.947)	Loss 7.1255e-02 (7.5150e-02) 
2023-05-26 00:37:05.669897: train Epoch: [57][ 67/129]	Time  0.973 ( 1.888)	Data  0.001 ( 0.933)	Loss 5.6960e-02 (7.4882e-02) 
2023-05-26 00:37:08.783388: train Epoch: [57][ 68/129]	Time  3.113 ( 1.906)	Data  2.159 ( 0.951)	Loss 1.4977e-01 (7.5968e-02) 
2023-05-26 00:37:09.750195: train Epoch: [57][ 69/129]	Time  0.967 ( 1.893)	Data  0.001 ( 0.937)	Loss 5.4805e-02 (7.5665e-02) 
2023-05-26 00:37:12.930880: train Epoch: [57][ 70/129]	Time  3.181 ( 1.911)	Data  2.205 ( 0.955)	Loss 3.9442e-02 (7.5155e-02) 
2023-05-26 00:37:13.902821: train Epoch: [57][ 71/129]	Time  0.972 ( 1.898)	Data  0.001 ( 0.942)	Loss 7.8373e-02 (7.5200e-02) 
2023-05-26 00:37:16.937474: train Epoch: [57][ 72/129]	Time  3.035 ( 1.913)	Data  2.052 ( 0.957)	Loss 6.6180e-02 (7.5076e-02) 
2023-05-26 00:37:17.917172: train Epoch: [57][ 73/129]	Time  0.980 ( 1.901)	Data  0.001 ( 0.944)	Loss 7.1017e-02 (7.5021e-02) 
2023-05-26 00:37:20.957403: train Epoch: [57][ 74/129]	Time  3.040 ( 1.916)	Data  2.074 ( 0.959)	Loss 4.7859e-02 (7.4659e-02) 
2023-05-26 00:37:21.928594: train Epoch: [57][ 75/129]	Time  0.971 ( 1.903)	Data  0.001 ( 0.947)	Loss 7.8226e-02 (7.4706e-02) 
2023-05-26 00:37:24.995569: train Epoch: [57][ 76/129]	Time  3.067 ( 1.919)	Data  2.092 ( 0.961)	Loss 9.4531e-02 (7.4964e-02) 
2023-05-26 00:37:25.961290: train Epoch: [57][ 77/129]	Time  0.966 ( 1.906)	Data  0.001 ( 0.949)	Loss 6.2230e-02 (7.4800e-02) 
2023-05-26 00:37:29.116170: train Epoch: [57][ 78/129]	Time  3.155 ( 1.922)	Data  2.158 ( 0.964)	Loss 8.3659e-02 (7.4913e-02) 
2023-05-26 00:37:30.097116: train Epoch: [57][ 79/129]	Time  0.981 ( 1.910)	Data  0.001 ( 0.952)	Loss 3.2584e-02 (7.4383e-02) 
2023-05-26 00:37:33.232297: train Epoch: [57][ 80/129]	Time  3.135 ( 1.926)	Data  2.160 ( 0.967)	Loss 7.5124e-02 (7.4393e-02) 
2023-05-26 00:37:34.203280: train Epoch: [57][ 81/129]	Time  0.971 ( 1.914)	Data  0.001 ( 0.955)	Loss 6.7658e-02 (7.4310e-02) 
2023-05-26 00:37:37.132842: train Epoch: [57][ 82/129]	Time  2.930 ( 1.926)	Data  1.966 ( 0.968)	Loss 4.9429e-02 (7.4011e-02) 
2023-05-26 00:37:38.111330: train Epoch: [57][ 83/129]	Time  0.978 ( 1.915)	Data  0.001 ( 0.956)	Loss 9.3432e-02 (7.4242e-02) 
2023-05-26 00:37:41.182499: train Epoch: [57][ 84/129]	Time  3.071 ( 1.928)	Data  2.097 ( 0.970)	Loss 6.4179e-02 (7.4124e-02) 
2023-05-26 00:37:42.153936: train Epoch: [57][ 85/129]	Time  0.971 ( 1.917)	Data  0.001 ( 0.958)	Loss 5.4955e-02 (7.3901e-02) 
2023-05-26 00:37:45.181462: train Epoch: [57][ 86/129]	Time  3.028 ( 1.930)	Data  2.053 ( 0.971)	Loss 8.8898e-02 (7.4073e-02) 
2023-05-26 00:37:46.151275: train Epoch: [57][ 87/129]	Time  0.970 ( 1.919)	Data  0.001 ( 0.960)	Loss 5.4410e-02 (7.3850e-02) 
2023-05-26 00:37:49.152535: train Epoch: [57][ 88/129]	Time  3.001 ( 1.931)	Data  2.013 ( 0.972)	Loss 1.0138e-01 (7.4159e-02) 
2023-05-26 00:37:50.117243: train Epoch: [57][ 89/129]	Time  0.965 ( 1.921)	Data  0.001 ( 0.961)	Loss 7.9602e-02 (7.4219e-02) 
2023-05-26 00:37:53.170282: train Epoch: [57][ 90/129]	Time  3.053 ( 1.933)	Data  2.082 ( 0.973)	Loss 8.1286e-02 (7.4297e-02) 
2023-05-26 00:37:54.136967: train Epoch: [57][ 91/129]	Time  0.967 ( 1.923)	Data  0.001 ( 0.963)	Loss 1.5017e-01 (7.5122e-02) 
2023-05-26 00:37:57.280103: train Epoch: [57][ 92/129]	Time  3.143 ( 1.936)	Data  2.170 ( 0.976)	Loss 5.5709e-02 (7.4913e-02) 
2023-05-26 00:37:58.253698: train Epoch: [57][ 93/129]	Time  0.974 ( 1.925)	Data  0.002 ( 0.965)	Loss 4.1874e-02 (7.4562e-02) 
2023-05-26 00:38:01.400815: train Epoch: [57][ 94/129]	Time  3.147 ( 1.938)	Data  2.164 ( 0.978)	Loss 7.3546e-02 (7.4551e-02) 
2023-05-26 00:38:02.368512: train Epoch: [57][ 95/129]	Time  0.968 ( 1.928)	Data  0.001 ( 0.968)	Loss 5.7516e-02 (7.4373e-02) 
2023-05-26 00:38:05.557951: train Epoch: [57][ 96/129]	Time  3.189 ( 1.941)	Data  2.222 ( 0.981)	Loss 1.0323e-01 (7.4671e-02) 
2023-05-26 00:38:06.525970: train Epoch: [57][ 97/129]	Time  0.968 ( 1.931)	Data  0.001 ( 0.971)	Loss 8.6471e-02 (7.4791e-02) 
2023-05-26 00:38:09.658091: train Epoch: [57][ 98/129]	Time  3.132 ( 1.943)	Data  2.161 ( 0.983)	Loss 5.0573e-02 (7.4547e-02) 
2023-05-26 00:38:10.629721: train Epoch: [57][ 99/129]	Time  0.972 ( 1.934)	Data  0.001 ( 0.973)	Loss 4.7724e-02 (7.4278e-02) 
2023-05-26 00:38:13.845922: train Epoch: [57][100/129]	Time  3.216 ( 1.946)	Data  2.231 ( 0.985)	Loss 8.3838e-02 (7.4373e-02) 
2023-05-26 00:38:14.821512: train Epoch: [57][101/129]	Time  0.976 ( 1.937)	Data  0.002 ( 0.976)	Loss 5.3537e-02 (7.4169e-02) 
2023-05-26 00:38:17.960622: train Epoch: [57][102/129]	Time  3.139 ( 1.948)	Data  2.155 ( 0.987)	Loss 9.1556e-02 (7.4338e-02) 
2023-05-26 00:38:18.929790: train Epoch: [57][103/129]	Time  0.969 ( 1.939)	Data  0.001 ( 0.978)	Loss 5.9253e-02 (7.4193e-02) 
2023-05-26 00:38:22.124213: train Epoch: [57][104/129]	Time  3.194 ( 1.951)	Data  2.228 ( 0.990)	Loss 9.3139e-02 (7.4373e-02) 
2023-05-26 00:38:23.092371: train Epoch: [57][105/129]	Time  0.968 ( 1.942)	Data  0.001 ( 0.980)	Loss 8.5689e-02 (7.4480e-02) 
2023-05-26 00:38:26.172038: train Epoch: [57][106/129]	Time  3.080 ( 1.952)	Data  2.116 ( 0.991)	Loss 5.5246e-02 (7.4300e-02) 
2023-05-26 00:38:27.136974: train Epoch: [57][107/129]	Time  0.965 ( 1.943)	Data  0.001 ( 0.982)	Loss 7.0712e-02 (7.4267e-02) 
2023-05-26 00:38:30.238128: train Epoch: [57][108/129]	Time  3.101 ( 1.954)	Data  2.145 ( 0.992)	Loss 5.0234e-02 (7.4046e-02) 
2023-05-26 00:38:31.207038: train Epoch: [57][109/129]	Time  0.969 ( 1.945)	Data  0.001 ( 0.983)	Loss 9.9488e-02 (7.4278e-02) 
2023-05-26 00:38:34.248084: train Epoch: [57][110/129]	Time  3.041 ( 1.955)	Data  2.075 ( 0.993)	Loss 3.9537e-02 (7.3965e-02) 
2023-05-26 00:38:35.212985: train Epoch: [57][111/129]	Time  0.965 ( 1.946)	Data  0.001 ( 0.984)	Loss 1.1437e-01 (7.4325e-02) 
2023-05-26 00:38:38.399953: train Epoch: [57][112/129]	Time  3.187 ( 1.957)	Data  2.216 ( 0.995)	Loss 5.2087e-02 (7.4129e-02) 
2023-05-26 00:38:39.375724: train Epoch: [57][113/129]	Time  0.976 ( 1.948)	Data  0.001 ( 0.987)	Loss 8.1090e-02 (7.4190e-02) 
2023-05-26 00:38:42.278590: train Epoch: [57][114/129]	Time  2.903 ( 1.957)	Data  1.930 ( 0.995)	Loss 5.5707e-02 (7.4029e-02) 
2023-05-26 00:38:43.261742: train Epoch: [57][115/129]	Time  0.983 ( 1.948)	Data  0.002 ( 0.986)	Loss 7.0422e-02 (7.3998e-02) 
2023-05-26 00:38:46.282634: train Epoch: [57][116/129]	Time  3.021 ( 1.957)	Data  2.052 ( 0.995)	Loss 7.2348e-02 (7.3984e-02) 
2023-05-26 00:38:47.258899: train Epoch: [57][117/129]	Time  0.976 ( 1.949)	Data  0.001 ( 0.987)	Loss 5.9304e-02 (7.3859e-02) 
2023-05-26 00:38:50.440660: train Epoch: [57][118/129]	Time  3.182 ( 1.959)	Data  2.208 ( 0.997)	Loss 8.3654e-02 (7.3942e-02) 
2023-05-26 00:38:51.407709: train Epoch: [57][119/129]	Time  0.967 ( 1.951)	Data  0.001 ( 0.989)	Loss 7.1767e-02 (7.3924e-02) 
2023-05-26 00:38:54.590984: train Epoch: [57][120/129]	Time  3.183 ( 1.961)	Data  2.206 ( 0.999)	Loss 6.3073e-02 (7.3834e-02) 
2023-05-26 00:38:55.559280: train Epoch: [57][121/129]	Time  0.968 ( 1.953)	Data  0.001 ( 0.991)	Loss 8.2724e-02 (7.3907e-02) 
2023-05-26 00:38:58.671871: train Epoch: [57][122/129]	Time  3.113 ( 1.963)	Data  2.147 ( 1.000)	Loss 7.9412e-02 (7.3952e-02) 
2023-05-26 00:38:59.640554: train Epoch: [57][123/129]	Time  0.969 ( 1.955)	Data  0.001 ( 0.992)	Loss 1.0717e-01 (7.4219e-02) 
2023-05-26 00:39:02.759214: train Epoch: [57][124/129]	Time  3.119 ( 1.964)	Data  2.144 ( 1.001)	Loss 7.7424e-02 (7.4245e-02) 
2023-05-26 00:39:03.733824: train Epoch: [57][125/129]	Time  0.975 ( 1.956)	Data  0.001 ( 0.993)	Loss 5.6421e-02 (7.4104e-02) 
2023-05-26 00:39:06.789969: train Epoch: [57][126/129]	Time  3.056 ( 1.965)	Data  2.089 ( 1.002)	Loss 5.6177e-02 (7.3962e-02) 
2023-05-26 00:39:07.755513: train Epoch: [57][127/129]	Time  0.966 ( 1.957)	Data  0.001 ( 0.994)	Loss 5.0088e-02 (7.3776e-02) 
2023-05-26 00:39:09.880992: train Epoch: [57][128/129]	Time  2.125 ( 1.958)	Data  1.161 ( 0.995)	Loss 6.3191e-02 (7.3694e-02) 
2023-05-26 00:39:09.927995: Train Epoch done in 252.66226681099943 s 
2023-05-26 00:39:12.727003: val Epoch: [57][ 0/72]	Time  1.817 ( 1.817)	Data  1.556 ( 1.556)	Loss 3.0327e-02 (3.0327e-02) 
2023-05-26 00:39:12.870676: val Epoch: [57][ 1/72]	Time  0.144 ( 0.980)	Data  0.002 ( 0.779)	Loss 6.1321e-02 (4.5824e-02) 
2023-05-26 00:39:13.970689: val Epoch: [57][ 2/72]	Time  1.100 ( 1.020)	Data  0.960 ( 0.839)	Loss 8.0964e-02 (5.7538e-02) 
2023-05-26 00:39:14.100148: val Epoch: [57][ 3/72]	Time  0.129 ( 0.798)	Data  0.001 ( 0.630)	Loss 1.4161e-01 (7.8556e-02) 
2023-05-26 00:39:15.391090: val Epoch: [57][ 4/72]	Time  1.291 ( 0.896)	Data  1.144 ( 0.733)	Loss 3.2790e-01 (1.2843e-01) 
2023-05-26 00:39:15.529363: val Epoch: [57][ 5/72]	Time  0.138 ( 0.770)	Data  0.001 ( 0.611)	Loss 3.5332e-01 (1.6591e-01) 
2023-05-26 00:39:16.799819: val Epoch: [57][ 6/72]	Time  1.270 ( 0.841)	Data  1.134 ( 0.685)	Loss 3.9248e-02 (1.4781e-01) 
2023-05-26 00:39:16.928508: val Epoch: [57][ 7/72]	Time  0.129 ( 0.752)	Data  0.001 ( 0.600)	Loss 7.5682e-02 (1.3880e-01) 
2023-05-26 00:39:18.075169: val Epoch: [57][ 8/72]	Time  1.147 ( 0.796)	Data  1.019 ( 0.646)	Loss 3.8736e-02 (1.2768e-01) 
2023-05-26 00:39:18.243289: val Epoch: [57][ 9/72]	Time  0.168 ( 0.733)	Data  0.022 ( 0.584)	Loss 4.5573e-02 (1.1947e-01) 
2023-05-26 00:39:19.404937: val Epoch: [57][10/72]	Time  1.162 ( 0.772)	Data  1.033 ( 0.625)	Loss 5.5245e-02 (1.1363e-01) 
2023-05-26 00:39:19.595487: val Epoch: [57][11/72]	Time  0.191 ( 0.724)	Data  0.059 ( 0.578)	Loss 4.4442e-02 (1.0786e-01) 
2023-05-26 00:39:20.707018: val Epoch: [57][12/72]	Time  1.112 ( 0.754)	Data  0.978 ( 0.608)	Loss 1.0283e-01 (1.0748e-01) 
2023-05-26 00:39:21.004329: val Epoch: [57][13/72]	Time  0.297 ( 0.721)	Data  0.153 ( 0.576)	Loss 1.8527e-01 (1.1303e-01) 
2023-05-26 00:39:22.174358: val Epoch: [57][14/72]	Time  1.170 ( 0.751)	Data  1.040 ( 0.607)	Loss 7.4799e-02 (1.1048e-01) 
2023-05-26 00:39:22.403052: val Epoch: [57][15/72]	Time  0.229 ( 0.718)	Data  0.075 ( 0.574)	Loss 5.1131e-02 (1.0677e-01) 
2023-05-26 00:39:23.590731: val Epoch: [57][16/72]	Time  1.188 ( 0.746)	Data  1.058 ( 0.602)	Loss 8.0782e-02 (1.0525e-01) 
2023-05-26 00:39:23.799615: val Epoch: [57][17/72]	Time  0.209 ( 0.716)	Data  0.068 ( 0.572)	Loss 9.7224e-02 (1.0480e-01) 
2023-05-26 00:39:25.024527: val Epoch: [57][18/72]	Time  1.225 ( 0.743)	Data  1.083 ( 0.599)	Loss 1.2146e-01 (1.0568e-01) 
2023-05-26 00:39:25.240700: val Epoch: [57][19/72]	Time  0.216 ( 0.717)	Data  0.079 ( 0.573)	Loss 4.1143e-01 (1.2096e-01) 
2023-05-26 00:39:26.387395: val Epoch: [57][20/72]	Time  1.147 ( 0.737)	Data  1.008 ( 0.594)	Loss 5.4369e-02 (1.1779e-01) 
2023-05-26 00:39:26.654440: val Epoch: [57][21/72]	Time  0.267 ( 0.716)	Data  0.128 ( 0.573)	Loss 1.3223e-01 (1.1845e-01) 
2023-05-26 00:39:27.723531: val Epoch: [57][22/72]	Time  1.069 ( 0.731)	Data  0.933 ( 0.588)	Loss 2.3472e-01 (1.2351e-01) 
2023-05-26 00:39:28.011873: val Epoch: [57][23/72]	Time  0.288 ( 0.713)	Data  0.149 ( 0.570)	Loss 3.4520e-02 (1.1980e-01) 
2023-05-26 00:39:29.099876: val Epoch: [57][24/72]	Time  1.088 ( 0.728)	Data  0.960 ( 0.586)	Loss 8.5389e-02 (1.1842e-01) 
2023-05-26 00:39:29.313015: val Epoch: [57][25/72]	Time  0.213 ( 0.708)	Data  0.088 ( 0.567)	Loss 4.6584e-02 (1.1566e-01) 
2023-05-26 00:39:30.453314: val Epoch: [57][26/72]	Time  1.140 ( 0.724)	Data  1.003 ( 0.583)	Loss 3.6941e-02 (1.1274e-01) 
2023-05-26 00:39:30.681195: val Epoch: [57][27/72]	Time  0.228 ( 0.706)	Data  0.086 ( 0.565)	Loss 4.2737e-02 (1.1024e-01) 
2023-05-26 00:39:31.788362: val Epoch: [57][28/72]	Time  1.107 ( 0.720)	Data  0.980 ( 0.579)	Loss 4.8009e-02 (1.0810e-01) 
2023-05-26 00:39:31.978582: val Epoch: [57][29/72]	Time  0.190 ( 0.702)	Data  0.060 ( 0.562)	Loss 5.7661e-02 (1.0642e-01) 
2023-05-26 00:39:33.155371: val Epoch: [57][30/72]	Time  1.177 ( 0.718)	Data  1.036 ( 0.577)	Loss 3.8543e-02 (1.0423e-01) 
2023-05-26 00:39:33.348628: val Epoch: [57][31/72]	Time  0.193 ( 0.701)	Data  0.067 ( 0.561)	Loss 6.8257e-02 (1.0310e-01) 
2023-05-26 00:39:34.500629: val Epoch: [57][32/72]	Time  1.152 ( 0.715)	Data  1.023 ( 0.575)	Loss 3.9036e-01 (1.1181e-01) 
2023-05-26 00:39:34.683642: val Epoch: [57][33/72]	Time  0.183 ( 0.699)	Data  0.053 ( 0.560)	Loss 9.1485e-02 (1.1121e-01) 
2023-05-26 00:39:35.905552: val Epoch: [57][34/72]	Time  1.222 ( 0.714)	Data  1.086 ( 0.575)	Loss 2.0523e-01 (1.1390e-01) 
2023-05-26 00:39:36.113157: val Epoch: [57][35/72]	Time  0.208 ( 0.700)	Data  0.065 ( 0.561)	Loss 3.0886e-01 (1.1931e-01) 
2023-05-26 00:39:37.274520: val Epoch: [57][36/72]	Time  1.161 ( 0.713)	Data  1.034 ( 0.574)	Loss 1.7365e-01 (1.2078e-01) 
2023-05-26 00:39:37.471523: val Epoch: [57][37/72]	Time  0.197 ( 0.699)	Data  0.062 ( 0.560)	Loss 2.1814e-01 (1.2334e-01) 
2023-05-26 00:39:38.655506: val Epoch: [57][38/72]	Time  1.184 ( 0.711)	Data  1.047 ( 0.573)	Loss 5.4412e-02 (1.2157e-01) 
2023-05-26 00:39:38.864210: val Epoch: [57][39/72]	Time  0.209 ( 0.699)	Data  0.069 ( 0.560)	Loss 7.4181e-02 (1.2039e-01) 
2023-05-26 00:39:40.012127: val Epoch: [57][40/72]	Time  1.148 ( 0.710)	Data  1.018 ( 0.571)	Loss 1.8302e-01 (1.2192e-01) 
2023-05-26 00:39:40.197733: val Epoch: [57][41/72]	Time  0.186 ( 0.697)	Data  0.055 ( 0.559)	Loss 4.9069e-02 (1.2018e-01) 
2023-05-26 00:39:41.379240: val Epoch: [57][42/72]	Time  1.182 ( 0.709)	Data  1.051 ( 0.570)	Loss 7.5899e-02 (1.1915e-01) 
2023-05-26 00:39:41.526467: val Epoch: [57][43/72]	Time  0.147 ( 0.696)	Data  0.017 ( 0.558)	Loss 7.0076e-02 (1.1804e-01) 
2023-05-26 00:39:42.702281: val Epoch: [57][44/72]	Time  1.176 ( 0.706)	Data  1.043 ( 0.569)	Loss 1.1880e-01 (1.1805e-01) 
2023-05-26 00:39:42.885392: val Epoch: [57][45/72]	Time  0.183 ( 0.695)	Data  0.054 ( 0.557)	Loss 1.4991e-01 (1.1875e-01) 
2023-05-26 00:39:44.104918: val Epoch: [57][46/72]	Time  1.220 ( 0.706)	Data  1.084 ( 0.569)	Loss 5.6543e-02 (1.1742e-01) 
2023-05-26 00:39:44.242889: val Epoch: [57][47/72]	Time  0.138 ( 0.694)	Data  0.008 ( 0.557)	Loss 4.1205e-02 (1.1584e-01) 
2023-05-26 00:39:45.425789: val Epoch: [57][48/72]	Time  1.183 ( 0.704)	Data  1.053 ( 0.567)	Loss 1.1879e-01 (1.1590e-01) 
2023-05-26 00:39:45.583271: val Epoch: [57][49/72]	Time  0.157 ( 0.693)	Data  0.025 ( 0.556)	Loss 9.9125e-02 (1.1556e-01) 
2023-05-26 00:39:46.709252: val Epoch: [57][50/72]	Time  1.126 ( 0.702)	Data  0.995 ( 0.565)	Loss 5.5783e-02 (1.1439e-01) 
2023-05-26 00:39:46.954926: val Epoch: [57][51/72]	Time  0.246 ( 0.693)	Data  0.116 ( 0.556)	Loss 4.6155e-02 (1.1308e-01) 
2023-05-26 00:39:48.030515: val Epoch: [57][52/72]	Time  1.076 ( 0.700)	Data  0.944 ( 0.564)	Loss 7.1675e-02 (1.1230e-01) 
2023-05-26 00:39:48.328974: val Epoch: [57][53/72]	Time  0.298 ( 0.693)	Data  0.166 ( 0.556)	Loss 9.3348e-02 (1.1194e-01) 
2023-05-26 00:39:49.415724: val Epoch: [57][54/72]	Time  1.087 ( 0.700)	Data  0.956 ( 0.563)	Loss 8.8888e-02 (1.1152e-01) 
2023-05-26 00:39:49.720554: val Epoch: [57][55/72]	Time  0.305 ( 0.693)	Data  0.172 ( 0.556)	Loss 2.3467e-01 (1.1372e-01) 
2023-05-26 00:39:50.760668: val Epoch: [57][56/72]	Time  1.040 ( 0.699)	Data  0.912 ( 0.563)	Loss 4.9261e-02 (1.1259e-01) 
2023-05-26 00:39:51.084679: val Epoch: [57][57/72]	Time  0.324 ( 0.693)	Data  0.197 ( 0.556)	Loss 1.0293e-01 (1.1243e-01) 
2023-05-26 00:39:52.161302: val Epoch: [57][58/72]	Time  1.077 ( 0.699)	Data  0.949 ( 0.563)	Loss 1.4235e-01 (1.1293e-01) 
2023-05-26 00:39:52.427145: val Epoch: [57][59/72]	Time  0.266 ( 0.692)	Data  0.138 ( 0.556)	Loss 8.2287e-02 (1.1242e-01) 
2023-05-26 00:39:53.449165: val Epoch: [57][60/72]	Time  1.022 ( 0.697)	Data  0.894 ( 0.561)	Loss 6.1852e-02 (1.1159e-01) 
2023-05-26 00:39:53.734885: val Epoch: [57][61/72]	Time  0.286 ( 0.691)	Data  0.156 ( 0.555)	Loss 6.0441e-02 (1.1077e-01) 
2023-05-26 00:39:54.787756: val Epoch: [57][62/72]	Time  1.053 ( 0.696)	Data  0.926 ( 0.561)	Loss 5.2424e-02 (1.0984e-01) 
2023-05-26 00:39:55.122433: val Epoch: [57][63/72]	Time  0.335 ( 0.691)	Data  0.204 ( 0.555)	Loss 6.9899e-02 (1.0922e-01) 
2023-05-26 00:39:56.188903: val Epoch: [57][64/72]	Time  1.066 ( 0.697)	Data  0.938 ( 0.561)	Loss 6.2288e-02 (1.0850e-01) 
2023-05-26 00:39:56.508327: val Epoch: [57][65/72]	Time  0.319 ( 0.691)	Data  0.187 ( 0.555)	Loss 8.9059e-02 (1.0820e-01) 
2023-05-26 00:39:57.551916: val Epoch: [57][66/72]	Time  1.044 ( 0.696)	Data  0.916 ( 0.561)	Loss 3.7937e-01 (1.1225e-01) 
2023-05-26 00:39:57.853090: val Epoch: [57][67/72]	Time  0.301 ( 0.690)	Data  0.174 ( 0.555)	Loss 3.9556e-02 (1.1118e-01) 
2023-05-26 00:39:58.952369: val Epoch: [57][68/72]	Time  1.099 ( 0.696)	Data  0.970 ( 0.561)	Loss 4.5817e-02 (1.1023e-01) 
2023-05-26 00:39:59.241763: val Epoch: [57][69/72]	Time  0.289 ( 0.690)	Data  0.159 ( 0.555)	Loss 3.5289e-01 (1.1370e-01) 
2023-05-26 00:40:00.395516: val Epoch: [57][70/72]	Time  1.154 ( 0.697)	Data  1.004 ( 0.562)	Loss 3.3363e-01 (1.1680e-01) 
2023-05-26 00:40:00.604544: val Epoch: [57][71/72]	Time  0.209 ( 0.690)	Data  0.077 ( 0.555)	Loss 2.7632e-01 (1.1901e-01) 
2023-05-26 00:40:00.797934: Epoch 57 :Val : ['ET : 0.7721841335296631', 'TC : 0.7908501029014587', 'WT : 0.8803666234016418'] 
2023-05-26 00:40:00.798833: Epoch 57 :Val : ['ET : 0.7721841335296631', 'TC : 0.7908501029014587', 'WT : 0.8803666234016418'] 
2023-05-26 00:40:00.801913: Val epoch done in 50.873921186997904 s 
2023-05-26 00:40:00.811503: Batches per epoch:  129 
2023-05-26 00:40:06.304438: train Epoch: [58][  0/129]	Time  5.492 ( 5.492)	Data  4.449 ( 4.449)	Loss 6.2192e-02 (6.2192e-02) 
2023-05-26 00:40:07.277022: train Epoch: [58][  1/129]	Time  0.973 ( 3.232)	Data  0.001 ( 2.225)	Loss 6.9350e-02 (6.5771e-02) 
2023-05-26 00:40:10.235860: train Epoch: [58][  2/129]	Time  2.959 ( 3.141)	Data  1.981 ( 2.144)	Loss 5.3357e-02 (6.1633e-02) 
2023-05-26 00:40:11.207741: train Epoch: [58][  3/129]	Time  0.972 ( 2.599)	Data  0.001 ( 1.608)	Loss 1.2210e-01 (7.6749e-02) 
2023-05-26 00:40:14.153105: train Epoch: [58][  4/129]	Time  2.945 ( 2.668)	Data  1.967 ( 1.680)	Loss 8.3319e-02 (7.8063e-02) 
2023-05-26 00:40:15.127634: train Epoch: [58][  5/129]	Time  0.975 ( 2.386)	Data  0.001 ( 1.400)	Loss 7.6444e-02 (7.7793e-02) 
2023-05-26 00:40:18.160769: train Epoch: [58][  6/129]	Time  3.033 ( 2.478)	Data  2.062 ( 1.495)	Loss 7.2945e-02 (7.7100e-02) 
2023-05-26 00:40:19.128310: train Epoch: [58][  7/129]	Time  0.968 ( 2.290)	Data  0.001 ( 1.308)	Loss 5.8622e-02 (7.4790e-02) 
2023-05-26 00:40:22.117260: train Epoch: [58][  8/129]	Time  2.989 ( 2.367)	Data  2.020 ( 1.387)	Loss 3.9911e-02 (7.0915e-02) 
2023-05-26 00:40:23.091653: train Epoch: [58][  9/129]	Time  0.974 ( 2.228)	Data  0.001 ( 1.249)	Loss 4.4323e-02 (6.8256e-02) 
2023-05-26 00:40:26.199769: train Epoch: [58][ 10/129]	Time  3.108 ( 2.308)	Data  2.135 ( 1.329)	Loss 4.1123e-02 (6.5789e-02) 
2023-05-26 00:40:27.174195: train Epoch: [58][ 11/129]	Time  0.974 ( 2.197)	Data  0.001 ( 1.218)	Loss 5.4488e-02 (6.4847e-02) 
2023-05-26 00:40:30.197442: train Epoch: [58][ 12/129]	Time  3.023 ( 2.260)	Data  2.046 ( 1.282)	Loss 1.4547e-01 (7.1049e-02) 
2023-05-26 00:40:31.183705: train Epoch: [58][ 13/129]	Time  0.986 ( 2.169)	Data  0.002 ( 1.191)	Loss 7.8711e-02 (7.1596e-02) 
2023-05-26 00:40:34.166415: train Epoch: [58][ 14/129]	Time  2.983 ( 2.224)	Data  1.992 ( 1.244)	Loss 1.3406e-01 (7.5761e-02) 
2023-05-26 00:40:35.133373: train Epoch: [58][ 15/129]	Time  0.967 ( 2.145)	Data  0.001 ( 1.166)	Loss 6.4799e-02 (7.5076e-02) 
2023-05-26 00:40:38.144871: train Epoch: [58][ 16/129]	Time  3.011 ( 2.196)	Data  2.025 ( 1.217)	Loss 8.6207e-02 (7.5730e-02) 
2023-05-26 00:40:39.116893: train Epoch: [58][ 17/129]	Time  0.972 ( 2.128)	Data  0.001 ( 1.149)	Loss 4.6606e-02 (7.4112e-02) 
2023-05-26 00:40:42.215679: train Epoch: [58][ 18/129]	Time  3.099 ( 2.179)	Data  2.122 ( 1.201)	Loss 8.4271e-02 (7.4647e-02) 
2023-05-26 00:40:43.184335: train Epoch: [58][ 19/129]	Time  0.969 ( 2.119)	Data  0.001 ( 1.141)	Loss 4.9470e-02 (7.3388e-02) 
2023-05-26 00:40:46.270778: train Epoch: [58][ 20/129]	Time  3.086 ( 2.165)	Data  2.117 ( 1.187)	Loss 6.2691e-02 (7.2879e-02) 
2023-05-26 00:40:47.255097: train Epoch: [58][ 21/129]	Time  0.984 ( 2.111)	Data  0.002 ( 1.133)	Loss 7.7298e-02 (7.3080e-02) 
2023-05-26 00:40:50.278108: train Epoch: [58][ 22/129]	Time  3.023 ( 2.151)	Data  2.053 ( 1.173)	Loss 5.6061e-02 (7.2340e-02) 
2023-05-26 00:40:51.250859: train Epoch: [58][ 23/129]	Time  0.973 ( 2.102)	Data  0.001 ( 1.124)	Loss 1.2408e-01 (7.4496e-02) 
2023-05-26 00:40:54.349394: train Epoch: [58][ 24/129]	Time  3.099 ( 2.141)	Data  2.132 ( 1.165)	Loss 8.7455e-02 (7.5014e-02) 
2023-05-26 00:40:55.317874: train Epoch: [58][ 25/129]	Time  0.968 ( 2.096)	Data  0.001 ( 1.120)	Loss 6.2510e-02 (7.4533e-02) 
2023-05-26 00:40:58.348924: train Epoch: [58][ 26/129]	Time  3.031 ( 2.131)	Data  2.061 ( 1.155)	Loss 6.4657e-02 (7.4167e-02) 
2023-05-26 00:40:59.345062: train Epoch: [58][ 27/129]	Time  0.996 ( 2.090)	Data  0.001 ( 1.114)	Loss 4.9012e-02 (7.3269e-02) 
2023-05-26 00:41:02.479143: train Epoch: [58][ 28/129]	Time  3.134 ( 2.126)	Data  2.150 ( 1.149)	Loss 6.8269e-02 (7.3097e-02) 
2023-05-26 00:41:03.474490: train Epoch: [58][ 29/129]	Time  0.995 ( 2.089)	Data  0.002 ( 1.111)	Loss 9.2432e-02 (7.3741e-02) 
2023-05-26 00:41:06.420140: train Epoch: [58][ 30/129]	Time  2.946 ( 2.116)	Data  1.967 ( 1.139)	Loss 9.7714e-02 (7.4514e-02) 
2023-05-26 00:41:07.398284: train Epoch: [58][ 31/129]	Time  0.978 ( 2.081)	Data  0.002 ( 1.103)	Loss 1.0315e-01 (7.5409e-02) 
2023-05-26 00:41:10.483210: train Epoch: [58][ 32/129]	Time  3.085 ( 2.111)	Data  2.111 ( 1.134)	Loss 6.8924e-02 (7.5213e-02) 
2023-05-26 00:41:11.457491: train Epoch: [58][ 33/129]	Time  0.974 ( 2.078)	Data  0.001 ( 1.100)	Loss 4.8347e-02 (7.4422e-02) 
2023-05-26 00:41:14.584551: train Epoch: [58][ 34/129]	Time  3.127 ( 2.108)	Data  2.144 ( 1.130)	Loss 9.3413e-02 (7.4965e-02) 
2023-05-26 00:41:15.556454: train Epoch: [58][ 35/129]	Time  0.972 ( 2.076)	Data  0.001 ( 1.099)	Loss 7.7765e-02 (7.5043e-02) 
2023-05-26 00:41:18.682938: train Epoch: [58][ 36/129]	Time  3.126 ( 2.105)	Data  2.163 ( 1.128)	Loss 4.2376e-02 (7.4160e-02) 
2023-05-26 00:41:19.659398: train Epoch: [58][ 37/129]	Time  0.976 ( 2.075)	Data  0.001 ( 1.098)	Loss 5.6761e-02 (7.3702e-02) 
2023-05-26 00:41:22.744437: train Epoch: [58][ 38/129]	Time  3.085 ( 2.101)	Data  2.121 ( 1.124)	Loss 7.2048e-02 (7.3660e-02) 
2023-05-26 00:41:23.721112: train Epoch: [58][ 39/129]	Time  0.977 ( 2.073)	Data  0.001 ( 1.096)	Loss 7.1186e-02 (7.3598e-02) 
2023-05-26 00:41:26.807607: train Epoch: [58][ 40/129]	Time  3.086 ( 2.097)	Data  2.121 ( 1.121)	Loss 7.6388e-02 (7.3666e-02) 
2023-05-26 00:41:27.779834: train Epoch: [58][ 41/129]	Time  0.972 ( 2.071)	Data  0.001 ( 1.094)	Loss 6.6823e-02 (7.3503e-02) 
2023-05-26 00:41:30.934915: train Epoch: [58][ 42/129]	Time  3.155 ( 2.096)	Data  2.191 ( 1.120)	Loss 5.1176e-02 (7.2984e-02) 
2023-05-26 00:41:31.908643: train Epoch: [58][ 43/129]	Time  0.974 ( 2.070)	Data  0.002 ( 1.095)	Loss 5.4814e-02 (7.2571e-02) 
2023-05-26 00:41:35.184740: train Epoch: [58][ 44/129]	Time  3.276 ( 2.097)	Data  2.305 ( 1.121)	Loss 6.2044e-02 (7.2337e-02) 
2023-05-26 00:41:36.160747: train Epoch: [58][ 45/129]	Time  0.976 ( 2.073)	Data  0.001 ( 1.097)	Loss 9.5184e-02 (7.2833e-02) 
2023-05-26 00:41:39.214894: train Epoch: [58][ 46/129]	Time  3.054 ( 2.094)	Data  2.080 ( 1.118)	Loss 6.7284e-02 (7.2715e-02) 
2023-05-26 00:41:40.190641: train Epoch: [58][ 47/129]	Time  0.976 ( 2.070)	Data  0.001 ( 1.095)	Loss 1.0180e-01 (7.3321e-02) 
2023-05-26 00:41:43.254477: train Epoch: [58][ 48/129]	Time  3.064 ( 2.091)	Data  2.099 ( 1.115)	Loss 7.2803e-02 (7.3311e-02) 
2023-05-26 00:41:44.223725: train Epoch: [58][ 49/129]	Time  0.969 ( 2.068)	Data  0.001 ( 1.093)	Loss 5.5607e-02 (7.2957e-02) 
2023-05-26 00:41:47.402567: train Epoch: [58][ 50/129]	Time  3.179 ( 2.090)	Data  2.211 ( 1.115)	Loss 5.8082e-02 (7.2665e-02) 
2023-05-26 00:41:48.381484: train Epoch: [58][ 51/129]	Time  0.979 ( 2.069)	Data  0.001 ( 1.093)	Loss 9.2913e-02 (7.3054e-02) 
2023-05-26 00:41:51.446605: train Epoch: [58][ 52/129]	Time  3.065 ( 2.087)	Data  2.101 ( 1.112)	Loss 1.3472e-01 (7.4218e-02) 
2023-05-26 00:41:52.432916: train Epoch: [58][ 53/129]	Time  0.986 ( 2.067)	Data  0.001 ( 1.092)	Loss 5.6487e-02 (7.3890e-02) 
2023-05-26 00:41:55.580523: train Epoch: [58][ 54/129]	Time  3.148 ( 2.087)	Data  2.158 ( 1.111)	Loss 7.0616e-02 (7.3830e-02) 
2023-05-26 00:41:56.565006: train Epoch: [58][ 55/129]	Time  0.984 ( 2.067)	Data  0.001 ( 1.091)	Loss 9.2129e-02 (7.4157e-02) 
2023-05-26 00:41:59.594900: train Epoch: [58][ 56/129]	Time  3.030 ( 2.084)	Data  2.063 ( 1.108)	Loss 9.5738e-02 (7.4536e-02) 
2023-05-26 00:42:00.552083: train Epoch: [58][ 57/129]	Time  0.957 ( 2.064)	Data  0.001 ( 1.089)	Loss 1.1195e-01 (7.5181e-02) 
2023-05-26 00:42:03.734622: train Epoch: [58][ 58/129]	Time  3.183 ( 2.083)	Data  2.211 ( 1.108)	Loss 9.9570e-02 (7.5594e-02) 
2023-05-26 00:42:04.711366: train Epoch: [58][ 59/129]	Time  0.977 ( 2.065)	Data  0.001 ( 1.090)	Loss 5.8536e-02 (7.5310e-02) 
2023-05-26 00:42:07.860670: train Epoch: [58][ 60/129]	Time  3.149 ( 2.083)	Data  2.178 ( 1.108)	Loss 4.9754e-02 (7.4891e-02) 
2023-05-26 00:42:08.834352: train Epoch: [58][ 61/129]	Time  0.974 ( 2.065)	Data  0.001 ( 1.090)	Loss 8.0901e-02 (7.4988e-02) 
2023-05-26 00:42:11.912981: train Epoch: [58][ 62/129]	Time  3.079 ( 2.081)	Data  2.113 ( 1.106)	Loss 5.5516e-02 (7.4679e-02) 
2023-05-26 00:42:12.883174: train Epoch: [58][ 63/129]	Time  0.970 ( 2.064)	Data  0.001 ( 1.089)	Loss 5.7450e-02 (7.4409e-02) 
2023-05-26 00:42:16.127554: train Epoch: [58][ 64/129]	Time  3.244 ( 2.082)	Data  2.276 ( 1.107)	Loss 3.8016e-02 (7.3849e-02) 
2023-05-26 00:42:17.119543: train Epoch: [58][ 65/129]	Time  0.992 ( 2.065)	Data  0.001 ( 1.090)	Loss 8.0128e-02 (7.3945e-02) 
2023-05-26 00:42:20.059329: train Epoch: [58][ 66/129]	Time  2.940 ( 2.078)	Data  1.965 ( 1.103)	Loss 9.0103e-02 (7.4186e-02) 
2023-05-26 00:42:21.029608: train Epoch: [58][ 67/129]	Time  0.970 ( 2.062)	Data  0.001 ( 1.087)	Loss 4.9184e-02 (7.3818e-02) 
2023-05-26 00:42:24.271105: train Epoch: [58][ 68/129]	Time  3.242 ( 2.079)	Data  2.261 ( 1.104)	Loss 7.3644e-02 (7.3816e-02) 
2023-05-26 00:42:25.253457: train Epoch: [58][ 69/129]	Time  0.982 ( 2.063)	Data  0.001 ( 1.088)	Loss 4.9468e-02 (7.3468e-02) 
2023-05-26 00:42:28.378492: train Epoch: [58][ 70/129]	Time  3.125 ( 2.078)	Data  2.148 ( 1.103)	Loss 6.2884e-02 (7.3319e-02) 
2023-05-26 00:42:29.354080: train Epoch: [58][ 71/129]	Time  0.976 ( 2.063)	Data  0.001 ( 1.088)	Loss 6.4629e-02 (7.3198e-02) 
2023-05-26 00:42:32.247473: train Epoch: [58][ 72/129]	Time  2.893 ( 2.074)	Data  1.915 ( 1.099)	Loss 9.8092e-02 (7.3539e-02) 
2023-05-26 00:42:33.219851: train Epoch: [58][ 73/129]	Time  0.972 ( 2.060)	Data  0.001 ( 1.085)	Loss 1.1696e-01 (7.4126e-02) 
2023-05-26 00:42:36.352872: train Epoch: [58][ 74/129]	Time  3.133 ( 2.074)	Data  2.157 ( 1.099)	Loss 1.1071e-01 (7.4613e-02) 
2023-05-26 00:42:37.332650: train Epoch: [58][ 75/129]	Time  0.980 ( 2.059)	Data  0.001 ( 1.084)	Loss 3.3867e-02 (7.4077e-02) 
2023-05-26 00:42:40.348899: train Epoch: [58][ 76/129]	Time  3.016 ( 2.072)	Data  2.044 ( 1.097)	Loss 9.9614e-02 (7.4409e-02) 
2023-05-26 00:42:41.315573: train Epoch: [58][ 77/129]	Time  0.967 ( 2.058)	Data  0.001 ( 1.083)	Loss 4.0777e-02 (7.3978e-02) 
2023-05-26 00:42:44.403811: train Epoch: [58][ 78/129]	Time  3.088 ( 2.071)	Data  2.089 ( 1.096)	Loss 9.4517e-02 (7.4238e-02) 
2023-05-26 00:42:45.372985: train Epoch: [58][ 79/129]	Time  0.969 ( 2.057)	Data  0.001 ( 1.082)	Loss 6.8413e-02 (7.4165e-02) 
2023-05-26 00:42:48.427163: train Epoch: [58][ 80/129]	Time  3.054 ( 2.069)	Data  2.084 ( 1.094)	Loss 6.8236e-02 (7.4092e-02) 
2023-05-26 00:42:49.411885: train Epoch: [58][ 81/129]	Time  0.985 ( 2.056)	Data  0.001 ( 1.081)	Loss 5.8049e-02 (7.3896e-02) 
2023-05-26 00:42:52.527048: train Epoch: [58][ 82/129]	Time  3.115 ( 2.069)	Data  2.133 ( 1.094)	Loss 4.6736e-02 (7.3569e-02) 
2023-05-26 00:42:53.504847: train Epoch: [58][ 83/129]	Time  0.978 ( 2.056)	Data  0.001 ( 1.081)	Loss 1.0632e-01 (7.3959e-02) 
2023-05-26 00:42:56.652858: train Epoch: [58][ 84/129]	Time  3.148 ( 2.069)	Data  2.164 ( 1.093)	Loss 8.6368e-02 (7.4105e-02) 
2023-05-26 00:42:57.626914: train Epoch: [58][ 85/129]	Time  0.974 ( 2.056)	Data  0.001 ( 1.081)	Loss 5.5873e-02 (7.3893e-02) 
2023-05-26 00:43:00.763758: train Epoch: [58][ 86/129]	Time  3.137 ( 2.068)	Data  2.159 ( 1.093)	Loss 4.6513e-02 (7.3578e-02) 
2023-05-26 00:43:01.742242: train Epoch: [58][ 87/129]	Time  0.978 ( 2.056)	Data  0.001 ( 1.081)	Loss 6.7032e-02 (7.3504e-02) 
2023-05-26 00:43:04.823876: train Epoch: [58][ 88/129]	Time  3.082 ( 2.068)	Data  2.114 ( 1.092)	Loss 8.3058e-02 (7.3611e-02) 
2023-05-26 00:43:05.794771: train Epoch: [58][ 89/129]	Time  0.971 ( 2.055)	Data  0.001 ( 1.080)	Loss 7.0333e-02 (7.3575e-02) 
2023-05-26 00:43:08.845335: train Epoch: [58][ 90/129]	Time  3.051 ( 2.066)	Data  2.083 ( 1.091)	Loss 7.3573e-02 (7.3575e-02) 
2023-05-26 00:43:09.822094: train Epoch: [58][ 91/129]	Time  0.977 ( 2.054)	Data  0.001 ( 1.079)	Loss 1.1275e-01 (7.4000e-02) 
2023-05-26 00:43:12.834236: train Epoch: [58][ 92/129]	Time  3.012 ( 2.065)	Data  2.031 ( 1.090)	Loss 1.0822e-01 (7.4368e-02) 
2023-05-26 00:43:13.802832: train Epoch: [58][ 93/129]	Time  0.969 ( 2.053)	Data  0.001 ( 1.078)	Loss 8.8111e-02 (7.4515e-02) 
2023-05-26 00:43:16.759305: train Epoch: [58][ 94/129]	Time  2.956 ( 2.063)	Data  1.989 ( 1.088)	Loss 7.9816e-02 (7.4570e-02) 
2023-05-26 00:43:17.727192: train Epoch: [58][ 95/129]	Time  0.968 ( 2.051)	Data  0.001 ( 1.076)	Loss 8.2950e-02 (7.4658e-02) 
2023-05-26 00:43:20.980181: train Epoch: [58][ 96/129]	Time  3.253 ( 2.064)	Data  2.294 ( 1.089)	Loss 6.0256e-02 (7.4509e-02) 
2023-05-26 00:43:21.964474: train Epoch: [58][ 97/129]	Time  0.984 ( 2.053)	Data  0.001 ( 1.078)	Loss 6.3546e-02 (7.4397e-02) 
2023-05-26 00:43:25.104510: train Epoch: [58][ 98/129]	Time  3.140 ( 2.064)	Data  2.164 ( 1.089)	Loss 6.4337e-02 (7.4296e-02) 
2023-05-26 00:43:26.092678: train Epoch: [58][ 99/129]	Time  0.988 ( 2.053)	Data  0.002 ( 1.078)	Loss 7.8467e-02 (7.4337e-02) 
2023-05-26 00:43:29.115073: train Epoch: [58][100/129]	Time  3.022 ( 2.062)	Data  2.058 ( 1.087)	Loss 8.4291e-02 (7.4436e-02) 
2023-05-26 00:43:30.090741: train Epoch: [58][101/129]	Time  0.976 ( 2.052)	Data  0.002 ( 1.077)	Loss 9.2277e-02 (7.4611e-02) 
2023-05-26 00:43:33.268415: train Epoch: [58][102/129]	Time  3.178 ( 2.063)	Data  2.212 ( 1.088)	Loss 7.1293e-02 (7.4579e-02) 
2023-05-26 00:43:34.239107: train Epoch: [58][103/129]	Time  0.971 ( 2.052)	Data  0.001 ( 1.077)	Loss 1.1982e-01 (7.5014e-02) 
2023-05-26 00:43:37.465872: train Epoch: [58][104/129]	Time  3.227 ( 2.063)	Data  2.258 ( 1.089)	Loss 1.0374e-01 (7.5287e-02) 
2023-05-26 00:43:38.435350: train Epoch: [58][105/129]	Time  0.969 ( 2.053)	Data  0.001 ( 1.078)	Loss 5.7377e-02 (7.5118e-02) 
2023-05-26 00:43:41.496353: train Epoch: [58][106/129]	Time  3.061 ( 2.062)	Data  2.076 ( 1.088)	Loss 4.8342e-02 (7.4868e-02) 
2023-05-26 00:43:42.468120: train Epoch: [58][107/129]	Time  0.972 ( 2.052)	Data  0.001 ( 1.078)	Loss 5.3808e-02 (7.4673e-02) 
2023-05-26 00:43:45.624732: train Epoch: [58][108/129]	Time  3.157 ( 2.062)	Data  2.174 ( 1.088)	Loss 8.6808e-02 (7.4784e-02) 
2023-05-26 00:43:46.598610: train Epoch: [58][109/129]	Time  0.974 ( 2.053)	Data  0.001 ( 1.078)	Loss 7.2037e-02 (7.4759e-02) 
2023-05-26 00:43:49.738734: train Epoch: [58][110/129]	Time  3.140 ( 2.062)	Data  2.158 ( 1.088)	Loss 9.5323e-02 (7.4945e-02) 
2023-05-26 00:43:50.703660: train Epoch: [58][111/129]	Time  0.965 ( 2.053)	Data  0.001 ( 1.078)	Loss 4.8446e-02 (7.4708e-02) 
2023-05-26 00:43:53.708110: train Epoch: [58][112/129]	Time  3.004 ( 2.061)	Data  2.032 ( 1.086)	Loss 7.3902e-02 (7.4701e-02) 
2023-05-26 00:43:54.681272: train Epoch: [58][113/129]	Time  0.973 ( 2.051)	Data  0.002 ( 1.077)	Loss 8.8808e-02 (7.4825e-02) 
2023-05-26 00:43:57.753811: train Epoch: [58][114/129]	Time  3.073 ( 2.060)	Data  2.103 ( 1.086)	Loss 6.3710e-02 (7.4728e-02) 
2023-05-26 00:43:58.720546: train Epoch: [58][115/129]	Time  0.967 ( 2.051)	Data  0.001 ( 1.076)	Loss 8.3539e-02 (7.4804e-02) 
2023-05-26 00:44:01.709350: train Epoch: [58][116/129]	Time  2.989 ( 2.059)	Data  2.025 ( 1.084)	Loss 6.2412e-02 (7.4698e-02) 
2023-05-26 00:44:02.678685: train Epoch: [58][117/129]	Time  0.969 ( 2.050)	Data  0.001 ( 1.075)	Loss 9.0727e-02 (7.4834e-02) 
2023-05-26 00:44:05.796254: train Epoch: [58][118/129]	Time  3.118 ( 2.059)	Data  2.137 ( 1.084)	Loss 9.1761e-02 (7.4976e-02) 
2023-05-26 00:44:06.766477: train Epoch: [58][119/129]	Time  0.970 ( 2.050)	Data  0.001 ( 1.075)	Loss 4.5187e-02 (7.4728e-02) 
2023-05-26 00:44:09.759374: train Epoch: [58][120/129]	Time  2.993 ( 2.057)	Data  2.003 ( 1.083)	Loss 6.5674e-02 (7.4653e-02) 
2023-05-26 00:44:10.737710: train Epoch: [58][121/129]	Time  0.978 ( 2.049)	Data  0.001 ( 1.074)	Loss 1.2821e-01 (7.5092e-02) 
2023-05-26 00:44:13.876012: train Epoch: [58][122/129]	Time  3.138 ( 2.057)	Data  2.173 ( 1.083)	Loss 9.1988e-02 (7.5230e-02) 
2023-05-26 00:44:14.849327: train Epoch: [58][123/129]	Time  0.973 ( 2.049)	Data  0.001 ( 1.074)	Loss 6.3693e-02 (7.5137e-02) 
2023-05-26 00:44:17.978453: train Epoch: [58][124/129]	Time  3.129 ( 2.057)	Data  2.161 ( 1.083)	Loss 6.5258e-02 (7.5057e-02) 
2023-05-26 00:44:18.947199: train Epoch: [58][125/129]	Time  0.969 ( 2.049)	Data  0.001 ( 1.074)	Loss 6.5356e-02 (7.4980e-02) 
2023-05-26 00:44:22.105039: train Epoch: [58][126/129]	Time  3.158 ( 2.057)	Data  2.184 ( 1.083)	Loss 7.3164e-02 (7.4966e-02) 
2023-05-26 00:44:23.076654: train Epoch: [58][127/129]	Time  0.972 ( 2.049)	Data  0.001 ( 1.075)	Loss 6.4793e-02 (7.4887e-02) 
2023-05-26 00:44:25.101849: train Epoch: [58][128/129]	Time  2.025 ( 2.049)	Data  1.055 ( 1.074)	Loss 8.3194e-02 (7.4951e-02) 
2023-05-26 00:44:25.157092: Train Epoch done in 264.34568896899873 s 
2023-05-26 00:44:28.064275: val Epoch: [58][ 0/72]	Time  1.820 ( 1.820)	Data  1.607 ( 1.607)	Loss 3.1434e-02 (3.1434e-02) 
2023-05-26 00:44:28.196313: val Epoch: [58][ 1/72]	Time  0.132 ( 0.976)	Data  0.001 ( 0.804)	Loss 8.8687e-02 (6.0060e-02) 
2023-05-26 00:44:29.327067: val Epoch: [58][ 2/72]	Time  1.131 ( 1.028)	Data  0.995 ( 0.868)	Loss 5.6568e-02 (5.8896e-02) 
2023-05-26 00:44:29.474689: val Epoch: [58][ 3/72]	Time  0.148 ( 0.808)	Data  0.014 ( 0.654)	Loss 8.5937e-02 (6.5656e-02) 
2023-05-26 00:44:30.607324: val Epoch: [58][ 4/72]	Time  1.133 ( 0.873)	Data  1.008 ( 0.725)	Loss 7.8216e-02 (6.8168e-02) 
2023-05-26 00:44:30.883001: val Epoch: [58][ 5/72]	Time  0.276 ( 0.773)	Data  0.141 ( 0.628)	Loss 9.0070e-02 (7.1819e-02) 
2023-05-26 00:44:31.955890: val Epoch: [58][ 6/72]	Time  1.073 ( 0.816)	Data  0.945 ( 0.673)	Loss 1.7981e-01 (8.7245e-02) 
2023-05-26 00:44:32.251402: val Epoch: [58][ 7/72]	Time  0.295 ( 0.751)	Data  0.163 ( 0.609)	Loss 2.8444e-01 (1.1189e-01) 
2023-05-26 00:44:33.359626: val Epoch: [58][ 8/72]	Time  1.108 ( 0.791)	Data  0.976 ( 0.650)	Loss 8.1369e-02 (1.0850e-01) 
2023-05-26 00:44:33.635298: val Epoch: [58][ 9/72]	Time  0.276 ( 0.739)	Data  0.148 ( 0.600)	Loss 4.4385e-02 (1.0209e-01) 
2023-05-26 00:44:34.769973: val Epoch: [58][10/72]	Time  1.135 ( 0.775)	Data  1.005 ( 0.637)	Loss 9.7814e-02 (1.0170e-01) 
2023-05-26 00:44:34.976511: val Epoch: [58][11/72]	Time  0.207 ( 0.728)	Data  0.077 ( 0.590)	Loss 4.5747e-02 (9.7039e-02) 
2023-05-26 00:44:36.141233: val Epoch: [58][12/72]	Time  1.165 ( 0.761)	Data  1.035 ( 0.624)	Loss 8.8510e-02 (9.6383e-02) 
2023-05-26 00:44:36.410040: val Epoch: [58][13/72]	Time  0.269 ( 0.726)	Data  0.134 ( 0.589)	Loss 9.1851e-02 (9.6060e-02) 
2023-05-26 00:44:37.497752: val Epoch: [58][14/72]	Time  1.088 ( 0.750)	Data  0.957 ( 0.614)	Loss 4.5460e-02 (9.2686e-02) 
2023-05-26 00:44:37.788136: val Epoch: [58][15/72]	Time  0.290 ( 0.722)	Data  0.157 ( 0.585)	Loss 5.4900e-02 (9.0325e-02) 
2023-05-26 00:44:38.882225: val Epoch: [58][16/72]	Time  1.094 ( 0.743)	Data  0.966 ( 0.608)	Loss 1.3153e-01 (9.2749e-02) 
2023-05-26 00:44:39.197172: val Epoch: [58][17/72]	Time  0.315 ( 0.720)	Data  0.187 ( 0.584)	Loss 7.5503e-02 (9.1791e-02) 
2023-05-26 00:44:40.286194: val Epoch: [58][18/72]	Time  1.089 ( 0.739)	Data  0.959 ( 0.604)	Loss 8.8355e-02 (9.1610e-02) 
2023-05-26 00:44:40.606423: val Epoch: [58][19/72]	Time  0.320 ( 0.718)	Data  0.191 ( 0.583)	Loss 1.2647e-01 (9.3353e-02) 
2023-05-26 00:44:41.701172: val Epoch: [58][20/72]	Time  1.095 ( 0.736)	Data  0.971 ( 0.602)	Loss 1.7159e-01 (9.7078e-02) 
2023-05-26 00:44:41.992946: val Epoch: [58][21/72]	Time  0.292 ( 0.716)	Data  0.165 ( 0.582)	Loss 3.2773e-01 (1.0756e-01) 
2023-05-26 00:44:43.067540: val Epoch: [58][22/72]	Time  1.075 ( 0.731)	Data  0.946 ( 0.598)	Loss 4.7445e-02 (1.0495e-01) 
2023-05-26 00:44:43.355321: val Epoch: [58][23/72]	Time  0.288 ( 0.713)	Data  0.161 ( 0.580)	Loss 1.2658e-01 (1.0585e-01) 
2023-05-26 00:44:44.417504: val Epoch: [58][24/72]	Time  1.062 ( 0.727)	Data  0.927 ( 0.593)	Loss 3.6494e-02 (1.0308e-01) 
2023-05-26 00:44:44.736370: val Epoch: [58][25/72]	Time  0.319 ( 0.711)	Data  0.182 ( 0.578)	Loss 4.2134e-01 (1.1532e-01) 
2023-05-26 00:44:45.785527: val Epoch: [58][26/72]	Time  1.049 ( 0.724)	Data  0.910 ( 0.590)	Loss 7.4881e-02 (1.1382e-01) 
2023-05-26 00:44:46.045174: val Epoch: [58][27/72]	Time  0.260 ( 0.707)	Data  0.124 ( 0.573)	Loss 6.5530e-02 (1.1209e-01) 
2023-05-26 00:44:47.084946: val Epoch: [58][28/72]	Time  1.040 ( 0.719)	Data  0.910 ( 0.585)	Loss 6.0372e-02 (1.1031e-01) 
2023-05-26 00:44:47.369096: val Epoch: [58][29/72]	Time  0.284 ( 0.704)	Data  0.157 ( 0.571)	Loss 4.3887e-02 (1.0810e-01) 
2023-05-26 00:44:48.443633: val Epoch: [58][30/72]	Time  1.075 ( 0.716)	Data  0.947 ( 0.583)	Loss 4.5590e-02 (1.0608e-01) 
2023-05-26 00:44:48.739453: val Epoch: [58][31/72]	Time  0.296 ( 0.703)	Data  0.168 ( 0.570)	Loss 3.0643e-01 (1.1234e-01) 
2023-05-26 00:44:49.807922: val Epoch: [58][32/72]	Time  1.068 ( 0.714)	Data  0.941 ( 0.581)	Loss 9.8755e-02 (1.1193e-01) 
2023-05-26 00:44:50.078655: val Epoch: [58][33/72]	Time  0.271 ( 0.701)	Data  0.145 ( 0.568)	Loss 3.6302e-02 (1.0971e-01) 
2023-05-26 00:44:51.215105: val Epoch: [58][34/72]	Time  1.136 ( 0.713)	Data  1.010 ( 0.581)	Loss 5.6075e-02 (1.0817e-01) 
2023-05-26 00:44:51.439910: val Epoch: [58][35/72]	Time  0.225 ( 0.700)	Data  0.098 ( 0.567)	Loss 4.1970e-02 (1.0633e-01) 
2023-05-26 00:44:52.512273: val Epoch: [58][36/72]	Time  1.072 ( 0.710)	Data  0.944 ( 0.578)	Loss 5.0351e-02 (1.0482e-01) 
2023-05-26 00:44:52.765627: val Epoch: [58][37/72]	Time  0.253 ( 0.698)	Data  0.129 ( 0.566)	Loss 9.2035e-02 (1.0448e-01) 
2023-05-26 00:44:53.826905: val Epoch: [58][38/72]	Time  1.061 ( 0.707)	Data  0.918 ( 0.575)	Loss 4.2721e-02 (1.0290e-01) 
2023-05-26 00:44:54.100282: val Epoch: [58][39/72]	Time  0.273 ( 0.696)	Data  0.146 ( 0.564)	Loss 5.1858e-02 (1.0162e-01) 
2023-05-26 00:44:55.160529: val Epoch: [58][40/72]	Time  1.060 ( 0.705)	Data  0.933 ( 0.573)	Loss 2.2139e-01 (1.0455e-01) 
2023-05-26 00:44:55.458958: val Epoch: [58][41/72]	Time  0.298 ( 0.696)	Data  0.171 ( 0.564)	Loss 3.4925e-02 (1.0289e-01) 
2023-05-26 00:44:56.519763: val Epoch: [58][42/72]	Time  1.061 ( 0.704)	Data  0.923 ( 0.572)	Loss 4.2337e-02 (1.0148e-01) 
2023-05-26 00:44:56.844407: val Epoch: [58][43/72]	Time  0.325 ( 0.695)	Data  0.196 ( 0.563)	Loss 7.8206e-02 (1.0095e-01) 
2023-05-26 00:44:57.974253: val Epoch: [58][44/72]	Time  1.130 ( 0.705)	Data  0.986 ( 0.573)	Loss 6.1736e-02 (1.0008e-01) 
2023-05-26 00:44:58.256744: val Epoch: [58][45/72]	Time  0.282 ( 0.696)	Data  0.136 ( 0.563)	Loss 6.0786e-02 (9.9226e-02) 
2023-05-26 00:44:59.379804: val Epoch: [58][46/72]	Time  1.123 ( 0.705)	Data  0.977 ( 0.572)	Loss 5.2838e-02 (9.8239e-02) 
2023-05-26 00:44:59.634413: val Epoch: [58][47/72]	Time  0.255 ( 0.696)	Data  0.124 ( 0.563)	Loss 4.5440e-02 (9.7139e-02) 
2023-05-26 00:45:00.730559: val Epoch: [58][48/72]	Time  1.096 ( 0.704)	Data  0.968 ( 0.571)	Loss 1.0731e-01 (9.7346e-02) 
2023-05-26 00:45:01.041534: val Epoch: [58][49/72]	Time  0.311 ( 0.696)	Data  0.184 ( 0.563)	Loss 3.7098e-01 (1.0282e-01) 
2023-05-26 00:45:02.117970: val Epoch: [58][50/72]	Time  1.076 ( 0.703)	Data  0.947 ( 0.571)	Loss 1.3749e-01 (1.0350e-01) 
2023-05-26 00:45:02.471925: val Epoch: [58][51/72]	Time  0.354 ( 0.697)	Data  0.224 ( 0.564)	Loss 7.4075e-02 (1.0293e-01) 
2023-05-26 00:45:03.526361: val Epoch: [58][52/72]	Time  1.054 ( 0.703)	Data  0.926 ( 0.571)	Loss 2.3609e-01 (1.0545e-01) 
2023-05-26 00:45:03.844420: val Epoch: [58][53/72]	Time  0.318 ( 0.696)	Data  0.191 ( 0.564)	Loss 2.6602e-01 (1.0842e-01) 
2023-05-26 00:45:04.934002: val Epoch: [58][54/72]	Time  1.090 ( 0.703)	Data  0.961 ( 0.571)	Loss 2.8306e-01 (1.1159e-01) 
2023-05-26 00:45:05.222755: val Epoch: [58][55/72]	Time  0.289 ( 0.696)	Data  0.154 ( 0.564)	Loss 5.3513e-02 (1.1056e-01) 
2023-05-26 00:45:06.292883: val Epoch: [58][56/72]	Time  1.070 ( 0.703)	Data  0.945 ( 0.570)	Loss 6.9350e-02 (1.0983e-01) 
2023-05-26 00:45:06.613097: val Epoch: [58][57/72]	Time  0.320 ( 0.696)	Data  0.189 ( 0.564)	Loss 2.0574e-01 (1.1149e-01) 
2023-05-26 00:45:07.654298: val Epoch: [58][58/72]	Time  1.041 ( 0.702)	Data  0.904 ( 0.570)	Loss 8.1253e-02 (1.1098e-01) 
2023-05-26 00:45:07.993147: val Epoch: [58][59/72]	Time  0.339 ( 0.696)	Data  0.212 ( 0.564)	Loss 3.3834e-01 (1.1476e-01) 
2023-05-26 00:45:08.980156: val Epoch: [58][60/72]	Time  0.987 ( 0.701)	Data  0.859 ( 0.568)	Loss 6.4615e-02 (1.1394e-01) 
2023-05-26 00:45:09.373087: val Epoch: [58][61/72]	Time  0.393 ( 0.696)	Data  0.264 ( 0.564)	Loss 3.9019e-01 (1.1840e-01) 
2023-05-26 00:45:10.402776: val Epoch: [58][62/72]	Time  1.030 ( 0.701)	Data  0.901 ( 0.569)	Loss 1.2770e-01 (1.1855e-01) 
2023-05-26 00:45:10.804883: val Epoch: [58][63/72]	Time  0.402 ( 0.696)	Data  0.262 ( 0.564)	Loss 6.3516e-01 (1.2662e-01) 
2023-05-26 00:45:11.849905: val Epoch: [58][64/72]	Time  1.045 ( 0.702)	Data  0.917 ( 0.570)	Loss 6.7527e-02 (1.2571e-01) 
2023-05-26 00:45:12.198343: val Epoch: [58][65/72]	Time  0.348 ( 0.696)	Data  0.220 ( 0.564)	Loss 4.9359e-02 (1.2455e-01) 
2023-05-26 00:45:13.262066: val Epoch: [58][66/72]	Time  1.064 ( 0.702)	Data  0.934 ( 0.570)	Loss 3.4181e-01 (1.2779e-01) 
2023-05-26 00:45:13.537775: val Epoch: [58][67/72]	Time  0.276 ( 0.695)	Data  0.149 ( 0.564)	Loss 1.1646e-01 (1.2763e-01) 
2023-05-26 00:45:14.624335: val Epoch: [58][68/72]	Time  1.087 ( 0.701)	Data  0.959 ( 0.569)	Loss 1.4027e-01 (1.2781e-01) 
2023-05-26 00:45:14.912277: val Epoch: [58][69/72]	Time  0.288 ( 0.695)	Data  0.161 ( 0.563)	Loss 9.3414e-02 (1.2732e-01) 
2023-05-26 00:45:15.997932: val Epoch: [58][70/72]	Time  1.086 ( 0.701)	Data  0.954 ( 0.569)	Loss 8.6334e-02 (1.2674e-01) 
2023-05-26 00:45:16.229683: val Epoch: [58][71/72]	Time  0.232 ( 0.694)	Data  0.105 ( 0.563)	Loss 6.2637e-02 (1.2585e-01) 
2023-05-26 00:45:16.435924: Epoch 58 :Val : ['ET : 0.7545784711837769', 'TC : 0.7842228412628174', 'WT : 0.86761474609375'] 
2023-05-26 00:45:16.440710: Epoch 58 :Val : ['ET : 0.7545784711837769', 'TC : 0.7842228412628174', 'WT : 0.86761474609375'] 
2023-05-26 00:45:16.443635: Val epoch done in 51.28654873800042 s 
2023-05-26 00:45:16.452727: Batches per epoch:  129 
2023-05-26 00:45:21.924729: train Epoch: [59][  0/129]	Time  5.471 ( 5.471)	Data  4.399 ( 4.399)	Loss 1.0268e-01 (1.0268e-01) 
2023-05-26 00:45:22.896038: train Epoch: [59][  1/129]	Time  0.971 ( 3.221)	Data  0.001 ( 2.200)	Loss 7.0352e-02 (8.6515e-02) 
2023-05-26 00:45:25.874555: train Epoch: [59][  2/129]	Time  2.979 ( 3.140)	Data  2.015 ( 2.138)	Loss 7.7479e-02 (8.3503e-02) 
2023-05-26 00:45:26.845446: train Epoch: [59][  3/129]	Time  0.971 ( 2.598)	Data  0.001 ( 1.604)	Loss 7.6996e-02 (8.1876e-02) 
2023-05-26 00:45:30.065368: train Epoch: [59][  4/129]	Time  3.220 ( 2.722)	Data  2.233 ( 1.730)	Loss 7.2026e-02 (7.9906e-02) 
2023-05-26 00:45:31.040251: train Epoch: [59][  5/129]	Time  0.975 ( 2.431)	Data  0.001 ( 1.442)	Loss 9.4238e-02 (8.2295e-02) 
2023-05-26 00:45:34.168077: train Epoch: [59][  6/129]	Time  3.128 ( 2.531)	Data  2.162 ( 1.545)	Loss 7.6488e-02 (8.1465e-02) 
2023-05-26 00:45:35.141148: train Epoch: [59][  7/129]	Time  0.973 ( 2.336)	Data  0.001 ( 1.352)	Loss 7.5281e-02 (8.0692e-02) 
2023-05-26 00:45:38.191990: train Epoch: [59][  8/129]	Time  3.051 ( 2.415)	Data  2.078 ( 1.432)	Loss 4.4961e-02 (7.6722e-02) 
2023-05-26 00:45:39.162538: train Epoch: [59][  9/129]	Time  0.971 ( 2.271)	Data  0.001 ( 1.289)	Loss 8.0726e-02 (7.7122e-02) 
2023-05-26 00:45:42.332762: train Epoch: [59][ 10/129]	Time  3.170 ( 2.353)	Data  2.201 ( 1.372)	Loss 5.6428e-02 (7.5241e-02) 
2023-05-26 00:45:43.325316: train Epoch: [59][ 11/129]	Time  0.993 ( 2.239)	Data  0.001 ( 1.258)	Loss 6.0215e-02 (7.3989e-02) 
2023-05-26 00:45:46.436394: train Epoch: [59][ 12/129]	Time  3.111 ( 2.306)	Data  2.125 ( 1.325)	Loss 8.7513e-02 (7.5029e-02) 
2023-05-26 00:45:47.415079: train Epoch: [59][ 13/129]	Time  0.979 ( 2.212)	Data  0.001 ( 1.230)	Loss 4.7691e-02 (7.3077e-02) 
2023-05-26 00:45:50.552103: train Epoch: [59][ 14/129]	Time  3.137 ( 2.273)	Data  2.161 ( 1.292)	Loss 1.6488e-01 (7.9197e-02) 
2023-05-26 00:45:51.523034: train Epoch: [59][ 15/129]	Time  0.971 ( 2.192)	Data  0.001 ( 1.211)	Loss 1.0101e-01 (8.0560e-02) 
2023-05-26 00:45:54.561576: train Epoch: [59][ 16/129]	Time  3.039 ( 2.242)	Data  2.054 ( 1.261)	Loss 6.8019e-02 (7.9823e-02) 
2023-05-26 00:45:55.543634: train Epoch: [59][ 17/129]	Time  0.982 ( 2.172)	Data  0.001 ( 1.191)	Loss 6.4748e-02 (7.8985e-02) 
2023-05-26 00:45:58.602922: train Epoch: [59][ 18/129]	Time  3.059 ( 2.218)	Data  2.084 ( 1.238)	Loss 8.6842e-02 (7.9399e-02) 
2023-05-26 00:45:59.591288: train Epoch: [59][ 19/129]	Time  0.988 ( 2.157)	Data  0.001 ( 1.176)	Loss 7.8356e-02 (7.9347e-02) 
2023-05-26 00:46:02.728284: train Epoch: [59][ 20/129]	Time  3.137 ( 2.204)	Data  2.151 ( 1.223)	Loss 9.7153e-02 (8.0195e-02) 
2023-05-26 00:46:03.732701: train Epoch: [59][ 21/129]	Time  1.004 ( 2.149)	Data  0.001 ( 1.167)	Loss 8.7265e-02 (8.0516e-02) 
2023-05-26 00:46:06.846807: train Epoch: [59][ 22/129]	Time  3.114 ( 2.191)	Data  2.127 ( 1.209)	Loss 5.9177e-02 (7.9588e-02) 
2023-05-26 00:46:07.833934: train Epoch: [59][ 23/129]	Time  0.987 ( 2.141)	Data  0.001 ( 1.159)	Loss 7.4408e-02 (7.9372e-02) 
2023-05-26 00:46:11.047107: train Epoch: [59][ 24/129]	Time  3.213 ( 2.184)	Data  2.231 ( 1.201)	Loss 1.0007e-01 (8.0200e-02) 
2023-05-26 00:46:12.016229: train Epoch: [59][ 25/129]	Time  0.969 ( 2.137)	Data  0.001 ( 1.155)	Loss 5.1004e-02 (7.9077e-02) 
2023-05-26 00:46:15.135999: train Epoch: [59][ 26/129]	Time  3.120 ( 2.173)	Data  2.133 ( 1.191)	Loss 1.2979e-01 (8.0955e-02) 
2023-05-26 00:46:16.115493: train Epoch: [59][ 27/129]	Time  0.980 ( 2.131)	Data  0.001 ( 1.149)	Loss 8.6621e-02 (8.1158e-02) 
2023-05-26 00:46:19.268492: train Epoch: [59][ 28/129]	Time  3.153 ( 2.166)	Data  2.187 ( 1.185)	Loss 7.8558e-02 (8.1068e-02) 
2023-05-26 00:46:20.234253: train Epoch: [59][ 29/129]	Time  0.966 ( 2.126)	Data  0.001 ( 1.145)	Loss 6.6864e-02 (8.0595e-02) 
2023-05-26 00:46:23.268597: train Epoch: [59][ 30/129]	Time  3.034 ( 2.155)	Data  2.069 ( 1.175)	Loss 7.9120e-02 (8.0547e-02) 
2023-05-26 00:46:24.254236: train Epoch: [59][ 31/129]	Time  0.986 ( 2.119)	Data  0.001 ( 1.138)	Loss 9.9925e-02 (8.1153e-02) 
2023-05-26 00:46:27.318121: train Epoch: [59][ 32/129]	Time  3.064 ( 2.147)	Data  2.095 ( 1.167)	Loss 8.7321e-02 (8.1340e-02) 
2023-05-26 00:46:28.302659: train Epoch: [59][ 33/129]	Time  0.985 ( 2.113)	Data  0.001 ( 1.133)	Loss 6.0946e-02 (8.0740e-02) 
2023-05-26 00:46:31.292747: train Epoch: [59][ 34/129]	Time  2.990 ( 2.138)	Data  2.025 ( 1.159)	Loss 5.1680e-02 (7.9910e-02) 
2023-05-26 00:46:32.261140: train Epoch: [59][ 35/129]	Time  0.968 ( 2.106)	Data  0.001 ( 1.126)	Loss 9.6536e-02 (8.0371e-02) 
2023-05-26 00:46:35.326144: train Epoch: [59][ 36/129]	Time  3.065 ( 2.132)	Data  2.099 ( 1.153)	Loss 7.4964e-02 (8.0225e-02) 
2023-05-26 00:46:36.292466: train Epoch: [59][ 37/129]	Time  0.966 ( 2.101)	Data  0.001 ( 1.122)	Loss 6.0927e-02 (7.9717e-02) 
2023-05-26 00:46:39.281241: train Epoch: [59][ 38/129]	Time  2.989 ( 2.124)	Data  2.023 ( 1.145)	Loss 5.4265e-02 (7.9065e-02) 
2023-05-26 00:46:40.249419: train Epoch: [59][ 39/129]	Time  0.968 ( 2.095)	Data  0.001 ( 1.117)	Loss 9.3810e-02 (7.9433e-02) 
2023-05-26 00:46:43.329540: train Epoch: [59][ 40/129]	Time  3.080 ( 2.119)	Data  2.116 ( 1.141)	Loss 1.1300e-01 (8.0252e-02) 
2023-05-26 00:46:44.299052: train Epoch: [59][ 41/129]	Time  0.970 ( 2.092)	Data  0.001 ( 1.114)	Loss 7.5246e-02 (8.0133e-02) 
2023-05-26 00:46:47.336353: train Epoch: [59][ 42/129]	Time  3.037 ( 2.114)	Data  2.064 ( 1.136)	Loss 1.3191e-01 (8.1337e-02) 
2023-05-26 00:46:48.318024: train Epoch: [59][ 43/129]	Time  0.982 ( 2.088)	Data  0.001 ( 1.110)	Loss 1.0359e-01 (8.1843e-02) 
2023-05-26 00:46:51.502591: train Epoch: [59][ 44/129]	Time  3.185 ( 2.112)	Data  2.221 ( 1.135)	Loss 5.7015e-02 (8.1291e-02) 
2023-05-26 00:46:52.472352: train Epoch: [59][ 45/129]	Time  0.970 ( 2.087)	Data  0.001 ( 1.110)	Loss 7.5904e-02 (8.1174e-02) 
2023-05-26 00:46:55.550018: train Epoch: [59][ 46/129]	Time  3.078 ( 2.108)	Data  2.114 ( 1.132)	Loss 6.6208e-02 (8.0856e-02) 
2023-05-26 00:46:56.527998: train Epoch: [59][ 47/129]	Time  0.978 ( 2.085)	Data  0.001 ( 1.108)	Loss 5.9612e-02 (8.0413e-02) 
2023-05-26 00:46:59.575537: train Epoch: [59][ 48/129]	Time  3.048 ( 2.105)	Data  2.079 ( 1.128)	Loss 9.5780e-02 (8.0727e-02) 
2023-05-26 00:47:00.558815: train Epoch: [59][ 49/129]	Time  0.983 ( 2.082)	Data  0.001 ( 1.105)	Loss 6.6117e-02 (8.0434e-02) 
2023-05-26 00:47:03.658128: train Epoch: [59][ 50/129]	Time  3.099 ( 2.102)	Data  2.121 ( 1.125)	Loss 8.3827e-02 (8.0501e-02) 
2023-05-26 00:47:04.640710: train Epoch: [59][ 51/129]	Time  0.983 ( 2.081)	Data  0.002 ( 1.104)	Loss 4.6284e-02 (7.9843e-02) 
2023-05-26 00:47:07.798800: train Epoch: [59][ 52/129]	Time  3.158 ( 2.101)	Data  2.193 ( 1.124)	Loss 1.8825e-01 (8.1888e-02) 
2023-05-26 00:47:08.764167: train Epoch: [59][ 53/129]	Time  0.965 ( 2.080)	Data  0.001 ( 1.104)	Loss 6.1726e-02 (8.1515e-02) 
2023-05-26 00:47:12.014446: train Epoch: [59][ 54/129]	Time  3.250 ( 2.101)	Data  2.281 ( 1.125)	Loss 8.3435e-02 (8.1550e-02) 
2023-05-26 00:47:12.980283: train Epoch: [59][ 55/129]	Time  0.966 ( 2.081)	Data  0.001 ( 1.105)	Loss 1.1019e-01 (8.2061e-02) 
2023-05-26 00:47:16.113934: train Epoch: [59][ 56/129]	Time  3.134 ( 2.099)	Data  2.161 ( 1.123)	Loss 7.1946e-02 (8.1884e-02) 
2023-05-26 00:47:17.079207: train Epoch: [59][ 57/129]	Time  0.965 ( 2.080)	Data  0.001 ( 1.104)	Loss 5.8328e-02 (8.1478e-02) 
2023-05-26 00:47:20.128051: train Epoch: [59][ 58/129]	Time  3.049 ( 2.096)	Data  2.081 ( 1.121)	Loss 1.0654e-01 (8.1902e-02) 
2023-05-26 00:47:21.106393: train Epoch: [59][ 59/129]	Time  0.978 ( 2.078)	Data  0.001 ( 1.102)	Loss 6.1608e-02 (8.1564e-02) 
2023-05-26 00:47:24.227229: train Epoch: [59][ 60/129]	Time  3.121 ( 2.095)	Data  2.151 ( 1.119)	Loss 7.2384e-02 (8.1414e-02) 
2023-05-26 00:47:25.212677: train Epoch: [59][ 61/129]	Time  0.985 ( 2.077)	Data  0.001 ( 1.101)	Loss 5.6520e-02 (8.1012e-02) 
2023-05-26 00:47:28.308306: train Epoch: [59][ 62/129]	Time  3.096 ( 2.093)	Data  2.128 ( 1.117)	Loss 6.7101e-02 (8.0791e-02) 
2023-05-26 00:47:29.274449: train Epoch: [59][ 63/129]	Time  0.966 ( 2.075)	Data  0.001 ( 1.100)	Loss 6.9239e-02 (8.0611e-02) 
2023-05-26 00:47:32.384698: train Epoch: [59][ 64/129]	Time  3.110 ( 2.091)	Data  2.134 ( 1.116)	Loss 8.4060e-02 (8.0664e-02) 
2023-05-26 00:47:33.365274: train Epoch: [59][ 65/129]	Time  0.981 ( 2.074)	Data  0.001 ( 1.099)	Loss 6.5655e-02 (8.0436e-02) 
2023-05-26 00:47:36.403510: train Epoch: [59][ 66/129]	Time  3.038 ( 2.089)	Data  2.068 ( 1.113)	Loss 7.5310e-02 (8.0360e-02) 
2023-05-26 00:47:37.374311: train Epoch: [59][ 67/129]	Time  0.971 ( 2.072)	Data  0.001 ( 1.097)	Loss 7.6999e-02 (8.0311e-02) 
2023-05-26 00:47:40.515102: train Epoch: [59][ 68/129]	Time  3.141 ( 2.088)	Data  2.158 ( 1.112)	Loss 6.0589e-02 (8.0025e-02) 
2023-05-26 00:47:41.502847: train Epoch: [59][ 69/129]	Time  0.988 ( 2.072)	Data  0.001 ( 1.097)	Loss 8.1506e-02 (8.0046e-02) 
2023-05-26 00:47:44.511380: train Epoch: [59][ 70/129]	Time  3.009 ( 2.085)	Data  2.039 ( 1.110)	Loss 7.5690e-02 (7.9985e-02) 
2023-05-26 00:47:45.482995: train Epoch: [59][ 71/129]	Time  0.972 ( 2.070)	Data  0.001 ( 1.094)	Loss 9.3428e-02 (8.0171e-02) 
2023-05-26 00:47:48.501397: train Epoch: [59][ 72/129]	Time  3.018 ( 2.083)	Data  2.049 ( 1.108)	Loss 5.6563e-02 (7.9848e-02) 
2023-05-26 00:47:49.467916: train Epoch: [59][ 73/129]	Time  0.967 ( 2.068)	Data  0.001 ( 1.093)	Loss 5.2882e-02 (7.9483e-02) 
2023-05-26 00:47:52.481953: train Epoch: [59][ 74/129]	Time  3.014 ( 2.080)	Data  2.034 ( 1.105)	Loss 7.3195e-02 (7.9400e-02) 
2023-05-26 00:47:53.457037: train Epoch: [59][ 75/129]	Time  0.975 ( 2.066)	Data  0.001 ( 1.091)	Loss 5.2205e-02 (7.9042e-02) 
2023-05-26 00:47:56.428289: train Epoch: [59][ 76/129]	Time  2.971 ( 2.078)	Data  1.996 ( 1.102)	Loss 4.1990e-02 (7.8561e-02) 
2023-05-26 00:47:57.401357: train Epoch: [59][ 77/129]	Time  0.973 ( 2.063)	Data  0.001 ( 1.088)	Loss 6.3836e-02 (7.8372e-02) 
2023-05-26 00:48:00.484555: train Epoch: [59][ 78/129]	Time  3.083 ( 2.076)	Data  2.114 ( 1.101)	Loss 4.9421e-02 (7.8005e-02) 
2023-05-26 00:48:01.448610: train Epoch: [59][ 79/129]	Time  0.964 ( 2.062)	Data  0.001 ( 1.087)	Loss 1.2893e-01 (7.8642e-02) 
2023-05-26 00:48:04.498982: train Epoch: [59][ 80/129]	Time  3.050 ( 2.075)	Data  2.082 ( 1.100)	Loss 3.9906e-02 (7.8164e-02) 
2023-05-26 00:48:05.464020: train Epoch: [59][ 81/129]	Time  0.965 ( 2.061)	Data  0.001 ( 1.086)	Loss 1.4026e-01 (7.8921e-02) 
2023-05-26 00:48:08.745412: train Epoch: [59][ 82/129]	Time  3.281 ( 2.076)	Data  2.310 ( 1.101)	Loss 9.0141e-02 (7.9056e-02) 
2023-05-26 00:48:09.713445: train Epoch: [59][ 83/129]	Time  0.968 ( 2.063)	Data  0.001 ( 1.088)	Loss 7.6440e-02 (7.9025e-02) 
2023-05-26 00:48:12.686708: train Epoch: [59][ 84/129]	Time  2.973 ( 2.073)	Data  2.008 ( 1.099)	Loss 6.1500e-02 (7.8819e-02) 
2023-05-26 00:48:13.655579: train Epoch: [59][ 85/129]	Time  0.969 ( 2.060)	Data  0.001 ( 1.086)	Loss 1.0567e-01 (7.9131e-02) 
2023-05-26 00:48:16.840950: train Epoch: [59][ 86/129]	Time  3.185 ( 2.073)	Data  2.216 ( 1.099)	Loss 1.0547e-01 (7.9434e-02) 
2023-05-26 00:48:17.829524: train Epoch: [59][ 87/129]	Time  0.989 ( 2.061)	Data  0.001 ( 1.087)	Loss 1.3690e-01 (8.0087e-02) 
2023-05-26 00:48:20.943385: train Epoch: [59][ 88/129]	Time  3.114 ( 2.073)	Data  2.133 ( 1.098)	Loss 6.7197e-02 (7.9942e-02) 
2023-05-26 00:48:21.920812: train Epoch: [59][ 89/129]	Time  0.977 ( 2.061)	Data  0.001 ( 1.086)	Loss 6.5052e-02 (7.9777e-02) 
2023-05-26 00:48:24.974792: train Epoch: [59][ 90/129]	Time  3.054 ( 2.072)	Data  2.087 ( 1.097)	Loss 7.4864e-02 (7.9723e-02) 
2023-05-26 00:48:25.943674: train Epoch: [59][ 91/129]	Time  0.969 ( 2.060)	Data  0.001 ( 1.085)	Loss 1.0132e-01 (7.9957e-02) 
2023-05-26 00:48:29.089441: train Epoch: [59][ 92/129]	Time  3.146 ( 2.071)	Data  2.172 ( 1.097)	Loss 8.6450e-02 (8.0027e-02) 
2023-05-26 00:48:30.060241: train Epoch: [59][ 93/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.085)	Loss 6.7296e-02 (7.9892e-02) 
2023-05-26 00:48:33.147813: train Epoch: [59][ 94/129]	Time  3.088 ( 2.070)	Data  2.118 ( 1.096)	Loss 5.5511e-02 (7.9635e-02) 
2023-05-26 00:48:34.115855: train Epoch: [59][ 95/129]	Time  0.968 ( 2.059)	Data  0.001 ( 1.085)	Loss 7.6345e-02 (7.9601e-02) 
2023-05-26 00:48:37.207671: train Epoch: [59][ 96/129]	Time  3.092 ( 2.070)	Data  2.120 ( 1.095)	Loss 1.0859e-01 (7.9900e-02) 
2023-05-26 00:48:38.174213: train Epoch: [59][ 97/129]	Time  0.967 ( 2.058)	Data  0.001 ( 1.084)	Loss 8.2891e-02 (7.9930e-02) 
2023-05-26 00:48:41.269252: train Epoch: [59][ 98/129]	Time  3.095 ( 2.069)	Data  2.125 ( 1.095)	Loss 1.0035e-01 (8.0137e-02) 
2023-05-26 00:48:42.247083: train Epoch: [59][ 99/129]	Time  0.978 ( 2.058)	Data  0.001 ( 1.084)	Loss 1.6517e-01 (8.0987e-02) 
2023-05-26 00:48:45.319259: train Epoch: [59][100/129]	Time  3.072 ( 2.068)	Data  2.107 ( 1.094)	Loss 1.2631e-01 (8.1436e-02) 
2023-05-26 00:48:46.288481: train Epoch: [59][101/129]	Time  0.969 ( 2.057)	Data  0.001 ( 1.083)	Loss 6.3160e-02 (8.1256e-02) 
2023-05-26 00:48:49.479346: train Epoch: [59][102/129]	Time  3.191 ( 2.068)	Data  2.222 ( 1.094)	Loss 1.0850e-01 (8.1521e-02) 
2023-05-26 00:48:50.450401: train Epoch: [59][103/129]	Time  0.971 ( 2.058)	Data  0.001 ( 1.084)	Loss 7.3243e-02 (8.1441e-02) 
2023-05-26 00:48:53.738994: train Epoch: [59][104/129]	Time  3.289 ( 2.069)	Data  2.318 ( 1.096)	Loss 8.4655e-02 (8.1472e-02) 
2023-05-26 00:48:54.711695: train Epoch: [59][105/129]	Time  0.973 ( 2.059)	Data  0.001 ( 1.085)	Loss 8.5264e-02 (8.1508e-02) 
2023-05-26 00:48:57.877508: train Epoch: [59][106/129]	Time  3.166 ( 2.069)	Data  2.198 ( 1.096)	Loss 2.7606e-01 (8.3326e-02) 
2023-05-26 00:48:58.845454: train Epoch: [59][107/129]	Time  0.968 ( 2.059)	Data  0.001 ( 1.085)	Loss 6.4085e-02 (8.3148e-02) 
2023-05-26 00:49:01.889692: train Epoch: [59][108/129]	Time  3.044 ( 2.068)	Data  2.078 ( 1.095)	Loss 9.3822e-02 (8.3246e-02) 
2023-05-26 00:49:02.857765: train Epoch: [59][109/129]	Time  0.968 ( 2.058)	Data  0.001 ( 1.085)	Loss 9.0259e-02 (8.3310e-02) 
2023-05-26 00:49:05.910024: train Epoch: [59][110/129]	Time  3.052 ( 2.067)	Data  2.082 ( 1.094)	Loss 7.1515e-02 (8.3203e-02) 
2023-05-26 00:49:06.879591: train Epoch: [59][111/129]	Time  0.970 ( 2.057)	Data  0.001 ( 1.084)	Loss 1.1501e-01 (8.3487e-02) 
2023-05-26 00:49:09.949463: train Epoch: [59][112/129]	Time  3.070 ( 2.066)	Data  2.101 ( 1.093)	Loss 3.8969e-02 (8.3093e-02) 
2023-05-26 00:49:10.921001: train Epoch: [59][113/129]	Time  0.972 ( 2.057)	Data  0.001 ( 1.083)	Loss 7.5979e-02 (8.3031e-02) 
2023-05-26 00:49:14.081518: train Epoch: [59][114/129]	Time  3.160 ( 2.066)	Data  2.179 ( 1.093)	Loss 7.3139e-02 (8.2945e-02) 
2023-05-26 00:49:15.052958: train Epoch: [59][115/129]	Time  0.971 ( 2.057)	Data  0.001 ( 1.083)	Loss 5.5961e-02 (8.2712e-02) 
2023-05-26 00:49:17.989945: train Epoch: [59][116/129]	Time  2.937 ( 2.064)	Data  1.975 ( 1.091)	Loss 9.6611e-02 (8.2831e-02) 
2023-05-26 00:49:18.959713: train Epoch: [59][117/129]	Time  0.970 ( 2.055)	Data  0.002 ( 1.082)	Loss 1.1713e-01 (8.3122e-02) 
2023-05-26 00:49:22.068398: train Epoch: [59][118/129]	Time  3.109 ( 2.064)	Data  2.129 ( 1.091)	Loss 9.1873e-02 (8.3195e-02) 
2023-05-26 00:49:23.050467: train Epoch: [59][119/129]	Time  0.982 ( 2.055)	Data  0.001 ( 1.082)	Loss 6.2338e-02 (8.3021e-02) 
2023-05-26 00:49:26.011688: train Epoch: [59][120/129]	Time  2.961 ( 2.062)	Data  1.984 ( 1.089)	Loss 1.5637e-01 (8.3628e-02) 
2023-05-26 00:49:26.980380: train Epoch: [59][121/129]	Time  0.969 ( 2.053)	Data  0.001 ( 1.080)	Loss 9.3116e-02 (8.3705e-02) 
2023-05-26 00:49:30.161760: train Epoch: [59][122/129]	Time  3.181 ( 2.063)	Data  2.215 ( 1.089)	Loss 9.5192e-02 (8.3799e-02) 
2023-05-26 00:49:31.128842: train Epoch: [59][123/129]	Time  0.967 ( 2.054)	Data  0.001 ( 1.080)	Loss 1.4481e-01 (8.4291e-02) 
2023-05-26 00:49:34.218398: train Epoch: [59][124/129]	Time  3.090 ( 2.062)	Data  2.121 ( 1.089)	Loss 4.7276e-02 (8.3995e-02) 
2023-05-26 00:49:35.190440: train Epoch: [59][125/129]	Time  0.972 ( 2.053)	Data  0.001 ( 1.080)	Loss 3.2244e-02 (8.3584e-02) 
2023-05-26 00:49:37.823489: train Epoch: [59][126/129]	Time  2.633 ( 2.058)	Data  1.665 ( 1.085)	Loss 1.6788e-01 (8.4248e-02) 
2023-05-26 00:49:38.808030: train Epoch: [59][127/129]	Time  0.985 ( 2.050)	Data  0.001 ( 1.076)	Loss 4.9045e-02 (8.3973e-02) 
2023-05-26 00:49:40.744569: train Epoch: [59][128/129]	Time  1.937 ( 2.049)	Data  0.957 ( 1.075)	Loss 6.3360e-02 (8.3813e-02) 
2023-05-26 00:49:40.783850: Train Epoch done in 264.3312116870002 s 
2023-05-26 00:49:43.682360: val Epoch: [59][ 0/72]	Time  1.870 ( 1.870)	Data  1.655 ( 1.655)	Loss 4.4100e-01 (4.4100e-01) 
2023-05-26 00:49:43.815893: val Epoch: [59][ 1/72]	Time  0.134 ( 1.002)	Data  0.002 ( 0.828)	Loss 9.0702e-02 (2.6585e-01) 
2023-05-26 00:49:45.001159: val Epoch: [59][ 2/72]	Time  1.185 ( 1.063)	Data  1.034 ( 0.897)	Loss 3.6356e-02 (1.8935e-01) 
2023-05-26 00:49:45.132932: val Epoch: [59][ 3/72]	Time  0.132 ( 0.830)	Data  0.001 ( 0.673)	Loss 6.1196e-02 (1.5731e-01) 
2023-05-26 00:49:46.453234: val Epoch: [59][ 4/72]	Time  1.320 ( 0.928)	Data  1.169 ( 0.772)	Loss 5.9630e-02 (1.3778e-01) 
2023-05-26 00:49:46.590218: val Epoch: [59][ 5/72]	Time  0.137 ( 0.796)	Data  0.001 ( 0.644)	Loss 1.0884e-01 (1.3295e-01) 
2023-05-26 00:49:47.866456: val Epoch: [59][ 6/72]	Time  1.276 ( 0.865)	Data  1.133 ( 0.714)	Loss 1.6053e-01 (1.3689e-01) 
2023-05-26 00:49:48.003606: val Epoch: [59][ 7/72]	Time  0.137 ( 0.774)	Data  0.001 ( 0.625)	Loss 1.8053e-01 (1.4235e-01) 
2023-05-26 00:49:49.226336: val Epoch: [59][ 8/72]	Time  1.223 ( 0.824)	Data  1.095 ( 0.677)	Loss 6.2587e-02 (1.3349e-01) 
2023-05-26 00:49:49.357061: val Epoch: [59][ 9/72]	Time  0.131 ( 0.754)	Data  0.001 ( 0.609)	Loss 9.3812e-02 (1.2952e-01) 
2023-05-26 00:49:50.580605: val Epoch: [59][10/72]	Time  1.224 ( 0.797)	Data  1.085 ( 0.652)	Loss 2.8113e-01 (1.4330e-01) 
2023-05-26 00:49:50.729972: val Epoch: [59][11/72]	Time  0.149 ( 0.743)	Data  0.018 ( 0.600)	Loss 3.5110e-01 (1.6062e-01) 
2023-05-26 00:49:51.956744: val Epoch: [59][12/72]	Time  1.227 ( 0.780)	Data  1.088 ( 0.637)	Loss 2.8943e-01 (1.7053e-01) 
2023-05-26 00:49:52.128270: val Epoch: [59][13/72]	Time  0.172 ( 0.737)	Data  0.030 ( 0.594)	Loss 2.3816e-01 (1.7536e-01) 
2023-05-26 00:49:53.336902: val Epoch: [59][14/72]	Time  1.209 ( 0.768)	Data  1.072 ( 0.626)	Loss 4.6338e-02 (1.6676e-01) 
2023-05-26 00:49:53.529153: val Epoch: [59][15/72]	Time  0.192 ( 0.732)	Data  0.056 ( 0.590)	Loss 7.1592e-02 (1.6081e-01) 
2023-05-26 00:49:54.720922: val Epoch: [59][16/72]	Time  1.192 ( 0.759)	Data  1.051 ( 0.617)	Loss 1.2187e-01 (1.5852e-01) 
2023-05-26 00:49:54.909621: val Epoch: [59][17/72]	Time  0.189 ( 0.728)	Data  0.064 ( 0.586)	Loss 1.4237e-01 (1.5762e-01) 
2023-05-26 00:49:56.082876: val Epoch: [59][18/72]	Time  1.173 ( 0.751)	Data  1.045 ( 0.611)	Loss 2.6696e-01 (1.6337e-01) 
2023-05-26 00:49:56.232628: val Epoch: [59][19/72]	Time  0.150 ( 0.721)	Data  0.022 ( 0.581)	Loss 7.8174e-02 (1.5911e-01) 
2023-05-26 00:49:57.410565: val Epoch: [59][20/72]	Time  1.178 ( 0.743)	Data  1.049 ( 0.603)	Loss 6.1500e-02 (1.5447e-01) 
2023-05-26 00:49:57.653367: val Epoch: [59][21/72]	Time  0.243 ( 0.720)	Data  0.111 ( 0.581)	Loss 3.3662e-01 (1.6275e-01) 
2023-05-26 00:49:58.737897: val Epoch: [59][22/72]	Time  1.085 ( 0.736)	Data  0.961 ( 0.598)	Loss 1.6773e-01 (1.6296e-01) 
2023-05-26 00:49:59.005970: val Epoch: [59][23/72]	Time  0.268 ( 0.716)	Data  0.137 ( 0.578)	Loss 5.2038e-02 (1.5834e-01) 
2023-05-26 00:50:00.108733: val Epoch: [59][24/72]	Time  1.103 ( 0.732)	Data  0.975 ( 0.594)	Loss 1.1168e-01 (1.5647e-01) 
2023-05-26 00:50:00.382202: val Epoch: [59][25/72]	Time  0.273 ( 0.714)	Data  0.146 ( 0.577)	Loss 1.0314e-01 (1.5442e-01) 
2023-05-26 00:50:01.536420: val Epoch: [59][26/72]	Time  1.154 ( 0.731)	Data  1.023 ( 0.593)	Loss 4.9681e-02 (1.5054e-01) 
2023-05-26 00:50:01.767458: val Epoch: [59][27/72]	Time  0.231 ( 0.713)	Data  0.092 ( 0.576)	Loss 1.9663e-01 (1.5219e-01) 
2023-05-26 00:50:02.861342: val Epoch: [59][28/72]	Time  1.094 ( 0.726)	Data  0.963 ( 0.589)	Loss 2.9483e-02 (1.4796e-01) 
2023-05-26 00:50:03.136312: val Epoch: [59][29/72]	Time  0.275 ( 0.711)	Data  0.144 ( 0.574)	Loss 3.9774e-01 (1.5629e-01) 
2023-05-26 00:50:04.278864: val Epoch: [59][30/72]	Time  1.143 ( 0.725)	Data  1.013 ( 0.588)	Loss 4.1102e-02 (1.5257e-01) 
2023-05-26 00:50:04.492923: val Epoch: [59][31/72]	Time  0.214 ( 0.709)	Data  0.085 ( 0.573)	Loss 7.1065e-02 (1.5002e-01) 
2023-05-26 00:50:05.619462: val Epoch: [59][32/72]	Time  1.127 ( 0.721)	Data  1.000 ( 0.586)	Loss 6.8942e-02 (1.4757e-01) 
2023-05-26 00:50:05.901994: val Epoch: [59][33/72]	Time  0.283 ( 0.709)	Data  0.149 ( 0.573)	Loss 1.0139e-01 (1.4621e-01) 
2023-05-26 00:50:06.996737: val Epoch: [59][34/72]	Time  1.095 ( 0.720)	Data  0.962 ( 0.584)	Loss 3.9718e-02 (1.4316e-01) 
2023-05-26 00:50:07.245442: val Epoch: [59][35/72]	Time  0.249 ( 0.706)	Data  0.117 ( 0.571)	Loss 1.3421e-01 (1.4292e-01) 
2023-05-26 00:50:08.417472: val Epoch: [59][36/72]	Time  1.172 ( 0.719)	Data  1.040 ( 0.584)	Loss 1.0379e-01 (1.4186e-01) 
2023-05-26 00:50:08.582675: val Epoch: [59][37/72]	Time  0.165 ( 0.704)	Data  0.032 ( 0.569)	Loss 4.2258e-02 (1.3924e-01) 
2023-05-26 00:50:09.810424: val Epoch: [59][38/72]	Time  1.228 ( 0.718)	Data  1.092 ( 0.582)	Loss 2.8882e-01 (1.4307e-01) 
2023-05-26 00:50:10.025486: val Epoch: [59][39/72]	Time  0.215 ( 0.705)	Data  0.083 ( 0.570)	Loss 1.1969e-01 (1.4249e-01) 
2023-05-26 00:50:11.196183: val Epoch: [59][40/72]	Time  1.171 ( 0.717)	Data  1.038 ( 0.581)	Loss 1.6543e-01 (1.4305e-01) 
2023-05-26 00:50:11.423765: val Epoch: [59][41/72]	Time  0.228 ( 0.705)	Data  0.100 ( 0.570)	Loss 4.1784e-01 (1.4959e-01) 
2023-05-26 00:50:12.557003: val Epoch: [59][42/72]	Time  1.133 ( 0.715)	Data  1.005 ( 0.580)	Loss 9.0381e-02 (1.4821e-01) 
2023-05-26 00:50:12.868299: val Epoch: [59][43/72]	Time  0.311 ( 0.706)	Data  0.183 ( 0.571)	Loss 8.7842e-02 (1.4684e-01) 
2023-05-26 00:50:13.967626: val Epoch: [59][44/72]	Time  1.099 ( 0.715)	Data  0.973 ( 0.580)	Loss 3.5657e-01 (1.5150e-01) 
2023-05-26 00:50:14.233652: val Epoch: [59][45/72]	Time  0.266 ( 0.705)	Data  0.132 ( 0.570)	Loss 9.2417e-02 (1.5022e-01) 
2023-05-26 00:50:15.401906: val Epoch: [59][46/72]	Time  1.168 ( 0.715)	Data  1.026 ( 0.580)	Loss 1.7850e-01 (1.5082e-01) 
2023-05-26 00:50:15.601591: val Epoch: [59][47/72]	Time  0.200 ( 0.704)	Data  0.060 ( 0.569)	Loss 4.1584e-02 (1.4854e-01) 
2023-05-26 00:50:16.765647: val Epoch: [59][48/72]	Time  1.164 ( 0.713)	Data  1.021 ( 0.578)	Loss 1.3684e-01 (1.4830e-01) 
2023-05-26 00:50:17.031612: val Epoch: [59][49/72]	Time  0.266 ( 0.704)	Data  0.132 ( 0.569)	Loss 3.1197e-01 (1.5158e-01) 
2023-05-26 00:50:18.112564: val Epoch: [59][50/72]	Time  1.081 ( 0.712)	Data  0.951 ( 0.577)	Loss 5.4030e-02 (1.4967e-01) 
2023-05-26 00:50:18.401142: val Epoch: [59][51/72]	Time  0.289 ( 0.704)	Data  0.152 ( 0.569)	Loss 5.8109e-02 (1.4790e-01) 
2023-05-26 00:50:19.490916: val Epoch: [59][52/72]	Time  1.090 ( 0.711)	Data  0.962 ( 0.576)	Loss 5.0741e-02 (1.4607e-01) 
2023-05-26 00:50:19.806324: val Epoch: [59][53/72]	Time  0.315 ( 0.704)	Data  0.181 ( 0.569)	Loss 6.6076e-02 (1.4459e-01) 
2023-05-26 00:50:20.877020: val Epoch: [59][54/72]	Time  1.071 ( 0.710)	Data  0.939 ( 0.575)	Loss 6.0889e-02 (1.4307e-01) 
2023-05-26 00:50:21.193159: val Epoch: [59][55/72]	Time  0.316 ( 0.703)	Data  0.183 ( 0.568)	Loss 6.1020e-02 (1.4160e-01) 
2023-05-26 00:50:22.254151: val Epoch: [59][56/72]	Time  1.061 ( 0.710)	Data  0.929 ( 0.575)	Loss 4.4441e-02 (1.3990e-01) 
2023-05-26 00:50:22.559252: val Epoch: [59][57/72]	Time  0.305 ( 0.703)	Data  0.174 ( 0.568)	Loss 1.3909e-01 (1.3988e-01) 
2023-05-26 00:50:23.641629: val Epoch: [59][58/72]	Time  1.082 ( 0.709)	Data  0.950 ( 0.574)	Loss 4.5879e-02 (1.3829e-01) 
2023-05-26 00:50:23.894442: val Epoch: [59][59/72]	Time  0.253 ( 0.701)	Data  0.119 ( 0.567)	Loss 7.7851e-02 (1.3728e-01) 
2023-05-26 00:50:25.025129: val Epoch: [59][60/72]	Time  1.131 ( 0.708)	Data  0.991 ( 0.574)	Loss 4.7640e-02 (1.3581e-01) 
2023-05-26 00:50:25.293614: val Epoch: [59][61/72]	Time  0.268 ( 0.701)	Data  0.113 ( 0.566)	Loss 1.9367e-01 (1.3675e-01) 
2023-05-26 00:50:26.436736: val Epoch: [59][62/72]	Time  1.143 ( 0.708)	Data  1.011 ( 0.573)	Loss 2.3752e-01 (1.3835e-01) 
2023-05-26 00:50:26.686250: val Epoch: [59][63/72]	Time  0.250 ( 0.701)	Data  0.119 ( 0.566)	Loss 7.7286e-02 (1.3739e-01) 
2023-05-26 00:50:27.766528: val Epoch: [59][64/72]	Time  1.080 ( 0.707)	Data  0.948 ( 0.572)	Loss 4.6125e-02 (1.3599e-01) 
2023-05-26 00:50:28.091364: val Epoch: [59][65/72]	Time  0.325 ( 0.701)	Data  0.193 ( 0.566)	Loss 9.8152e-02 (1.3542e-01) 
2023-05-26 00:50:29.141773: val Epoch: [59][66/72]	Time  1.050 ( 0.706)	Data  0.911 ( 0.572)	Loss 1.5349e-01 (1.3569e-01) 
2023-05-26 00:50:29.473634: val Epoch: [59][67/72]	Time  0.332 ( 0.701)	Data  0.192 ( 0.566)	Loss 6.1521e-02 (1.3459e-01) 
2023-05-26 00:50:30.572457: val Epoch: [59][68/72]	Time  1.099 ( 0.707)	Data  0.952 ( 0.572)	Loss 9.5674e-02 (1.3403e-01) 
2023-05-26 00:50:30.883922: val Epoch: [59][69/72]	Time  0.311 ( 0.701)	Data  0.170 ( 0.566)	Loss 3.5525e-01 (1.3719e-01) 
2023-05-26 00:50:31.938114: val Epoch: [59][70/72]	Time  1.054 ( 0.706)	Data  0.907 ( 0.571)	Loss 2.4275e-01 (1.3868e-01) 
2023-05-26 00:50:32.121955: val Epoch: [59][71/72]	Time  0.184 ( 0.699)	Data  0.053 ( 0.563)	Loss 9.0773e-02 (1.3801e-01) 
2023-05-26 00:50:32.344095: Epoch 59 :Val : ['ET : 0.7313601970672607', 'TC : 0.7625428438186646', 'WT : 0.8577608466148376'] 
2023-05-26 00:50:32.347155: Epoch 59 :Val : ['ET : 0.7313601970672607', 'TC : 0.7625428438186646', 'WT : 0.8577608466148376'] 
2023-05-26 00:50:32.349900: Val epoch done in 51.566051816000254 s 
2023-05-26 00:50:32.358097: Batches per epoch:  129 
2023-05-26 00:50:37.653400: train Epoch: [60][  0/129]	Time  5.295 ( 5.295)	Data  4.254 ( 4.254)	Loss 1.2062e-01 (1.2062e-01) 
2023-05-26 00:50:38.624491: train Epoch: [60][  1/129]	Time  0.971 ( 3.133)	Data  0.001 ( 2.127)	Loss 1.0579e-01 (1.1320e-01) 
2023-05-26 00:50:41.695417: train Epoch: [60][  2/129]	Time  3.071 ( 3.112)	Data  2.115 ( 2.123)	Loss 1.0615e-01 (1.1085e-01) 
2023-05-26 00:50:42.656349: train Epoch: [60][  3/129]	Time  0.961 ( 2.574)	Data  0.001 ( 1.593)	Loss 6.5721e-02 (9.9569e-02) 
2023-05-26 00:50:45.762514: train Epoch: [60][  4/129]	Time  3.106 ( 2.681)	Data  2.134 ( 1.701)	Loss 8.3360e-02 (9.6327e-02) 
2023-05-26 00:50:46.740942: train Epoch: [60][  5/129]	Time  0.978 ( 2.397)	Data  0.001 ( 1.418)	Loss 1.3177e-01 (1.0223e-01) 
2023-05-26 00:50:49.757940: train Epoch: [60][  6/129]	Time  3.017 ( 2.486)	Data  2.045 ( 1.507)	Loss 1.0889e-01 (1.0318e-01) 
2023-05-26 00:50:50.724350: train Epoch: [60][  7/129]	Time  0.966 ( 2.296)	Data  0.001 ( 1.319)	Loss 6.0168e-02 (9.7807e-02) 
2023-05-26 00:50:53.754811: train Epoch: [60][  8/129]	Time  3.030 ( 2.377)	Data  2.079 ( 1.403)	Loss 7.1387e-02 (9.4872e-02) 
2023-05-26 00:50:54.721070: train Epoch: [60][  9/129]	Time  0.966 ( 2.236)	Data  0.001 ( 1.263)	Loss 8.6231e-02 (9.4008e-02) 
2023-05-26 00:50:57.979095: train Epoch: [60][ 10/129]	Time  3.258 ( 2.329)	Data  2.286 ( 1.356)	Loss 8.5924e-02 (9.3273e-02) 
2023-05-26 00:50:58.942464: train Epoch: [60][ 11/129]	Time  0.963 ( 2.215)	Data  0.001 ( 1.243)	Loss 1.0016e-01 (9.3847e-02) 
2023-05-26 00:51:02.032973: train Epoch: [60][ 12/129]	Time  3.090 ( 2.283)	Data  2.113 ( 1.310)	Loss 1.0447e-01 (9.4664e-02) 
2023-05-26 00:51:03.006079: train Epoch: [60][ 13/129]	Time  0.973 ( 2.189)	Data  0.001 ( 1.217)	Loss 4.9418e-02 (9.1432e-02) 
2023-05-26 00:51:06.157170: train Epoch: [60][ 14/129]	Time  3.151 ( 2.253)	Data  2.175 ( 1.281)	Loss 7.9616e-02 (9.0644e-02) 
2023-05-26 00:51:07.146756: train Epoch: [60][ 15/129]	Time  0.990 ( 2.174)	Data  0.001 ( 1.201)	Loss 1.6904e-01 (9.5544e-02) 
2023-05-26 00:51:10.348051: train Epoch: [60][ 16/129]	Time  3.201 ( 2.235)	Data  2.224 ( 1.261)	Loss 9.5147e-02 (9.5521e-02) 
2023-05-26 00:51:11.312927: train Epoch: [60][ 17/129]	Time  0.965 ( 2.164)	Data  0.001 ( 1.191)	Loss 9.4115e-02 (9.5443e-02) 
2023-05-26 00:51:14.333750: train Epoch: [60][ 18/129]	Time  3.021 ( 2.209)	Data  2.039 ( 1.235)	Loss 6.8913e-02 (9.4046e-02) 
2023-05-26 00:51:15.310378: train Epoch: [60][ 19/129]	Time  0.977 ( 2.148)	Data  0.002 ( 1.174)	Loss 5.9279e-02 (9.2308e-02) 
2023-05-26 00:51:18.605904: train Epoch: [60][ 20/129]	Time  3.296 ( 2.202)	Data  2.320 ( 1.228)	Loss 6.3010e-02 (9.0913e-02) 
2023-05-26 00:51:19.586390: train Epoch: [60][ 21/129]	Time  0.980 ( 2.147)	Data  0.001 ( 1.173)	Loss 7.4185e-02 (9.0152e-02) 
2023-05-26 00:51:22.644878: train Epoch: [60][ 22/129]	Time  3.058 ( 2.186)	Data  2.075 ( 1.212)	Loss 6.2461e-02 (8.8949e-02) 
2023-05-26 00:51:23.609980: train Epoch: [60][ 23/129]	Time  0.965 ( 2.135)	Data  0.001 ( 1.161)	Loss 8.3774e-02 (8.8733e-02) 
2023-05-26 00:51:26.759251: train Epoch: [60][ 24/129]	Time  3.149 ( 2.176)	Data  2.183 ( 1.202)	Loss 7.7330e-02 (8.8277e-02) 
2023-05-26 00:51:27.722550: train Epoch: [60][ 25/129]	Time  0.963 ( 2.129)	Data  0.001 ( 1.156)	Loss 8.0027e-02 (8.7960e-02) 
2023-05-26 00:51:30.962900: train Epoch: [60][ 26/129]	Time  3.240 ( 2.171)	Data  2.262 ( 1.197)	Loss 4.0043e-02 (8.6185e-02) 
2023-05-26 00:51:31.927981: train Epoch: [60][ 27/129]	Time  0.965 ( 2.127)	Data  0.001 ( 1.154)	Loss 7.8017e-02 (8.5893e-02) 
2023-05-26 00:51:35.125611: train Epoch: [60][ 28/129]	Time  3.198 ( 2.164)	Data  2.237 ( 1.192)	Loss 7.5519e-02 (8.5535e-02) 
2023-05-26 00:51:36.095681: train Epoch: [60][ 29/129]	Time  0.970 ( 2.125)	Data  0.002 ( 1.152)	Loss 8.2181e-02 (8.5424e-02) 
2023-05-26 00:51:39.222725: train Epoch: [60][ 30/129]	Time  3.127 ( 2.157)	Data  2.150 ( 1.184)	Loss 7.7923e-02 (8.5182e-02) 
2023-05-26 00:51:40.187747: train Epoch: [60][ 31/129]	Time  0.965 ( 2.120)	Data  0.001 ( 1.147)	Loss 1.2473e-01 (8.6418e-02) 
2023-05-26 00:51:43.206068: train Epoch: [60][ 32/129]	Time  3.018 ( 2.147)	Data  2.052 ( 1.175)	Loss 1.9418e-01 (8.9683e-02) 
2023-05-26 00:51:44.193492: train Epoch: [60][ 33/129]	Time  0.987 ( 2.113)	Data  0.002 ( 1.140)	Loss 4.2248e-02 (8.8288e-02) 
2023-05-26 00:51:47.208987: train Epoch: [60][ 34/129]	Time  3.015 ( 2.139)	Data  2.031 ( 1.166)	Loss 8.9901e-02 (8.8334e-02) 
2023-05-26 00:51:48.173739: train Epoch: [60][ 35/129]	Time  0.965 ( 2.106)	Data  0.001 ( 1.133)	Loss 8.5551e-02 (8.8257e-02) 
2023-05-26 00:51:51.412650: train Epoch: [60][ 36/129]	Time  3.239 ( 2.137)	Data  2.281 ( 1.164)	Loss 9.6987e-02 (8.8493e-02) 
2023-05-26 00:51:52.381589: train Epoch: [60][ 37/129]	Time  0.969 ( 2.106)	Data  0.001 ( 1.134)	Loss 1.1837e-01 (8.9279e-02) 
2023-05-26 00:51:55.552870: train Epoch: [60][ 38/129]	Time  3.171 ( 2.133)	Data  2.210 ( 1.161)	Loss 7.0458e-02 (8.8796e-02) 
2023-05-26 00:51:56.530268: train Epoch: [60][ 39/129]	Time  0.977 ( 2.104)	Data  0.001 ( 1.132)	Loss 9.9949e-02 (8.9075e-02) 
2023-05-26 00:51:59.592197: train Epoch: [60][ 40/129]	Time  3.062 ( 2.128)	Data  2.108 ( 1.156)	Loss 1.2992e-01 (9.0071e-02) 
2023-05-26 00:52:00.548811: train Epoch: [60][ 41/129]	Time  0.957 ( 2.100)	Data  0.001 ( 1.129)	Loss 1.1544e-01 (9.0675e-02) 
2023-05-26 00:52:03.698393: train Epoch: [60][ 42/129]	Time  3.150 ( 2.124)	Data  2.192 ( 1.153)	Loss 9.5478e-02 (9.0787e-02) 
2023-05-26 00:52:04.665361: train Epoch: [60][ 43/129]	Time  0.967 ( 2.098)	Data  0.001 ( 1.127)	Loss 9.0855e-02 (9.0789e-02) 
2023-05-26 00:52:07.727569: train Epoch: [60][ 44/129]	Time  3.062 ( 2.119)	Data  2.101 ( 1.149)	Loss 5.3902e-02 (8.9969e-02) 
2023-05-26 00:52:08.690002: train Epoch: [60][ 45/129]	Time  0.962 ( 2.094)	Data  0.001 ( 1.124)	Loss 7.6737e-02 (8.9681e-02) 
2023-05-26 00:52:11.811973: train Epoch: [60][ 46/129]	Time  3.122 ( 2.116)	Data  2.157 ( 1.146)	Loss 7.2975e-02 (8.9326e-02) 
2023-05-26 00:52:12.783293: train Epoch: [60][ 47/129]	Time  0.971 ( 2.092)	Data  0.002 ( 1.122)	Loss 1.2087e-01 (8.9983e-02) 
2023-05-26 00:52:15.964299: train Epoch: [60][ 48/129]	Time  3.181 ( 2.114)	Data  2.222 ( 1.144)	Loss 1.0228e-01 (9.0234e-02) 
2023-05-26 00:52:16.921805: train Epoch: [60][ 49/129]	Time  0.957 ( 2.091)	Data  0.001 ( 1.122)	Loss 7.2939e-02 (8.9888e-02) 
2023-05-26 00:52:20.106549: train Epoch: [60][ 50/129]	Time  3.185 ( 2.113)	Data  2.228 ( 1.143)	Loss 6.4179e-02 (8.9384e-02) 
2023-05-26 00:52:21.079253: train Epoch: [60][ 51/129]	Time  0.973 ( 2.091)	Data  0.001 ( 1.121)	Loss 5.0590e-02 (8.8638e-02) 
2023-05-26 00:52:24.296995: train Epoch: [60][ 52/129]	Time  3.218 ( 2.112)	Data  2.260 ( 1.143)	Loss 8.1958e-02 (8.8512e-02) 
2023-05-26 00:52:25.270195: train Epoch: [60][ 53/129]	Time  0.973 ( 2.091)	Data  0.001 ( 1.122)	Loss 1.7265e-01 (9.0070e-02) 
2023-05-26 00:52:28.113952: train Epoch: [60][ 54/129]	Time  2.844 ( 2.105)	Data  1.891 ( 1.136)	Loss 7.2306e-02 (8.9747e-02) 
2023-05-26 00:52:29.065701: train Epoch: [60][ 55/129]	Time  0.952 ( 2.084)	Data  0.001 ( 1.115)	Loss 5.9499e-02 (8.9207e-02) 
2023-05-26 00:52:31.858076: train Epoch: [60][ 56/129]	Time  2.792 ( 2.096)	Data  1.845 ( 1.128)	Loss 5.3724e-02 (8.8585e-02) 
2023-05-26 00:52:32.808907: train Epoch: [60][ 57/129]	Time  0.951 ( 2.077)	Data  0.001 ( 1.109)	Loss 1.0025e-01 (8.8786e-02) 
2023-05-26 00:52:35.608995: train Epoch: [60][ 58/129]	Time  2.800 ( 2.089)	Data  1.840 ( 1.121)	Loss 6.5466e-02 (8.8390e-02) 
2023-05-26 00:52:36.560489: train Epoch: [60][ 59/129]	Time  0.951 ( 2.070)	Data  0.001 ( 1.102)	Loss 9.4581e-02 (8.8494e-02) 
2023-05-26 00:52:39.300663: train Epoch: [60][ 60/129]	Time  2.740 ( 2.081)	Data  1.784 ( 1.114)	Loss 8.1315e-02 (8.8376e-02) 
2023-05-26 00:52:40.252496: train Epoch: [60][ 61/129]	Time  0.952 ( 2.063)	Data  0.001 ( 1.096)	Loss 1.2647e-01 (8.8990e-02) 
2023-05-26 00:52:42.973815: train Epoch: [60][ 62/129]	Time  2.721 ( 2.073)	Data  1.773 ( 1.106)	Loss 1.0059e-01 (8.9174e-02) 
2023-05-26 00:52:43.929264: train Epoch: [60][ 63/129]	Time  0.955 ( 2.056)	Data  0.001 ( 1.089)	Loss 8.7271e-02 (8.9145e-02) 
2023-05-26 00:52:46.585685: train Epoch: [60][ 64/129]	Time  2.656 ( 2.065)	Data  1.709 ( 1.099)	Loss 5.4796e-02 (8.8616e-02) 
2023-05-26 00:52:47.536318: train Epoch: [60][ 65/129]	Time  0.951 ( 2.048)	Data  0.001 ( 1.082)	Loss 8.1275e-02 (8.8505e-02) 
2023-05-26 00:52:50.221868: train Epoch: [60][ 66/129]	Time  2.686 ( 2.058)	Data  1.746 ( 1.092)	Loss 1.2700e-01 (8.9080e-02) 
2023-05-26 00:52:51.164823: train Epoch: [60][ 67/129]	Time  0.943 ( 2.041)	Data  0.001 ( 1.076)	Loss 1.0742e-01 (8.9349e-02) 
2023-05-26 00:52:53.762014: train Epoch: [60][ 68/129]	Time  2.597 ( 2.049)	Data  1.655 ( 1.084)	Loss 1.0502e-01 (8.9577e-02) 
2023-05-26 00:52:54.707222: train Epoch: [60][ 69/129]	Time  0.945 ( 2.034)	Data  0.001 ( 1.069)	Loss 7.1078e-02 (8.9312e-02) 
2023-05-26 00:52:57.443951: train Epoch: [60][ 70/129]	Time  2.737 ( 2.043)	Data  1.795 ( 1.079)	Loss 7.8742e-02 (8.9163e-02) 
2023-05-26 00:52:58.387748: train Epoch: [60][ 71/129]	Time  0.944 ( 2.028)	Data  0.001 ( 1.064)	Loss 5.3389e-02 (8.8667e-02) 
2023-05-26 00:53:01.057032: train Epoch: [60][ 72/129]	Time  2.669 ( 2.037)	Data  1.729 ( 1.073)	Loss 8.8343e-02 (8.8662e-02) 
2023-05-26 00:53:02.001452: train Epoch: [60][ 73/129]	Time  0.944 ( 2.022)	Data  0.001 ( 1.059)	Loss 6.8985e-02 (8.8396e-02) 
2023-05-26 00:53:04.695701: train Epoch: [60][ 74/129]	Time  2.694 ( 2.031)	Data  1.753 ( 1.068)	Loss 1.0154e-01 (8.8571e-02) 
2023-05-26 00:53:05.640339: train Epoch: [60][ 75/129]	Time  0.945 ( 2.017)	Data  0.001 ( 1.054)	Loss 1.1596e-01 (8.8932e-02) 
2023-05-26 00:53:08.494127: train Epoch: [60][ 76/129]	Time  2.854 ( 2.028)	Data  1.888 ( 1.065)	Loss 8.6028e-02 (8.8894e-02) 
2023-05-26 00:53:09.440300: train Epoch: [60][ 77/129]	Time  0.946 ( 2.014)	Data  0.001 ( 1.051)	Loss 9.5155e-02 (8.8974e-02) 
2023-05-26 00:53:12.557926: train Epoch: [60][ 78/129]	Time  3.118 ( 2.028)	Data  2.157 ( 1.065)	Loss 6.6712e-02 (8.8693e-02) 
2023-05-26 00:53:13.515316: train Epoch: [60][ 79/129]	Time  0.957 ( 2.014)	Data  0.001 ( 1.052)	Loss 5.6753e-02 (8.8293e-02) 
2023-05-26 00:53:16.572148: train Epoch: [60][ 80/129]	Time  3.057 ( 2.027)	Data  2.084 ( 1.065)	Loss 5.4137e-02 (8.7872e-02) 
2023-05-26 00:53:17.532397: train Epoch: [60][ 81/129]	Time  0.960 ( 2.014)	Data  0.002 ( 1.052)	Loss 5.2937e-02 (8.7446e-02) 
2023-05-26 00:53:20.776215: train Epoch: [60][ 82/129]	Time  3.244 ( 2.029)	Data  2.286 ( 1.066)	Loss 8.8671e-02 (8.7460e-02) 
2023-05-26 00:53:21.750530: train Epoch: [60][ 83/129]	Time  0.974 ( 2.017)	Data  0.001 ( 1.054)	Loss 5.1708e-02 (8.7035e-02) 
2023-05-26 00:53:24.741117: train Epoch: [60][ 84/129]	Time  2.991 ( 2.028)	Data  2.034 ( 1.065)	Loss 7.2252e-02 (8.6861e-02) 
2023-05-26 00:53:25.699958: train Epoch: [60][ 85/129]	Time  0.959 ( 2.016)	Data  0.001 ( 1.053)	Loss 6.0801e-02 (8.6558e-02) 
2023-05-26 00:53:28.933132: train Epoch: [60][ 86/129]	Time  3.233 ( 2.030)	Data  2.264 ( 1.067)	Loss 1.2278e-01 (8.6974e-02) 
2023-05-26 00:53:29.901767: train Epoch: [60][ 87/129]	Time  0.969 ( 2.018)	Data  0.001 ( 1.055)	Loss 4.2827e-02 (8.6472e-02) 
2023-05-26 00:53:32.979920: train Epoch: [60][ 88/129]	Time  3.078 ( 2.029)	Data  2.122 ( 1.067)	Loss 6.8738e-02 (8.6273e-02) 
2023-05-26 00:53:33.951457: train Epoch: [60][ 89/129]	Time  0.972 ( 2.018)	Data  0.001 ( 1.055)	Loss 9.4217e-02 (8.6361e-02) 
2023-05-26 00:53:37.066067: train Epoch: [60][ 90/129]	Time  3.115 ( 2.030)	Data  2.158 ( 1.067)	Loss 1.0233e-01 (8.6537e-02) 
2023-05-26 00:53:38.037512: train Epoch: [60][ 91/129]	Time  0.971 ( 2.018)	Data  0.001 ( 1.055)	Loss 9.8300e-02 (8.6665e-02) 
2023-05-26 00:53:41.181769: train Epoch: [60][ 92/129]	Time  3.144 ( 2.030)	Data  2.189 ( 1.068)	Loss 1.4576e-01 (8.7300e-02) 
2023-05-26 00:53:42.149898: train Epoch: [60][ 93/129]	Time  0.968 ( 2.019)	Data  0.001 ( 1.056)	Loss 7.4676e-02 (8.7166e-02) 
2023-05-26 00:53:45.260891: train Epoch: [60][ 94/129]	Time  3.111 ( 2.031)	Data  2.155 ( 1.068)	Loss 8.5704e-02 (8.7151e-02) 
2023-05-26 00:53:46.220577: train Epoch: [60][ 95/129]	Time  0.960 ( 2.019)	Data  0.001 ( 1.057)	Loss 4.9947e-02 (8.6763e-02) 
2023-05-26 00:53:49.269527: train Epoch: [60][ 96/129]	Time  3.049 ( 2.030)	Data  2.092 ( 1.067)	Loss 6.3217e-02 (8.6520e-02) 
2023-05-26 00:53:50.227025: train Epoch: [60][ 97/129]	Time  0.957 ( 2.019)	Data  0.001 ( 1.056)	Loss 3.6730e-02 (8.6012e-02) 
2023-05-26 00:53:53.311985: train Epoch: [60][ 98/129]	Time  3.085 ( 2.030)	Data  2.130 ( 1.067)	Loss 7.3490e-02 (8.5886e-02) 
2023-05-26 00:53:54.272244: train Epoch: [60][ 99/129]	Time  0.960 ( 2.019)	Data  0.001 ( 1.057)	Loss 8.5814e-02 (8.5885e-02) 
2023-05-26 00:53:57.283858: train Epoch: [60][100/129]	Time  3.012 ( 2.029)	Data  2.053 ( 1.067)	Loss 7.5023e-02 (8.5778e-02) 
2023-05-26 00:53:58.255998: train Epoch: [60][101/129]	Time  0.972 ( 2.019)	Data  0.001 ( 1.056)	Loss 5.4244e-02 (8.5468e-02) 
2023-05-26 00:54:01.465297: train Epoch: [60][102/129]	Time  3.209 ( 2.030)	Data  2.251 ( 1.068)	Loss 8.0027e-02 (8.5416e-02) 
2023-05-26 00:54:02.428538: train Epoch: [60][103/129]	Time  0.963 ( 2.020)	Data  0.001 ( 1.057)	Loss 9.4037e-02 (8.5498e-02) 
2023-05-26 00:54:05.527125: train Epoch: [60][104/129]	Time  3.099 ( 2.030)	Data  2.134 ( 1.068)	Loss 8.9019e-02 (8.5532e-02) 
2023-05-26 00:54:06.486377: train Epoch: [60][105/129]	Time  0.959 ( 2.020)	Data  0.001 ( 1.058)	Loss 3.9405e-02 (8.5097e-02) 
2023-05-26 00:54:09.559733: train Epoch: [60][106/129]	Time  3.073 ( 2.030)	Data  2.109 ( 1.067)	Loss 7.0388e-02 (8.4959e-02) 
2023-05-26 00:54:10.529296: train Epoch: [60][107/129]	Time  0.970 ( 2.020)	Data  0.001 ( 1.058)	Loss 4.6549e-02 (8.4604e-02) 
2023-05-26 00:54:13.582294: train Epoch: [60][108/129]	Time  3.053 ( 2.030)	Data  2.084 ( 1.067)	Loss 5.8653e-02 (8.4366e-02) 
2023-05-26 00:54:14.539768: train Epoch: [60][109/129]	Time  0.957 ( 2.020)	Data  0.001 ( 1.057)	Loss 5.4607e-02 (8.4095e-02) 
2023-05-26 00:54:17.549169: train Epoch: [60][110/129]	Time  3.009 ( 2.029)	Data  2.054 ( 1.066)	Loss 8.8515e-02 (8.4135e-02) 
2023-05-26 00:54:18.508991: train Epoch: [60][111/129]	Time  0.960 ( 2.019)	Data  0.001 ( 1.057)	Loss 4.6723e-02 (8.3801e-02) 
2023-05-26 00:54:21.566827: train Epoch: [60][112/129]	Time  3.058 ( 2.028)	Data  2.099 ( 1.066)	Loss 6.5773e-02 (8.3641e-02) 
2023-05-26 00:54:22.534893: train Epoch: [60][113/129]	Time  0.968 ( 2.019)	Data  0.001 ( 1.057)	Loss 1.1630e-01 (8.3928e-02) 
2023-05-26 00:54:25.642296: train Epoch: [60][114/129]	Time  3.107 ( 2.029)	Data  2.129 ( 1.066)	Loss 7.3914e-02 (8.3841e-02) 
2023-05-26 00:54:26.610746: train Epoch: [60][115/129]	Time  0.968 ( 2.019)	Data  0.001 ( 1.057)	Loss 6.2956e-02 (8.3661e-02) 
2023-05-26 00:54:29.634407: train Epoch: [60][116/129]	Time  3.024 ( 2.028)	Data  2.068 ( 1.065)	Loss 5.3599e-02 (8.3404e-02) 
2023-05-26 00:54:30.601574: train Epoch: [60][117/129]	Time  0.967 ( 2.019)	Data  0.001 ( 1.056)	Loss 2.3836e-01 (8.4717e-02) 
2023-05-26 00:54:33.724822: train Epoch: [60][118/129]	Time  3.123 ( 2.028)	Data  2.159 ( 1.066)	Loss 7.6340e-02 (8.4647e-02) 
2023-05-26 00:54:34.689029: train Epoch: [60][119/129]	Time  0.964 ( 2.019)	Data  0.001 ( 1.057)	Loss 7.3199e-02 (8.4551e-02) 
2023-05-26 00:54:37.828598: train Epoch: [60][120/129]	Time  3.140 ( 2.029)	Data  2.179 ( 1.066)	Loss 1.0329e-01 (8.4706e-02) 
2023-05-26 00:54:38.795002: train Epoch: [60][121/129]	Time  0.966 ( 2.020)	Data  0.002 ( 1.057)	Loss 7.1701e-02 (8.4599e-02) 
2023-05-26 00:54:41.783664: train Epoch: [60][122/129]	Time  2.989 ( 2.028)	Data  2.015 ( 1.065)	Loss 8.2523e-02 (8.4582e-02) 
2023-05-26 00:54:42.755581: train Epoch: [60][123/129]	Time  0.972 ( 2.019)	Data  0.001 ( 1.057)	Loss 5.4695e-02 (8.4341e-02) 
2023-05-26 00:54:45.676359: train Epoch: [60][124/129]	Time  2.921 ( 2.027)	Data  1.963 ( 1.064)	Loss 9.8388e-02 (8.4454e-02) 
2023-05-26 00:54:46.650659: train Epoch: [60][125/129]	Time  0.974 ( 2.018)	Data  0.001 ( 1.055)	Loss 7.2454e-02 (8.4359e-02) 
2023-05-26 00:54:49.689298: train Epoch: [60][126/129]	Time  3.039 ( 2.026)	Data  2.089 ( 1.064)	Loss 6.6854e-02 (8.4221e-02) 
2023-05-26 00:54:50.652261: train Epoch: [60][127/129]	Time  0.963 ( 2.018)	Data  0.001 ( 1.055)	Loss 1.4596e-01 (8.4703e-02) 
2023-05-26 00:54:52.794490: train Epoch: [60][128/129]	Time  2.142 ( 2.019)	Data  1.179 ( 1.056)	Loss 1.4928e-01 (8.5204e-02) 
2023-05-26 00:54:52.832147: Train Epoch done in 260.47412382600305 s 
2023-05-26 00:54:55.737599: val Epoch: [60][ 0/72]	Time  1.944 ( 1.944)	Data  1.697 ( 1.697)	Loss 2.4251e-01 (2.4251e-01) 
2023-05-26 00:54:55.887094: val Epoch: [60][ 1/72]	Time  0.150 ( 1.047)	Data  0.002 ( 0.850)	Loss 2.8188e-01 (2.6220e-01) 
2023-05-26 00:54:57.010786: val Epoch: [60][ 2/72]	Time  1.124 ( 1.073)	Data  0.975 ( 0.891)	Loss 7.7585e-02 (2.0066e-01) 
2023-05-26 00:54:57.151388: val Epoch: [60][ 3/72]	Time  0.141 ( 0.840)	Data  0.001 ( 0.669)	Loss 5.3695e-02 (1.6392e-01) 
2023-05-26 00:54:58.431597: val Epoch: [60][ 4/72]	Time  1.280 ( 0.928)	Data  1.136 ( 0.762)	Loss 1.6891e-01 (1.6492e-01) 
2023-05-26 00:54:58.570936: val Epoch: [60][ 5/72]	Time  0.139 ( 0.796)	Data  0.001 ( 0.635)	Loss 1.6755e-01 (1.6536e-01) 
2023-05-26 00:54:59.751498: val Epoch: [60][ 6/72]	Time  1.181 ( 0.851)	Data  1.045 ( 0.694)	Loss 5.5625e-02 (1.4968e-01) 
2023-05-26 00:54:59.876197: val Epoch: [60][ 7/72]	Time  0.125 ( 0.760)	Data  0.001 ( 0.607)	Loss 4.5198e-02 (1.3662e-01) 
2023-05-26 00:55:01.115860: val Epoch: [60][ 8/72]	Time  1.240 ( 0.814)	Data  1.109 ( 0.663)	Loss 5.9996e-02 (1.2811e-01) 
2023-05-26 00:55:01.249202: val Epoch: [60][ 9/72]	Time  0.133 ( 0.746)	Data  0.001 ( 0.597)	Loss 7.2325e-02 (1.2253e-01) 
2023-05-26 00:55:02.500124: val Epoch: [60][10/72]	Time  1.251 ( 0.792)	Data  1.120 ( 0.644)	Loss 6.4048e-02 (1.1721e-01) 
2023-05-26 00:55:02.632248: val Epoch: [60][11/72]	Time  0.132 ( 0.737)	Data  0.001 ( 0.591)	Loss 6.2603e-02 (1.1266e-01) 
2023-05-26 00:55:03.826046: val Epoch: [60][12/72]	Time  1.194 ( 0.772)	Data  1.064 ( 0.627)	Loss 5.5411e-02 (1.0826e-01) 
2023-05-26 00:55:03.958549: val Epoch: [60][13/72]	Time  0.132 ( 0.726)	Data  0.001 ( 0.582)	Loss 6.7252e-02 (1.0533e-01) 
2023-05-26 00:55:05.196262: val Epoch: [60][14/72]	Time  1.238 ( 0.760)	Data  1.109 ( 0.617)	Loss 3.7351e-01 (1.2321e-01) 
2023-05-26 00:55:05.327212: val Epoch: [60][15/72]	Time  0.131 ( 0.721)	Data  0.001 ( 0.579)	Loss 1.0632e-01 (1.2215e-01) 
2023-05-26 00:55:06.574587: val Epoch: [60][16/72]	Time  1.247 ( 0.752)	Data  1.113 ( 0.610)	Loss 9.0298e-02 (1.2028e-01) 
2023-05-26 00:55:06.719925: val Epoch: [60][17/72]	Time  0.145 ( 0.718)	Data  0.001 ( 0.576)	Loss 1.0167e-01 (1.1924e-01) 
2023-05-26 00:55:07.885584: val Epoch: [60][18/72]	Time  1.166 ( 0.742)	Data  1.044 ( 0.601)	Loss 7.5465e-02 (1.1694e-01) 
2023-05-26 00:55:08.008711: val Epoch: [60][19/72]	Time  0.123 ( 0.711)	Data  0.001 ( 0.571)	Loss 3.5998e-02 (1.1289e-01) 
2023-05-26 00:55:09.192979: val Epoch: [60][20/72]	Time  1.184 ( 0.733)	Data  1.056 ( 0.594)	Loss 9.3442e-02 (1.1197e-01) 
2023-05-26 00:55:09.320787: val Epoch: [60][21/72]	Time  0.128 ( 0.706)	Data  0.001 ( 0.567)	Loss 5.5985e-02 (1.0942e-01) 
2023-05-26 00:55:10.525405: val Epoch: [60][22/72]	Time  1.205 ( 0.727)	Data  1.069 ( 0.589)	Loss 3.4406e-01 (1.1962e-01) 
2023-05-26 00:55:10.655687: val Epoch: [60][23/72]	Time  0.130 ( 0.703)	Data  0.001 ( 0.564)	Loss 1.1349e-01 (1.1937e-01) 
2023-05-26 00:55:11.895658: val Epoch: [60][24/72]	Time  1.240 ( 0.724)	Data  1.100 ( 0.586)	Loss 8.7936e-02 (1.1811e-01) 
2023-05-26 00:55:12.031836: val Epoch: [60][25/72]	Time  0.136 ( 0.701)	Data  0.001 ( 0.563)	Loss 1.3133e-01 (1.1862e-01) 
2023-05-26 00:55:13.280331: val Epoch: [60][26/72]	Time  1.248 ( 0.722)	Data  1.121 ( 0.584)	Loss 7.5055e-02 (1.1701e-01) 
2023-05-26 00:55:13.410680: val Epoch: [60][27/72]	Time  0.130 ( 0.701)	Data  0.001 ( 0.563)	Loss 6.0140e-02 (1.1497e-01) 
2023-05-26 00:55:14.634724: val Epoch: [60][28/72]	Time  1.224 ( 0.719)	Data  1.095 ( 0.582)	Loss 3.9944e-01 (1.2478e-01) 
2023-05-26 00:55:14.765396: val Epoch: [60][29/72]	Time  0.131 ( 0.699)	Data  0.001 ( 0.562)	Loss 1.7663e-01 (1.2651e-01) 
2023-05-26 00:55:15.934290: val Epoch: [60][30/72]	Time  1.169 ( 0.714)	Data  1.035 ( 0.577)	Loss 4.8009e-02 (1.2398e-01) 
2023-05-26 00:55:16.064652: val Epoch: [60][31/72]	Time  0.130 ( 0.696)	Data  0.001 ( 0.559)	Loss 1.2829e-01 (1.2411e-01) 
2023-05-26 00:55:17.246999: val Epoch: [60][32/72]	Time  1.182 ( 0.711)	Data  1.055 ( 0.574)	Loss 6.2110e-02 (1.2224e-01) 
2023-05-26 00:55:17.383936: val Epoch: [60][33/72]	Time  0.137 ( 0.694)	Data  0.001 ( 0.558)	Loss 1.4232e-01 (1.2283e-01) 
2023-05-26 00:55:18.644102: val Epoch: [60][34/72]	Time  1.260 ( 0.710)	Data  1.128 ( 0.574)	Loss 4.0658e-02 (1.2048e-01) 
2023-05-26 00:55:18.783879: val Epoch: [60][35/72]	Time  0.140 ( 0.694)	Data  0.001 ( 0.558)	Loss 4.1314e-02 (1.1828e-01) 
2023-05-26 00:55:20.054967: val Epoch: [60][36/72]	Time  1.271 ( 0.710)	Data  1.141 ( 0.574)	Loss 4.8104e-02 (1.1638e-01) 
2023-05-26 00:55:20.186072: val Epoch: [60][37/72]	Time  0.131 ( 0.695)	Data  0.001 ( 0.559)	Loss 3.5216e-01 (1.2259e-01) 
2023-05-26 00:55:21.437266: val Epoch: [60][38/72]	Time  1.251 ( 0.709)	Data  1.124 ( 0.573)	Loss 1.0784e-01 (1.2221e-01) 
2023-05-26 00:55:21.568255: val Epoch: [60][39/72]	Time  0.131 ( 0.694)	Data  0.001 ( 0.559)	Loss 4.5082e-02 (1.2028e-01) 
2023-05-26 00:55:22.768855: val Epoch: [60][40/72]	Time  1.201 ( 0.707)	Data  1.063 ( 0.571)	Loss 6.4359e-02 (1.1892e-01) 
2023-05-26 00:55:22.910310: val Epoch: [60][41/72]	Time  0.141 ( 0.693)	Data  0.001 ( 0.558)	Loss 2.1343e-01 (1.2117e-01) 
2023-05-26 00:55:24.122675: val Epoch: [60][42/72]	Time  1.212 ( 0.705)	Data  1.085 ( 0.570)	Loss 2.0754e-01 (1.2318e-01) 
2023-05-26 00:55:24.249351: val Epoch: [60][43/72]	Time  0.127 ( 0.692)	Data  0.001 ( 0.557)	Loss 7.7320e-02 (1.2213e-01) 
2023-05-26 00:55:25.401473: val Epoch: [60][44/72]	Time  1.152 ( 0.702)	Data  1.025 ( 0.567)	Loss 3.8854e-02 (1.2028e-01) 
2023-05-26 00:55:25.528825: val Epoch: [60][45/72]	Time  0.127 ( 0.690)	Data  0.001 ( 0.555)	Loss 6.3934e-02 (1.1906e-01) 
2023-05-26 00:55:26.759372: val Epoch: [60][46/72]	Time  1.231 ( 0.701)	Data  1.105 ( 0.567)	Loss 4.1699e-01 (1.2540e-01) 
2023-05-26 00:55:26.891011: val Epoch: [60][47/72]	Time  0.132 ( 0.690)	Data  0.001 ( 0.555)	Loss 9.4473e-02 (1.2475e-01) 
2023-05-26 00:55:28.120887: val Epoch: [60][48/72]	Time  1.230 ( 0.701)	Data  1.098 ( 0.566)	Loss 1.8962e-01 (1.2608e-01) 
2023-05-26 00:55:28.257115: val Epoch: [60][49/72]	Time  0.136 ( 0.689)	Data  0.001 ( 0.555)	Loss 4.2159e-02 (1.2440e-01) 
2023-05-26 00:55:29.419713: val Epoch: [60][50/72]	Time  1.163 ( 0.699)	Data  1.037 ( 0.564)	Loss 8.1904e-02 (1.2357e-01) 
2023-05-26 00:55:29.559427: val Epoch: [60][51/72]	Time  0.140 ( 0.688)	Data  0.001 ( 0.553)	Loss 2.9358e-02 (1.2175e-01) 
2023-05-26 00:55:30.725508: val Epoch: [60][52/72]	Time  1.166 ( 0.697)	Data  1.031 ( 0.562)	Loss 2.2454e-01 (1.2369e-01) 
2023-05-26 00:55:30.860561: val Epoch: [60][53/72]	Time  0.135 ( 0.686)	Data  0.001 ( 0.552)	Loss 1.0953e-01 (1.2343e-01) 
2023-05-26 00:55:32.012355: val Epoch: [60][54/72]	Time  1.152 ( 0.695)	Data  1.018 ( 0.560)	Loss 4.8188e-02 (1.2206e-01) 
2023-05-26 00:55:32.158650: val Epoch: [60][55/72]	Time  0.146 ( 0.685)	Data  0.001 ( 0.550)	Loss 1.3373e-01 (1.2227e-01) 
2023-05-26 00:55:33.425248: val Epoch: [60][56/72]	Time  1.267 ( 0.695)	Data  1.138 ( 0.561)	Loss 4.7844e-02 (1.2097e-01) 
2023-05-26 00:55:33.562644: val Epoch: [60][57/72]	Time  0.137 ( 0.686)	Data  0.001 ( 0.551)	Loss 7.9571e-02 (1.2025e-01) 
2023-05-26 00:55:34.815919: val Epoch: [60][58/72]	Time  1.253 ( 0.695)	Data  1.107 ( 0.560)	Loss 1.4722e-01 (1.2071e-01) 
2023-05-26 00:55:34.957382: val Epoch: [60][59/72]	Time  0.141 ( 0.686)	Data  0.001 ( 0.551)	Loss 2.8754e-01 (1.2349e-01) 
2023-05-26 00:55:36.159369: val Epoch: [60][60/72]	Time  1.202 ( 0.695)	Data  1.058 ( 0.559)	Loss 5.8496e-02 (1.2242e-01) 
2023-05-26 00:55:36.296157: val Epoch: [60][61/72]	Time  0.137 ( 0.686)	Data  0.001 ( 0.550)	Loss 4.6265e-02 (1.2120e-01) 
2023-05-26 00:55:37.441195: val Epoch: [60][62/72]	Time  1.145 ( 0.693)	Data  1.012 ( 0.558)	Loss 1.6751e-01 (1.2193e-01) 
2023-05-26 00:55:37.569475: val Epoch: [60][63/72]	Time  0.128 ( 0.684)	Data  0.001 ( 0.549)	Loss 1.4243e-01 (1.2225e-01) 
2023-05-26 00:55:38.787773: val Epoch: [60][64/72]	Time  1.218 ( 0.692)	Data  1.092 ( 0.557)	Loss 8.4289e-02 (1.2167e-01) 
2023-05-26 00:55:38.918469: val Epoch: [60][65/72]	Time  0.131 ( 0.684)	Data  0.001 ( 0.549)	Loss 3.9884e-02 (1.2043e-01) 
2023-05-26 00:55:40.210682: val Epoch: [60][66/72]	Time  1.292 ( 0.693)	Data  1.162 ( 0.558)	Loss 6.9734e-01 (1.2904e-01) 
2023-05-26 00:55:40.338237: val Epoch: [60][67/72]	Time  0.128 ( 0.684)	Data  0.001 ( 0.550)	Loss 1.4522e-01 (1.2928e-01) 
2023-05-26 00:55:41.539681: val Epoch: [60][68/72]	Time  1.201 ( 0.692)	Data  1.069 ( 0.557)	Loss 1.1394e-01 (1.2905e-01) 
2023-05-26 00:55:41.672401: val Epoch: [60][69/72]	Time  0.133 ( 0.684)	Data  0.001 ( 0.549)	Loss 4.2849e-02 (1.2782e-01) 
2023-05-26 00:55:42.851574: val Epoch: [60][70/72]	Time  1.179 ( 0.691)	Data  1.047 ( 0.557)	Loss 3.3948e-01 (1.3080e-01) 
2023-05-26 00:55:42.990206: val Epoch: [60][71/72]	Time  0.139 ( 0.683)	Data  0.001 ( 0.549)	Loss 5.8148e-02 (1.2979e-01) 
2023-05-26 00:55:43.187064: Epoch 60 :Val : ['ET : 0.7626956105232239', 'TC : 0.7781910300254822', 'WT : 0.8591296076774597'] 
2023-05-26 00:55:43.188330: Epoch 60 :Val : ['ET : 0.7626956105232239', 'TC : 0.7781910300254822', 'WT : 0.8591296076774597'] 
2023-05-26 00:55:43.193917: Val epoch done in 50.361776632998954 s 
2023-05-26 00:55:43.203107: Batches per epoch:  129 
2023-05-26 00:55:48.487442: train Epoch: [61][  0/129]	Time  5.283 ( 5.283)	Data  4.214 ( 4.214)	Loss 8.5728e-02 (8.5728e-02) 
2023-05-26 00:55:49.458796: train Epoch: [61][  1/129]	Time  0.971 ( 3.127)	Data  0.001 ( 2.108)	Loss 5.9851e-02 (7.2790e-02) 
2023-05-26 00:55:52.475599: train Epoch: [61][  2/129]	Time  3.017 ( 3.091)	Data  2.049 ( 2.088)	Loss 8.5027e-02 (7.6869e-02) 
2023-05-26 00:55:53.445592: train Epoch: [61][  3/129]	Time  0.970 ( 2.560)	Data  0.001 ( 1.566)	Loss 8.0549e-02 (7.7789e-02) 
2023-05-26 00:55:56.514035: train Epoch: [61][  4/129]	Time  3.068 ( 2.662)	Data  2.085 ( 1.670)	Loss 7.0288e-02 (7.6289e-02) 
2023-05-26 00:55:57.489185: train Epoch: [61][  5/129]	Time  0.975 ( 2.381)	Data  0.001 ( 1.392)	Loss 1.4604e-01 (8.7915e-02) 
2023-05-26 00:56:00.586728: train Epoch: [61][  6/129]	Time  3.098 ( 2.483)	Data  2.089 ( 1.491)	Loss 6.1349e-02 (8.4119e-02) 
2023-05-26 00:56:01.579267: train Epoch: [61][  7/129]	Time  0.993 ( 2.297)	Data  0.001 ( 1.305)	Loss 6.3858e-02 (8.1587e-02) 
2023-05-26 00:56:04.773230: train Epoch: [61][  8/129]	Time  3.194 ( 2.397)	Data  2.201 ( 1.405)	Loss 3.1944e-02 (7.6071e-02) 
2023-05-26 00:56:05.748599: train Epoch: [61][  9/129]	Time  0.975 ( 2.254)	Data  0.001 ( 1.264)	Loss 9.3607e-02 (7.7825e-02) 
2023-05-26 00:56:08.841207: train Epoch: [61][ 10/129]	Time  3.093 ( 2.331)	Data  2.108 ( 1.341)	Loss 9.7439e-02 (7.9608e-02) 
2023-05-26 00:56:09.820911: train Epoch: [61][ 11/129]	Time  0.980 ( 2.218)	Data  0.001 ( 1.229)	Loss 8.8508e-02 (8.0349e-02) 
2023-05-26 00:56:12.831836: train Epoch: [61][ 12/129]	Time  3.011 ( 2.279)	Data  2.041 ( 1.292)	Loss 5.2583e-02 (7.8214e-02) 
2023-05-26 00:56:13.802576: train Epoch: [61][ 13/129]	Time  0.971 ( 2.186)	Data  0.001 ( 1.200)	Loss 1.0369e-01 (8.0033e-02) 
2023-05-26 00:56:16.935884: train Epoch: [61][ 14/129]	Time  3.133 ( 2.249)	Data  2.159 ( 1.264)	Loss 6.0965e-02 (7.8762e-02) 
2023-05-26 00:56:17.920562: train Epoch: [61][ 15/129]	Time  0.985 ( 2.170)	Data  0.001 ( 1.185)	Loss 8.0740e-02 (7.8885e-02) 
2023-05-26 00:56:21.035290: train Epoch: [61][ 16/129]	Time  3.115 ( 2.225)	Data  2.142 ( 1.241)	Loss 7.5566e-02 (7.8690e-02) 
2023-05-26 00:56:22.026675: train Epoch: [61][ 17/129]	Time  0.991 ( 2.157)	Data  0.001 ( 1.172)	Loss 1.1694e-01 (8.0815e-02) 
2023-05-26 00:56:25.099973: train Epoch: [61][ 18/129]	Time  3.073 ( 2.205)	Data  2.083 ( 1.220)	Loss 5.6306e-02 (7.9525e-02) 
2023-05-26 00:56:26.067608: train Epoch: [61][ 19/129]	Time  0.968 ( 2.143)	Data  0.001 ( 1.159)	Loss 5.9206e-02 (7.8509e-02) 
2023-05-26 00:56:29.164039: train Epoch: [61][ 20/129]	Time  3.096 ( 2.189)	Data  2.120 ( 1.205)	Loss 4.1505e-02 (7.6747e-02) 
2023-05-26 00:56:30.136149: train Epoch: [61][ 21/129]	Time  0.972 ( 2.133)	Data  0.001 ( 1.150)	Loss 8.0664e-02 (7.6925e-02) 
2023-05-26 00:56:33.169916: train Epoch: [61][ 22/129]	Time  3.034 ( 2.172)	Data  2.062 ( 1.190)	Loss 7.1512e-02 (7.6690e-02) 
2023-05-26 00:56:34.138034: train Epoch: [61][ 23/129]	Time  0.968 ( 2.122)	Data  0.001 ( 1.140)	Loss 7.7854e-02 (7.6738e-02) 
2023-05-26 00:56:37.210690: train Epoch: [61][ 24/129]	Time  3.073 ( 2.160)	Data  2.084 ( 1.178)	Loss 4.8993e-02 (7.5629e-02) 
2023-05-26 00:56:38.188109: train Epoch: [61][ 25/129]	Time  0.977 ( 2.115)	Data  0.001 ( 1.133)	Loss 8.2029e-02 (7.5875e-02) 
2023-05-26 00:56:41.275782: train Epoch: [61][ 26/129]	Time  3.088 ( 2.151)	Data  2.104 ( 1.169)	Loss 5.5182e-02 (7.5108e-02) 
2023-05-26 00:56:42.251727: train Epoch: [61][ 27/129]	Time  0.976 ( 2.109)	Data  0.002 ( 1.127)	Loss 1.4487e-01 (7.7600e-02) 
2023-05-26 00:56:45.388118: train Epoch: [61][ 28/129]	Time  3.136 ( 2.144)	Data  2.163 ( 1.163)	Loss 8.5928e-02 (7.7887e-02) 
2023-05-26 00:56:46.357784: train Epoch: [61][ 29/129]	Time  0.970 ( 2.105)	Data  0.001 ( 1.124)	Loss 7.6966e-02 (7.7856e-02) 
2023-05-26 00:56:49.413095: train Epoch: [61][ 30/129]	Time  3.055 ( 2.136)	Data  2.070 ( 1.155)	Loss 1.2299e-01 (7.9312e-02) 
2023-05-26 00:56:50.379602: train Epoch: [61][ 31/129]	Time  0.966 ( 2.099)	Data  0.001 ( 1.119)	Loss 6.9303e-02 (7.9000e-02) 
2023-05-26 00:56:53.436609: train Epoch: [61][ 32/129]	Time  3.057 ( 2.128)	Data  2.083 ( 1.148)	Loss 5.7015e-02 (7.8333e-02) 
2023-05-26 00:56:54.406476: train Epoch: [61][ 33/129]	Time  0.970 ( 2.094)	Data  0.001 ( 1.114)	Loss 6.4241e-02 (7.7919e-02) 
2023-05-26 00:56:57.425059: train Epoch: [61][ 34/129]	Time  3.019 ( 2.121)	Data  2.047 ( 1.141)	Loss 8.2716e-02 (7.8056e-02) 
2023-05-26 00:56:58.397432: train Epoch: [61][ 35/129]	Time  0.972 ( 2.089)	Data  0.001 ( 1.109)	Loss 1.0170e-01 (7.8713e-02) 
2023-05-26 00:57:01.450280: train Epoch: [61][ 36/129]	Time  3.053 ( 2.115)	Data  2.079 ( 1.135)	Loss 9.7528e-02 (7.9221e-02) 
2023-05-26 00:57:02.427509: train Epoch: [61][ 37/129]	Time  0.977 ( 2.085)	Data  0.001 ( 1.105)	Loss 9.2224e-02 (7.9564e-02) 
2023-05-26 00:57:05.493853: train Epoch: [61][ 38/129]	Time  3.066 ( 2.110)	Data  2.097 ( 1.131)	Loss 5.5541e-02 (7.8948e-02) 
2023-05-26 00:57:06.462676: train Epoch: [61][ 39/129]	Time  0.969 ( 2.081)	Data  0.001 ( 1.103)	Loss 6.1709e-02 (7.8517e-02) 
2023-05-26 00:57:09.577778: train Epoch: [61][ 40/129]	Time  3.115 ( 2.107)	Data  2.119 ( 1.127)	Loss 7.2861e-02 (7.8379e-02) 
2023-05-26 00:57:10.560011: train Epoch: [61][ 41/129]	Time  0.982 ( 2.080)	Data  0.002 ( 1.101)	Loss 7.0426e-02 (7.8189e-02) 
2023-05-26 00:57:13.547633: train Epoch: [61][ 42/129]	Time  2.988 ( 2.101)	Data  2.013 ( 1.122)	Loss 1.3435e-01 (7.9495e-02) 
2023-05-26 00:57:14.509335: train Epoch: [61][ 43/129]	Time  0.962 ( 2.075)	Data  0.001 ( 1.096)	Loss 8.5733e-02 (7.9637e-02) 
2023-05-26 00:57:17.697415: train Epoch: [61][ 44/129]	Time  3.188 ( 2.100)	Data  2.217 ( 1.121)	Loss 6.4838e-02 (7.9308e-02) 
2023-05-26 00:57:18.677934: train Epoch: [61][ 45/129]	Time  0.981 ( 2.076)	Data  0.001 ( 1.097)	Loss 8.1917e-02 (7.9365e-02) 
2023-05-26 00:57:21.691109: train Epoch: [61][ 46/129]	Time  3.013 ( 2.095)	Data  2.027 ( 1.117)	Loss 6.3059e-02 (7.9018e-02) 
2023-05-26 00:57:22.670972: train Epoch: [61][ 47/129]	Time  0.980 ( 2.072)	Data  0.001 ( 1.093)	Loss 6.7555e-02 (7.8779e-02) 
2023-05-26 00:57:25.725988: train Epoch: [61][ 48/129]	Time  3.055 ( 2.092)	Data  2.080 ( 1.114)	Loss 3.9828e-02 (7.7984e-02) 
2023-05-26 00:57:26.692932: train Epoch: [61][ 49/129]	Time  0.967 ( 2.070)	Data  0.001 ( 1.091)	Loss 5.7829e-02 (7.7581e-02) 
2023-05-26 00:57:29.869791: train Epoch: [61][ 50/129]	Time  3.177 ( 2.091)	Data  2.208 ( 1.113)	Loss 8.5488e-02 (7.7736e-02) 
2023-05-26 00:57:30.841033: train Epoch: [61][ 51/129]	Time  0.971 ( 2.070)	Data  0.001 ( 1.092)	Loss 5.7810e-02 (7.7353e-02) 
2023-05-26 00:57:34.026304: train Epoch: [61][ 52/129]	Time  3.185 ( 2.091)	Data  2.210 ( 1.113)	Loss 7.4797e-02 (7.7305e-02) 
2023-05-26 00:57:35.010478: train Epoch: [61][ 53/129]	Time  0.984 ( 2.070)	Data  0.001 ( 1.092)	Loss 6.2676e-02 (7.7034e-02) 
2023-05-26 00:57:38.173415: train Epoch: [61][ 54/129]	Time  3.163 ( 2.090)	Data  2.194 ( 1.112)	Loss 6.8846e-02 (7.6885e-02) 
2023-05-26 00:57:39.153783: train Epoch: [61][ 55/129]	Time  0.980 ( 2.071)	Data  0.001 ( 1.093)	Loss 6.9480e-02 (7.6753e-02) 
2023-05-26 00:57:42.205022: train Epoch: [61][ 56/129]	Time  3.051 ( 2.088)	Data  2.085 ( 1.110)	Loss 6.9124e-02 (7.6619e-02) 
2023-05-26 00:57:43.169007: train Epoch: [61][ 57/129]	Time  0.964 ( 2.068)	Data  0.001 ( 1.091)	Loss 1.0985e-01 (7.7192e-02) 
2023-05-26 00:57:46.310438: train Epoch: [61][ 58/129]	Time  3.141 ( 2.087)	Data  2.164 ( 1.109)	Loss 5.5994e-02 (7.6833e-02) 
2023-05-26 00:57:47.288692: train Epoch: [61][ 59/129]	Time  0.978 ( 2.068)	Data  0.001 ( 1.091)	Loss 5.0988e-02 (7.6402e-02) 
2023-05-26 00:57:50.374344: train Epoch: [61][ 60/129]	Time  3.086 ( 2.085)	Data  2.109 ( 1.107)	Loss 7.7421e-02 (7.6419e-02) 
2023-05-26 00:57:51.340521: train Epoch: [61][ 61/129]	Time  0.966 ( 2.067)	Data  0.001 ( 1.089)	Loss 1.3255e-01 (7.7324e-02) 
2023-05-26 00:57:54.503998: train Epoch: [61][ 62/129]	Time  3.163 ( 2.084)	Data  2.183 ( 1.107)	Loss 8.5722e-02 (7.7457e-02) 
2023-05-26 00:57:55.474312: train Epoch: [61][ 63/129]	Time  0.970 ( 2.067)	Data  0.001 ( 1.089)	Loss 6.0755e-02 (7.7196e-02) 
2023-05-26 00:57:58.499202: train Epoch: [61][ 64/129]	Time  3.025 ( 2.081)	Data  2.049 ( 1.104)	Loss 8.9862e-02 (7.7391e-02) 
2023-05-26 00:57:59.478634: train Epoch: [61][ 65/129]	Time  0.979 ( 2.065)	Data  0.001 ( 1.088)	Loss 6.7317e-02 (7.7238e-02) 
2023-05-26 00:58:02.637788: train Epoch: [61][ 66/129]	Time  3.159 ( 2.081)	Data  2.177 ( 1.104)	Loss 7.5241e-02 (7.7209e-02) 
2023-05-26 00:58:03.612059: train Epoch: [61][ 67/129]	Time  0.974 ( 2.065)	Data  0.001 ( 1.088)	Loss 7.6201e-02 (7.7194e-02) 
2023-05-26 00:58:06.601198: train Epoch: [61][ 68/129]	Time  2.989 ( 2.078)	Data  2.009 ( 1.101)	Loss 8.1779e-02 (7.7260e-02) 
2023-05-26 00:58:07.569658: train Epoch: [61][ 69/129]	Time  0.968 ( 2.062)	Data  0.001 ( 1.085)	Loss 1.6038e-01 (7.8448e-02) 
2023-05-26 00:58:10.716783: train Epoch: [61][ 70/129]	Time  3.147 ( 2.078)	Data  2.169 ( 1.100)	Loss 1.0292e-01 (7.8792e-02) 
2023-05-26 00:58:11.691961: train Epoch: [61][ 71/129]	Time  0.975 ( 2.062)	Data  0.001 ( 1.085)	Loss 8.8700e-02 (7.8930e-02) 
2023-05-26 00:58:14.843230: train Epoch: [61][ 72/129]	Time  3.151 ( 2.077)	Data  2.168 ( 1.100)	Loss 5.3185e-02 (7.8577e-02) 
2023-05-26 00:58:15.813351: train Epoch: [61][ 73/129]	Time  0.970 ( 2.062)	Data  0.001 ( 1.085)	Loss 7.3720e-02 (7.8512e-02) 
2023-05-26 00:58:18.828902: train Epoch: [61][ 74/129]	Time  3.016 ( 2.075)	Data  2.050 ( 1.098)	Loss 7.1495e-02 (7.8418e-02) 
2023-05-26 00:58:19.812402: train Epoch: [61][ 75/129]	Time  0.983 ( 2.061)	Data  0.001 ( 1.084)	Loss 8.9733e-02 (7.8567e-02) 
2023-05-26 00:58:22.773385: train Epoch: [61][ 76/129]	Time  2.961 ( 2.072)	Data  1.980 ( 1.095)	Loss 4.3824e-02 (7.8116e-02) 
2023-05-26 00:58:23.763019: train Epoch: [61][ 77/129]	Time  0.990 ( 2.058)	Data  0.001 ( 1.081)	Loss 1.7364e-01 (7.9341e-02) 
2023-05-26 00:58:26.981907: train Epoch: [61][ 78/129]	Time  3.219 ( 2.073)	Data  2.227 ( 1.096)	Loss 8.2116e-02 (7.9376e-02) 
2023-05-26 00:58:27.966198: train Epoch: [61][ 79/129]	Time  0.984 ( 2.060)	Data  0.001 ( 1.082)	Loss 4.9046e-02 (7.8997e-02) 
2023-05-26 00:58:31.220611: train Epoch: [61][ 80/129]	Time  3.254 ( 2.074)	Data  2.263 ( 1.097)	Loss 9.6985e-02 (7.9219e-02) 
2023-05-26 00:58:32.186070: train Epoch: [61][ 81/129]	Time  0.965 ( 2.061)	Data  0.001 ( 1.083)	Loss 8.2526e-02 (7.9259e-02) 
2023-05-26 00:58:35.237338: train Epoch: [61][ 82/129]	Time  3.051 ( 2.073)	Data  2.076 ( 1.095)	Loss 8.8163e-02 (7.9366e-02) 
2023-05-26 00:58:36.207484: train Epoch: [61][ 83/129]	Time  0.970 ( 2.060)	Data  0.001 ( 1.082)	Loss 6.0824e-02 (7.9146e-02) 
2023-05-26 00:58:39.368006: train Epoch: [61][ 84/129]	Time  3.161 ( 2.073)	Data  2.204 ( 1.095)	Loss 5.5771e-02 (7.8871e-02) 
2023-05-26 00:58:40.337446: train Epoch: [61][ 85/129]	Time  0.969 ( 2.060)	Data  0.001 ( 1.083)	Loss 7.8259e-02 (7.8863e-02) 
2023-05-26 00:58:43.355800: train Epoch: [61][ 86/129]	Time  3.018 ( 2.071)	Data  2.029 ( 1.094)	Loss 6.1634e-02 (7.8665e-02) 
2023-05-26 00:58:44.323320: train Epoch: [61][ 87/129]	Time  0.968 ( 2.058)	Data  0.001 ( 1.081)	Loss 5.3846e-02 (7.8383e-02) 
2023-05-26 00:58:47.513286: train Epoch: [61][ 88/129]	Time  3.190 ( 2.071)	Data  2.220 ( 1.094)	Loss 6.4535e-02 (7.8228e-02) 
2023-05-26 00:58:48.478510: train Epoch: [61][ 89/129]	Time  0.965 ( 2.059)	Data  0.001 ( 1.082)	Loss 1.2768e-01 (7.8777e-02) 
2023-05-26 00:58:51.616248: train Epoch: [61][ 90/129]	Time  3.138 ( 2.070)	Data  2.156 ( 1.094)	Loss 5.7496e-02 (7.8543e-02) 
2023-05-26 00:58:52.593070: train Epoch: [61][ 91/129]	Time  0.977 ( 2.059)	Data  0.001 ( 1.082)	Loss 3.8561e-02 (7.8109e-02) 
2023-05-26 00:58:55.869722: train Epoch: [61][ 92/129]	Time  3.277 ( 2.072)	Data  2.301 ( 1.095)	Loss 1.4298e-01 (7.8806e-02) 
2023-05-26 00:58:56.838783: train Epoch: [61][ 93/129]	Time  0.969 ( 2.060)	Data  0.001 ( 1.083)	Loss 5.2918e-02 (7.8531e-02) 
2023-05-26 00:59:00.023207: train Epoch: [61][ 94/129]	Time  3.184 ( 2.072)	Data  2.214 ( 1.095)	Loss 1.1622e-01 (7.8928e-02) 
2023-05-26 00:59:01.011369: train Epoch: [61][ 95/129]	Time  0.988 ( 2.060)	Data  0.001 ( 1.084)	Loss 7.6953e-02 (7.8907e-02) 
2023-05-26 00:59:04.136845: train Epoch: [61][ 96/129]	Time  3.126 ( 2.071)	Data  2.165 ( 1.095)	Loss 5.6700e-02 (7.8678e-02) 
2023-05-26 00:59:05.108299: train Epoch: [61][ 97/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.084)	Loss 4.4952e-02 (7.8334e-02) 
2023-05-26 00:59:08.255061: train Epoch: [61][ 98/129]	Time  3.147 ( 2.071)	Data  2.180 ( 1.095)	Loss 4.5194e-02 (7.7999e-02) 
2023-05-26 00:59:09.225688: train Epoch: [61][ 99/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.084)	Loss 1.1026e-01 (7.8322e-02) 
2023-05-26 00:59:12.445544: train Epoch: [61][100/129]	Time  3.220 ( 2.072)	Data  2.251 ( 1.095)	Loss 4.7681e-02 (7.8018e-02) 
2023-05-26 00:59:13.411759: train Epoch: [61][101/129]	Time  0.966 ( 2.061)	Data  0.001 ( 1.085)	Loss 9.4204e-02 (7.8177e-02) 
2023-05-26 00:59:16.447143: train Epoch: [61][102/129]	Time  3.035 ( 2.070)	Data  2.068 ( 1.094)	Loss 8.3379e-02 (7.8228e-02) 
2023-05-26 00:59:17.428928: train Epoch: [61][103/129]	Time  0.982 ( 2.060)	Data  0.001 ( 1.084)	Loss 9.2794e-02 (7.8368e-02) 
2023-05-26 00:59:20.437309: train Epoch: [61][104/129]	Time  3.008 ( 2.069)	Data  2.043 ( 1.093)	Loss 9.3916e-02 (7.8516e-02) 
2023-05-26 00:59:21.408772: train Epoch: [61][105/129]	Time  0.971 ( 2.059)	Data  0.001 ( 1.083)	Loss 7.9413e-02 (7.8524e-02) 
2023-05-26 00:59:24.516619: train Epoch: [61][106/129]	Time  3.108 ( 2.068)	Data  2.143 ( 1.092)	Loss 8.0811e-02 (7.8546e-02) 
2023-05-26 00:59:25.488850: train Epoch: [61][107/129]	Time  0.972 ( 2.058)	Data  0.001 ( 1.082)	Loss 4.2359e-02 (7.8211e-02) 
2023-05-26 00:59:28.623615: train Epoch: [61][108/129]	Time  3.135 ( 2.068)	Data  2.168 ( 1.092)	Loss 5.2806e-02 (7.7977e-02) 
2023-05-26 00:59:29.593471: train Epoch: [61][109/129]	Time  0.970 ( 2.058)	Data  0.001 ( 1.082)	Loss 7.7956e-02 (7.7977e-02) 
2023-05-26 00:59:32.734735: train Epoch: [61][110/129]	Time  3.141 ( 2.068)	Data  2.176 ( 1.092)	Loss 6.2843e-02 (7.7841e-02) 
2023-05-26 00:59:33.725384: train Epoch: [61][111/129]	Time  0.991 ( 2.058)	Data  0.002 ( 1.083)	Loss 6.3852e-02 (7.7716e-02) 
2023-05-26 00:59:36.958362: train Epoch: [61][112/129]	Time  3.233 ( 2.069)	Data  2.268 ( 1.093)	Loss 5.7192e-02 (7.7534e-02) 
2023-05-26 00:59:37.930375: train Epoch: [61][113/129]	Time  0.972 ( 2.059)	Data  0.001 ( 1.083)	Loss 4.8798e-02 (7.7282e-02) 
2023-05-26 00:59:41.080503: train Epoch: [61][114/129]	Time  3.150 ( 2.068)	Data  2.182 ( 1.093)	Loss 9.9403e-02 (7.7475e-02) 
2023-05-26 00:59:42.049963: train Epoch: [61][115/129]	Time  0.969 ( 2.059)	Data  0.001 ( 1.084)	Loss 6.7201e-02 (7.7386e-02) 
2023-05-26 00:59:45.196703: train Epoch: [61][116/129]	Time  3.147 ( 2.068)	Data  2.167 ( 1.093)	Loss 7.1853e-02 (7.7339e-02) 
2023-05-26 00:59:46.157224: train Epoch: [61][117/129]	Time  0.961 ( 2.059)	Data  0.001 ( 1.084)	Loss 7.5237e-02 (7.7321e-02) 
2023-05-26 00:59:49.183062: train Epoch: [61][118/129]	Time  3.026 ( 2.067)	Data  2.058 ( 1.092)	Loss 8.3817e-02 (7.7376e-02) 
2023-05-26 00:59:50.166081: train Epoch: [61][119/129]	Time  0.983 ( 2.058)	Data  0.002 ( 1.083)	Loss 7.3388e-02 (7.7342e-02) 
2023-05-26 00:59:53.313412: train Epoch: [61][120/129]	Time  3.147 ( 2.067)	Data  2.176 ( 1.092)	Loss 7.8641e-02 (7.7353e-02) 
2023-05-26 00:59:54.297761: train Epoch: [61][121/129]	Time  0.984 ( 2.058)	Data  0.001 ( 1.083)	Loss 6.6383e-02 (7.7263e-02) 
2023-05-26 00:59:57.380654: train Epoch: [61][122/129]	Time  3.083 ( 2.066)	Data  2.112 ( 1.091)	Loss 4.8487e-02 (7.7029e-02) 
2023-05-26 00:59:58.345530: train Epoch: [61][123/129]	Time  0.965 ( 2.058)	Data  0.001 ( 1.082)	Loss 5.5774e-02 (7.6858e-02) 
2023-05-26 01:00:01.419542: train Epoch: [61][124/129]	Time  3.074 ( 2.066)	Data  2.106 ( 1.091)	Loss 5.6851e-02 (7.6698e-02) 
2023-05-26 01:00:02.395514: train Epoch: [61][125/129]	Time  0.976 ( 2.057)	Data  0.002 ( 1.082)	Loss 5.2389e-02 (7.6505e-02) 
2023-05-26 01:00:05.486715: train Epoch: [61][126/129]	Time  3.091 ( 2.065)	Data  2.112 ( 1.090)	Loss 1.0367e-01 (7.6719e-02) 
2023-05-26 01:00:06.473662: train Epoch: [61][127/129]	Time  0.987 ( 2.057)	Data  0.002 ( 1.082)	Loss 7.8218e-02 (7.6730e-02) 
2023-05-26 01:00:08.511313: train Epoch: [61][128/129]	Time  2.038 ( 2.057)	Data  1.077 ( 1.081)	Loss 7.1097e-02 (7.6687e-02) 
2023-05-26 01:00:08.546531: Train Epoch done in 265.3434840209993 s 
2023-05-26 01:00:11.284674: val Epoch: [61][ 0/72]	Time  1.831 ( 1.831)	Data  1.602 ( 1.602)	Loss 3.2089e-02 (3.2089e-02) 
2023-05-26 01:00:11.428177: val Epoch: [61][ 1/72]	Time  0.144 ( 0.987)	Data  0.002 ( 0.802)	Loss 7.5646e-02 (5.3867e-02) 
2023-05-26 01:00:12.583771: val Epoch: [61][ 2/72]	Time  1.156 ( 1.043)	Data  1.012 ( 0.872)	Loss 8.8032e-02 (6.5255e-02) 
2023-05-26 01:00:12.716387: val Epoch: [61][ 3/72]	Time  0.133 ( 0.816)	Data  0.001 ( 0.654)	Loss 1.3125e-01 (8.1754e-02) 
2023-05-26 01:00:13.930085: val Epoch: [61][ 4/72]	Time  1.214 ( 0.895)	Data  1.075 ( 0.738)	Loss 6.3197e-02 (7.8042e-02) 
2023-05-26 01:00:14.067130: val Epoch: [61][ 5/72]	Time  0.137 ( 0.769)	Data  0.001 ( 0.615)	Loss 9.2450e-02 (8.0444e-02) 
2023-05-26 01:00:15.256267: val Epoch: [61][ 6/72]	Time  1.189 ( 0.829)	Data  1.044 ( 0.677)	Loss 1.2296e-01 (8.6518e-02) 
2023-05-26 01:00:15.401821: val Epoch: [61][ 7/72]	Time  0.146 ( 0.744)	Data  0.011 ( 0.593)	Loss 5.1816e-02 (8.2180e-02) 
2023-05-26 01:00:16.651543: val Epoch: [61][ 8/72]	Time  1.250 ( 0.800)	Data  1.107 ( 0.650)	Loss 1.0472e-01 (8.4684e-02) 
2023-05-26 01:00:16.793318: val Epoch: [61][ 9/72]	Time  0.142 ( 0.734)	Data  0.001 ( 0.586)	Loss 4.1243e-01 (1.1746e-01) 
2023-05-26 01:00:17.998580: val Epoch: [61][10/72]	Time  1.205 ( 0.777)	Data  1.072 ( 0.630)	Loss 3.7056e-02 (1.1015e-01) 
2023-05-26 01:00:18.195012: val Epoch: [61][11/72]	Time  0.196 ( 0.728)	Data  0.054 ( 0.582)	Loss 1.6479e-01 (1.1470e-01) 
2023-05-26 01:00:19.401067: val Epoch: [61][12/72]	Time  1.206 ( 0.765)	Data  1.075 ( 0.620)	Loss 1.0102e-01 (1.1365e-01) 
2023-05-26 01:00:19.624891: val Epoch: [61][13/72]	Time  0.224 ( 0.727)	Data  0.050 ( 0.579)	Loss 7.6488e-02 (1.1100e-01) 
2023-05-26 01:00:20.747019: val Epoch: [61][14/72]	Time  1.122 ( 0.753)	Data  0.991 ( 0.607)	Loss 5.1098e-02 (1.0700e-01) 
2023-05-26 01:00:20.952574: val Epoch: [61][15/72]	Time  0.206 ( 0.719)	Data  0.081 ( 0.574)	Loss 4.1979e-02 (1.0294e-01) 
2023-05-26 01:00:22.141052: val Epoch: [61][16/72]	Time  1.188 ( 0.746)	Data  1.062 ( 0.602)	Loss 2.9769e-01 (1.1440e-01) 
2023-05-26 01:00:22.366638: val Epoch: [61][17/72]	Time  0.226 ( 0.717)	Data  0.092 ( 0.574)	Loss 6.9235e-02 (1.1189e-01) 
2023-05-26 01:00:23.576497: val Epoch: [61][18/72]	Time  1.210 ( 0.743)	Data  1.078 ( 0.601)	Loss 4.6921e-02 (1.0847e-01) 
2023-05-26 01:00:23.796968: val Epoch: [61][19/72]	Time  0.220 ( 0.717)	Data  0.089 ( 0.575)	Loss 8.0292e-02 (1.0706e-01) 
2023-05-26 01:00:25.000266: val Epoch: [61][20/72]	Time  1.203 ( 0.740)	Data  1.064 ( 0.598)	Loss 2.1394e-01 (1.1215e-01) 
2023-05-26 01:00:25.159327: val Epoch: [61][21/72]	Time  0.159 ( 0.714)	Data  0.019 ( 0.572)	Loss 4.7481e-02 (1.0921e-01) 
2023-05-26 01:00:26.388624: val Epoch: [61][22/72]	Time  1.229 ( 0.736)	Data  1.091 ( 0.595)	Loss 9.6658e-02 (1.0866e-01) 
2023-05-26 01:00:26.582151: val Epoch: [61][23/72]	Time  0.193 ( 0.714)	Data  0.047 ( 0.572)	Loss 2.6938e-01 (1.1536e-01) 
2023-05-26 01:00:27.755562: val Epoch: [61][24/72]	Time  1.173 ( 0.732)	Data  1.041 ( 0.591)	Loss 1.0859e-01 (1.1509e-01) 
2023-05-26 01:00:27.980625: val Epoch: [61][25/72]	Time  0.225 ( 0.713)	Data  0.083 ( 0.571)	Loss 3.2274e-01 (1.2307e-01) 
2023-05-26 01:00:29.115405: val Epoch: [61][26/72]	Time  1.135 ( 0.728)	Data  1.002 ( 0.587)	Loss 5.3242e-02 (1.2049e-01) 
2023-05-26 01:00:29.365202: val Epoch: [61][27/72]	Time  0.250 ( 0.711)	Data  0.119 ( 0.570)	Loss 1.6553e-01 (1.2210e-01) 
2023-05-26 01:00:30.520760: val Epoch: [61][28/72]	Time  1.156 ( 0.726)	Data  1.024 ( 0.586)	Loss 1.3783e-01 (1.2264e-01) 
2023-05-26 01:00:30.810575: val Epoch: [61][29/72]	Time  0.290 ( 0.712)	Data  0.160 ( 0.572)	Loss 6.3080e-01 (1.3958e-01) 
2023-05-26 01:00:31.913271: val Epoch: [61][30/72]	Time  1.103 ( 0.725)	Data  0.970 ( 0.585)	Loss 3.7364e-02 (1.3628e-01) 
2023-05-26 01:00:32.181628: val Epoch: [61][31/72]	Time  0.268 ( 0.710)	Data  0.138 ( 0.571)	Loss 4.5954e-02 (1.3346e-01) 
2023-05-26 01:00:33.296771: val Epoch: [61][32/72]	Time  1.115 ( 0.723)	Data  0.983 ( 0.583)	Loss 5.1772e-02 (1.3098e-01) 
2023-05-26 01:00:33.588486: val Epoch: [61][33/72]	Time  0.292 ( 0.710)	Data  0.158 ( 0.571)	Loss 3.4026e-01 (1.3714e-01) 
2023-05-26 01:00:34.732564: val Epoch: [61][34/72]	Time  1.144 ( 0.722)	Data  1.013 ( 0.583)	Loss 3.9705e-02 (1.3435e-01) 
2023-05-26 01:00:34.965360: val Epoch: [61][35/72]	Time  0.233 ( 0.709)	Data  0.100 ( 0.570)	Loss 3.2206e-02 (1.3152e-01) 
2023-05-26 01:00:36.121289: val Epoch: [61][36/72]	Time  1.156 ( 0.721)	Data  1.019 ( 0.582)	Loss 2.3008e-01 (1.3418e-01) 
2023-05-26 01:00:36.368237: val Epoch: [61][37/72]	Time  0.247 ( 0.708)	Data  0.107 ( 0.569)	Loss 4.6660e-02 (1.3188e-01) 
2023-05-26 01:00:37.519715: val Epoch: [61][38/72]	Time  1.151 ( 0.720)	Data  1.020 ( 0.581)	Loss 3.9618e-01 (1.3865e-01) 
2023-05-26 01:00:37.706248: val Epoch: [61][39/72]	Time  0.187 ( 0.706)	Data  0.056 ( 0.568)	Loss 3.8165e-02 (1.3614e-01) 
2023-05-26 01:00:38.914756: val Epoch: [61][40/72]	Time  1.209 ( 0.719)	Data  1.079 ( 0.580)	Loss 1.0237e-01 (1.3532e-01) 
2023-05-26 01:00:39.133550: val Epoch: [61][41/72]	Time  0.219 ( 0.707)	Data  0.091 ( 0.569)	Loss 5.5505e-02 (1.3342e-01) 
2023-05-26 01:00:40.294326: val Epoch: [61][42/72]	Time  1.161 ( 0.717)	Data  1.028 ( 0.579)	Loss 9.2614e-02 (1.3247e-01) 
2023-05-26 01:00:40.473700: val Epoch: [61][43/72]	Time  0.179 ( 0.705)	Data  0.051 ( 0.567)	Loss 6.3110e-02 (1.3089e-01) 
2023-05-26 01:00:41.626682: val Epoch: [61][44/72]	Time  1.153 ( 0.715)	Data  1.021 ( 0.577)	Loss 8.4058e-02 (1.2985e-01) 
2023-05-26 01:00:41.807203: val Epoch: [61][45/72]	Time  0.181 ( 0.703)	Data  0.047 ( 0.566)	Loss 5.2037e-02 (1.2816e-01) 
2023-05-26 01:00:42.994162: val Epoch: [61][46/72]	Time  1.187 ( 0.714)	Data  1.055 ( 0.576)	Loss 3.5499e-01 (1.3299e-01) 
2023-05-26 01:00:43.183036: val Epoch: [61][47/72]	Time  0.189 ( 0.703)	Data  0.058 ( 0.566)	Loss 5.7023e-02 (1.3140e-01) 
2023-05-26 01:00:44.332924: val Epoch: [61][48/72]	Time  1.150 ( 0.712)	Data  1.017 ( 0.575)	Loss 1.0144e-01 (1.3079e-01) 
2023-05-26 01:00:44.615316: val Epoch: [61][49/72]	Time  0.282 ( 0.703)	Data  0.152 ( 0.566)	Loss 1.6777e-01 (1.3153e-01) 
2023-05-26 01:00:45.700594: val Epoch: [61][50/72]	Time  1.085 ( 0.711)	Data  0.953 ( 0.574)	Loss 1.5921e-01 (1.3207e-01) 
2023-05-26 01:00:45.991148: val Epoch: [61][51/72]	Time  0.291 ( 0.703)	Data  0.161 ( 0.566)	Loss 3.6753e-02 (1.3024e-01) 
2023-05-26 01:00:47.042590: val Epoch: [61][52/72]	Time  1.051 ( 0.709)	Data  0.920 ( 0.573)	Loss 7.3922e-02 (1.2918e-01) 
2023-05-26 01:00:47.343237: val Epoch: [61][53/72]	Time  0.301 ( 0.702)	Data  0.169 ( 0.565)	Loss 8.0701e-02 (1.2828e-01) 
2023-05-26 01:00:48.451593: val Epoch: [61][54/72]	Time  1.108 ( 0.709)	Data  0.979 ( 0.573)	Loss 4.5594e-02 (1.2678e-01) 
2023-05-26 01:00:48.685055: val Epoch: [61][55/72]	Time  0.233 ( 0.701)	Data  0.105 ( 0.564)	Loss 4.3635e-02 (1.2529e-01) 
2023-05-26 01:00:49.811331: val Epoch: [61][56/72]	Time  1.126 ( 0.708)	Data  0.994 ( 0.572)	Loss 5.7644e-02 (1.2411e-01) 
2023-05-26 01:00:50.098936: val Epoch: [61][57/72]	Time  0.288 ( 0.701)	Data  0.162 ( 0.565)	Loss 3.5434e-01 (1.2808e-01) 
2023-05-26 01:00:51.232589: val Epoch: [61][58/72]	Time  1.134 ( 0.708)	Data  1.004 ( 0.572)	Loss 1.4092e-01 (1.2829e-01) 
2023-05-26 01:00:51.462423: val Epoch: [61][59/72]	Time  0.230 ( 0.700)	Data  0.101 ( 0.564)	Loss 1.1605e-01 (1.2809e-01) 
2023-05-26 01:00:52.633379: val Epoch: [61][60/72]	Time  1.171 ( 0.708)	Data  1.041 ( 0.572)	Loss 6.8553e-02 (1.2711e-01) 
2023-05-26 01:00:52.799238: val Epoch: [61][61/72]	Time  0.166 ( 0.699)	Data  0.034 ( 0.563)	Loss 8.2279e-02 (1.2639e-01) 
2023-05-26 01:00:53.981528: val Epoch: [61][62/72]	Time  1.182 ( 0.707)	Data  1.049 ( 0.571)	Loss 1.3904e-01 (1.2659e-01) 
2023-05-26 01:00:54.180752: val Epoch: [61][63/72]	Time  0.199 ( 0.699)	Data  0.064 ( 0.563)	Loss 6.9974e-02 (1.2571e-01) 
2023-05-26 01:00:55.300023: val Epoch: [61][64/72]	Time  1.119 ( 0.705)	Data  0.986 ( 0.570)	Loss 4.1535e-02 (1.2441e-01) 
2023-05-26 01:00:55.586561: val Epoch: [61][65/72]	Time  0.287 ( 0.699)	Data  0.157 ( 0.564)	Loss 7.6657e-02 (1.2369e-01) 
2023-05-26 01:00:56.651643: val Epoch: [61][66/72]	Time  1.065 ( 0.704)	Data  0.934 ( 0.569)	Loss 6.0289e-02 (1.2274e-01) 
2023-05-26 01:00:56.942925: val Epoch: [61][67/72]	Time  0.291 ( 0.698)	Data  0.161 ( 0.563)	Loss 2.6249e-01 (1.2480e-01) 
2023-05-26 01:00:58.055656: val Epoch: [61][68/72]	Time  1.113 ( 0.704)	Data  0.974 ( 0.569)	Loss 8.5166e-02 (1.2422e-01) 
2023-05-26 01:00:58.360607: val Epoch: [61][69/72]	Time  0.305 ( 0.699)	Data  0.172 ( 0.563)	Loss 8.1861e-02 (1.2362e-01) 
2023-05-26 01:00:59.425742: val Epoch: [61][70/72]	Time  1.065 ( 0.704)	Data  0.933 ( 0.569)	Loss 5.5317e-02 (1.2266e-01) 
2023-05-26 01:00:59.696498: val Epoch: [61][71/72]	Time  0.271 ( 0.698)	Data  0.138 ( 0.563)	Loss 5.5304e-02 (1.2172e-01) 
2023-05-26 01:00:59.906840: Epoch 61 :Val : ['ET : 0.7569243907928467', 'TC : 0.7969740629196167', 'WT : 0.8707955479621887'] 
2023-05-26 01:00:59.913399: Epoch 61 :Val : ['ET : 0.7569243907928467', 'TC : 0.7969740629196167', 'WT : 0.8707955479621887'] 
2023-05-26 01:00:59.916602: Val epoch done in 51.370075342001655 s 
2023-05-26 01:00:59.924576: Batches per epoch:  129 
2023-05-26 01:01:05.213467: train Epoch: [62][  0/129]	Time  5.288 ( 5.288)	Data  4.235 ( 4.235)	Loss 5.9314e-02 (5.9314e-02) 
2023-05-26 01:01:06.189837: train Epoch: [62][  1/129]	Time  0.976 ( 3.132)	Data  0.002 ( 2.118)	Loss 5.3341e-02 (5.6328e-02) 
2023-05-26 01:01:09.224896: train Epoch: [62][  2/129]	Time  3.035 ( 3.100)	Data  2.047 ( 2.094)	Loss 6.3187e-02 (5.8614e-02) 
2023-05-26 01:01:10.208220: train Epoch: [62][  3/129]	Time  0.983 ( 2.571)	Data  0.001 ( 1.571)	Loss 1.1975e-01 (7.3897e-02) 
2023-05-26 01:01:13.188942: train Epoch: [62][  4/129]	Time  2.981 ( 2.653)	Data  1.995 ( 1.656)	Loss 6.1410e-02 (7.1400e-02) 
2023-05-26 01:01:14.159890: train Epoch: [62][  5/129]	Time  0.971 ( 2.372)	Data  0.001 ( 1.380)	Loss 6.3802e-02 (7.0133e-02) 
2023-05-26 01:01:17.237765: train Epoch: [62][  6/129]	Time  3.078 ( 2.473)	Data  2.119 ( 1.486)	Loss 7.5817e-02 (7.0945e-02) 
2023-05-26 01:01:18.216196: train Epoch: [62][  7/129]	Time  0.978 ( 2.286)	Data  0.001 ( 1.300)	Loss 8.3482e-02 (7.2512e-02) 
2023-05-26 01:01:21.297804: train Epoch: [62][  8/129]	Time  3.082 ( 2.375)	Data  2.092 ( 1.388)	Loss 5.9339e-02 (7.1049e-02) 
2023-05-26 01:01:22.266666: train Epoch: [62][  9/129]	Time  0.969 ( 2.234)	Data  0.001 ( 1.249)	Loss 6.1999e-02 (7.0144e-02) 
2023-05-26 01:01:25.568945: train Epoch: [62][ 10/129]	Time  3.302 ( 2.331)	Data  2.331 ( 1.348)	Loss 5.7651e-02 (6.9008e-02) 
2023-05-26 01:01:26.545048: train Epoch: [62][ 11/129]	Time  0.976 ( 2.218)	Data  0.001 ( 1.236)	Loss 3.6270e-02 (6.6280e-02) 
2023-05-26 01:01:29.710767: train Epoch: [62][ 12/129]	Time  3.166 ( 2.291)	Data  2.200 ( 1.310)	Loss 4.9092e-02 (6.4958e-02) 
2023-05-26 01:01:30.690572: train Epoch: [62][ 13/129]	Time  0.980 ( 2.198)	Data  0.001 ( 1.216)	Loss 8.1935e-02 (6.6170e-02) 
2023-05-26 01:01:33.890409: train Epoch: [62][ 14/129]	Time  3.200 ( 2.264)	Data  2.220 ( 1.283)	Loss 5.0310e-02 (6.5113e-02) 
2023-05-26 01:01:34.857293: train Epoch: [62][ 15/129]	Time  0.967 ( 2.183)	Data  0.001 ( 1.203)	Loss 6.1274e-02 (6.4873e-02) 
2023-05-26 01:01:38.030069: train Epoch: [62][ 16/129]	Time  3.173 ( 2.241)	Data  2.197 ( 1.261)	Loss 7.7767e-02 (6.5632e-02) 
2023-05-26 01:01:39.012925: train Epoch: [62][ 17/129]	Time  0.983 ( 2.172)	Data  0.002 ( 1.191)	Loss 5.8954e-02 (6.5261e-02) 
2023-05-26 01:01:42.103223: train Epoch: [62][ 18/129]	Time  3.090 ( 2.220)	Data  2.110 ( 1.240)	Loss 1.0498e-01 (6.7351e-02) 
2023-05-26 01:01:43.082879: train Epoch: [62][ 19/129]	Time  0.980 ( 2.158)	Data  0.001 ( 1.178)	Loss 6.2862e-02 (6.7126e-02) 
2023-05-26 01:01:46.347128: train Epoch: [62][ 20/129]	Time  3.264 ( 2.211)	Data  2.281 ( 1.230)	Loss 4.8150e-02 (6.6223e-02) 
2023-05-26 01:01:47.332783: train Epoch: [62][ 21/129]	Time  0.986 ( 2.155)	Data  0.001 ( 1.175)	Loss 6.6531e-02 (6.6237e-02) 
2023-05-26 01:01:50.383446: train Epoch: [62][ 22/129]	Time  3.051 ( 2.194)	Data  2.073 ( 1.214)	Loss 5.4447e-02 (6.5724e-02) 
2023-05-26 01:01:51.349763: train Epoch: [62][ 23/129]	Time  0.966 ( 2.143)	Data  0.001 ( 1.163)	Loss 4.7785e-02 (6.4977e-02) 
2023-05-26 01:01:54.424673: train Epoch: [62][ 24/129]	Time  3.075 ( 2.180)	Data  2.092 ( 1.200)	Loss 9.0706e-02 (6.6006e-02) 
2023-05-26 01:01:55.396696: train Epoch: [62][ 25/129]	Time  0.972 ( 2.134)	Data  0.001 ( 1.154)	Loss 8.4087e-02 (6.6701e-02) 
2023-05-26 01:01:58.542264: train Epoch: [62][ 26/129]	Time  3.146 ( 2.171)	Data  2.183 ( 1.192)	Loss 4.9907e-02 (6.6079e-02) 
2023-05-26 01:01:59.525491: train Epoch: [62][ 27/129]	Time  0.983 ( 2.129)	Data  0.001 ( 1.150)	Loss 9.6337e-02 (6.7160e-02) 
2023-05-26 01:02:02.659062: train Epoch: [62][ 28/129]	Time  3.134 ( 2.163)	Data  2.112 ( 1.183)	Loss 7.8670e-02 (6.7557e-02) 
2023-05-26 01:02:03.651368: train Epoch: [62][ 29/129]	Time  0.992 ( 2.124)	Data  0.001 ( 1.144)	Loss 1.0116e-01 (6.8677e-02) 
2023-05-26 01:02:06.715313: train Epoch: [62][ 30/129]	Time  3.064 ( 2.155)	Data  2.089 ( 1.174)	Loss 6.6271e-02 (6.8599e-02) 
2023-05-26 01:02:07.693154: train Epoch: [62][ 31/129]	Time  0.978 ( 2.118)	Data  0.001 ( 1.137)	Loss 8.0290e-02 (6.8965e-02) 
2023-05-26 01:02:10.764665: train Epoch: [62][ 32/129]	Time  3.072 ( 2.147)	Data  2.099 ( 1.166)	Loss 8.3021e-02 (6.9391e-02) 
2023-05-26 01:02:11.726358: train Epoch: [62][ 33/129]	Time  0.962 ( 2.112)	Data  0.001 ( 1.132)	Loss 8.9989e-02 (6.9996e-02) 
2023-05-26 01:02:14.559785: train Epoch: [62][ 34/129]	Time  2.833 ( 2.132)	Data  1.872 ( 1.153)	Loss 8.1746e-02 (7.0332e-02) 
2023-05-26 01:02:15.549108: train Epoch: [62][ 35/129]	Time  0.989 ( 2.101)	Data  0.002 ( 1.121)	Loss 8.8127e-02 (7.0826e-02) 
2023-05-26 01:02:18.778792: train Epoch: [62][ 36/129]	Time  3.230 ( 2.131)	Data  2.250 ( 1.152)	Loss 9.5008e-02 (7.1480e-02) 
2023-05-26 01:02:19.756292: train Epoch: [62][ 37/129]	Time  0.977 ( 2.101)	Data  0.001 ( 1.122)	Loss 6.6111e-02 (7.1339e-02) 
2023-05-26 01:02:22.950548: train Epoch: [62][ 38/129]	Time  3.194 ( 2.129)	Data  2.206 ( 1.149)	Loss 6.7019e-02 (7.1228e-02) 
2023-05-26 01:02:23.943042: train Epoch: [62][ 39/129]	Time  0.992 ( 2.100)	Data  0.001 ( 1.121)	Loss 6.4016e-02 (7.1048e-02) 
2023-05-26 01:02:27.133103: train Epoch: [62][ 40/129]	Time  3.190 ( 2.127)	Data  2.187 ( 1.147)	Loss 4.0439e-02 (7.0301e-02) 
2023-05-26 01:02:28.120807: train Epoch: [62][ 41/129]	Time  0.988 ( 2.100)	Data  0.002 ( 1.119)	Loss 9.3760e-02 (7.0860e-02) 
2023-05-26 01:02:31.190304: train Epoch: [62][ 42/129]	Time  3.069 ( 2.122)	Data  2.101 ( 1.142)	Loss 5.7360e-02 (7.0546e-02) 
2023-05-26 01:02:32.162948: train Epoch: [62][ 43/129]	Time  0.973 ( 2.096)	Data  0.001 ( 1.116)	Loss 6.6385e-02 (7.0451e-02) 
2023-05-26 01:02:35.274265: train Epoch: [62][ 44/129]	Time  3.111 ( 2.119)	Data  2.134 ( 1.139)	Loss 1.1833e-01 (7.1515e-02) 
2023-05-26 01:02:36.260569: train Epoch: [62][ 45/129]	Time  0.986 ( 2.094)	Data  0.001 ( 1.114)	Loss 9.0996e-02 (7.1939e-02) 
2023-05-26 01:02:39.356669: train Epoch: [62][ 46/129]	Time  3.096 ( 2.116)	Data  2.133 ( 1.136)	Loss 8.7339e-02 (7.2266e-02) 
2023-05-26 01:02:40.342462: train Epoch: [62][ 47/129]	Time  0.986 ( 2.092)	Data  0.001 ( 1.112)	Loss 1.4602e-01 (7.3803e-02) 
2023-05-26 01:02:43.384693: train Epoch: [62][ 48/129]	Time  3.042 ( 2.111)	Data  2.067 ( 1.132)	Loss 7.0913e-02 (7.3744e-02) 
2023-05-26 01:02:44.383195: train Epoch: [62][ 49/129]	Time  0.998 ( 2.089)	Data  0.001 ( 1.109)	Loss 6.8776e-02 (7.3644e-02) 
2023-05-26 01:02:47.555531: train Epoch: [62][ 50/129]	Time  3.172 ( 2.110)	Data  2.171 ( 1.130)	Loss 6.7616e-02 (7.3526e-02) 
2023-05-26 01:02:48.529053: train Epoch: [62][ 51/129]	Time  0.974 ( 2.089)	Data  0.001 ( 1.108)	Loss 6.3179e-02 (7.3327e-02) 
2023-05-26 01:02:51.628853: train Epoch: [62][ 52/129]	Time  3.100 ( 2.108)	Data  2.111 ( 1.127)	Loss 1.2420e-01 (7.4287e-02) 
2023-05-26 01:02:52.598640: train Epoch: [62][ 53/129]	Time  0.970 ( 2.087)	Data  0.001 ( 1.106)	Loss 1.1621e-01 (7.5064e-02) 
2023-05-26 01:02:55.754908: train Epoch: [62][ 54/129]	Time  3.156 ( 2.106)	Data  2.168 ( 1.126)	Loss 5.1214e-02 (7.4630e-02) 
2023-05-26 01:02:56.720684: train Epoch: [62][ 55/129]	Time  0.966 ( 2.086)	Data  0.001 ( 1.106)	Loss 1.0285e-01 (7.5134e-02) 
2023-05-26 01:02:59.701864: train Epoch: [62][ 56/129]	Time  2.981 ( 2.101)	Data  2.008 ( 1.121)	Loss 9.5825e-02 (7.5497e-02) 
2023-05-26 01:03:00.668677: train Epoch: [62][ 57/129]	Time  0.967 ( 2.082)	Data  0.001 ( 1.102)	Loss 9.5740e-02 (7.5846e-02) 
2023-05-26 01:03:03.790050: train Epoch: [62][ 58/129]	Time  3.121 ( 2.099)	Data  2.144 ( 1.120)	Loss 8.6902e-02 (7.6033e-02) 
2023-05-26 01:03:04.760368: train Epoch: [62][ 59/129]	Time  0.970 ( 2.081)	Data  0.001 ( 1.101)	Loss 1.0688e-01 (7.6547e-02) 
2023-05-26 01:03:08.002009: train Epoch: [62][ 60/129]	Time  3.242 ( 2.100)	Data  2.270 ( 1.120)	Loss 6.6204e-02 (7.6378e-02) 
2023-05-26 01:03:08.973948: train Epoch: [62][ 61/129]	Time  0.972 ( 2.081)	Data  0.001 ( 1.102)	Loss 6.2298e-02 (7.6151e-02) 
2023-05-26 01:03:12.017068: train Epoch: [62][ 62/129]	Time  3.043 ( 2.097)	Data  2.059 ( 1.117)	Loss 4.8380e-02 (7.5710e-02) 
2023-05-26 01:03:12.990027: train Epoch: [62][ 63/129]	Time  0.973 ( 2.079)	Data  0.001 ( 1.100)	Loss 7.0666e-02 (7.5631e-02) 
2023-05-26 01:03:16.154372: train Epoch: [62][ 64/129]	Time  3.164 ( 2.096)	Data  2.180 ( 1.117)	Loss 5.5380e-02 (7.5320e-02) 
2023-05-26 01:03:17.128243: train Epoch: [62][ 65/129]	Time  0.974 ( 2.079)	Data  0.001 ( 1.100)	Loss 6.8929e-02 (7.5223e-02) 
2023-05-26 01:03:20.275230: train Epoch: [62][ 66/129]	Time  3.147 ( 2.095)	Data  2.160 ( 1.115)	Loss 9.2271e-02 (7.5477e-02) 
2023-05-26 01:03:21.252017: train Epoch: [62][ 67/129]	Time  0.977 ( 2.078)	Data  0.001 ( 1.099)	Loss 6.7122e-02 (7.5354e-02) 
2023-05-26 01:03:24.332757: train Epoch: [62][ 68/129]	Time  3.081 ( 2.093)	Data  2.104 ( 1.114)	Loss 6.5184e-02 (7.5207e-02) 
2023-05-26 01:03:25.306529: train Epoch: [62][ 69/129]	Time  0.974 ( 2.077)	Data  0.001 ( 1.098)	Loss 3.2449e-02 (7.4596e-02) 
2023-05-26 01:03:28.549861: train Epoch: [62][ 70/129]	Time  3.243 ( 2.093)	Data  2.276 ( 1.114)	Loss 1.1476e-01 (7.5162e-02) 
2023-05-26 01:03:29.525891: train Epoch: [62][ 71/129]	Time  0.976 ( 2.078)	Data  0.001 ( 1.099)	Loss 5.2992e-02 (7.4854e-02) 
2023-05-26 01:03:32.574582: train Epoch: [62][ 72/129]	Time  3.049 ( 2.091)	Data  2.057 ( 1.112)	Loss 5.2706e-02 (7.4550e-02) 
2023-05-26 01:03:33.568566: train Epoch: [62][ 73/129]	Time  0.994 ( 2.076)	Data  0.002 ( 1.097)	Loss 9.5708e-02 (7.4836e-02) 
2023-05-26 01:03:36.620503: train Epoch: [62][ 74/129]	Time  3.052 ( 2.089)	Data  2.064 ( 1.110)	Loss 4.2912e-02 (7.4411e-02) 
2023-05-26 01:03:37.591512: train Epoch: [62][ 75/129]	Time  0.971 ( 2.075)	Data  0.001 ( 1.095)	Loss 6.7019e-02 (7.4313e-02) 
2023-05-26 01:03:40.713684: train Epoch: [62][ 76/129]	Time  3.122 ( 2.088)	Data  2.148 ( 1.109)	Loss 1.0136e-01 (7.4665e-02) 
2023-05-26 01:03:41.684087: train Epoch: [62][ 77/129]	Time  0.970 ( 2.074)	Data  0.001 ( 1.095)	Loss 7.2982e-02 (7.4643e-02) 
2023-05-26 01:03:44.736377: train Epoch: [62][ 78/129]	Time  3.052 ( 2.086)	Data  2.082 ( 1.107)	Loss 8.2735e-02 (7.4746e-02) 
2023-05-26 01:03:45.706117: train Epoch: [62][ 79/129]	Time  0.970 ( 2.072)	Data  0.001 ( 1.093)	Loss 3.5139e-02 (7.4250e-02) 
2023-05-26 01:03:48.703285: train Epoch: [62][ 80/129]	Time  2.997 ( 2.084)	Data  2.027 ( 1.105)	Loss 5.0356e-02 (7.3955e-02) 
2023-05-26 01:03:49.678081: train Epoch: [62][ 81/129]	Time  0.975 ( 2.070)	Data  0.001 ( 1.092)	Loss 5.8036e-02 (7.3761e-02) 
2023-05-26 01:03:52.799942: train Epoch: [62][ 82/129]	Time  3.122 ( 2.083)	Data  2.156 ( 1.104)	Loss 6.1641e-02 (7.3615e-02) 
2023-05-26 01:03:53.774168: train Epoch: [62][ 83/129]	Time  0.974 ( 2.070)	Data  0.001 ( 1.091)	Loss 8.9804e-02 (7.3808e-02) 
2023-05-26 01:03:56.997522: train Epoch: [62][ 84/129]	Time  3.223 ( 2.083)	Data  2.254 ( 1.105)	Loss 5.8736e-02 (7.3631e-02) 
2023-05-26 01:03:57.968954: train Epoch: [62][ 85/129]	Time  0.971 ( 2.070)	Data  0.001 ( 1.092)	Loss 1.1201e-01 (7.4077e-02) 
2023-05-26 01:04:01.105314: train Epoch: [62][ 86/129]	Time  3.136 ( 2.083)	Data  2.159 ( 1.104)	Loss 7.6983e-02 (7.4110e-02) 
2023-05-26 01:04:02.082185: train Epoch: [62][ 87/129]	Time  0.977 ( 2.070)	Data  0.001 ( 1.092)	Loss 9.8722e-02 (7.4390e-02) 
2023-05-26 01:04:05.202448: train Epoch: [62][ 88/129]	Time  3.120 ( 2.082)	Data  2.146 ( 1.104)	Loss 1.7743e-01 (7.5548e-02) 
2023-05-26 01:04:06.172926: train Epoch: [62][ 89/129]	Time  0.970 ( 2.069)	Data  0.001 ( 1.091)	Loss 1.0007e-01 (7.5820e-02) 
2023-05-26 01:04:09.401733: train Epoch: [62][ 90/129]	Time  3.229 ( 2.082)	Data  2.258 ( 1.104)	Loss 8.7004e-02 (7.5943e-02) 
2023-05-26 01:04:10.378150: train Epoch: [62][ 91/129]	Time  0.976 ( 2.070)	Data  0.001 ( 1.092)	Loss 6.2113e-02 (7.5793e-02) 
2023-05-26 01:04:13.641768: train Epoch: [62][ 92/129]	Time  3.264 ( 2.083)	Data  2.293 ( 1.105)	Loss 7.3890e-02 (7.5772e-02) 
2023-05-26 01:04:14.616588: train Epoch: [62][ 93/129]	Time  0.975 ( 2.071)	Data  0.001 ( 1.093)	Loss 1.0300e-01 (7.6062e-02) 
2023-05-26 01:04:17.867611: train Epoch: [62][ 94/129]	Time  3.251 ( 2.084)	Data  2.284 ( 1.106)	Loss 8.9383e-02 (7.6202e-02) 
2023-05-26 01:04:18.848030: train Epoch: [62][ 95/129]	Time  0.980 ( 2.072)	Data  0.001 ( 1.094)	Loss 7.6078e-02 (7.6201e-02) 
2023-05-26 01:04:21.885386: train Epoch: [62][ 96/129]	Time  3.037 ( 2.082)	Data  2.058 ( 1.104)	Loss 5.5089e-02 (7.5983e-02) 
2023-05-26 01:04:22.853940: train Epoch: [62][ 97/129]	Time  0.969 ( 2.071)	Data  0.001 ( 1.093)	Loss 9.2982e-02 (7.6157e-02) 
2023-05-26 01:04:25.944046: train Epoch: [62][ 98/129]	Time  3.090 ( 2.081)	Data  2.116 ( 1.103)	Loss 7.8497e-02 (7.6180e-02) 
2023-05-26 01:04:26.924937: train Epoch: [62][ 99/129]	Time  0.981 ( 2.070)	Data  0.001 ( 1.092)	Loss 5.4845e-02 (7.5967e-02) 
2023-05-26 01:04:29.967088: train Epoch: [62][100/129]	Time  3.042 ( 2.080)	Data  2.065 ( 1.102)	Loss 5.3479e-02 (7.5744e-02) 
2023-05-26 01:04:30.935212: train Epoch: [62][101/129]	Time  0.968 ( 2.069)	Data  0.001 ( 1.091)	Loss 5.0355e-02 (7.5495e-02) 
2023-05-26 01:04:34.097287: train Epoch: [62][102/129]	Time  3.162 ( 2.079)	Data  2.184 ( 1.102)	Loss 6.8616e-02 (7.5429e-02) 
2023-05-26 01:04:35.066564: train Epoch: [62][103/129]	Time  0.969 ( 2.069)	Data  0.001 ( 1.091)	Loss 8.0671e-02 (7.5479e-02) 
2023-05-26 01:04:38.048764: train Epoch: [62][104/129]	Time  2.982 ( 2.077)	Data  2.010 ( 1.100)	Loss 6.4652e-02 (7.5376e-02) 
2023-05-26 01:04:39.025731: train Epoch: [62][105/129]	Time  0.977 ( 2.067)	Data  0.002 ( 1.090)	Loss 5.9564e-02 (7.5227e-02) 
2023-05-26 01:04:42.262763: train Epoch: [62][106/129]	Time  3.237 ( 2.078)	Data  2.252 ( 1.100)	Loss 1.3548e-01 (7.5790e-02) 
2023-05-26 01:04:43.240671: train Epoch: [62][107/129]	Time  0.978 ( 2.068)	Data  0.001 ( 1.090)	Loss 5.8054e-02 (7.5626e-02) 
2023-05-26 01:04:46.255201: train Epoch: [62][108/129]	Time  3.015 ( 2.076)	Data  2.027 ( 1.099)	Loss 4.6990e-02 (7.5363e-02) 
2023-05-26 01:04:47.232733: train Epoch: [62][109/129]	Time  0.978 ( 2.066)	Data  0.002 ( 1.089)	Loss 7.0292e-02 (7.5317e-02) 
2023-05-26 01:04:50.370357: train Epoch: [62][110/129]	Time  3.138 ( 2.076)	Data  2.172 ( 1.099)	Loss 7.3653e-02 (7.5302e-02) 
2023-05-26 01:04:51.348927: train Epoch: [62][111/129]	Time  0.979 ( 2.066)	Data  0.001 ( 1.089)	Loss 9.4810e-02 (7.5476e-02) 
2023-05-26 01:04:54.338346: train Epoch: [62][112/129]	Time  2.989 ( 2.074)	Data  2.025 ( 1.097)	Loss 8.1794e-02 (7.5532e-02) 
2023-05-26 01:04:55.318290: train Epoch: [62][113/129]	Time  0.980 ( 2.065)	Data  0.001 ( 1.088)	Loss 6.2376e-02 (7.5417e-02) 
2023-05-26 01:04:58.336788: train Epoch: [62][114/129]	Time  3.018 ( 2.073)	Data  2.045 ( 1.096)	Loss 8.7957e-02 (7.5526e-02) 
2023-05-26 01:04:59.320992: train Epoch: [62][115/129]	Time  0.984 ( 2.064)	Data  0.001 ( 1.086)	Loss 5.9096e-02 (7.5384e-02) 
2023-05-26 01:05:02.449974: train Epoch: [62][116/129]	Time  3.129 ( 2.073)	Data  2.167 ( 1.096)	Loss 3.3091e-02 (7.5023e-02) 
2023-05-26 01:05:03.416827: train Epoch: [62][117/129]	Time  0.967 ( 2.063)	Data  0.001 ( 1.086)	Loss 4.9783e-02 (7.4809e-02) 
2023-05-26 01:05:06.366718: train Epoch: [62][118/129]	Time  2.950 ( 2.071)	Data  1.975 ( 1.094)	Loss 5.0500e-02 (7.4604e-02) 
2023-05-26 01:05:07.334096: train Epoch: [62][119/129]	Time  0.967 ( 2.062)	Data  0.001 ( 1.085)	Loss 1.1558e-01 (7.4946e-02) 
2023-05-26 01:05:10.442652: train Epoch: [62][120/129]	Time  3.109 ( 2.070)	Data  2.141 ( 1.093)	Loss 7.3183e-02 (7.4931e-02) 
2023-05-26 01:05:11.419090: train Epoch: [62][121/129]	Time  0.976 ( 2.061)	Data  0.001 ( 1.085)	Loss 5.7532e-02 (7.4789e-02) 
2023-05-26 01:05:14.555724: train Epoch: [62][122/129]	Time  3.137 ( 2.070)	Data  2.162 ( 1.093)	Loss 5.5700e-02 (7.4633e-02) 
2023-05-26 01:05:15.527109: train Epoch: [62][123/129]	Time  0.971 ( 2.061)	Data  0.001 ( 1.084)	Loss 5.9440e-02 (7.4511e-02) 
2023-05-26 01:05:18.652297: train Epoch: [62][124/129]	Time  3.125 ( 2.070)	Data  2.141 ( 1.093)	Loss 9.4026e-02 (7.4667e-02) 
2023-05-26 01:05:19.635106: train Epoch: [62][125/129]	Time  0.983 ( 2.061)	Data  0.002 ( 1.084)	Loss 1.0317e-01 (7.4893e-02) 
2023-05-26 01:05:22.587449: train Epoch: [62][126/129]	Time  2.952 ( 2.068)	Data  1.983 ( 1.091)	Loss 8.0987e-02 (7.4941e-02) 
2023-05-26 01:05:23.571559: train Epoch: [62][127/129]	Time  0.984 ( 2.060)	Data  0.001 ( 1.083)	Loss 5.3858e-02 (7.4776e-02) 
2023-05-26 01:05:25.664149: train Epoch: [62][128/129]	Time  2.093 ( 2.060)	Data  1.127 ( 1.083)	Loss 5.9989e-02 (7.4662e-02) 
2023-05-26 01:05:25.711588: Train Epoch done in 265.78707995699733 s 
2023-05-26 01:05:28.433176: val Epoch: [62][ 0/72]	Time  1.842 ( 1.842)	Data  1.616 ( 1.616)	Loss 3.8907e-02 (3.8907e-02) 
2023-05-26 01:05:28.566993: val Epoch: [62][ 1/72]	Time  0.134 ( 0.988)	Data  0.001 ( 0.809)	Loss 1.2345e-01 (8.1176e-02) 
2023-05-26 01:05:29.747991: val Epoch: [62][ 2/72]	Time  1.181 ( 1.052)	Data  1.047 ( 0.888)	Loss 2.9998e-02 (6.4117e-02) 
2023-05-26 01:05:29.879634: val Epoch: [62][ 3/72]	Time  0.132 ( 0.822)	Data  0.001 ( 0.666)	Loss 1.8232e-01 (9.3668e-02) 
2023-05-26 01:05:31.236453: val Epoch: [62][ 4/72]	Time  1.357 ( 0.929)	Data  1.209 ( 0.775)	Loss 8.0308e-02 (9.0996e-02) 
2023-05-26 01:05:31.372591: val Epoch: [62][ 5/72]	Time  0.136 ( 0.797)	Data  0.001 ( 0.646)	Loss 1.5604e-01 (1.0184e-01) 
2023-05-26 01:05:32.574424: val Epoch: [62][ 6/72]	Time  1.202 ( 0.855)	Data  1.064 ( 0.706)	Loss 4.1136e-02 (9.3165e-02) 
2023-05-26 01:05:32.707756: val Epoch: [62][ 7/72]	Time  0.133 ( 0.765)	Data  0.001 ( 0.617)	Loss 1.2938e-01 (9.7691e-02) 
2023-05-26 01:05:33.970453: val Epoch: [62][ 8/72]	Time  1.263 ( 0.820)	Data  1.115 ( 0.673)	Loss 4.0731e-02 (9.1363e-02) 
2023-05-26 01:05:34.116991: val Epoch: [62][ 9/72]	Time  0.147 ( 0.753)	Data  0.002 ( 0.606)	Loss 3.0127e-01 (1.1235e-01) 
2023-05-26 01:05:35.375957: val Epoch: [62][10/72]	Time  1.259 ( 0.799)	Data  1.129 ( 0.653)	Loss 4.5933e-02 (1.0631e-01) 
2023-05-26 01:05:35.507067: val Epoch: [62][11/72]	Time  0.131 ( 0.743)	Data  0.001 ( 0.599)	Loss 1.5721e-01 (1.1056e-01) 
2023-05-26 01:05:36.859853: val Epoch: [62][12/72]	Time  1.353 ( 0.790)	Data  1.207 ( 0.646)	Loss 2.4879e-01 (1.2119e-01) 
2023-05-26 01:05:37.001792: val Epoch: [62][13/72]	Time  0.142 ( 0.744)	Data  0.001 ( 0.600)	Loss 1.2118e-01 (1.2119e-01) 
2023-05-26 01:05:38.241184: val Epoch: [62][14/72]	Time  1.239 ( 0.777)	Data  1.099 ( 0.633)	Loss 2.2079e-01 (1.2783e-01) 
2023-05-26 01:05:38.373314: val Epoch: [62][15/72]	Time  0.132 ( 0.736)	Data  0.001 ( 0.593)	Loss 9.1604e-02 (1.2557e-01) 
2023-05-26 01:05:39.637329: val Epoch: [62][16/72]	Time  1.264 ( 0.767)	Data  1.130 ( 0.625)	Loss 1.3134e-01 (1.2591e-01) 
2023-05-26 01:05:39.783523: val Epoch: [62][17/72]	Time  0.146 ( 0.733)	Data  0.014 ( 0.591)	Loss 6.5318e-02 (1.2254e-01) 
2023-05-26 01:05:40.993741: val Epoch: [62][18/72]	Time  1.210 ( 0.758)	Data  1.077 ( 0.617)	Loss 3.7107e-02 (1.1804e-01) 
2023-05-26 01:05:41.215469: val Epoch: [62][19/72]	Time  0.222 ( 0.731)	Data  0.091 ( 0.590)	Loss 4.7523e-02 (1.1452e-01) 
2023-05-26 01:05:42.330641: val Epoch: [62][20/72]	Time  1.115 ( 0.750)	Data  0.981 ( 0.609)	Loss 6.8232e-02 (1.1231e-01) 
2023-05-26 01:05:42.570912: val Epoch: [62][21/72]	Time  0.240 ( 0.726)	Data  0.108 ( 0.586)	Loss 1.2200e-01 (1.1275e-01) 
2023-05-26 01:05:43.701396: val Epoch: [62][22/72]	Time  1.130 ( 0.744)	Data  0.991 ( 0.604)	Loss 2.2137e-01 (1.1748e-01) 
2023-05-26 01:05:44.011036: val Epoch: [62][23/72]	Time  0.310 ( 0.726)	Data  0.166 ( 0.586)	Loss 1.4396e-01 (1.1858e-01) 
2023-05-26 01:05:45.111681: val Epoch: [62][24/72]	Time  1.101 ( 0.741)	Data  0.968 ( 0.601)	Loss 3.6996e-01 (1.2863e-01) 
2023-05-26 01:05:45.404983: val Epoch: [62][25/72]	Time  0.293 ( 0.724)	Data  0.159 ( 0.584)	Loss 5.2841e-02 (1.2572e-01) 
2023-05-26 01:05:46.508167: val Epoch: [62][26/72]	Time  1.103 ( 0.738)	Data  0.969 ( 0.598)	Loss 3.5714e-02 (1.2239e-01) 
2023-05-26 01:05:46.814699: val Epoch: [62][27/72]	Time  0.307 ( 0.722)	Data  0.175 ( 0.583)	Loss 2.9650e-01 (1.2860e-01) 
2023-05-26 01:05:47.890876: val Epoch: [62][28/72]	Time  1.076 ( 0.734)	Data  0.946 ( 0.595)	Loss 7.3246e-02 (1.2670e-01) 
2023-05-26 01:05:48.182423: val Epoch: [62][29/72]	Time  0.292 ( 0.720)	Data  0.160 ( 0.581)	Loss 6.9323e-02 (1.2478e-01) 
2023-05-26 01:05:49.260483: val Epoch: [62][30/72]	Time  1.078 ( 0.731)	Data  0.955 ( 0.593)	Loss 5.1031e-02 (1.2240e-01) 
2023-05-26 01:05:49.556381: val Epoch: [62][31/72]	Time  0.296 ( 0.718)	Data  0.160 ( 0.579)	Loss 1.8995e-01 (1.2451e-01) 
2023-05-26 01:05:50.641934: val Epoch: [62][32/72]	Time  1.086 ( 0.729)	Data  0.952 ( 0.591)	Loss 5.4005e-02 (1.2238e-01) 
2023-05-26 01:05:50.977963: val Epoch: [62][33/72]	Time  0.336 ( 0.717)	Data  0.192 ( 0.579)	Loss 4.5275e-01 (1.3209e-01) 
2023-05-26 01:05:52.104927: val Epoch: [62][34/72]	Time  1.127 ( 0.729)	Data  0.984 ( 0.591)	Loss 7.6662e-02 (1.3051e-01) 
2023-05-26 01:05:52.394752: val Epoch: [62][35/72]	Time  0.290 ( 0.717)	Data  0.144 ( 0.578)	Loss 6.4773e-02 (1.2868e-01) 
2023-05-26 01:05:53.459787: val Epoch: [62][36/72]	Time  1.065 ( 0.726)	Data  0.940 ( 0.588)	Loss 3.5217e-02 (1.2616e-01) 
2023-05-26 01:05:53.736244: val Epoch: [62][37/72]	Time  0.276 ( 0.714)	Data  0.143 ( 0.576)	Loss 6.0722e-02 (1.2444e-01) 
2023-05-26 01:05:54.849602: val Epoch: [62][38/72]	Time  1.113 ( 0.725)	Data  0.975 ( 0.586)	Loss 4.2875e-02 (1.2235e-01) 
2023-05-26 01:05:55.067719: val Epoch: [62][39/72]	Time  0.218 ( 0.712)	Data  0.090 ( 0.574)	Loss 4.3879e-02 (1.2038e-01) 
2023-05-26 01:05:56.154880: val Epoch: [62][40/72]	Time  1.087 ( 0.721)	Data  0.963 ( 0.584)	Loss 5.3161e-02 (1.1874e-01) 
2023-05-26 01:05:56.460716: val Epoch: [62][41/72]	Time  0.306 ( 0.711)	Data  0.165 ( 0.574)	Loss 7.3524e-02 (1.1767e-01) 
2023-05-26 01:05:57.597860: val Epoch: [62][42/72]	Time  1.137 ( 0.721)	Data  0.995 ( 0.583)	Loss 3.7926e-01 (1.2375e-01) 
2023-05-26 01:05:57.843984: val Epoch: [62][43/72]	Time  0.246 ( 0.710)	Data  0.117 ( 0.573)	Loss 5.8544e-02 (1.2227e-01) 
2023-05-26 01:05:58.955095: val Epoch: [62][44/72]	Time  1.111 ( 0.719)	Data  0.984 ( 0.582)	Loss 3.9779e-01 (1.2839e-01) 
2023-05-26 01:05:59.252134: val Epoch: [62][45/72]	Time  0.297 ( 0.710)	Data  0.159 ( 0.573)	Loss 2.5919e-01 (1.3124e-01) 
2023-05-26 01:06:00.352720: val Epoch: [62][46/72]	Time  1.101 ( 0.718)	Data  0.971 ( 0.581)	Loss 5.1275e-02 (1.2953e-01) 
2023-05-26 01:06:00.654627: val Epoch: [62][47/72]	Time  0.302 ( 0.710)	Data  0.174 ( 0.573)	Loss 8.8462e-02 (1.2868e-01) 
2023-05-26 01:06:01.735039: val Epoch: [62][48/72]	Time  1.080 ( 0.717)	Data  0.943 ( 0.580)	Loss 6.9580e-02 (1.2747e-01) 
2023-05-26 01:06:02.035074: val Epoch: [62][49/72]	Time  0.300 ( 0.709)	Data  0.159 ( 0.572)	Loss 9.9234e-02 (1.2691e-01) 
2023-05-26 01:06:03.107307: val Epoch: [62][50/72]	Time  1.072 ( 0.716)	Data  0.939 ( 0.579)	Loss 2.6248e-01 (1.2957e-01) 
2023-05-26 01:06:03.408591: val Epoch: [62][51/72]	Time  0.301 ( 0.708)	Data  0.173 ( 0.571)	Loss 1.1066e-01 (1.2920e-01) 
2023-05-26 01:06:04.422979: val Epoch: [62][52/72]	Time  1.014 ( 0.714)	Data  0.887 ( 0.577)	Loss 7.5087e-02 (1.2818e-01) 
2023-05-26 01:06:04.749107: val Epoch: [62][53/72]	Time  0.326 ( 0.707)	Data  0.186 ( 0.570)	Loss 1.0646e-01 (1.2778e-01) 
2023-05-26 01:06:05.829223: val Epoch: [62][54/72]	Time  1.080 ( 0.713)	Data  0.950 ( 0.577)	Loss 2.9047e-01 (1.3074e-01) 
2023-05-26 01:06:06.073794: val Epoch: [62][55/72]	Time  0.245 ( 0.705)	Data  0.113 ( 0.569)	Loss 3.7047e-02 (1.2906e-01) 
2023-05-26 01:06:07.267744: val Epoch: [62][56/72]	Time  1.194 ( 0.714)	Data  1.064 ( 0.577)	Loss 3.3827e-01 (1.3273e-01) 
2023-05-26 01:06:07.475296: val Epoch: [62][57/72]	Time  0.208 ( 0.705)	Data  0.076 ( 0.569)	Loss 9.0094e-02 (1.3200e-01) 
2023-05-26 01:06:08.667545: val Epoch: [62][58/72]	Time  1.192 ( 0.713)	Data  1.061 ( 0.577)	Loss 4.4129e-02 (1.3051e-01) 
2023-05-26 01:06:08.876026: val Epoch: [62][59/72]	Time  0.208 ( 0.705)	Data  0.069 ( 0.569)	Loss 4.5240e-02 (1.2909e-01) 
2023-05-26 01:06:10.106525: val Epoch: [62][60/72]	Time  1.231 ( 0.713)	Data  1.101 ( 0.577)	Loss 8.2000e-02 (1.2832e-01) 
2023-05-26 01:06:10.241711: val Epoch: [62][61/72]	Time  0.135 ( 0.704)	Data  0.001 ( 0.568)	Loss 7.8177e-02 (1.2751e-01) 
2023-05-26 01:06:11.439783: val Epoch: [62][62/72]	Time  1.198 ( 0.712)	Data  1.064 ( 0.576)	Loss 6.3738e-02 (1.2650e-01) 
2023-05-26 01:06:11.595791: val Epoch: [62][63/72]	Time  0.156 ( 0.703)	Data  0.017 ( 0.567)	Loss 5.6911e-02 (1.2541e-01) 
2023-05-26 01:06:12.796600: val Epoch: [62][64/72]	Time  1.201 ( 0.711)	Data  1.074 ( 0.575)	Loss 5.6753e-02 (1.2435e-01) 
2023-05-26 01:06:12.961112: val Epoch: [62][65/72]	Time  0.164 ( 0.703)	Data  0.033 ( 0.567)	Loss 5.5702e-02 (1.2331e-01) 
2023-05-26 01:06:14.120525: val Epoch: [62][66/72]	Time  1.159 ( 0.709)	Data  1.031 ( 0.574)	Loss 8.0498e-02 (1.2267e-01) 
2023-05-26 01:06:14.386960: val Epoch: [62][67/72]	Time  0.266 ( 0.703)	Data  0.136 ( 0.567)	Loss 6.5756e-02 (1.2184e-01) 
2023-05-26 01:06:15.561697: val Epoch: [62][68/72]	Time  1.175 ( 0.710)	Data  1.047 ( 0.574)	Loss 8.4932e-02 (1.2130e-01) 
2023-05-26 01:06:15.765273: val Epoch: [62][69/72]	Time  0.204 ( 0.702)	Data  0.065 ( 0.567)	Loss 4.8801e-02 (1.2027e-01) 
2023-05-26 01:06:16.943301: val Epoch: [62][70/72]	Time  1.178 ( 0.709)	Data  1.039 ( 0.573)	Loss 9.6240e-02 (1.1993e-01) 
2023-05-26 01:06:17.073433: val Epoch: [62][71/72]	Time  0.130 ( 0.701)	Data  0.001 ( 0.566)	Loss 8.4090e-02 (1.1943e-01) 
2023-05-26 01:06:17.253007: Epoch 62 :Val : ['ET : 0.7452116012573242', 'TC : 0.8051574230194092', 'WT : 0.8761122226715088'] 
2023-05-26 01:06:17.260791: Epoch 62 :Val : ['ET : 0.7452116012573242', 'TC : 0.8051574230194092', 'WT : 0.8761122226715088'] 
2023-05-26 01:06:17.264043: Saving the model with DSC 0.8160662055015564 
2023-05-26 01:06:18.179720: Val epoch done in 52.46811113399963 s 
2023-05-26 01:06:18.187543: Batches per epoch:  129 
2023-05-26 01:06:23.523276: train Epoch: [63][  0/129]	Time  5.335 ( 5.335)	Data  4.279 ( 4.279)	Loss 1.3069e-01 (1.3069e-01) 
2023-05-26 01:06:24.489016: train Epoch: [63][  1/129]	Time  0.966 ( 3.150)	Data  0.002 ( 2.141)	Loss 6.3152e-02 (9.6921e-02) 
2023-05-26 01:06:27.546576: train Epoch: [63][  2/129]	Time  3.058 ( 3.119)	Data  2.084 ( 2.122)	Loss 4.5461e-02 (7.9768e-02) 
2023-05-26 01:06:28.517279: train Epoch: [63][  3/129]	Time  0.971 ( 2.582)	Data  0.001 ( 1.592)	Loss 5.5455e-02 (7.3689e-02) 
2023-05-26 01:06:31.519850: train Epoch: [63][  4/129]	Time  3.002 ( 2.666)	Data  2.025 ( 1.678)	Loss 5.1997e-02 (6.9351e-02) 
2023-05-26 01:06:32.505991: train Epoch: [63][  5/129]	Time  0.986 ( 2.386)	Data  0.002 ( 1.399)	Loss 8.1582e-02 (7.1389e-02) 
2023-05-26 01:06:35.557127: train Epoch: [63][  6/129]	Time  3.051 ( 2.481)	Data  2.084 ( 1.497)	Loss 7.1092e-02 (7.1347e-02) 
2023-05-26 01:06:36.533983: train Epoch: [63][  7/129]	Time  0.977 ( 2.293)	Data  0.001 ( 1.310)	Loss 9.2264e-02 (7.3962e-02) 
2023-05-26 01:06:39.569583: train Epoch: [63][  8/129]	Time  3.036 ( 2.376)	Data  2.054 ( 1.393)	Loss 5.9846e-02 (7.2393e-02) 
2023-05-26 01:06:40.566099: train Epoch: [63][  9/129]	Time  0.996 ( 2.238)	Data  0.001 ( 1.253)	Loss 5.9427e-02 (7.1097e-02) 
2023-05-26 01:06:43.623720: train Epoch: [63][ 10/129]	Time  3.058 ( 2.312)	Data  2.072 ( 1.328)	Loss 7.5505e-02 (7.1497e-02) 
2023-05-26 01:06:44.608465: train Epoch: [63][ 11/129]	Time  0.985 ( 2.202)	Data  0.001 ( 1.217)	Loss 7.3471e-02 (7.1662e-02) 
2023-05-26 01:06:47.721649: train Epoch: [63][ 12/129]	Time  3.113 ( 2.272)	Data  2.148 ( 1.289)	Loss 9.3404e-02 (7.3334e-02) 
2023-05-26 01:06:48.693124: train Epoch: [63][ 13/129]	Time  0.971 ( 2.179)	Data  0.001 ( 1.197)	Loss 5.9396e-02 (7.2339e-02) 
2023-05-26 01:06:51.716115: train Epoch: [63][ 14/129]	Time  3.023 ( 2.235)	Data  2.059 ( 1.254)	Loss 5.2936e-02 (7.1045e-02) 
2023-05-26 01:06:52.683303: train Epoch: [63][ 15/129]	Time  0.967 ( 2.156)	Data  0.001 ( 1.176)	Loss 6.6131e-02 (7.0738e-02) 
2023-05-26 01:06:55.818486: train Epoch: [63][ 16/129]	Time  3.135 ( 2.214)	Data  2.164 ( 1.234)	Loss 7.7806e-02 (7.1154e-02) 
2023-05-26 01:06:56.801890: train Epoch: [63][ 17/129]	Time  0.983 ( 2.145)	Data  0.002 ( 1.166)	Loss 7.6012e-02 (7.1424e-02) 
2023-05-26 01:06:59.829725: train Epoch: [63][ 18/129]	Time  3.028 ( 2.192)	Data  2.073 ( 1.214)	Loss 7.9441e-02 (7.1846e-02) 
2023-05-26 01:07:00.798872: train Epoch: [63][ 19/129]	Time  0.969 ( 2.131)	Data  0.001 ( 1.153)	Loss 7.0527e-02 (7.1780e-02) 
2023-05-26 01:07:04.001647: train Epoch: [63][ 20/129]	Time  3.203 ( 2.182)	Data  2.237 ( 1.205)	Loss 6.6802e-02 (7.1543e-02) 
2023-05-26 01:07:04.986063: train Epoch: [63][ 21/129]	Time  0.984 ( 2.127)	Data  0.001 ( 1.150)	Loss 6.0201e-02 (7.1027e-02) 
2023-05-26 01:07:08.094539: train Epoch: [63][ 22/129]	Time  3.108 ( 2.170)	Data  2.134 ( 1.193)	Loss 1.1781e-01 (7.3061e-02) 
2023-05-26 01:07:09.055790: train Epoch: [63][ 23/129]	Time  0.961 ( 2.119)	Data  0.001 ( 1.143)	Loss 5.7882e-02 (7.2429e-02) 
2023-05-26 01:07:12.127390: train Epoch: [63][ 24/129]	Time  3.072 ( 2.158)	Data  2.099 ( 1.181)	Loss 7.7858e-02 (7.2646e-02) 
2023-05-26 01:07:13.114903: train Epoch: [63][ 25/129]	Time  0.988 ( 2.113)	Data  0.002 ( 1.136)	Loss 7.2689e-02 (7.2648e-02) 
2023-05-26 01:07:16.188284: train Epoch: [63][ 26/129]	Time  3.073 ( 2.148)	Data  2.101 ( 1.172)	Loss 9.1146e-02 (7.3333e-02) 
2023-05-26 01:07:17.172199: train Epoch: [63][ 27/129]	Time  0.984 ( 2.107)	Data  0.001 ( 1.130)	Loss 3.7112e-02 (7.2039e-02) 
2023-05-26 01:07:20.341484: train Epoch: [63][ 28/129]	Time  3.169 ( 2.143)	Data  2.204 ( 1.167)	Loss 4.3623e-02 (7.1059e-02) 
2023-05-26 01:07:21.314638: train Epoch: [63][ 29/129]	Time  0.973 ( 2.104)	Data  0.001 ( 1.128)	Loss 4.6434e-02 (7.0239e-02) 
2023-05-26 01:07:24.359921: train Epoch: [63][ 30/129]	Time  3.045 ( 2.135)	Data  2.079 ( 1.159)	Loss 1.1044e-01 (7.1535e-02) 
2023-05-26 01:07:25.338624: train Epoch: [63][ 31/129]	Time  0.979 ( 2.098)	Data  0.001 ( 1.122)	Loss 7.5178e-02 (7.1649e-02) 
2023-05-26 01:07:28.408133: train Epoch: [63][ 32/129]	Time  3.070 ( 2.128)	Data  2.105 ( 1.152)	Loss 7.4406e-02 (7.1733e-02) 
2023-05-26 01:07:29.380543: train Epoch: [63][ 33/129]	Time  0.972 ( 2.094)	Data  0.001 ( 1.118)	Loss 5.2587e-02 (7.1170e-02) 
2023-05-26 01:07:32.536945: train Epoch: [63][ 34/129]	Time  3.156 ( 2.124)	Data  2.186 ( 1.149)	Loss 7.2221e-02 (7.1200e-02) 
2023-05-26 01:07:33.511153: train Epoch: [63][ 35/129]	Time  0.974 ( 2.092)	Data  0.001 ( 1.117)	Loss 8.1419e-02 (7.1483e-02) 
2023-05-26 01:07:36.645731: train Epoch: [63][ 36/129]	Time  3.135 ( 2.120)	Data  2.159 ( 1.145)	Loss 5.9037e-02 (7.1147e-02) 
2023-05-26 01:07:37.627820: train Epoch: [63][ 37/129]	Time  0.982 ( 2.091)	Data  0.001 ( 1.115)	Loss 6.9951e-02 (7.1116e-02) 
2023-05-26 01:07:40.646610: train Epoch: [63][ 38/129]	Time  3.019 ( 2.114)	Data  2.051 ( 1.139)	Loss 6.7575e-02 (7.1025e-02) 
2023-05-26 01:07:41.628359: train Epoch: [63][ 39/129]	Time  0.982 ( 2.086)	Data  0.001 ( 1.111)	Loss 8.2404e-02 (7.1309e-02) 
2023-05-26 01:07:44.774144: train Epoch: [63][ 40/129]	Time  3.146 ( 2.112)	Data  2.171 ( 1.136)	Loss 6.8215e-02 (7.1234e-02) 
2023-05-26 01:07:45.742338: train Epoch: [63][ 41/129]	Time  0.968 ( 2.085)	Data  0.001 ( 1.109)	Loss 5.7269e-02 (7.0901e-02) 
2023-05-26 01:07:48.864491: train Epoch: [63][ 42/129]	Time  3.122 ( 2.109)	Data  2.152 ( 1.134)	Loss 6.3271e-02 (7.0724e-02) 
2023-05-26 01:07:49.831335: train Epoch: [63][ 43/129]	Time  0.967 ( 2.083)	Data  0.001 ( 1.108)	Loss 1.2094e-01 (7.1865e-02) 
2023-05-26 01:07:53.080588: train Epoch: [63][ 44/129]	Time  3.249 ( 2.109)	Data  2.270 ( 1.134)	Loss 8.5157e-02 (7.2161e-02) 
2023-05-26 01:07:54.053818: train Epoch: [63][ 45/129]	Time  0.973 ( 2.084)	Data  0.001 ( 1.109)	Loss 6.3691e-02 (7.1976e-02) 
2023-05-26 01:07:57.290561: train Epoch: [63][ 46/129]	Time  3.237 ( 2.109)	Data  2.270 ( 1.134)	Loss 7.9691e-02 (7.2141e-02) 
2023-05-26 01:07:58.264892: train Epoch: [63][ 47/129]	Time  0.974 ( 2.085)	Data  0.001 ( 1.110)	Loss 4.8743e-02 (7.1653e-02) 
2023-05-26 01:08:01.493463: train Epoch: [63][ 48/129]	Time  3.229 ( 2.108)	Data  2.248 ( 1.133)	Loss 1.0015e-01 (7.2235e-02) 
2023-05-26 01:08:02.461774: train Epoch: [63][ 49/129]	Time  0.968 ( 2.085)	Data  0.001 ( 1.111)	Loss 9.8854e-02 (7.2767e-02) 
2023-05-26 01:08:05.643656: train Epoch: [63][ 50/129]	Time  3.182 ( 2.107)	Data  2.210 ( 1.132)	Loss 5.0578e-02 (7.2332e-02) 
2023-05-26 01:08:06.612971: train Epoch: [63][ 51/129]	Time  0.969 ( 2.085)	Data  0.001 ( 1.111)	Loss 3.8374e-02 (7.1679e-02) 
2023-05-26 01:08:09.685377: train Epoch: [63][ 52/129]	Time  3.072 ( 2.104)	Data  2.058 ( 1.128)	Loss 8.8289e-02 (7.1992e-02) 
2023-05-26 01:08:10.664128: train Epoch: [63][ 53/129]	Time  0.979 ( 2.083)	Data  0.001 ( 1.108)	Loss 1.0241e-01 (7.2556e-02) 
2023-05-26 01:08:13.807175: train Epoch: [63][ 54/129]	Time  3.143 ( 2.102)	Data  2.157 ( 1.127)	Loss 7.8581e-02 (7.2665e-02) 
2023-05-26 01:08:14.784354: train Epoch: [63][ 55/129]	Time  0.977 ( 2.082)	Data  0.002 ( 1.107)	Loss 4.7209e-02 (7.2211e-02) 
2023-05-26 01:08:17.777504: train Epoch: [63][ 56/129]	Time  2.993 ( 2.098)	Data  2.015 ( 1.123)	Loss 8.5005e-02 (7.2435e-02) 
2023-05-26 01:08:18.770159: train Epoch: [63][ 57/129]	Time  0.993 ( 2.079)	Data  0.001 ( 1.103)	Loss 5.8005e-02 (7.2186e-02) 
2023-05-26 01:08:21.790566: train Epoch: [63][ 58/129]	Time  3.020 ( 2.095)	Data  2.038 ( 1.119)	Loss 8.5239e-02 (7.2408e-02) 
2023-05-26 01:08:22.765397: train Epoch: [63][ 59/129]	Time  0.975 ( 2.076)	Data  0.001 ( 1.100)	Loss 5.9745e-02 (7.2197e-02) 
2023-05-26 01:08:25.808667: train Epoch: [63][ 60/129]	Time  3.043 ( 2.092)	Data  2.060 ( 1.116)	Loss 4.4387e-02 (7.1741e-02) 
2023-05-26 01:08:26.795851: train Epoch: [63][ 61/129]	Time  0.987 ( 2.074)	Data  0.001 ( 1.098)	Loss 9.8079e-02 (7.2165e-02) 
2023-05-26 01:08:29.908671: train Epoch: [63][ 62/129]	Time  3.113 ( 2.091)	Data  2.118 ( 1.114)	Loss 5.7210e-02 (7.1928e-02) 
2023-05-26 01:08:30.895398: train Epoch: [63][ 63/129]	Time  0.987 ( 2.074)	Data  0.001 ( 1.097)	Loss 6.9542e-02 (7.1891e-02) 
2023-05-26 01:08:34.105664: train Epoch: [63][ 64/129]	Time  3.210 ( 2.091)	Data  2.229 ( 1.114)	Loss 1.0389e-01 (7.2383e-02) 
2023-05-26 01:08:35.076270: train Epoch: [63][ 65/129]	Time  0.971 ( 2.074)	Data  0.001 ( 1.097)	Loss 5.6513e-02 (7.2143e-02) 
2023-05-26 01:08:38.140468: train Epoch: [63][ 66/129]	Time  3.064 ( 2.089)	Data  2.087 ( 1.112)	Loss 9.2720e-02 (7.2450e-02) 
2023-05-26 01:08:39.117257: train Epoch: [63][ 67/129]	Time  0.977 ( 2.072)	Data  0.001 ( 1.096)	Loss 8.0996e-02 (7.2575e-02) 
2023-05-26 01:08:41.819447: train Epoch: [63][ 68/129]	Time  2.702 ( 2.082)	Data  1.753 ( 1.105)	Loss 5.9205e-02 (7.2382e-02) 
2023-05-26 01:08:42.782215: train Epoch: [63][ 69/129]	Time  0.963 ( 2.066)	Data  0.001 ( 1.090)	Loss 7.8580e-02 (7.2470e-02) 
2023-05-26 01:08:45.631997: train Epoch: [63][ 70/129]	Time  2.850 ( 2.077)	Data  1.888 ( 1.101)	Loss 1.0232e-01 (7.2891e-02) 
2023-05-26 01:08:46.595419: train Epoch: [63][ 71/129]	Time  0.963 ( 2.061)	Data  0.001 ( 1.086)	Loss 8.8819e-02 (7.3112e-02) 
2023-05-26 01:08:49.395405: train Epoch: [63][ 72/129]	Time  2.800 ( 2.071)	Data  1.823 ( 1.096)	Loss 4.5241e-02 (7.2730e-02) 
2023-05-26 01:08:50.355649: train Epoch: [63][ 73/129]	Time  0.960 ( 2.056)	Data  0.001 ( 1.081)	Loss 9.6499e-02 (7.3051e-02) 
2023-05-26 01:08:53.156652: train Epoch: [63][ 74/129]	Time  2.801 ( 2.066)	Data  1.827 ( 1.091)	Loss 5.2731e-02 (7.2780e-02) 
2023-05-26 01:08:54.121349: train Epoch: [63][ 75/129]	Time  0.965 ( 2.052)	Data  0.001 ( 1.077)	Loss 7.5745e-02 (7.2819e-02) 
2023-05-26 01:08:56.840367: train Epoch: [63][ 76/129]	Time  2.719 ( 2.060)	Data  1.758 ( 1.085)	Loss 1.5027e-01 (7.3825e-02) 
2023-05-26 01:08:57.789983: train Epoch: [63][ 77/129]	Time  0.950 ( 2.046)	Data  0.001 ( 1.071)	Loss 6.2449e-02 (7.3679e-02) 
2023-05-26 01:09:00.524134: train Epoch: [63][ 78/129]	Time  2.734 ( 2.055)	Data  1.772 ( 1.080)	Loss 5.2482e-02 (7.3411e-02) 
2023-05-26 01:09:01.473929: train Epoch: [63][ 79/129]	Time  0.950 ( 2.041)	Data  0.001 ( 1.067)	Loss 6.6947e-02 (7.3330e-02) 
2023-05-26 01:09:04.202659: train Epoch: [63][ 80/129]	Time  2.729 ( 2.050)	Data  1.780 ( 1.076)	Loss 6.0355e-02 (7.3170e-02) 
2023-05-26 01:09:05.151777: train Epoch: [63][ 81/129]	Time  0.949 ( 2.036)	Data  0.001 ( 1.063)	Loss 8.7982e-02 (7.3351e-02) 
2023-05-26 01:09:07.915328: train Epoch: [63][ 82/129]	Time  2.764 ( 2.045)	Data  1.816 ( 1.072)	Loss 5.9157e-02 (7.3180e-02) 
2023-05-26 01:09:08.864566: train Epoch: [63][ 83/129]	Time  0.949 ( 2.032)	Data  0.001 ( 1.059)	Loss 8.5833e-02 (7.3330e-02) 
2023-05-26 01:09:11.626052: train Epoch: [63][ 84/129]	Time  2.761 ( 2.040)	Data  1.813 ( 1.068)	Loss 7.9290e-02 (7.3400e-02) 
2023-05-26 01:09:12.575832: train Epoch: [63][ 85/129]	Time  0.950 ( 2.028)	Data  0.001 ( 1.055)	Loss 1.0168e-01 (7.3729e-02) 
2023-05-26 01:09:15.307497: train Epoch: [63][ 86/129]	Time  2.732 ( 2.036)	Data  1.781 ( 1.064)	Loss 1.0521e-01 (7.4091e-02) 
2023-05-26 01:09:16.258921: train Epoch: [63][ 87/129]	Time  0.951 ( 2.024)	Data  0.001 ( 1.052)	Loss 7.5599e-02 (7.4108e-02) 
2023-05-26 01:09:18.997324: train Epoch: [63][ 88/129]	Time  2.738 ( 2.032)	Data  1.770 ( 1.060)	Loss 4.8919e-02 (7.3825e-02) 
2023-05-26 01:09:19.960188: train Epoch: [63][ 89/129]	Time  0.963 ( 2.020)	Data  0.001 ( 1.048)	Loss 8.4288e-02 (7.3941e-02) 
2023-05-26 01:09:22.998294: train Epoch: [63][ 90/129]	Time  3.038 ( 2.031)	Data  2.050 ( 1.059)	Loss 5.8373e-02 (7.3770e-02) 
2023-05-26 01:09:23.969777: train Epoch: [63][ 91/129]	Time  0.971 ( 2.019)	Data  0.001 ( 1.047)	Loss 8.6198e-02 (7.3905e-02) 
2023-05-26 01:09:27.054436: train Epoch: [63][ 92/129]	Time  3.085 ( 2.031)	Data  2.108 ( 1.059)	Loss 5.6904e-02 (7.3723e-02) 
2023-05-26 01:09:28.043625: train Epoch: [63][ 93/129]	Time  0.989 ( 2.020)	Data  0.001 ( 1.048)	Loss 6.8487e-02 (7.3667e-02) 
2023-05-26 01:09:31.117046: train Epoch: [63][ 94/129]	Time  3.073 ( 2.031)	Data  2.099 ( 1.059)	Loss 6.1939e-02 (7.3543e-02) 
2023-05-26 01:09:32.085757: train Epoch: [63][ 95/129]	Time  0.969 ( 2.020)	Data  0.001 ( 1.048)	Loss 6.9148e-02 (7.3498e-02) 
2023-05-26 01:09:35.200859: train Epoch: [63][ 96/129]	Time  3.115 ( 2.031)	Data  2.129 ( 1.059)	Loss 6.9706e-02 (7.3459e-02) 
2023-05-26 01:09:36.182570: train Epoch: [63][ 97/129]	Time  0.982 ( 2.020)	Data  0.001 ( 1.048)	Loss 1.1791e-01 (7.3912e-02) 
2023-05-26 01:09:39.269195: train Epoch: [63][ 98/129]	Time  3.087 ( 2.031)	Data  2.096 ( 1.059)	Loss 5.6474e-02 (7.3736e-02) 
2023-05-26 01:09:40.257859: train Epoch: [63][ 99/129]	Time  0.989 ( 2.021)	Data  0.002 ( 1.048)	Loss 9.2389e-02 (7.3923e-02) 
2023-05-26 01:09:43.414099: train Epoch: [63][100/129]	Time  3.156 ( 2.032)	Data  2.185 ( 1.059)	Loss 5.6276e-02 (7.3748e-02) 
2023-05-26 01:09:44.386252: train Epoch: [63][101/129]	Time  0.972 ( 2.022)	Data  0.001 ( 1.049)	Loss 6.4723e-02 (7.3659e-02) 
2023-05-26 01:09:47.509839: train Epoch: [63][102/129]	Time  3.124 ( 2.032)	Data  2.141 ( 1.059)	Loss 1.1932e-01 (7.4103e-02) 
2023-05-26 01:09:48.488672: train Epoch: [63][103/129]	Time  0.979 ( 2.022)	Data  0.002 ( 1.049)	Loss 3.9606e-02 (7.3771e-02) 
2023-05-26 01:09:51.508719: train Epoch: [63][104/129]	Time  3.020 ( 2.032)	Data  2.047 ( 1.059)	Loss 1.2036e-01 (7.4215e-02) 
2023-05-26 01:09:52.474410: train Epoch: [63][105/129]	Time  0.966 ( 2.022)	Data  0.001 ( 1.049)	Loss 7.0094e-02 (7.4176e-02) 
2023-05-26 01:09:55.612333: train Epoch: [63][106/129]	Time  3.138 ( 2.032)	Data  2.141 ( 1.059)	Loss 6.4374e-02 (7.4084e-02) 
2023-05-26 01:09:56.585607: train Epoch: [63][107/129]	Time  0.973 ( 2.022)	Data  0.001 ( 1.049)	Loss 1.0995e-01 (7.4416e-02) 
2023-05-26 01:09:59.648451: train Epoch: [63][108/129]	Time  3.063 ( 2.032)	Data  2.083 ( 1.059)	Loss 5.4935e-02 (7.4238e-02) 
2023-05-26 01:10:00.639501: train Epoch: [63][109/129]	Time  0.991 ( 2.022)	Data  0.002 ( 1.049)	Loss 5.1557e-02 (7.4031e-02) 
2023-05-26 01:10:03.710209: train Epoch: [63][110/129]	Time  3.071 ( 2.032)	Data  2.100 ( 1.059)	Loss 4.2549e-02 (7.3748e-02) 
2023-05-26 01:10:04.674043: train Epoch: [63][111/129]	Time  0.964 ( 2.022)	Data  0.001 ( 1.049)	Loss 7.3641e-02 (7.3747e-02) 
2023-05-26 01:10:07.673391: train Epoch: [63][112/129]	Time  2.999 ( 2.031)	Data  2.019 ( 1.058)	Loss 8.9237e-02 (7.3884e-02) 
2023-05-26 01:10:08.651273: train Epoch: [63][113/129]	Time  0.978 ( 2.022)	Data  0.001 ( 1.048)	Loss 5.9311e-02 (7.3756e-02) 
2023-05-26 01:10:11.927369: train Epoch: [63][114/129]	Time  3.276 ( 2.033)	Data  2.301 ( 1.059)	Loss 9.0715e-02 (7.3903e-02) 
2023-05-26 01:10:12.905991: train Epoch: [63][115/129]	Time  0.979 ( 2.023)	Data  0.001 ( 1.050)	Loss 6.8183e-02 (7.3854e-02) 
2023-05-26 01:10:16.089629: train Epoch: [63][116/129]	Time  3.184 ( 2.033)	Data  2.201 ( 1.060)	Loss 4.3933e-02 (7.3598e-02) 
2023-05-26 01:10:17.080645: train Epoch: [63][117/129]	Time  0.991 ( 2.025)	Data  0.001 ( 1.051)	Loss 8.2155e-02 (7.3671e-02) 
2023-05-26 01:10:20.129968: train Epoch: [63][118/129]	Time  3.049 ( 2.033)	Data  2.084 ( 1.060)	Loss 4.6625e-02 (7.3444e-02) 
2023-05-26 01:10:21.100370: train Epoch: [63][119/129]	Time  0.970 ( 2.024)	Data  0.001 ( 1.051)	Loss 9.2359e-02 (7.3601e-02) 
2023-05-26 01:10:24.125123: train Epoch: [63][120/129]	Time  3.025 ( 2.033)	Data  2.038 ( 1.059)	Loss 8.7535e-02 (7.3716e-02) 
2023-05-26 01:10:25.113599: train Epoch: [63][121/129]	Time  0.989 ( 2.024)	Data  0.001 ( 1.050)	Loss 4.9901e-02 (7.3521e-02) 
2023-05-26 01:10:28.162609: train Epoch: [63][122/129]	Time  3.049 ( 2.032)	Data  2.074 ( 1.059)	Loss 1.2570e-01 (7.3945e-02) 
2023-05-26 01:10:29.131386: train Epoch: [63][123/129]	Time  0.969 ( 2.024)	Data  0.002 ( 1.050)	Loss 3.8628e-02 (7.3661e-02) 
2023-05-26 01:10:32.205147: train Epoch: [63][124/129]	Time  3.074 ( 2.032)	Data  2.090 ( 1.059)	Loss 7.5110e-02 (7.3672e-02) 
2023-05-26 01:10:33.177844: train Epoch: [63][125/129]	Time  0.973 ( 2.024)	Data  0.001 ( 1.050)	Loss 6.5780e-02 (7.3610e-02) 
2023-05-26 01:10:36.228732: train Epoch: [63][126/129]	Time  3.051 ( 2.032)	Data  2.082 ( 1.058)	Loss 1.3748e-01 (7.4112e-02) 
2023-05-26 01:10:37.194589: train Epoch: [63][127/129]	Time  0.966 ( 2.023)	Data  0.001 ( 1.050)	Loss 1.6557e-01 (7.4827e-02) 
2023-05-26 01:10:39.108477: train Epoch: [63][128/129]	Time  1.914 ( 2.023)	Data  0.942 ( 1.049)	Loss 4.6031e-02 (7.4604e-02) 
2023-05-26 01:10:39.179102: Train Epoch done in 260.9916180529981 s 
2023-05-26 01:10:42.024389: val Epoch: [63][ 0/72]	Time  1.866 ( 1.866)	Data  1.632 ( 1.632)	Loss 4.5129e-02 (4.5129e-02) 
2023-05-26 01:10:42.159424: val Epoch: [63][ 1/72]	Time  0.135 ( 1.001)	Data  0.001 ( 0.817)	Loss 1.6516e-01 (1.0514e-01) 
2023-05-26 01:10:43.346564: val Epoch: [63][ 2/72]	Time  1.187 ( 1.063)	Data  1.062 ( 0.898)	Loss 1.2577e-01 (1.1202e-01) 
2023-05-26 01:10:43.490660: val Epoch: [63][ 3/72]	Time  0.144 ( 0.833)	Data  0.001 ( 0.674)	Loss 8.5491e-02 (1.0539e-01) 
2023-05-26 01:10:44.733334: val Epoch: [63][ 4/72]	Time  1.243 ( 0.915)	Data  1.119 ( 0.763)	Loss 7.7929e-02 (9.9894e-02) 
2023-05-26 01:10:44.857975: val Epoch: [63][ 5/72]	Time  0.125 ( 0.783)	Data  0.001 ( 0.636)	Loss 5.3123e-02 (9.2099e-02) 
2023-05-26 01:10:46.171200: val Epoch: [63][ 6/72]	Time  1.313 ( 0.859)	Data  1.176 ( 0.713)	Loss 3.1142e-01 (1.2343e-01) 
2023-05-26 01:10:46.311511: val Epoch: [63][ 7/72]	Time  0.140 ( 0.769)	Data  0.001 ( 0.624)	Loss 4.2000e-01 (1.6050e-01) 
2023-05-26 01:10:47.589675: val Epoch: [63][ 8/72]	Time  1.278 ( 0.826)	Data  1.148 ( 0.682)	Loss 1.6133e-01 (1.6059e-01) 
2023-05-26 01:10:47.719933: val Epoch: [63][ 9/72]	Time  0.130 ( 0.756)	Data  0.001 ( 0.614)	Loss 5.3733e-02 (1.4991e-01) 
2023-05-26 01:10:49.011195: val Epoch: [63][10/72]	Time  1.291 ( 0.805)	Data  1.154 ( 0.663)	Loss 9.6111e-02 (1.4502e-01) 
2023-05-26 01:10:49.149788: val Epoch: [63][11/72]	Time  0.139 ( 0.749)	Data  0.001 ( 0.608)	Loss 6.9022e-02 (1.3868e-01) 
2023-05-26 01:10:50.334677: val Epoch: [63][12/72]	Time  1.185 ( 0.783)	Data  1.052 ( 0.642)	Loss 2.1942e-01 (1.4489e-01) 
2023-05-26 01:10:50.496000: val Epoch: [63][13/72]	Time  0.161 ( 0.738)	Data  0.025 ( 0.598)	Loss 7.8235e-02 (1.4013e-01) 
2023-05-26 01:10:51.729702: val Epoch: [63][14/72]	Time  1.234 ( 0.771)	Data  1.108 ( 0.632)	Loss 3.2053e-01 (1.5216e-01) 
2023-05-26 01:10:51.857262: val Epoch: [63][15/72]	Time  0.128 ( 0.731)	Data  0.001 ( 0.593)	Loss 1.1122e-01 (1.4960e-01) 
2023-05-26 01:10:53.121955: val Epoch: [63][16/72]	Time  1.265 ( 0.763)	Data  1.138 ( 0.625)	Loss 1.0852e-01 (1.4718e-01) 
2023-05-26 01:10:53.248875: val Epoch: [63][17/72]	Time  0.127 ( 0.727)	Data  0.001 ( 0.590)	Loss 4.3799e-02 (1.4144e-01) 
2023-05-26 01:10:54.458164: val Epoch: [63][18/72]	Time  1.209 ( 0.753)	Data  1.083 ( 0.616)	Loss 6.4390e-02 (1.3739e-01) 
2023-05-26 01:10:54.585513: val Epoch: [63][19/72]	Time  0.127 ( 0.721)	Data  0.001 ( 0.585)	Loss 1.0503e-01 (1.3577e-01) 
2023-05-26 01:10:55.920811: val Epoch: [63][20/72]	Time  1.335 ( 0.751)	Data  1.207 ( 0.615)	Loss 5.6475e-02 (1.3199e-01) 
2023-05-26 01:10:56.049726: val Epoch: [63][21/72]	Time  0.129 ( 0.722)	Data  0.001 ( 0.587)	Loss 3.0809e-01 (1.4000e-01) 
2023-05-26 01:10:57.311018: val Epoch: [63][22/72]	Time  1.261 ( 0.746)	Data  1.126 ( 0.610)	Loss 5.3613e-02 (1.3624e-01) 
2023-05-26 01:10:57.441168: val Epoch: [63][23/72]	Time  0.130 ( 0.720)	Data  0.001 ( 0.585)	Loss 5.0198e-02 (1.3266e-01) 
2023-05-26 01:10:58.728997: val Epoch: [63][24/72]	Time  1.288 ( 0.743)	Data  1.158 ( 0.608)	Loss 6.9710e-02 (1.3014e-01) 
2023-05-26 01:10:58.856325: val Epoch: [63][25/72]	Time  0.127 ( 0.719)	Data  0.001 ( 0.584)	Loss 5.1136e-02 (1.2710e-01) 
2023-05-26 01:11:00.097165: val Epoch: [63][26/72]	Time  1.241 ( 0.738)	Data  1.114 ( 0.604)	Loss 4.8506e-02 (1.2419e-01) 
2023-05-26 01:11:00.241472: val Epoch: [63][27/72]	Time  0.144 ( 0.717)	Data  0.001 ( 0.583)	Loss 1.0663e-01 (1.2356e-01) 
2023-05-26 01:11:01.543734: val Epoch: [63][28/72]	Time  1.302 ( 0.737)	Data  1.174 ( 0.603)	Loss 3.2349e-01 (1.3046e-01) 
2023-05-26 01:11:01.680214: val Epoch: [63][29/72]	Time  0.136 ( 0.717)	Data  0.001 ( 0.583)	Loss 3.9902e-02 (1.2744e-01) 
2023-05-26 01:11:02.944130: val Epoch: [63][30/72]	Time  1.264 ( 0.735)	Data  1.135 ( 0.601)	Loss 7.0806e-02 (1.2561e-01) 
2023-05-26 01:11:03.074622: val Epoch: [63][31/72]	Time  0.131 ( 0.716)	Data  0.001 ( 0.582)	Loss 4.3421e-02 (1.2304e-01) 
2023-05-26 01:11:04.378445: val Epoch: [63][32/72]	Time  1.304 ( 0.734)	Data  1.168 ( 0.600)	Loss 1.1524e-01 (1.2281e-01) 
2023-05-26 01:11:04.505254: val Epoch: [63][33/72]	Time  0.127 ( 0.716)	Data  0.001 ( 0.582)	Loss 6.6105e-02 (1.2114e-01) 
2023-05-26 01:11:05.822513: val Epoch: [63][34/72]	Time  1.317 ( 0.733)	Data  1.189 ( 0.599)	Loss 7.7610e-02 (1.1989e-01) 
2023-05-26 01:11:05.955349: val Epoch: [63][35/72]	Time  0.133 ( 0.717)	Data  0.001 ( 0.583)	Loss 6.0582e-02 (1.1825e-01) 
2023-05-26 01:11:07.192259: val Epoch: [63][36/72]	Time  1.237 ( 0.731)	Data  1.109 ( 0.597)	Loss 1.1803e-01 (1.1824e-01) 
2023-05-26 01:11:07.319911: val Epoch: [63][37/72]	Time  0.128 ( 0.715)	Data  0.001 ( 0.581)	Loss 2.8451e-01 (1.2262e-01) 
2023-05-26 01:11:08.569293: val Epoch: [63][38/72]	Time  1.249 ( 0.728)	Data  1.114 ( 0.595)	Loss 5.5759e-02 (1.2090e-01) 
2023-05-26 01:11:08.705296: val Epoch: [63][39/72]	Time  0.136 ( 0.714)	Data  0.001 ( 0.580)	Loss 1.7744e-01 (1.2232e-01) 
2023-05-26 01:11:09.972454: val Epoch: [63][40/72]	Time  1.267 ( 0.727)	Data  1.141 ( 0.594)	Loss 9.9673e-02 (1.2176e-01) 
2023-05-26 01:11:10.099953: val Epoch: [63][41/72]	Time  0.127 ( 0.713)	Data  0.001 ( 0.580)	Loss 1.9096e-01 (1.2341e-01) 
2023-05-26 01:11:11.374931: val Epoch: [63][42/72]	Time  1.275 ( 0.726)	Data  1.149 ( 0.593)	Loss 5.1588e-02 (1.2174e-01) 
2023-05-26 01:11:11.501805: val Epoch: [63][43/72]	Time  0.127 ( 0.712)	Data  0.001 ( 0.579)	Loss 1.2980e-01 (1.2192e-01) 
2023-05-26 01:11:12.774875: val Epoch: [63][44/72]	Time  1.273 ( 0.725)	Data  1.141 ( 0.592)	Loss 6.9370e-02 (1.2076e-01) 
2023-05-26 01:11:12.915130: val Epoch: [63][45/72]	Time  0.140 ( 0.712)	Data  0.001 ( 0.579)	Loss 6.2458e-02 (1.1949e-01) 
2023-05-26 01:11:14.174673: val Epoch: [63][46/72]	Time  1.260 ( 0.724)	Data  1.133 ( 0.591)	Loss 3.7451e-01 (1.2491e-01) 
2023-05-26 01:11:14.305947: val Epoch: [63][47/72]	Time  0.131 ( 0.711)	Data  0.001 ( 0.579)	Loss 7.2488e-02 (1.2382e-01) 
2023-05-26 01:11:15.539279: val Epoch: [63][48/72]	Time  1.233 ( 0.722)	Data  1.094 ( 0.589)	Loss 2.0382e-01 (1.2545e-01) 
2023-05-26 01:11:15.669110: val Epoch: [63][49/72]	Time  0.130 ( 0.710)	Data  0.001 ( 0.577)	Loss 1.4579e-01 (1.2586e-01) 
2023-05-26 01:11:16.948700: val Epoch: [63][50/72]	Time  1.280 ( 0.721)	Data  1.152 ( 0.589)	Loss 2.5660e-01 (1.2842e-01) 
2023-05-26 01:11:17.081208: val Epoch: [63][51/72]	Time  0.133 ( 0.710)	Data  0.001 ( 0.577)	Loss 3.8565e-02 (1.2670e-01) 
2023-05-26 01:11:18.424114: val Epoch: [63][52/72]	Time  1.343 ( 0.722)	Data  1.190 ( 0.589)	Loss 1.2666e-01 (1.2670e-01) 
2023-05-26 01:11:18.560038: val Epoch: [63][53/72]	Time  0.136 ( 0.711)	Data  0.001 ( 0.578)	Loss 1.3016e-01 (1.2676e-01) 
2023-05-26 01:11:19.799818: val Epoch: [63][54/72]	Time  1.240 ( 0.721)	Data  1.112 ( 0.588)	Loss 1.4938e-01 (1.2717e-01) 
2023-05-26 01:11:19.938622: val Epoch: [63][55/72]	Time  0.139 ( 0.710)	Data  0.001 ( 0.577)	Loss 6.1494e-01 (1.3588e-01) 
2023-05-26 01:11:21.171320: val Epoch: [63][56/72]	Time  1.233 ( 0.720)	Data  1.109 ( 0.587)	Loss 6.9668e-02 (1.3472e-01) 
2023-05-26 01:11:21.305768: val Epoch: [63][57/72]	Time  0.134 ( 0.709)	Data  0.001 ( 0.576)	Loss 6.2016e-02 (1.3347e-01) 
2023-05-26 01:11:22.553629: val Epoch: [63][58/72]	Time  1.248 ( 0.719)	Data  1.121 ( 0.586)	Loss 4.7346e-02 (1.3201e-01) 
2023-05-26 01:11:22.683944: val Epoch: [63][59/72]	Time  0.130 ( 0.709)	Data  0.001 ( 0.576)	Loss 4.8675e-02 (1.3062e-01) 
2023-05-26 01:11:23.954887: val Epoch: [63][60/72]	Time  1.271 ( 0.718)	Data  1.143 ( 0.585)	Loss 1.6045e-01 (1.3111e-01) 
2023-05-26 01:11:24.083528: val Epoch: [63][61/72]	Time  0.129 ( 0.708)	Data  0.001 ( 0.576)	Loss 3.6739e-01 (1.3492e-01) 
2023-05-26 01:11:25.389029: val Epoch: [63][62/72]	Time  1.305 ( 0.718)	Data  1.174 ( 0.585)	Loss 3.2676e-01 (1.3796e-01) 
2023-05-26 01:11:25.532300: val Epoch: [63][63/72]	Time  0.143 ( 0.709)	Data  0.001 ( 0.576)	Loss 6.6470e-02 (1.3685e-01) 
2023-05-26 01:11:26.780587: val Epoch: [63][64/72]	Time  1.248 ( 0.717)	Data  1.122 ( 0.585)	Loss 9.2494e-02 (1.3616e-01) 
2023-05-26 01:11:26.908234: val Epoch: [63][65/72]	Time  0.128 ( 0.708)	Data  0.001 ( 0.576)	Loss 3.2118e-02 (1.3459e-01) 
2023-05-26 01:11:28.091932: val Epoch: [63][66/72]	Time  1.184 ( 0.715)	Data  1.056 ( 0.583)	Loss 3.8860e-02 (1.3316e-01) 
2023-05-26 01:11:28.219392: val Epoch: [63][67/72]	Time  0.127 ( 0.707)	Data  0.001 ( 0.574)	Loss 3.2810e-02 (1.3168e-01) 
2023-05-26 01:11:29.445980: val Epoch: [63][68/72]	Time  1.227 ( 0.714)	Data  1.100 ( 0.582)	Loss 4.0751e-02 (1.3036e-01) 
2023-05-26 01:11:29.585453: val Epoch: [63][69/72]	Time  0.139 ( 0.706)	Data  0.001 ( 0.574)	Loss 4.6643e-02 (1.2917e-01) 
2023-05-26 01:11:30.743166: val Epoch: [63][70/72]	Time  1.158 ( 0.712)	Data  1.026 ( 0.580)	Loss 4.8151e-02 (1.2803e-01) 
2023-05-26 01:11:30.881687: val Epoch: [63][71/72]	Time  0.139 ( 0.704)	Data  0.001 ( 0.572)	Loss 6.5734e-02 (1.2716e-01) 
2023-05-26 01:11:31.094925: Epoch 63 :Val : ['ET : 0.726628839969635', 'TC : 0.7961083650588989', 'WT : 0.8708169460296631'] 
2023-05-26 01:11:31.100823: Epoch 63 :Val : ['ET : 0.726628839969635', 'TC : 0.7961083650588989', 'WT : 0.8708169460296631'] 
2023-05-26 01:11:31.103320: Val epoch done in 51.92422433300089 s 
2023-05-26 01:11:31.109099: Batches per epoch:  129 
2023-05-26 01:11:36.475984: train Epoch: [64][  0/129]	Time  5.366 ( 5.366)	Data  4.310 ( 4.310)	Loss 4.9365e-02 (4.9365e-02) 
2023-05-26 01:11:37.452798: train Epoch: [64][  1/129]	Time  0.977 ( 3.172)	Data  0.001 ( 2.155)	Loss 1.2323e-01 (8.6295e-02) 
2023-05-26 01:11:40.613402: train Epoch: [64][  2/129]	Time  3.161 ( 3.168)	Data  2.191 ( 2.167)	Loss 7.2769e-02 (8.1787e-02) 
2023-05-26 01:11:41.586714: train Epoch: [64][  3/129]	Time  0.973 ( 2.619)	Data  0.001 ( 1.626)	Loss 7.8634e-02 (8.0998e-02) 
2023-05-26 01:11:44.628191: train Epoch: [64][  4/129]	Time  3.041 ( 2.704)	Data  2.061 ( 1.713)	Loss 9.6412e-02 (8.4081e-02) 
2023-05-26 01:11:45.600703: train Epoch: [64][  5/129]	Time  0.972 ( 2.415)	Data  0.001 ( 1.427)	Loss 6.2376e-02 (8.0464e-02) 
2023-05-26 01:11:48.717699: train Epoch: [64][  6/129]	Time  3.117 ( 2.515)	Data  2.134 ( 1.528)	Loss 7.5681e-02 (7.9780e-02) 
2023-05-26 01:11:49.691197: train Epoch: [64][  7/129]	Time  0.974 ( 2.323)	Data  0.001 ( 1.338)	Loss 6.6035e-02 (7.8062e-02) 
2023-05-26 01:11:52.783561: train Epoch: [64][  8/129]	Time  3.092 ( 2.408)	Data  2.103 ( 1.423)	Loss 9.4708e-02 (7.9912e-02) 
2023-05-26 01:11:53.758427: train Epoch: [64][  9/129]	Time  0.975 ( 2.265)	Data  0.002 ( 1.281)	Loss 4.6114e-02 (7.6532e-02) 
2023-05-26 01:11:56.649915: train Epoch: [64][ 10/129]	Time  2.892 ( 2.322)	Data  1.929 ( 1.339)	Loss 7.4831e-02 (7.6377e-02) 
2023-05-26 01:11:57.636481: train Epoch: [64][ 11/129]	Time  0.987 ( 2.211)	Data  0.003 ( 1.228)	Loss 8.8188e-02 (7.7361e-02) 
2023-05-26 01:12:00.755737: train Epoch: [64][ 12/129]	Time  3.119 ( 2.280)	Data  2.136 ( 1.298)	Loss 6.8788e-02 (7.6702e-02) 
2023-05-26 01:12:01.731743: train Epoch: [64][ 13/129]	Time  0.976 ( 2.187)	Data  0.001 ( 1.205)	Loss 6.1480e-02 (7.5615e-02) 
2023-05-26 01:12:04.871176: train Epoch: [64][ 14/129]	Time  3.139 ( 2.251)	Data  2.173 ( 1.270)	Loss 8.3656e-02 (7.6151e-02) 
2023-05-26 01:12:05.838124: train Epoch: [64][ 15/129]	Time  0.967 ( 2.171)	Data  0.001 ( 1.191)	Loss 5.0789e-02 (7.4566e-02) 
2023-05-26 01:12:09.057682: train Epoch: [64][ 16/129]	Time  3.220 ( 2.232)	Data  2.249 ( 1.253)	Loss 6.9066e-02 (7.4242e-02) 
2023-05-26 01:12:10.031050: train Epoch: [64][ 17/129]	Time  0.973 ( 2.162)	Data  0.001 ( 1.183)	Loss 7.8720e-02 (7.4491e-02) 
2023-05-26 01:12:13.179416: train Epoch: [64][ 18/129]	Time  3.148 ( 2.214)	Data  2.180 ( 1.236)	Loss 7.5658e-02 (7.4552e-02) 
2023-05-26 01:12:14.162619: train Epoch: [64][ 19/129]	Time  0.983 ( 2.153)	Data  0.002 ( 1.174)	Loss 7.8238e-02 (7.4737e-02) 
2023-05-26 01:12:17.213630: train Epoch: [64][ 20/129]	Time  3.051 ( 2.195)	Data  2.054 ( 1.216)	Loss 1.0389e-01 (7.6125e-02) 
2023-05-26 01:12:18.197674: train Epoch: [64][ 21/129]	Time  0.984 ( 2.140)	Data  0.001 ( 1.161)	Loss 6.3600e-02 (7.5556e-02) 
2023-05-26 01:12:21.262075: train Epoch: [64][ 22/129]	Time  3.064 ( 2.181)	Data  2.096 ( 1.201)	Loss 6.3607e-02 (7.5036e-02) 
2023-05-26 01:12:22.236351: train Epoch: [64][ 23/129]	Time  0.974 ( 2.130)	Data  0.001 ( 1.151)	Loss 5.6334e-02 (7.4257e-02) 
2023-05-26 01:12:25.402327: train Epoch: [64][ 24/129]	Time  3.166 ( 2.172)	Data  2.177 ( 1.192)	Loss 8.4546e-02 (7.4668e-02) 
2023-05-26 01:12:26.374327: train Epoch: [64][ 25/129]	Time  0.972 ( 2.126)	Data  0.001 ( 1.147)	Loss 8.2302e-02 (7.4962e-02) 
2023-05-26 01:12:29.352326: train Epoch: [64][ 26/129]	Time  2.978 ( 2.157)	Data  2.012 ( 1.179)	Loss 4.2636e-02 (7.3765e-02) 
2023-05-26 01:12:30.329866: train Epoch: [64][ 27/129]	Time  0.978 ( 2.115)	Data  0.001 ( 1.137)	Loss 4.8727e-02 (7.2870e-02) 
2023-05-26 01:12:33.379627: train Epoch: [64][ 28/129]	Time  3.050 ( 2.147)	Data  2.088 ( 1.169)	Loss 4.9293e-02 (7.2057e-02) 
2023-05-26 01:12:34.363723: train Epoch: [64][ 29/129]	Time  0.984 ( 2.108)	Data  0.001 ( 1.130)	Loss 1.1063e-01 (7.3343e-02) 
2023-05-26 01:12:37.451019: train Epoch: [64][ 30/129]	Time  3.087 ( 2.140)	Data  2.108 ( 1.162)	Loss 7.6634e-02 (7.3449e-02) 
2023-05-26 01:12:38.427917: train Epoch: [64][ 31/129]	Time  0.977 ( 2.104)	Data  0.002 ( 1.126)	Loss 1.7180e-01 (7.6523e-02) 
2023-05-26 01:12:41.437321: train Epoch: [64][ 32/129]	Time  3.009 ( 2.131)	Data  2.023 ( 1.153)	Loss 6.5546e-02 (7.6190e-02) 
2023-05-26 01:12:42.421085: train Epoch: [64][ 33/129]	Time  0.984 ( 2.097)	Data  0.002 ( 1.119)	Loss 8.7851e-02 (7.6533e-02) 
2023-05-26 01:12:45.505029: train Epoch: [64][ 34/129]	Time  3.084 ( 2.126)	Data  2.100 ( 1.147)	Loss 5.2629e-02 (7.5850e-02) 
2023-05-26 01:12:46.497131: train Epoch: [64][ 35/129]	Time  0.992 ( 2.094)	Data  0.001 ( 1.115)	Loss 5.7974e-02 (7.5354e-02) 
2023-05-26 01:12:49.653692: train Epoch: [64][ 36/129]	Time  3.157 ( 2.123)	Data  2.171 ( 1.144)	Loss 9.0968e-02 (7.5776e-02) 
2023-05-26 01:12:50.631895: train Epoch: [64][ 37/129]	Time  0.978 ( 2.093)	Data  0.001 ( 1.114)	Loss 1.0043e-01 (7.6424e-02) 
2023-05-26 01:12:53.598544: train Epoch: [64][ 38/129]	Time  2.967 ( 2.115)	Data  2.015 ( 1.137)	Loss 8.7966e-02 (7.6720e-02) 
2023-05-26 01:12:54.564345: train Epoch: [64][ 39/129]	Time  0.966 ( 2.086)	Data  0.001 ( 1.108)	Loss 8.6273e-02 (7.6959e-02) 
2023-05-26 01:12:57.692384: train Epoch: [64][ 40/129]	Time  3.128 ( 2.112)	Data  2.164 ( 1.134)	Loss 8.1128e-02 (7.7061e-02) 
2023-05-26 01:12:58.664636: train Epoch: [64][ 41/129]	Time  0.972 ( 2.085)	Data  0.001 ( 1.107)	Loss 8.3625e-02 (7.7217e-02) 
2023-05-26 01:13:01.788878: train Epoch: [64][ 42/129]	Time  3.124 ( 2.109)	Data  2.160 ( 1.132)	Loss 5.7292e-02 (7.6754e-02) 
2023-05-26 01:13:02.774805: train Epoch: [64][ 43/129]	Time  0.986 ( 2.083)	Data  0.001 ( 1.106)	Loss 1.0314e-01 (7.7354e-02) 
2023-05-26 01:13:05.848412: train Epoch: [64][ 44/129]	Time  3.074 ( 2.105)	Data  2.113 ( 1.128)	Loss 9.2105e-02 (7.7681e-02) 
2023-05-26 01:13:06.833461: train Epoch: [64][ 45/129]	Time  0.985 ( 2.081)	Data  0.001 ( 1.104)	Loss 5.6639e-02 (7.7224e-02) 
2023-05-26 01:13:10.077827: train Epoch: [64][ 46/129]	Time  3.244 ( 2.106)	Data  2.258 ( 1.128)	Loss 7.6679e-02 (7.7212e-02) 
2023-05-26 01:13:11.053054: train Epoch: [64][ 47/129]	Time  0.975 ( 2.082)	Data  0.001 ( 1.105)	Loss 9.5174e-02 (7.7587e-02) 
2023-05-26 01:13:14.068959: train Epoch: [64][ 48/129]	Time  3.016 ( 2.101)	Data  2.014 ( 1.123)	Loss 1.1628e-01 (7.8376e-02) 
2023-05-26 01:13:15.033988: train Epoch: [64][ 49/129]	Time  0.965 ( 2.078)	Data  0.001 ( 1.101)	Loss 8.6489e-02 (7.8539e-02) 
2023-05-26 01:13:18.055983: train Epoch: [64][ 50/129]	Time  3.022 ( 2.097)	Data  2.057 ( 1.120)	Loss 9.2426e-02 (7.8811e-02) 
2023-05-26 01:13:19.029254: train Epoch: [64][ 51/129]	Time  0.973 ( 2.075)	Data  0.001 ( 1.098)	Loss 8.8554e-02 (7.8998e-02) 
2023-05-26 01:13:22.062303: train Epoch: [64][ 52/129]	Time  3.033 ( 2.093)	Data  2.066 ( 1.117)	Loss 6.8853e-02 (7.8807e-02) 
2023-05-26 01:13:23.043413: train Epoch: [64][ 53/129]	Time  0.981 ( 2.073)	Data  0.001 ( 1.096)	Loss 8.9892e-02 (7.9012e-02) 
2023-05-26 01:13:26.160253: train Epoch: [64][ 54/129]	Time  3.117 ( 2.092)	Data  2.153 ( 1.115)	Loss 6.7540e-02 (7.8804e-02) 
2023-05-26 01:13:27.126643: train Epoch: [64][ 55/129]	Time  0.966 ( 2.072)	Data  0.001 ( 1.095)	Loss 5.2313e-02 (7.8330e-02) 
2023-05-26 01:13:30.190802: train Epoch: [64][ 56/129]	Time  3.064 ( 2.089)	Data  2.099 ( 1.113)	Loss 4.9414e-02 (7.7823e-02) 
2023-05-26 01:13:31.159175: train Epoch: [64][ 57/129]	Time  0.968 ( 2.070)	Data  0.001 ( 1.094)	Loss 5.8492e-02 (7.7490e-02) 
2023-05-26 01:13:34.168771: train Epoch: [64][ 58/129]	Time  3.010 ( 2.086)	Data  2.047 ( 1.110)	Loss 6.3601e-02 (7.7254e-02) 
2023-05-26 01:13:35.134826: train Epoch: [64][ 59/129]	Time  0.966 ( 2.067)	Data  0.001 ( 1.091)	Loss 6.3260e-02 (7.7021e-02) 
2023-05-26 01:13:38.195062: train Epoch: [64][ 60/129]	Time  3.060 ( 2.083)	Data  2.094 ( 1.108)	Loss 1.2065e-01 (7.7736e-02) 
2023-05-26 01:13:39.166296: train Epoch: [64][ 61/129]	Time  0.971 ( 2.065)	Data  0.001 ( 1.090)	Loss 6.3884e-02 (7.7513e-02) 
2023-05-26 01:13:42.221816: train Epoch: [64][ 62/129]	Time  3.056 ( 2.081)	Data  2.095 ( 1.106)	Loss 6.9204e-02 (7.7381e-02) 
2023-05-26 01:13:43.184273: train Epoch: [64][ 63/129]	Time  0.962 ( 2.064)	Data  0.001 ( 1.089)	Loss 8.6490e-02 (7.7523e-02) 
2023-05-26 01:13:46.230106: train Epoch: [64][ 64/129]	Time  3.046 ( 2.079)	Data  2.070 ( 1.104)	Loss 6.7196e-02 (7.7365e-02) 
2023-05-26 01:13:47.209651: train Epoch: [64][ 65/129]	Time  0.980 ( 2.062)	Data  0.001 ( 1.087)	Loss 1.1906e-01 (7.7996e-02) 
2023-05-26 01:13:50.312966: train Epoch: [64][ 66/129]	Time  3.103 ( 2.078)	Data  2.133 ( 1.103)	Loss 8.4905e-02 (7.8099e-02) 
2023-05-26 01:13:51.286909: train Epoch: [64][ 67/129]	Time  0.974 ( 2.061)	Data  0.001 ( 1.086)	Loss 7.1066e-02 (7.7996e-02) 
2023-05-26 01:13:54.265317: train Epoch: [64][ 68/129]	Time  2.978 ( 2.075)	Data  2.007 ( 1.100)	Loss 4.3931e-02 (7.7502e-02) 
2023-05-26 01:13:55.221988: train Epoch: [64][ 69/129]	Time  0.957 ( 2.059)	Data  0.001 ( 1.084)	Loss 5.0344e-02 (7.7114e-02) 
2023-05-26 01:13:58.271732: train Epoch: [64][ 70/129]	Time  3.050 ( 2.073)	Data  2.067 ( 1.098)	Loss 7.0824e-02 (7.7026e-02) 
2023-05-26 01:13:59.240952: train Epoch: [64][ 71/129]	Time  0.969 ( 2.057)	Data  0.001 ( 1.083)	Loss 7.8915e-02 (7.7052e-02) 
2023-05-26 01:14:02.425290: train Epoch: [64][ 72/129]	Time  3.184 ( 2.073)	Data  2.205 ( 1.098)	Loss 6.3874e-02 (7.6871e-02) 
2023-05-26 01:14:03.393019: train Epoch: [64][ 73/129]	Time  0.968 ( 2.058)	Data  0.001 ( 1.083)	Loss 5.1263e-02 (7.6525e-02) 
2023-05-26 01:14:06.334481: train Epoch: [64][ 74/129]	Time  2.941 ( 2.070)	Data  1.975 ( 1.095)	Loss 6.4296e-02 (7.6362e-02) 
2023-05-26 01:14:07.302699: train Epoch: [64][ 75/129]	Time  0.968 ( 2.055)	Data  0.001 ( 1.081)	Loss 6.6259e-02 (7.6229e-02) 
2023-05-26 01:14:10.310286: train Epoch: [64][ 76/129]	Time  3.008 ( 2.068)	Data  2.038 ( 1.093)	Loss 8.5248e-02 (7.6347e-02) 
2023-05-26 01:14:11.282464: train Epoch: [64][ 77/129]	Time  0.972 ( 2.053)	Data  0.001 ( 1.079)	Loss 6.4757e-02 (7.6198e-02) 
2023-05-26 01:14:14.306163: train Epoch: [64][ 78/129]	Time  3.024 ( 2.066)	Data  2.053 ( 1.091)	Loss 6.0211e-02 (7.5996e-02) 
2023-05-26 01:14:15.286922: train Epoch: [64][ 79/129]	Time  0.981 ( 2.052)	Data  0.001 ( 1.078)	Loss 6.4823e-02 (7.5856e-02) 
2023-05-26 01:14:18.284970: train Epoch: [64][ 80/129]	Time  2.998 ( 2.064)	Data  2.040 ( 1.090)	Loss 8.6209e-02 (7.5984e-02) 
2023-05-26 01:14:19.256858: train Epoch: [64][ 81/129]	Time  0.972 ( 2.051)	Data  0.001 ( 1.076)	Loss 5.0848e-02 (7.5677e-02) 
2023-05-26 01:14:22.509702: train Epoch: [64][ 82/129]	Time  3.253 ( 2.065)	Data  2.286 ( 1.091)	Loss 6.4544e-02 (7.5543e-02) 
2023-05-26 01:14:23.478738: train Epoch: [64][ 83/129]	Time  0.969 ( 2.052)	Data  0.001 ( 1.078)	Loss 5.8639e-02 (7.5342e-02) 
2023-05-26 01:14:26.602924: train Epoch: [64][ 84/129]	Time  3.124 ( 2.065)	Data  2.158 ( 1.091)	Loss 6.0350e-02 (7.5165e-02) 
2023-05-26 01:14:27.580179: train Epoch: [64][ 85/129]	Time  0.977 ( 2.052)	Data  0.001 ( 1.078)	Loss 6.0820e-02 (7.4999e-02) 
2023-05-26 01:14:30.636992: train Epoch: [64][ 86/129]	Time  3.057 ( 2.064)	Data  2.078 ( 1.090)	Loss 1.2124e-01 (7.5530e-02) 
2023-05-26 01:14:31.625424: train Epoch: [64][ 87/129]	Time  0.988 ( 2.051)	Data  0.002 ( 1.077)	Loss 1.2365e-01 (7.6077e-02) 
2023-05-26 01:14:34.724801: train Epoch: [64][ 88/129]	Time  3.099 ( 2.063)	Data  2.115 ( 1.089)	Loss 5.7389e-02 (7.5867e-02) 
2023-05-26 01:14:35.704263: train Epoch: [64][ 89/129]	Time  0.979 ( 2.051)	Data  0.001 ( 1.077)	Loss 1.0374e-01 (7.6177e-02) 
2023-05-26 01:14:38.849470: train Epoch: [64][ 90/129]	Time  3.145 ( 2.063)	Data  2.183 ( 1.089)	Loss 1.5682e-01 (7.7063e-02) 
2023-05-26 01:14:39.816049: train Epoch: [64][ 91/129]	Time  0.967 ( 2.051)	Data  0.001 ( 1.077)	Loss 6.9181e-02 (7.6977e-02) 
2023-05-26 01:14:42.891102: train Epoch: [64][ 92/129]	Time  3.075 ( 2.062)	Data  2.109 ( 1.088)	Loss 5.8022e-02 (7.6773e-02) 
2023-05-26 01:14:43.865077: train Epoch: [64][ 93/129]	Time  0.974 ( 2.051)	Data  0.003 ( 1.077)	Loss 7.9617e-02 (7.6804e-02) 
2023-05-26 01:14:46.979577: train Epoch: [64][ 94/129]	Time  3.114 ( 2.062)	Data  2.139 ( 1.088)	Loss 7.8208e-02 (7.6818e-02) 
2023-05-26 01:14:47.962637: train Epoch: [64][ 95/129]	Time  0.983 ( 2.051)	Data  0.001 ( 1.077)	Loss 8.4158e-02 (7.6895e-02) 
2023-05-26 01:14:50.938612: train Epoch: [64][ 96/129]	Time  2.976 ( 2.060)	Data  2.011 ( 1.086)	Loss 7.0067e-02 (7.6824e-02) 
2023-05-26 01:14:51.920177: train Epoch: [64][ 97/129]	Time  0.982 ( 2.049)	Data  0.001 ( 1.075)	Loss 7.1969e-02 (7.6775e-02) 
2023-05-26 01:14:54.898082: train Epoch: [64][ 98/129]	Time  2.978 ( 2.058)	Data  2.012 ( 1.085)	Loss 6.2209e-02 (7.6628e-02) 
2023-05-26 01:14:55.867296: train Epoch: [64][ 99/129]	Time  0.969 ( 2.048)	Data  0.001 ( 1.074)	Loss 7.9841e-02 (7.6660e-02) 
2023-05-26 01:14:58.935924: train Epoch: [64][100/129]	Time  3.069 ( 2.058)	Data  2.107 ( 1.084)	Loss 9.9485e-02 (7.6886e-02) 
2023-05-26 01:14:59.906894: train Epoch: [64][101/129]	Time  0.971 ( 2.047)	Data  0.001 ( 1.073)	Loss 1.2283e-01 (7.7336e-02) 
2023-05-26 01:15:02.957634: train Epoch: [64][102/129]	Time  3.051 ( 2.057)	Data  2.079 ( 1.083)	Loss 4.5315e-02 (7.7025e-02) 
2023-05-26 01:15:03.933856: train Epoch: [64][103/129]	Time  0.976 ( 2.046)	Data  0.001 ( 1.073)	Loss 6.7070e-02 (7.6930e-02) 
2023-05-26 01:15:06.978052: train Epoch: [64][104/129]	Time  3.044 ( 2.056)	Data  2.066 ( 1.082)	Loss 7.3807e-02 (7.6900e-02) 
2023-05-26 01:15:07.966778: train Epoch: [64][105/129]	Time  0.989 ( 2.046)	Data  0.001 ( 1.072)	Loss 6.9933e-02 (7.6834e-02) 
2023-05-26 01:15:11.083743: train Epoch: [64][106/129]	Time  3.117 ( 2.056)	Data  2.154 ( 1.082)	Loss 1.1045e-01 (7.7148e-02) 
2023-05-26 01:15:12.041715: train Epoch: [64][107/129]	Time  0.958 ( 2.046)	Data  0.001 ( 1.072)	Loss 1.2631e-01 (7.7604e-02) 
2023-05-26 01:15:15.078008: train Epoch: [64][108/129]	Time  3.036 ( 2.055)	Data  2.067 ( 1.081)	Loss 7.7497e-02 (7.7603e-02) 
2023-05-26 01:15:16.046071: train Epoch: [64][109/129]	Time  0.968 ( 2.045)	Data  0.001 ( 1.071)	Loss 1.0201e-01 (7.7825e-02) 
2023-05-26 01:15:19.031373: train Epoch: [64][110/129]	Time  2.985 ( 2.053)	Data  2.017 ( 1.080)	Loss 6.0033e-02 (7.7664e-02) 
2023-05-26 01:15:20.031147: train Epoch: [64][111/129]	Time  1.000 ( 2.044)	Data  0.001 ( 1.070)	Loss 5.6459e-02 (7.7475e-02) 
2023-05-26 01:15:23.134626: train Epoch: [64][112/129]	Time  3.103 ( 2.053)	Data  2.134 ( 1.080)	Loss 1.3573e-01 (7.7990e-02) 
2023-05-26 01:15:24.118286: train Epoch: [64][113/129]	Time  0.984 ( 2.044)	Data  0.001 ( 1.070)	Loss 2.8458e-02 (7.7556e-02) 
2023-05-26 01:15:27.131622: train Epoch: [64][114/129]	Time  3.013 ( 2.052)	Data  2.050 ( 1.079)	Loss 5.9477e-02 (7.7399e-02) 
2023-05-26 01:15:28.097872: train Epoch: [64][115/129]	Time  0.966 ( 2.043)	Data  0.001 ( 1.069)	Loss 1.2373e-01 (7.7798e-02) 
2023-05-26 01:15:31.173607: train Epoch: [64][116/129]	Time  3.076 ( 2.052)	Data  2.112 ( 1.078)	Loss 7.3876e-02 (7.7765e-02) 
2023-05-26 01:15:32.142695: train Epoch: [64][117/129]	Time  0.969 ( 2.043)	Data  0.001 ( 1.069)	Loss 1.0984e-01 (7.8036e-02) 
2023-05-26 01:15:35.206301: train Epoch: [64][118/129]	Time  3.064 ( 2.051)	Data  2.096 ( 1.078)	Loss 8.6929e-02 (7.8111e-02) 
2023-05-26 01:15:36.179903: train Epoch: [64][119/129]	Time  0.974 ( 2.042)	Data  0.001 ( 1.069)	Loss 8.4827e-02 (7.8167e-02) 
2023-05-26 01:15:39.158909: train Epoch: [64][120/129]	Time  2.979 ( 2.050)	Data  2.013 ( 1.077)	Loss 9.0830e-02 (7.8272e-02) 
2023-05-26 01:15:40.129815: train Epoch: [64][121/129]	Time  0.971 ( 2.041)	Data  0.002 ( 1.068)	Loss 6.4878e-02 (7.8162e-02) 
2023-05-26 01:15:43.328871: train Epoch: [64][122/129]	Time  3.199 ( 2.051)	Data  2.234 ( 1.077)	Loss 5.8980e-02 (7.8006e-02) 
2023-05-26 01:15:44.303908: train Epoch: [64][123/129]	Time  0.975 ( 2.042)	Data  0.001 ( 1.069)	Loss 6.1323e-02 (7.7871e-02) 
2023-05-26 01:15:47.357104: train Epoch: [64][124/129]	Time  3.053 ( 2.050)	Data  2.069 ( 1.077)	Loss 1.1582e-01 (7.8175e-02) 
2023-05-26 01:15:48.344866: train Epoch: [64][125/129]	Time  0.988 ( 2.042)	Data  0.001 ( 1.068)	Loss 4.8011e-02 (7.7936e-02) 
2023-05-26 01:15:51.481435: train Epoch: [64][126/129]	Time  3.137 ( 2.050)	Data  2.162 ( 1.077)	Loss 6.7636e-02 (7.7855e-02) 
2023-05-26 01:15:52.460900: train Epoch: [64][127/129]	Time  0.979 ( 2.042)	Data  0.001 ( 1.068)	Loss 9.9713e-02 (7.8025e-02) 
2023-05-26 01:15:54.290227: train Epoch: [64][128/129]	Time  1.829 ( 2.040)	Data  0.856 ( 1.067)	Loss 5.2661e-02 (7.7829e-02) 
2023-05-26 01:15:54.368288: Train Epoch done in 263.2592406139993 s 
2023-05-26 01:15:57.044684: val Epoch: [64][ 0/72]	Time  1.835 ( 1.835)	Data  1.588 ( 1.588)	Loss 6.8312e-02 (6.8312e-02) 
2023-05-26 01:15:57.189296: val Epoch: [64][ 1/72]	Time  0.145 ( 0.990)	Data  0.002 ( 0.795)	Loss 3.9641e-02 (5.3976e-02) 
2023-05-26 01:15:58.282951: val Epoch: [64][ 2/72]	Time  1.094 ( 1.025)	Data  0.967 ( 0.852)	Loss 6.3766e-02 (5.7240e-02) 
2023-05-26 01:15:58.414016: val Epoch: [64][ 3/72]	Time  0.131 ( 0.801)	Data  0.001 ( 0.639)	Loss 3.8595e-02 (5.2578e-02) 
2023-05-26 01:15:59.677963: val Epoch: [64][ 4/72]	Time  1.264 ( 0.894)	Data  1.126 ( 0.737)	Loss 9.2510e-02 (6.0565e-02) 
2023-05-26 01:15:59.813769: val Epoch: [64][ 5/72]	Time  0.136 ( 0.767)	Data  0.001 ( 0.614)	Loss 4.8148e-02 (5.8495e-02) 
2023-05-26 01:16:01.081696: val Epoch: [64][ 6/72]	Time  1.268 ( 0.839)	Data  1.137 ( 0.689)	Loss 7.4060e-02 (6.0719e-02) 
2023-05-26 01:16:01.213000: val Epoch: [64][ 7/72]	Time  0.131 ( 0.750)	Data  0.001 ( 0.603)	Loss 9.1170e-02 (6.4525e-02) 
2023-05-26 01:16:02.485227: val Epoch: [64][ 8/72]	Time  1.272 ( 0.808)	Data  1.137 ( 0.662)	Loss 1.0710e-01 (6.9256e-02) 
2023-05-26 01:16:02.619241: val Epoch: [64][ 9/72]	Time  0.134 ( 0.741)	Data  0.001 ( 0.596)	Loss 4.9340e-02 (6.7264e-02) 
2023-05-26 01:16:03.840146: val Epoch: [64][10/72]	Time  1.221 ( 0.785)	Data  1.096 ( 0.641)	Loss 1.4126e-01 (7.3991e-02) 
2023-05-26 01:16:03.977023: val Epoch: [64][11/72]	Time  0.137 ( 0.731)	Data  0.001 ( 0.588)	Loss 3.5141e-01 (9.7109e-02) 
2023-05-26 01:16:05.170633: val Epoch: [64][12/72]	Time  1.194 ( 0.766)	Data  1.067 ( 0.625)	Loss 3.5058e-02 (9.2336e-02) 
2023-05-26 01:16:05.310405: val Epoch: [64][13/72]	Time  0.140 ( 0.721)	Data  0.001 ( 0.580)	Loss 1.0760e-01 (9.3426e-02) 
2023-05-26 01:16:06.580788: val Epoch: [64][14/72]	Time  1.270 ( 0.758)	Data  1.132 ( 0.617)	Loss 1.6060e-01 (9.7904e-02) 
2023-05-26 01:16:06.721347: val Epoch: [64][15/72]	Time  0.141 ( 0.719)	Data  0.001 ( 0.579)	Loss 1.6062e-01 (1.0182e-01) 
2023-05-26 01:16:07.934702: val Epoch: [64][16/72]	Time  1.213 ( 0.749)	Data  1.082 ( 0.608)	Loss 7.6102e-02 (1.0031e-01) 
2023-05-26 01:16:08.072305: val Epoch: [64][17/72]	Time  0.138 ( 0.715)	Data  0.001 ( 0.574)	Loss 9.3102e-02 (9.9911e-02) 
2023-05-26 01:16:09.342684: val Epoch: [64][18/72]	Time  1.270 ( 0.744)	Data  1.143 ( 0.604)	Loss 5.3754e-02 (9.7481e-02) 
2023-05-26 01:16:09.469774: val Epoch: [64][19/72]	Time  0.127 ( 0.713)	Data  0.001 ( 0.574)	Loss 3.4135e-01 (1.0967e-01) 
2023-05-26 01:16:10.729174: val Epoch: [64][20/72]	Time  1.259 ( 0.739)	Data  1.132 ( 0.601)	Loss 2.8010e-01 (1.1779e-01) 
2023-05-26 01:16:10.857061: val Epoch: [64][21/72]	Time  0.128 ( 0.711)	Data  0.001 ( 0.573)	Loss 6.1184e-02 (1.1522e-01) 
2023-05-26 01:16:12.092413: val Epoch: [64][22/72]	Time  1.235 ( 0.734)	Data  1.109 ( 0.597)	Loss 5.2790e-02 (1.1250e-01) 
2023-05-26 01:16:12.222573: val Epoch: [64][23/72]	Time  0.130 ( 0.709)	Data  0.001 ( 0.572)	Loss 7.3258e-02 (1.1087e-01) 
2023-05-26 01:16:13.557811: val Epoch: [64][24/72]	Time  1.335 ( 0.734)	Data  1.207 ( 0.597)	Loss 4.6074e-02 (1.0828e-01) 
2023-05-26 01:16:13.685290: val Epoch: [64][25/72]	Time  0.127 ( 0.711)	Data  0.001 ( 0.574)	Loss 1.1784e-01 (1.0864e-01) 
2023-05-26 01:16:14.950026: val Epoch: [64][26/72]	Time  1.265 ( 0.731)	Data  1.137 ( 0.595)	Loss 5.2961e-02 (1.0658e-01) 
2023-05-26 01:16:15.081602: val Epoch: [64][27/72]	Time  0.132 ( 0.710)	Data  0.001 ( 0.574)	Loss 2.2332e-01 (1.1075e-01) 
2023-05-26 01:16:16.408004: val Epoch: [64][28/72]	Time  1.326 ( 0.731)	Data  1.200 ( 0.595)	Loss 3.5335e-01 (1.1912e-01) 
2023-05-26 01:16:16.538859: val Epoch: [64][29/72]	Time  0.131 ( 0.711)	Data  0.001 ( 0.576)	Loss 7.6664e-02 (1.1770e-01) 
2023-05-26 01:16:17.877625: val Epoch: [64][30/72]	Time  1.339 ( 0.731)	Data  1.211 ( 0.596)	Loss 1.5999e-01 (1.1907e-01) 
2023-05-26 01:16:18.019586: val Epoch: [64][31/72]	Time  0.142 ( 0.713)	Data  0.001 ( 0.578)	Loss 9.9664e-02 (1.1846e-01) 
2023-05-26 01:16:19.237875: val Epoch: [64][32/72]	Time  1.218 ( 0.728)	Data  1.093 ( 0.593)	Loss 4.4589e-02 (1.1622e-01) 
2023-05-26 01:16:19.369166: val Epoch: [64][33/72]	Time  0.131 ( 0.711)	Data  0.001 ( 0.576)	Loss 9.0099e-02 (1.1545e-01) 
2023-05-26 01:16:20.646603: val Epoch: [64][34/72]	Time  1.277 ( 0.727)	Data  1.147 ( 0.592)	Loss 2.1443e-01 (1.1828e-01) 
2023-05-26 01:16:20.781054: val Epoch: [64][35/72]	Time  0.134 ( 0.710)	Data  0.001 ( 0.576)	Loss 1.1844e-01 (1.1828e-01) 
2023-05-26 01:16:22.015578: val Epoch: [64][36/72]	Time  1.235 ( 0.724)	Data  1.094 ( 0.590)	Loss 5.1606e-02 (1.1648e-01) 
2023-05-26 01:16:22.151318: val Epoch: [64][37/72]	Time  0.136 ( 0.709)	Data  0.001 ( 0.574)	Loss 5.6491e-02 (1.1490e-01) 
2023-05-26 01:16:23.377822: val Epoch: [64][38/72]	Time  1.226 ( 0.722)	Data  1.101 ( 0.588)	Loss 3.8598e-02 (1.1295e-01) 
2023-05-26 01:16:23.510598: val Epoch: [64][39/72]	Time  0.133 ( 0.708)	Data  0.001 ( 0.573)	Loss 4.6542e-02 (1.1129e-01) 
2023-05-26 01:16:24.741916: val Epoch: [64][40/72]	Time  1.231 ( 0.720)	Data  1.100 ( 0.586)	Loss 2.2304e-01 (1.1401e-01) 
2023-05-26 01:16:24.873115: val Epoch: [64][41/72]	Time  0.131 ( 0.706)	Data  0.001 ( 0.572)	Loss 4.4914e-02 (1.1237e-01) 
2023-05-26 01:16:26.123523: val Epoch: [64][42/72]	Time  1.250 ( 0.719)	Data  1.114 ( 0.585)	Loss 4.0605e-02 (1.1070e-01) 
2023-05-26 01:16:26.263759: val Epoch: [64][43/72]	Time  0.140 ( 0.706)	Data  0.001 ( 0.571)	Loss 1.2938e-01 (1.1112e-01) 
2023-05-26 01:16:27.518707: val Epoch: [64][44/72]	Time  1.255 ( 0.718)	Data  1.126 ( 0.584)	Loss 4.7608e-02 (1.0971e-01) 
2023-05-26 01:16:27.650121: val Epoch: [64][45/72]	Time  0.131 ( 0.705)	Data  0.001 ( 0.571)	Loss 5.6334e-02 (1.0855e-01) 
2023-05-26 01:16:28.876308: val Epoch: [64][46/72]	Time  1.226 ( 0.716)	Data  1.100 ( 0.582)	Loss 5.2929e-02 (1.0737e-01) 
2023-05-26 01:16:29.007913: val Epoch: [64][47/72]	Time  0.132 ( 0.704)	Data  0.001 ( 0.570)	Loss 2.8375e-01 (1.1104e-01) 
2023-05-26 01:16:30.216082: val Epoch: [64][48/72]	Time  1.208 ( 0.714)	Data  1.081 ( 0.581)	Loss 7.3049e-02 (1.1027e-01) 
2023-05-26 01:16:30.343301: val Epoch: [64][49/72]	Time  0.127 ( 0.703)	Data  0.001 ( 0.569)	Loss 5.3978e-02 (1.0914e-01) 
2023-05-26 01:16:31.531747: val Epoch: [64][50/72]	Time  1.188 ( 0.712)	Data  1.062 ( 0.579)	Loss 7.1989e-02 (1.0841e-01) 
2023-05-26 01:16:31.661964: val Epoch: [64][51/72]	Time  0.130 ( 0.701)	Data  0.001 ( 0.567)	Loss 3.8995e-01 (1.1383e-01) 
2023-05-26 01:16:32.888984: val Epoch: [64][52/72]	Time  1.227 ( 0.711)	Data  1.100 ( 0.578)	Loss 1.1897e-01 (1.1392e-01) 
2023-05-26 01:16:33.017390: val Epoch: [64][53/72]	Time  0.128 ( 0.700)	Data  0.001 ( 0.567)	Loss 1.3676e-01 (1.1435e-01) 
2023-05-26 01:16:34.271505: val Epoch: [64][54/72]	Time  1.254 ( 0.710)	Data  1.126 ( 0.577)	Loss 3.7374e-02 (1.1295e-01) 
2023-05-26 01:16:34.403260: val Epoch: [64][55/72]	Time  0.132 ( 0.700)	Data  0.001 ( 0.567)	Loss 5.1904e-02 (1.1186e-01) 
2023-05-26 01:16:35.659841: val Epoch: [64][56/72]	Time  1.257 ( 0.710)	Data  1.129 ( 0.577)	Loss 3.3429e-02 (1.1048e-01) 
2023-05-26 01:16:35.791142: val Epoch: [64][57/72]	Time  0.131 ( 0.700)	Data  0.001 ( 0.567)	Loss 2.9386e-01 (1.1364e-01) 
2023-05-26 01:16:37.086464: val Epoch: [64][58/72]	Time  1.295 ( 0.710)	Data  1.163 ( 0.577)	Loss 8.6339e-02 (1.1318e-01) 
2023-05-26 01:16:37.215656: val Epoch: [64][59/72]	Time  0.129 ( 0.700)	Data  0.001 ( 0.567)	Loss 7.2313e-02 (1.1250e-01) 
2023-05-26 01:16:38.501617: val Epoch: [64][60/72]	Time  1.286 ( 0.710)	Data  1.159 ( 0.577)	Loss 9.0737e-02 (1.1214e-01) 
2023-05-26 01:16:38.628869: val Epoch: [64][61/72]	Time  0.127 ( 0.700)	Data  0.001 ( 0.568)	Loss 4.7184e-01 (1.1794e-01) 
2023-05-26 01:16:39.932409: val Epoch: [64][62/72]	Time  1.304 ( 0.710)	Data  1.173 ( 0.577)	Loss 5.4044e-02 (1.1693e-01) 
2023-05-26 01:16:40.062509: val Epoch: [64][63/72]	Time  0.130 ( 0.701)	Data  0.001 ( 0.568)	Loss 1.2280e-01 (1.1702e-01) 
2023-05-26 01:16:41.314909: val Epoch: [64][64/72]	Time  1.252 ( 0.709)	Data  1.122 ( 0.577)	Loss 8.9967e-02 (1.1661e-01) 
2023-05-26 01:16:41.450459: val Epoch: [64][65/72]	Time  0.136 ( 0.701)	Data  0.001 ( 0.568)	Loss 9.1761e-02 (1.1623e-01) 
2023-05-26 01:16:42.705445: val Epoch: [64][66/72]	Time  1.255 ( 0.709)	Data  1.123 ( 0.576)	Loss 2.9269e-01 (1.1886e-01) 
2023-05-26 01:16:42.833202: val Epoch: [64][67/72]	Time  0.128 ( 0.700)	Data  0.001 ( 0.568)	Loss 4.2776e-02 (1.1774e-01) 
2023-05-26 01:16:44.125036: val Epoch: [64][68/72]	Time  1.292 ( 0.709)	Data  1.156 ( 0.576)	Loss 3.4271e-01 (1.2100e-01) 
2023-05-26 01:16:44.265159: val Epoch: [64][69/72]	Time  0.140 ( 0.701)	Data  0.001 ( 0.568)	Loss 5.6541e-02 (1.2008e-01) 
2023-05-26 01:16:45.373692: val Epoch: [64][70/72]	Time  1.109 ( 0.707)	Data  0.982 ( 0.574)	Loss 6.3258e-02 (1.1928e-01) 
2023-05-26 01:16:45.499556: val Epoch: [64][71/72]	Time  0.126 ( 0.698)	Data  0.001 ( 0.566)	Loss 4.6385e-01 (1.2407e-01) 
2023-05-26 01:16:45.704237: Epoch 64 :Val : ['ET : 0.7257922291755676', 'TC : 0.7967888116836548', 'WT : 0.8669667840003967'] 
2023-05-26 01:16:45.709630: Epoch 64 :Val : ['ET : 0.7257922291755676', 'TC : 0.7967888116836548', 'WT : 0.8669667840003967'] 
2023-05-26 01:16:45.712629: Val epoch done in 51.344337253998674 s 
2023-05-26 01:16:45.723571: Batches per epoch:  129 
2023-05-26 01:16:51.345200: train Epoch: [65][  0/129]	Time  5.621 ( 5.621)	Data  4.581 ( 4.581)	Loss 4.0276e-02 (4.0276e-02) 
2023-05-26 01:16:52.313671: train Epoch: [65][  1/129]	Time  0.969 ( 3.295)	Data  0.001 ( 2.291)	Loss 1.0313e-01 (7.1703e-02) 
2023-05-26 01:16:55.364046: train Epoch: [65][  2/129]	Time  3.050 ( 3.213)	Data  2.078 ( 2.220)	Loss 4.3665e-02 (6.2357e-02) 
2023-05-26 01:16:56.333254: train Epoch: [65][  3/129]	Time  0.969 ( 2.652)	Data  0.001 ( 1.665)	Loss 6.4981e-02 (6.3013e-02) 
2023-05-26 01:16:59.449060: train Epoch: [65][  4/129]	Time  3.116 ( 2.745)	Data  2.150 ( 1.762)	Loss 9.0120e-02 (6.8434e-02) 
2023-05-26 01:17:00.416755: train Epoch: [65][  5/129]	Time  0.968 ( 2.449)	Data  0.001 ( 1.469)	Loss 8.3071e-02 (7.0874e-02) 
2023-05-26 01:17:03.417114: train Epoch: [65][  6/129]	Time  3.000 ( 2.528)	Data  2.037 ( 1.550)	Loss 7.8042e-02 (7.1898e-02) 
2023-05-26 01:17:04.393869: train Epoch: [65][  7/129]	Time  0.977 ( 2.334)	Data  0.001 ( 1.356)	Loss 7.3531e-02 (7.2102e-02) 
2023-05-26 01:17:07.400599: train Epoch: [65][  8/129]	Time  3.007 ( 2.408)	Data  2.038 ( 1.432)	Loss 6.8591e-02 (7.1712e-02) 
2023-05-26 01:17:08.369917: train Epoch: [65][  9/129]	Time  0.969 ( 2.265)	Data  0.001 ( 1.289)	Loss 7.7528e-02 (7.2293e-02) 
2023-05-26 01:17:11.490822: train Epoch: [65][ 10/129]	Time  3.121 ( 2.342)	Data  2.149 ( 1.367)	Loss 5.2076e-02 (7.0456e-02) 
2023-05-26 01:17:12.465331: train Epoch: [65][ 11/129]	Time  0.975 ( 2.228)	Data  0.001 ( 1.253)	Loss 6.0408e-02 (6.9618e-02) 
2023-05-26 01:17:15.489211: train Epoch: [65][ 12/129]	Time  3.024 ( 2.290)	Data  2.057 ( 1.315)	Loss 8.8490e-02 (7.1070e-02) 
2023-05-26 01:17:16.454242: train Epoch: [65][ 13/129]	Time  0.965 ( 2.195)	Data  0.001 ( 1.221)	Loss 6.0949e-02 (7.0347e-02) 
2023-05-26 01:17:19.615201: train Epoch: [65][ 14/129]	Time  3.161 ( 2.259)	Data  2.196 ( 1.286)	Loss 5.6982e-02 (6.9456e-02) 
2023-05-26 01:17:20.580612: train Epoch: [65][ 15/129]	Time  0.965 ( 2.179)	Data  0.001 ( 1.206)	Loss 6.9763e-02 (6.9475e-02) 
2023-05-26 01:17:23.827047: train Epoch: [65][ 16/129]	Time  3.246 ( 2.241)	Data  2.277 ( 1.269)	Loss 7.0587e-02 (6.9541e-02) 
2023-05-26 01:17:24.814303: train Epoch: [65][ 17/129]	Time  0.987 ( 2.172)	Data  0.001 ( 1.198)	Loss 4.7336e-02 (6.8307e-02) 
2023-05-26 01:17:27.896529: train Epoch: [65][ 18/129]	Time  3.082 ( 2.220)	Data  2.127 ( 1.247)	Loss 1.2742e-01 (7.1418e-02) 
2023-05-26 01:17:28.887005: train Epoch: [65][ 19/129]	Time  0.990 ( 2.158)	Data  0.001 ( 1.185)	Loss 1.0549e-01 (7.3122e-02) 
2023-05-26 01:17:32.013310: train Epoch: [65][ 20/129]	Time  3.126 ( 2.204)	Data  2.163 ( 1.232)	Loss 1.3098e-01 (7.5877e-02) 
2023-05-26 01:17:32.984346: train Epoch: [65][ 21/129]	Time  0.971 ( 2.148)	Data  0.001 ( 1.176)	Loss 8.4125e-02 (7.6252e-02) 
2023-05-26 01:17:36.102418: train Epoch: [65][ 22/129]	Time  3.118 ( 2.190)	Data  2.164 ( 1.219)	Loss 7.3028e-02 (7.6112e-02) 
2023-05-26 01:17:37.057141: train Epoch: [65][ 23/129]	Time  0.955 ( 2.139)	Data  0.001 ( 1.168)	Loss 5.9748e-02 (7.5430e-02) 
2023-05-26 01:17:40.158640: train Epoch: [65][ 24/129]	Time  3.102 ( 2.177)	Data  2.122 ( 1.206)	Loss 6.6516e-02 (7.5073e-02) 
2023-05-26 01:17:41.119857: train Epoch: [65][ 25/129]	Time  0.961 ( 2.131)	Data  0.001 ( 1.160)	Loss 7.1665e-02 (7.4942e-02) 
2023-05-26 01:17:44.285022: train Epoch: [65][ 26/129]	Time  3.165 ( 2.169)	Data  2.186 ( 1.198)	Loss 5.4089e-02 (7.4170e-02) 
2023-05-26 01:17:45.251516: train Epoch: [65][ 27/129]	Time  0.966 ( 2.126)	Data  0.001 ( 1.155)	Loss 5.6538e-02 (7.3540e-02) 
2023-05-26 01:17:48.211745: train Epoch: [65][ 28/129]	Time  2.960 ( 2.155)	Data  1.973 ( 1.183)	Loss 9.8597e-02 (7.4404e-02) 
2023-05-26 01:17:49.180198: train Epoch: [65][ 29/129]	Time  0.968 ( 2.115)	Data  0.001 ( 1.144)	Loss 1.0576e-01 (7.5449e-02) 
2023-05-26 01:17:52.331412: train Epoch: [65][ 30/129]	Time  3.151 ( 2.149)	Data  2.178 ( 1.177)	Loss 3.9902e-02 (7.4303e-02) 
2023-05-26 01:17:53.314485: train Epoch: [65][ 31/129]	Time  0.983 ( 2.112)	Data  0.001 ( 1.140)	Loss 1.1247e-01 (7.5496e-02) 
2023-05-26 01:17:56.473742: train Epoch: [65][ 32/129]	Time  3.159 ( 2.144)	Data  2.165 ( 1.171)	Loss 6.2092e-02 (7.5089e-02) 
2023-05-26 01:17:57.453625: train Epoch: [65][ 33/129]	Time  0.980 ( 2.110)	Data  0.001 ( 1.137)	Loss 7.2035e-02 (7.5000e-02) 
2023-05-26 01:18:00.452002: train Epoch: [65][ 34/129]	Time  2.998 ( 2.135)	Data  2.028 ( 1.163)	Loss 8.5636e-02 (7.5303e-02) 
2023-05-26 01:18:01.431030: train Epoch: [65][ 35/129]	Time  0.979 ( 2.103)	Data  0.001 ( 1.130)	Loss 9.6618e-02 (7.5896e-02) 
2023-05-26 01:18:04.599174: train Epoch: [65][ 36/129]	Time  3.168 ( 2.132)	Data  2.198 ( 1.159)	Loss 7.7213e-02 (7.5931e-02) 
2023-05-26 01:18:05.571696: train Epoch: [65][ 37/129]	Time  0.972 ( 2.101)	Data  0.001 ( 1.129)	Loss 8.1177e-02 (7.6069e-02) 
2023-05-26 01:18:08.636420: train Epoch: [65][ 38/129]	Time  3.065 ( 2.126)	Data  2.088 ( 1.153)	Loss 3.9561e-02 (7.5133e-02) 
2023-05-26 01:18:09.625545: train Epoch: [65][ 39/129]	Time  0.989 ( 2.098)	Data  0.001 ( 1.124)	Loss 9.2282e-02 (7.5562e-02) 
2023-05-26 01:18:12.729298: train Epoch: [65][ 40/129]	Time  3.104 ( 2.122)	Data  2.137 ( 1.149)	Loss 1.0024e-01 (7.6164e-02) 
2023-05-26 01:18:13.700559: train Epoch: [65][ 41/129]	Time  0.971 ( 2.095)	Data  0.001 ( 1.122)	Loss 8.3202e-02 (7.6331e-02) 
2023-05-26 01:18:16.840820: train Epoch: [65][ 42/129]	Time  3.140 ( 2.119)	Data  2.170 ( 1.146)	Loss 9.0309e-02 (7.6656e-02) 
2023-05-26 01:18:17.810653: train Epoch: [65][ 43/129]	Time  0.970 ( 2.093)	Data  0.001 ( 1.120)	Loss 7.1219e-02 (7.6533e-02) 
2023-05-26 01:18:20.941278: train Epoch: [65][ 44/129]	Time  3.131 ( 2.116)	Data  2.165 ( 1.143)	Loss 1.2302e-01 (7.7566e-02) 
2023-05-26 01:18:21.916229: train Epoch: [65][ 45/129]	Time  0.975 ( 2.091)	Data  0.001 ( 1.119)	Loss 6.7721e-02 (7.7352e-02) 
2023-05-26 01:18:25.042642: train Epoch: [65][ 46/129]	Time  3.126 ( 2.113)	Data  2.154 ( 1.141)	Loss 6.0688e-02 (7.6997e-02) 
2023-05-26 01:18:26.012268: train Epoch: [65][ 47/129]	Time  0.970 ( 2.089)	Data  0.001 ( 1.117)	Loss 6.3164e-02 (7.6709e-02) 
2023-05-26 01:18:29.198740: train Epoch: [65][ 48/129]	Time  3.186 ( 2.112)	Data  2.193 ( 1.139)	Loss 6.5394e-02 (7.6478e-02) 
2023-05-26 01:18:30.170709: train Epoch: [65][ 49/129]	Time  0.972 ( 2.089)	Data  0.001 ( 1.116)	Loss 6.8588e-02 (7.6320e-02) 
2023-05-26 01:18:33.285333: train Epoch: [65][ 50/129]	Time  3.115 ( 2.109)	Data  2.143 ( 1.136)	Loss 4.6644e-02 (7.5738e-02) 
2023-05-26 01:18:34.269467: train Epoch: [65][ 51/129]	Time  0.984 ( 2.087)	Data  0.001 ( 1.114)	Loss 7.9942e-02 (7.5819e-02) 
2023-05-26 01:18:37.293339: train Epoch: [65][ 52/129]	Time  3.024 ( 2.105)	Data  2.041 ( 1.132)	Loss 5.8239e-02 (7.5487e-02) 
2023-05-26 01:18:38.260642: train Epoch: [65][ 53/129]	Time  0.967 ( 2.084)	Data  0.001 ( 1.111)	Loss 7.6704e-02 (7.5510e-02) 
2023-05-26 01:18:41.362378: train Epoch: [65][ 54/129]	Time  3.102 ( 2.103)	Data  2.136 ( 1.130)	Loss 7.4050e-02 (7.5483e-02) 
2023-05-26 01:18:42.333902: train Epoch: [65][ 55/129]	Time  0.972 ( 2.082)	Data  0.001 ( 1.109)	Loss 1.2383e-01 (7.6347e-02) 
2023-05-26 01:18:45.404779: train Epoch: [65][ 56/129]	Time  3.071 ( 2.100)	Data  2.087 ( 1.127)	Loss 8.5839e-02 (7.6513e-02) 
2023-05-26 01:18:46.386064: train Epoch: [65][ 57/129]	Time  0.981 ( 2.080)	Data  0.001 ( 1.107)	Loss 5.8231e-02 (7.6198e-02) 
2023-05-26 01:18:49.464213: train Epoch: [65][ 58/129]	Time  3.078 ( 2.097)	Data  2.107 ( 1.124)	Loss 9.2420e-02 (7.6473e-02) 
2023-05-26 01:18:50.439438: train Epoch: [65][ 59/129]	Time  0.975 ( 2.079)	Data  0.001 ( 1.105)	Loss 8.0691e-02 (7.6543e-02) 
2023-05-26 01:18:53.530806: train Epoch: [65][ 60/129]	Time  3.091 ( 2.095)	Data  2.118 ( 1.122)	Loss 7.4655e-02 (7.6512e-02) 
2023-05-26 01:18:54.512167: train Epoch: [65][ 61/129]	Time  0.981 ( 2.077)	Data  0.001 ( 1.104)	Loss 1.4776e-01 (7.7662e-02) 
2023-05-26 01:18:57.729326: train Epoch: [65][ 62/129]	Time  3.217 ( 2.095)	Data  2.246 ( 1.122)	Loss 6.4930e-02 (7.7459e-02) 
2023-05-26 01:18:58.702742: train Epoch: [65][ 63/129]	Time  0.973 ( 2.078)	Data  0.001 ( 1.105)	Loss 7.4132e-02 (7.7407e-02) 
2023-05-26 01:19:01.921591: train Epoch: [65][ 64/129]	Time  3.219 ( 2.095)	Data  2.243 ( 1.122)	Loss 5.3290e-02 (7.7036e-02) 
2023-05-26 01:19:02.899603: train Epoch: [65][ 65/129]	Time  0.978 ( 2.078)	Data  0.001 ( 1.105)	Loss 9.3589e-02 (7.7287e-02) 
2023-05-26 01:19:05.993217: train Epoch: [65][ 66/129]	Time  3.094 ( 2.094)	Data  2.119 ( 1.120)	Loss 5.3614e-02 (7.6934e-02) 
2023-05-26 01:19:06.960767: train Epoch: [65][ 67/129]	Time  0.968 ( 2.077)	Data  0.001 ( 1.104)	Loss 5.2180e-02 (7.6570e-02) 
2023-05-26 01:19:10.035644: train Epoch: [65][ 68/129]	Time  3.075 ( 2.091)	Data  2.094 ( 1.118)	Loss 6.6757e-02 (7.6428e-02) 
2023-05-26 01:19:11.009349: train Epoch: [65][ 69/129]	Time  0.974 ( 2.075)	Data  0.001 ( 1.102)	Loss 7.1075e-02 (7.6351e-02) 
2023-05-26 01:19:14.008052: train Epoch: [65][ 70/129]	Time  2.999 ( 2.089)	Data  2.042 ( 1.115)	Loss 1.0314e-01 (7.6728e-02) 
2023-05-26 01:19:14.988189: train Epoch: [65][ 71/129]	Time  0.980 ( 2.073)	Data  0.001 ( 1.100)	Loss 1.2055e-01 (7.7337e-02) 
2023-05-26 01:19:18.235047: train Epoch: [65][ 72/129]	Time  3.247 ( 2.089)	Data  2.278 ( 1.116)	Loss 6.2826e-02 (7.7138e-02) 
2023-05-26 01:19:19.223030: train Epoch: [65][ 73/129]	Time  0.988 ( 2.074)	Data  0.001 ( 1.101)	Loss 6.4649e-02 (7.6969e-02) 
2023-05-26 01:19:22.484291: train Epoch: [65][ 74/129]	Time  3.261 ( 2.090)	Data  2.281 ( 1.117)	Loss 6.8991e-02 (7.6863e-02) 
2023-05-26 01:19:23.455868: train Epoch: [65][ 75/129]	Time  0.972 ( 2.075)	Data  0.001 ( 1.102)	Loss 7.6816e-02 (7.6862e-02) 
2023-05-26 01:19:26.602554: train Epoch: [65][ 76/129]	Time  3.147 ( 2.089)	Data  2.178 ( 1.116)	Loss 4.2751e-02 (7.6419e-02) 
2023-05-26 01:19:27.595608: train Epoch: [65][ 77/129]	Time  0.993 ( 2.075)	Data  0.001 ( 1.102)	Loss 6.0603e-02 (7.6217e-02) 
2023-05-26 01:19:30.664021: train Epoch: [65][ 78/129]	Time  3.068 ( 2.088)	Data  2.086 ( 1.114)	Loss 6.6477e-02 (7.6093e-02) 
2023-05-26 01:19:31.643556: train Epoch: [65][ 79/129]	Time  0.980 ( 2.074)	Data  0.001 ( 1.100)	Loss 4.6416e-02 (7.5722e-02) 
2023-05-26 01:19:34.771528: train Epoch: [65][ 80/129]	Time  3.128 ( 2.087)	Data  2.166 ( 1.113)	Loss 7.7028e-02 (7.5739e-02) 
2023-05-26 01:19:35.741437: train Epoch: [65][ 81/129]	Time  0.970 ( 2.073)	Data  0.001 ( 1.100)	Loss 6.3263e-02 (7.5586e-02) 
2023-05-26 01:19:38.863819: train Epoch: [65][ 82/129]	Time  3.122 ( 2.086)	Data  2.157 ( 1.113)	Loss 4.1695e-02 (7.5178e-02) 
2023-05-26 01:19:39.827366: train Epoch: [65][ 83/129]	Time  0.964 ( 2.073)	Data  0.001 ( 1.099)	Loss 7.3816e-02 (7.5162e-02) 
2023-05-26 01:19:43.026346: train Epoch: [65][ 84/129]	Time  3.199 ( 2.086)	Data  2.225 ( 1.113)	Loss 6.7362e-02 (7.5070e-02) 
2023-05-26 01:19:44.001964: train Epoch: [65][ 85/129]	Time  0.976 ( 2.073)	Data  0.001 ( 1.100)	Loss 8.2314e-02 (7.5154e-02) 
2023-05-26 01:19:47.179878: train Epoch: [65][ 86/129]	Time  3.178 ( 2.086)	Data  2.211 ( 1.112)	Loss 6.6722e-02 (7.5057e-02) 
2023-05-26 01:19:48.157636: train Epoch: [65][ 87/129]	Time  0.978 ( 2.073)	Data  0.001 ( 1.100)	Loss 7.8359e-02 (7.5095e-02) 
2023-05-26 01:19:51.223546: train Epoch: [65][ 88/129]	Time  3.066 ( 2.084)	Data  2.090 ( 1.111)	Loss 8.2425e-02 (7.5177e-02) 
2023-05-26 01:19:52.193469: train Epoch: [65][ 89/129]	Time  0.970 ( 2.072)	Data  0.001 ( 1.099)	Loss 7.1624e-02 (7.5138e-02) 
2023-05-26 01:19:55.299433: train Epoch: [65][ 90/129]	Time  3.106 ( 2.083)	Data  2.139 ( 1.110)	Loss 6.1177e-02 (7.4984e-02) 
2023-05-26 01:19:56.265754: train Epoch: [65][ 91/129]	Time  0.966 ( 2.071)	Data  0.001 ( 1.098)	Loss 1.2984e-01 (7.5581e-02) 
2023-05-26 01:19:59.421904: train Epoch: [65][ 92/129]	Time  3.156 ( 2.083)	Data  2.192 ( 1.110)	Loss 6.6681e-02 (7.5485e-02) 
2023-05-26 01:20:00.388505: train Epoch: [65][ 93/129]	Time  0.967 ( 2.071)	Data  0.001 ( 1.098)	Loss 5.1310e-02 (7.5228e-02) 
2023-05-26 01:20:03.429904: train Epoch: [65][ 94/129]	Time  3.041 ( 2.081)	Data  2.077 ( 1.108)	Loss 5.9512e-02 (7.5062e-02) 
2023-05-26 01:20:04.392114: train Epoch: [65][ 95/129]	Time  0.962 ( 2.069)	Data  0.001 ( 1.097)	Loss 5.2977e-02 (7.4832e-02) 
2023-05-26 01:20:07.594000: train Epoch: [65][ 96/129]	Time  3.202 ( 2.081)	Data  2.235 ( 1.108)	Loss 8.0373e-02 (7.4889e-02) 
2023-05-26 01:20:08.550683: train Epoch: [65][ 97/129]	Time  0.957 ( 2.070)	Data  0.001 ( 1.097)	Loss 6.9714e-02 (7.4837e-02) 
2023-05-26 01:20:11.596903: train Epoch: [65][ 98/129]	Time  3.046 ( 2.080)	Data  2.072 ( 1.107)	Loss 8.9316e-02 (7.4983e-02) 
2023-05-26 01:20:12.588765: train Epoch: [65][ 99/129]	Time  0.992 ( 2.069)	Data  0.001 ( 1.096)	Loss 8.3975e-02 (7.5073e-02) 
2023-05-26 01:20:15.595917: train Epoch: [65][100/129]	Time  3.007 ( 2.078)	Data  2.032 ( 1.105)	Loss 7.2175e-02 (7.5044e-02) 
2023-05-26 01:20:16.568045: train Epoch: [65][101/129]	Time  0.972 ( 2.067)	Data  0.001 ( 1.094)	Loss 3.6534e-02 (7.4667e-02) 
2023-05-26 01:20:19.737243: train Epoch: [65][102/129]	Time  3.169 ( 2.078)	Data  2.190 ( 1.105)	Loss 8.1678e-02 (7.4735e-02) 
2023-05-26 01:20:20.709669: train Epoch: [65][103/129]	Time  0.972 ( 2.067)	Data  0.002 ( 1.094)	Loss 7.1030e-02 (7.4699e-02) 
2023-05-26 01:20:23.828088: train Epoch: [65][104/129]	Time  3.118 ( 2.077)	Data  2.152 ( 1.104)	Loss 4.4781e-02 (7.4414e-02) 
2023-05-26 01:20:24.798820: train Epoch: [65][105/129]	Time  0.971 ( 2.067)	Data  0.001 ( 1.094)	Loss 7.4552e-02 (7.4415e-02) 
2023-05-26 01:20:28.004415: train Epoch: [65][106/129]	Time  3.206 ( 2.077)	Data  2.237 ( 1.105)	Loss 8.4806e-02 (7.4512e-02) 
2023-05-26 01:20:28.976616: train Epoch: [65][107/129]	Time  0.972 ( 2.067)	Data  0.001 ( 1.095)	Loss 3.7307e-02 (7.4168e-02) 
2023-05-26 01:20:32.021270: train Epoch: [65][108/129]	Time  3.045 ( 2.076)	Data  2.075 ( 1.104)	Loss 6.0247e-02 (7.4040e-02) 
2023-05-26 01:20:32.996411: train Epoch: [65][109/129]	Time  0.975 ( 2.066)	Data  0.001 ( 1.094)	Loss 5.4425e-02 (7.3862e-02) 
2023-05-26 01:20:36.090501: train Epoch: [65][110/129]	Time  3.094 ( 2.075)	Data  2.123 ( 1.103)	Loss 4.2379e-02 (7.3578e-02) 
2023-05-26 01:20:37.066368: train Epoch: [65][111/129]	Time  0.976 ( 2.066)	Data  0.001 ( 1.093)	Loss 6.3543e-02 (7.3489e-02) 
2023-05-26 01:20:40.364829: train Epoch: [65][112/129]	Time  3.298 ( 2.076)	Data  2.313 ( 1.104)	Loss 1.1789e-01 (7.3882e-02) 
2023-05-26 01:20:41.335476: train Epoch: [65][113/129]	Time  0.971 ( 2.067)	Data  0.001 ( 1.094)	Loss 8.9021e-02 (7.4014e-02) 
2023-05-26 01:20:44.697325: train Epoch: [65][114/129]	Time  3.362 ( 2.078)	Data  2.384 ( 1.105)	Loss 7.3057e-02 (7.4006e-02) 
2023-05-26 01:20:45.689698: train Epoch: [65][115/129]	Time  0.992 ( 2.069)	Data  0.002 ( 1.096)	Loss 4.8912e-02 (7.3790e-02) 
2023-05-26 01:20:48.957876: train Epoch: [65][116/129]	Time  3.268 ( 2.079)	Data  2.291 ( 1.106)	Loss 1.0161e-01 (7.4028e-02) 
2023-05-26 01:20:49.941157: train Epoch: [65][117/129]	Time  0.983 ( 2.070)	Data  0.001 ( 1.097)	Loss 7.1808e-02 (7.4009e-02) 
2023-05-26 01:20:52.946330: train Epoch: [65][118/129]	Time  3.005 ( 2.077)	Data  2.041 ( 1.105)	Loss 9.1087e-02 (7.4152e-02) 
2023-05-26 01:20:53.939856: train Epoch: [65][119/129]	Time  0.994 ( 2.068)	Data  0.001 ( 1.095)	Loss 5.8441e-02 (7.4021e-02) 
2023-05-26 01:20:57.012499: train Epoch: [65][120/129]	Time  3.073 ( 2.077)	Data  2.107 ( 1.104)	Loss 5.3598e-02 (7.3853e-02) 
2023-05-26 01:20:57.994067: train Epoch: [65][121/129]	Time  0.982 ( 2.068)	Data  0.001 ( 1.095)	Loss 5.8734e-02 (7.3729e-02) 
2023-05-26 01:21:01.158676: train Epoch: [65][122/129]	Time  3.165 ( 2.077)	Data  2.194 ( 1.104)	Loss 5.7452e-02 (7.3596e-02) 
2023-05-26 01:21:02.134552: train Epoch: [65][123/129]	Time  0.976 ( 2.068)	Data  0.001 ( 1.095)	Loss 6.8407e-02 (7.3554e-02) 
2023-05-26 01:21:05.157557: train Epoch: [65][124/129]	Time  3.023 ( 2.075)	Data  2.057 ( 1.102)	Loss 7.3421e-02 (7.3553e-02) 
2023-05-26 01:21:06.132746: train Epoch: [65][125/129]	Time  0.975 ( 2.067)	Data  0.001 ( 1.094)	Loss 8.6696e-02 (7.3658e-02) 
2023-05-26 01:21:08.475827: train Epoch: [65][126/129]	Time  2.343 ( 2.069)	Data  1.373 ( 1.096)	Loss 1.1000e-01 (7.3944e-02) 
2023-05-26 01:21:09.440154: train Epoch: [65][127/129]	Time  0.964 ( 2.060)	Data  0.001 ( 1.087)	Loss 8.2266e-02 (7.4009e-02) 
2023-05-26 01:21:11.367625: train Epoch: [65][128/129]	Time  1.927 ( 2.059)	Data  0.959 ( 1.086)	Loss 6.8534e-02 (7.3966e-02) 
2023-05-26 01:21:11.440133: Train Epoch done in 265.7166211219992 s 
2023-05-26 01:21:14.232407: val Epoch: [65][ 0/72]	Time  1.816 ( 1.816)	Data  1.591 ( 1.591)	Loss 5.1391e-02 (5.1391e-02) 
2023-05-26 01:21:14.363591: val Epoch: [65][ 1/72]	Time  0.132 ( 0.974)	Data  0.002 ( 0.796)	Loss 9.5596e-02 (7.3493e-02) 
2023-05-26 01:21:15.605433: val Epoch: [65][ 2/72]	Time  1.242 ( 1.063)	Data  1.110 ( 0.901)	Loss 1.8493e-01 (1.1064e-01) 
2023-05-26 01:21:15.742720: val Epoch: [65][ 3/72]	Time  0.137 ( 0.832)	Data  0.001 ( 0.676)	Loss 3.2450e-01 (1.6410e-01) 
2023-05-26 01:21:17.069467: val Epoch: [65][ 4/72]	Time  1.327 ( 0.931)	Data  1.181 ( 0.777)	Loss 8.1676e-02 (1.4762e-01) 
2023-05-26 01:21:17.213699: val Epoch: [65][ 5/72]	Time  0.144 ( 0.800)	Data  0.001 ( 0.648)	Loss 4.4026e-02 (1.3035e-01) 
2023-05-26 01:21:18.470760: val Epoch: [65][ 6/72]	Time  1.257 ( 0.865)	Data  1.127 ( 0.716)	Loss 1.6646e-01 (1.3551e-01) 
2023-05-26 01:21:18.620711: val Epoch: [65][ 7/72]	Time  0.150 ( 0.776)	Data  0.020 ( 0.629)	Loss 4.9602e-02 (1.2477e-01) 
2023-05-26 01:21:19.816146: val Epoch: [65][ 8/72]	Time  1.195 ( 0.822)	Data  1.054 ( 0.676)	Loss 3.4939e-02 (1.1479e-01) 
2023-05-26 01:21:19.954446: val Epoch: [65][ 9/72]	Time  0.138 ( 0.754)	Data  0.001 ( 0.609)	Loss 9.4933e-02 (1.1281e-01) 
2023-05-26 01:21:21.179830: val Epoch: [65][10/72]	Time  1.225 ( 0.797)	Data  1.091 ( 0.653)	Loss 2.8670e-01 (1.2861e-01) 
2023-05-26 01:21:21.318506: val Epoch: [65][11/72]	Time  0.139 ( 0.742)	Data  0.001 ( 0.598)	Loss 3.4565e-02 (1.2078e-01) 
2023-05-26 01:21:22.558301: val Epoch: [65][12/72]	Time  1.240 ( 0.780)	Data  1.098 ( 0.637)	Loss 1.4186e-01 (1.2240e-01) 
2023-05-26 01:21:22.699115: val Epoch: [65][13/72]	Time  0.141 ( 0.734)	Data  0.001 ( 0.591)	Loss 3.5040e-02 (1.1616e-01) 
2023-05-26 01:21:23.884268: val Epoch: [65][14/72]	Time  1.185 ( 0.765)	Data  1.056 ( 0.622)	Loss 4.5184e-02 (1.1143e-01) 
2023-05-26 01:21:24.014952: val Epoch: [65][15/72]	Time  0.131 ( 0.725)	Data  0.001 ( 0.583)	Loss 7.9601e-02 (1.0944e-01) 
2023-05-26 01:21:25.224919: val Epoch: [65][16/72]	Time  1.210 ( 0.753)	Data  1.083 ( 0.613)	Loss 2.5598e-01 (1.1806e-01) 
2023-05-26 01:21:25.350464: val Epoch: [65][17/72]	Time  0.126 ( 0.719)	Data  0.001 ( 0.579)	Loss 5.7976e-02 (1.1472e-01) 
2023-05-26 01:21:26.577396: val Epoch: [65][18/72]	Time  1.227 ( 0.745)	Data  1.096 ( 0.606)	Loss 1.2429e-01 (1.1522e-01) 
2023-05-26 01:21:26.708469: val Epoch: [65][19/72]	Time  0.131 ( 0.715)	Data  0.001 ( 0.576)	Loss 9.1236e-02 (1.1402e-01) 
2023-05-26 01:21:27.934145: val Epoch: [65][20/72]	Time  1.226 ( 0.739)	Data  1.093 ( 0.600)	Loss 5.6737e-02 (1.1130e-01) 
2023-05-26 01:21:28.065458: val Epoch: [65][21/72]	Time  0.131 ( 0.711)	Data  0.001 ( 0.573)	Loss 4.9299e-02 (1.0848e-01) 
2023-05-26 01:21:29.348504: val Epoch: [65][22/72]	Time  1.283 ( 0.736)	Data  1.150 ( 0.598)	Loss 4.2133e-02 (1.0559e-01) 
2023-05-26 01:21:29.481225: val Epoch: [65][23/72]	Time  0.133 ( 0.711)	Data  0.001 ( 0.573)	Loss 1.6812e-01 (1.0820e-01) 
2023-05-26 01:21:30.718141: val Epoch: [65][24/72]	Time  1.237 ( 0.732)	Data  1.107 ( 0.595)	Loss 9.0477e-02 (1.0749e-01) 
2023-05-26 01:21:30.848589: val Epoch: [65][25/72]	Time  0.130 ( 0.709)	Data  0.001 ( 0.572)	Loss 4.7552e-02 (1.0518e-01) 
2023-05-26 01:21:32.078220: val Epoch: [65][26/72]	Time  1.230 ( 0.728)	Data  1.099 ( 0.591)	Loss 4.3341e-02 (1.0289e-01) 
2023-05-26 01:21:32.210044: val Epoch: [65][27/72]	Time  0.132 ( 0.707)	Data  0.001 ( 0.570)	Loss 5.6819e-02 (1.0125e-01) 
2023-05-26 01:21:33.528310: val Epoch: [65][28/72]	Time  1.318 ( 0.728)	Data  1.177 ( 0.591)	Loss 6.6272e-02 (1.0004e-01) 
2023-05-26 01:21:33.662966: val Epoch: [65][29/72]	Time  0.135 ( 0.708)	Data  0.001 ( 0.571)	Loss 1.0203e-01 (1.0011e-01) 
2023-05-26 01:21:34.941643: val Epoch: [65][30/72]	Time  1.279 ( 0.727)	Data  1.138 ( 0.590)	Loss 6.0944e-02 (9.8845e-02) 
2023-05-26 01:21:35.073225: val Epoch: [65][31/72]	Time  0.132 ( 0.708)	Data  0.001 ( 0.571)	Loss 8.3819e-02 (9.8376e-02) 
2023-05-26 01:21:36.385355: val Epoch: [65][32/72]	Time  1.312 ( 0.726)	Data  1.178 ( 0.590)	Loss 9.6552e-02 (9.8321e-02) 
2023-05-26 01:21:36.518997: val Epoch: [65][33/72]	Time  0.134 ( 0.709)	Data  0.001 ( 0.572)	Loss 5.8988e-02 (9.7164e-02) 
2023-05-26 01:21:37.762229: val Epoch: [65][34/72]	Time  1.243 ( 0.724)	Data  1.105 ( 0.588)	Loss 5.2025e-02 (9.5874e-02) 
2023-05-26 01:21:37.898795: val Epoch: [65][35/72]	Time  0.137 ( 0.708)	Data  0.001 ( 0.571)	Loss 5.3005e-02 (9.4683e-02) 
2023-05-26 01:21:39.140576: val Epoch: [65][36/72]	Time  1.242 ( 0.722)	Data  1.096 ( 0.586)	Loss 4.2023e-02 (9.3260e-02) 
2023-05-26 01:21:39.280045: val Epoch: [65][37/72]	Time  0.139 ( 0.707)	Data  0.001 ( 0.570)	Loss 9.8050e-02 (9.3386e-02) 
2023-05-26 01:21:40.477270: val Epoch: [65][38/72]	Time  1.197 ( 0.720)	Data  1.066 ( 0.583)	Loss 2.5168e-01 (9.7445e-02) 
2023-05-26 01:21:40.617892: val Epoch: [65][39/72]	Time  0.141 ( 0.705)	Data  0.001 ( 0.568)	Loss 8.7426e-02 (9.7194e-02) 
2023-05-26 01:21:41.843774: val Epoch: [65][40/72]	Time  1.226 ( 0.718)	Data  1.087 ( 0.581)	Loss 5.8375e-02 (9.6248e-02) 
2023-05-26 01:21:41.980628: val Epoch: [65][41/72]	Time  0.137 ( 0.704)	Data  0.001 ( 0.567)	Loss 2.5108e-01 (9.9934e-02) 
2023-05-26 01:21:43.160911: val Epoch: [65][42/72]	Time  1.180 ( 0.715)	Data  1.052 ( 0.578)	Loss 8.3864e-02 (9.9560e-02) 
2023-05-26 01:21:43.290073: val Epoch: [65][43/72]	Time  0.129 ( 0.702)	Data  0.001 ( 0.565)	Loss 4.2729e-01 (1.0701e-01) 
2023-05-26 01:21:44.547348: val Epoch: [65][44/72]	Time  1.257 ( 0.714)	Data  1.127 ( 0.578)	Loss 3.6623e-01 (1.1277e-01) 
2023-05-26 01:21:44.679628: val Epoch: [65][45/72]	Time  0.132 ( 0.701)	Data  0.001 ( 0.565)	Loss 3.4658e-01 (1.1785e-01) 
2023-05-26 01:21:45.964122: val Epoch: [65][46/72]	Time  1.284 ( 0.714)	Data  1.147 ( 0.578)	Loss 6.3022e-02 (1.1669e-01) 
2023-05-26 01:21:46.101800: val Epoch: [65][47/72]	Time  0.138 ( 0.702)	Data  0.001 ( 0.566)	Loss 3.8975e-02 (1.1507e-01) 
2023-05-26 01:21:47.333577: val Epoch: [65][48/72]	Time  1.232 ( 0.713)	Data  1.103 ( 0.577)	Loss 5.2092e-02 (1.1378e-01) 
2023-05-26 01:21:47.465256: val Epoch: [65][49/72]	Time  0.132 ( 0.701)	Data  0.001 ( 0.565)	Loss 7.9690e-02 (1.1310e-01) 
2023-05-26 01:21:48.677251: val Epoch: [65][50/72]	Time  1.212 ( 0.711)	Data  1.080 ( 0.575)	Loss 6.4817e-02 (1.1215e-01) 
2023-05-26 01:21:48.811166: val Epoch: [65][51/72]	Time  0.134 ( 0.700)	Data  0.001 ( 0.564)	Loss 4.2643e-02 (1.1082e-01) 
2023-05-26 01:21:50.070735: val Epoch: [65][52/72]	Time  1.260 ( 0.710)	Data  1.130 ( 0.575)	Loss 1.6306e-01 (1.1180e-01) 
2023-05-26 01:21:50.200882: val Epoch: [65][53/72]	Time  0.130 ( 0.700)	Data  0.001 ( 0.564)	Loss 1.2267e-01 (1.1200e-01) 
2023-05-26 01:21:51.414869: val Epoch: [65][54/72]	Time  1.214 ( 0.709)	Data  1.084 ( 0.574)	Loss 2.5777e-01 (1.1465e-01) 
2023-05-26 01:21:51.544586: val Epoch: [65][55/72]	Time  0.130 ( 0.699)	Data  0.001 ( 0.563)	Loss 1.2429e-01 (1.1483e-01) 
2023-05-26 01:21:52.779546: val Epoch: [65][56/72]	Time  1.235 ( 0.708)	Data  1.107 ( 0.573)	Loss 1.1330e-01 (1.1480e-01) 
2023-05-26 01:21:52.909842: val Epoch: [65][57/72]	Time  0.130 ( 0.698)	Data  0.001 ( 0.563)	Loss 3.4953e-01 (1.1885e-01) 
2023-05-26 01:21:54.173685: val Epoch: [65][58/72]	Time  1.264 ( 0.708)	Data  1.134 ( 0.573)	Loss 9.0248e-02 (1.1836e-01) 
2023-05-26 01:21:54.303996: val Epoch: [65][59/72]	Time  0.130 ( 0.698)	Data  0.001 ( 0.563)	Loss 7.6756e-02 (1.1767e-01) 
2023-05-26 01:21:55.531294: val Epoch: [65][60/72]	Time  1.227 ( 0.707)	Data  1.087 ( 0.572)	Loss 4.8342e-02 (1.1653e-01) 
2023-05-26 01:21:55.661139: val Epoch: [65][61/72]	Time  0.130 ( 0.697)	Data  0.001 ( 0.563)	Loss 7.4672e-02 (1.1586e-01) 
2023-05-26 01:21:56.860182: val Epoch: [65][62/72]	Time  1.199 ( 0.705)	Data  1.067 ( 0.571)	Loss 8.2467e-02 (1.1533e-01) 
2023-05-26 01:21:56.991232: val Epoch: [65][63/72]	Time  0.131 ( 0.696)	Data  0.001 ( 0.562)	Loss 4.6305e-02 (1.1425e-01) 
2023-05-26 01:21:58.220292: val Epoch: [65][64/72]	Time  1.229 ( 0.705)	Data  1.101 ( 0.570)	Loss 2.8672e-01 (1.1690e-01) 
2023-05-26 01:21:58.359800: val Epoch: [65][65/72]	Time  0.140 ( 0.696)	Data  0.001 ( 0.561)	Loss 7.2918e-02 (1.1623e-01) 
2023-05-26 01:21:59.613085: val Epoch: [65][66/72]	Time  1.253 ( 0.704)	Data  1.113 ( 0.570)	Loss 3.3397e-02 (1.1500e-01) 
2023-05-26 01:21:59.779454: val Epoch: [65][67/72]	Time  0.166 ( 0.697)	Data  0.002 ( 0.561)	Loss 5.2016e-01 (1.2096e-01) 
2023-05-26 01:22:01.047650: val Epoch: [65][68/72]	Time  1.268 ( 0.705)	Data  1.140 ( 0.570)	Loss 6.5876e-02 (1.2016e-01) 
2023-05-26 01:22:01.178724: val Epoch: [65][69/72]	Time  0.131 ( 0.697)	Data  0.001 ( 0.561)	Loss 4.1467e-01 (1.2437e-01) 
2023-05-26 01:22:02.315895: val Epoch: [65][70/72]	Time  1.137 ( 0.703)	Data  1.004 ( 0.568)	Loss 4.2825e-02 (1.2322e-01) 
2023-05-26 01:22:02.456353: val Epoch: [65][71/72]	Time  0.140 ( 0.695)	Data  0.001 ( 0.560)	Loss 6.2378e-02 (1.2237e-01) 
2023-05-26 01:22:02.712815: Epoch 65 :Val : ['ET : 0.736534059047699', 'TC : 0.7901532649993896', 'WT : 0.8753573894500732'] 
2023-05-26 01:22:02.715994: Epoch 65 :Val : ['ET : 0.736534059047699', 'TC : 0.7901532649993896', 'WT : 0.8753573894500732'] 
2023-05-26 01:22:02.718670: Val epoch done in 51.27853969100033 s 
2023-05-26 01:22:02.724942: Batches per epoch:  129 
2023-05-26 01:22:08.087649: train Epoch: [66][  0/129]	Time  5.362 ( 5.362)	Data  4.346 ( 4.346)	Loss 4.6701e-02 (4.6701e-02) 
2023-05-26 01:22:09.068849: train Epoch: [66][  1/129]	Time  0.981 ( 3.172)	Data  0.002 ( 2.174)	Loss 5.2215e-02 (4.9458e-02) 
2023-05-26 01:22:12.098495: train Epoch: [66][  2/129]	Time  3.030 ( 3.124)	Data  2.022 ( 2.123)	Loss 4.7900e-02 (4.8939e-02) 
2023-05-26 01:22:13.065174: train Epoch: [66][  3/129]	Time  0.967 ( 2.585)	Data  0.001 ( 1.593)	Loss 7.1540e-02 (5.4589e-02) 
2023-05-26 01:22:16.063553: train Epoch: [66][  4/129]	Time  2.998 ( 2.668)	Data  2.025 ( 1.679)	Loss 8.5139e-02 (6.0699e-02) 
2023-05-26 01:22:17.032481: train Epoch: [66][  5/129]	Time  0.969 ( 2.385)	Data  0.001 ( 1.400)	Loss 5.3804e-02 (5.9550e-02) 
2023-05-26 01:22:20.010569: train Epoch: [66][  6/129]	Time  2.978 ( 2.469)	Data  2.003 ( 1.486)	Loss 6.6241e-02 (6.0506e-02) 
2023-05-26 01:22:20.996574: train Epoch: [66][  7/129]	Time  0.986 ( 2.284)	Data  0.001 ( 1.300)	Loss 6.1281e-02 (6.0603e-02) 
2023-05-26 01:22:24.014987: train Epoch: [66][  8/129]	Time  3.018 ( 2.366)	Data  2.048 ( 1.383)	Loss 6.2869e-02 (6.0855e-02) 
2023-05-26 01:22:24.983798: train Epoch: [66][  9/129]	Time  0.969 ( 2.226)	Data  0.001 ( 1.245)	Loss 6.1458e-02 (6.0915e-02) 
2023-05-26 01:22:28.185424: train Epoch: [66][ 10/129]	Time  3.202 ( 2.315)	Data  2.237 ( 1.335)	Loss 6.6399e-02 (6.1413e-02) 
2023-05-26 01:22:29.151281: train Epoch: [66][ 11/129]	Time  0.966 ( 2.202)	Data  0.001 ( 1.224)	Loss 6.2714e-02 (6.1522e-02) 
2023-05-26 01:22:32.360225: train Epoch: [66][ 12/129]	Time  3.209 ( 2.280)	Data  2.246 ( 1.303)	Loss 8.4142e-02 (6.3262e-02) 
2023-05-26 01:22:33.324555: train Epoch: [66][ 13/129]	Time  0.964 ( 2.186)	Data  0.001 ( 1.210)	Loss 5.4255e-02 (6.2619e-02) 
2023-05-26 01:22:36.361129: train Epoch: [66][ 14/129]	Time  3.037 ( 2.242)	Data  2.073 ( 1.267)	Loss 1.0436e-01 (6.5402e-02) 
2023-05-26 01:22:37.334134: train Epoch: [66][ 15/129]	Time  0.973 ( 2.163)	Data  0.002 ( 1.188)	Loss 4.0190e-02 (6.3826e-02) 
2023-05-26 01:22:40.479872: train Epoch: [66][ 16/129]	Time  3.146 ( 2.221)	Data  2.159 ( 1.245)	Loss 5.4802e-02 (6.3295e-02) 
2023-05-26 01:22:41.454946: train Epoch: [66][ 17/129]	Time  0.975 ( 2.152)	Data  0.001 ( 1.176)	Loss 5.8846e-02 (6.3048e-02) 
2023-05-26 01:22:44.474064: train Epoch: [66][ 18/129]	Time  3.019 ( 2.197)	Data  2.053 ( 1.222)	Loss 6.3018e-02 (6.3046e-02) 
2023-05-26 01:22:45.438427: train Epoch: [66][ 19/129]	Time  0.964 ( 2.136)	Data  0.001 ( 1.161)	Loss 6.2134e-02 (6.3001e-02) 
2023-05-26 01:22:48.521705: train Epoch: [66][ 20/129]	Time  3.083 ( 2.181)	Data  2.114 ( 1.207)	Loss 6.3527e-02 (6.3026e-02) 
2023-05-26 01:22:49.498567: train Epoch: [66][ 21/129]	Time  0.977 ( 2.126)	Data  0.001 ( 1.152)	Loss 8.3970e-02 (6.3978e-02) 
2023-05-26 01:22:52.609900: train Epoch: [66][ 22/129]	Time  3.111 ( 2.169)	Data  2.138 ( 1.195)	Loss 5.8890e-02 (6.3757e-02) 
2023-05-26 01:22:53.598691: train Epoch: [66][ 23/129]	Time  0.989 ( 2.120)	Data  0.001 ( 1.145)	Loss 8.0489e-02 (6.4454e-02) 
2023-05-26 01:22:56.711828: train Epoch: [66][ 24/129]	Time  3.113 ( 2.159)	Data  2.132 ( 1.184)	Loss 6.4893e-02 (6.4471e-02) 
2023-05-26 01:22:57.685992: train Epoch: [66][ 25/129]	Time  0.974 ( 2.114)	Data  0.001 ( 1.139)	Loss 7.0197e-02 (6.4692e-02) 
2023-05-26 01:23:00.960923: train Epoch: [66][ 26/129]	Time  3.275 ( 2.157)	Data  2.312 ( 1.182)	Loss 9.1336e-02 (6.5678e-02) 
2023-05-26 01:23:01.943803: train Epoch: [66][ 27/129]	Time  0.983 ( 2.115)	Data  0.001 ( 1.140)	Loss 5.9401e-02 (6.5454e-02) 
2023-05-26 01:23:05.002604: train Epoch: [66][ 28/129]	Time  3.059 ( 2.147)	Data  2.081 ( 1.173)	Loss 7.5236e-02 (6.5791e-02) 
2023-05-26 01:23:05.983174: train Epoch: [66][ 29/129]	Time  0.981 ( 2.109)	Data  0.001 ( 1.134)	Loss 5.7335e-02 (6.5510e-02) 
2023-05-26 01:23:09.032549: train Epoch: [66][ 30/129]	Time  3.049 ( 2.139)	Data  2.084 ( 1.164)	Loss 7.2594e-02 (6.5738e-02) 
2023-05-26 01:23:10.008472: train Epoch: [66][ 31/129]	Time  0.976 ( 2.103)	Data  0.001 ( 1.128)	Loss 4.8599e-02 (6.5203e-02) 
2023-05-26 01:23:13.004871: train Epoch: [66][ 32/129]	Time  2.996 ( 2.130)	Data  2.024 ( 1.155)	Loss 6.1921e-02 (6.5103e-02) 
2023-05-26 01:23:13.993419: train Epoch: [66][ 33/129]	Time  0.989 ( 2.096)	Data  0.002 ( 1.121)	Loss 6.7374e-02 (6.5170e-02) 
2023-05-26 01:23:17.024839: train Epoch: [66][ 34/129]	Time  3.031 ( 2.123)	Data  2.045 ( 1.148)	Loss 1.1584e-01 (6.6618e-02) 
2023-05-26 01:23:18.001036: train Epoch: [66][ 35/129]	Time  0.976 ( 2.091)	Data  0.001 ( 1.116)	Loss 6.3087e-02 (6.6520e-02) 
2023-05-26 01:23:21.043029: train Epoch: [66][ 36/129]	Time  3.042 ( 2.117)	Data  2.073 ( 1.142)	Loss 9.0519e-02 (6.7168e-02) 
2023-05-26 01:23:22.028294: train Epoch: [66][ 37/129]	Time  0.985 ( 2.087)	Data  0.002 ( 1.112)	Loss 6.2681e-02 (6.7050e-02) 
2023-05-26 01:23:24.987819: train Epoch: [66][ 38/129]	Time  2.960 ( 2.109)	Data  1.987 ( 1.134)	Loss 1.1589e-01 (6.8302e-02) 
2023-05-26 01:23:25.955866: train Epoch: [66][ 39/129]	Time  0.968 ( 2.081)	Data  0.001 ( 1.106)	Loss 4.3907e-02 (6.7693e-02) 
2023-05-26 01:23:28.963634: train Epoch: [66][ 40/129]	Time  3.008 ( 2.103)	Data  2.043 ( 1.129)	Loss 6.6265e-02 (6.7658e-02) 
2023-05-26 01:23:29.939715: train Epoch: [66][ 41/129]	Time  0.976 ( 2.077)	Data  0.001 ( 1.102)	Loss 6.1760e-02 (6.7517e-02) 
2023-05-26 01:23:33.011497: train Epoch: [66][ 42/129]	Time  3.072 ( 2.100)	Data  2.100 ( 1.125)	Loss 7.7965e-02 (6.7760e-02) 
2023-05-26 01:23:33.986624: train Epoch: [66][ 43/129]	Time  0.975 ( 2.074)	Data  0.001 ( 1.099)	Loss 4.5898e-02 (6.7263e-02) 
2023-05-26 01:23:37.105359: train Epoch: [66][ 44/129]	Time  3.119 ( 2.097)	Data  2.157 ( 1.123)	Loss 7.0378e-02 (6.7333e-02) 
2023-05-26 01:23:38.070879: train Epoch: [66][ 45/129]	Time  0.966 ( 2.073)	Data  0.001 ( 1.098)	Loss 6.5128e-02 (6.7285e-02) 
2023-05-26 01:23:41.201920: train Epoch: [66][ 46/129]	Time  3.131 ( 2.095)	Data  2.161 ( 1.121)	Loss 7.5636e-02 (6.7462e-02) 
2023-05-26 01:23:42.167291: train Epoch: [66][ 47/129]	Time  0.965 ( 2.072)	Data  0.001 ( 1.098)	Loss 1.1518e-01 (6.8457e-02) 
2023-05-26 01:23:45.182657: train Epoch: [66][ 48/129]	Time  3.015 ( 2.091)	Data  2.050 ( 1.117)	Loss 6.1280e-02 (6.8310e-02) 
2023-05-26 01:23:46.161497: train Epoch: [66][ 49/129]	Time  0.979 ( 2.069)	Data  0.001 ( 1.095)	Loss 6.2160e-02 (6.8187e-02) 
2023-05-26 01:23:49.300422: train Epoch: [66][ 50/129]	Time  3.139 ( 2.090)	Data  2.155 ( 1.116)	Loss 5.8059e-02 (6.7988e-02) 
2023-05-26 01:23:50.290222: train Epoch: [66][ 51/129]	Time  0.990 ( 2.069)	Data  0.001 ( 1.094)	Loss 6.1564e-02 (6.7865e-02) 
2023-05-26 01:23:53.313877: train Epoch: [66][ 52/129]	Time  3.024 ( 2.087)	Data  2.062 ( 1.112)	Loss 9.0048e-02 (6.8283e-02) 
2023-05-26 01:23:54.286194: train Epoch: [66][ 53/129]	Time  0.972 ( 2.066)	Data  0.001 ( 1.092)	Loss 7.0768e-02 (6.8329e-02) 
2023-05-26 01:23:57.418177: train Epoch: [66][ 54/129]	Time  3.132 ( 2.085)	Data  2.152 ( 1.111)	Loss 8.3896e-02 (6.8613e-02) 
2023-05-26 01:23:58.396199: train Epoch: [66][ 55/129]	Time  0.978 ( 2.066)	Data  0.001 ( 1.091)	Loss 6.8456e-02 (6.8610e-02) 
2023-05-26 01:24:01.579594: train Epoch: [66][ 56/129]	Time  3.183 ( 2.085)	Data  2.208 ( 1.111)	Loss 5.7736e-02 (6.8419e-02) 
2023-05-26 01:24:02.551995: train Epoch: [66][ 57/129]	Time  0.972 ( 2.066)	Data  0.001 ( 1.092)	Loss 3.1824e-02 (6.7788e-02) 
2023-05-26 01:24:05.692398: train Epoch: [66][ 58/129]	Time  3.140 ( 2.084)	Data  2.171 ( 1.110)	Loss 7.1273e-02 (6.7847e-02) 
2023-05-26 01:24:06.656464: train Epoch: [66][ 59/129]	Time  0.964 ( 2.066)	Data  0.001 ( 1.092)	Loss 5.6940e-02 (6.7665e-02) 
2023-05-26 01:24:09.686574: train Epoch: [66][ 60/129]	Time  3.030 ( 2.081)	Data  2.069 ( 1.108)	Loss 7.4665e-02 (6.7780e-02) 
2023-05-26 01:24:10.651107: train Epoch: [66][ 61/129]	Time  0.965 ( 2.063)	Data  0.001 ( 1.090)	Loss 8.3570e-02 (6.8035e-02) 
2023-05-26 01:24:13.749230: train Epoch: [66][ 62/129]	Time  3.098 ( 2.080)	Data  2.129 ( 1.106)	Loss 5.2459e-02 (6.7787e-02) 
2023-05-26 01:24:14.708753: train Epoch: [66][ 63/129]	Time  0.960 ( 2.062)	Data  0.001 ( 1.089)	Loss 8.2210e-02 (6.8013e-02) 
2023-05-26 01:24:17.729393: train Epoch: [66][ 64/129]	Time  3.021 ( 2.077)	Data  2.056 ( 1.104)	Loss 6.5851e-02 (6.7980e-02) 
2023-05-26 01:24:18.705302: train Epoch: [66][ 65/129]	Time  0.976 ( 2.060)	Data  0.001 ( 1.087)	Loss 6.4389e-02 (6.7925e-02) 
2023-05-26 01:24:21.738009: train Epoch: [66][ 66/129]	Time  3.033 ( 2.075)	Data  2.069 ( 1.102)	Loss 1.2183e-01 (6.8730e-02) 
2023-05-26 01:24:22.704725: train Epoch: [66][ 67/129]	Time  0.967 ( 2.059)	Data  0.001 ( 1.086)	Loss 5.6031e-02 (6.8543e-02) 
2023-05-26 01:24:25.775694: train Epoch: [66][ 68/129]	Time  3.071 ( 2.073)	Data  2.106 ( 1.100)	Loss 6.3443e-02 (6.8469e-02) 
2023-05-26 01:24:26.743195: train Epoch: [66][ 69/129]	Time  0.967 ( 2.057)	Data  0.001 ( 1.085)	Loss 6.6993e-02 (6.8448e-02) 
2023-05-26 01:24:29.877059: train Epoch: [66][ 70/129]	Time  3.134 ( 2.073)	Data  2.164 ( 1.100)	Loss 6.8240e-02 (6.8445e-02) 
2023-05-26 01:24:30.841999: train Epoch: [66][ 71/129]	Time  0.965 ( 2.057)	Data  0.001 ( 1.085)	Loss 5.5419e-02 (6.8264e-02) 
2023-05-26 01:24:33.966465: train Epoch: [66][ 72/129]	Time  3.124 ( 2.072)	Data  2.159 ( 1.099)	Loss 5.0723e-02 (6.8024e-02) 
2023-05-26 01:24:34.947196: train Epoch: [66][ 73/129]	Time  0.981 ( 2.057)	Data  0.001 ( 1.085)	Loss 1.0133e-01 (6.8474e-02) 
2023-05-26 01:24:38.008773: train Epoch: [66][ 74/129]	Time  3.062 ( 2.070)	Data  2.081 ( 1.098)	Loss 5.8910e-02 (6.8346e-02) 
2023-05-26 01:24:38.996429: train Epoch: [66][ 75/129]	Time  0.988 ( 2.056)	Data  0.001 ( 1.083)	Loss 6.2108e-02 (6.8264e-02) 
2023-05-26 01:24:41.996414: train Epoch: [66][ 76/129]	Time  3.000 ( 2.068)	Data  2.020 ( 1.096)	Loss 4.1459e-02 (6.7916e-02) 
2023-05-26 01:24:42.977929: train Epoch: [66][ 77/129]	Time  0.982 ( 2.055)	Data  0.002 ( 1.082)	Loss 8.0887e-02 (6.8082e-02) 
2023-05-26 01:24:45.932264: train Epoch: [66][ 78/129]	Time  2.954 ( 2.066)	Data  1.997 ( 1.093)	Loss 7.4078e-02 (6.8158e-02) 
2023-05-26 01:24:46.907435: train Epoch: [66][ 79/129]	Time  0.975 ( 2.052)	Data  0.001 ( 1.080)	Loss 7.1923e-02 (6.8205e-02) 
2023-05-26 01:24:50.058568: train Epoch: [66][ 80/129]	Time  3.151 ( 2.066)	Data  2.187 ( 1.093)	Loss 6.1563e-02 (6.8123e-02) 
2023-05-26 01:24:51.028461: train Epoch: [66][ 81/129]	Time  0.970 ( 2.052)	Data  0.001 ( 1.080)	Loss 6.9188e-02 (6.8136e-02) 
2023-05-26 01:24:54.065657: train Epoch: [66][ 82/129]	Time  3.037 ( 2.064)	Data  2.080 ( 1.092)	Loss 7.2467e-02 (6.8189e-02) 
2023-05-26 01:24:55.030663: train Epoch: [66][ 83/129]	Time  0.965 ( 2.051)	Data  0.001 ( 1.079)	Loss 8.5574e-02 (6.8395e-02) 
2023-05-26 01:24:57.804512: train Epoch: [66][ 84/129]	Time  2.774 ( 2.060)	Data  1.817 ( 1.088)	Loss 6.1149e-02 (6.8310e-02) 
2023-05-26 01:24:58.762499: train Epoch: [66][ 85/129]	Time  0.958 ( 2.047)	Data  0.001 ( 1.075)	Loss 6.2124e-02 (6.8238e-02) 
2023-05-26 01:25:01.523294: train Epoch: [66][ 86/129]	Time  2.761 ( 2.055)	Data  1.804 ( 1.083)	Loss 1.0748e-01 (6.8689e-02) 
2023-05-26 01:25:02.481143: train Epoch: [66][ 87/129]	Time  0.958 ( 2.043)	Data  0.001 ( 1.071)	Loss 6.4294e-02 (6.8639e-02) 
2023-05-26 01:25:05.198109: train Epoch: [66][ 88/129]	Time  2.717 ( 2.050)	Data  1.761 ( 1.079)	Loss 6.9898e-02 (6.8654e-02) 
2023-05-26 01:25:06.147694: train Epoch: [66][ 89/129]	Time  0.950 ( 2.038)	Data  0.001 ( 1.067)	Loss 9.2286e-02 (6.8916e-02) 
2023-05-26 01:25:08.777310: train Epoch: [66][ 90/129]	Time  2.630 ( 2.045)	Data  1.684 ( 1.074)	Loss 6.6788e-02 (6.8893e-02) 
2023-05-26 01:25:09.726551: train Epoch: [66][ 91/129]	Time  0.949 ( 2.033)	Data  0.001 ( 1.062)	Loss 3.8799e-02 (6.8566e-02) 
2023-05-26 01:25:12.335719: train Epoch: [66][ 92/129]	Time  2.609 ( 2.039)	Data  1.661 ( 1.068)	Loss 4.4139e-02 (6.8303e-02) 
2023-05-26 01:25:13.285150: train Epoch: [66][ 93/129]	Time  0.949 ( 2.027)	Data  0.001 ( 1.057)	Loss 7.6524e-02 (6.8390e-02) 
2023-05-26 01:25:16.030621: train Epoch: [66][ 94/129]	Time  2.745 ( 2.035)	Data  1.798 ( 1.065)	Loss 1.8802e-01 (6.9650e-02) 
2023-05-26 01:25:16.980572: train Epoch: [66][ 95/129]	Time  0.950 ( 2.023)	Data  0.001 ( 1.054)	Loss 5.2459e-02 (6.9471e-02) 
2023-05-26 01:25:19.795037: train Epoch: [66][ 96/129]	Time  2.814 ( 2.032)	Data  1.858 ( 1.062)	Loss 1.1191e-01 (6.9908e-02) 
2023-05-26 01:25:20.756740: train Epoch: [66][ 97/129]	Time  0.962 ( 2.021)	Data  0.001 ( 1.051)	Loss 5.4657e-02 (6.9753e-02) 
2023-05-26 01:25:23.396824: train Epoch: [66][ 98/129]	Time  2.640 ( 2.027)	Data  1.693 ( 1.058)	Loss 6.6099e-02 (6.9716e-02) 
2023-05-26 01:25:24.349229: train Epoch: [66][ 99/129]	Time  0.952 ( 2.016)	Data  0.001 ( 1.047)	Loss 9.6450e-02 (6.9983e-02) 
2023-05-26 01:25:27.120852: train Epoch: [66][100/129]	Time  2.772 ( 2.024)	Data  1.825 ( 1.055)	Loss 7.2561e-02 (7.0009e-02) 
2023-05-26 01:25:28.083829: train Epoch: [66][101/129]	Time  0.963 ( 2.013)	Data  0.001 ( 1.044)	Loss 7.2645e-02 (7.0034e-02) 
2023-05-26 01:25:30.940303: train Epoch: [66][102/129]	Time  2.856 ( 2.021)	Data  1.890 ( 1.053)	Loss 7.1818e-02 (7.0052e-02) 
2023-05-26 01:25:31.903566: train Epoch: [66][103/129]	Time  0.963 ( 2.011)	Data  0.001 ( 1.043)	Loss 1.2604e-01 (7.0590e-02) 
2023-05-26 01:25:34.751462: train Epoch: [66][104/129]	Time  2.848 ( 2.019)	Data  1.890 ( 1.051)	Loss 5.5189e-02 (7.0443e-02) 
2023-05-26 01:25:35.713420: train Epoch: [66][105/129]	Time  0.962 ( 2.009)	Data  0.001 ( 1.041)	Loss 4.0687e-02 (7.0163e-02) 
2023-05-26 01:25:38.412269: train Epoch: [66][106/129]	Time  2.699 ( 2.016)	Data  1.742 ( 1.047)	Loss 5.5819e-02 (7.0029e-02) 
2023-05-26 01:25:39.376685: train Epoch: [66][107/129]	Time  0.964 ( 2.006)	Data  0.001 ( 1.038)	Loss 7.5187e-02 (7.0076e-02) 
2023-05-26 01:25:42.539537: train Epoch: [66][108/129]	Time  3.163 ( 2.017)	Data  2.182 ( 1.048)	Loss 6.5576e-02 (7.0035e-02) 
2023-05-26 01:25:43.517644: train Epoch: [66][109/129]	Time  0.978 ( 2.007)	Data  0.001 ( 1.039)	Loss 7.0844e-02 (7.0042e-02) 
2023-05-26 01:25:46.550704: train Epoch: [66][110/129]	Time  3.033 ( 2.016)	Data  2.069 ( 1.048)	Loss 9.1855e-02 (7.0239e-02) 
2023-05-26 01:25:47.530793: train Epoch: [66][111/129]	Time  0.980 ( 2.007)	Data  0.001 ( 1.039)	Loss 5.4688e-02 (7.0100e-02) 
2023-05-26 01:25:50.668379: train Epoch: [66][112/129]	Time  3.138 ( 2.017)	Data  2.179 ( 1.049)	Loss 5.1245e-02 (6.9933e-02) 
2023-05-26 01:25:51.644257: train Epoch: [66][113/129]	Time  0.976 ( 2.008)	Data  0.001 ( 1.039)	Loss 4.7413e-02 (6.9736e-02) 
2023-05-26 01:25:54.716435: train Epoch: [66][114/129]	Time  3.072 ( 2.017)	Data  2.106 ( 1.049)	Loss 4.4583e-02 (6.9517e-02) 
2023-05-26 01:25:55.696494: train Epoch: [66][115/129]	Time  0.980 ( 2.008)	Data  0.001 ( 1.040)	Loss 8.8437e-02 (6.9680e-02) 
2023-05-26 01:25:58.833729: train Epoch: [66][116/129]	Time  3.137 ( 2.018)	Data  2.161 ( 1.049)	Loss 6.9386e-02 (6.9678e-02) 
2023-05-26 01:25:59.801725: train Epoch: [66][117/129]	Time  0.968 ( 2.009)	Data  0.001 ( 1.040)	Loss 1.4198e-01 (7.0290e-02) 
2023-05-26 01:26:02.829731: train Epoch: [66][118/129]	Time  3.028 ( 2.018)	Data  2.057 ( 1.049)	Loss 6.4173e-02 (7.0239e-02) 
2023-05-26 01:26:03.798497: train Epoch: [66][119/129]	Time  0.969 ( 2.009)	Data  0.001 ( 1.040)	Loss 7.5009e-02 (7.0279e-02) 
2023-05-26 01:26:06.828180: train Epoch: [66][120/129]	Time  3.030 ( 2.017)	Data  2.065 ( 1.049)	Loss 9.8482e-02 (7.0512e-02) 
2023-05-26 01:26:07.798129: train Epoch: [66][121/129]	Time  0.970 ( 2.009)	Data  0.001 ( 1.040)	Loss 9.0935e-02 (7.0679e-02) 
2023-05-26 01:26:10.948534: train Epoch: [66][122/129]	Time  3.150 ( 2.018)	Data  2.174 ( 1.049)	Loss 8.9084e-02 (7.0829e-02) 
2023-05-26 01:26:11.911395: train Epoch: [66][123/129]	Time  0.963 ( 2.010)	Data  0.001 ( 1.041)	Loss 5.6039e-02 (7.0709e-02) 
2023-05-26 01:26:15.008111: train Epoch: [66][124/129]	Time  3.097 ( 2.018)	Data  2.121 ( 1.049)	Loss 8.3956e-02 (7.0815e-02) 
2023-05-26 01:26:15.990695: train Epoch: [66][125/129]	Time  0.983 ( 2.010)	Data  0.001 ( 1.041)	Loss 1.0301e-01 (7.1071e-02) 
2023-05-26 01:26:18.840921: train Epoch: [66][126/129]	Time  2.850 ( 2.017)	Data  1.885 ( 1.048)	Loss 6.5518e-02 (7.1027e-02) 
2023-05-26 01:26:19.809817: train Epoch: [66][127/129]	Time  0.969 ( 2.008)	Data  0.001 ( 1.040)	Loss 1.0077e-01 (7.1260e-02) 
2023-05-26 01:26:21.887266: train Epoch: [66][128/129]	Time  2.077 ( 2.009)	Data  1.110 ( 1.040)	Loss 8.2738e-02 (7.1349e-02) 
2023-05-26 01:26:21.965516: Train Epoch done in 259.2406342619979 s 
2023-05-26 01:26:24.716273: val Epoch: [66][ 0/72]	Time  1.880 ( 1.880)	Data  1.612 ( 1.612)	Loss 1.2554e-01 (1.2554e-01) 
2023-05-26 01:26:24.847241: val Epoch: [66][ 1/72]	Time  0.131 ( 1.006)	Data  0.002 ( 0.807)	Loss 7.3052e-02 (9.9294e-02) 
2023-05-26 01:26:25.905281: val Epoch: [66][ 2/72]	Time  1.058 ( 1.023)	Data  0.921 ( 0.845)	Loss 4.8597e-02 (8.2395e-02) 
2023-05-26 01:26:26.041284: val Epoch: [66][ 3/72]	Time  0.136 ( 0.801)	Data  0.001 ( 0.634)	Loss 5.2215e-02 (7.4850e-02) 
2023-05-26 01:26:27.362470: val Epoch: [66][ 4/72]	Time  1.321 ( 0.905)	Data  1.193 ( 0.746)	Loss 8.3930e-02 (7.6666e-02) 
2023-05-26 01:26:27.506267: val Epoch: [66][ 5/72]	Time  0.144 ( 0.778)	Data  0.001 ( 0.622)	Loss 1.6073e-01 (9.0677e-02) 
2023-05-26 01:26:28.738797: val Epoch: [66][ 6/72]	Time  1.233 ( 0.843)	Data  1.104 ( 0.691)	Loss 8.2118e-02 (8.9454e-02) 
2023-05-26 01:26:28.880876: val Epoch: [66][ 7/72]	Time  0.142 ( 0.756)	Data  0.001 ( 0.604)	Loss 5.2838e-02 (8.4877e-02) 
2023-05-26 01:26:30.136058: val Epoch: [66][ 8/72]	Time  1.255 ( 0.811)	Data  1.111 ( 0.661)	Loss 1.1673e-01 (8.8417e-02) 
2023-05-26 01:26:30.270277: val Epoch: [66][ 9/72]	Time  0.134 ( 0.743)	Data  0.001 ( 0.595)	Loss 6.4683e-02 (8.6043e-02) 
2023-05-26 01:26:31.496915: val Epoch: [66][10/72]	Time  1.227 ( 0.787)	Data  1.085 ( 0.639)	Loss 1.0471e-01 (8.7741e-02) 
2023-05-26 01:26:31.626778: val Epoch: [66][11/72]	Time  0.130 ( 0.733)	Data  0.001 ( 0.586)	Loss 3.6549e-02 (8.3475e-02) 
2023-05-26 01:26:32.828006: val Epoch: [66][12/72]	Time  1.201 ( 0.769)	Data  1.066 ( 0.623)	Loss 1.7270e-01 (9.0338e-02) 
2023-05-26 01:26:32.958334: val Epoch: [66][13/72]	Time  0.130 ( 0.723)	Data  0.001 ( 0.578)	Loss 6.6992e-02 (8.8670e-02) 
2023-05-26 01:26:34.230888: val Epoch: [66][14/72]	Time  1.273 ( 0.760)	Data  1.128 ( 0.615)	Loss 3.1765e-01 (1.0394e-01) 
2023-05-26 01:26:34.372577: val Epoch: [66][15/72]	Time  0.142 ( 0.721)	Data  0.001 ( 0.577)	Loss 2.0511e-01 (1.1026e-01) 
2023-05-26 01:26:35.608049: val Epoch: [66][16/72]	Time  1.235 ( 0.751)	Data  1.088 ( 0.607)	Loss 4.0168e-01 (1.2740e-01) 
2023-05-26 01:26:35.748546: val Epoch: [66][17/72]	Time  0.140 ( 0.717)	Data  0.001 ( 0.573)	Loss 2.6172e-01 (1.3486e-01) 
2023-05-26 01:26:36.917614: val Epoch: [66][18/72]	Time  1.169 ( 0.741)	Data  1.031 ( 0.597)	Loss 1.3048e-01 (1.3463e-01) 
2023-05-26 01:26:37.053690: val Epoch: [66][19/72]	Time  0.136 ( 0.711)	Data  0.001 ( 0.567)	Loss 4.2660e-02 (1.3003e-01) 
2023-05-26 01:26:38.228628: val Epoch: [66][20/72]	Time  1.175 ( 0.733)	Data  1.044 ( 0.590)	Loss 3.8351e-01 (1.4210e-01) 
2023-05-26 01:26:38.427281: val Epoch: [66][21/72]	Time  0.199 ( 0.709)	Data  0.058 ( 0.566)	Loss 6.9265e-02 (1.3879e-01) 
2023-05-26 01:26:39.498529: val Epoch: [66][22/72]	Time  1.071 ( 0.724)	Data  0.934 ( 0.582)	Loss 6.4468e-02 (1.3556e-01) 
2023-05-26 01:26:39.768568: val Epoch: [66][23/72]	Time  0.270 ( 0.706)	Data  0.136 ( 0.563)	Loss 6.1140e-02 (1.3246e-01) 
2023-05-26 01:26:40.813306: val Epoch: [66][24/72]	Time  1.045 ( 0.719)	Data  0.911 ( 0.577)	Loss 2.2398e-01 (1.3612e-01) 
2023-05-26 01:26:41.134558: val Epoch: [66][25/72]	Time  0.321 ( 0.704)	Data  0.180 ( 0.562)	Loss 5.3526e-02 (1.3294e-01) 
2023-05-26 01:26:42.149853: val Epoch: [66][26/72]	Time  1.015 ( 0.715)	Data  0.875 ( 0.574)	Loss 5.8673e-02 (1.3019e-01) 
2023-05-26 01:26:42.457924: val Epoch: [66][27/72]	Time  0.308 ( 0.701)	Data  0.166 ( 0.559)	Loss 5.0616e-02 (1.2735e-01) 
2023-05-26 01:26:43.514893: val Epoch: [66][28/72]	Time  1.057 ( 0.713)	Data  0.915 ( 0.571)	Loss 4.6077e-02 (1.2455e-01) 
2023-05-26 01:26:43.800882: val Epoch: [66][29/72]	Time  0.286 ( 0.699)	Data  0.154 ( 0.557)	Loss 8.9092e-02 (1.2337e-01) 
2023-05-26 01:26:44.798652: val Epoch: [66][30/72]	Time  0.998 ( 0.708)	Data  0.867 ( 0.567)	Loss 4.0846e-02 (1.2071e-01) 
2023-05-26 01:26:45.089174: val Epoch: [66][31/72]	Time  0.291 ( 0.695)	Data  0.162 ( 0.555)	Loss 9.7491e-02 (1.1998e-01) 
2023-05-26 01:26:46.129513: val Epoch: [66][32/72]	Time  1.040 ( 0.706)	Data  0.909 ( 0.565)	Loss 3.3853e-02 (1.1737e-01) 
2023-05-26 01:26:46.429933: val Epoch: [66][33/72]	Time  0.300 ( 0.694)	Data  0.160 ( 0.553)	Loss 1.3135e-01 (1.1778e-01) 
2023-05-26 01:26:47.501697: val Epoch: [66][34/72]	Time  1.072 ( 0.705)	Data  0.929 ( 0.564)	Loss 2.6762e-01 (1.2206e-01) 
2023-05-26 01:26:47.809941: val Epoch: [66][35/72]	Time  0.308 ( 0.694)	Data  0.175 ( 0.553)	Loss 1.7822e-01 (1.2362e-01) 
2023-05-26 01:26:48.867960: val Epoch: [66][36/72]	Time  1.058 ( 0.704)	Data  0.918 ( 0.563)	Loss 8.7969e-02 (1.2266e-01) 
2023-05-26 01:26:49.158405: val Epoch: [66][37/72]	Time  0.290 ( 0.693)	Data  0.160 ( 0.553)	Loss 1.3219e-01 (1.2291e-01) 
2023-05-26 01:26:50.231527: val Epoch: [66][38/72]	Time  1.073 ( 0.702)	Data  0.941 ( 0.563)	Loss 1.3071e-01 (1.2311e-01) 
2023-05-26 01:26:50.505665: val Epoch: [66][39/72]	Time  0.274 ( 0.692)	Data  0.139 ( 0.552)	Loss 3.3737e-02 (1.2088e-01) 
2023-05-26 01:26:51.637076: val Epoch: [66][40/72]	Time  1.131 ( 0.702)	Data  0.989 ( 0.563)	Loss 9.4576e-02 (1.2023e-01) 
2023-05-26 01:26:51.913459: val Epoch: [66][41/72]	Time  0.276 ( 0.692)	Data  0.146 ( 0.553)	Loss 1.6341e-01 (1.2126e-01) 
2023-05-26 01:26:52.980319: val Epoch: [66][42/72]	Time  1.067 ( 0.701)	Data  0.927 ( 0.561)	Loss 7.7812e-02 (1.2025e-01) 
2023-05-26 01:26:53.218380: val Epoch: [66][43/72]	Time  0.238 ( 0.691)	Data  0.109 ( 0.551)	Loss 4.8410e-02 (1.1862e-01) 
2023-05-26 01:26:54.299674: val Epoch: [66][44/72]	Time  1.081 ( 0.699)	Data  0.949 ( 0.560)	Loss 8.4334e-02 (1.1786e-01) 
2023-05-26 01:26:54.606298: val Epoch: [66][45/72]	Time  0.307 ( 0.691)	Data  0.169 ( 0.551)	Loss 6.3658e-02 (1.1668e-01) 
2023-05-26 01:26:55.553757: val Epoch: [66][46/72]	Time  0.947 ( 0.696)	Data  0.816 ( 0.557)	Loss 3.7632e-02 (1.1500e-01) 
2023-05-26 01:26:55.964655: val Epoch: [66][47/72]	Time  0.411 ( 0.690)	Data  0.281 ( 0.551)	Loss 4.8800e-02 (1.1362e-01) 
2023-05-26 01:26:57.002083: val Epoch: [66][48/72]	Time  1.037 ( 0.697)	Data  0.908 ( 0.559)	Loss 5.9730e-02 (1.1252e-01) 
2023-05-26 01:26:57.305268: val Epoch: [66][49/72]	Time  0.303 ( 0.689)	Data  0.174 ( 0.551)	Loss 3.3349e-02 (1.1093e-01) 
2023-05-26 01:26:58.311071: val Epoch: [66][50/72]	Time  1.006 ( 0.696)	Data  0.877 ( 0.557)	Loss 7.4807e-02 (1.1023e-01) 
2023-05-26 01:26:58.625965: val Epoch: [66][51/72]	Time  0.315 ( 0.688)	Data  0.181 ( 0.550)	Loss 4.3353e-02 (1.0894e-01) 
2023-05-26 01:26:59.703426: val Epoch: [66][52/72]	Time  1.077 ( 0.696)	Data  0.936 ( 0.557)	Loss 9.3396e-02 (1.0865e-01) 
2023-05-26 01:26:59.998376: val Epoch: [66][53/72]	Time  0.295 ( 0.688)	Data  0.153 ( 0.550)	Loss 4.7813e-01 (1.1549e-01) 
2023-05-26 01:27:01.020923: val Epoch: [66][54/72]	Time  1.023 ( 0.694)	Data  0.886 ( 0.556)	Loss 5.4626e-02 (1.1438e-01) 
2023-05-26 01:27:01.308592: val Epoch: [66][55/72]	Time  0.288 ( 0.687)	Data  0.147 ( 0.549)	Loss 4.5234e-02 (1.1315e-01) 
2023-05-26 01:27:02.445355: val Epoch: [66][56/72]	Time  1.137 ( 0.695)	Data  1.003 ( 0.557)	Loss 1.0319e-01 (1.1297e-01) 
2023-05-26 01:27:02.658393: val Epoch: [66][57/72]	Time  0.213 ( 0.687)	Data  0.077 ( 0.548)	Loss 4.4278e-02 (1.1179e-01) 
2023-05-26 01:27:03.811013: val Epoch: [66][58/72]	Time  1.153 ( 0.694)	Data  1.019 ( 0.556)	Loss 5.5830e-02 (1.1084e-01) 
2023-05-26 01:27:04.000682: val Epoch: [66][59/72]	Time  0.190 ( 0.686)	Data  0.059 ( 0.548)	Loss 6.3183e-02 (1.1005e-01) 
2023-05-26 01:27:05.220699: val Epoch: [66][60/72]	Time  1.220 ( 0.695)	Data  1.086 ( 0.557)	Loss 3.0547e-01 (1.1325e-01) 
2023-05-26 01:27:05.436050: val Epoch: [66][61/72]	Time  0.215 ( 0.687)	Data  0.084 ( 0.549)	Loss 3.6065e-01 (1.1724e-01) 
2023-05-26 01:27:06.605937: val Epoch: [66][62/72]	Time  1.170 ( 0.695)	Data  1.039 ( 0.557)	Loss 3.2132e-01 (1.2048e-01) 
2023-05-26 01:27:06.790462: val Epoch: [66][63/72]	Time  0.185 ( 0.687)	Data  0.055 ( 0.549)	Loss 7.4493e-02 (1.1976e-01) 
2023-05-26 01:27:07.933886: val Epoch: [66][64/72]	Time  1.143 ( 0.694)	Data  1.008 ( 0.556)	Loss 3.4500e-02 (1.1845e-01) 
2023-05-26 01:27:08.181131: val Epoch: [66][65/72]	Time  0.247 ( 0.687)	Data  0.117 ( 0.550)	Loss 8.2745e-02 (1.1791e-01) 
2023-05-26 01:27:09.297960: val Epoch: [66][66/72]	Time  1.117 ( 0.693)	Data  0.982 ( 0.556)	Loss 3.0108e-01 (1.2064e-01) 
2023-05-26 01:27:09.522200: val Epoch: [66][67/72]	Time  0.224 ( 0.687)	Data  0.089 ( 0.549)	Loss 5.6854e-02 (1.1970e-01) 
2023-05-26 01:27:10.627575: val Epoch: [66][68/72]	Time  1.105 ( 0.693)	Data  0.970 ( 0.555)	Loss 4.1338e-02 (1.1857e-01) 
2023-05-26 01:27:10.871152: val Epoch: [66][69/72]	Time  0.244 ( 0.686)	Data  0.114 ( 0.549)	Loss 2.8814e-01 (1.2099e-01) 
2023-05-26 01:27:11.987158: val Epoch: [66][70/72]	Time  1.116 ( 0.692)	Data  0.980 ( 0.555)	Loss 3.5391e-02 (1.1978e-01) 
2023-05-26 01:27:12.117111: val Epoch: [66][71/72]	Time  0.130 ( 0.684)	Data  0.001 ( 0.547)	Loss 5.6764e-02 (1.1891e-01) 
2023-05-26 01:27:12.339978: Epoch 66 :Val : ['ET : 0.7717586755752563', 'TC : 0.7948758006095886', 'WT : 0.8809206485748291'] 
2023-05-26 01:27:12.351230: Epoch 66 :Val : ['ET : 0.7717586755752563', 'TC : 0.7948758006095886', 'WT : 0.8809206485748291'] 
2023-05-26 01:27:12.354604: Val epoch done in 50.38908243699916 s 
2023-05-26 01:27:12.361050: Batches per epoch:  129 
2023-05-26 01:27:17.904846: train Epoch: [67][  0/129]	Time  5.543 ( 5.543)	Data  4.486 ( 4.486)	Loss 8.2263e-02 (8.2263e-02) 
2023-05-26 01:27:18.891845: train Epoch: [67][  1/129]	Time  0.987 ( 3.265)	Data  0.002 ( 2.244)	Loss 7.9100e-02 (8.0681e-02) 
2023-05-26 01:27:21.953310: train Epoch: [67][  2/129]	Time  3.061 ( 3.197)	Data  2.082 ( 2.190)	Loss 5.9209e-02 (7.3524e-02) 
2023-05-26 01:27:22.925490: train Epoch: [67][  3/129]	Time  0.972 ( 2.641)	Data  0.001 ( 1.643)	Loss 4.1764e-02 (6.5584e-02) 
2023-05-26 01:27:26.063488: train Epoch: [67][  4/129]	Time  3.138 ( 2.740)	Data  2.173 ( 1.749)	Loss 7.4589e-02 (6.7385e-02) 
2023-05-26 01:27:27.046816: train Epoch: [67][  5/129]	Time  0.983 ( 2.448)	Data  0.001 ( 1.458)	Loss 5.4662e-02 (6.5264e-02) 
2023-05-26 01:27:30.027953: train Epoch: [67][  6/129]	Time  2.981 ( 2.524)	Data  1.997 ( 1.535)	Loss 6.9886e-02 (6.5925e-02) 
2023-05-26 01:27:31.009858: train Epoch: [67][  7/129]	Time  0.982 ( 2.331)	Data  0.001 ( 1.343)	Loss 1.0002e-01 (7.0186e-02) 
2023-05-26 01:27:34.021604: train Epoch: [67][  8/129]	Time  3.012 ( 2.407)	Data  2.030 ( 1.419)	Loss 1.0790e-01 (7.4377e-02) 
2023-05-26 01:27:34.990065: train Epoch: [67][  9/129]	Time  0.968 ( 2.263)	Data  0.001 ( 1.277)	Loss 6.9244e-02 (7.3863e-02) 
2023-05-26 01:27:37.956598: train Epoch: [67][ 10/129]	Time  2.967 ( 2.327)	Data  1.998 ( 1.343)	Loss 9.5761e-02 (7.5854e-02) 
2023-05-26 01:27:38.942886: train Epoch: [67][ 11/129]	Time  0.986 ( 2.215)	Data  0.001 ( 1.231)	Loss 7.5284e-02 (7.5806e-02) 
2023-05-26 01:27:42.145402: train Epoch: [67][ 12/129]	Time  3.202 ( 2.291)	Data  2.219 ( 1.307)	Loss 5.1702e-02 (7.3952e-02) 
2023-05-26 01:27:43.122691: train Epoch: [67][ 13/129]	Time  0.977 ( 2.197)	Data  0.001 ( 1.214)	Loss 3.4525e-02 (7.1136e-02) 
2023-05-26 01:27:46.123811: train Epoch: [67][ 14/129]	Time  3.001 ( 2.251)	Data  2.024 ( 1.268)	Loss 5.7626e-02 (7.0235e-02) 
2023-05-26 01:27:47.093704: train Epoch: [67][ 15/129]	Time  0.970 ( 2.171)	Data  0.001 ( 1.189)	Loss 4.7678e-02 (6.8826e-02) 
2023-05-26 01:27:50.327369: train Epoch: [67][ 16/129]	Time  3.234 ( 2.233)	Data  2.268 ( 1.252)	Loss 1.0760e-01 (7.1106e-02) 
2023-05-26 01:27:51.295562: train Epoch: [67][ 17/129]	Time  0.968 ( 2.163)	Data  0.001 ( 1.183)	Loss 3.2977e-02 (6.8988e-02) 
2023-05-26 01:27:54.430299: train Epoch: [67][ 18/129]	Time  3.135 ( 2.214)	Data  2.164 ( 1.234)	Loss 6.8740e-02 (6.8975e-02) 
2023-05-26 01:27:55.417905: train Epoch: [67][ 19/129]	Time  0.988 ( 2.153)	Data  0.002 ( 1.173)	Loss 8.0854e-02 (6.9569e-02) 
2023-05-26 01:27:58.452324: train Epoch: [67][ 20/129]	Time  3.034 ( 2.195)	Data  2.055 ( 1.215)	Loss 8.4259e-02 (7.0269e-02) 
2023-05-26 01:27:59.425816: train Epoch: [67][ 21/129]	Time  0.973 ( 2.139)	Data  0.001 ( 1.160)	Loss 8.3930e-02 (7.0890e-02) 
2023-05-26 01:28:02.501058: train Epoch: [67][ 22/129]	Time  3.075 ( 2.180)	Data  2.104 ( 1.201)	Loss 4.7057e-02 (6.9853e-02) 
2023-05-26 01:28:03.472289: train Epoch: [67][ 23/129]	Time  0.971 ( 2.130)	Data  0.001 ( 1.151)	Loss 6.8859e-02 (6.9812e-02) 
2023-05-26 01:28:06.635945: train Epoch: [67][ 24/129]	Time  3.164 ( 2.171)	Data  2.193 ( 1.192)	Loss 7.5472e-02 (7.0038e-02) 
2023-05-26 01:28:07.613016: train Epoch: [67][ 25/129]	Time  0.977 ( 2.125)	Data  0.001 ( 1.147)	Loss 6.5782e-02 (6.9875e-02) 
2023-05-26 01:28:10.799790: train Epoch: [67][ 26/129]	Time  3.187 ( 2.164)	Data  2.211 ( 1.186)	Loss 7.6351e-02 (7.0114e-02) 
2023-05-26 01:28:11.780307: train Epoch: [67][ 27/129]	Time  0.980 ( 2.122)	Data  0.001 ( 1.144)	Loss 5.3095e-02 (6.9507e-02) 
2023-05-26 01:28:14.837276: train Epoch: [67][ 28/129]	Time  3.057 ( 2.154)	Data  2.084 ( 1.176)	Loss 9.3235e-02 (7.0325e-02) 
2023-05-26 01:28:15.816451: train Epoch: [67][ 29/129]	Time  0.979 ( 2.115)	Data  0.001 ( 1.137)	Loss 6.3578e-02 (7.0100e-02) 
2023-05-26 01:28:18.912488: train Epoch: [67][ 30/129]	Time  3.096 ( 2.147)	Data  2.118 ( 1.169)	Loss 6.3239e-02 (6.9879e-02) 
2023-05-26 01:28:19.891572: train Epoch: [67][ 31/129]	Time  0.979 ( 2.110)	Data  0.001 ( 1.132)	Loss 6.7353e-02 (6.9800e-02) 
2023-05-26 01:28:22.918891: train Epoch: [67][ 32/129]	Time  3.027 ( 2.138)	Data  2.052 ( 1.160)	Loss 7.1771e-02 (6.9859e-02) 
2023-05-26 01:28:23.891809: train Epoch: [67][ 33/129]	Time  0.973 ( 2.104)	Data  0.001 ( 1.126)	Loss 5.3105e-02 (6.9367e-02) 
2023-05-26 01:28:27.001379: train Epoch: [67][ 34/129]	Time  3.110 ( 2.133)	Data  2.140 ( 1.155)	Loss 4.5664e-02 (6.8689e-02) 
2023-05-26 01:28:27.958285: train Epoch: [67][ 35/129]	Time  0.957 ( 2.100)	Data  0.001 ( 1.123)	Loss 7.3494e-02 (6.8823e-02) 
2023-05-26 01:28:30.904709: train Epoch: [67][ 36/129]	Time  2.946 ( 2.123)	Data  1.989 ( 1.146)	Loss 5.6266e-02 (6.8483e-02) 
2023-05-26 01:28:31.887702: train Epoch: [67][ 37/129]	Time  0.983 ( 2.093)	Data  0.001 ( 1.116)	Loss 7.7988e-02 (6.8734e-02) 
2023-05-26 01:28:34.928473: train Epoch: [67][ 38/129]	Time  3.041 ( 2.117)	Data  2.059 ( 1.140)	Loss 2.9770e-02 (6.7735e-02) 
2023-05-26 01:28:35.908273: train Epoch: [67][ 39/129]	Time  0.980 ( 2.089)	Data  0.001 ( 1.112)	Loss 6.2280e-02 (6.7598e-02) 
2023-05-26 01:28:38.908594: train Epoch: [67][ 40/129]	Time  3.000 ( 2.111)	Data  2.023 ( 1.134)	Loss 7.5425e-02 (6.7789e-02) 
2023-05-26 01:28:39.879517: train Epoch: [67][ 41/129]	Time  0.971 ( 2.084)	Data  0.001 ( 1.107)	Loss 4.2716e-02 (6.7192e-02) 
2023-05-26 01:28:42.990963: train Epoch: [67][ 42/129]	Time  3.111 ( 2.108)	Data  2.147 ( 1.131)	Loss 6.5247e-02 (6.7147e-02) 
2023-05-26 01:28:43.963107: train Epoch: [67][ 43/129]	Time  0.972 ( 2.082)	Data  0.001 ( 1.105)	Loss 8.6145e-02 (6.7579e-02) 
2023-05-26 01:28:47.127295: train Epoch: [67][ 44/129]	Time  3.164 ( 2.106)	Data  2.199 ( 1.130)	Loss 8.8901e-02 (6.8052e-02) 
2023-05-26 01:28:48.101622: train Epoch: [67][ 45/129]	Time  0.974 ( 2.081)	Data  0.001 ( 1.105)	Loss 4.6061e-02 (6.7574e-02) 
2023-05-26 01:28:51.167147: train Epoch: [67][ 46/129]	Time  3.066 ( 2.102)	Data  2.091 ( 1.126)	Loss 4.6605e-02 (6.7128e-02) 
2023-05-26 01:28:52.161493: train Epoch: [67][ 47/129]	Time  0.994 ( 2.079)	Data  0.001 ( 1.103)	Loss 2.0120e-01 (6.9922e-02) 
2023-05-26 01:28:55.213168: train Epoch: [67][ 48/129]	Time  3.052 ( 2.099)	Data  2.086 ( 1.123)	Loss 6.8493e-02 (6.9892e-02) 
2023-05-26 01:28:56.183184: train Epoch: [67][ 49/129]	Time  0.970 ( 2.076)	Data  0.001 ( 1.100)	Loss 7.3731e-02 (6.9969e-02) 
2023-05-26 01:28:59.210607: train Epoch: [67][ 50/129]	Time  3.027 ( 2.095)	Data  2.055 ( 1.119)	Loss 7.5065e-02 (7.0069e-02) 
2023-05-26 01:29:00.183423: train Epoch: [67][ 51/129]	Time  0.973 ( 2.073)	Data  0.001 ( 1.098)	Loss 5.7447e-02 (6.9826e-02) 
2023-05-26 01:29:03.286259: train Epoch: [67][ 52/129]	Time  3.103 ( 2.093)	Data  2.131 ( 1.117)	Loss 7.4514e-02 (6.9915e-02) 
2023-05-26 01:29:04.265278: train Epoch: [67][ 53/129]	Time  0.979 ( 2.072)	Data  0.001 ( 1.096)	Loss 5.5697e-02 (6.9651e-02) 
2023-05-26 01:29:07.442123: train Epoch: [67][ 54/129]	Time  3.177 ( 2.092)	Data  2.213 ( 1.117)	Loss 1.3244e-01 (7.0793e-02) 
2023-05-26 01:29:08.410653: train Epoch: [67][ 55/129]	Time  0.969 ( 2.072)	Data  0.001 ( 1.097)	Loss 7.9560e-02 (7.0950e-02) 
2023-05-26 01:29:11.492429: train Epoch: [67][ 56/129]	Time  3.082 ( 2.090)	Data  2.112 ( 1.115)	Loss 4.9044e-02 (7.0565e-02) 
2023-05-26 01:29:12.467516: train Epoch: [67][ 57/129]	Time  0.975 ( 2.071)	Data  0.002 ( 1.095)	Loss 3.1336e-02 (6.9889e-02) 
2023-05-26 01:29:15.638219: train Epoch: [67][ 58/129]	Time  3.171 ( 2.089)	Data  2.203 ( 1.114)	Loss 8.9905e-02 (7.0228e-02) 
2023-05-26 01:29:16.629332: train Epoch: [67][ 59/129]	Time  0.991 ( 2.071)	Data  0.002 ( 1.096)	Loss 5.6094e-02 (6.9993e-02) 
2023-05-26 01:29:19.761169: train Epoch: [67][ 60/129]	Time  3.132 ( 2.089)	Data  2.163 ( 1.113)	Loss 7.8919e-02 (7.0139e-02) 
2023-05-26 01:29:20.727248: train Epoch: [67][ 61/129]	Time  0.966 ( 2.070)	Data  0.004 ( 1.095)	Loss 7.8480e-02 (7.0274e-02) 
2023-05-26 01:29:23.737244: train Epoch: [67][ 62/129]	Time  3.010 ( 2.085)	Data  2.047 ( 1.110)	Loss 8.7994e-02 (7.0555e-02) 
2023-05-26 01:29:24.706400: train Epoch: [67][ 63/129]	Time  0.969 ( 2.068)	Data  0.001 ( 1.093)	Loss 5.7303e-02 (7.0348e-02) 
2023-05-26 01:29:27.896353: train Epoch: [67][ 64/129]	Time  3.190 ( 2.085)	Data  2.222 ( 1.110)	Loss 1.0182e-01 (7.0832e-02) 
2023-05-26 01:29:28.872693: train Epoch: [67][ 65/129]	Time  0.976 ( 2.068)	Data  0.001 ( 1.094)	Loss 5.3099e-02 (7.0563e-02) 
2023-05-26 01:29:31.778604: train Epoch: [67][ 66/129]	Time  2.906 ( 2.081)	Data  1.955 ( 1.106)	Loss 6.9724e-02 (7.0551e-02) 
2023-05-26 01:29:32.741398: train Epoch: [67][ 67/129]	Time  0.963 ( 2.064)	Data  0.001 ( 1.090)	Loss 5.1419e-02 (7.0269e-02) 
2023-05-26 01:29:35.814049: train Epoch: [67][ 68/129]	Time  3.073 ( 2.079)	Data  2.106 ( 1.105)	Loss 9.1721e-02 (7.0580e-02) 
2023-05-26 01:29:36.787655: train Epoch: [67][ 69/129]	Time  0.974 ( 2.063)	Data  0.001 ( 1.089)	Loss 1.0310e-01 (7.1045e-02) 
2023-05-26 01:29:39.960851: train Epoch: [67][ 70/129]	Time  3.173 ( 2.079)	Data  2.207 ( 1.105)	Loss 7.8797e-02 (7.1154e-02) 
2023-05-26 01:29:40.930831: train Epoch: [67][ 71/129]	Time  0.970 ( 2.063)	Data  0.001 ( 1.090)	Loss 5.6823e-02 (7.0955e-02) 
2023-05-26 01:29:44.088222: train Epoch: [67][ 72/129]	Time  3.157 ( 2.078)	Data  2.194 ( 1.105)	Loss 6.6664e-02 (7.0896e-02) 
2023-05-26 01:29:45.065517: train Epoch: [67][ 73/129]	Time  0.977 ( 2.064)	Data  0.001 ( 1.090)	Loss 7.3845e-02 (7.0936e-02) 
2023-05-26 01:29:48.206205: train Epoch: [67][ 74/129]	Time  3.141 ( 2.078)	Data  2.172 ( 1.104)	Loss 1.0088e-01 (7.1335e-02) 
2023-05-26 01:29:49.186379: train Epoch: [67][ 75/129]	Time  0.980 ( 2.063)	Data  0.001 ( 1.090)	Loss 8.2730e-02 (7.1485e-02) 
2023-05-26 01:29:52.271488: train Epoch: [67][ 76/129]	Time  3.085 ( 2.077)	Data  2.121 ( 1.103)	Loss 6.0809e-02 (7.1347e-02) 
2023-05-26 01:29:53.242124: train Epoch: [67][ 77/129]	Time  0.971 ( 2.063)	Data  0.001 ( 1.089)	Loss 9.4937e-02 (7.1649e-02) 
2023-05-26 01:29:56.398836: train Epoch: [67][ 78/129]	Time  3.157 ( 2.076)	Data  2.183 ( 1.103)	Loss 8.9598e-02 (7.1876e-02) 
2023-05-26 01:29:57.365063: train Epoch: [67][ 79/129]	Time  0.966 ( 2.063)	Data  0.001 ( 1.089)	Loss 4.6729e-02 (7.1562e-02) 
2023-05-26 01:30:00.371116: train Epoch: [67][ 80/129]	Time  3.006 ( 2.074)	Data  2.038 ( 1.101)	Loss 5.4970e-02 (7.1357e-02) 
2023-05-26 01:30:01.335283: train Epoch: [67][ 81/129]	Time  0.964 ( 2.061)	Data  0.002 ( 1.087)	Loss 4.7466e-02 (7.1066e-02) 
2023-05-26 01:30:04.394504: train Epoch: [67][ 82/129]	Time  3.059 ( 2.073)	Data  2.091 ( 1.099)	Loss 5.4804e-02 (7.0870e-02) 
2023-05-26 01:30:05.366112: train Epoch: [67][ 83/129]	Time  0.972 ( 2.060)	Data  0.001 ( 1.086)	Loss 8.2741e-02 (7.1011e-02) 
2023-05-26 01:30:08.425256: train Epoch: [67][ 84/129]	Time  3.059 ( 2.071)	Data  2.090 ( 1.098)	Loss 4.3245e-02 (7.0684e-02) 
2023-05-26 01:30:09.402531: train Epoch: [67][ 85/129]	Time  0.977 ( 2.059)	Data  0.001 ( 1.085)	Loss 5.2661e-02 (7.0475e-02) 
2023-05-26 01:30:12.536972: train Epoch: [67][ 86/129]	Time  3.134 ( 2.071)	Data  2.168 ( 1.098)	Loss 6.6428e-02 (7.0428e-02) 
2023-05-26 01:30:13.512039: train Epoch: [67][ 87/129]	Time  0.975 ( 2.059)	Data  0.001 ( 1.085)	Loss 7.3506e-02 (7.0463e-02) 
2023-05-26 01:30:16.533574: train Epoch: [67][ 88/129]	Time  3.022 ( 2.069)	Data  2.043 ( 1.096)	Loss 1.2190e-01 (7.1041e-02) 
2023-05-26 01:30:17.512784: train Epoch: [67][ 89/129]	Time  0.979 ( 2.057)	Data  0.001 ( 1.084)	Loss 6.8697e-02 (7.1015e-02) 
2023-05-26 01:30:20.502868: train Epoch: [67][ 90/129]	Time  2.990 ( 2.067)	Data  2.017 ( 1.094)	Loss 4.4196e-02 (7.0720e-02) 
2023-05-26 01:30:21.473799: train Epoch: [67][ 91/129]	Time  0.971 ( 2.056)	Data  0.001 ( 1.082)	Loss 1.8967e-01 (7.2013e-02) 
2023-05-26 01:30:24.712532: train Epoch: [67][ 92/129]	Time  3.239 ( 2.068)	Data  2.258 ( 1.095)	Loss 5.5366e-02 (7.1834e-02) 
2023-05-26 01:30:25.694493: train Epoch: [67][ 93/129]	Time  0.982 ( 2.057)	Data  0.002 ( 1.083)	Loss 4.6160e-02 (7.1561e-02) 
2023-05-26 01:30:28.757600: train Epoch: [67][ 94/129]	Time  3.063 ( 2.067)	Data  2.095 ( 1.094)	Loss 8.2077e-02 (7.1672e-02) 
2023-05-26 01:30:29.738482: train Epoch: [67][ 95/129]	Time  0.981 ( 2.056)	Data  0.001 ( 1.083)	Loss 6.6254e-02 (7.1615e-02) 
2023-05-26 01:30:32.789289: train Epoch: [67][ 96/129]	Time  3.051 ( 2.066)	Data  2.070 ( 1.093)	Loss 8.6721e-02 (7.1771e-02) 
2023-05-26 01:30:33.773799: train Epoch: [67][ 97/129]	Time  0.985 ( 2.055)	Data  0.001 ( 1.082)	Loss 6.9688e-02 (7.1750e-02) 
2023-05-26 01:30:36.863606: train Epoch: [67][ 98/129]	Time  3.090 ( 2.066)	Data  2.125 ( 1.092)	Loss 5.5716e-02 (7.1588e-02) 
2023-05-26 01:30:37.833721: train Epoch: [67][ 99/129]	Time  0.970 ( 2.055)	Data  0.001 ( 1.081)	Loss 5.8819e-02 (7.1460e-02) 
2023-05-26 01:30:40.787652: train Epoch: [67][100/129]	Time  2.954 ( 2.064)	Data  1.988 ( 1.090)	Loss 4.0132e-02 (7.1150e-02) 
2023-05-26 01:30:41.775992: train Epoch: [67][101/129]	Time  0.988 ( 2.053)	Data  0.001 ( 1.080)	Loss 6.9124e-02 (7.1130e-02) 
2023-05-26 01:30:44.775363: train Epoch: [67][102/129]	Time  2.999 ( 2.062)	Data  2.015 ( 1.089)	Loss 5.9727e-02 (7.1020e-02) 
2023-05-26 01:30:45.756427: train Epoch: [67][103/129]	Time  0.981 ( 2.052)	Data  0.001 ( 1.078)	Loss 1.1411e-01 (7.1434e-02) 
2023-05-26 01:30:48.858141: train Epoch: [67][104/129]	Time  3.102 ( 2.062)	Data  2.137 ( 1.088)	Loss 9.3547e-02 (7.1644e-02) 
2023-05-26 01:30:49.826349: train Epoch: [67][105/129]	Time  0.968 ( 2.052)	Data  0.001 ( 1.078)	Loss 8.8434e-02 (7.1803e-02) 
2023-05-26 01:30:52.879071: train Epoch: [67][106/129]	Time  3.053 ( 2.061)	Data  2.084 ( 1.087)	Loss 8.1334e-02 (7.1892e-02) 
2023-05-26 01:30:53.854423: train Epoch: [67][107/129]	Time  0.975 ( 2.051)	Data  0.001 ( 1.077)	Loss 6.4883e-02 (7.1827e-02) 
2023-05-26 01:30:56.858975: train Epoch: [67][108/129]	Time  3.005 ( 2.060)	Data  2.048 ( 1.086)	Loss 1.2088e-01 (7.2277e-02) 
2023-05-26 01:30:57.841439: train Epoch: [67][109/129]	Time  0.982 ( 2.050)	Data  0.001 ( 1.076)	Loss 7.3617e-02 (7.2289e-02) 
2023-05-26 01:31:00.910272: train Epoch: [67][110/129]	Time  3.069 ( 2.059)	Data  2.103 ( 1.086)	Loss 5.3759e-02 (7.2122e-02) 
2023-05-26 01:31:01.884260: train Epoch: [67][111/129]	Time  0.974 ( 2.049)	Data  0.001 ( 1.076)	Loss 5.5193e-02 (7.1971e-02) 
2023-05-26 01:31:05.561666: train Epoch: [67][112/129]	Time  3.677 ( 2.064)	Data  2.198 ( 1.086)	Loss 7.7840e-02 (7.2023e-02) 
2023-05-26 01:31:06.564906: train Epoch: [67][113/129]	Time  1.003 ( 2.054)	Data  0.001 ( 1.076)	Loss 6.1788e-02 (7.1933e-02) 
2023-05-26 01:31:09.252774: train Epoch: [67][114/129]	Time  2.688 ( 2.060)	Data  1.713 ( 1.082)	Loss 8.5155e-02 (7.2048e-02) 
2023-05-26 01:31:10.225748: train Epoch: [67][115/129]	Time  0.973 ( 2.051)	Data  0.001 ( 1.073)	Loss 5.5331e-02 (7.1904e-02) 
2023-05-26 01:31:13.365232: train Epoch: [67][116/129]	Time  3.139 ( 2.060)	Data  2.169 ( 1.082)	Loss 4.3555e-02 (7.1662e-02) 
2023-05-26 01:31:14.337582: train Epoch: [67][117/129]	Time  0.972 ( 2.051)	Data  0.001 ( 1.073)	Loss 7.3606e-02 (7.1678e-02) 
2023-05-26 01:31:17.414086: train Epoch: [67][118/129]	Time  3.076 ( 2.059)	Data  2.074 ( 1.081)	Loss 6.6580e-02 (7.1635e-02) 
2023-05-26 01:31:18.402197: train Epoch: [67][119/129]	Time  0.988 ( 2.050)	Data  0.001 ( 1.072)	Loss 6.9978e-02 (7.1622e-02) 
2023-05-26 01:31:21.369759: train Epoch: [67][120/129]	Time  2.968 ( 2.058)	Data  2.004 ( 1.080)	Loss 5.8525e-02 (7.1513e-02) 
2023-05-26 01:31:22.339981: train Epoch: [67][121/129]	Time  0.970 ( 2.049)	Data  0.001 ( 1.071)	Loss 6.1885e-02 (7.1435e-02) 
2023-05-26 01:31:25.414078: train Epoch: [67][122/129]	Time  3.074 ( 2.057)	Data  2.099 ( 1.079)	Loss 5.3633e-02 (7.1290e-02) 
2023-05-26 01:31:26.387021: train Epoch: [67][123/129]	Time  0.973 ( 2.049)	Data  0.001 ( 1.071)	Loss 5.6825e-02 (7.1173e-02) 
2023-05-26 01:31:29.443610: train Epoch: [67][124/129]	Time  3.057 ( 2.057)	Data  2.095 ( 1.079)	Loss 5.6499e-02 (7.1056e-02) 
2023-05-26 01:31:30.413310: train Epoch: [67][125/129]	Time  0.970 ( 2.048)	Data  0.002 ( 1.070)	Loss 5.6419e-02 (7.0940e-02) 
2023-05-26 01:31:33.449898: train Epoch: [67][126/129]	Time  3.037 ( 2.056)	Data  2.067 ( 1.078)	Loss 7.5687e-02 (7.0977e-02) 
2023-05-26 01:31:34.418277: train Epoch: [67][127/129]	Time  0.968 ( 2.047)	Data  0.001 ( 1.070)	Loss 9.4419e-02 (7.1160e-02) 
2023-05-26 01:31:36.295576: train Epoch: [67][128/129]	Time  1.877 ( 2.046)	Data  0.909 ( 1.069)	Loss 6.8796e-02 (7.1142e-02) 
2023-05-26 01:31:36.387802: Train Epoch done in 264.02680385200074 s 
2023-05-26 01:31:39.190221: val Epoch: [67][ 0/72]	Time  1.908 ( 1.908)	Data  1.689 ( 1.689)	Loss 4.2221e-02 (4.2221e-02) 
2023-05-26 01:31:39.318554: val Epoch: [67][ 1/72]	Time  0.129 ( 1.018)	Data  0.001 ( 0.845)	Loss 3.3206e-01 (1.8714e-01) 
2023-05-26 01:31:40.476691: val Epoch: [67][ 2/72]	Time  1.158 ( 1.065)	Data  1.022 ( 0.904)	Loss 2.3203e-01 (2.0210e-01) 
2023-05-26 01:31:40.606608: val Epoch: [67][ 3/72]	Time  0.130 ( 0.831)	Data  0.001 ( 0.679)	Loss 1.7117e-01 (1.9437e-01) 
2023-05-26 01:31:41.925563: val Epoch: [67][ 4/72]	Time  1.319 ( 0.929)	Data  1.176 ( 0.778)	Loss 1.0803e-01 (1.7710e-01) 
2023-05-26 01:31:42.054839: val Epoch: [67][ 5/72]	Time  0.129 ( 0.795)	Data  0.001 ( 0.649)	Loss 5.7329e-02 (1.5714e-01) 
2023-05-26 01:31:43.310618: val Epoch: [67][ 6/72]	Time  1.256 ( 0.861)	Data  1.119 ( 0.716)	Loss 1.4037e-01 (1.5474e-01) 
2023-05-26 01:31:43.438886: val Epoch: [67][ 7/72]	Time  0.128 ( 0.770)	Data  0.001 ( 0.626)	Loss 3.5686e-02 (1.3986e-01) 
2023-05-26 01:31:44.741467: val Epoch: [67][ 8/72]	Time  1.303 ( 0.829)	Data  1.169 ( 0.687)	Loss 2.6920e-01 (1.5423e-01) 
2023-05-26 01:31:44.872737: val Epoch: [67][ 9/72]	Time  0.131 ( 0.759)	Data  0.001 ( 0.618)	Loss 5.2242e-01 (1.9105e-01) 
2023-05-26 01:31:46.066020: val Epoch: [67][10/72]	Time  1.193 ( 0.799)	Data  1.061 ( 0.658)	Loss 5.5808e-02 (1.7876e-01) 
2023-05-26 01:31:46.196974: val Epoch: [67][11/72]	Time  0.131 ( 0.743)	Data  0.001 ( 0.604)	Loss 6.4544e-02 (1.6924e-01) 
2023-05-26 01:31:47.411377: val Epoch: [67][12/72]	Time  1.214 ( 0.779)	Data  1.079 ( 0.640)	Loss 4.2918e-02 (1.5952e-01) 
2023-05-26 01:31:47.543973: val Epoch: [67][13/72]	Time  0.133 ( 0.733)	Data  0.001 ( 0.594)	Loss 6.3630e-02 (1.5267e-01) 
2023-05-26 01:31:48.776652: val Epoch: [67][14/72]	Time  1.233 ( 0.766)	Data  1.100 ( 0.628)	Loss 2.4312e-01 (1.5870e-01) 
2023-05-26 01:31:48.899027: val Epoch: [67][15/72]	Time  0.122 ( 0.726)	Data  0.001 ( 0.589)	Loss 5.1378e-02 (1.5199e-01) 
2023-05-26 01:31:50.112406: val Epoch: [67][16/72]	Time  1.213 ( 0.755)	Data  1.070 ( 0.617)	Loss 4.9833e-02 (1.4599e-01) 
2023-05-26 01:31:50.251192: val Epoch: [67][17/72]	Time  0.139 ( 0.720)	Data  0.001 ( 0.583)	Loss 5.5013e-02 (1.4093e-01) 
2023-05-26 01:31:51.492011: val Epoch: [67][18/72]	Time  1.241 ( 0.748)	Data  1.098 ( 0.610)	Loss 4.2430e-01 (1.5585e-01) 
2023-05-26 01:31:51.632003: val Epoch: [67][19/72]	Time  0.140 ( 0.717)	Data  0.001 ( 0.580)	Loss 1.1506e-01 (1.5381e-01) 
2023-05-26 01:31:52.838764: val Epoch: [67][20/72]	Time  1.207 ( 0.741)	Data  1.072 ( 0.603)	Loss 7.9565e-02 (1.5027e-01) 
2023-05-26 01:31:52.984840: val Epoch: [67][21/72]	Time  0.146 ( 0.714)	Data  0.011 ( 0.576)	Loss 4.5197e-02 (1.4549e-01) 
2023-05-26 01:31:54.184508: val Epoch: [67][22/72]	Time  1.200 ( 0.735)	Data  1.073 ( 0.598)	Loss 4.0841e-01 (1.5693e-01) 
2023-05-26 01:31:54.342219: val Epoch: [67][23/72]	Time  0.158 ( 0.711)	Data  0.031 ( 0.574)	Loss 8.4831e-02 (1.5392e-01) 
2023-05-26 01:31:55.499145: val Epoch: [67][24/72]	Time  1.157 ( 0.729)	Data  1.028 ( 0.592)	Loss 5.7219e-02 (1.5005e-01) 
2023-05-26 01:31:55.697170: val Epoch: [67][25/72]	Time  0.198 ( 0.708)	Data  0.056 ( 0.572)	Loss 7.8829e-02 (1.4731e-01) 
2023-05-26 01:31:56.859575: val Epoch: [67][26/72]	Time  1.162 ( 0.725)	Data  1.033 ( 0.589)	Loss 8.2792e-02 (1.4492e-01) 
2023-05-26 01:31:57.105579: val Epoch: [67][27/72]	Time  0.246 ( 0.708)	Data  0.112 ( 0.572)	Loss 7.8771e-02 (1.4256e-01) 
2023-05-26 01:31:58.250171: val Epoch: [67][28/72]	Time  1.145 ( 0.723)	Data  1.007 ( 0.587)	Loss 1.0384e-01 (1.4123e-01) 
2023-05-26 01:31:58.444850: val Epoch: [67][29/72]	Time  0.195 ( 0.705)	Data  0.058 ( 0.569)	Loss 5.3681e-02 (1.3831e-01) 
2023-05-26 01:31:59.602269: val Epoch: [67][30/72]	Time  1.157 ( 0.720)	Data  1.031 ( 0.584)	Loss 1.4070e-01 (1.3839e-01) 
2023-05-26 01:31:59.857495: val Epoch: [67][31/72]	Time  0.255 ( 0.705)	Data  0.124 ( 0.570)	Loss 7.7578e-02 (1.3649e-01) 
2023-05-26 01:32:00.964859: val Epoch: [67][32/72]	Time  1.107 ( 0.718)	Data  0.982 ( 0.582)	Loss 4.4350e-02 (1.3369e-01) 
2023-05-26 01:32:01.230443: val Epoch: [67][33/72]	Time  0.266 ( 0.704)	Data  0.135 ( 0.569)	Loss 2.1651e-01 (1.3613e-01) 
2023-05-26 01:32:02.395090: val Epoch: [67][34/72]	Time  1.165 ( 0.718)	Data  1.038 ( 0.582)	Loss 1.9160e-01 (1.3771e-01) 
2023-05-26 01:32:02.575434: val Epoch: [67][35/72]	Time  0.180 ( 0.703)	Data  0.053 ( 0.568)	Loss 4.0492e-02 (1.3501e-01) 
2023-05-26 01:32:03.738475: val Epoch: [67][36/72]	Time  1.163 ( 0.715)	Data  1.023 ( 0.580)	Loss 4.2373e-02 (1.3251e-01) 
2023-05-26 01:32:03.984304: val Epoch: [67][37/72]	Time  0.246 ( 0.703)	Data  0.103 ( 0.567)	Loss 6.0264e-02 (1.3061e-01) 
2023-05-26 01:32:05.096977: val Epoch: [67][38/72]	Time  1.113 ( 0.713)	Data  0.984 ( 0.578)	Loss 8.8078e-02 (1.2952e-01) 
2023-05-26 01:32:05.325308: val Epoch: [67][39/72]	Time  0.228 ( 0.701)	Data  0.101 ( 0.566)	Loss 1.0878e-01 (1.2900e-01) 
2023-05-26 01:32:06.435704: val Epoch: [67][40/72]	Time  1.110 ( 0.711)	Data  0.981 ( 0.576)	Loss 3.3077e-02 (1.2666e-01) 
2023-05-26 01:32:06.704465: val Epoch: [67][41/72]	Time  0.269 ( 0.701)	Data  0.140 ( 0.566)	Loss 2.5378e-01 (1.2969e-01) 
2023-05-26 01:32:07.837675: val Epoch: [67][42/72]	Time  1.133 ( 0.711)	Data  1.004 ( 0.576)	Loss 7.0434e-02 (1.2831e-01) 
2023-05-26 01:32:08.042510: val Epoch: [67][43/72]	Time  0.205 ( 0.699)	Data  0.076 ( 0.565)	Loss 2.7049e-01 (1.3154e-01) 
2023-05-26 01:32:09.140794: val Epoch: [67][44/72]	Time  1.098 ( 0.708)	Data  0.971 ( 0.574)	Loss 1.1779e-01 (1.3123e-01) 
2023-05-26 01:32:09.402809: val Epoch: [67][45/72]	Time  0.262 ( 0.698)	Data  0.135 ( 0.564)	Loss 2.9739e-01 (1.3485e-01) 
2023-05-26 01:32:10.477777: val Epoch: [67][46/72]	Time  1.075 ( 0.706)	Data  0.948 ( 0.572)	Loss 8.7436e-02 (1.3384e-01) 
2023-05-26 01:32:10.725787: val Epoch: [67][47/72]	Time  0.248 ( 0.697)	Data  0.118 ( 0.563)	Loss 7.8997e-02 (1.3270e-01) 
2023-05-26 01:32:11.841510: val Epoch: [67][48/72]	Time  1.116 ( 0.705)	Data  0.990 ( 0.572)	Loss 4.3042e-02 (1.3087e-01) 
2023-05-26 01:32:12.068362: val Epoch: [67][49/72]	Time  0.227 ( 0.696)	Data  0.100 ( 0.562)	Loss 3.2883e-02 (1.2891e-01) 
2023-05-26 01:32:13.132890: val Epoch: [67][50/72]	Time  1.065 ( 0.703)	Data  0.938 ( 0.570)	Loss 5.8217e-02 (1.2752e-01) 
2023-05-26 01:32:13.368984: val Epoch: [67][51/72]	Time  0.236 ( 0.694)	Data  0.108 ( 0.561)	Loss 2.3359e-01 (1.2956e-01) 
2023-05-26 01:32:14.441159: val Epoch: [67][52/72]	Time  1.072 ( 0.701)	Data  0.950 ( 0.568)	Loss 3.9401e-02 (1.2786e-01) 
2023-05-26 01:32:14.728759: val Epoch: [67][53/72]	Time  0.288 ( 0.693)	Data  0.155 ( 0.560)	Loss 1.1644e-01 (1.2765e-01) 
2023-05-26 01:32:15.769575: val Epoch: [67][54/72]	Time  1.041 ( 0.700)	Data  0.904 ( 0.567)	Loss 4.4053e-02 (1.2613e-01) 
2023-05-26 01:32:16.108862: val Epoch: [67][55/72]	Time  0.339 ( 0.693)	Data  0.209 ( 0.560)	Loss 5.8998e-02 (1.2493e-01) 
2023-05-26 01:32:17.174789: val Epoch: [67][56/72]	Time  1.066 ( 0.700)	Data  0.937 ( 0.567)	Loss 3.4530e-01 (1.2879e-01) 
2023-05-26 01:32:17.468221: val Epoch: [67][57/72]	Time  0.293 ( 0.693)	Data  0.165 ( 0.560)	Loss 9.8130e-02 (1.2827e-01) 
2023-05-26 01:32:18.540057: val Epoch: [67][58/72]	Time  1.072 ( 0.699)	Data  0.933 ( 0.566)	Loss 8.1398e-02 (1.2747e-01) 
2023-05-26 01:32:18.775717: val Epoch: [67][59/72]	Time  0.236 ( 0.692)	Data  0.102 ( 0.559)	Loss 6.4514e-02 (1.2642e-01) 
2023-05-26 01:32:19.871162: val Epoch: [67][60/72]	Time  1.095 ( 0.698)	Data  0.962 ( 0.565)	Loss 6.0671e-02 (1.2534e-01) 
2023-05-26 01:32:20.129044: val Epoch: [67][61/72]	Time  0.258 ( 0.691)	Data  0.122 ( 0.558)	Loss 9.2299e-02 (1.2481e-01) 
2023-05-26 01:32:21.260230: val Epoch: [67][62/72]	Time  1.131 ( 0.698)	Data  1.004 ( 0.565)	Loss 8.2447e-02 (1.2414e-01) 
2023-05-26 01:32:21.451641: val Epoch: [67][63/72]	Time  0.191 ( 0.690)	Data  0.060 ( 0.557)	Loss 1.2247e-01 (1.2411e-01) 
2023-05-26 01:32:22.583840: val Epoch: [67][64/72]	Time  1.132 ( 0.697)	Data  1.001 ( 0.564)	Loss 3.2296e-02 (1.2270e-01) 
2023-05-26 01:32:22.738883: val Epoch: [67][65/72]	Time  0.155 ( 0.689)	Data  0.031 ( 0.556)	Loss 4.1638e-02 (1.2147e-01) 
2023-05-26 01:32:23.960015: val Epoch: [67][66/72]	Time  1.221 ( 0.697)	Data  1.084 ( 0.564)	Loss 1.4925e-01 (1.2189e-01) 
2023-05-26 01:32:24.173635: val Epoch: [67][67/72]	Time  0.214 ( 0.690)	Data  0.077 ( 0.557)	Loss 8.5995e-02 (1.2136e-01) 
2023-05-26 01:32:25.332633: val Epoch: [67][68/72]	Time  1.159 ( 0.696)	Data  1.023 ( 0.563)	Loss 5.2751e-02 (1.2036e-01) 
2023-05-26 01:32:25.533750: val Epoch: [67][69/72]	Time  0.201 ( 0.689)	Data  0.067 ( 0.556)	Loss 1.8119e-01 (1.2123e-01) 
2023-05-26 01:32:26.654371: val Epoch: [67][70/72]	Time  1.121 ( 0.695)	Data  0.987 ( 0.562)	Loss 8.0502e-02 (1.2066e-01) 
2023-05-26 01:32:26.907863: val Epoch: [67][71/72]	Time  0.253 ( 0.689)	Data  0.116 ( 0.556)	Loss 3.2656e-01 (1.2352e-01) 
2023-05-26 01:32:27.128702: Epoch 67 :Val : ['ET : 0.7484424114227295', 'TC : 0.7850784063339233', 'WT : 0.8803084492683411'] 
2023-05-26 01:32:27.132206: Epoch 67 :Val : ['ET : 0.7484424114227295', 'TC : 0.7850784063339233', 'WT : 0.8803084492683411'] 
2023-05-26 01:32:27.135185: Val epoch done in 50.747384254998906 s 
2023-05-26 01:32:27.141320: Batches per epoch:  129 
2023-05-26 01:32:32.714918: train Epoch: [68][  0/129]	Time  5.573 ( 5.573)	Data  4.523 ( 4.523)	Loss 7.2829e-02 (7.2829e-02) 
2023-05-26 01:32:33.687906: train Epoch: [68][  1/129]	Time  0.973 ( 3.273)	Data  0.001 ( 2.262)	Loss 6.4192e-02 (6.8510e-02) 
2023-05-26 01:32:36.772177: train Epoch: [68][  2/129]	Time  3.084 ( 3.210)	Data  2.119 ( 2.214)	Loss 6.9732e-02 (6.8918e-02) 
2023-05-26 01:32:37.738010: train Epoch: [68][  3/129]	Time  0.966 ( 2.649)	Data  0.001 ( 1.661)	Loss 6.7985e-02 (6.8685e-02) 
2023-05-26 01:32:40.744153: train Epoch: [68][  4/129]	Time  3.006 ( 2.720)	Data  2.038 ( 1.736)	Loss 7.9535e-02 (7.0855e-02) 
2023-05-26 01:32:41.720306: train Epoch: [68][  5/129]	Time  0.976 ( 2.430)	Data  0.001 ( 1.447)	Loss 8.0381e-02 (7.2442e-02) 
2023-05-26 01:32:44.872866: train Epoch: [68][  6/129]	Time  3.153 ( 2.533)	Data  2.168 ( 1.550)	Loss 7.5824e-02 (7.2926e-02) 
2023-05-26 01:32:45.851200: train Epoch: [68][  7/129]	Time  0.978 ( 2.339)	Data  0.002 ( 1.357)	Loss 4.4805e-02 (6.9410e-02) 
2023-05-26 01:32:49.023635: train Epoch: [68][  8/129]	Time  3.172 ( 2.431)	Data  2.206 ( 1.451)	Loss 1.1066e-01 (7.3994e-02) 
2023-05-26 01:32:49.992408: train Epoch: [68][  9/129]	Time  0.969 ( 2.285)	Data  0.001 ( 1.306)	Loss 5.7939e-02 (7.2388e-02) 
2023-05-26 01:32:53.018085: train Epoch: [68][ 10/129]	Time  3.026 ( 2.352)	Data  2.048 ( 1.373)	Loss 8.3958e-02 (7.3440e-02) 
2023-05-26 01:32:53.988453: train Epoch: [68][ 11/129]	Time  0.970 ( 2.237)	Data  0.001 ( 1.259)	Loss 5.5279e-02 (7.1927e-02) 
2023-05-26 01:32:57.122469: train Epoch: [68][ 12/129]	Time  3.134 ( 2.306)	Data  2.169 ( 1.329)	Loss 9.4178e-02 (7.3638e-02) 
2023-05-26 01:32:58.090789: train Epoch: [68][ 13/129]	Time  0.968 ( 2.211)	Data  0.001 ( 1.234)	Loss 7.0395e-02 (7.3407e-02) 
2023-05-26 01:33:01.247706: train Epoch: [68][ 14/129]	Time  3.157 ( 2.274)	Data  2.188 ( 1.298)	Loss 1.2746e-01 (7.7011e-02) 
2023-05-26 01:33:02.217819: train Epoch: [68][ 15/129]	Time  0.970 ( 2.192)	Data  0.001 ( 1.217)	Loss 7.3322e-02 (7.6780e-02) 
2023-05-26 01:33:05.337919: train Epoch: [68][ 16/129]	Time  3.120 ( 2.247)	Data  2.144 ( 1.271)	Loss 3.8251e-02 (7.4514e-02) 
2023-05-26 01:33:06.306788: train Epoch: [68][ 17/129]	Time  0.969 ( 2.176)	Data  0.001 ( 1.201)	Loss 8.4376e-02 (7.5061e-02) 
2023-05-26 01:33:09.476312: train Epoch: [68][ 18/129]	Time  3.169 ( 2.228)	Data  2.192 ( 1.253)	Loss 1.0840e-01 (7.6816e-02) 
2023-05-26 01:33:10.465611: train Epoch: [68][ 19/129]	Time  0.989 ( 2.166)	Data  0.001 ( 1.190)	Loss 9.4894e-02 (7.7720e-02) 
2023-05-26 01:33:13.600089: train Epoch: [68][ 20/129]	Time  3.134 ( 2.212)	Data  2.166 ( 1.237)	Loss 6.4185e-02 (7.7075e-02) 
2023-05-26 01:33:14.576528: train Epoch: [68][ 21/129]	Time  0.976 ( 2.156)	Data  0.001 ( 1.181)	Loss 4.8181e-02 (7.5762e-02) 
2023-05-26 01:33:17.658906: train Epoch: [68][ 22/129]	Time  3.082 ( 2.196)	Data  2.102 ( 1.221)	Loss 1.0833e-01 (7.7178e-02) 
2023-05-26 01:33:18.643939: train Epoch: [68][ 23/129]	Time  0.985 ( 2.146)	Data  0.001 ( 1.170)	Loss 7.0523e-02 (7.6901e-02) 
2023-05-26 01:33:21.750912: train Epoch: [68][ 24/129]	Time  3.107 ( 2.184)	Data  2.147 ( 1.209)	Loss 8.6366e-02 (7.7279e-02) 
2023-05-26 01:33:22.725586: train Epoch: [68][ 25/129]	Time  0.975 ( 2.138)	Data  0.001 ( 1.163)	Loss 4.5358e-02 (7.6052e-02) 
2023-05-26 01:33:25.822883: train Epoch: [68][ 26/129]	Time  3.097 ( 2.173)	Data  2.127 ( 1.198)	Loss 5.8400e-02 (7.5398e-02) 
2023-05-26 01:33:26.795100: train Epoch: [68][ 27/129]	Time  0.972 ( 2.130)	Data  0.001 ( 1.156)	Loss 4.9602e-02 (7.4477e-02) 
2023-05-26 01:33:29.823675: train Epoch: [68][ 28/129]	Time  3.029 ( 2.161)	Data  2.060 ( 1.187)	Loss 6.3644e-02 (7.4103e-02) 
2023-05-26 01:33:30.792416: train Epoch: [68][ 29/129]	Time  0.969 ( 2.122)	Data  0.001 ( 1.147)	Loss 6.5312e-02 (7.3810e-02) 
2023-05-26 01:33:33.933651: train Epoch: [68][ 30/129]	Time  3.141 ( 2.155)	Data  2.175 ( 1.180)	Loss 5.5271e-02 (7.3212e-02) 
2023-05-26 01:33:34.901669: train Epoch: [68][ 31/129]	Time  0.968 ( 2.117)	Data  0.001 ( 1.143)	Loss 6.5197e-02 (7.2962e-02) 
2023-05-26 01:33:37.985727: train Epoch: [68][ 32/129]	Time  3.084 ( 2.147)	Data  2.107 ( 1.173)	Loss 6.4895e-02 (7.2717e-02) 
2023-05-26 01:33:38.955277: train Epoch: [68][ 33/129]	Time  0.970 ( 2.112)	Data  0.001 ( 1.138)	Loss 7.2148e-02 (7.2700e-02) 
2023-05-26 01:33:42.013518: train Epoch: [68][ 34/129]	Time  3.058 ( 2.139)	Data  2.094 ( 1.166)	Loss 7.5039e-02 (7.2767e-02) 
2023-05-26 01:33:42.983364: train Epoch: [68][ 35/129]	Time  0.970 ( 2.107)	Data  0.001 ( 1.133)	Loss 8.8103e-02 (7.3193e-02) 
2023-05-26 01:33:46.061720: train Epoch: [68][ 36/129]	Time  3.078 ( 2.133)	Data  2.115 ( 1.160)	Loss 6.5106e-02 (7.2975e-02) 
2023-05-26 01:33:47.032041: train Epoch: [68][ 37/129]	Time  0.970 ( 2.102)	Data  0.001 ( 1.129)	Loss 7.7815e-02 (7.3102e-02) 
2023-05-26 01:33:50.046710: train Epoch: [68][ 38/129]	Time  3.015 ( 2.126)	Data  2.039 ( 1.153)	Loss 8.0240e-02 (7.3285e-02) 
2023-05-26 01:33:51.018281: train Epoch: [68][ 39/129]	Time  0.972 ( 2.097)	Data  0.001 ( 1.124)	Loss 7.3331e-02 (7.3286e-02) 
2023-05-26 01:33:54.073550: train Epoch: [68][ 40/129]	Time  3.055 ( 2.120)	Data  2.079 ( 1.147)	Loss 4.8606e-02 (7.2684e-02) 
2023-05-26 01:33:55.048519: train Epoch: [68][ 41/129]	Time  0.975 ( 2.093)	Data  0.001 ( 1.120)	Loss 6.1945e-02 (7.2428e-02) 
2023-05-26 01:33:58.049474: train Epoch: [68][ 42/129]	Time  3.001 ( 2.114)	Data  2.030 ( 1.141)	Loss 6.6214e-02 (7.2284e-02) 
2023-05-26 01:33:59.035681: train Epoch: [68][ 43/129]	Time  0.986 ( 2.088)	Data  0.002 ( 1.115)	Loss 7.8145e-02 (7.2417e-02) 
2023-05-26 01:34:02.094228: train Epoch: [68][ 44/129]	Time  3.059 ( 2.110)	Data  2.083 ( 1.137)	Loss 6.1027e-02 (7.2164e-02) 
2023-05-26 01:34:03.061448: train Epoch: [68][ 45/129]	Time  0.967 ( 2.085)	Data  0.001 ( 1.112)	Loss 5.4647e-02 (7.1783e-02) 
2023-05-26 01:34:06.175729: train Epoch: [68][ 46/129]	Time  3.114 ( 2.107)	Data  2.135 ( 1.134)	Loss 7.4322e-02 (7.1837e-02) 
2023-05-26 01:34:07.145823: train Epoch: [68][ 47/129]	Time  0.970 ( 2.083)	Data  0.001 ( 1.110)	Loss 4.7656e-02 (7.1333e-02) 
2023-05-26 01:34:10.247468: train Epoch: [68][ 48/129]	Time  3.102 ( 2.104)	Data  2.125 ( 1.131)	Loss 1.7778e-01 (7.3506e-02) 
2023-05-26 01:34:11.221100: train Epoch: [68][ 49/129]	Time  0.974 ( 2.082)	Data  0.002 ( 1.108)	Loss 5.3620e-02 (7.3108e-02) 
2023-05-26 01:34:14.197012: train Epoch: [68][ 50/129]	Time  2.976 ( 2.099)	Data  2.007 ( 1.126)	Loss 1.0303e-01 (7.3695e-02) 
2023-05-26 01:34:15.175197: train Epoch: [68][ 51/129]	Time  0.978 ( 2.078)	Data  0.001 ( 1.104)	Loss 6.2184e-02 (7.3474e-02) 
2023-05-26 01:34:18.205134: train Epoch: [68][ 52/129]	Time  3.030 ( 2.096)	Data  2.059 ( 1.122)	Loss 6.1270e-02 (7.3243e-02) 
2023-05-26 01:34:19.175020: train Epoch: [68][ 53/129]	Time  0.970 ( 2.075)	Data  0.001 ( 1.101)	Loss 7.1045e-02 (7.3203e-02) 
2023-05-26 01:34:22.268344: train Epoch: [68][ 54/129]	Time  3.093 ( 2.093)	Data  2.129 ( 1.120)	Loss 5.0154e-02 (7.2784e-02) 
2023-05-26 01:34:23.246794: train Epoch: [68][ 55/129]	Time  0.978 ( 2.073)	Data  0.001 ( 1.100)	Loss 1.0026e-01 (7.3274e-02) 
2023-05-26 01:34:26.300859: train Epoch: [68][ 56/129]	Time  3.054 ( 2.091)	Data  2.078 ( 1.117)	Loss 4.2277e-02 (7.2730e-02) 
2023-05-26 01:34:27.261255: train Epoch: [68][ 57/129]	Time  0.960 ( 2.071)	Data  0.001 ( 1.098)	Loss 1.7283e-01 (7.4456e-02) 
2023-05-26 01:34:30.298075: train Epoch: [68][ 58/129]	Time  3.037 ( 2.087)	Data  2.071 ( 1.115)	Loss 8.8196e-02 (7.4689e-02) 
2023-05-26 01:34:31.269584: train Epoch: [68][ 59/129]	Time  0.972 ( 2.069)	Data  0.001 ( 1.096)	Loss 1.2742e-01 (7.5568e-02) 
2023-05-26 01:34:34.430097: train Epoch: [68][ 60/129]	Time  3.160 ( 2.087)	Data  2.191 ( 1.114)	Loss 9.6638e-02 (7.5913e-02) 
2023-05-26 01:34:35.412788: train Epoch: [68][ 61/129]	Time  0.983 ( 2.069)	Data  0.001 ( 1.096)	Loss 8.5946e-02 (7.6075e-02) 
2023-05-26 01:34:38.514640: train Epoch: [68][ 62/129]	Time  3.102 ( 2.085)	Data  2.136 ( 1.112)	Loss 5.8737e-02 (7.5800e-02) 
2023-05-26 01:34:39.496991: train Epoch: [68][ 63/129]	Time  0.982 ( 2.068)	Data  0.002 ( 1.095)	Loss 4.1302e-02 (7.5261e-02) 
2023-05-26 01:34:42.616352: train Epoch: [68][ 64/129]	Time  3.119 ( 2.084)	Data  2.134 ( 1.111)	Loss 5.7270e-02 (7.4984e-02) 
2023-05-26 01:34:43.620828: train Epoch: [68][ 65/129]	Time  1.004 ( 2.068)	Data  0.002 ( 1.094)	Loss 5.5214e-02 (7.4685e-02) 
2023-05-26 01:34:46.660629: train Epoch: [68][ 66/129]	Time  3.040 ( 2.082)	Data  2.077 ( 1.109)	Loss 8.8421e-02 (7.4890e-02) 
2023-05-26 01:34:47.633862: train Epoch: [68][ 67/129]	Time  0.973 ( 2.066)	Data  0.001 ( 1.093)	Loss 4.0560e-02 (7.4385e-02) 
2023-05-26 01:34:50.655495: train Epoch: [68][ 68/129]	Time  3.022 ( 2.080)	Data  2.057 ( 1.107)	Loss 5.0479e-02 (7.4038e-02) 
2023-05-26 01:34:51.626428: train Epoch: [68][ 69/129]	Time  0.971 ( 2.064)	Data  0.001 ( 1.091)	Loss 4.0801e-02 (7.3564e-02) 
2023-05-26 01:34:54.763027: train Epoch: [68][ 70/129]	Time  3.137 ( 2.079)	Data  2.158 ( 1.106)	Loss 6.7478e-02 (7.3478e-02) 
2023-05-26 01:34:55.733513: train Epoch: [68][ 71/129]	Time  0.970 ( 2.064)	Data  0.001 ( 1.091)	Loss 1.0233e-01 (7.3878e-02) 
2023-05-26 01:34:58.888831: train Epoch: [68][ 72/129]	Time  3.155 ( 2.079)	Data  2.183 ( 1.106)	Loss 4.6942e-02 (7.3510e-02) 
2023-05-26 01:34:59.860251: train Epoch: [68][ 73/129]	Time  0.971 ( 2.064)	Data  0.001 ( 1.091)	Loss 1.4482e-01 (7.4473e-02) 
2023-05-26 01:35:03.095491: train Epoch: [68][ 74/129]	Time  3.235 ( 2.079)	Data  2.264 ( 1.106)	Loss 7.9868e-02 (7.4545e-02) 
2023-05-26 01:35:04.072059: train Epoch: [68][ 75/129]	Time  0.977 ( 2.065)	Data  0.002 ( 1.092)	Loss 1.7298e-01 (7.5840e-02) 
2023-05-26 01:35:07.151512: train Epoch: [68][ 76/129]	Time  3.079 ( 2.078)	Data  2.107 ( 1.105)	Loss 6.0342e-02 (7.5639e-02) 
2023-05-26 01:35:08.135250: train Epoch: [68][ 77/129]	Time  0.984 ( 2.064)	Data  0.001 ( 1.091)	Loss 7.0299e-02 (7.5571e-02) 
2023-05-26 01:35:11.289974: train Epoch: [68][ 78/129]	Time  3.155 ( 2.078)	Data  2.185 ( 1.105)	Loss 1.0071e-01 (7.5889e-02) 
2023-05-26 01:35:12.259202: train Epoch: [68][ 79/129]	Time  0.969 ( 2.064)	Data  0.001 ( 1.091)	Loss 5.5737e-02 (7.5637e-02) 
2023-05-26 01:35:15.285919: train Epoch: [68][ 80/129]	Time  3.027 ( 2.076)	Data  2.043 ( 1.103)	Loss 7.4555e-02 (7.5624e-02) 
2023-05-26 01:35:16.263964: train Epoch: [68][ 81/129]	Time  0.978 ( 2.062)	Data  0.001 ( 1.089)	Loss 7.6814e-02 (7.5638e-02) 
2023-05-26 01:35:19.350382: train Epoch: [68][ 82/129]	Time  3.086 ( 2.075)	Data  2.111 ( 1.101)	Loss 9.7562e-02 (7.5902e-02) 
2023-05-26 01:35:20.320114: train Epoch: [68][ 83/129]	Time  0.970 ( 2.062)	Data  0.001 ( 1.088)	Loss 1.1371e-01 (7.6352e-02) 
2023-05-26 01:35:23.367323: train Epoch: [68][ 84/129]	Time  3.047 ( 2.073)	Data  2.085 ( 1.100)	Loss 8.6864e-02 (7.6476e-02) 
2023-05-26 01:35:24.338253: train Epoch: [68][ 85/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.087)	Loss 8.2309e-02 (7.6544e-02) 
2023-05-26 01:35:27.464480: train Epoch: [68][ 86/129]	Time  3.126 ( 2.073)	Data  2.160 ( 1.100)	Loss 1.4135e-01 (7.7289e-02) 
2023-05-26 01:35:28.435841: train Epoch: [68][ 87/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.087)	Loss 7.2327e-02 (7.7232e-02) 
2023-05-26 01:35:31.654706: train Epoch: [68][ 88/129]	Time  3.219 ( 2.073)	Data  2.234 ( 1.100)	Loss 6.6621e-02 (7.7113e-02) 
2023-05-26 01:35:32.645740: train Epoch: [68][ 89/129]	Time  0.991 ( 2.061)	Data  0.001 ( 1.088)	Loss 4.5880e-02 (7.6766e-02) 
2023-05-26 01:35:35.629758: train Epoch: [68][ 90/129]	Time  2.984 ( 2.071)	Data  2.002 ( 1.098)	Loss 5.6922e-02 (7.6548e-02) 
2023-05-26 01:35:36.604674: train Epoch: [68][ 91/129]	Time  0.975 ( 2.059)	Data  0.001 ( 1.086)	Loss 6.5514e-02 (7.6428e-02) 
2023-05-26 01:35:39.639627: train Epoch: [68][ 92/129]	Time  3.035 ( 2.070)	Data  2.075 ( 1.097)	Loss 5.3737e-02 (7.6184e-02) 
2023-05-26 01:35:40.614488: train Epoch: [68][ 93/129]	Time  0.975 ( 2.058)	Data  0.001 ( 1.085)	Loss 1.0092e-01 (7.6447e-02) 
2023-05-26 01:35:43.875114: train Epoch: [68][ 94/129]	Time  3.261 ( 2.071)	Data  2.278 ( 1.097)	Loss 7.0553e-02 (7.6385e-02) 
2023-05-26 01:35:44.847816: train Epoch: [68][ 95/129]	Time  0.973 ( 2.059)	Data  0.001 ( 1.086)	Loss 7.8624e-02 (7.6408e-02) 
2023-05-26 01:35:47.932292: train Epoch: [68][ 96/129]	Time  3.084 ( 2.070)	Data  2.113 ( 1.097)	Loss 6.7486e-02 (7.6316e-02) 
2023-05-26 01:35:48.910546: train Epoch: [68][ 97/129]	Time  0.978 ( 2.059)	Data  0.001 ( 1.085)	Loss 4.7651e-02 (7.6024e-02) 
2023-05-26 01:35:51.958866: train Epoch: [68][ 98/129]	Time  3.048 ( 2.069)	Data  2.083 ( 1.096)	Loss 6.1416e-02 (7.5876e-02) 
2023-05-26 01:35:52.943704: train Epoch: [68][ 99/129]	Time  0.985 ( 2.058)	Data  0.001 ( 1.085)	Loss 7.0802e-02 (7.5826e-02) 
2023-05-26 01:35:56.108986: train Epoch: [68][100/129]	Time  3.165 ( 2.069)	Data  2.190 ( 1.096)	Loss 1.1877e-01 (7.6251e-02) 
2023-05-26 01:35:57.088149: train Epoch: [68][101/129]	Time  0.979 ( 2.058)	Data  0.002 ( 1.085)	Loss 5.1239e-02 (7.6006e-02) 
2023-05-26 01:36:00.194827: train Epoch: [68][102/129]	Time  3.107 ( 2.068)	Data  2.118 ( 1.095)	Loss 6.8685e-02 (7.5935e-02) 
2023-05-26 01:36:01.160880: train Epoch: [68][103/129]	Time  0.966 ( 2.058)	Data  0.001 ( 1.084)	Loss 7.6532e-02 (7.5940e-02) 
2023-05-26 01:36:04.313567: train Epoch: [68][104/129]	Time  3.153 ( 2.068)	Data  2.180 ( 1.095)	Loss 1.1046e-01 (7.6269e-02) 
2023-05-26 01:36:05.295019: train Epoch: [68][105/129]	Time  0.981 ( 2.058)	Data  0.001 ( 1.084)	Loss 6.0860e-02 (7.6124e-02) 
2023-05-26 01:36:08.502951: train Epoch: [68][106/129]	Time  3.208 ( 2.069)	Data  2.241 ( 1.095)	Loss 7.4444e-02 (7.6108e-02) 
2023-05-26 01:36:09.480679: train Epoch: [68][107/129]	Time  0.978 ( 2.059)	Data  0.001 ( 1.085)	Loss 6.7640e-02 (7.6030e-02) 
2023-05-26 01:36:12.589003: train Epoch: [68][108/129]	Time  3.108 ( 2.068)	Data  2.145 ( 1.095)	Loss 1.1279e-01 (7.6367e-02) 
2023-05-26 01:36:13.565053: train Epoch: [68][109/129]	Time  0.976 ( 2.058)	Data  0.001 ( 1.085)	Loss 1.5800e-01 (7.7109e-02) 
2023-05-26 01:36:16.654407: train Epoch: [68][110/129]	Time  3.089 ( 2.068)	Data  2.122 ( 1.094)	Loss 8.8754e-02 (7.7214e-02) 
2023-05-26 01:36:17.633317: train Epoch: [68][111/129]	Time  0.979 ( 2.058)	Data  0.001 ( 1.084)	Loss 7.8272e-02 (7.7223e-02) 
2023-05-26 01:36:20.774941: train Epoch: [68][112/129]	Time  3.142 ( 2.068)	Data  2.165 ( 1.094)	Loss 8.2172e-02 (7.7267e-02) 
2023-05-26 01:36:21.751375: train Epoch: [68][113/129]	Time  0.976 ( 2.058)	Data  0.001 ( 1.084)	Loss 8.5755e-02 (7.7342e-02) 
2023-05-26 01:36:24.906620: train Epoch: [68][114/129]	Time  3.155 ( 2.068)	Data  2.172 ( 1.094)	Loss 1.1567e-01 (7.7675e-02) 
2023-05-26 01:36:25.902224: train Epoch: [68][115/129]	Time  0.996 ( 2.058)	Data  0.002 ( 1.084)	Loss 7.0605e-02 (7.7614e-02) 
2023-05-26 01:36:28.921450: train Epoch: [68][116/129]	Time  3.019 ( 2.066)	Data  2.052 ( 1.093)	Loss 1.2185e-01 (7.7992e-02) 
2023-05-26 01:36:29.905034: train Epoch: [68][117/129]	Time  0.984 ( 2.057)	Data  0.001 ( 1.084)	Loss 1.0945e-01 (7.8259e-02) 
2023-05-26 01:36:33.093072: train Epoch: [68][118/129]	Time  3.188 ( 2.067)	Data  2.207 ( 1.093)	Loss 1.3673e-01 (7.8750e-02) 
2023-05-26 01:36:34.079680: train Epoch: [68][119/129]	Time  0.987 ( 2.058)	Data  0.001 ( 1.084)	Loss 6.9940e-02 (7.8677e-02) 
2023-05-26 01:36:37.244851: train Epoch: [68][120/129]	Time  3.165 ( 2.067)	Data  2.194 ( 1.093)	Loss 9.3146e-02 (7.8796e-02) 
2023-05-26 01:36:38.220820: train Epoch: [68][121/129]	Time  0.976 ( 2.058)	Data  0.001 ( 1.084)	Loss 8.2780e-02 (7.8829e-02) 
2023-05-26 01:36:41.286850: train Epoch: [68][122/129]	Time  3.066 ( 2.066)	Data  2.096 ( 1.092)	Loss 1.0207e-01 (7.9018e-02) 
2023-05-26 01:36:42.259975: train Epoch: [68][123/129]	Time  0.973 ( 2.057)	Data  0.002 ( 1.084)	Loss 6.1757e-02 (7.8879e-02) 
2023-05-26 01:36:45.298708: train Epoch: [68][124/129]	Time  3.039 ( 2.065)	Data  2.078 ( 1.091)	Loss 8.2789e-02 (7.8910e-02) 
2023-05-26 01:36:46.272182: train Epoch: [68][125/129]	Time  0.973 ( 2.057)	Data  0.001 ( 1.083)	Loss 8.0187e-02 (7.8920e-02) 
2023-05-26 01:36:49.301676: train Epoch: [68][126/129]	Time  3.030 ( 2.064)	Data  2.069 ( 1.091)	Loss 1.0301e-01 (7.9110e-02) 
2023-05-26 01:36:50.270994: train Epoch: [68][127/129]	Time  0.969 ( 2.056)	Data  0.001 ( 1.082)	Loss 3.4073e-01 (8.1153e-02) 
2023-05-26 01:36:52.323482: train Epoch: [68][128/129]	Time  2.052 ( 2.056)	Data  1.082 ( 1.082)	Loss 1.8582e-01 (8.1965e-02) 
2023-05-26 01:36:52.364269: Train Epoch done in 265.22299959999873 s 
2023-05-26 01:36:55.169494: val Epoch: [68][ 0/72]	Time  1.931 ( 1.931)	Data  1.684 ( 1.684)	Loss 3.0427e-01 (3.0427e-01) 
2023-05-26 01:36:55.304964: val Epoch: [68][ 1/72]	Time  0.136 ( 1.033)	Data  0.002 ( 0.843)	Loss 4.6992e-02 (1.7563e-01) 
2023-05-26 01:36:56.384176: val Epoch: [68][ 2/72]	Time  1.079 ( 1.049)	Data  0.946 ( 0.877)	Loss 2.2169e-01 (1.9098e-01) 
2023-05-26 01:36:56.520514: val Epoch: [68][ 3/72]	Time  0.136 ( 0.820)	Data  0.001 ( 0.658)	Loss 1.5937e-01 (1.8308e-01) 
2023-05-26 01:36:57.749824: val Epoch: [68][ 4/72]	Time  1.229 ( 0.902)	Data  1.093 ( 0.745)	Loss 4.3590e-02 (1.5518e-01) 
2023-05-26 01:36:57.888474: val Epoch: [68][ 5/72]	Time  0.139 ( 0.775)	Data  0.001 ( 0.621)	Loss 3.7551e-02 (1.3558e-01) 
2023-05-26 01:36:59.167773: val Epoch: [68][ 6/72]	Time  1.279 ( 0.847)	Data  1.145 ( 0.696)	Loss 5.3152e-02 (1.2380e-01) 
2023-05-26 01:36:59.306424: val Epoch: [68][ 7/72]	Time  0.139 ( 0.758)	Data  0.001 ( 0.609)	Loss 5.4340e-02 (1.1512e-01) 
2023-05-26 01:37:00.534422: val Epoch: [68][ 8/72]	Time  1.228 ( 0.811)	Data  1.090 ( 0.662)	Loss 5.1100e-01 (1.5911e-01) 
2023-05-26 01:37:00.668955: val Epoch: [68][ 9/72]	Time  0.135 ( 0.743)	Data  0.001 ( 0.596)	Loss 9.4767e-02 (1.5267e-01) 
2023-05-26 01:37:01.885116: val Epoch: [68][10/72]	Time  1.216 ( 0.786)	Data  1.080 ( 0.640)	Loss 9.4898e-02 (1.4742e-01) 
2023-05-26 01:37:02.020218: val Epoch: [68][11/72]	Time  0.135 ( 0.732)	Data  0.001 ( 0.587)	Loss 8.9874e-02 (1.4262e-01) 
2023-05-26 01:37:03.288028: val Epoch: [68][12/72]	Time  1.268 ( 0.773)	Data  1.124 ( 0.628)	Loss 3.7565e-01 (1.6055e-01) 
2023-05-26 01:37:03.409815: val Epoch: [68][13/72]	Time  0.122 ( 0.727)	Data  0.001 ( 0.583)	Loss 3.5618e-02 (1.5163e-01) 
2023-05-26 01:37:04.600153: val Epoch: [68][14/72]	Time  1.190 ( 0.757)	Data  1.065 ( 0.616)	Loss 2.8400e-01 (1.6045e-01) 
2023-05-26 01:37:04.726481: val Epoch: [68][15/72]	Time  0.126 ( 0.718)	Data  0.001 ( 0.577)	Loss 1.3919e-01 (1.5912e-01) 
2023-05-26 01:37:05.942372: val Epoch: [68][16/72]	Time  1.216 ( 0.747)	Data  1.090 ( 0.607)	Loss 4.1453e-02 (1.5220e-01) 
2023-05-26 01:37:06.068735: val Epoch: [68][17/72]	Time  0.126 ( 0.713)	Data  0.001 ( 0.574)	Loss 6.1522e-02 (1.4716e-01) 
2023-05-26 01:37:07.272550: val Epoch: [68][18/72]	Time  1.204 ( 0.739)	Data  1.070 ( 0.600)	Loss 3.7112e-02 (1.4137e-01) 
2023-05-26 01:37:07.408737: val Epoch: [68][19/72]	Time  0.136 ( 0.709)	Data  0.001 ( 0.570)	Loss 3.7491e-02 (1.3618e-01) 
2023-05-26 01:37:08.670534: val Epoch: [68][20/72]	Time  1.262 ( 0.735)	Data  1.137 ( 0.597)	Loss 4.3302e-01 (1.5031e-01) 
2023-05-26 01:37:08.802541: val Epoch: [68][21/72]	Time  0.132 ( 0.707)	Data  0.001 ( 0.570)	Loss 2.4923e-01 (1.5481e-01) 
2023-05-26 01:37:10.009761: val Epoch: [68][22/72]	Time  1.207 ( 0.729)	Data  1.082 ( 0.592)	Loss 1.3610e-01 (1.5399e-01) 
2023-05-26 01:37:10.137999: val Epoch: [68][23/72]	Time  0.128 ( 0.704)	Data  0.001 ( 0.567)	Loss 7.9823e-02 (1.5090e-01) 
2023-05-26 01:37:11.418300: val Epoch: [68][24/72]	Time  1.280 ( 0.727)	Data  1.155 ( 0.591)	Loss 1.9780e-01 (1.5278e-01) 
2023-05-26 01:37:11.546181: val Epoch: [68][25/72]	Time  0.128 ( 0.704)	Data  0.001 ( 0.568)	Loss 7.1172e-02 (1.4964e-01) 
2023-05-26 01:37:12.852706: val Epoch: [68][26/72]	Time  1.307 ( 0.726)	Data  1.179 ( 0.591)	Loss 9.0271e-02 (1.4744e-01) 
2023-05-26 01:37:12.982181: val Epoch: [68][27/72]	Time  0.129 ( 0.705)	Data  0.001 ( 0.570)	Loss 1.3212e-01 (1.4690e-01) 
2023-05-26 01:37:14.219207: val Epoch: [68][28/72]	Time  1.237 ( 0.723)	Data  1.109 ( 0.588)	Loss 3.2496e-02 (1.4295e-01) 
2023-05-26 01:37:14.349946: val Epoch: [68][29/72]	Time  0.131 ( 0.704)	Data  0.001 ( 0.569)	Loss 7.5322e-02 (1.4070e-01) 
2023-05-26 01:37:15.656960: val Epoch: [68][30/72]	Time  1.307 ( 0.723)	Data  1.179 ( 0.588)	Loss 1.8140e-01 (1.4201e-01) 
2023-05-26 01:37:15.792763: val Epoch: [68][31/72]	Time  0.136 ( 0.705)	Data  0.001 ( 0.570)	Loss 1.1610e-01 (1.4120e-01) 
2023-05-26 01:37:16.994499: val Epoch: [68][32/72]	Time  1.202 ( 0.720)	Data  1.078 ( 0.585)	Loss 6.1001e-02 (1.3877e-01) 
2023-05-26 01:37:17.130032: val Epoch: [68][33/72]	Time  0.136 ( 0.703)	Data  0.001 ( 0.568)	Loss 4.7423e-01 (1.4864e-01) 
2023-05-26 01:37:18.358440: val Epoch: [68][34/72]	Time  1.228 ( 0.718)	Data  1.101 ( 0.583)	Loss 9.1009e-02 (1.4699e-01) 
2023-05-26 01:37:18.486283: val Epoch: [68][35/72]	Time  0.128 ( 0.701)	Data  0.001 ( 0.567)	Loss 4.8627e-02 (1.4426e-01) 
2023-05-26 01:37:19.793083: val Epoch: [68][36/72]	Time  1.307 ( 0.718)	Data  1.169 ( 0.583)	Loss 3.7008e-01 (1.5036e-01) 
2023-05-26 01:37:19.930638: val Epoch: [68][37/72]	Time  0.138 ( 0.702)	Data  0.001 ( 0.568)	Loss 4.3005e-02 (1.4754e-01) 
2023-05-26 01:37:21.148702: val Epoch: [68][38/72]	Time  1.218 ( 0.716)	Data  1.085 ( 0.581)	Loss 8.9566e-02 (1.4605e-01) 
2023-05-26 01:37:21.281554: val Epoch: [68][39/72]	Time  0.133 ( 0.701)	Data  0.001 ( 0.567)	Loss 1.1727e-01 (1.4533e-01) 
2023-05-26 01:37:22.477146: val Epoch: [68][40/72]	Time  1.196 ( 0.713)	Data  1.074 ( 0.579)	Loss 4.8856e-02 (1.4298e-01) 
2023-05-26 01:37:22.599953: val Epoch: [68][41/72]	Time  0.123 ( 0.699)	Data  0.001 ( 0.565)	Loss 4.8594e-01 (1.5114e-01) 
2023-05-26 01:37:23.872811: val Epoch: [68][42/72]	Time  1.273 ( 0.712)	Data  1.141 ( 0.579)	Loss 6.7506e-02 (1.4920e-01) 
2023-05-26 01:37:24.000634: val Epoch: [68][43/72]	Time  0.128 ( 0.699)	Data  0.001 ( 0.566)	Loss 1.8444e-01 (1.5000e-01) 
2023-05-26 01:37:25.313318: val Epoch: [68][44/72]	Time  1.313 ( 0.713)	Data  1.185 ( 0.579)	Loss 7.0174e-02 (1.4822e-01) 
2023-05-26 01:37:25.452661: val Epoch: [68][45/72]	Time  0.139 ( 0.700)	Data  0.001 ( 0.567)	Loss 1.4285e-01 (1.4811e-01) 
2023-05-26 01:37:26.619381: val Epoch: [68][46/72]	Time  1.167 ( 0.710)	Data  1.034 ( 0.577)	Loss 6.9218e-02 (1.4643e-01) 
2023-05-26 01:37:26.756237: val Epoch: [68][47/72]	Time  0.137 ( 0.698)	Data  0.001 ( 0.565)	Loss 6.8285e-02 (1.4480e-01) 
2023-05-26 01:37:27.952132: val Epoch: [68][48/72]	Time  1.196 ( 0.708)	Data  1.069 ( 0.575)	Loss 2.1797e-01 (1.4629e-01) 
2023-05-26 01:37:28.079767: val Epoch: [68][49/72]	Time  0.128 ( 0.697)	Data  0.001 ( 0.564)	Loss 5.9881e-02 (1.4457e-01) 
2023-05-26 01:37:29.356446: val Epoch: [68][50/72]	Time  1.277 ( 0.708)	Data  1.141 ( 0.575)	Loss 7.4981e-02 (1.4320e-01) 
2023-05-26 01:37:29.487602: val Epoch: [68][51/72]	Time  0.131 ( 0.697)	Data  0.001 ( 0.564)	Loss 5.2810e-02 (1.4146e-01) 
2023-05-26 01:37:30.652756: val Epoch: [68][52/72]	Time  1.165 ( 0.706)	Data  1.038 ( 0.573)	Loss 5.6190e-02 (1.3985e-01) 
2023-05-26 01:37:30.779958: val Epoch: [68][53/72]	Time  0.127 ( 0.695)	Data  0.001 ( 0.562)	Loss 1.5988e-01 (1.4023e-01) 
2023-05-26 01:37:32.033834: val Epoch: [68][54/72]	Time  1.254 ( 0.705)	Data  1.122 ( 0.572)	Loss 9.6943e-02 (1.3944e-01) 
2023-05-26 01:37:32.169427: val Epoch: [68][55/72]	Time  0.136 ( 0.695)	Data  0.001 ( 0.562)	Loss 1.9978e-01 (1.4052e-01) 
2023-05-26 01:37:33.360273: val Epoch: [68][56/72]	Time  1.191 ( 0.704)	Data  1.053 ( 0.571)	Loss 2.5136e-01 (1.4246e-01) 
2023-05-26 01:37:33.487927: val Epoch: [68][57/72]	Time  0.128 ( 0.694)	Data  0.001 ( 0.561)	Loss 5.2088e-02 (1.4090e-01) 
2023-05-26 01:37:34.762139: val Epoch: [68][58/72]	Time  1.274 ( 0.704)	Data  1.147 ( 0.571)	Loss 8.8607e-02 (1.4002e-01) 
2023-05-26 01:37:34.889673: val Epoch: [68][59/72]	Time  0.128 ( 0.694)	Data  0.001 ( 0.561)	Loss 7.4965e-02 (1.3893e-01) 
2023-05-26 01:37:36.188874: val Epoch: [68][60/72]	Time  1.299 ( 0.704)	Data  1.171 ( 0.571)	Loss 1.5177e-01 (1.3914e-01) 
2023-05-26 01:37:36.317570: val Epoch: [68][61/72]	Time  0.129 ( 0.695)	Data  0.001 ( 0.562)	Loss 6.4004e-02 (1.3793e-01) 
2023-05-26 01:37:37.508152: val Epoch: [68][62/72]	Time  1.191 ( 0.703)	Data  1.053 ( 0.570)	Loss 8.7635e-02 (1.3713e-01) 
2023-05-26 01:37:37.647387: val Epoch: [68][63/72]	Time  0.139 ( 0.694)	Data  0.001 ( 0.561)	Loss 7.6979e-02 (1.3619e-01) 
2023-05-26 01:37:38.870432: val Epoch: [68][64/72]	Time  1.223 ( 0.702)	Data  1.090 ( 0.569)	Loss 9.7134e-02 (1.3559e-01) 
2023-05-26 01:37:39.005855: val Epoch: [68][65/72]	Time  0.135 ( 0.693)	Data  0.001 ( 0.561)	Loss 4.7310e-02 (1.3425e-01) 
2023-05-26 01:37:40.249792: val Epoch: [68][66/72]	Time  1.244 ( 0.702)	Data  1.116 ( 0.569)	Loss 3.6149e-01 (1.3765e-01) 
2023-05-26 01:37:40.378823: val Epoch: [68][67/72]	Time  0.129 ( 0.693)	Data  0.001 ( 0.561)	Loss 2.3458e-01 (1.3907e-01) 
2023-05-26 01:37:41.628053: val Epoch: [68][68/72]	Time  1.249 ( 0.701)	Data  1.120 ( 0.569)	Loss 9.5568e-02 (1.3844e-01) 
2023-05-26 01:37:41.755515: val Epoch: [68][69/72]	Time  0.127 ( 0.693)	Data  0.001 ( 0.561)	Loss 3.8915e-01 (1.4202e-01) 
2023-05-26 01:37:42.927414: val Epoch: [68][70/72]	Time  1.172 ( 0.700)	Data  1.045 ( 0.567)	Loss 1.0809e-01 (1.4154e-01) 
2023-05-26 01:37:43.054897: val Epoch: [68][71/72]	Time  0.127 ( 0.692)	Data  0.001 ( 0.560)	Loss 1.0241e-01 (1.4100e-01) 
2023-05-26 01:37:43.269773: Epoch 68 :Val : ['ET : 0.7016990184783936', 'TC : 0.7868332266807556', 'WT : 0.8320605158805847'] 
2023-05-26 01:37:43.273122: Epoch 68 :Val : ['ET : 0.7016990184783936', 'TC : 0.7868332266807556', 'WT : 0.8320605158805847'] 
2023-05-26 01:37:43.276235: Val epoch done in 50.911966849002056 s 
2023-05-26 01:37:43.282609: Batches per epoch:  129 
2023-05-26 01:37:48.755587: train Epoch: [69][  0/129]	Time  5.472 ( 5.472)	Data  4.410 ( 4.410)	Loss 7.8876e-02 (7.8876e-02) 
2023-05-26 01:37:49.732598: train Epoch: [69][  1/129]	Time  0.977 ( 3.225)	Data  0.002 ( 2.206)	Loss 9.1178e-02 (8.5027e-02) 
2023-05-26 01:37:52.737880: train Epoch: [69][  2/129]	Time  3.005 ( 3.152)	Data  2.027 ( 2.146)	Loss 1.3785e-01 (1.0264e-01) 
2023-05-26 01:37:53.708138: train Epoch: [69][  3/129]	Time  0.970 ( 2.606)	Data  0.001 ( 1.610)	Loss 8.5263e-02 (9.8293e-02) 
2023-05-26 01:37:56.923069: train Epoch: [69][  4/129]	Time  3.215 ( 2.728)	Data  2.230 ( 1.734)	Loss 7.4842e-02 (9.3602e-02) 
2023-05-26 01:37:57.893951: train Epoch: [69][  5/129]	Time  0.971 ( 2.435)	Data  0.001 ( 1.445)	Loss 9.8679e-02 (9.4449e-02) 
2023-05-26 01:38:01.127591: train Epoch: [69][  6/129]	Time  3.234 ( 2.549)	Data  2.252 ( 1.560)	Loss 6.4207e-02 (9.0128e-02) 
2023-05-26 01:38:02.093730: train Epoch: [69][  7/129]	Time  0.966 ( 2.351)	Data  0.001 ( 1.366)	Loss 1.0429e-01 (9.1898e-02) 
2023-05-26 01:38:05.174503: train Epoch: [69][  8/129]	Time  3.081 ( 2.432)	Data  2.112 ( 1.448)	Loss 1.0858e-01 (9.3752e-02) 
2023-05-26 01:38:06.156415: train Epoch: [69][  9/129]	Time  0.982 ( 2.287)	Data  0.001 ( 1.304)	Loss 9.1330e-02 (9.3510e-02) 
2023-05-26 01:38:09.354430: train Epoch: [69][ 10/129]	Time  3.198 ( 2.370)	Data  2.228 ( 1.388)	Loss 3.3931e-02 (8.8094e-02) 
2023-05-26 01:38:10.328245: train Epoch: [69][ 11/129]	Time  0.974 ( 2.254)	Data  0.001 ( 1.272)	Loss 1.2433e-01 (9.1114e-02) 
2023-05-26 01:38:13.540837: train Epoch: [69][ 12/129]	Time  3.213 ( 2.328)	Data  2.242 ( 1.347)	Loss 6.2822e-02 (8.8938e-02) 
2023-05-26 01:38:14.524996: train Epoch: [69][ 13/129]	Time  0.984 ( 2.232)	Data  0.001 ( 1.251)	Loss 6.4649e-02 (8.7203e-02) 
2023-05-26 01:38:17.698668: train Epoch: [69][ 14/129]	Time  3.174 ( 2.294)	Data  2.198 ( 1.314)	Loss 7.6205e-02 (8.6469e-02) 
2023-05-26 01:38:18.664021: train Epoch: [69][ 15/129]	Time  0.965 ( 2.211)	Data  0.001 ( 1.232)	Loss 9.6264e-02 (8.7082e-02) 
2023-05-26 01:38:21.692843: train Epoch: [69][ 16/129]	Time  3.029 ( 2.259)	Data  2.058 ( 1.280)	Loss 8.9546e-02 (8.7227e-02) 
2023-05-26 01:38:22.660927: train Epoch: [69][ 17/129]	Time  0.968 ( 2.188)	Data  0.002 ( 1.209)	Loss 1.6507e-01 (9.1551e-02) 
2023-05-26 01:38:25.782474: train Epoch: [69][ 18/129]	Time  3.122 ( 2.237)	Data  2.151 ( 1.259)	Loss 2.1772e-01 (9.8192e-02) 
2023-05-26 01:38:26.769967: train Epoch: [69][ 19/129]	Time  0.987 ( 2.174)	Data  0.001 ( 1.196)	Loss 8.6388e-02 (9.7602e-02) 
2023-05-26 01:38:29.885479: train Epoch: [69][ 20/129]	Time  3.116 ( 2.219)	Data  2.133 ( 1.241)	Loss 8.5034e-02 (9.7003e-02) 
2023-05-26 01:38:30.875773: train Epoch: [69][ 21/129]	Time  0.990 ( 2.163)	Data  0.001 ( 1.184)	Loss 6.3089e-02 (9.5462e-02) 
2023-05-26 01:38:33.932990: train Epoch: [69][ 22/129]	Time  3.057 ( 2.202)	Data  2.099 ( 1.224)	Loss 9.4918e-02 (9.5438e-02) 
2023-05-26 01:38:34.922354: train Epoch: [69][ 23/129]	Time  0.989 ( 2.152)	Data  0.001 ( 1.173)	Loss 6.0892e-02 (9.3999e-02) 
2023-05-26 01:38:37.970661: train Epoch: [69][ 24/129]	Time  3.048 ( 2.188)	Data  2.075 ( 1.209)	Loss 7.1823e-02 (9.3112e-02) 
2023-05-26 01:38:38.951298: train Epoch: [69][ 25/129]	Time  0.981 ( 2.141)	Data  0.001 ( 1.163)	Loss 7.8131e-02 (9.2535e-02) 
2023-05-26 01:38:42.138081: train Epoch: [69][ 26/129]	Time  3.187 ( 2.180)	Data  2.220 ( 1.202)	Loss 1.4894e-01 (9.4624e-02) 
2023-05-26 01:38:43.107184: train Epoch: [69][ 27/129]	Time  0.969 ( 2.137)	Data  0.001 ( 1.159)	Loss 7.9754e-02 (9.4093e-02) 
2023-05-26 01:38:46.201318: train Epoch: [69][ 28/129]	Time  3.094 ( 2.170)	Data  2.129 ( 1.192)	Loss 8.7524e-02 (9.3867e-02) 
2023-05-26 01:38:47.170649: train Epoch: [69][ 29/129]	Time  0.969 ( 2.130)	Data  0.001 ( 1.153)	Loss 8.5067e-02 (9.3574e-02) 
2023-05-26 01:38:50.269898: train Epoch: [69][ 30/129]	Time  3.099 ( 2.161)	Data  2.135 ( 1.184)	Loss 1.1840e-01 (9.4374e-02) 
2023-05-26 01:38:51.237827: train Epoch: [69][ 31/129]	Time  0.968 ( 2.124)	Data  0.001 ( 1.147)	Loss 9.7016e-02 (9.4457e-02) 
2023-05-26 01:38:54.358974: train Epoch: [69][ 32/129]	Time  3.121 ( 2.154)	Data  2.149 ( 1.178)	Loss 1.3739e-01 (9.5758e-02) 
2023-05-26 01:38:55.322842: train Epoch: [69][ 33/129]	Time  0.964 ( 2.119)	Data  0.001 ( 1.143)	Loss 9.0044e-02 (9.5590e-02) 
2023-05-26 01:38:58.339493: train Epoch: [69][ 34/129]	Time  3.017 ( 2.144)	Data  2.048 ( 1.169)	Loss 5.7019e-02 (9.4488e-02) 
2023-05-26 01:38:59.316444: train Epoch: [69][ 35/129]	Time  0.977 ( 2.112)	Data  0.001 ( 1.137)	Loss 6.2087e-02 (9.3588e-02) 
2023-05-26 01:39:02.437598: train Epoch: [69][ 36/129]	Time  3.121 ( 2.139)	Data  2.156 ( 1.164)	Loss 8.3999e-02 (9.3329e-02) 
2023-05-26 01:39:03.408109: train Epoch: [69][ 37/129]	Time  0.970 ( 2.109)	Data  0.001 ( 1.134)	Loss 6.5339e-02 (9.2592e-02) 
2023-05-26 01:39:06.513883: train Epoch: [69][ 38/129]	Time  3.106 ( 2.134)	Data  2.138 ( 1.159)	Loss 9.4995e-02 (9.2654e-02) 
2023-05-26 01:39:07.483100: train Epoch: [69][ 39/129]	Time  0.969 ( 2.105)	Data  0.001 ( 1.130)	Loss 7.2978e-02 (9.2162e-02) 
2023-05-26 01:39:10.641152: train Epoch: [69][ 40/129]	Time  3.158 ( 2.131)	Data  2.177 ( 1.156)	Loss 7.5299e-02 (9.1750e-02) 
2023-05-26 01:39:11.628470: train Epoch: [69][ 41/129]	Time  0.987 ( 2.103)	Data  0.001 ( 1.128)	Loss 7.1368e-02 (9.1265e-02) 
2023-05-26 01:39:14.605559: train Epoch: [69][ 42/129]	Time  2.977 ( 2.124)	Data  1.996 ( 1.149)	Loss 3.9661e-02 (9.0065e-02) 
2023-05-26 01:39:15.595747: train Epoch: [69][ 43/129]	Time  0.990 ( 2.098)	Data  0.002 ( 1.122)	Loss 7.9632e-02 (8.9828e-02) 
2023-05-26 01:39:18.625718: train Epoch: [69][ 44/129]	Time  3.030 ( 2.119)	Data  2.075 ( 1.144)	Loss 1.0440e-01 (9.0152e-02) 
2023-05-26 01:39:19.594648: train Epoch: [69][ 45/129]	Time  0.969 ( 2.094)	Data  0.001 ( 1.119)	Loss 1.5366e-01 (9.1532e-02) 
2023-05-26 01:39:22.607100: train Epoch: [69][ 46/129]	Time  3.012 ( 2.113)	Data  2.046 ( 1.139)	Loss 8.9621e-02 (9.1492e-02) 
2023-05-26 01:39:23.579538: train Epoch: [69][ 47/129]	Time  0.972 ( 2.090)	Data  0.001 ( 1.115)	Loss 8.8399e-02 (9.1427e-02) 
2023-05-26 01:39:26.600317: train Epoch: [69][ 48/129]	Time  3.021 ( 2.109)	Data  2.055 ( 1.134)	Loss 7.4481e-02 (9.1081e-02) 
2023-05-26 01:39:27.575476: train Epoch: [69][ 49/129]	Time  0.975 ( 2.086)	Data  0.001 ( 1.111)	Loss 6.1288e-02 (9.0485e-02) 
2023-05-26 01:39:30.700620: train Epoch: [69][ 50/129]	Time  3.125 ( 2.106)	Data  2.160 ( 1.132)	Loss 7.6567e-02 (9.0212e-02) 
2023-05-26 01:39:31.672083: train Epoch: [69][ 51/129]	Time  0.971 ( 2.084)	Data  0.001 ( 1.110)	Loss 1.0442e-01 (9.0486e-02) 
2023-05-26 01:39:34.710994: train Epoch: [69][ 52/129]	Time  3.039 ( 2.102)	Data  2.064 ( 1.128)	Loss 1.6782e-01 (9.1945e-02) 
2023-05-26 01:39:35.694459: train Epoch: [69][ 53/129]	Time  0.983 ( 2.082)	Data  0.001 ( 1.107)	Loss 1.4747e-01 (9.2973e-02) 
2023-05-26 01:39:38.792949: train Epoch: [69][ 54/129]	Time  3.098 ( 2.100)	Data  2.125 ( 1.126)	Loss 8.8879e-02 (9.2898e-02) 
2023-05-26 01:39:39.778036: train Epoch: [69][ 55/129]	Time  0.985 ( 2.080)	Data  0.002 ( 1.106)	Loss 6.2477e-02 (9.2355e-02) 
2023-05-26 01:39:42.741354: train Epoch: [69][ 56/129]	Time  2.963 ( 2.096)	Data  1.979 ( 1.121)	Loss 8.4249e-02 (9.2213e-02) 
2023-05-26 01:39:43.719115: train Epoch: [69][ 57/129]	Time  0.978 ( 2.076)	Data  0.001 ( 1.102)	Loss 1.2092e-01 (9.2708e-02) 
2023-05-26 01:39:46.770307: train Epoch: [69][ 58/129]	Time  3.051 ( 2.093)	Data  2.080 ( 1.118)	Loss 9.0488e-02 (9.2670e-02) 
2023-05-26 01:39:47.754388: train Epoch: [69][ 59/129]	Time  0.984 ( 2.075)	Data  0.003 ( 1.100)	Loss 1.1390e-01 (9.3024e-02) 
2023-05-26 01:39:50.916654: train Epoch: [69][ 60/129]	Time  3.162 ( 2.092)	Data  2.175 ( 1.117)	Loss 6.5378e-02 (9.2571e-02) 
2023-05-26 01:39:51.904905: train Epoch: [69][ 61/129]	Time  0.988 ( 2.075)	Data  0.001 ( 1.099)	Loss 8.3983e-02 (9.2432e-02) 
2023-05-26 01:39:54.955046: train Epoch: [69][ 62/129]	Time  3.050 ( 2.090)	Data  2.079 ( 1.115)	Loss 7.6505e-02 (9.2180e-02) 
2023-05-26 01:39:55.930460: train Epoch: [69][ 63/129]	Time  0.975 ( 2.073)	Data  0.001 ( 1.098)	Loss 8.4790e-02 (9.2064e-02) 
2023-05-26 01:39:59.149002: train Epoch: [69][ 64/129]	Time  3.219 ( 2.090)	Data  2.251 ( 1.115)	Loss 5.3676e-02 (9.1474e-02) 
2023-05-26 01:40:00.121814: train Epoch: [69][ 65/129]	Time  0.973 ( 2.073)	Data  0.001 ( 1.098)	Loss 9.7718e-02 (9.1568e-02) 
2023-05-26 01:40:03.186380: train Epoch: [69][ 66/129]	Time  3.065 ( 2.088)	Data  2.098 ( 1.113)	Loss 7.9411e-02 (9.1387e-02) 
2023-05-26 01:40:04.161552: train Epoch: [69][ 67/129]	Time  0.975 ( 2.072)	Data  0.001 ( 1.097)	Loss 1.0581e-01 (9.1599e-02) 
2023-05-26 01:40:07.291468: train Epoch: [69][ 68/129]	Time  3.130 ( 2.087)	Data  2.150 ( 1.112)	Loss 1.6329e-01 (9.2638e-02) 
2023-05-26 01:40:08.288183: train Epoch: [69][ 69/129]	Time  0.997 ( 2.071)	Data  0.002 ( 1.096)	Loss 9.0158e-02 (9.2602e-02) 
2023-05-26 01:40:11.445389: train Epoch: [69][ 70/129]	Time  3.157 ( 2.087)	Data  2.173 ( 1.112)	Loss 1.1099e-01 (9.2861e-02) 
2023-05-26 01:40:12.427227: train Epoch: [69][ 71/129]	Time  0.982 ( 2.071)	Data  0.002 ( 1.096)	Loss 7.1387e-02 (9.2563e-02) 
2023-05-26 01:40:15.480228: train Epoch: [69][ 72/129]	Time  3.053 ( 2.085)	Data  2.068 ( 1.109)	Loss 1.1235e-01 (9.2834e-02) 
2023-05-26 01:40:16.472365: train Epoch: [69][ 73/129]	Time  0.992 ( 2.070)	Data  0.002 ( 1.094)	Loss 8.1457e-02 (9.2680e-02) 
2023-05-26 01:40:19.688648: train Epoch: [69][ 74/129]	Time  3.216 ( 2.085)	Data  2.245 ( 1.110)	Loss 8.0350e-02 (9.2516e-02) 
2023-05-26 01:40:20.660858: train Epoch: [69][ 75/129]	Time  0.972 ( 2.071)	Data  0.001 ( 1.095)	Loss 7.4600e-02 (9.2280e-02) 
2023-05-26 01:40:23.698793: train Epoch: [69][ 76/129]	Time  3.038 ( 2.083)	Data  2.074 ( 1.108)	Loss 7.7730e-02 (9.2091e-02) 
2023-05-26 01:40:24.672224: train Epoch: [69][ 77/129]	Time  0.973 ( 2.069)	Data  0.001 ( 1.094)	Loss 6.6817e-02 (9.1767e-02) 
2023-05-26 01:40:27.745468: train Epoch: [69][ 78/129]	Time  3.073 ( 2.082)	Data  2.099 ( 1.106)	Loss 7.8514e-02 (9.1599e-02) 
2023-05-26 01:40:28.735305: train Epoch: [69][ 79/129]	Time  0.990 ( 2.068)	Data  0.001 ( 1.093)	Loss 1.0910e-01 (9.1818e-02) 
2023-05-26 01:40:31.849993: train Epoch: [69][ 80/129]	Time  3.115 ( 2.081)	Data  2.148 ( 1.106)	Loss 8.9474e-02 (9.1789e-02) 
2023-05-26 01:40:32.833542: train Epoch: [69][ 81/129]	Time  0.984 ( 2.068)	Data  0.001 ( 1.092)	Loss 1.0273e-01 (9.1923e-02) 
2023-05-26 01:40:35.953140: train Epoch: [69][ 82/129]	Time  3.120 ( 2.080)	Data  2.145 ( 1.105)	Loss 5.5225e-02 (9.1480e-02) 
2023-05-26 01:40:36.929490: train Epoch: [69][ 83/129]	Time  0.976 ( 2.067)	Data  0.001 ( 1.092)	Loss 5.0670e-02 (9.0995e-02) 
2023-05-26 01:40:39.997483: train Epoch: [69][ 84/129]	Time  3.068 ( 2.079)	Data  2.103 ( 1.104)	Loss 5.5542e-02 (9.0578e-02) 
2023-05-26 01:40:40.982878: train Epoch: [69][ 85/129]	Time  0.985 ( 2.066)	Data  0.001 ( 1.091)	Loss 7.7365e-02 (9.0424e-02) 
2023-05-26 01:40:44.087510: train Epoch: [69][ 86/129]	Time  3.105 ( 2.078)	Data  2.129 ( 1.103)	Loss 9.7905e-02 (9.0510e-02) 
2023-05-26 01:40:45.068264: train Epoch: [69][ 87/129]	Time  0.981 ( 2.066)	Data  0.001 ( 1.090)	Loss 4.8557e-02 (9.0033e-02) 
2023-05-26 01:40:48.330033: train Epoch: [69][ 88/129]	Time  3.262 ( 2.079)	Data  2.287 ( 1.104)	Loss 5.6834e-02 (8.9660e-02) 
2023-05-26 01:40:49.299719: train Epoch: [69][ 89/129]	Time  0.970 ( 2.067)	Data  0.001 ( 1.091)	Loss 6.2565e-02 (8.9359e-02) 
2023-05-26 01:40:52.407661: train Epoch: [69][ 90/129]	Time  3.108 ( 2.078)	Data  2.146 ( 1.103)	Loss 7.9807e-02 (8.9254e-02) 
2023-05-26 01:40:53.381977: train Epoch: [69][ 91/129]	Time  0.974 ( 2.066)	Data  0.001 ( 1.091)	Loss 7.6395e-02 (8.9114e-02) 
2023-05-26 01:40:56.418504: train Epoch: [69][ 92/129]	Time  3.037 ( 2.077)	Data  2.065 ( 1.102)	Loss 7.2385e-02 (8.8934e-02) 
2023-05-26 01:40:57.389631: train Epoch: [69][ 93/129]	Time  0.971 ( 2.065)	Data  0.001 ( 1.090)	Loss 7.6781e-02 (8.8805e-02) 
2023-05-26 01:41:00.462802: train Epoch: [69][ 94/129]	Time  3.073 ( 2.076)	Data  2.104 ( 1.100)	Loss 5.3262e-02 (8.8431e-02) 
2023-05-26 01:41:01.431483: train Epoch: [69][ 95/129]	Time  0.969 ( 2.064)	Data  0.001 ( 1.089)	Loss 9.1104e-02 (8.8459e-02) 
2023-05-26 01:41:04.525291: train Epoch: [69][ 96/129]	Time  3.094 ( 2.075)	Data  2.124 ( 1.100)	Loss 6.4556e-02 (8.8212e-02) 
2023-05-26 01:41:05.495264: train Epoch: [69][ 97/129]	Time  0.970 ( 2.063)	Data  0.001 ( 1.088)	Loss 7.5199e-02 (8.8080e-02) 
2023-05-26 01:41:08.607975: train Epoch: [69][ 98/129]	Time  3.113 ( 2.074)	Data  2.145 ( 1.099)	Loss 1.5767e-01 (8.8783e-02) 
2023-05-26 01:41:09.579317: train Epoch: [69][ 99/129]	Time  0.971 ( 2.063)	Data  0.001 ( 1.088)	Loss 2.3490e-01 (9.0244e-02) 
2023-05-26 01:41:12.687253: train Epoch: [69][100/129]	Time  3.108 ( 2.073)	Data  2.146 ( 1.099)	Loss 9.3689e-02 (9.0278e-02) 
2023-05-26 01:41:13.655590: train Epoch: [69][101/129]	Time  0.968 ( 2.062)	Data  0.001 ( 1.088)	Loss 6.4093e-02 (9.0021e-02) 
2023-05-26 01:41:16.480981: train Epoch: [69][102/129]	Time  2.825 ( 2.070)	Data  1.866 ( 1.095)	Loss 1.3391e-01 (9.0447e-02) 
2023-05-26 01:41:17.440878: train Epoch: [69][103/129]	Time  0.960 ( 2.059)	Data  0.001 ( 1.085)	Loss 5.1150e-02 (9.0069e-02) 
2023-05-26 01:41:20.250168: train Epoch: [69][104/129]	Time  2.809 ( 2.066)	Data  1.859 ( 1.092)	Loss 7.3815e-02 (8.9915e-02) 
2023-05-26 01:41:21.201140: train Epoch: [69][105/129]	Time  0.951 ( 2.056)	Data  0.001 ( 1.082)	Loss 1.2589e-01 (9.0254e-02) 
2023-05-26 01:41:23.886988: train Epoch: [69][106/129]	Time  2.686 ( 2.062)	Data  1.732 ( 1.088)	Loss 5.8560e-02 (8.9958e-02) 
2023-05-26 01:41:24.838252: train Epoch: [69][107/129]	Time  0.951 ( 2.051)	Data  0.001 ( 1.078)	Loss 6.9087e-02 (8.9764e-02) 
2023-05-26 01:41:27.562588: train Epoch: [69][108/129]	Time  2.724 ( 2.058)	Data  1.777 ( 1.084)	Loss 5.7744e-02 (8.9471e-02) 
2023-05-26 01:41:28.515203: train Epoch: [69][109/129]	Time  0.953 ( 2.048)	Data  0.001 ( 1.075)	Loss 9.9846e-02 (8.9565e-02) 
2023-05-26 01:41:31.276767: train Epoch: [69][110/129]	Time  2.762 ( 2.054)	Data  1.814 ( 1.081)	Loss 8.2304e-02 (8.9500e-02) 
2023-05-26 01:41:32.225829: train Epoch: [69][111/129]	Time  0.949 ( 2.044)	Data  0.001 ( 1.072)	Loss 7.3145e-02 (8.9354e-02) 
2023-05-26 01:41:34.873375: train Epoch: [69][112/129]	Time  2.648 ( 2.049)	Data  1.700 ( 1.077)	Loss 5.6170e-02 (8.9060e-02) 
2023-05-26 01:41:35.823851: train Epoch: [69][113/129]	Time  0.950 ( 2.040)	Data  0.001 ( 1.068)	Loss 8.5738e-02 (8.9031e-02) 
2023-05-26 01:41:38.518443: train Epoch: [69][114/129]	Time  2.695 ( 2.046)	Data  1.747 ( 1.074)	Loss 5.1077e-02 (8.8701e-02) 
2023-05-26 01:41:39.469427: train Epoch: [69][115/129]	Time  0.951 ( 2.036)	Data  0.001 ( 1.064)	Loss 1.6646e-01 (8.9371e-02) 
2023-05-26 01:41:42.154492: train Epoch: [69][116/129]	Time  2.685 ( 2.042)	Data  1.738 ( 1.070)	Loss 6.8045e-02 (8.9189e-02) 
2023-05-26 01:41:43.105010: train Epoch: [69][117/129]	Time  0.951 ( 2.032)	Data  0.001 ( 1.061)	Loss 1.4219e-01 (8.9638e-02) 
2023-05-26 01:41:45.895474: train Epoch: [69][118/129]	Time  2.790 ( 2.039)	Data  1.843 ( 1.068)	Loss 5.8050e-02 (8.9373e-02) 
2023-05-26 01:41:46.846066: train Epoch: [69][119/129]	Time  0.951 ( 2.030)	Data  0.001 ( 1.059)	Loss 6.5702e-02 (8.9175e-02) 
2023-05-26 01:41:49.558000: train Epoch: [69][120/129]	Time  2.712 ( 2.035)	Data  1.763 ( 1.065)	Loss 5.1985e-02 (8.8868e-02) 
2023-05-26 01:41:50.507929: train Epoch: [69][121/129]	Time  0.950 ( 2.026)	Data  0.001 ( 1.056)	Loss 8.3258e-02 (8.8822e-02) 
2023-05-26 01:41:53.206753: train Epoch: [69][122/129]	Time  2.699 ( 2.032)	Data  1.750 ( 1.061)	Loss 6.3227e-02 (8.8614e-02) 
2023-05-26 01:41:54.157506: train Epoch: [69][123/129]	Time  0.951 ( 2.023)	Data  0.001 ( 1.053)	Loss 4.2464e-02 (8.8242e-02) 
2023-05-26 01:41:56.920105: train Epoch: [69][124/129]	Time  2.763 ( 2.029)	Data  1.807 ( 1.059)	Loss 7.4949e-02 (8.8135e-02) 
2023-05-26 01:41:57.911542: train Epoch: [69][125/129]	Time  0.991 ( 2.021)	Data  0.001 ( 1.051)	Loss 6.9888e-02 (8.7991e-02) 
2023-05-26 01:42:00.896184: train Epoch: [69][126/129]	Time  2.985 ( 2.028)	Data  2.013 ( 1.058)	Loss 1.1298e-01 (8.8187e-02) 
2023-05-26 01:42:01.863596: train Epoch: [69][127/129]	Time  0.967 ( 2.020)	Data  0.001 ( 1.050)	Loss 1.2891e-01 (8.8505e-02) 
2023-05-26 01:42:03.907462: train Epoch: [69][128/129]	Time  2.044 ( 2.020)	Data  1.079 ( 1.050)	Loss 1.0505e-01 (8.8634e-02) 
2023-05-26 01:42:03.960914: Train Epoch done in 260.6783591659987 s 
2023-05-26 01:42:06.841951: val Epoch: [69][ 0/72]	Time  1.905 ( 1.905)	Data  1.681 ( 1.681)	Loss 3.7033e-01 (3.7033e-01) 
2023-05-26 01:42:06.969339: val Epoch: [69][ 1/72]	Time  0.128 ( 1.016)	Data  0.001 ( 0.841)	Loss 1.7071e-01 (2.7052e-01) 
2023-05-26 01:42:08.110363: val Epoch: [69][ 2/72]	Time  1.141 ( 1.058)	Data  1.012 ( 0.898)	Loss 4.4412e-02 (1.9515e-01) 
2023-05-26 01:42:08.238175: val Epoch: [69][ 3/72]	Time  0.128 ( 0.825)	Data  0.001 ( 0.674)	Loss 4.4662e-02 (1.5753e-01) 
2023-05-26 01:42:09.492833: val Epoch: [69][ 4/72]	Time  1.255 ( 0.911)	Data  1.119 ( 0.763)	Loss 3.7605e-02 (1.3354e-01) 
2023-05-26 01:42:09.625515: val Epoch: [69][ 5/72]	Time  0.133 ( 0.781)	Data  0.002 ( 0.636)	Loss 3.9401e-02 (1.1785e-01) 
2023-05-26 01:42:10.903952: val Epoch: [69][ 6/72]	Time  1.278 ( 0.852)	Data  1.150 ( 0.710)	Loss 8.2211e-02 (1.1276e-01) 
2023-05-26 01:42:11.031996: val Epoch: [69][ 7/72]	Time  0.128 ( 0.762)	Data  0.001 ( 0.621)	Loss 3.8164e-02 (1.0344e-01) 
2023-05-26 01:42:12.233477: val Epoch: [69][ 8/72]	Time  1.201 ( 0.811)	Data  1.065 ( 0.670)	Loss 4.9351e-02 (9.7428e-02) 
2023-05-26 01:42:12.363302: val Epoch: [69][ 9/72]	Time  0.130 ( 0.743)	Data  0.001 ( 0.603)	Loss 3.3167e-01 (1.2085e-01) 
2023-05-26 01:42:13.604001: val Epoch: [69][10/72]	Time  1.241 ( 0.788)	Data  1.107 ( 0.649)	Loss 1.0160e-01 (1.1910e-01) 
2023-05-26 01:42:13.734439: val Epoch: [69][11/72]	Time  0.130 ( 0.733)	Data  0.001 ( 0.595)	Loss 6.6335e-02 (1.1470e-01) 
2023-05-26 01:42:14.995267: val Epoch: [69][12/72]	Time  1.261 ( 0.774)	Data  1.116 ( 0.635)	Loss 1.9484e-01 (1.2087e-01) 
2023-05-26 01:42:15.123894: val Epoch: [69][13/72]	Time  0.129 ( 0.728)	Data  0.001 ( 0.590)	Loss 6.0971e-02 (1.1659e-01) 
2023-05-26 01:42:16.373149: val Epoch: [69][14/72]	Time  1.249 ( 0.762)	Data  1.113 ( 0.625)	Loss 5.4201e-02 (1.1243e-01) 
2023-05-26 01:42:16.499263: val Epoch: [69][15/72]	Time  0.126 ( 0.723)	Data  0.001 ( 0.586)	Loss 3.7757e-01 (1.2900e-01) 
2023-05-26 01:42:17.784229: val Epoch: [69][16/72]	Time  1.285 ( 0.756)	Data  1.154 ( 0.619)	Loss 9.2661e-02 (1.2686e-01) 
2023-05-26 01:42:17.910534: val Epoch: [69][17/72]	Time  0.126 ( 0.721)	Data  0.001 ( 0.585)	Loss 1.4981e-01 (1.2814e-01) 
2023-05-26 01:42:19.261533: val Epoch: [69][18/72]	Time  1.351 ( 0.754)	Data  1.222 ( 0.618)	Loss 8.3996e-02 (1.2582e-01) 
2023-05-26 01:42:19.389630: val Epoch: [69][19/72]	Time  0.128 ( 0.723)	Data  0.001 ( 0.588)	Loss 3.0664e-01 (1.3486e-01) 
2023-05-26 01:42:20.671208: val Epoch: [69][20/72]	Time  1.282 ( 0.749)	Data  1.153 ( 0.614)	Loss 4.8247e-02 (1.3073e-01) 
2023-05-26 01:42:20.798168: val Epoch: [69][21/72]	Time  0.127 ( 0.721)	Data  0.001 ( 0.587)	Loss 2.5824e-01 (1.3653e-01) 
2023-05-26 01:42:22.037084: val Epoch: [69][22/72]	Time  1.239 ( 0.743)	Data  1.110 ( 0.609)	Loss 5.9336e-02 (1.3317e-01) 
2023-05-26 01:42:22.163292: val Epoch: [69][23/72]	Time  0.126 ( 0.718)	Data  0.001 ( 0.584)	Loss 5.7806e-02 (1.3003e-01) 
2023-05-26 01:42:23.368639: val Epoch: [69][24/72]	Time  1.205 ( 0.737)	Data  1.078 ( 0.604)	Loss 5.7019e-02 (1.2711e-01) 
2023-05-26 01:42:23.497491: val Epoch: [69][25/72]	Time  0.129 ( 0.714)	Data  0.001 ( 0.581)	Loss 7.2937e-02 (1.2503e-01) 
2023-05-26 01:42:24.691030: val Epoch: [69][26/72]	Time  1.194 ( 0.732)	Data  1.067 ( 0.599)	Loss 4.7324e-02 (1.2215e-01) 
2023-05-26 01:42:24.819878: val Epoch: [69][27/72]	Time  0.129 ( 0.710)	Data  0.001 ( 0.577)	Loss 1.1195e-01 (1.2179e-01) 
2023-05-26 01:42:26.108417: val Epoch: [69][28/72]	Time  1.289 ( 0.730)	Data  1.148 ( 0.597)	Loss 1.4933e-01 (1.2274e-01) 
2023-05-26 01:42:26.236548: val Epoch: [69][29/72]	Time  0.128 ( 0.710)	Data  0.001 ( 0.577)	Loss 2.0833e-01 (1.2559e-01) 
2023-05-26 01:42:27.402319: val Epoch: [69][30/72]	Time  1.166 ( 0.725)	Data  1.039 ( 0.592)	Loss 3.8124e-02 (1.2277e-01) 
2023-05-26 01:42:27.610146: val Epoch: [69][31/72]	Time  0.208 ( 0.709)	Data  0.081 ( 0.576)	Loss 5.6334e-02 (1.2069e-01) 
2023-05-26 01:42:28.803067: val Epoch: [69][32/72]	Time  1.193 ( 0.723)	Data  1.064 ( 0.591)	Loss 8.4725e-02 (1.1960e-01) 
2023-05-26 01:42:28.986399: val Epoch: [69][33/72]	Time  0.183 ( 0.707)	Data  0.054 ( 0.575)	Loss 8.1431e-02 (1.1848e-01) 
2023-05-26 01:42:30.089431: val Epoch: [69][34/72]	Time  1.103 ( 0.719)	Data  0.968 ( 0.586)	Loss 6.0380e-02 (1.1682e-01) 
2023-05-26 01:42:30.377793: val Epoch: [69][35/72]	Time  0.288 ( 0.707)	Data  0.158 ( 0.574)	Loss 9.5620e-02 (1.1623e-01) 
2023-05-26 01:42:31.528288: val Epoch: [69][36/72]	Time  1.150 ( 0.719)	Data  1.016 ( 0.586)	Loss 5.9272e-02 (1.1469e-01) 
2023-05-26 01:42:31.734510: val Epoch: [69][37/72]	Time  0.206 ( 0.705)	Data  0.066 ( 0.573)	Loss 5.2834e-02 (1.1306e-01) 
2023-05-26 01:42:32.893891: val Epoch: [69][38/72]	Time  1.159 ( 0.717)	Data  1.029 ( 0.584)	Loss 1.2921e-01 (1.1348e-01) 
2023-05-26 01:42:33.165790: val Epoch: [69][39/72]	Time  0.272 ( 0.706)	Data  0.131 ( 0.573)	Loss 8.5117e-02 (1.1277e-01) 
2023-05-26 01:42:34.221368: val Epoch: [69][40/72]	Time  1.056 ( 0.714)	Data  0.928 ( 0.582)	Loss 4.4085e-02 (1.1109e-01) 
2023-05-26 01:42:34.476970: val Epoch: [69][41/72]	Time  0.256 ( 0.703)	Data  0.129 ( 0.571)	Loss 5.1992e-02 (1.0969e-01) 
2023-05-26 01:42:35.624914: val Epoch: [69][42/72]	Time  1.148 ( 0.714)	Data  1.020 ( 0.581)	Loss 4.6325e-01 (1.1791e-01) 
2023-05-26 01:42:35.856968: val Epoch: [69][43/72]	Time  0.232 ( 0.703)	Data  0.104 ( 0.570)	Loss 1.3180e-01 (1.1822e-01) 
2023-05-26 01:42:36.952287: val Epoch: [69][44/72]	Time  1.095 ( 0.711)	Data  0.969 ( 0.579)	Loss 1.2868e-01 (1.1846e-01) 
2023-05-26 01:42:37.200284: val Epoch: [69][45/72]	Time  0.248 ( 0.701)	Data  0.121 ( 0.569)	Loss 1.0318e-01 (1.1812e-01) 
2023-05-26 01:42:38.315691: val Epoch: [69][46/72]	Time  1.115 ( 0.710)	Data  0.979 ( 0.578)	Loss 4.6481e-02 (1.1660e-01) 
2023-05-26 01:42:38.552145: val Epoch: [69][47/72]	Time  0.236 ( 0.700)	Data  0.101 ( 0.568)	Loss 1.1878e-01 (1.1665e-01) 
2023-05-26 01:42:39.581313: val Epoch: [69][48/72]	Time  1.029 ( 0.707)	Data  0.896 ( 0.575)	Loss 5.9254e-02 (1.1547e-01) 
2023-05-26 01:42:39.869829: val Epoch: [69][49/72]	Time  0.289 ( 0.699)	Data  0.159 ( 0.566)	Loss 2.5186e-01 (1.1820e-01) 
2023-05-26 01:42:40.964842: val Epoch: [69][50/72]	Time  1.095 ( 0.706)	Data  0.958 ( 0.574)	Loss 6.2195e-02 (1.1710e-01) 
2023-05-26 01:42:41.202165: val Epoch: [69][51/72]	Time  0.237 ( 0.697)	Data  0.110 ( 0.565)	Loss 4.4898e-01 (1.2349e-01) 
2023-05-26 01:42:42.331240: val Epoch: [69][52/72]	Time  1.129 ( 0.706)	Data  1.003 ( 0.573)	Loss 3.3471e-01 (1.2747e-01) 
2023-05-26 01:42:42.508254: val Epoch: [69][53/72]	Time  0.177 ( 0.696)	Data  0.054 ( 0.564)	Loss 8.1334e-02 (1.2662e-01) 
2023-05-26 01:42:43.639305: val Epoch: [69][54/72]	Time  1.131 ( 0.704)	Data  0.996 ( 0.572)	Loss 4.6381e-02 (1.2516e-01) 
2023-05-26 01:42:43.874090: val Epoch: [69][55/72]	Time  0.235 ( 0.695)	Data  0.100 ( 0.563)	Loss 8.3912e-02 (1.2442e-01) 
2023-05-26 01:42:44.937801: val Epoch: [69][56/72]	Time  1.064 ( 0.702)	Data  0.941 ( 0.570)	Loss 5.8294e-02 (1.2326e-01) 
2023-05-26 01:42:45.249358: val Epoch: [69][57/72]	Time  0.312 ( 0.695)	Data  0.185 ( 0.563)	Loss 1.7247e-01 (1.2411e-01) 
2023-05-26 01:42:46.333394: val Epoch: [69][58/72]	Time  1.084 ( 0.702)	Data  0.945 ( 0.570)	Loss 4.8849e-02 (1.2283e-01) 
2023-05-26 01:42:46.632478: val Epoch: [69][59/72]	Time  0.299 ( 0.695)	Data  0.160 ( 0.563)	Loss 8.8073e-02 (1.2225e-01) 
2023-05-26 01:42:47.688751: val Epoch: [69][60/72]	Time  1.056 ( 0.701)	Data  0.926 ( 0.569)	Loss 6.8427e-02 (1.2137e-01) 
2023-05-26 01:42:48.001845: val Epoch: [69][61/72]	Time  0.313 ( 0.695)	Data  0.186 ( 0.563)	Loss 1.0574e-01 (1.2112e-01) 
2023-05-26 01:42:49.057066: val Epoch: [69][62/72]	Time  1.055 ( 0.700)	Data  0.927 ( 0.568)	Loss 2.0378e-01 (1.2243e-01) 
2023-05-26 01:42:49.345027: val Epoch: [69][63/72]	Time  0.288 ( 0.694)	Data  0.160 ( 0.562)	Loss 6.1336e-02 (1.2148e-01) 
2023-05-26 01:42:50.403973: val Epoch: [69][64/72]	Time  1.059 ( 0.699)	Data  0.932 ( 0.568)	Loss 6.5852e-02 (1.2062e-01) 
2023-05-26 01:42:50.635583: val Epoch: [69][65/72]	Time  0.232 ( 0.692)	Data  0.103 ( 0.561)	Loss 3.8873e-02 (1.1938e-01) 
2023-05-26 01:42:51.783884: val Epoch: [69][66/72]	Time  1.148 ( 0.699)	Data  1.021 ( 0.568)	Loss 7.7673e-02 (1.1876e-01) 
2023-05-26 01:42:52.013256: val Epoch: [69][67/72]	Time  0.229 ( 0.692)	Data  0.085 ( 0.561)	Loss 1.3982e-01 (1.1907e-01) 
2023-05-26 01:42:53.133616: val Epoch: [69][68/72]	Time  1.120 ( 0.698)	Data  0.992 ( 0.567)	Loss 3.4992e-01 (1.2242e-01) 
2023-05-26 01:42:53.319885: val Epoch: [69][69/72]	Time  0.186 ( 0.691)	Data  0.059 ( 0.560)	Loss 2.1130e-01 (1.2369e-01) 
2023-05-26 01:42:54.473471: val Epoch: [69][70/72]	Time  1.154 ( 0.698)	Data  1.020 ( 0.566)	Loss 5.5855e-02 (1.2273e-01) 
2023-05-26 01:42:54.620722: val Epoch: [69][71/72]	Time  0.147 ( 0.690)	Data  0.020 ( 0.558)	Loss 1.4942e-01 (1.2310e-01) 
2023-05-26 01:42:54.825743: Epoch 69 :Val : ['ET : 0.7640920877456665', 'TC : 0.7932005524635315', 'WT : 0.8689248561859131'] 
2023-05-26 01:42:54.830187: Epoch 69 :Val : ['ET : 0.7640920877456665', 'TC : 0.7932005524635315', 'WT : 0.8689248561859131'] 
2023-05-26 01:42:54.832629: Val epoch done in 50.871710701001575 s 
2023-05-26 01:42:54.838414: Batches per epoch:  129 
2023-05-26 01:43:00.309161: train Epoch: [70][  0/129]	Time  5.470 ( 5.470)	Data  4.404 ( 4.404)	Loss 6.7651e-02 (6.7651e-02) 
2023-05-26 01:43:01.285333: train Epoch: [70][  1/129]	Time  0.976 ( 3.223)	Data  0.001 ( 2.203)	Loss 4.7759e-02 (5.7705e-02) 
2023-05-26 01:43:04.315705: train Epoch: [70][  2/129]	Time  3.030 ( 3.159)	Data  2.044 ( 2.150)	Loss 6.3566e-02 (5.9659e-02) 
2023-05-26 01:43:05.289916: train Epoch: [70][  3/129]	Time  0.974 ( 2.613)	Data  0.001 ( 1.613)	Loss 5.1393e-02 (5.7592e-02) 
2023-05-26 01:43:08.693899: train Epoch: [70][  4/129]	Time  3.404 ( 2.771)	Data  2.434 ( 1.777)	Loss 6.9031e-02 (5.9880e-02) 
2023-05-26 01:43:09.669111: train Epoch: [70][  5/129]	Time  0.975 ( 2.472)	Data  0.001 ( 1.481)	Loss 1.2025e-01 (6.9942e-02) 
2023-05-26 01:43:12.789544: train Epoch: [70][  6/129]	Time  3.120 ( 2.564)	Data  2.155 ( 1.577)	Loss 6.0215e-02 (6.8552e-02) 
2023-05-26 01:43:13.760767: train Epoch: [70][  7/129]	Time  0.971 ( 2.365)	Data  0.001 ( 1.380)	Loss 5.6784e-02 (6.7081e-02) 
2023-05-26 01:43:16.917020: train Epoch: [70][  8/129]	Time  3.156 ( 2.453)	Data  2.175 ( 1.469)	Loss 9.7304e-02 (7.0439e-02) 
2023-05-26 01:43:17.887042: train Epoch: [70][  9/129]	Time  0.970 ( 2.305)	Data  0.001 ( 1.322)	Loss 9.0460e-02 (7.2441e-02) 
2023-05-26 01:43:21.086025: train Epoch: [70][ 10/129]	Time  3.199 ( 2.386)	Data  2.230 ( 1.404)	Loss 6.4071e-02 (7.1680e-02) 
2023-05-26 01:43:22.058671: train Epoch: [70][ 11/129]	Time  0.973 ( 2.268)	Data  0.001 ( 1.287)	Loss 1.3034e-01 (7.6568e-02) 
2023-05-26 01:43:25.309770: train Epoch: [70][ 12/129]	Time  3.251 ( 2.344)	Data  2.284 ( 1.364)	Loss 6.4833e-02 (7.5665e-02) 
2023-05-26 01:43:26.268850: train Epoch: [70][ 13/129]	Time  0.959 ( 2.245)	Data  0.001 ( 1.267)	Loss 8.4323e-02 (7.6284e-02) 
2023-05-26 01:43:29.355449: train Epoch: [70][ 14/129]	Time  3.087 ( 2.301)	Data  2.109 ( 1.323)	Loss 7.4057e-02 (7.6135e-02) 
2023-05-26 01:43:30.328983: train Epoch: [70][ 15/129]	Time  0.974 ( 2.218)	Data  0.001 ( 1.240)	Loss 6.7439e-02 (7.5592e-02) 
2023-05-26 01:43:33.399849: train Epoch: [70][ 16/129]	Time  3.071 ( 2.268)	Data  2.097 ( 1.291)	Loss 4.6047e-02 (7.3854e-02) 
2023-05-26 01:43:34.363242: train Epoch: [70][ 17/129]	Time  0.963 ( 2.196)	Data  0.001 ( 1.219)	Loss 8.1436e-02 (7.4275e-02) 
2023-05-26 01:43:37.515291: train Epoch: [70][ 18/129]	Time  3.152 ( 2.246)	Data  2.173 ( 1.269)	Loss 9.2795e-02 (7.5250e-02) 
2023-05-26 01:43:38.494210: train Epoch: [70][ 19/129]	Time  0.979 ( 2.183)	Data  0.001 ( 1.206)	Loss 1.1453e-01 (7.7214e-02) 
2023-05-26 01:43:41.614618: train Epoch: [70][ 20/129]	Time  3.120 ( 2.227)	Data  2.145 ( 1.251)	Loss 7.4120e-02 (7.7067e-02) 
2023-05-26 01:43:42.588919: train Epoch: [70][ 21/129]	Time  0.974 ( 2.170)	Data  0.001 ( 1.194)	Loss 7.9867e-02 (7.7194e-02) 
2023-05-26 01:43:45.704159: train Epoch: [70][ 22/129]	Time  3.115 ( 2.212)	Data  2.147 ( 1.235)	Loss 6.9102e-02 (7.6842e-02) 
2023-05-26 01:43:46.670956: train Epoch: [70][ 23/129]	Time  0.967 ( 2.160)	Data  0.001 ( 1.184)	Loss 8.9247e-02 (7.7359e-02) 
2023-05-26 01:43:49.770879: train Epoch: [70][ 24/129]	Time  3.100 ( 2.197)	Data  2.114 ( 1.221)	Loss 6.1357e-02 (7.6719e-02) 
2023-05-26 01:43:50.749801: train Epoch: [70][ 25/129]	Time  0.979 ( 2.150)	Data  0.001 ( 1.174)	Loss 5.3486e-02 (7.5825e-02) 
2023-05-26 01:43:53.734768: train Epoch: [70][ 26/129]	Time  2.985 ( 2.181)	Data  1.999 ( 1.205)	Loss 8.9986e-02 (7.6350e-02) 
2023-05-26 01:43:54.704977: train Epoch: [70][ 27/129]	Time  0.970 ( 2.138)	Data  0.001 ( 1.162)	Loss 4.5035e-02 (7.5232e-02) 
2023-05-26 01:43:57.760932: train Epoch: [70][ 28/129]	Time  3.056 ( 2.170)	Data  2.079 ( 1.193)	Loss 8.6595e-02 (7.5623e-02) 
2023-05-26 01:43:58.729820: train Epoch: [70][ 29/129]	Time  0.969 ( 2.130)	Data  0.001 ( 1.154)	Loss 4.1593e-02 (7.4489e-02) 
2023-05-26 01:44:01.854658: train Epoch: [70][ 30/129]	Time  3.125 ( 2.162)	Data  2.139 ( 1.185)	Loss 6.0745e-02 (7.4046e-02) 
2023-05-26 01:44:02.824778: train Epoch: [70][ 31/129]	Time  0.970 ( 2.125)	Data  0.001 ( 1.148)	Loss 5.1155e-02 (7.3330e-02) 
2023-05-26 01:44:05.870670: train Epoch: [70][ 32/129]	Time  3.046 ( 2.152)	Data  2.062 ( 1.176)	Loss 1.0292e-01 (7.4227e-02) 
2023-05-26 01:44:06.842574: train Epoch: [70][ 33/129]	Time  0.972 ( 2.118)	Data  0.001 ( 1.141)	Loss 7.7574e-02 (7.4325e-02) 
2023-05-26 01:44:09.997015: train Epoch: [70][ 34/129]	Time  3.154 ( 2.147)	Data  2.183 ( 1.171)	Loss 8.7761e-02 (7.4709e-02) 
2023-05-26 01:44:10.969352: train Epoch: [70][ 35/129]	Time  0.972 ( 2.115)	Data  0.001 ( 1.139)	Loss 6.9804e-02 (7.4573e-02) 
2023-05-26 01:44:14.193415: train Epoch: [70][ 36/129]	Time  3.224 ( 2.145)	Data  2.229 ( 1.168)	Loss 5.1489e-02 (7.3949e-02) 
2023-05-26 01:44:15.187182: train Epoch: [70][ 37/129]	Time  0.994 ( 2.114)	Data  0.001 ( 1.138)	Loss 5.1505e-02 (7.3358e-02) 
2023-05-26 01:44:18.339550: train Epoch: [70][ 38/129]	Time  3.152 ( 2.141)	Data  2.181 ( 1.164)	Loss 6.2317e-02 (7.3075e-02) 
2023-05-26 01:44:19.311685: train Epoch: [70][ 39/129]	Time  0.972 ( 2.112)	Data  0.001 ( 1.135)	Loss 5.7222e-02 (7.2679e-02) 
2023-05-26 01:44:22.373533: train Epoch: [70][ 40/129]	Time  3.062 ( 2.135)	Data  2.092 ( 1.159)	Loss 5.8032e-02 (7.2322e-02) 
2023-05-26 01:44:23.355042: train Epoch: [70][ 41/129]	Time  0.982 ( 2.108)	Data  0.001 ( 1.131)	Loss 8.6635e-02 (7.2663e-02) 
2023-05-26 01:44:26.425179: train Epoch: [70][ 42/129]	Time  3.070 ( 2.130)	Data  2.101 ( 1.154)	Loss 7.1418e-02 (7.2634e-02) 
2023-05-26 01:44:27.398739: train Epoch: [70][ 43/129]	Time  0.974 ( 2.104)	Data  0.001 ( 1.127)	Loss 1.1474e-01 (7.3590e-02) 
2023-05-26 01:44:30.387748: train Epoch: [70][ 44/129]	Time  2.989 ( 2.123)	Data  2.020 ( 1.147)	Loss 1.9565e-01 (7.6303e-02) 
2023-05-26 01:44:31.369320: train Epoch: [70][ 45/129]	Time  0.982 ( 2.098)	Data  0.001 ( 1.122)	Loss 6.8957e-02 (7.6143e-02) 
2023-05-26 01:44:34.586907: train Epoch: [70][ 46/129]	Time  3.218 ( 2.122)	Data  2.231 ( 1.146)	Loss 1.4561e-01 (7.7621e-02) 
2023-05-26 01:44:35.572122: train Epoch: [70][ 47/129]	Time  0.985 ( 2.099)	Data  0.002 ( 1.122)	Loss 4.9181e-02 (7.7029e-02) 
2023-05-26 01:44:38.698347: train Epoch: [70][ 48/129]	Time  3.126 ( 2.120)	Data  2.142 ( 1.143)	Loss 6.1964e-02 (7.6721e-02) 
2023-05-26 01:44:39.691376: train Epoch: [70][ 49/129]	Time  0.993 ( 2.097)	Data  0.002 ( 1.120)	Loss 6.1522e-02 (7.6417e-02) 
2023-05-26 01:44:42.703506: train Epoch: [70][ 50/129]	Time  3.012 ( 2.115)	Data  2.036 ( 1.138)	Loss 4.1364e-02 (7.5730e-02) 
2023-05-26 01:44:43.672979: train Epoch: [70][ 51/129]	Time  0.969 ( 2.093)	Data  0.001 ( 1.116)	Loss 6.0682e-02 (7.5441e-02) 
2023-05-26 01:44:46.720693: train Epoch: [70][ 52/129]	Time  3.048 ( 2.111)	Data  2.078 ( 1.134)	Loss 4.6486e-02 (7.4894e-02) 
2023-05-26 01:44:47.700156: train Epoch: [70][ 53/129]	Time  0.979 ( 2.090)	Data  0.001 ( 1.113)	Loss 9.4946e-02 (7.5266e-02) 
2023-05-26 01:44:50.784477: train Epoch: [70][ 54/129]	Time  3.084 ( 2.108)	Data  2.117 ( 1.132)	Loss 6.1984e-02 (7.5024e-02) 
2023-05-26 01:44:51.757803: train Epoch: [70][ 55/129]	Time  0.973 ( 2.088)	Data  0.001 ( 1.111)	Loss 8.7698e-02 (7.5250e-02) 
2023-05-26 01:44:54.853258: train Epoch: [70][ 56/129]	Time  3.095 ( 2.106)	Data  2.116 ( 1.129)	Loss 8.6486e-02 (7.5448e-02) 
2023-05-26 01:44:55.827334: train Epoch: [70][ 57/129]	Time  0.974 ( 2.086)	Data  0.001 ( 1.110)	Loss 6.8659e-02 (7.5331e-02) 
2023-05-26 01:44:58.859150: train Epoch: [70][ 58/129]	Time  3.032 ( 2.102)	Data  2.064 ( 1.126)	Loss 6.8950e-02 (7.5222e-02) 
2023-05-26 01:44:59.828193: train Epoch: [70][ 59/129]	Time  0.969 ( 2.083)	Data  0.001 ( 1.107)	Loss 5.4069e-02 (7.4870e-02) 
2023-05-26 01:45:02.901506: train Epoch: [70][ 60/129]	Time  3.073 ( 2.099)	Data  2.106 ( 1.123)	Loss 4.7450e-02 (7.4420e-02) 
2023-05-26 01:45:03.872648: train Epoch: [70][ 61/129]	Time  0.971 ( 2.081)	Data  0.001 ( 1.105)	Loss 4.9045e-02 (7.4011e-02) 
2023-05-26 01:45:07.089074: train Epoch: [70][ 62/129]	Time  3.216 ( 2.099)	Data  2.244 ( 1.123)	Loss 4.4149e-02 (7.3537e-02) 
2023-05-26 01:45:08.057738: train Epoch: [70][ 63/129]	Time  0.969 ( 2.082)	Data  0.001 ( 1.106)	Loss 1.0243e-01 (7.3989e-02) 
2023-05-26 01:45:11.168576: train Epoch: [70][ 64/129]	Time  3.111 ( 2.097)	Data  2.135 ( 1.122)	Loss 7.1691e-02 (7.3953e-02) 
2023-05-26 01:45:12.147551: train Epoch: [70][ 65/129]	Time  0.979 ( 2.080)	Data  0.001 ( 1.105)	Loss 1.0653e-01 (7.4447e-02) 
2023-05-26 01:45:15.304302: train Epoch: [70][ 66/129]	Time  3.157 ( 2.096)	Data  2.188 ( 1.121)	Loss 8.4448e-02 (7.4596e-02) 
2023-05-26 01:45:16.276194: train Epoch: [70][ 67/129]	Time  0.972 ( 2.080)	Data  0.001 ( 1.104)	Loss 5.1201e-02 (7.4252e-02) 
2023-05-26 01:45:19.427298: train Epoch: [70][ 68/129]	Time  3.151 ( 2.095)	Data  2.180 ( 1.120)	Loss 1.0500e-01 (7.4698e-02) 
2023-05-26 01:45:20.400507: train Epoch: [70][ 69/129]	Time  0.973 ( 2.079)	Data  0.001 ( 1.104)	Loss 1.3920e-01 (7.5619e-02) 
2023-05-26 01:45:23.437367: train Epoch: [70][ 70/129]	Time  3.037 ( 2.093)	Data  2.055 ( 1.117)	Loss 7.4367e-02 (7.5601e-02) 
2023-05-26 01:45:24.400622: train Epoch: [70][ 71/129]	Time  0.963 ( 2.077)	Data  0.001 ( 1.102)	Loss 9.7342e-02 (7.5903e-02) 
2023-05-26 01:45:27.469835: train Epoch: [70][ 72/129]	Time  3.069 ( 2.091)	Data  2.072 ( 1.115)	Loss 5.8343e-02 (7.5663e-02) 
2023-05-26 01:45:28.441668: train Epoch: [70][ 73/129]	Time  0.972 ( 2.076)	Data  0.001 ( 1.100)	Loss 6.5617e-02 (7.5527e-02) 
2023-05-26 01:45:31.561824: train Epoch: [70][ 74/129]	Time  3.120 ( 2.090)	Data  2.154 ( 1.114)	Loss 7.1167e-02 (7.5469e-02) 
2023-05-26 01:45:32.534847: train Epoch: [70][ 75/129]	Time  0.973 ( 2.075)	Data  0.001 ( 1.099)	Loss 7.7688e-02 (7.5498e-02) 
2023-05-26 01:45:35.666818: train Epoch: [70][ 76/129]	Time  3.132 ( 2.089)	Data  2.135 ( 1.113)	Loss 3.3293e-02 (7.4950e-02) 
2023-05-26 01:45:36.642871: train Epoch: [70][ 77/129]	Time  0.976 ( 2.074)	Data  0.002 ( 1.099)	Loss 9.0682e-02 (7.5152e-02) 
2023-05-26 01:45:39.721848: train Epoch: [70][ 78/129]	Time  3.079 ( 2.087)	Data  2.108 ( 1.111)	Loss 8.7304e-02 (7.5306e-02) 
2023-05-26 01:45:40.691533: train Epoch: [70][ 79/129]	Time  0.970 ( 2.073)	Data  0.001 ( 1.098)	Loss 6.2552e-02 (7.5146e-02) 
2023-05-26 01:45:43.830506: train Epoch: [70][ 80/129]	Time  3.139 ( 2.086)	Data  2.162 ( 1.111)	Loss 7.3221e-02 (7.5122e-02) 
2023-05-26 01:45:44.801790: train Epoch: [70][ 81/129]	Time  0.971 ( 2.073)	Data  0.001 ( 1.097)	Loss 9.2683e-02 (7.5336e-02) 
2023-05-26 01:45:47.818135: train Epoch: [70][ 82/129]	Time  3.016 ( 2.084)	Data  2.046 ( 1.109)	Loss 7.2843e-02 (7.5306e-02) 
2023-05-26 01:45:48.794338: train Epoch: [70][ 83/129]	Time  0.976 ( 2.071)	Data  0.001 ( 1.095)	Loss 5.6456e-02 (7.5082e-02) 
2023-05-26 01:45:51.934315: train Epoch: [70][ 84/129]	Time  3.140 ( 2.083)	Data  2.160 ( 1.108)	Loss 5.6244e-02 (7.4860e-02) 
2023-05-26 01:45:52.902880: train Epoch: [70][ 85/129]	Time  0.969 ( 2.071)	Data  0.001 ( 1.095)	Loss 6.6575e-02 (7.4764e-02) 
2023-05-26 01:45:56.047901: train Epoch: [70][ 86/129]	Time  3.145 ( 2.083)	Data  2.161 ( 1.107)	Loss 9.3541e-02 (7.4980e-02) 
2023-05-26 01:45:57.009676: train Epoch: [70][ 87/129]	Time  0.962 ( 2.070)	Data  0.001 ( 1.095)	Loss 7.9811e-02 (7.5035e-02) 
2023-05-26 01:45:59.974182: train Epoch: [70][ 88/129]	Time  2.965 ( 2.080)	Data  1.991 ( 1.105)	Loss 7.6926e-02 (7.5056e-02) 
2023-05-26 01:46:00.949504: train Epoch: [70][ 89/129]	Time  0.975 ( 2.068)	Data  0.001 ( 1.093)	Loss 6.4496e-02 (7.4939e-02) 
2023-05-26 01:46:04.045652: train Epoch: [70][ 90/129]	Time  3.096 ( 2.079)	Data  2.116 ( 1.104)	Loss 9.0948e-02 (7.5115e-02) 
2023-05-26 01:46:05.038548: train Epoch: [70][ 91/129]	Time  0.993 ( 2.067)	Data  0.001 ( 1.092)	Loss 7.0123e-02 (7.5060e-02) 
2023-05-26 01:46:08.124903: train Epoch: [70][ 92/129]	Time  3.086 ( 2.078)	Data  2.103 ( 1.103)	Loss 7.8713e-02 (7.5100e-02) 
2023-05-26 01:46:09.105448: train Epoch: [70][ 93/129]	Time  0.981 ( 2.067)	Data  0.001 ( 1.091)	Loss 8.8154e-02 (7.5239e-02) 
2023-05-26 01:46:12.162123: train Epoch: [70][ 94/129]	Time  3.057 ( 2.077)	Data  2.073 ( 1.101)	Loss 5.8626e-02 (7.5064e-02) 
2023-05-26 01:46:13.132257: train Epoch: [70][ 95/129]	Time  0.970 ( 2.066)	Data  0.001 ( 1.090)	Loss 4.7131e-02 (7.4773e-02) 
2023-05-26 01:46:16.075745: train Epoch: [70][ 96/129]	Time  2.943 ( 2.075)	Data  1.974 ( 1.099)	Loss 6.1680e-02 (7.4638e-02) 
2023-05-26 01:46:17.043212: train Epoch: [70][ 97/129]	Time  0.967 ( 2.063)	Data  0.001 ( 1.088)	Loss 5.2272e-02 (7.4409e-02) 
2023-05-26 01:46:20.210501: train Epoch: [70][ 98/129]	Time  3.167 ( 2.074)	Data  2.186 ( 1.099)	Loss 1.0494e-01 (7.4718e-02) 
2023-05-26 01:46:21.192434: train Epoch: [70][ 99/129]	Time  0.982 ( 2.064)	Data  0.001 ( 1.088)	Loss 8.7220e-02 (7.4843e-02) 
2023-05-26 01:46:24.259699: train Epoch: [70][100/129]	Time  3.067 ( 2.073)	Data  2.085 ( 1.098)	Loss 7.6870e-02 (7.4863e-02) 
2023-05-26 01:46:25.241785: train Epoch: [70][101/129]	Time  0.982 ( 2.063)	Data  0.001 ( 1.087)	Loss 5.2113e-02 (7.4640e-02) 
2023-05-26 01:46:28.292680: train Epoch: [70][102/129]	Time  3.051 ( 2.072)	Data  2.080 ( 1.097)	Loss 5.3560e-02 (7.4435e-02) 
2023-05-26 01:46:29.277220: train Epoch: [70][103/129]	Time  0.985 ( 2.062)	Data  0.001 ( 1.086)	Loss 6.3817e-02 (7.4333e-02) 
2023-05-26 01:46:32.453274: train Epoch: [70][104/129]	Time  3.176 ( 2.073)	Data  2.194 ( 1.097)	Loss 8.2989e-02 (7.4416e-02) 
2023-05-26 01:46:33.421914: train Epoch: [70][105/129]	Time  0.969 ( 2.062)	Data  0.001 ( 1.086)	Loss 6.8074e-02 (7.4356e-02) 
2023-05-26 01:46:36.602763: train Epoch: [70][106/129]	Time  3.181 ( 2.073)	Data  2.199 ( 1.097)	Loss 5.9650e-02 (7.4218e-02) 
2023-05-26 01:46:37.577600: train Epoch: [70][107/129]	Time  0.975 ( 2.062)	Data  0.001 ( 1.087)	Loss 4.6737e-02 (7.3964e-02) 
2023-05-26 01:46:40.676142: train Epoch: [70][108/129]	Time  3.099 ( 2.072)	Data  2.123 ( 1.096)	Loss 6.7294e-02 (7.3903e-02) 
2023-05-26 01:46:41.650473: train Epoch: [70][109/129]	Time  0.974 ( 2.062)	Data  0.001 ( 1.086)	Loss 1.0312e-01 (7.4168e-02) 
2023-05-26 01:46:44.613972: train Epoch: [70][110/129]	Time  2.963 ( 2.070)	Data  1.976 ( 1.094)	Loss 7.9804e-02 (7.4219e-02) 
2023-05-26 01:46:45.584876: train Epoch: [70][111/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.084)	Loss 6.5829e-02 (7.4144e-02) 
2023-05-26 01:46:48.669645: train Epoch: [70][112/129]	Time  3.085 ( 2.069)	Data  2.118 ( 1.094)	Loss 9.5941e-02 (7.4337e-02) 
2023-05-26 01:46:49.640648: train Epoch: [70][113/129]	Time  0.971 ( 2.060)	Data  0.001 ( 1.084)	Loss 5.8697e-02 (7.4200e-02) 
2023-05-26 01:46:52.888139: train Epoch: [70][114/129]	Time  3.248 ( 2.070)	Data  2.272 ( 1.094)	Loss 9.4713e-02 (7.4378e-02) 
2023-05-26 01:46:53.860404: train Epoch: [70][115/129]	Time  0.972 ( 2.061)	Data  0.001 ( 1.085)	Loss 5.5011e-02 (7.4211e-02) 
2023-05-26 01:46:57.052640: train Epoch: [70][116/129]	Time  3.192 ( 2.070)	Data  2.201 ( 1.094)	Loss 1.1172e-01 (7.4532e-02) 
2023-05-26 01:46:58.042241: train Epoch: [70][117/129]	Time  0.990 ( 2.061)	Data  0.001 ( 1.085)	Loss 6.2475e-02 (7.4430e-02) 
2023-05-26 01:47:01.003146: train Epoch: [70][118/129]	Time  2.961 ( 2.069)	Data  1.996 ( 1.093)	Loss 4.5404e-02 (7.4186e-02) 
2023-05-26 01:47:01.982721: train Epoch: [70][119/129]	Time  0.980 ( 2.060)	Data  0.001 ( 1.084)	Loss 1.1663e-01 (7.4540e-02) 
2023-05-26 01:47:05.099468: train Epoch: [70][120/129]	Time  3.117 ( 2.068)	Data  2.130 ( 1.092)	Loss 5.6488e-02 (7.4390e-02) 
2023-05-26 01:47:06.078188: train Epoch: [70][121/129]	Time  0.979 ( 2.059)	Data  0.002 ( 1.083)	Loss 6.8892e-02 (7.4345e-02) 
2023-05-26 01:47:09.143107: train Epoch: [70][122/129]	Time  3.065 ( 2.068)	Data  2.081 ( 1.092)	Loss 3.8823e-02 (7.4056e-02) 
2023-05-26 01:47:10.143480: train Epoch: [70][123/129]	Time  1.000 ( 2.059)	Data  0.001 ( 1.083)	Loss 7.9979e-02 (7.4104e-02) 
2023-05-26 01:47:13.249273: train Epoch: [70][124/129]	Time  3.106 ( 2.067)	Data  2.134 ( 1.091)	Loss 6.4419e-02 (7.4027e-02) 
2023-05-26 01:47:14.219078: train Epoch: [70][125/129]	Time  0.970 ( 2.059)	Data  0.001 ( 1.082)	Loss 6.7864e-02 (7.3978e-02) 
2023-05-26 01:47:17.281943: train Epoch: [70][126/129]	Time  3.063 ( 2.066)	Data  2.096 ( 1.090)	Loss 4.4519e-02 (7.3746e-02) 
2023-05-26 01:47:18.253635: train Epoch: [70][127/129]	Time  0.972 ( 2.058)	Data  0.001 ( 1.082)	Loss 1.3477e-01 (7.4223e-02) 
2023-05-26 01:47:20.397175: train Epoch: [70][128/129]	Time  2.144 ( 2.059)	Data  1.162 ( 1.083)	Loss 6.2316e-02 (7.4130e-02) 
2023-05-26 01:47:20.470845: Train Epoch done in 265.632472977999 s 
2023-05-26 01:47:23.341284: val Epoch: [70][ 0/72]	Time  1.867 ( 1.867)	Data  1.653 ( 1.653)	Loss 3.7002e-02 (3.7002e-02) 
2023-05-26 01:47:23.470342: val Epoch: [70][ 1/72]	Time  0.129 ( 0.998)	Data  0.001 ( 0.827)	Loss 6.9979e-02 (5.3491e-02) 
2023-05-26 01:47:24.644666: val Epoch: [70][ 2/72]	Time  1.174 ( 1.057)	Data  1.047 ( 0.900)	Loss 3.2866e-01 (1.4521e-01) 
2023-05-26 01:47:24.774227: val Epoch: [70][ 3/72]	Time  0.130 ( 0.825)	Data  0.001 ( 0.676)	Loss 4.5329e-02 (1.2024e-01) 
2023-05-26 01:47:26.027044: val Epoch: [70][ 4/72]	Time  1.253 ( 0.911)	Data  1.124 ( 0.765)	Loss 2.2461e-01 (1.4112e-01) 
2023-05-26 01:47:26.156114: val Epoch: [70][ 5/72]	Time  0.129 ( 0.780)	Data  0.001 ( 0.638)	Loss 4.7733e-02 (1.2555e-01) 
2023-05-26 01:47:27.465537: val Epoch: [70][ 6/72]	Time  1.309 ( 0.856)	Data  1.181 ( 0.715)	Loss 4.3179e-02 (1.1378e-01) 
2023-05-26 01:47:27.594501: val Epoch: [70][ 7/72]	Time  0.129 ( 0.765)	Data  0.001 ( 0.626)	Loss 5.2206e-02 (1.0609e-01) 
2023-05-26 01:47:28.862744: val Epoch: [70][ 8/72]	Time  1.268 ( 0.821)	Data  1.140 ( 0.683)	Loss 7.6585e-02 (1.0281e-01) 
2023-05-26 01:47:28.989305: val Epoch: [70][ 9/72]	Time  0.127 ( 0.752)	Data  0.001 ( 0.615)	Loss 3.5139e-01 (1.2767e-01) 
2023-05-26 01:47:30.236799: val Epoch: [70][10/72]	Time  1.247 ( 0.797)	Data  1.119 ( 0.661)	Loss 4.3282e-01 (1.5541e-01) 
2023-05-26 01:47:30.366064: val Epoch: [70][11/72]	Time  0.129 ( 0.741)	Data  0.001 ( 0.606)	Loss 7.0624e-02 (1.4834e-01) 
2023-05-26 01:47:31.688544: val Epoch: [70][12/72]	Time  1.322 ( 0.786)	Data  1.193 ( 0.651)	Loss 7.5396e-02 (1.4273e-01) 
2023-05-26 01:47:31.818047: val Epoch: [70][13/72]	Time  0.130 ( 0.739)	Data  0.001 ( 0.605)	Loss 6.5483e-02 (1.3721e-01) 
2023-05-26 01:47:33.022442: val Epoch: [70][14/72]	Time  1.204 ( 0.770)	Data  1.076 ( 0.636)	Loss 4.0228e-02 (1.3075e-01) 
2023-05-26 01:47:33.149885: val Epoch: [70][15/72]	Time  0.127 ( 0.730)	Data  0.001 ( 0.596)	Loss 1.8074e-01 (1.3387e-01) 
2023-05-26 01:47:34.448893: val Epoch: [70][16/72]	Time  1.299 ( 0.763)	Data  1.170 ( 0.630)	Loss 9.2730e-02 (1.3145e-01) 
2023-05-26 01:47:34.577093: val Epoch: [70][17/72]	Time  0.128 ( 0.728)	Data  0.001 ( 0.595)	Loss 1.0455e-01 (1.2996e-01) 
2023-05-26 01:47:35.851451: val Epoch: [70][18/72]	Time  1.274 ( 0.757)	Data  1.137 ( 0.624)	Loss 5.5463e-02 (1.2604e-01) 
2023-05-26 01:47:35.981210: val Epoch: [70][19/72]	Time  0.130 ( 0.725)	Data  0.001 ( 0.593)	Loss 3.8309e-02 (1.2165e-01) 
2023-05-26 01:47:37.255599: val Epoch: [70][20/72]	Time  1.274 ( 0.752)	Data  1.146 ( 0.619)	Loss 5.7838e-02 (1.1861e-01) 
2023-05-26 01:47:37.385107: val Epoch: [70][21/72]	Time  0.129 ( 0.723)	Data  0.001 ( 0.591)	Loss 5.3702e-02 (1.1566e-01) 
2023-05-26 01:47:38.602370: val Epoch: [70][22/72]	Time  1.217 ( 0.745)	Data  1.090 ( 0.612)	Loss 8.7224e-02 (1.1443e-01) 
2023-05-26 01:47:38.729879: val Epoch: [70][23/72]	Time  0.127 ( 0.719)	Data  0.001 ( 0.587)	Loss 3.3195e-02 (1.1104e-01) 
2023-05-26 01:47:39.946849: val Epoch: [70][24/72]	Time  1.217 ( 0.739)	Data  1.087 ( 0.607)	Loss 4.4717e-02 (1.0839e-01) 
2023-05-26 01:47:40.075535: val Epoch: [70][25/72]	Time  0.129 ( 0.715)	Data  0.001 ( 0.584)	Loss 4.9331e-02 (1.0612e-01) 
2023-05-26 01:47:41.375662: val Epoch: [70][26/72]	Time  1.300 ( 0.737)	Data  1.173 ( 0.605)	Loss 8.5330e-02 (1.0535e-01) 
2023-05-26 01:47:41.505316: val Epoch: [70][27/72]	Time  0.130 ( 0.715)	Data  0.001 ( 0.584)	Loss 6.0067e-02 (1.0373e-01) 
2023-05-26 01:47:42.768800: val Epoch: [70][28/72]	Time  1.263 ( 0.734)	Data  1.136 ( 0.603)	Loss 4.4639e-02 (1.0169e-01) 
2023-05-26 01:47:42.896342: val Epoch: [70][29/72]	Time  0.128 ( 0.714)	Data  0.001 ( 0.583)	Loss 3.2250e-02 (9.9377e-02) 
2023-05-26 01:47:44.140113: val Epoch: [70][30/72]	Time  1.244 ( 0.731)	Data  1.112 ( 0.600)	Loss 5.5941e-02 (9.7976e-02) 
2023-05-26 01:47:44.270847: val Epoch: [70][31/72]	Time  0.131 ( 0.712)	Data  0.001 ( 0.581)	Loss 7.5722e-02 (9.7280e-02) 
2023-05-26 01:47:45.544185: val Epoch: [70][32/72]	Time  1.273 ( 0.729)	Data  1.145 ( 0.598)	Loss 5.3099e-02 (9.5942e-02) 
2023-05-26 01:47:45.674524: val Epoch: [70][33/72]	Time  0.130 ( 0.712)	Data  0.001 ( 0.581)	Loss 5.0531e-02 (9.4606e-02) 
2023-05-26 01:47:46.938412: val Epoch: [70][34/72]	Time  1.264 ( 0.728)	Data  1.138 ( 0.597)	Loss 8.8548e-02 (9.4433e-02) 
2023-05-26 01:47:47.068855: val Epoch: [70][35/72]	Time  0.130 ( 0.711)	Data  0.001 ( 0.580)	Loss 3.6347e-01 (1.0191e-01) 
2023-05-26 01:47:48.382275: val Epoch: [70][36/72]	Time  1.313 ( 0.727)	Data  1.173 ( 0.596)	Loss 1.9898e-01 (1.0453e-01) 
2023-05-26 01:47:48.513051: val Epoch: [70][37/72]	Time  0.131 ( 0.712)	Data  0.001 ( 0.580)	Loss 1.1729e-01 (1.0487e-01) 
2023-05-26 01:47:49.731545: val Epoch: [70][38/72]	Time  1.218 ( 0.725)	Data  1.093 ( 0.594)	Loss 3.7051e-01 (1.1168e-01) 
2023-05-26 01:47:49.858908: val Epoch: [70][39/72]	Time  0.127 ( 0.710)	Data  0.001 ( 0.579)	Loss 5.7078e-02 (1.1031e-01) 
2023-05-26 01:47:51.041483: val Epoch: [70][40/72]	Time  1.183 ( 0.721)	Data  1.056 ( 0.590)	Loss 9.9254e-02 (1.1004e-01) 
2023-05-26 01:47:51.167680: val Epoch: [70][41/72]	Time  0.126 ( 0.707)	Data  0.001 ( 0.576)	Loss 7.6829e-02 (1.0925e-01) 
2023-05-26 01:47:52.437167: val Epoch: [70][42/72]	Time  1.270 ( 0.720)	Data  1.147 ( 0.590)	Loss 4.4933e-01 (1.1716e-01) 
2023-05-26 01:47:52.563426: val Epoch: [70][43/72]	Time  0.126 ( 0.707)	Data  0.000 ( 0.576)	Loss 9.1326e-02 (1.1657e-01) 
2023-05-26 01:47:53.851851: val Epoch: [70][44/72]	Time  1.288 ( 0.720)	Data  1.153 ( 0.589)	Loss 1.4155e-01 (1.1713e-01) 
2023-05-26 01:47:53.989561: val Epoch: [70][45/72]	Time  0.138 ( 0.707)	Data  0.001 ( 0.576)	Loss 1.4232e-01 (1.1768e-01) 
2023-05-26 01:47:55.221278: val Epoch: [70][46/72]	Time  1.232 ( 0.718)	Data  1.097 ( 0.587)	Loss 9.8859e-02 (1.1728e-01) 
2023-05-26 01:47:55.360472: val Epoch: [70][47/72]	Time  0.139 ( 0.706)	Data  0.001 ( 0.575)	Loss 7.9497e-02 (1.1649e-01) 
2023-05-26 01:47:56.611846: val Epoch: [70][48/72]	Time  1.251 ( 0.717)	Data  1.117 ( 0.586)	Loss 1.3837e-01 (1.1693e-01) 
2023-05-26 01:47:56.745833: val Epoch: [70][49/72]	Time  0.134 ( 0.705)	Data  0.001 ( 0.575)	Loss 5.1639e-02 (1.1563e-01) 
2023-05-26 01:47:57.919148: val Epoch: [70][50/72]	Time  1.173 ( 0.715)	Data  1.036 ( 0.584)	Loss 1.4886e-01 (1.1628e-01) 
2023-05-26 01:47:58.054817: val Epoch: [70][51/72]	Time  0.136 ( 0.703)	Data  0.001 ( 0.572)	Loss 5.9047e-02 (1.1518e-01) 
2023-05-26 01:47:59.268868: val Epoch: [70][52/72]	Time  1.214 ( 0.713)	Data  1.073 ( 0.582)	Loss 3.4574e-02 (1.1366e-01) 
2023-05-26 01:47:59.407875: val Epoch: [70][53/72]	Time  0.139 ( 0.702)	Data  0.001 ( 0.571)	Loss 7.8190e-02 (1.1300e-01) 
2023-05-26 01:48:00.612051: val Epoch: [70][54/72]	Time  1.204 ( 0.712)	Data  1.069 ( 0.580)	Loss 8.0361e-02 (1.1241e-01) 
2023-05-26 01:48:00.745812: val Epoch: [70][55/72]	Time  0.134 ( 0.701)	Data  0.001 ( 0.570)	Loss 2.4981e-01 (1.1486e-01) 
2023-05-26 01:48:01.947725: val Epoch: [70][56/72]	Time  1.202 ( 0.710)	Data  1.072 ( 0.579)	Loss 9.2241e-02 (1.1447e-01) 
2023-05-26 01:48:02.080416: val Epoch: [70][57/72]	Time  0.133 ( 0.700)	Data  0.001 ( 0.569)	Loss 7.7184e-02 (1.1382e-01) 
2023-05-26 01:48:03.295268: val Epoch: [70][58/72]	Time  1.215 ( 0.709)	Data  1.080 ( 0.577)	Loss 1.2094e-01 (1.1394e-01) 
2023-05-26 01:48:03.424087: val Epoch: [70][59/72]	Time  0.129 ( 0.699)	Data  0.001 ( 0.568)	Loss 5.2089e-02 (1.1291e-01) 
2023-05-26 01:48:04.625948: val Epoch: [70][60/72]	Time  1.202 ( 0.707)	Data  1.079 ( 0.576)	Loss 1.6892e-01 (1.1383e-01) 
2023-05-26 01:48:04.752978: val Epoch: [70][61/72]	Time  0.127 ( 0.698)	Data  0.001 ( 0.567)	Loss 2.1714e-01 (1.1550e-01) 
2023-05-26 01:48:06.027116: val Epoch: [70][62/72]	Time  1.274 ( 0.707)	Data  1.138 ( 0.576)	Loss 1.1862e-01 (1.1555e-01) 
2023-05-26 01:48:06.169216: val Epoch: [70][63/72]	Time  0.142 ( 0.698)	Data  0.001 ( 0.567)	Loss 1.2983e-01 (1.1577e-01) 
2023-05-26 01:48:07.394196: val Epoch: [70][64/72]	Time  1.225 ( 0.706)	Data  1.090 ( 0.575)	Loss 5.4613e-01 (1.2239e-01) 
2023-05-26 01:48:07.535846: val Epoch: [70][65/72]	Time  0.142 ( 0.698)	Data  0.001 ( 0.566)	Loss 3.2092e-02 (1.2102e-01) 
2023-05-26 01:48:08.773318: val Epoch: [70][66/72]	Time  1.237 ( 0.706)	Data  1.108 ( 0.574)	Loss 2.5236e-01 (1.2298e-01) 
2023-05-26 01:48:08.901873: val Epoch: [70][67/72]	Time  0.129 ( 0.697)	Data  0.001 ( 0.566)	Loss 4.5262e-02 (1.2184e-01) 
2023-05-26 01:48:10.163690: val Epoch: [70][68/72]	Time  1.262 ( 0.706)	Data  1.131 ( 0.574)	Loss 4.3377e-02 (1.2070e-01) 
2023-05-26 01:48:10.304029: val Epoch: [70][69/72]	Time  0.140 ( 0.698)	Data  0.001 ( 0.566)	Loss 3.8458e-02 (1.1953e-01) 
2023-05-26 01:48:11.478886: val Epoch: [70][70/72]	Time  1.175 ( 0.704)	Data  1.047 ( 0.573)	Loss 3.1145e-01 (1.2223e-01) 
2023-05-26 01:48:11.606301: val Epoch: [70][71/72]	Time  0.127 ( 0.696)	Data  0.001 ( 0.565)	Loss 5.7805e-02 (1.2134e-01) 
2023-05-26 01:48:11.806614: Epoch 70 :Val : ['ET : 0.7595044374465942', 'TC : 0.792560875415802', 'WT : 0.871815025806427'] 
2023-05-26 01:48:11.812442: Epoch 70 :Val : ['ET : 0.7595044374465942', 'TC : 0.792560875415802', 'WT : 0.871815025806427'] 
2023-05-26 01:48:11.815973: Val epoch done in 51.345131100999424 s 
2023-05-26 01:48:11.824449: Batches per epoch:  129 
2023-05-26 01:48:17.476218: train Epoch: [71][  0/129]	Time  5.651 ( 5.651)	Data  4.572 ( 4.572)	Loss 3.9875e-02 (3.9875e-02) 
2023-05-26 01:48:18.451751: train Epoch: [71][  1/129]	Time  0.976 ( 3.313)	Data  0.001 ( 2.287)	Loss 6.5163e-02 (5.2519e-02) 
2023-05-26 01:48:21.450505: train Epoch: [71][  2/129]	Time  2.999 ( 3.208)	Data  2.019 ( 2.197)	Loss 6.9474e-02 (5.8170e-02) 
2023-05-26 01:48:22.447945: train Epoch: [71][  3/129]	Time  0.997 ( 2.656)	Data  0.001 ( 1.648)	Loss 7.6150e-02 (6.2665e-02) 
2023-05-26 01:48:25.496418: train Epoch: [71][  4/129]	Time  3.048 ( 2.734)	Data  2.081 ( 1.735)	Loss 9.8515e-02 (6.9835e-02) 
2023-05-26 01:48:26.464787: train Epoch: [71][  5/129]	Time  0.968 ( 2.440)	Data  0.001 ( 1.446)	Loss 6.0116e-02 (6.8215e-02) 
2023-05-26 01:48:29.501561: train Epoch: [71][  6/129]	Time  3.037 ( 2.525)	Data  2.069 ( 1.535)	Loss 6.6901e-02 (6.8028e-02) 
2023-05-26 01:48:30.476313: train Epoch: [71][  7/129]	Time  0.975 ( 2.331)	Data  0.001 ( 1.343)	Loss 5.2548e-02 (6.6093e-02) 
2023-05-26 01:48:33.530426: train Epoch: [71][  8/129]	Time  3.054 ( 2.412)	Data  2.085 ( 1.426)	Loss 6.6972e-02 (6.6191e-02) 
2023-05-26 01:48:34.507760: train Epoch: [71][  9/129]	Time  0.977 ( 2.268)	Data  0.002 ( 1.283)	Loss 7.5163e-02 (6.7088e-02) 
2023-05-26 01:48:37.571518: train Epoch: [71][ 10/129]	Time  3.064 ( 2.341)	Data  2.083 ( 1.356)	Loss 6.7830e-02 (6.7155e-02) 
2023-05-26 01:48:38.557437: train Epoch: [71][ 11/129]	Time  0.986 ( 2.228)	Data  0.001 ( 1.243)	Loss 6.3395e-02 (6.6842e-02) 
2023-05-26 01:48:41.608243: train Epoch: [71][ 12/129]	Time  3.051 ( 2.291)	Data  2.083 ( 1.308)	Loss 4.7892e-02 (6.5384e-02) 
2023-05-26 01:48:42.577615: train Epoch: [71][ 13/129]	Time  0.969 ( 2.197)	Data  0.001 ( 1.214)	Loss 9.2874e-02 (6.7348e-02) 
2023-05-26 01:48:45.664639: train Epoch: [71][ 14/129]	Time  3.087 ( 2.256)	Data  2.120 ( 1.275)	Loss 9.0617e-02 (6.8899e-02) 
2023-05-26 01:48:46.633979: train Epoch: [71][ 15/129]	Time  0.969 ( 2.176)	Data  0.001 ( 1.195)	Loss 9.1505e-02 (7.0312e-02) 
2023-05-26 01:48:49.791991: train Epoch: [71][ 16/129]	Time  3.158 ( 2.233)	Data  2.190 ( 1.254)	Loss 8.0500e-02 (7.0911e-02) 
2023-05-26 01:48:50.766071: train Epoch: [71][ 17/129]	Time  0.974 ( 2.163)	Data  0.001 ( 1.184)	Loss 8.3768e-02 (7.1626e-02) 
2023-05-26 01:48:53.977679: train Epoch: [71][ 18/129]	Time  3.212 ( 2.219)	Data  2.242 ( 1.240)	Loss 6.0445e-02 (7.1037e-02) 
2023-05-26 01:48:54.955710: train Epoch: [71][ 19/129]	Time  0.978 ( 2.157)	Data  0.001 ( 1.178)	Loss 9.4958e-02 (7.2233e-02) 
2023-05-26 01:48:58.114854: train Epoch: [71][ 20/129]	Time  3.159 ( 2.204)	Data  2.175 ( 1.225)	Loss 8.6301e-02 (7.2903e-02) 
2023-05-26 01:48:59.091615: train Epoch: [71][ 21/129]	Time  0.977 ( 2.148)	Data  0.002 ( 1.170)	Loss 1.0584e-01 (7.4400e-02) 
2023-05-26 01:49:02.231513: train Epoch: [71][ 22/129]	Time  3.140 ( 2.192)	Data  2.165 ( 1.213)	Loss 5.3822e-02 (7.3505e-02) 
2023-05-26 01:49:03.202351: train Epoch: [71][ 23/129]	Time  0.971 ( 2.141)	Data  0.002 ( 1.162)	Loss 5.7065e-02 (7.2820e-02) 
2023-05-26 01:49:06.502427: train Epoch: [71][ 24/129]	Time  3.300 ( 2.187)	Data  2.319 ( 1.209)	Loss 1.2762e-01 (7.5012e-02) 
2023-05-26 01:49:07.479317: train Epoch: [71][ 25/129]	Time  0.977 ( 2.141)	Data  0.001 ( 1.162)	Loss 7.0247e-02 (7.4829e-02) 
2023-05-26 01:49:10.711171: train Epoch: [71][ 26/129]	Time  3.232 ( 2.181)	Data  2.257 ( 1.203)	Loss 5.9792e-02 (7.4272e-02) 
2023-05-26 01:49:11.677678: train Epoch: [71][ 27/129]	Time  0.967 ( 2.138)	Data  0.001 ( 1.160)	Loss 5.4685e-02 (7.3573e-02) 
2023-05-26 01:49:14.843195: train Epoch: [71][ 28/129]	Time  3.166 ( 2.173)	Data  2.199 ( 1.196)	Loss 7.5183e-02 (7.3628e-02) 
2023-05-26 01:49:15.825027: train Epoch: [71][ 29/129]	Time  0.982 ( 2.133)	Data  0.001 ( 1.156)	Loss 5.5323e-02 (7.3018e-02) 
2023-05-26 01:49:18.896472: train Epoch: [71][ 30/129]	Time  3.071 ( 2.164)	Data  2.106 ( 1.187)	Loss 6.1811e-02 (7.2656e-02) 
2023-05-26 01:49:19.869772: train Epoch: [71][ 31/129]	Time  0.973 ( 2.126)	Data  0.001 ( 1.150)	Loss 5.7837e-02 (7.2193e-02) 
2023-05-26 01:49:22.954906: train Epoch: [71][ 32/129]	Time  3.085 ( 2.155)	Data  2.116 ( 1.179)	Loss 5.7967e-02 (7.1762e-02) 
2023-05-26 01:49:23.920975: train Epoch: [71][ 33/129]	Time  0.966 ( 2.120)	Data  0.001 ( 1.144)	Loss 5.2375e-02 (7.1192e-02) 
2023-05-26 01:49:26.985066: train Epoch: [71][ 34/129]	Time  3.064 ( 2.147)	Data  2.093 ( 1.171)	Loss 5.1647e-02 (7.0634e-02) 
2023-05-26 01:49:27.960363: train Epoch: [71][ 35/129]	Time  0.975 ( 2.115)	Data  0.001 ( 1.139)	Loss 4.4250e-02 (6.9901e-02) 
2023-05-26 01:49:30.934676: train Epoch: [71][ 36/129]	Time  2.974 ( 2.138)	Data  1.999 ( 1.162)	Loss 5.0805e-02 (6.9385e-02) 
2023-05-26 01:49:31.909153: train Epoch: [71][ 37/129]	Time  0.974 ( 2.107)	Data  0.001 ( 1.132)	Loss 7.7284e-02 (6.9592e-02) 
2023-05-26 01:49:35.003707: train Epoch: [71][ 38/129]	Time  3.095 ( 2.133)	Data  2.122 ( 1.157)	Loss 8.5472e-02 (7.0000e-02) 
2023-05-26 01:49:35.968902: train Epoch: [71][ 39/129]	Time  0.965 ( 2.104)	Data  0.001 ( 1.128)	Loss 8.0030e-02 (7.0250e-02) 
2023-05-26 01:49:39.134571: train Epoch: [71][ 40/129]	Time  3.166 ( 2.129)	Data  2.192 ( 1.154)	Loss 5.3773e-02 (6.9849e-02) 
2023-05-26 01:49:40.102812: train Epoch: [71][ 41/129]	Time  0.968 ( 2.102)	Data  0.001 ( 1.127)	Loss 9.3500e-02 (7.0412e-02) 
2023-05-26 01:49:43.138461: train Epoch: [71][ 42/129]	Time  3.036 ( 2.124)	Data  2.063 ( 1.148)	Loss 4.7064e-02 (6.9869e-02) 
2023-05-26 01:49:44.118227: train Epoch: [71][ 43/129]	Time  0.980 ( 2.098)	Data  0.001 ( 1.122)	Loss 5.7140e-02 (6.9579e-02) 
2023-05-26 01:49:47.157591: train Epoch: [71][ 44/129]	Time  3.039 ( 2.118)	Data  2.061 ( 1.143)	Loss 4.2354e-02 (6.8974e-02) 
2023-05-26 01:49:48.134349: train Epoch: [71][ 45/129]	Time  0.977 ( 2.094)	Data  0.002 ( 1.118)	Loss 4.2943e-02 (6.8409e-02) 
2023-05-26 01:49:51.142396: train Epoch: [71][ 46/129]	Time  3.008 ( 2.113)	Data  2.046 ( 1.138)	Loss 5.5341e-02 (6.8130e-02) 
2023-05-26 01:49:52.116451: train Epoch: [71][ 47/129]	Time  0.974 ( 2.089)	Data  0.001 ( 1.114)	Loss 6.1922e-02 (6.8001e-02) 
2023-05-26 01:49:55.231536: train Epoch: [71][ 48/129]	Time  3.115 ( 2.110)	Data  2.121 ( 1.135)	Loss 7.1322e-02 (6.8069e-02) 
2023-05-26 01:49:56.206924: train Epoch: [71][ 49/129]	Time  0.975 ( 2.088)	Data  0.001 ( 1.112)	Loss 7.4570e-02 (6.8199e-02) 
2023-05-26 01:49:59.313194: train Epoch: [71][ 50/129]	Time  3.106 ( 2.108)	Data  2.140 ( 1.132)	Loss 4.2946e-02 (6.7704e-02) 
2023-05-26 01:50:00.286227: train Epoch: [71][ 51/129]	Time  0.973 ( 2.086)	Data  0.001 ( 1.111)	Loss 1.0933e-01 (6.8504e-02) 
2023-05-26 01:50:03.356715: train Epoch: [71][ 52/129]	Time  3.070 ( 2.104)	Data  2.111 ( 1.129)	Loss 7.8416e-02 (6.8691e-02) 
2023-05-26 01:50:04.335567: train Epoch: [71][ 53/129]	Time  0.979 ( 2.084)	Data  0.001 ( 1.109)	Loss 6.3952e-02 (6.8604e-02) 
2023-05-26 01:50:07.403813: train Epoch: [71][ 54/129]	Time  3.068 ( 2.101)	Data  2.098 ( 1.127)	Loss 4.8489e-02 (6.8238e-02) 
2023-05-26 01:50:08.374233: train Epoch: [71][ 55/129]	Time  0.970 ( 2.081)	Data  0.001 ( 1.106)	Loss 8.9821e-02 (6.8623e-02) 
2023-05-26 01:50:11.535563: train Epoch: [71][ 56/129]	Time  3.161 ( 2.100)	Data  2.194 ( 1.126)	Loss 6.9540e-02 (6.8639e-02) 
2023-05-26 01:50:12.507050: train Epoch: [71][ 57/129]	Time  0.971 ( 2.081)	Data  0.001 ( 1.106)	Loss 1.1023e-01 (6.9356e-02) 
2023-05-26 01:50:15.551582: train Epoch: [71][ 58/129]	Time  3.045 ( 2.097)	Data  2.073 ( 1.123)	Loss 1.0634e-01 (6.9983e-02) 
2023-05-26 01:50:16.537843: train Epoch: [71][ 59/129]	Time  0.986 ( 2.079)	Data  0.002 ( 1.104)	Loss 6.0157e-02 (6.9820e-02) 
2023-05-26 01:50:19.694453: train Epoch: [71][ 60/129]	Time  3.157 ( 2.096)	Data  2.188 ( 1.122)	Loss 3.0065e-02 (6.9168e-02) 
2023-05-26 01:50:20.666415: train Epoch: [71][ 61/129]	Time  0.972 ( 2.078)	Data  0.001 ( 1.104)	Loss 5.6109e-02 (6.8957e-02) 
2023-05-26 01:50:23.674965: train Epoch: [71][ 62/129]	Time  3.009 ( 2.093)	Data  2.043 ( 1.118)	Loss 4.2698e-02 (6.8540e-02) 
2023-05-26 01:50:24.645265: train Epoch: [71][ 63/129]	Time  0.970 ( 2.075)	Data  0.001 ( 1.101)	Loss 5.3923e-02 (6.8312e-02) 
2023-05-26 01:50:27.688667: train Epoch: [71][ 64/129]	Time  3.043 ( 2.090)	Data  2.074 ( 1.116)	Loss 4.1720e-02 (6.7903e-02) 
2023-05-26 01:50:28.659699: train Epoch: [71][ 65/129]	Time  0.971 ( 2.073)	Data  0.001 ( 1.099)	Loss 4.1449e-02 (6.7502e-02) 
2023-05-26 01:50:31.730012: train Epoch: [71][ 66/129]	Time  3.070 ( 2.088)	Data  2.102 ( 1.114)	Loss 6.9435e-02 (6.7531e-02) 
2023-05-26 01:50:32.698656: train Epoch: [71][ 67/129]	Time  0.969 ( 2.072)	Data  0.001 ( 1.098)	Loss 9.9563e-02 (6.8002e-02) 
2023-05-26 01:50:35.821681: train Epoch: [71][ 68/129]	Time  3.123 ( 2.087)	Data  2.154 ( 1.113)	Loss 9.0902e-02 (6.8334e-02) 
2023-05-26 01:50:36.792415: train Epoch: [71][ 69/129]	Time  0.971 ( 2.071)	Data  0.001 ( 1.097)	Loss 1.0061e-01 (6.8795e-02) 
2023-05-26 01:50:39.932506: train Epoch: [71][ 70/129]	Time  3.140 ( 2.086)	Data  2.168 ( 1.112)	Loss 8.9314e-02 (6.9084e-02) 
2023-05-26 01:50:40.922532: train Epoch: [71][ 71/129]	Time  0.990 ( 2.071)	Data  0.002 ( 1.097)	Loss 5.4940e-02 (6.8887e-02) 
2023-05-26 01:50:44.099546: train Epoch: [71][ 72/129]	Time  3.177 ( 2.086)	Data  2.211 ( 1.112)	Loss 7.8214e-02 (6.9015e-02) 
2023-05-26 01:50:45.070634: train Epoch: [71][ 73/129]	Time  0.971 ( 2.071)	Data  0.001 ( 1.097)	Loss 7.5655e-02 (6.9105e-02) 
2023-05-26 01:50:48.164480: train Epoch: [71][ 74/129]	Time  3.094 ( 2.085)	Data  2.126 ( 1.111)	Loss 8.6213e-02 (6.9333e-02) 
2023-05-26 01:50:49.139324: train Epoch: [71][ 75/129]	Time  0.975 ( 2.070)	Data  0.001 ( 1.096)	Loss 6.6967e-02 (6.9302e-02) 
2023-05-26 01:50:52.140486: train Epoch: [71][ 76/129]	Time  3.001 ( 2.082)	Data  2.034 ( 1.108)	Loss 6.3567e-02 (6.9227e-02) 
2023-05-26 01:50:53.109491: train Epoch: [71][ 77/129]	Time  0.969 ( 2.068)	Data  0.001 ( 1.094)	Loss 8.2491e-02 (6.9398e-02) 
2023-05-26 01:50:56.276561: train Epoch: [71][ 78/129]	Time  3.167 ( 2.082)	Data  2.200 ( 1.108)	Loss 8.3836e-02 (6.9580e-02) 
2023-05-26 01:50:57.252782: train Epoch: [71][ 79/129]	Time  0.976 ( 2.068)	Data  0.001 ( 1.094)	Loss 5.1224e-02 (6.9351e-02) 
2023-05-26 01:51:00.372425: train Epoch: [71][ 80/129]	Time  3.120 ( 2.081)	Data  2.149 ( 1.107)	Loss 6.9517e-02 (6.9353e-02) 
2023-05-26 01:51:01.345028: train Epoch: [71][ 81/129]	Time  0.973 ( 2.067)	Data  0.001 ( 1.094)	Loss 8.2694e-02 (6.9516e-02) 
2023-05-26 01:51:04.548405: train Epoch: [71][ 82/129]	Time  3.203 ( 2.081)	Data  2.196 ( 1.107)	Loss 6.8938e-02 (6.9509e-02) 
2023-05-26 01:51:05.542588: train Epoch: [71][ 83/129]	Time  0.994 ( 2.068)	Data  0.002 ( 1.094)	Loss 4.5997e-02 (6.9229e-02) 
2023-05-26 01:51:08.589745: train Epoch: [71][ 84/129]	Time  3.047 ( 2.080)	Data  2.078 ( 1.106)	Loss 9.3136e-02 (6.9510e-02) 
2023-05-26 01:51:09.567190: train Epoch: [71][ 85/129]	Time  0.977 ( 2.067)	Data  0.001 ( 1.093)	Loss 1.1823e-01 (7.0076e-02) 
2023-05-26 01:51:12.649538: train Epoch: [71][ 86/129]	Time  3.082 ( 2.078)	Data  2.116 ( 1.104)	Loss 5.8043e-02 (6.9938e-02) 
2023-05-26 01:51:13.629163: train Epoch: [71][ 87/129]	Time  0.980 ( 2.066)	Data  0.001 ( 1.092)	Loss 1.0701e-01 (7.0359e-02) 
2023-05-26 01:51:16.815286: train Epoch: [71][ 88/129]	Time  3.186 ( 2.079)	Data  2.224 ( 1.105)	Loss 5.3322e-02 (7.0168e-02) 
2023-05-26 01:51:17.792809: train Epoch: [71][ 89/129]	Time  0.978 ( 2.066)	Data  0.001 ( 1.092)	Loss 6.4570e-02 (7.0106e-02) 
2023-05-26 01:51:20.924747: train Epoch: [71][ 90/129]	Time  3.132 ( 2.078)	Data  2.159 ( 1.104)	Loss 8.8335e-02 (7.0306e-02) 
2023-05-26 01:51:21.909387: train Epoch: [71][ 91/129]	Time  0.985 ( 2.066)	Data  0.003 ( 1.092)	Loss 6.9682e-02 (7.0299e-02) 
2023-05-26 01:51:25.034929: train Epoch: [71][ 92/129]	Time  3.126 ( 2.078)	Data  2.145 ( 1.103)	Loss 4.9077e-02 (7.0071e-02) 
2023-05-26 01:51:26.018754: train Epoch: [71][ 93/129]	Time  0.984 ( 2.066)	Data  0.002 ( 1.092)	Loss 7.2853e-02 (7.0101e-02) 
2023-05-26 01:51:29.134320: train Epoch: [71][ 94/129]	Time  3.116 ( 2.077)	Data  2.148 ( 1.103)	Loss 8.8905e-02 (7.0299e-02) 
2023-05-26 01:51:30.113362: train Epoch: [71][ 95/129]	Time  0.979 ( 2.065)	Data  0.001 ( 1.091)	Loss 7.2446e-02 (7.0321e-02) 
2023-05-26 01:51:33.208127: train Epoch: [71][ 96/129]	Time  3.095 ( 2.076)	Data  2.114 ( 1.102)	Loss 8.3682e-02 (7.0459e-02) 
2023-05-26 01:51:34.199647: train Epoch: [71][ 97/129]	Time  0.992 ( 2.065)	Data  0.001 ( 1.091)	Loss 6.2929e-02 (7.0382e-02) 
2023-05-26 01:51:37.287381: train Epoch: [71][ 98/129]	Time  3.088 ( 2.075)	Data  2.109 ( 1.101)	Loss 7.8042e-02 (7.0459e-02) 
2023-05-26 01:51:38.278389: train Epoch: [71][ 99/129]	Time  0.991 ( 2.065)	Data  0.001 ( 1.090)	Loss 8.5723e-02 (7.0612e-02) 
2023-05-26 01:51:41.431185: train Epoch: [71][100/129]	Time  3.153 ( 2.075)	Data  2.184 ( 1.101)	Loss 5.0374e-02 (7.0412e-02) 
2023-05-26 01:51:42.404564: train Epoch: [71][101/129]	Time  0.973 ( 2.064)	Data  0.001 ( 1.090)	Loss 1.0106e-01 (7.0712e-02) 
2023-05-26 01:51:45.492013: train Epoch: [71][102/129]	Time  3.087 ( 2.074)	Data  2.114 ( 1.100)	Loss 6.2500e-02 (7.0632e-02) 
2023-05-26 01:51:46.485693: train Epoch: [71][103/129]	Time  0.994 ( 2.064)	Data  0.002 ( 1.089)	Loss 6.9173e-02 (7.0618e-02) 
2023-05-26 01:51:49.764109: train Epoch: [71][104/129]	Time  3.278 ( 2.076)	Data  2.310 ( 1.101)	Loss 9.7155e-02 (7.0871e-02) 
2023-05-26 01:51:50.732778: train Epoch: [71][105/129]	Time  0.969 ( 2.065)	Data  0.001 ( 1.091)	Loss 6.4427e-02 (7.0810e-02) 
2023-05-26 01:51:53.996564: train Epoch: [71][106/129]	Time  3.264 ( 2.076)	Data  2.264 ( 1.102)	Loss 5.1178e-02 (7.0627e-02) 
2023-05-26 01:51:54.976556: train Epoch: [71][107/129]	Time  0.980 ( 2.066)	Data  0.001 ( 1.091)	Loss 9.8185e-02 (7.0882e-02) 
2023-05-26 01:51:58.166631: train Epoch: [71][108/129]	Time  3.190 ( 2.077)	Data  2.208 ( 1.102)	Loss 6.9776e-02 (7.0872e-02) 
2023-05-26 01:51:59.158082: train Epoch: [71][109/129]	Time  0.991 ( 2.067)	Data  0.001 ( 1.092)	Loss 5.6611e-02 (7.0742e-02) 
2023-05-26 01:52:02.416925: train Epoch: [71][110/129]	Time  3.259 ( 2.077)	Data  2.280 ( 1.102)	Loss 9.2515e-02 (7.0938e-02) 
2023-05-26 01:52:03.403624: train Epoch: [71][111/129]	Time  0.987 ( 2.068)	Data  0.001 ( 1.093)	Loss 7.5603e-02 (7.0980e-02) 
2023-05-26 01:52:06.504978: train Epoch: [71][112/129]	Time  3.101 ( 2.077)	Data  2.112 ( 1.102)	Loss 7.8443e-02 (7.1046e-02) 
2023-05-26 01:52:07.489411: train Epoch: [71][113/129]	Time  0.984 ( 2.067)	Data  0.002 ( 1.092)	Loss 5.8764e-02 (7.0938e-02) 
2023-05-26 01:52:10.544675: train Epoch: [71][114/129]	Time  3.055 ( 2.076)	Data  2.085 ( 1.101)	Loss 7.9672e-02 (7.1014e-02) 
2023-05-26 01:52:11.518270: train Epoch: [71][115/129]	Time  0.974 ( 2.066)	Data  0.001 ( 1.091)	Loss 1.0533e-01 (7.1310e-02) 
2023-05-26 01:52:14.510715: train Epoch: [71][116/129]	Time  2.992 ( 2.074)	Data  2.018 ( 1.099)	Loss 5.7240e-02 (7.1190e-02) 
2023-05-26 01:52:15.480292: train Epoch: [71][117/129]	Time  0.970 ( 2.065)	Data  0.001 ( 1.090)	Loss 6.7768e-02 (7.1161e-02) 
2023-05-26 01:52:18.653448: train Epoch: [71][118/129]	Time  3.173 ( 2.074)	Data  2.202 ( 1.099)	Loss 5.2124e-02 (7.1001e-02) 
2023-05-26 01:52:19.628205: train Epoch: [71][119/129]	Time  0.975 ( 2.065)	Data  0.001 ( 1.090)	Loss 9.5820e-02 (7.1208e-02) 
2023-05-26 01:52:22.621974: train Epoch: [71][120/129]	Time  2.994 ( 2.073)	Data  2.029 ( 1.098)	Loss 1.0035e-01 (7.1448e-02) 
2023-05-26 01:52:23.594965: train Epoch: [71][121/129]	Time  0.973 ( 2.064)	Data  0.001 ( 1.089)	Loss 7.5482e-02 (7.1482e-02) 
2023-05-26 01:52:26.650504: train Epoch: [71][122/129]	Time  3.056 ( 2.072)	Data  2.088 ( 1.097)	Loss 3.6198e-02 (7.1195e-02) 
2023-05-26 01:52:27.624161: train Epoch: [71][123/129]	Time  0.974 ( 2.063)	Data  0.001 ( 1.088)	Loss 9.2218e-02 (7.1364e-02) 
2023-05-26 01:52:30.779844: train Epoch: [71][124/129]	Time  3.156 ( 2.072)	Data  2.189 ( 1.097)	Loss 4.3314e-02 (7.1140e-02) 
2023-05-26 01:52:31.752486: train Epoch: [71][125/129]	Time  0.973 ( 2.063)	Data  0.001 ( 1.088)	Loss 4.8597e-02 (7.0961e-02) 
2023-05-26 01:52:34.860313: train Epoch: [71][126/129]	Time  3.108 ( 2.071)	Data  2.139 ( 1.096)	Loss 7.9757e-02 (7.1030e-02) 
2023-05-26 01:52:35.829529: train Epoch: [71][127/129]	Time  0.969 ( 2.063)	Data  0.001 ( 1.088)	Loss 6.9032e-02 (7.1015e-02) 
2023-05-26 01:52:37.869450: train Epoch: [71][128/129]	Time  2.040 ( 2.062)	Data  1.068 ( 1.088)	Loss 1.5544e-01 (7.1669e-02) 
2023-05-26 01:52:37.961410: Train Epoch done in 266.13704061799945 s 
2023-05-26 01:52:40.805048: val Epoch: [71][ 0/72]	Time  1.804 ( 1.804)	Data  1.590 ( 1.590)	Loss 3.9628e-02 (3.9628e-02) 
2023-05-26 01:52:40.934496: val Epoch: [71][ 1/72]	Time  0.130 ( 0.967)	Data  0.002 ( 0.796)	Loss 4.4370e-02 (4.1999e-02) 
2023-05-26 01:52:42.043165: val Epoch: [71][ 2/72]	Time  1.109 ( 1.014)	Data  0.978 ( 0.857)	Loss 5.3391e-02 (4.5796e-02) 
2023-05-26 01:52:42.168606: val Epoch: [71][ 3/72]	Time  0.125 ( 0.792)	Data  0.001 ( 0.643)	Loss 4.8238e-01 (1.5494e-01) 
2023-05-26 01:52:43.423282: val Epoch: [71][ 4/72]	Time  1.255 ( 0.884)	Data  1.106 ( 0.735)	Loss 6.0554e-02 (1.3607e-01) 
2023-05-26 01:52:43.559756: val Epoch: [71][ 5/72]	Time  0.136 ( 0.760)	Data  0.001 ( 0.613)	Loss 3.5040e-02 (1.1923e-01) 
2023-05-26 01:52:44.814312: val Epoch: [71][ 6/72]	Time  1.255 ( 0.831)	Data  1.111 ( 0.684)	Loss 4.4600e-02 (1.0857e-01) 
2023-05-26 01:52:44.941930: val Epoch: [71][ 7/72]	Time  0.128 ( 0.743)	Data  0.001 ( 0.599)	Loss 6.9352e-02 (1.0366e-01) 
2023-05-26 01:52:46.314692: val Epoch: [71][ 8/72]	Time  1.373 ( 0.813)	Data  1.232 ( 0.669)	Loss 6.1704e-02 (9.9003e-02) 
2023-05-26 01:52:46.457456: val Epoch: [71][ 9/72]	Time  0.143 ( 0.746)	Data  0.001 ( 0.602)	Loss 1.1702e-01 (1.0080e-01) 
2023-05-26 01:52:47.660952: val Epoch: [71][10/72]	Time  1.204 ( 0.787)	Data  1.075 ( 0.645)	Loss 1.3066e-01 (1.0352e-01) 
2023-05-26 01:52:47.787414: val Epoch: [71][11/72]	Time  0.126 ( 0.732)	Data  0.001 ( 0.592)	Loss 5.7987e-02 (9.9724e-02) 
2023-05-26 01:52:49.021280: val Epoch: [71][12/72]	Time  1.234 ( 0.771)	Data  1.104 ( 0.631)	Loss 5.5066e-02 (9.6289e-02) 
2023-05-26 01:52:49.149247: val Epoch: [71][13/72]	Time  0.128 ( 0.725)	Data  0.001 ( 0.586)	Loss 1.3008e-01 (9.8703e-02) 
2023-05-26 01:52:50.420323: val Epoch: [71][14/72]	Time  1.271 ( 0.761)	Data  1.144 ( 0.623)	Loss 1.7867e-01 (1.0403e-01) 
2023-05-26 01:52:50.548666: val Epoch: [71][15/72]	Time  0.128 ( 0.722)	Data  0.001 ( 0.584)	Loss 1.5343e-01 (1.0712e-01) 
2023-05-26 01:52:51.776551: val Epoch: [71][16/72]	Time  1.228 ( 0.752)	Data  1.101 ( 0.615)	Loss 2.2286e-01 (1.1393e-01) 
2023-05-26 01:52:51.904288: val Epoch: [71][17/72]	Time  0.128 ( 0.717)	Data  0.001 ( 0.581)	Loss 7.7016e-02 (1.1188e-01) 
2023-05-26 01:52:53.171835: val Epoch: [71][18/72]	Time  1.268 ( 0.746)	Data  1.136 ( 0.610)	Loss 1.1534e-01 (1.1206e-01) 
2023-05-26 01:52:53.297784: val Epoch: [71][19/72]	Time  0.126 ( 0.715)	Data  0.001 ( 0.579)	Loss 3.7676e-02 (1.0834e-01) 
2023-05-26 01:52:54.537633: val Epoch: [71][20/72]	Time  1.240 ( 0.740)	Data  1.112 ( 0.605)	Loss 3.3604e-01 (1.1918e-01) 
2023-05-26 01:52:54.666096: val Epoch: [71][21/72]	Time  0.128 ( 0.712)	Data  0.001 ( 0.577)	Loss 5.5010e-02 (1.1627e-01) 
2023-05-26 01:52:55.968987: val Epoch: [71][22/72]	Time  1.303 ( 0.738)	Data  1.164 ( 0.603)	Loss 3.6809e-01 (1.2722e-01) 
2023-05-26 01:52:56.102741: val Epoch: [71][23/72]	Time  0.134 ( 0.713)	Data  0.001 ( 0.578)	Loss 5.3973e-02 (1.2416e-01) 
2023-05-26 01:52:57.321191: val Epoch: [71][24/72]	Time  1.218 ( 0.733)	Data  1.084 ( 0.598)	Loss 8.6091e-02 (1.2264e-01) 
2023-05-26 01:52:57.456439: val Epoch: [71][25/72]	Time  0.135 ( 0.710)	Data  0.001 ( 0.575)	Loss 3.1916e-02 (1.1915e-01) 
2023-05-26 01:52:58.637349: val Epoch: [71][26/72]	Time  1.181 ( 0.727)	Data  1.048 ( 0.592)	Loss 5.1005e-02 (1.1663e-01) 
2023-05-26 01:52:58.776385: val Epoch: [71][27/72]	Time  0.139 ( 0.706)	Data  0.001 ( 0.571)	Loss 1.7977e-01 (1.1888e-01) 
2023-05-26 01:52:59.984119: val Epoch: [71][28/72]	Time  1.208 ( 0.724)	Data  1.081 ( 0.589)	Loss 7.5613e-02 (1.1739e-01) 
2023-05-26 01:53:00.112188: val Epoch: [71][29/72]	Time  0.128 ( 0.704)	Data  0.001 ( 0.569)	Loss 7.2236e-02 (1.1589e-01) 
2023-05-26 01:53:01.340229: val Epoch: [71][30/72]	Time  1.228 ( 0.721)	Data  1.099 ( 0.586)	Loss 2.0045e-01 (1.1861e-01) 
2023-05-26 01:53:01.467135: val Epoch: [71][31/72]	Time  0.127 ( 0.702)	Data  0.001 ( 0.568)	Loss 5.8241e-02 (1.1673e-01) 
2023-05-26 01:53:02.770133: val Epoch: [71][32/72]	Time  1.303 ( 0.720)	Data  1.158 ( 0.586)	Loss 8.9443e-02 (1.1590e-01) 
2023-05-26 01:53:02.911168: val Epoch: [71][33/72]	Time  0.141 ( 0.703)	Data  0.001 ( 0.569)	Loss 9.4268e-02 (1.1526e-01) 
2023-05-26 01:53:04.121171: val Epoch: [71][34/72]	Time  1.210 ( 0.718)	Data  1.081 ( 0.583)	Loss 9.9178e-02 (1.1480e-01) 
2023-05-26 01:53:04.261142: val Epoch: [71][35/72]	Time  0.140 ( 0.702)	Data  0.001 ( 0.567)	Loss 2.5654e-01 (1.1874e-01) 
2023-05-26 01:53:05.528984: val Epoch: [71][36/72]	Time  1.268 ( 0.717)	Data  1.125 ( 0.582)	Loss 1.0415e-01 (1.1835e-01) 
2023-05-26 01:53:05.662363: val Epoch: [71][37/72]	Time  0.133 ( 0.702)	Data  0.001 ( 0.567)	Loss 2.0439e-01 (1.2061e-01) 
2023-05-26 01:53:06.853394: val Epoch: [71][38/72]	Time  1.191 ( 0.714)	Data  1.058 ( 0.580)	Loss 6.1090e-02 (1.1909e-01) 
2023-05-26 01:53:06.988102: val Epoch: [71][39/72]	Time  0.135 ( 0.700)	Data  0.001 ( 0.565)	Loss 3.5544e-02 (1.1700e-01) 
2023-05-26 01:53:08.234714: val Epoch: [71][40/72]	Time  1.247 ( 0.713)	Data  1.121 ( 0.579)	Loss 4.6775e-02 (1.1528e-01) 
2023-05-26 01:53:08.364685: val Epoch: [71][41/72]	Time  0.130 ( 0.699)	Data  0.002 ( 0.565)	Loss 7.9097e-02 (1.1442e-01) 
2023-05-26 01:53:09.647034: val Epoch: [71][42/72]	Time  1.282 ( 0.713)	Data  1.161 ( 0.579)	Loss 1.4501e-01 (1.1513e-01) 
2023-05-26 01:53:09.776597: val Epoch: [71][43/72]	Time  0.130 ( 0.699)	Data  0.001 ( 0.566)	Loss 4.9653e-02 (1.1365e-01) 
2023-05-26 01:53:10.997498: val Epoch: [71][44/72]	Time  1.221 ( 0.711)	Data  1.092 ( 0.577)	Loss 3.8746e-02 (1.1198e-01) 
2023-05-26 01:53:11.133393: val Epoch: [71][45/72]	Time  0.136 ( 0.699)	Data  0.001 ( 0.565)	Loss 4.6240e-02 (1.1055e-01) 
2023-05-26 01:53:12.383533: val Epoch: [71][46/72]	Time  1.250 ( 0.710)	Data  1.119 ( 0.577)	Loss 1.3456e-01 (1.1106e-01) 
2023-05-26 01:53:12.507797: val Epoch: [71][47/72]	Time  0.124 ( 0.698)	Data  0.001 ( 0.565)	Loss 7.2747e-02 (1.1026e-01) 
2023-05-26 01:53:13.780149: val Epoch: [71][48/72]	Time  1.272 ( 0.710)	Data  1.140 ( 0.576)	Loss 3.5554e-01 (1.1527e-01) 
2023-05-26 01:53:13.921817: val Epoch: [71][49/72]	Time  0.142 ( 0.698)	Data  0.001 ( 0.565)	Loss 7.8490e-02 (1.1453e-01) 
2023-05-26 01:53:15.188035: val Epoch: [71][50/72]	Time  1.266 ( 0.710)	Data  1.141 ( 0.576)	Loss 7.0839e-02 (1.1368e-01) 
2023-05-26 01:53:15.316802: val Epoch: [71][51/72]	Time  0.129 ( 0.698)	Data  0.001 ( 0.565)	Loss 4.4675e-02 (1.1235e-01) 
2023-05-26 01:53:16.546333: val Epoch: [71][52/72]	Time  1.230 ( 0.708)	Data  1.102 ( 0.575)	Loss 3.7753e-01 (1.1735e-01) 
2023-05-26 01:53:16.674703: val Epoch: [71][53/72]	Time  0.128 ( 0.698)	Data  0.001 ( 0.565)	Loss 2.8582e-01 (1.2047e-01) 
2023-05-26 01:53:17.887370: val Epoch: [71][54/72]	Time  1.213 ( 0.707)	Data  1.087 ( 0.574)	Loss 5.8768e-02 (1.1935e-01) 
2023-05-26 01:53:18.014722: val Epoch: [71][55/72]	Time  0.127 ( 0.697)	Data  0.001 ( 0.564)	Loss 7.9179e-02 (1.1863e-01) 
2023-05-26 01:53:19.247304: val Epoch: [71][56/72]	Time  1.233 ( 0.706)	Data  1.104 ( 0.573)	Loss 3.0748e-01 (1.2195e-01) 
2023-05-26 01:53:19.375110: val Epoch: [71][57/72]	Time  0.128 ( 0.696)	Data  0.001 ( 0.563)	Loss 8.9105e-02 (1.2138e-01) 
2023-05-26 01:53:20.615666: val Epoch: [71][58/72]	Time  1.241 ( 0.705)	Data  1.113 ( 0.573)	Loss 7.0115e-02 (1.2051e-01) 
2023-05-26 01:53:20.744389: val Epoch: [71][59/72]	Time  0.129 ( 0.696)	Data  0.001 ( 0.563)	Loss 1.6314e-01 (1.2122e-01) 
2023-05-26 01:53:21.948124: val Epoch: [71][60/72]	Time  1.204 ( 0.704)	Data  1.077 ( 0.572)	Loss 1.7112e-01 (1.2204e-01) 
2023-05-26 01:53:22.075487: val Epoch: [71][61/72]	Time  0.127 ( 0.695)	Data  0.001 ( 0.562)	Loss 5.3936e-02 (1.2094e-01) 
2023-05-26 01:53:23.314584: val Epoch: [71][62/72]	Time  1.239 ( 0.703)	Data  1.109 ( 0.571)	Loss 7.0707e-02 (1.2015e-01) 
2023-05-26 01:53:23.452103: val Epoch: [71][63/72]	Time  0.137 ( 0.695)	Data  0.001 ( 0.562)	Loss 1.1665e-01 (1.2009e-01) 
2023-05-26 01:53:24.718810: val Epoch: [71][64/72]	Time  1.267 ( 0.703)	Data  1.138 ( 0.571)	Loss 4.8106e-02 (1.1898e-01) 
2023-05-26 01:53:24.849373: val Epoch: [71][65/72]	Time  0.131 ( 0.695)	Data  0.001 ( 0.562)	Loss 7.7075e-02 (1.1835e-01) 
2023-05-26 01:53:26.084244: val Epoch: [71][66/72]	Time  1.235 ( 0.703)	Data  1.106 ( 0.570)	Loss 4.1026e-01 (1.2270e-01) 
2023-05-26 01:53:26.216741: val Epoch: [71][67/72]	Time  0.132 ( 0.694)	Data  0.001 ( 0.562)	Loss 3.5541e-02 (1.2142e-01) 
2023-05-26 01:53:27.442200: val Epoch: [71][68/72]	Time  1.225 ( 0.702)	Data  1.097 ( 0.570)	Loss 3.4424e-01 (1.2465e-01) 
2023-05-26 01:53:27.570445: val Epoch: [71][69/72]	Time  0.128 ( 0.694)	Data  0.001 ( 0.562)	Loss 8.4262e-02 (1.2408e-01) 
2023-05-26 01:53:28.594900: val Epoch: [71][70/72]	Time  1.024 ( 0.699)	Data  0.897 ( 0.566)	Loss 9.9016e-02 (1.2372e-01) 
2023-05-26 01:53:28.722878: val Epoch: [71][71/72]	Time  0.128 ( 0.691)	Data  0.001 ( 0.559)	Loss 4.8494e-01 (1.2874e-01) 
2023-05-26 01:53:28.901750: Epoch 71 :Val : ['ET : 0.739704966545105', 'TC : 0.7775359153747559', 'WT : 0.8738094568252563'] 
2023-05-26 01:53:28.903047: Epoch 71 :Val : ['ET : 0.739704966545105', 'TC : 0.7775359153747559', 'WT : 0.8738094568252563'] 
2023-05-26 01:53:28.909333: Val epoch done in 50.947922466999444 s 
2023-05-26 01:53:28.921202: Batches per epoch:  129 
2023-05-26 01:53:34.568019: train Epoch: [72][  0/129]	Time  5.646 ( 5.646)	Data  4.624 ( 4.624)	Loss 5.7615e-02 (5.7615e-02) 
2023-05-26 01:53:35.536488: train Epoch: [72][  1/129]	Time  0.968 ( 3.307)	Data  0.001 ( 2.313)	Loss 8.4075e-02 (7.0845e-02) 
2023-05-26 01:53:38.605117: train Epoch: [72][  2/129]	Time  3.069 ( 3.228)	Data  2.095 ( 2.240)	Loss 7.5032e-02 (7.2241e-02) 
2023-05-26 01:53:39.576504: train Epoch: [72][  3/129]	Time  0.971 ( 2.664)	Data  0.001 ( 1.680)	Loss 7.0126e-02 (7.1712e-02) 
2023-05-26 01:53:42.644366: train Epoch: [72][  4/129]	Time  3.068 ( 2.744)	Data  2.101 ( 1.765)	Loss 1.5534e-01 (8.8437e-02) 
2023-05-26 01:53:43.624504: train Epoch: [72][  5/129]	Time  0.980 ( 2.450)	Data  0.001 ( 1.471)	Loss 6.6316e-02 (8.4750e-02) 
2023-05-26 01:53:46.784743: train Epoch: [72][  6/129]	Time  3.160 ( 2.552)	Data  2.188 ( 1.573)	Loss 4.7857e-02 (7.9480e-02) 
2023-05-26 01:53:47.756375: train Epoch: [72][  7/129]	Time  0.972 ( 2.354)	Data  0.001 ( 1.377)	Loss 5.6986e-02 (7.6668e-02) 
2023-05-26 01:53:50.843777: train Epoch: [72][  8/129]	Time  3.087 ( 2.436)	Data  2.124 ( 1.460)	Loss 5.2344e-02 (7.3965e-02) 
2023-05-26 01:53:51.811845: train Epoch: [72][  9/129]	Time  0.968 ( 2.289)	Data  0.001 ( 1.314)	Loss 6.3980e-02 (7.2967e-02) 
2023-05-26 01:53:54.906361: train Epoch: [72][ 10/129]	Time  3.095 ( 2.362)	Data  2.125 ( 1.388)	Loss 6.4230e-02 (7.2173e-02) 
2023-05-26 01:53:55.883399: train Epoch: [72][ 11/129]	Time  0.977 ( 2.247)	Data  0.001 ( 1.272)	Loss 1.0130e-01 (7.4600e-02) 
2023-05-26 01:53:58.945791: train Epoch: [72][ 12/129]	Time  3.062 ( 2.309)	Data  2.078 ( 1.334)	Loss 4.4455e-02 (7.2281e-02) 
2023-05-26 01:53:59.920869: train Epoch: [72][ 13/129]	Time  0.975 ( 2.214)	Data  0.001 ( 1.239)	Loss 6.4199e-02 (7.1704e-02) 
2023-05-26 01:54:02.891278: train Epoch: [72][ 14/129]	Time  2.970 ( 2.265)	Data  2.009 ( 1.290)	Loss 6.3574e-02 (7.1162e-02) 
2023-05-26 01:54:03.862558: train Epoch: [72][ 15/129]	Time  0.971 ( 2.184)	Data  0.001 ( 1.210)	Loss 3.1727e-02 (6.8697e-02) 
2023-05-26 01:54:06.958450: train Epoch: [72][ 16/129]	Time  3.096 ( 2.237)	Data  2.121 ( 1.263)	Loss 4.0515e-02 (6.7039e-02) 
2023-05-26 01:54:07.931858: train Epoch: [72][ 17/129]	Time  0.973 ( 2.167)	Data  0.001 ( 1.193)	Loss 8.6367e-02 (6.8113e-02) 
2023-05-26 01:54:11.074161: train Epoch: [72][ 18/129]	Time  3.142 ( 2.219)	Data  2.172 ( 1.245)	Loss 5.3544e-02 (6.7346e-02) 
2023-05-26 01:54:12.065150: train Epoch: [72][ 19/129]	Time  0.991 ( 2.157)	Data  0.001 ( 1.182)	Loss 8.8475e-02 (6.8403e-02) 
2023-05-26 01:54:15.211467: train Epoch: [72][ 20/129]	Time  3.146 ( 2.204)	Data  2.168 ( 1.229)	Loss 3.9939e-02 (6.7047e-02) 
2023-05-26 01:54:16.181297: train Epoch: [72][ 21/129]	Time  0.970 ( 2.148)	Data  0.001 ( 1.174)	Loss 2.8730e-02 (6.5306e-02) 
2023-05-26 01:54:19.298560: train Epoch: [72][ 22/129]	Time  3.117 ( 2.190)	Data  2.141 ( 1.216)	Loss 7.5634e-02 (6.5755e-02) 
2023-05-26 01:54:20.271714: train Epoch: [72][ 23/129]	Time  0.973 ( 2.140)	Data  0.001 ( 1.165)	Loss 8.0617e-02 (6.6374e-02) 
2023-05-26 01:54:23.373564: train Epoch: [72][ 24/129]	Time  3.102 ( 2.178)	Data  2.127 ( 1.203)	Loss 4.5447e-02 (6.5537e-02) 
2023-05-26 01:54:24.353656: train Epoch: [72][ 25/129]	Time  0.980 ( 2.132)	Data  0.002 ( 1.157)	Loss 5.6909e-02 (6.5205e-02) 
2023-05-26 01:54:27.564541: train Epoch: [72][ 26/129]	Time  3.211 ( 2.172)	Data  2.250 ( 1.198)	Loss 6.9227e-02 (6.5354e-02) 
2023-05-26 01:54:28.565476: train Epoch: [72][ 27/129]	Time  1.001 ( 2.130)	Data  0.001 ( 1.155)	Loss 7.6555e-02 (6.5754e-02) 
2023-05-26 01:54:31.670896: train Epoch: [72][ 28/129]	Time  3.105 ( 2.164)	Data  2.138 ( 1.189)	Loss 4.9080e-02 (6.5179e-02) 
2023-05-26 01:54:32.639850: train Epoch: [72][ 29/129]	Time  0.969 ( 2.124)	Data  0.001 ( 1.149)	Loss 7.9432e-02 (6.5654e-02) 
2023-05-26 01:54:35.770981: train Epoch: [72][ 30/129]	Time  3.131 ( 2.156)	Data  2.159 ( 1.182)	Loss 6.2435e-02 (6.5550e-02) 
2023-05-26 01:54:36.745594: train Epoch: [72][ 31/129]	Time  0.975 ( 2.119)	Data  0.001 ( 1.145)	Loss 9.5547e-02 (6.6488e-02) 
2023-05-26 01:54:39.812274: train Epoch: [72][ 32/129]	Time  3.067 ( 2.148)	Data  2.098 ( 1.174)	Loss 8.5426e-02 (6.7062e-02) 
2023-05-26 01:54:40.786147: train Epoch: [72][ 33/129]	Time  0.974 ( 2.114)	Data  0.001 ( 1.139)	Loss 7.7005e-02 (6.7354e-02) 
2023-05-26 01:54:43.884161: train Epoch: [72][ 34/129]	Time  3.098 ( 2.142)	Data  2.134 ( 1.168)	Loss 7.0272e-02 (6.7437e-02) 
2023-05-26 01:54:44.856009: train Epoch: [72][ 35/129]	Time  0.972 ( 2.109)	Data  0.001 ( 1.135)	Loss 8.5318e-02 (6.7934e-02) 
2023-05-26 01:54:47.930065: train Epoch: [72][ 36/129]	Time  3.074 ( 2.135)	Data  2.110 ( 1.162)	Loss 6.0000e-02 (6.7720e-02) 
2023-05-26 01:54:48.924209: train Epoch: [72][ 37/129]	Time  0.994 ( 2.105)	Data  0.001 ( 1.131)	Loss 4.6405e-02 (6.7159e-02) 
2023-05-26 01:54:52.012814: train Epoch: [72][ 38/129]	Time  3.089 ( 2.131)	Data  2.111 ( 1.156)	Loss 7.2523e-02 (6.7296e-02) 
2023-05-26 01:54:52.985786: train Epoch: [72][ 39/129]	Time  0.973 ( 2.102)	Data  0.001 ( 1.127)	Loss 6.4143e-02 (6.7217e-02) 
2023-05-26 01:54:56.150993: train Epoch: [72][ 40/129]	Time  3.165 ( 2.128)	Data  2.188 ( 1.153)	Loss 1.8498e-01 (7.0090e-02) 
2023-05-26 01:54:57.136154: train Epoch: [72][ 41/129]	Time  0.985 ( 2.100)	Data  0.001 ( 1.126)	Loss 4.7329e-02 (6.9548e-02) 
2023-05-26 01:55:00.222724: train Epoch: [72][ 42/129]	Time  3.087 ( 2.123)	Data  2.118 ( 1.149)	Loss 5.9462e-02 (6.9313e-02) 
2023-05-26 01:55:01.187920: train Epoch: [72][ 43/129]	Time  0.965 ( 2.097)	Data  0.001 ( 1.123)	Loss 1.3391e-01 (7.0781e-02) 
2023-05-26 01:55:04.226660: train Epoch: [72][ 44/129]	Time  3.039 ( 2.118)	Data  2.071 ( 1.144)	Loss 5.5440e-02 (7.0440e-02) 
2023-05-26 01:55:05.200861: train Epoch: [72][ 45/129]	Time  0.974 ( 2.093)	Data  0.002 ( 1.119)	Loss 1.0562e-01 (7.1205e-02) 
2023-05-26 01:55:08.223665: train Epoch: [72][ 46/129]	Time  3.023 ( 2.113)	Data  2.055 ( 1.139)	Loss 9.7554e-02 (7.1766e-02) 
2023-05-26 01:55:09.193317: train Epoch: [72][ 47/129]	Time  0.970 ( 2.089)	Data  0.001 ( 1.115)	Loss 7.3060e-02 (7.1793e-02) 
2023-05-26 01:55:12.379060: train Epoch: [72][ 48/129]	Time  3.186 ( 2.111)	Data  2.210 ( 1.138)	Loss 5.4150e-02 (7.1433e-02) 
2023-05-26 01:55:13.345751: train Epoch: [72][ 49/129]	Time  0.967 ( 2.088)	Data  0.001 ( 1.115)	Loss 5.2515e-02 (7.1054e-02) 
2023-05-26 01:55:16.535529: train Epoch: [72][ 50/129]	Time  3.190 ( 2.110)	Data  2.217 ( 1.136)	Loss 4.3731e-02 (7.0519e-02) 
2023-05-26 01:55:17.526642: train Epoch: [72][ 51/129]	Time  0.991 ( 2.089)	Data  0.002 ( 1.115)	Loss 5.5552e-02 (7.0231e-02) 
2023-05-26 01:55:20.613261: train Epoch: [72][ 52/129]	Time  3.087 ( 2.107)	Data  2.115 ( 1.134)	Loss 5.7960e-02 (6.9999e-02) 
2023-05-26 01:55:21.594543: train Epoch: [72][ 53/129]	Time  0.981 ( 2.087)	Data  0.001 ( 1.113)	Loss 7.0938e-02 (7.0017e-02) 
2023-05-26 01:55:24.656195: train Epoch: [72][ 54/129]	Time  3.062 ( 2.104)	Data  2.091 ( 1.130)	Loss 8.5776e-02 (7.0303e-02) 
2023-05-26 01:55:25.628719: train Epoch: [72][ 55/129]	Time  0.973 ( 2.084)	Data  0.001 ( 1.110)	Loss 7.1054e-02 (7.0317e-02) 
2023-05-26 01:55:28.582744: train Epoch: [72][ 56/129]	Time  2.954 ( 2.099)	Data  1.979 ( 1.125)	Loss 5.6754e-02 (7.0079e-02) 
2023-05-26 01:55:29.579491: train Epoch: [72][ 57/129]	Time  0.997 ( 2.080)	Data  0.002 ( 1.106)	Loss 7.5452e-02 (7.0171e-02) 
2023-05-26 01:55:32.662551: train Epoch: [72][ 58/129]	Time  3.083 ( 2.097)	Data  2.118 ( 1.123)	Loss 1.5223e-01 (7.1562e-02) 
2023-05-26 01:55:33.633969: train Epoch: [72][ 59/129]	Time  0.971 ( 2.079)	Data  0.001 ( 1.104)	Loss 7.4111e-02 (7.1605e-02) 
2023-05-26 01:55:36.705762: train Epoch: [72][ 60/129]	Time  3.072 ( 2.095)	Data  2.108 ( 1.121)	Loss 1.2351e-01 (7.2456e-02) 
2023-05-26 01:55:37.695296: train Epoch: [72][ 61/129]	Time  0.990 ( 2.077)	Data  0.001 ( 1.103)	Loss 8.7649e-02 (7.2701e-02) 
2023-05-26 01:55:40.813567: train Epoch: [72][ 62/129]	Time  3.118 ( 2.094)	Data  2.144 ( 1.119)	Loss 7.9281e-02 (7.2805e-02) 
2023-05-26 01:55:41.788459: train Epoch: [72][ 63/129]	Time  0.975 ( 2.076)	Data  0.001 ( 1.102)	Loss 9.1133e-02 (7.3091e-02) 
2023-05-26 01:55:44.982502: train Epoch: [72][ 64/129]	Time  3.194 ( 2.093)	Data  2.221 ( 1.119)	Loss 6.1730e-02 (7.2917e-02) 
2023-05-26 01:55:45.954940: train Epoch: [72][ 65/129]	Time  0.972 ( 2.076)	Data  0.002 ( 1.102)	Loss 1.0571e-01 (7.3413e-02) 
2023-05-26 01:55:49.195430: train Epoch: [72][ 66/129]	Time  3.240 ( 2.094)	Data  2.275 ( 1.120)	Loss 8.4290e-02 (7.3576e-02) 
2023-05-26 01:55:50.176529: train Epoch: [72][ 67/129]	Time  0.981 ( 2.077)	Data  0.001 ( 1.103)	Loss 8.3857e-02 (7.3727e-02) 
2023-05-26 01:55:53.368251: train Epoch: [72][ 68/129]	Time  3.192 ( 2.093)	Data  2.213 ( 1.119)	Loss 6.0481e-02 (7.3535e-02) 
2023-05-26 01:55:54.361223: train Epoch: [72][ 69/129]	Time  0.993 ( 2.078)	Data  0.001 ( 1.103)	Loss 8.8033e-02 (7.3742e-02) 
2023-05-26 01:55:57.552194: train Epoch: [72][ 70/129]	Time  3.191 ( 2.093)	Data  2.196 ( 1.119)	Loss 1.3096e-01 (7.4548e-02) 
2023-05-26 01:55:58.536682: train Epoch: [72][ 71/129]	Time  0.985 ( 2.078)	Data  0.002 ( 1.103)	Loss 5.1231e-02 (7.4224e-02) 
2023-05-26 01:56:01.566236: train Epoch: [72][ 72/129]	Time  3.030 ( 2.091)	Data  2.063 ( 1.116)	Loss 5.8171e-02 (7.4004e-02) 
2023-05-26 01:56:02.546329: train Epoch: [72][ 73/129]	Time  0.980 ( 2.076)	Data  0.001 ( 1.101)	Loss 6.7949e-02 (7.3922e-02) 
2023-05-26 01:56:05.646910: train Epoch: [72][ 74/129]	Time  3.101 ( 2.090)	Data  2.114 ( 1.115)	Loss 7.9523e-02 (7.3997e-02) 
2023-05-26 01:56:06.633819: train Epoch: [72][ 75/129]	Time  0.987 ( 2.075)	Data  0.001 ( 1.100)	Loss 5.4497e-02 (7.3740e-02) 
2023-05-26 01:56:09.946579: train Epoch: [72][ 76/129]	Time  3.313 ( 2.091)	Data  2.344 ( 1.116)	Loss 5.3657e-02 (7.3480e-02) 
2023-05-26 01:56:10.922831: train Epoch: [72][ 77/129]	Time  0.976 ( 2.077)	Data  0.001 ( 1.102)	Loss 9.1726e-02 (7.3714e-02) 
2023-05-26 01:56:14.134526: train Epoch: [72][ 78/129]	Time  3.212 ( 2.091)	Data  2.230 ( 1.116)	Loss 1.0786e-01 (7.4146e-02) 
2023-05-26 01:56:15.117257: train Epoch: [72][ 79/129]	Time  0.983 ( 2.077)	Data  0.001 ( 1.102)	Loss 4.2749e-02 (7.3753e-02) 
2023-05-26 01:56:18.254726: train Epoch: [72][ 80/129]	Time  3.137 ( 2.091)	Data  2.170 ( 1.116)	Loss 1.3212e-01 (7.4474e-02) 
2023-05-26 01:56:19.225032: train Epoch: [72][ 81/129]	Time  0.970 ( 2.077)	Data  0.001 ( 1.102)	Loss 7.8534e-02 (7.4523e-02) 
2023-05-26 01:56:22.476656: train Epoch: [72][ 82/129]	Time  3.252 ( 2.091)	Data  2.284 ( 1.116)	Loss 1.0501e-01 (7.4891e-02) 
2023-05-26 01:56:23.444196: train Epoch: [72][ 83/129]	Time  0.968 ( 2.078)	Data  0.001 ( 1.103)	Loss 4.4299e-02 (7.4527e-02) 
2023-05-26 01:56:26.498709: train Epoch: [72][ 84/129]	Time  3.055 ( 2.089)	Data  2.087 ( 1.115)	Loss 1.1414e-01 (7.4993e-02) 
2023-05-26 01:56:27.475956: train Epoch: [72][ 85/129]	Time  0.977 ( 2.076)	Data  0.001 ( 1.102)	Loss 6.8418e-02 (7.4916e-02) 
2023-05-26 01:56:30.579575: train Epoch: [72][ 86/129]	Time  3.104 ( 2.088)	Data  2.143 ( 1.114)	Loss 8.6962e-02 (7.5055e-02) 
2023-05-26 01:56:31.547370: train Epoch: [72][ 87/129]	Time  0.968 ( 2.075)	Data  0.001 ( 1.101)	Loss 8.4167e-02 (7.5158e-02) 
2023-05-26 01:56:34.548006: train Epoch: [72][ 88/129]	Time  3.001 ( 2.086)	Data  2.036 ( 1.111)	Loss 1.0292e-01 (7.5470e-02) 
2023-05-26 01:56:35.528130: train Epoch: [72][ 89/129]	Time  0.980 ( 2.073)	Data  0.001 ( 1.099)	Loss 5.3556e-02 (7.5227e-02) 
2023-05-26 01:56:38.652833: train Epoch: [72][ 90/129]	Time  3.125 ( 2.085)	Data  2.158 ( 1.111)	Loss 9.0205e-02 (7.5391e-02) 
2023-05-26 01:56:39.630992: train Epoch: [72][ 91/129]	Time  0.978 ( 2.073)	Data  0.001 ( 1.099)	Loss 1.0053e-01 (7.5664e-02) 
2023-05-26 01:56:42.798873: train Epoch: [72][ 92/129]	Time  3.168 ( 2.085)	Data  2.196 ( 1.110)	Loss 1.0689e-01 (7.6000e-02) 
2023-05-26 01:56:43.790309: train Epoch: [72][ 93/129]	Time  0.991 ( 2.073)	Data  0.004 ( 1.099)	Loss 6.7378e-02 (7.5908e-02) 
2023-05-26 01:56:46.871393: train Epoch: [72][ 94/129]	Time  3.081 ( 2.084)	Data  2.101 ( 1.109)	Loss 5.0922e-02 (7.5645e-02) 
2023-05-26 01:56:47.859017: train Epoch: [72][ 95/129]	Time  0.988 ( 2.072)	Data  0.001 ( 1.098)	Loss 4.9859e-02 (7.5377e-02) 
2023-05-26 01:56:50.962245: train Epoch: [72][ 96/129]	Time  3.103 ( 2.083)	Data  2.140 ( 1.108)	Loss 9.2904e-02 (7.5558e-02) 
2023-05-26 01:56:51.934006: train Epoch: [72][ 97/129]	Time  0.972 ( 2.072)	Data  0.001 ( 1.097)	Loss 5.9217e-02 (7.5391e-02) 
2023-05-26 01:56:55.088474: train Epoch: [72][ 98/129]	Time  3.154 ( 2.082)	Data  2.185 ( 1.108)	Loss 7.3883e-02 (7.5376e-02) 
2023-05-26 01:56:56.068936: train Epoch: [72][ 99/129]	Time  0.980 ( 2.071)	Data  0.001 ( 1.097)	Loss 9.1069e-02 (7.5533e-02) 
2023-05-26 01:56:59.226382: train Epoch: [72][100/129]	Time  3.157 ( 2.082)	Data  2.173 ( 1.108)	Loss 6.8692e-02 (7.5465e-02) 
2023-05-26 01:57:00.209678: train Epoch: [72][101/129]	Time  0.983 ( 2.071)	Data  0.002 ( 1.097)	Loss 1.1229e-01 (7.5826e-02) 
2023-05-26 01:57:03.328776: train Epoch: [72][102/129]	Time  3.119 ( 2.082)	Data  2.153 ( 1.107)	Loss 5.8355e-02 (7.5656e-02) 
2023-05-26 01:57:04.313403: train Epoch: [72][103/129]	Time  0.985 ( 2.071)	Data  0.003 ( 1.096)	Loss 6.5851e-02 (7.5562e-02) 
2023-05-26 01:57:07.469575: train Epoch: [72][104/129]	Time  3.156 ( 2.081)	Data  2.176 ( 1.107)	Loss 4.2347e-02 (7.5246e-02) 
2023-05-26 01:57:08.444147: train Epoch: [72][105/129]	Time  0.975 ( 2.071)	Data  0.001 ( 1.096)	Loss 9.1057e-02 (7.5395e-02) 
2023-05-26 01:57:11.603898: train Epoch: [72][106/129]	Time  3.160 ( 2.081)	Data  2.174 ( 1.106)	Loss 4.0319e-02 (7.5067e-02) 
2023-05-26 01:57:12.577442: train Epoch: [72][107/129]	Time  0.974 ( 2.071)	Data  0.001 ( 1.096)	Loss 7.8063e-02 (7.5095e-02) 
2023-05-26 01:57:15.672469: train Epoch: [72][108/129]	Time  3.095 ( 2.080)	Data  2.126 ( 1.106)	Loss 8.5397e-02 (7.5189e-02) 
2023-05-26 01:57:16.647166: train Epoch: [72][109/129]	Time  0.975 ( 2.070)	Data  0.001 ( 1.096)	Loss 1.0262e-01 (7.5439e-02) 
2023-05-26 01:57:19.727582: train Epoch: [72][110/129]	Time  3.080 ( 2.079)	Data  2.115 ( 1.105)	Loss 1.0455e-01 (7.5701e-02) 
2023-05-26 01:57:20.701930: train Epoch: [72][111/129]	Time  0.974 ( 2.069)	Data  0.001 ( 1.095)	Loss 1.4337e-01 (7.6305e-02) 
2023-05-26 01:57:23.767017: train Epoch: [72][112/129]	Time  3.065 ( 2.078)	Data  2.098 ( 1.104)	Loss 3.7452e-02 (7.5961e-02) 
2023-05-26 01:57:24.736986: train Epoch: [72][113/129]	Time  0.970 ( 2.069)	Data  0.001 ( 1.094)	Loss 5.5735e-02 (7.5784e-02) 
2023-05-26 01:57:27.794131: train Epoch: [72][114/129]	Time  3.057 ( 2.077)	Data  2.089 ( 1.103)	Loss 5.6005e-02 (7.5612e-02) 
2023-05-26 01:57:28.745659: train Epoch: [72][115/129]	Time  0.952 ( 2.067)	Data  0.001 ( 1.093)	Loss 8.5086e-02 (7.5693e-02) 
2023-05-26 01:57:31.533797: train Epoch: [72][116/129]	Time  2.788 ( 2.074)	Data  1.837 ( 1.100)	Loss 7.3418e-02 (7.5674e-02) 
2023-05-26 01:57:32.489751: train Epoch: [72][117/129]	Time  0.956 ( 2.064)	Data  0.001 ( 1.090)	Loss 3.7511e-02 (7.5351e-02) 
2023-05-26 01:57:35.369501: train Epoch: [72][118/129]	Time  2.880 ( 2.071)	Data  1.921 ( 1.097)	Loss 8.2866e-02 (7.5414e-02) 
2023-05-26 01:57:36.329886: train Epoch: [72][119/129]	Time  0.960 ( 2.062)	Data  0.001 ( 1.088)	Loss 7.3245e-02 (7.5396e-02) 
2023-05-26 01:57:39.104298: train Epoch: [72][120/129]	Time  2.774 ( 2.068)	Data  1.812 ( 1.094)	Loss 5.0367e-02 (7.5189e-02) 
2023-05-26 01:57:40.068029: train Epoch: [72][121/129]	Time  0.964 ( 2.059)	Data  0.001 ( 1.085)	Loss 7.4134e-02 (7.5180e-02) 
2023-05-26 01:57:42.762837: train Epoch: [72][122/129]	Time  2.695 ( 2.064)	Data  1.736 ( 1.090)	Loss 5.3872e-02 (7.5007e-02) 
2023-05-26 01:57:43.727397: train Epoch: [72][123/129]	Time  0.965 ( 2.055)	Data  0.001 ( 1.082)	Loss 8.8527e-02 (7.5116e-02) 
2023-05-26 01:57:46.426509: train Epoch: [72][124/129]	Time  2.699 ( 2.060)	Data  1.742 ( 1.087)	Loss 5.8595e-02 (7.4984e-02) 
2023-05-26 01:57:47.389118: train Epoch: [72][125/129]	Time  0.963 ( 2.051)	Data  0.001 ( 1.078)	Loss 5.3221e-02 (7.4811e-02) 
2023-05-26 01:57:50.114534: train Epoch: [72][126/129]	Time  2.725 ( 2.057)	Data  1.764 ( 1.084)	Loss 8.9351e-02 (7.4926e-02) 
2023-05-26 01:57:51.072726: train Epoch: [72][127/129]	Time  0.958 ( 2.048)	Data  0.001 ( 1.075)	Loss 9.4169e-02 (7.5076e-02) 
2023-05-26 01:57:52.618399: train Epoch: [72][128/129]	Time  1.546 ( 2.044)	Data  0.589 ( 1.072)	Loss 6.9124e-02 (7.5030e-02) 
2023-05-26 01:57:52.656094: Train Epoch done in 263.73498408199885 s 
2023-05-26 01:57:55.093684: val Epoch: [72][ 0/72]	Time  1.690 ( 1.690)	Data  1.511 ( 1.511)	Loss 3.0487e-01 (3.0487e-01) 
2023-05-26 01:57:55.211418: val Epoch: [72][ 1/72]	Time  0.118 ( 0.904)	Data  0.001 ( 0.756)	Loss 1.2552e-01 (2.1519e-01) 
2023-05-26 01:57:56.286958: val Epoch: [72][ 2/72]	Time  1.076 ( 0.961)	Data  0.956 ( 0.823)	Loss 3.3792e-02 (1.5473e-01) 
2023-05-26 01:57:56.404945: val Epoch: [72][ 3/72]	Time  0.118 ( 0.750)	Data  0.001 ( 0.617)	Loss 2.7683e-01 (1.8525e-01) 
2023-05-26 01:57:57.528085: val Epoch: [72][ 4/72]	Time  1.123 ( 0.825)	Data  1.002 ( 0.694)	Loss 4.7938e-02 (1.5779e-01) 
2023-05-26 01:57:57.645688: val Epoch: [72][ 5/72]	Time  0.118 ( 0.707)	Data  0.001 ( 0.578)	Loss 5.1182e-02 (1.4002e-01) 
2023-05-26 01:57:58.793885: val Epoch: [72][ 6/72]	Time  1.148 ( 0.770)	Data  1.027 ( 0.643)	Loss 5.9995e-02 (1.2859e-01) 
2023-05-26 01:57:58.911232: val Epoch: [72][ 7/72]	Time  0.117 ( 0.688)	Data  0.001 ( 0.562)	Loss 2.3288e-01 (1.4163e-01) 
2023-05-26 01:58:00.063464: val Epoch: [72][ 8/72]	Time  1.152 ( 0.740)	Data  1.025 ( 0.614)	Loss 1.5727e-01 (1.4336e-01) 
2023-05-26 01:58:00.181850: val Epoch: [72][ 9/72]	Time  0.118 ( 0.678)	Data  0.001 ( 0.552)	Loss 1.8554e-01 (1.4758e-01) 
2023-05-26 01:58:01.303494: val Epoch: [72][10/72]	Time  1.122 ( 0.718)	Data  0.998 ( 0.593)	Loss 4.2613e-01 (1.7290e-01) 
2023-05-26 01:58:01.421004: val Epoch: [72][11/72]	Time  0.118 ( 0.668)	Data  0.000 ( 0.544)	Loss 4.4796e-02 (1.6223e-01) 
2023-05-26 01:58:02.599686: val Epoch: [72][12/72]	Time  1.179 ( 0.707)	Data  1.058 ( 0.583)	Loss 1.2757e-01 (1.5956e-01) 
2023-05-26 01:58:02.717755: val Epoch: [72][13/72]	Time  0.118 ( 0.665)	Data  0.000 ( 0.542)	Loss 6.5107e-02 (1.5281e-01) 
2023-05-26 01:58:03.873638: val Epoch: [72][14/72]	Time  1.156 ( 0.698)	Data  1.038 ( 0.575)	Loss 1.8035e-01 (1.5465e-01) 
2023-05-26 01:58:03.991762: val Epoch: [72][15/72]	Time  0.118 ( 0.662)	Data  0.000 ( 0.539)	Loss 5.1246e-02 (1.4819e-01) 
2023-05-26 01:58:05.153850: val Epoch: [72][16/72]	Time  1.162 ( 0.691)	Data  1.043 ( 0.568)	Loss 9.5126e-02 (1.4507e-01) 
2023-05-26 01:58:05.274604: val Epoch: [72][17/72]	Time  0.121 ( 0.660)	Data  0.000 ( 0.537)	Loss 3.8711e-02 (1.3916e-01) 
2023-05-26 01:58:06.390584: val Epoch: [72][18/72]	Time  1.116 ( 0.684)	Data  0.993 ( 0.561)	Loss 5.6619e-02 (1.3481e-01) 
2023-05-26 01:58:06.512553: val Epoch: [72][19/72]	Time  0.122 ( 0.655)	Data  0.001 ( 0.533)	Loss 2.2896e-01 (1.3952e-01) 
2023-05-26 01:58:07.633830: val Epoch: [72][20/72]	Time  1.121 ( 0.678)	Data  1.004 ( 0.555)	Loss 1.8471e-01 (1.4167e-01) 
2023-05-26 01:58:07.751225: val Epoch: [72][21/72]	Time  0.117 ( 0.652)	Data  0.000 ( 0.530)	Loss 8.2696e-02 (1.3899e-01) 
2023-05-26 01:58:09.034992: val Epoch: [72][22/72]	Time  1.284 ( 0.680)	Data  1.152 ( 0.557)	Loss 1.0426e-01 (1.3748e-01) 
2023-05-26 01:58:09.169467: val Epoch: [72][23/72]	Time  0.134 ( 0.657)	Data  0.001 ( 0.534)	Loss 2.7783e-01 (1.4333e-01) 
2023-05-26 01:58:10.432491: val Epoch: [72][24/72]	Time  1.263 ( 0.681)	Data  1.136 ( 0.558)	Loss 7.0954e-02 (1.4043e-01) 
2023-05-26 01:58:10.561682: val Epoch: [72][25/72]	Time  0.129 ( 0.660)	Data  0.001 ( 0.537)	Loss 7.9557e-02 (1.3809e-01) 
2023-05-26 01:58:11.767673: val Epoch: [72][26/72]	Time  1.206 ( 0.680)	Data  1.077 ( 0.557)	Loss 5.4260e-02 (1.3499e-01) 
2023-05-26 01:58:11.902612: val Epoch: [72][27/72]	Time  0.135 ( 0.661)	Data  0.001 ( 0.537)	Loss 1.0867e-01 (1.3405e-01) 
2023-05-26 01:58:13.123845: val Epoch: [72][28/72]	Time  1.221 ( 0.680)	Data  1.091 ( 0.556)	Loss 4.0072e-02 (1.3081e-01) 
2023-05-26 01:58:13.254194: val Epoch: [72][29/72]	Time  0.130 ( 0.662)	Data  0.001 ( 0.537)	Loss 1.6378e-01 (1.3191e-01) 
2023-05-26 01:58:14.525218: val Epoch: [72][30/72]	Time  1.271 ( 0.681)	Data  1.131 ( 0.556)	Loss 7.4624e-02 (1.3006e-01) 
2023-05-26 01:58:14.667982: val Epoch: [72][31/72]	Time  0.143 ( 0.665)	Data  0.001 ( 0.539)	Loss 9.0605e-02 (1.2883e-01) 
2023-05-26 01:58:15.867960: val Epoch: [72][32/72]	Time  1.200 ( 0.681)	Data  1.073 ( 0.555)	Loss 9.2893e-02 (1.2774e-01) 
2023-05-26 01:58:15.995899: val Epoch: [72][33/72]	Time  0.128 ( 0.664)	Data  0.001 ( 0.539)	Loss 4.8185e-02 (1.2540e-01) 
2023-05-26 01:58:17.186366: val Epoch: [72][34/72]	Time  1.190 ( 0.680)	Data  1.058 ( 0.554)	Loss 7.0011e-02 (1.2381e-01) 
2023-05-26 01:58:17.318882: val Epoch: [72][35/72]	Time  0.133 ( 0.664)	Data  0.001 ( 0.538)	Loss 4.9931e-02 (1.2176e-01) 
2023-05-26 01:58:18.432722: val Epoch: [72][36/72]	Time  1.114 ( 0.676)	Data  0.991 ( 0.551)	Loss 6.4636e-02 (1.2022e-01) 
2023-05-26 01:58:18.565364: val Epoch: [72][37/72]	Time  0.133 ( 0.662)	Data  0.001 ( 0.536)	Loss 8.9980e-02 (1.1942e-01) 
2023-05-26 01:58:19.763898: val Epoch: [72][38/72]	Time  1.199 ( 0.676)	Data  1.062 ( 0.550)	Loss 1.3565e-01 (1.1984e-01) 
2023-05-26 01:58:19.904526: val Epoch: [72][39/72]	Time  0.141 ( 0.663)	Data  0.001 ( 0.536)	Loss 4.8705e-02 (1.1806e-01) 
2023-05-26 01:58:21.052715: val Epoch: [72][40/72]	Time  1.148 ( 0.674)	Data  1.011 ( 0.548)	Loss 6.0546e-02 (1.1666e-01) 
2023-05-26 01:58:21.201173: val Epoch: [72][41/72]	Time  0.148 ( 0.662)	Data  0.001 ( 0.535)	Loss 8.0541e-02 (1.1580e-01) 
2023-05-26 01:58:22.444174: val Epoch: [72][42/72]	Time  1.243 ( 0.675)	Data  1.115 ( 0.548)	Loss 3.2122e-01 (1.2058e-01) 
2023-05-26 01:58:22.573336: val Epoch: [72][43/72]	Time  0.129 ( 0.663)	Data  0.001 ( 0.536)	Loss 5.1702e-02 (1.1901e-01) 
2023-05-26 01:58:23.827971: val Epoch: [72][44/72]	Time  1.255 ( 0.676)	Data  1.126 ( 0.549)	Loss 2.7209e-01 (1.2241e-01) 
2023-05-26 01:58:23.955581: val Epoch: [72][45/72]	Time  0.128 ( 0.664)	Data  0.001 ( 0.537)	Loss 7.5130e-02 (1.2138e-01) 
2023-05-26 01:58:25.134234: val Epoch: [72][46/72]	Time  1.179 ( 0.675)	Data  1.044 ( 0.548)	Loss 1.0560e-01 (1.2105e-01) 
2023-05-26 01:58:25.262896: val Epoch: [72][47/72]	Time  0.129 ( 0.664)	Data  0.001 ( 0.536)	Loss 3.6785e-02 (1.1929e-01) 
2023-05-26 01:58:26.507537: val Epoch: [72][48/72]	Time  1.245 ( 0.676)	Data  1.116 ( 0.548)	Loss 9.3737e-02 (1.1877e-01) 
2023-05-26 01:58:26.643364: val Epoch: [72][49/72]	Time  0.136 ( 0.665)	Data  0.001 ( 0.537)	Loss 3.5341e-02 (1.1710e-01) 
2023-05-26 01:58:27.866911: val Epoch: [72][50/72]	Time  1.224 ( 0.676)	Data  1.096 ( 0.548)	Loss 3.3872e-01 (1.2145e-01) 
2023-05-26 01:58:28.023041: val Epoch: [72][51/72]	Time  0.156 ( 0.666)	Data  0.001 ( 0.538)	Loss 4.0158e-02 (1.1988e-01) 
2023-05-26 01:58:29.261766: val Epoch: [72][52/72]	Time  1.239 ( 0.677)	Data  1.111 ( 0.548)	Loss 4.6804e-02 (1.1851e-01) 
2023-05-26 01:58:29.392161: val Epoch: [72][53/72]	Time  0.130 ( 0.666)	Data  0.001 ( 0.538)	Loss 1.3378e-01 (1.1879e-01) 
2023-05-26 01:58:30.585416: val Epoch: [72][54/72]	Time  1.193 ( 0.676)	Data  1.066 ( 0.548)	Loss 7.7170e-02 (1.1803e-01) 
2023-05-26 01:58:30.713817: val Epoch: [72][55/72]	Time  0.128 ( 0.666)	Data  0.001 ( 0.538)	Loss 4.2700e-02 (1.1669e-01) 
2023-05-26 01:58:31.937534: val Epoch: [72][56/72]	Time  1.224 ( 0.676)	Data  1.097 ( 0.548)	Loss 7.6822e-02 (1.1599e-01) 
2023-05-26 01:58:32.064544: val Epoch: [72][57/72]	Time  0.127 ( 0.667)	Data  0.001 ( 0.538)	Loss 6.1353e-02 (1.1505e-01) 
2023-05-26 01:58:33.317176: val Epoch: [72][58/72]	Time  1.253 ( 0.676)	Data  1.126 ( 0.548)	Loss 3.6733e-01 (1.1932e-01) 
2023-05-26 01:58:33.444635: val Epoch: [72][59/72]	Time  0.127 ( 0.667)	Data  0.001 ( 0.539)	Loss 3.7491e-02 (1.1796e-01) 
2023-05-26 01:58:34.677438: val Epoch: [72][60/72]	Time  1.233 ( 0.677)	Data  1.095 ( 0.548)	Loss 5.2173e-02 (1.1688e-01) 
2023-05-26 01:58:34.811724: val Epoch: [72][61/72]	Time  0.134 ( 0.668)	Data  0.001 ( 0.539)	Loss 1.8123e-01 (1.1792e-01) 
2023-05-26 01:58:36.035260: val Epoch: [72][62/72]	Time  1.224 ( 0.677)	Data  1.083 ( 0.548)	Loss 5.1492e-02 (1.1686e-01) 
2023-05-26 01:58:36.161108: val Epoch: [72][63/72]	Time  0.126 ( 0.668)	Data  0.001 ( 0.540)	Loss 3.1730e-01 (1.1999e-01) 
2023-05-26 01:58:37.337182: val Epoch: [72][64/72]	Time  1.176 ( 0.676)	Data  1.049 ( 0.547)	Loss 5.7878e-02 (1.1904e-01) 
2023-05-26 01:58:37.464005: val Epoch: [72][65/72]	Time  0.127 ( 0.668)	Data  0.001 ( 0.539)	Loss 3.7768e-01 (1.2296e-01) 
2023-05-26 01:58:38.654476: val Epoch: [72][66/72]	Time  1.190 ( 0.675)	Data  1.062 ( 0.547)	Loss 9.3355e-02 (1.2252e-01) 
2023-05-26 01:58:38.782607: val Epoch: [72][67/72]	Time  0.128 ( 0.667)	Data  0.001 ( 0.539)	Loss 4.7666e-02 (1.2142e-01) 
2023-05-26 01:58:40.049236: val Epoch: [72][68/72]	Time  1.267 ( 0.676)	Data  1.139 ( 0.548)	Loss 5.9547e-02 (1.2052e-01) 
2023-05-26 01:58:40.176550: val Epoch: [72][69/72]	Time  0.127 ( 0.668)	Data  0.001 ( 0.540)	Loss 5.8164e-02 (1.1963e-01) 
2023-05-26 01:58:41.303168: val Epoch: [72][70/72]	Time  1.127 ( 0.675)	Data  1.000 ( 0.546)	Loss 3.9708e-02 (1.1850e-01) 
2023-05-26 01:58:41.431098: val Epoch: [72][71/72]	Time  0.128 ( 0.667)	Data  0.001 ( 0.539)	Loss 1.1621e-01 (1.1847e-01) 
2023-05-26 01:58:41.646568: Epoch 72 :Val : ['ET : 0.7563967704772949', 'TC : 0.8036582469940186', 'WT : 0.8789709806442261'] 
2023-05-26 01:58:41.651868: Epoch 72 :Val : ['ET : 0.7563967704772949', 'TC : 0.8036582469940186', 'WT : 0.8789709806442261'] 
2023-05-26 01:58:41.654674: Val epoch done in 48.99858398000288 s 
2023-05-26 01:58:41.660534: Batches per epoch:  129 
2023-05-26 01:58:47.174597: train Epoch: [73][  0/129]	Time  5.514 ( 5.514)	Data  4.454 ( 4.454)	Loss 1.3116e-01 (1.3116e-01) 
2023-05-26 01:58:48.153596: train Epoch: [73][  1/129]	Time  0.979 ( 3.246)	Data  0.001 ( 2.228)	Loss 6.9765e-02 (1.0046e-01) 
2023-05-26 01:58:51.165511: train Epoch: [73][  2/129]	Time  3.012 ( 3.168)	Data  2.042 ( 2.166)	Loss 9.0168e-02 (9.7030e-02) 
2023-05-26 01:58:52.143181: train Epoch: [73][  3/129]	Time  0.978 ( 2.621)	Data  0.001 ( 1.625)	Loss 1.1264e-01 (1.0093e-01) 
2023-05-26 01:58:55.241688: train Epoch: [73][  4/129]	Time  3.098 ( 2.716)	Data  2.131 ( 1.726)	Loss 8.1455e-02 (9.7038e-02) 
2023-05-26 01:58:56.210061: train Epoch: [73][  5/129]	Time  0.968 ( 2.425)	Data  0.001 ( 1.438)	Loss 9.2348e-02 (9.6256e-02) 
2023-05-26 01:58:59.278494: train Epoch: [73][  6/129]	Time  3.068 ( 2.517)	Data  2.104 ( 1.534)	Loss 1.0884e-01 (9.8053e-02) 
2023-05-26 01:59:00.251768: train Epoch: [73][  7/129]	Time  0.973 ( 2.324)	Data  0.001 ( 1.342)	Loss 1.2272e-01 (1.0114e-01) 
2023-05-26 01:59:03.412654: train Epoch: [73][  8/129]	Time  3.161 ( 2.417)	Data  2.148 ( 1.432)	Loss 8.0915e-02 (9.8889e-02) 
2023-05-26 01:59:04.384527: train Epoch: [73][  9/129]	Time  0.972 ( 2.272)	Data  0.001 ( 1.289)	Loss 5.9688e-02 (9.4969e-02) 
2023-05-26 01:59:07.595109: train Epoch: [73][ 10/129]	Time  3.211 ( 2.358)	Data  2.242 ( 1.375)	Loss 6.1750e-02 (9.1949e-02) 
2023-05-26 01:59:08.570986: train Epoch: [73][ 11/129]	Time  0.976 ( 2.242)	Data  0.001 ( 1.261)	Loss 7.6628e-02 (9.0672e-02) 
2023-05-26 01:59:11.684917: train Epoch: [73][ 12/129]	Time  3.114 ( 2.310)	Data  2.149 ( 1.329)	Loss 8.8408e-02 (9.0498e-02) 
2023-05-26 01:59:12.654894: train Epoch: [73][ 13/129]	Time  0.970 ( 2.214)	Data  0.001 ( 1.234)	Loss 1.1899e-01 (9.2533e-02) 
2023-05-26 01:59:15.769093: train Epoch: [73][ 14/129]	Time  3.114 ( 2.274)	Data  2.148 ( 1.295)	Loss 6.5358e-02 (9.0721e-02) 
2023-05-26 01:59:16.741882: train Epoch: [73][ 15/129]	Time  0.973 ( 2.193)	Data  0.001 ( 1.214)	Loss 6.7361e-02 (8.9261e-02) 
2023-05-26 01:59:19.806359: train Epoch: [73][ 16/129]	Time  3.064 ( 2.244)	Data  2.097 ( 1.266)	Loss 7.2931e-02 (8.8301e-02) 
2023-05-26 01:59:20.775348: train Epoch: [73][ 17/129]	Time  0.969 ( 2.173)	Data  0.001 ( 1.196)	Loss 1.0263e-01 (8.9097e-02) 
2023-05-26 01:59:23.954926: train Epoch: [73][ 18/129]	Time  3.180 ( 2.226)	Data  2.212 ( 1.249)	Loss 6.3878e-02 (8.7770e-02) 
2023-05-26 01:59:24.927815: train Epoch: [73][ 19/129]	Time  0.973 ( 2.163)	Data  0.001 ( 1.187)	Loss 6.0251e-02 (8.6394e-02) 
2023-05-26 01:59:28.096408: train Epoch: [73][ 20/129]	Time  3.169 ( 2.211)	Data  2.196 ( 1.235)	Loss 1.1432e-01 (8.7723e-02) 
2023-05-26 01:59:29.069745: train Epoch: [73][ 21/129]	Time  0.973 ( 2.155)	Data  0.002 ( 1.179)	Loss 7.6169e-02 (8.7198e-02) 
2023-05-26 01:59:32.334931: train Epoch: [73][ 22/129]	Time  3.265 ( 2.203)	Data  2.290 ( 1.227)	Loss 9.5874e-02 (8.7575e-02) 
2023-05-26 01:59:33.309330: train Epoch: [73][ 23/129]	Time  0.974 ( 2.152)	Data  0.001 ( 1.176)	Loss 6.1543e-02 (8.6491e-02) 
2023-05-26 01:59:36.539900: train Epoch: [73][ 24/129]	Time  3.231 ( 2.195)	Data  2.252 ( 1.219)	Loss 9.2793e-02 (8.6743e-02) 
2023-05-26 01:59:37.537053: train Epoch: [73][ 25/129]	Time  0.997 ( 2.149)	Data  0.002 ( 1.172)	Loss 7.2530e-02 (8.6196e-02) 
2023-05-26 01:59:40.576107: train Epoch: [73][ 26/129]	Time  3.039 ( 2.182)	Data  2.070 ( 1.206)	Loss 3.4237e-02 (8.4272e-02) 
2023-05-26 01:59:41.554121: train Epoch: [73][ 27/129]	Time  0.978 ( 2.139)	Data  0.001 ( 1.163)	Loss 4.8317e-02 (8.2988e-02) 
2023-05-26 01:59:44.605828: train Epoch: [73][ 28/129]	Time  3.052 ( 2.171)	Data  2.085 ( 1.194)	Loss 8.4291e-02 (8.3033e-02) 
2023-05-26 01:59:45.580121: train Epoch: [73][ 29/129]	Time  0.974 ( 2.131)	Data  0.001 ( 1.155)	Loss 4.4278e-02 (8.1741e-02) 
2023-05-26 01:59:48.715880: train Epoch: [73][ 30/129]	Time  3.136 ( 2.163)	Data  2.167 ( 1.187)	Loss 6.8319e-02 (8.1308e-02) 
2023-05-26 01:59:49.686421: train Epoch: [73][ 31/129]	Time  0.971 ( 2.126)	Data  0.001 ( 1.150)	Loss 8.9165e-02 (8.1553e-02) 
2023-05-26 01:59:52.825181: train Epoch: [73][ 32/129]	Time  3.139 ( 2.156)	Data  2.156 ( 1.181)	Loss 9.0983e-02 (8.1839e-02) 
2023-05-26 01:59:53.802611: train Epoch: [73][ 33/129]	Time  0.977 ( 2.122)	Data  0.001 ( 1.146)	Loss 5.1810e-02 (8.0956e-02) 
2023-05-26 01:59:56.867840: train Epoch: [73][ 34/129]	Time  3.065 ( 2.149)	Data  2.099 ( 1.173)	Loss 7.3450e-02 (8.0741e-02) 
2023-05-26 01:59:57.837027: train Epoch: [73][ 35/129]	Time  0.969 ( 2.116)	Data  0.001 ( 1.141)	Loss 6.3967e-02 (8.0275e-02) 
2023-05-26 02:00:00.979745: train Epoch: [73][ 36/129]	Time  3.143 ( 2.144)	Data  2.169 ( 1.168)	Loss 9.1573e-02 (8.0581e-02) 
2023-05-26 02:00:01.966612: train Epoch: [73][ 37/129]	Time  0.987 ( 2.113)	Data  0.002 ( 1.138)	Loss 6.4683e-02 (8.0162e-02) 
2023-05-26 02:00:05.061126: train Epoch: [73][ 38/129]	Time  3.094 ( 2.138)	Data  2.123 ( 1.163)	Loss 5.8254e-02 (7.9601e-02) 
2023-05-26 02:00:06.031486: train Epoch: [73][ 39/129]	Time  0.970 ( 2.109)	Data  0.001 ( 1.134)	Loss 8.5227e-02 (7.9741e-02) 
2023-05-26 02:00:09.120434: train Epoch: [73][ 40/129]	Time  3.089 ( 2.133)	Data  2.117 ( 1.158)	Loss 8.0892e-02 (7.9769e-02) 
2023-05-26 02:00:10.095423: train Epoch: [73][ 41/129]	Time  0.975 ( 2.106)	Data  0.001 ( 1.130)	Loss 1.1216e-01 (8.0541e-02) 
2023-05-26 02:00:13.121939: train Epoch: [73][ 42/129]	Time  3.026 ( 2.127)	Data  2.048 ( 1.152)	Loss 5.3959e-02 (7.9922e-02) 
2023-05-26 02:00:14.109420: train Epoch: [73][ 43/129]	Time  0.988 ( 2.101)	Data  0.001 ( 1.126)	Loss 6.8661e-02 (7.9667e-02) 
2023-05-26 02:00:17.145174: train Epoch: [73][ 44/129]	Time  3.036 ( 2.122)	Data  2.065 ( 1.146)	Loss 6.4223e-02 (7.9323e-02) 
2023-05-26 02:00:18.116496: train Epoch: [73][ 45/129]	Time  0.971 ( 2.097)	Data  0.001 ( 1.122)	Loss 5.6454e-02 (7.8826e-02) 
2023-05-26 02:00:21.173820: train Epoch: [73][ 46/129]	Time  3.057 ( 2.117)	Data  2.094 ( 1.142)	Loss 9.5800e-02 (7.9187e-02) 
2023-05-26 02:00:22.138659: train Epoch: [73][ 47/129]	Time  0.965 ( 2.093)	Data  0.001 ( 1.119)	Loss 9.0943e-02 (7.9432e-02) 
2023-05-26 02:00:25.398729: train Epoch: [73][ 48/129]	Time  3.260 ( 2.117)	Data  2.278 ( 1.142)	Loss 8.3165e-02 (7.9508e-02) 
2023-05-26 02:00:26.368417: train Epoch: [73][ 49/129]	Time  0.970 ( 2.094)	Data  0.001 ( 1.119)	Loss 5.7061e-02 (7.9059e-02) 
2023-05-26 02:00:29.524179: train Epoch: [73][ 50/129]	Time  3.156 ( 2.115)	Data  2.183 ( 1.140)	Loss 9.2869e-02 (7.9330e-02) 
2023-05-26 02:00:30.498575: train Epoch: [73][ 51/129]	Time  0.974 ( 2.093)	Data  0.001 ( 1.118)	Loss 4.3462e-02 (7.8640e-02) 
2023-05-26 02:00:33.591726: train Epoch: [73][ 52/129]	Time  3.093 ( 2.112)	Data  2.114 ( 1.137)	Loss 1.1455e-01 (7.9318e-02) 
2023-05-26 02:00:34.573327: train Epoch: [73][ 53/129]	Time  0.982 ( 2.091)	Data  0.001 ( 1.116)	Loss 5.4920e-02 (7.8866e-02) 
2023-05-26 02:00:37.682325: train Epoch: [73][ 54/129]	Time  3.109 ( 2.109)	Data  2.145 ( 1.135)	Loss 6.4667e-02 (7.8608e-02) 
2023-05-26 02:00:38.657573: train Epoch: [73][ 55/129]	Time  0.975 ( 2.089)	Data  0.001 ( 1.115)	Loss 6.9266e-02 (7.8441e-02) 
2023-05-26 02:00:41.725509: train Epoch: [73][ 56/129]	Time  3.068 ( 2.106)	Data  2.110 ( 1.132)	Loss 7.3417e-02 (7.8353e-02) 
2023-05-26 02:00:42.690826: train Epoch: [73][ 57/129]	Time  0.965 ( 2.087)	Data  0.001 ( 1.112)	Loss 1.0151e-01 (7.8752e-02) 
2023-05-26 02:00:45.736706: train Epoch: [73][ 58/129]	Time  3.046 ( 2.103)	Data  2.081 ( 1.129)	Loss 6.8872e-02 (7.8585e-02) 
2023-05-26 02:00:46.705773: train Epoch: [73][ 59/129]	Time  0.969 ( 2.084)	Data  0.001 ( 1.110)	Loss 7.6034e-02 (7.8542e-02) 
2023-05-26 02:00:49.779907: train Epoch: [73][ 60/129]	Time  3.074 ( 2.100)	Data  2.115 ( 1.127)	Loss 7.6354e-02 (7.8506e-02) 
2023-05-26 02:00:50.758503: train Epoch: [73][ 61/129]	Time  0.979 ( 2.082)	Data  0.001 ( 1.108)	Loss 7.2571e-02 (7.8411e-02) 
2023-05-26 02:00:53.808043: train Epoch: [73][ 62/129]	Time  3.050 ( 2.098)	Data  2.084 ( 1.124)	Loss 6.6655e-02 (7.8224e-02) 
2023-05-26 02:00:54.777858: train Epoch: [73][ 63/129]	Time  0.970 ( 2.080)	Data  0.001 ( 1.106)	Loss 5.0080e-02 (7.7784e-02) 
2023-05-26 02:00:57.779805: train Epoch: [73][ 64/129]	Time  3.002 ( 2.094)	Data  2.035 ( 1.121)	Loss 6.3211e-02 (7.7560e-02) 
2023-05-26 02:00:58.761919: train Epoch: [73][ 65/129]	Time  0.982 ( 2.077)	Data  0.002 ( 1.104)	Loss 8.3050e-02 (7.7643e-02) 
2023-05-26 02:01:01.984956: train Epoch: [73][ 66/129]	Time  3.223 ( 2.094)	Data  2.246 ( 1.121)	Loss 1.0243e-01 (7.8013e-02) 
2023-05-26 02:01:02.956960: train Epoch: [73][ 67/129]	Time  0.972 ( 2.078)	Data  0.001 ( 1.104)	Loss 5.8710e-02 (7.7729e-02) 
2023-05-26 02:01:05.999774: train Epoch: [73][ 68/129]	Time  3.043 ( 2.092)	Data  2.068 ( 1.118)	Loss 5.0880e-02 (7.7340e-02) 
2023-05-26 02:01:06.985528: train Epoch: [73][ 69/129]	Time  0.986 ( 2.076)	Data  0.002 ( 1.102)	Loss 1.0066e-01 (7.7673e-02) 
2023-05-26 02:01:10.078545: train Epoch: [73][ 70/129]	Time  3.093 ( 2.090)	Data  2.134 ( 1.117)	Loss 1.0159e-01 (7.8010e-02) 
2023-05-26 02:01:11.049993: train Epoch: [73][ 71/129]	Time  0.971 ( 2.075)	Data  0.001 ( 1.101)	Loss 6.6093e-02 (7.7845e-02) 
2023-05-26 02:01:14.146290: train Epoch: [73][ 72/129]	Time  3.096 ( 2.089)	Data  2.124 ( 1.115)	Loss 5.2573e-02 (7.7499e-02) 
2023-05-26 02:01:15.119624: train Epoch: [73][ 73/129]	Time  0.973 ( 2.074)	Data  0.002 ( 1.100)	Loss 4.9502e-02 (7.7120e-02) 
2023-05-26 02:01:18.203849: train Epoch: [73][ 74/129]	Time  3.084 ( 2.087)	Data  2.119 ( 1.114)	Loss 7.4483e-02 (7.7085e-02) 
2023-05-26 02:01:19.175554: train Epoch: [73][ 75/129]	Time  0.972 ( 2.073)	Data  0.001 ( 1.099)	Loss 3.8870e-02 (7.6582e-02) 
2023-05-26 02:01:22.292936: train Epoch: [73][ 76/129]	Time  3.117 ( 2.086)	Data  2.150 ( 1.113)	Loss 4.6584e-02 (7.6193e-02) 
2023-05-26 02:01:23.263194: train Epoch: [73][ 77/129]	Time  0.970 ( 2.072)	Data  0.001 ( 1.099)	Loss 5.8489e-02 (7.5966e-02) 
2023-05-26 02:01:26.193059: train Epoch: [73][ 78/129]	Time  2.930 ( 2.083)	Data  1.962 ( 1.110)	Loss 6.7676e-02 (7.5861e-02) 
2023-05-26 02:01:27.166405: train Epoch: [73][ 79/129]	Time  0.973 ( 2.069)	Data  0.001 ( 1.096)	Loss 6.2207e-02 (7.5690e-02) 
2023-05-26 02:01:30.252746: train Epoch: [73][ 80/129]	Time  3.086 ( 2.081)	Data  2.112 ( 1.108)	Loss 7.9821e-02 (7.5741e-02) 
2023-05-26 02:01:31.240846: train Epoch: [73][ 81/129]	Time  0.988 ( 2.068)	Data  0.001 ( 1.095)	Loss 8.7998e-02 (7.5891e-02) 
2023-05-26 02:01:34.393415: train Epoch: [73][ 82/129]	Time  3.153 ( 2.081)	Data  2.172 ( 1.108)	Loss 9.2609e-02 (7.6092e-02) 
2023-05-26 02:01:35.378233: train Epoch: [73][ 83/129]	Time  0.985 ( 2.068)	Data  0.001 ( 1.095)	Loss 5.6636e-02 (7.5860e-02) 
2023-05-26 02:01:38.556283: train Epoch: [73][ 84/129]	Time  3.178 ( 2.081)	Data  2.212 ( 1.108)	Loss 1.0730e-01 (7.6230e-02) 
2023-05-26 02:01:39.524868: train Epoch: [73][ 85/129]	Time  0.969 ( 2.068)	Data  0.001 ( 1.095)	Loss 6.1713e-02 (7.6061e-02) 
2023-05-26 02:01:42.562846: train Epoch: [73][ 86/129]	Time  3.038 ( 2.079)	Data  2.047 ( 1.106)	Loss 6.3184e-02 (7.5913e-02) 
2023-05-26 02:01:43.536827: train Epoch: [73][ 87/129]	Time  0.974 ( 2.067)	Data  0.001 ( 1.093)	Loss 6.1856e-02 (7.5754e-02) 
2023-05-26 02:01:46.662269: train Epoch: [73][ 88/129]	Time  3.125 ( 2.079)	Data  2.146 ( 1.105)	Loss 6.3741e-02 (7.5619e-02) 
2023-05-26 02:01:47.630948: train Epoch: [73][ 89/129]	Time  0.969 ( 2.066)	Data  0.001 ( 1.093)	Loss 1.0004e-01 (7.5890e-02) 
2023-05-26 02:01:50.709381: train Epoch: [73][ 90/129]	Time  3.078 ( 2.077)	Data  2.106 ( 1.104)	Loss 5.0124e-02 (7.5607e-02) 
2023-05-26 02:01:51.680629: train Epoch: [73][ 91/129]	Time  0.971 ( 2.065)	Data  0.001 ( 1.092)	Loss 4.6409e-02 (7.5290e-02) 
2023-05-26 02:01:54.795296: train Epoch: [73][ 92/129]	Time  3.115 ( 2.077)	Data  2.132 ( 1.103)	Loss 5.8696e-02 (7.5111e-02) 
2023-05-26 02:01:55.767812: train Epoch: [73][ 93/129]	Time  0.973 ( 2.065)	Data  0.001 ( 1.091)	Loss 5.6013e-02 (7.4908e-02) 
2023-05-26 02:01:59.030396: train Epoch: [73][ 94/129]	Time  3.263 ( 2.078)	Data  2.271 ( 1.104)	Loss 5.6680e-02 (7.4716e-02) 
2023-05-26 02:02:00.018229: train Epoch: [73][ 95/129]	Time  0.988 ( 2.066)	Data  0.001 ( 1.092)	Loss 7.2004e-02 (7.4688e-02) 
2023-05-26 02:02:03.106488: train Epoch: [73][ 96/129]	Time  3.088 ( 2.077)	Data  2.119 ( 1.103)	Loss 7.1125e-02 (7.4651e-02) 
2023-05-26 02:02:04.078134: train Epoch: [73][ 97/129]	Time  0.972 ( 2.065)	Data  0.001 ( 1.092)	Loss 5.7105e-02 (7.4472e-02) 
2023-05-26 02:02:07.231019: train Epoch: [73][ 98/129]	Time  3.153 ( 2.076)	Data  2.186 ( 1.103)	Loss 6.5123e-02 (7.4378e-02) 
2023-05-26 02:02:08.204251: train Epoch: [73][ 99/129]	Time  0.973 ( 2.065)	Data  0.001 ( 1.092)	Loss 7.1413e-02 (7.4348e-02) 
2023-05-26 02:02:11.282612: train Epoch: [73][100/129]	Time  3.078 ( 2.075)	Data  2.116 ( 1.102)	Loss 8.7186e-02 (7.4475e-02) 
2023-05-26 02:02:12.263312: train Epoch: [73][101/129]	Time  0.981 ( 2.065)	Data  0.001 ( 1.091)	Loss 4.9600e-02 (7.4231e-02) 
2023-05-26 02:02:15.456759: train Epoch: [73][102/129]	Time  3.193 ( 2.076)	Data  2.215 ( 1.102)	Loss 1.0616e-01 (7.4541e-02) 
2023-05-26 02:02:16.438573: train Epoch: [73][103/129]	Time  0.982 ( 2.065)	Data  0.001 ( 1.091)	Loss 8.6922e-02 (7.4660e-02) 
2023-05-26 02:02:19.353407: train Epoch: [73][104/129]	Time  2.915 ( 2.073)	Data  1.934 ( 1.099)	Loss 4.1912e-02 (7.4348e-02) 
2023-05-26 02:02:20.324376: train Epoch: [73][105/129]	Time  0.971 ( 2.063)	Data  0.001 ( 1.089)	Loss 6.9274e-02 (7.4301e-02) 
2023-05-26 02:02:23.360820: train Epoch: [73][106/129]	Time  3.036 ( 2.072)	Data  2.073 ( 1.098)	Loss 7.1209e-02 (7.4272e-02) 
2023-05-26 02:02:24.341144: train Epoch: [73][107/129]	Time  0.980 ( 2.062)	Data  0.002 ( 1.088)	Loss 1.3438e-01 (7.4828e-02) 
2023-05-26 02:02:27.401661: train Epoch: [73][108/129]	Time  3.061 ( 2.071)	Data  2.079 ( 1.097)	Loss 5.2206e-02 (7.4621e-02) 
2023-05-26 02:02:28.373114: train Epoch: [73][109/129]	Time  0.971 ( 2.061)	Data  0.001 ( 1.087)	Loss 5.4971e-02 (7.4442e-02) 
2023-05-26 02:02:31.550999: train Epoch: [73][110/129]	Time  3.178 ( 2.071)	Data  2.203 ( 1.097)	Loss 5.8189e-02 (7.4296e-02) 
2023-05-26 02:02:32.535412: train Epoch: [73][111/129]	Time  0.984 ( 2.061)	Data  0.001 ( 1.087)	Loss 8.0527e-02 (7.4351e-02) 
2023-05-26 02:02:35.765987: train Epoch: [73][112/129]	Time  3.231 ( 2.072)	Data  2.264 ( 1.098)	Loss 7.3105e-02 (7.4340e-02) 
2023-05-26 02:02:36.747796: train Epoch: [73][113/129]	Time  0.982 ( 2.062)	Data  0.001 ( 1.088)	Loss 3.8277e-02 (7.4024e-02) 
2023-05-26 02:02:39.861399: train Epoch: [73][114/129]	Time  3.114 ( 2.071)	Data  2.148 ( 1.097)	Loss 6.2030e-02 (7.3920e-02) 
2023-05-26 02:02:40.832769: train Epoch: [73][115/129]	Time  0.971 ( 2.062)	Data  0.001 ( 1.088)	Loss 8.8945e-02 (7.4049e-02) 
2023-05-26 02:02:43.898488: train Epoch: [73][116/129]	Time  3.066 ( 2.070)	Data  2.097 ( 1.097)	Loss 7.2384e-02 (7.4035e-02) 
2023-05-26 02:02:44.874172: train Epoch: [73][117/129]	Time  0.976 ( 2.061)	Data  0.001 ( 1.087)	Loss 4.8783e-02 (7.3821e-02) 
2023-05-26 02:02:48.054277: train Epoch: [73][118/129]	Time  3.180 ( 2.071)	Data  2.226 ( 1.097)	Loss 1.0125e-01 (7.4051e-02) 
2023-05-26 02:02:49.025486: train Epoch: [73][119/129]	Time  0.971 ( 2.061)	Data  0.001 ( 1.088)	Loss 3.6185e-02 (7.3736e-02) 
2023-05-26 02:02:52.164540: train Epoch: [73][120/129]	Time  3.139 ( 2.070)	Data  2.173 ( 1.097)	Loss 6.6710e-02 (7.3678e-02) 
2023-05-26 02:02:53.146031: train Epoch: [73][121/129]	Time  0.981 ( 2.061)	Data  0.001 ( 1.088)	Loss 6.4798e-02 (7.3605e-02) 
2023-05-26 02:02:56.269826: train Epoch: [73][122/129]	Time  3.124 ( 2.070)	Data  2.159 ( 1.097)	Loss 5.0659e-02 (7.3418e-02) 
2023-05-26 02:02:57.241694: train Epoch: [73][123/129]	Time  0.972 ( 2.061)	Data  0.001 ( 1.088)	Loss 6.3789e-02 (7.3341e-02) 
2023-05-26 02:03:00.285554: train Epoch: [73][124/129]	Time  3.044 ( 2.069)	Data  2.069 ( 1.096)	Loss 7.3786e-02 (7.3344e-02) 
2023-05-26 02:03:01.261525: train Epoch: [73][125/129]	Time  0.976 ( 2.060)	Data  0.001 ( 1.087)	Loss 7.3957e-02 (7.3349e-02) 
2023-05-26 02:03:04.351451: train Epoch: [73][126/129]	Time  3.090 ( 2.068)	Data  2.109 ( 1.095)	Loss 8.3084e-02 (7.3426e-02) 
2023-05-26 02:03:05.318781: train Epoch: [73][127/129]	Time  0.967 ( 2.060)	Data  0.001 ( 1.086)	Loss 6.4191e-02 (7.3354e-02) 
2023-05-26 02:03:07.268923: train Epoch: [73][128/129]	Time  1.950 ( 2.059)	Data  0.980 ( 1.086)	Loss 6.2263e-02 (7.3268e-02) 
2023-05-26 02:03:07.352452: Train Epoch done in 265.69198379999943 s 
2023-05-26 02:03:10.204111: val Epoch: [73][ 0/72]	Time  1.948 ( 1.948)	Data  1.699 ( 1.699)	Loss 8.2486e-02 (8.2486e-02) 
2023-05-26 02:03:10.343140: val Epoch: [73][ 1/72]	Time  0.139 ( 1.044)	Data  0.002 ( 0.851)	Loss 6.8121e-02 (7.5303e-02) 
2023-05-26 02:03:11.386944: val Epoch: [73][ 2/72]	Time  1.044 ( 1.044)	Data  0.914 ( 0.872)	Loss 7.0682e-02 (7.3763e-02) 
2023-05-26 02:03:11.516240: val Epoch: [73][ 3/72]	Time  0.129 ( 0.815)	Data  0.001 ( 0.654)	Loss 9.6989e-02 (7.9569e-02) 
2023-05-26 02:03:12.738076: val Epoch: [73][ 4/72]	Time  1.222 ( 0.896)	Data  1.094 ( 0.742)	Loss 1.3802e-01 (9.1260e-02) 
2023-05-26 02:03:12.866786: val Epoch: [73][ 5/72]	Time  0.129 ( 0.768)	Data  0.001 ( 0.619)	Loss 4.2079e-02 (8.3063e-02) 
2023-05-26 02:03:14.136498: val Epoch: [73][ 6/72]	Time  1.270 ( 0.840)	Data  1.121 ( 0.690)	Loss 4.6610e-02 (7.7855e-02) 
2023-05-26 02:03:14.274291: val Epoch: [73][ 7/72]	Time  0.138 ( 0.752)	Data  0.001 ( 0.604)	Loss 2.1868e-01 (9.5458e-02) 
2023-05-26 02:03:15.502318: val Epoch: [73][ 8/72]	Time  1.228 ( 0.805)	Data  1.082 ( 0.657)	Loss 8.3904e-02 (9.4174e-02) 
2023-05-26 02:03:15.642601: val Epoch: [73][ 9/72]	Time  0.140 ( 0.739)	Data  0.001 ( 0.592)	Loss 5.1354e-02 (8.9892e-02) 
2023-05-26 02:03:16.970633: val Epoch: [73][10/72]	Time  1.328 ( 0.792)	Data  1.189 ( 0.646)	Loss 1.3011e-01 (9.3548e-02) 
2023-05-26 02:03:17.105834: val Epoch: [73][11/72]	Time  0.135 ( 0.737)	Data  0.001 ( 0.592)	Loss 7.6755e-02 (9.2149e-02) 
2023-05-26 02:03:18.294930: val Epoch: [73][12/72]	Time  1.189 ( 0.772)	Data  1.063 ( 0.628)	Loss 4.9217e-02 (8.8847e-02) 
2023-05-26 02:03:18.423671: val Epoch: [73][13/72]	Time  0.129 ( 0.726)	Data  0.001 ( 0.584)	Loss 1.0005e-01 (8.9647e-02) 
2023-05-26 02:03:19.644636: val Epoch: [73][14/72]	Time  1.221 ( 0.759)	Data  1.093 ( 0.618)	Loss 3.7077e-02 (8.6142e-02) 
2023-05-26 02:03:19.774484: val Epoch: [73][15/72]	Time  0.130 ( 0.720)	Data  0.001 ( 0.579)	Loss 3.3919e-02 (8.2878e-02) 
2023-05-26 02:03:21.034082: val Epoch: [73][16/72]	Time  1.260 ( 0.752)	Data  1.115 ( 0.611)	Loss 5.4770e-02 (8.1225e-02) 
2023-05-26 02:03:21.165347: val Epoch: [73][17/72]	Time  0.131 ( 0.717)	Data  0.001 ( 0.577)	Loss 7.9218e-02 (8.1113e-02) 
2023-05-26 02:03:22.399029: val Epoch: [73][18/72]	Time  1.234 ( 0.744)	Data  1.102 ( 0.604)	Loss 3.4045e-02 (7.8636e-02) 
2023-05-26 02:03:22.534385: val Epoch: [73][19/72]	Time  0.135 ( 0.714)	Data  0.001 ( 0.574)	Loss 4.8267e-01 (9.8838e-02) 
2023-05-26 02:03:23.764935: val Epoch: [73][20/72]	Time  1.231 ( 0.739)	Data  1.092 ( 0.599)	Loss 3.0363e-02 (9.5577e-02) 
2023-05-26 02:03:23.894115: val Epoch: [73][21/72]	Time  0.129 ( 0.711)	Data  0.001 ( 0.572)	Loss 1.2826e-01 (9.7063e-02) 
2023-05-26 02:03:25.130756: val Epoch: [73][22/72]	Time  1.237 ( 0.734)	Data  1.104 ( 0.595)	Loss 5.7933e-02 (9.5361e-02) 
2023-05-26 02:03:25.266738: val Epoch: [73][23/72]	Time  0.136 ( 0.709)	Data  0.001 ( 0.570)	Loss 1.6383e-01 (9.8214e-02) 
2023-05-26 02:03:26.507128: val Epoch: [73][24/72]	Time  1.240 ( 0.730)	Data  1.101 ( 0.591)	Loss 6.2749e-02 (9.6795e-02) 
2023-05-26 02:03:26.652867: val Epoch: [73][25/72]	Time  0.146 ( 0.708)	Data  0.001 ( 0.568)	Loss 4.2874e-02 (9.4722e-02) 
2023-05-26 02:03:27.841417: val Epoch: [73][26/72]	Time  1.189 ( 0.725)	Data  1.054 ( 0.586)	Loss 1.1098e-01 (9.5324e-02) 
2023-05-26 02:03:28.003036: val Epoch: [73][27/72]	Time  0.162 ( 0.705)	Data  0.025 ( 0.566)	Loss 3.7687e-02 (9.3265e-02) 
2023-05-26 02:03:29.095218: val Epoch: [73][28/72]	Time  1.092 ( 0.719)	Data  0.965 ( 0.580)	Loss 3.9446e-02 (9.1409e-02) 
2023-05-26 02:03:29.345026: val Epoch: [73][29/72]	Time  0.250 ( 0.703)	Data  0.114 ( 0.565)	Loss 2.7491e-01 (9.7526e-02) 
2023-05-26 02:03:30.474293: val Epoch: [73][30/72]	Time  1.129 ( 0.717)	Data  0.994 ( 0.578)	Loss 3.4942e-02 (9.5507e-02) 
2023-05-26 02:03:30.682540: val Epoch: [73][31/72]	Time  0.208 ( 0.701)	Data  0.068 ( 0.563)	Loss 5.1374e-02 (9.4128e-02) 
2023-05-26 02:03:31.852579: val Epoch: [73][32/72]	Time  1.170 ( 0.715)	Data  1.028 ( 0.577)	Loss 4.5442e-02 (9.2653e-02) 
2023-05-26 02:03:32.045352: val Epoch: [73][33/72]	Time  0.193 ( 0.700)	Data  0.062 ( 0.561)	Loss 7.7834e-02 (9.2217e-02) 
2023-05-26 02:03:33.154322: val Epoch: [73][34/72]	Time  1.109 ( 0.711)	Data  0.981 ( 0.573)	Loss 1.4140e-01 (9.3622e-02) 
2023-05-26 02:03:33.386660: val Epoch: [73][35/72]	Time  0.232 ( 0.698)	Data  0.106 ( 0.560)	Loss 5.1880e-01 (1.0543e-01) 
2023-05-26 02:03:34.521777: val Epoch: [73][36/72]	Time  1.135 ( 0.710)	Data  1.007 ( 0.573)	Loss 6.0265e-02 (1.0421e-01) 
2023-05-26 02:03:34.748938: val Epoch: [73][37/72]	Time  0.227 ( 0.697)	Data  0.100 ( 0.560)	Loss 3.1886e-01 (1.0986e-01) 
2023-05-26 02:03:35.851119: val Epoch: [73][38/72]	Time  1.102 ( 0.708)	Data  0.976 ( 0.571)	Loss 2.2182e-01 (1.1273e-01) 
2023-05-26 02:03:36.073508: val Epoch: [73][39/72]	Time  0.222 ( 0.695)	Data  0.088 ( 0.559)	Loss 3.1045e-02 (1.1069e-01) 
2023-05-26 02:03:37.248719: val Epoch: [73][40/72]	Time  1.175 ( 0.707)	Data  1.038 ( 0.570)	Loss 4.4613e-02 (1.0908e-01) 
2023-05-26 02:03:37.449665: val Epoch: [73][41/72]	Time  0.201 ( 0.695)	Data  0.059 ( 0.558)	Loss 1.7292e-01 (1.1060e-01) 
2023-05-26 02:03:38.723671: val Epoch: [73][42/72]	Time  1.274 ( 0.709)	Data  1.123 ( 0.571)	Loss 5.8326e-02 (1.0938e-01) 
2023-05-26 02:03:38.855589: val Epoch: [73][43/72]	Time  0.132 ( 0.695)	Data  0.001 ( 0.558)	Loss 1.1353e-01 (1.0948e-01) 
2023-05-26 02:03:40.080760: val Epoch: [73][44/72]	Time  1.225 ( 0.707)	Data  1.094 ( 0.570)	Loss 8.4342e-02 (1.0892e-01) 
2023-05-26 02:03:40.266636: val Epoch: [73][45/72]	Time  0.186 ( 0.696)	Data  0.040 ( 0.559)	Loss 5.0241e-02 (1.0764e-01) 
2023-05-26 02:03:41.433790: val Epoch: [73][46/72]	Time  1.167 ( 0.706)	Data  1.039 ( 0.569)	Loss 6.2468e-02 (1.0668e-01) 
2023-05-26 02:03:41.634146: val Epoch: [73][47/72]	Time  0.200 ( 0.695)	Data  0.067 ( 0.559)	Loss 3.2432e-01 (1.1122e-01) 
2023-05-26 02:03:42.772511: val Epoch: [73][48/72]	Time  1.138 ( 0.704)	Data  1.016 ( 0.568)	Loss 2.3359e-01 (1.1371e-01) 
2023-05-26 02:03:42.961971: val Epoch: [73][49/72]	Time  0.189 ( 0.694)	Data  0.061 ( 0.558)	Loss 4.1322e-01 (1.1970e-01) 
2023-05-26 02:03:44.127514: val Epoch: [73][50/72]	Time  1.166 ( 0.703)	Data  1.038 ( 0.567)	Loss 1.4050e-01 (1.2011e-01) 
2023-05-26 02:03:44.320415: val Epoch: [73][51/72]	Time  0.193 ( 0.694)	Data  0.065 ( 0.558)	Loss 1.2430e-01 (1.2019e-01) 
2023-05-26 02:03:45.517917: val Epoch: [73][52/72]	Time  1.197 ( 0.703)	Data  1.068 ( 0.567)	Loss 3.0486e-01 (1.2368e-01) 
2023-05-26 02:03:45.667752: val Epoch: [73][53/72]	Time  0.150 ( 0.693)	Data  0.020 ( 0.557)	Loss 2.1548e-01 (1.2538e-01) 
2023-05-26 02:03:46.966196: val Epoch: [73][54/72]	Time  1.298 ( 0.704)	Data  1.161 ( 0.568)	Loss 5.1382e-02 (1.2403e-01) 
2023-05-26 02:03:47.097345: val Epoch: [73][55/72]	Time  0.131 ( 0.694)	Data  0.001 ( 0.558)	Loss 4.5998e-02 (1.2264e-01) 
2023-05-26 02:03:48.289821: val Epoch: [73][56/72]	Time  1.192 ( 0.702)	Data  1.065 ( 0.567)	Loss 5.4250e-02 (1.2144e-01) 
2023-05-26 02:03:48.436216: val Epoch: [73][57/72]	Time  0.146 ( 0.693)	Data  0.018 ( 0.557)	Loss 1.6650e-01 (1.2221e-01) 
2023-05-26 02:03:49.637144: val Epoch: [73][58/72]	Time  1.201 ( 0.701)	Data  1.074 ( 0.566)	Loss 6.9519e-02 (1.2132e-01) 
2023-05-26 02:03:49.851331: val Epoch: [73][59/72]	Time  0.214 ( 0.693)	Data  0.079 ( 0.558)	Loss 3.8368e-01 (1.2569e-01) 
2023-05-26 02:03:51.037167: val Epoch: [73][60/72]	Time  1.186 ( 0.701)	Data  1.052 ( 0.566)	Loss 8.4866e-02 (1.2502e-01) 
2023-05-26 02:03:51.243084: val Epoch: [73][61/72]	Time  0.206 ( 0.693)	Data  0.070 ( 0.558)	Loss 3.8604e-01 (1.2923e-01) 
2023-05-26 02:03:52.317883: val Epoch: [73][62/72]	Time  1.075 ( 0.699)	Data  0.941 ( 0.564)	Loss 5.8864e-02 (1.2812e-01) 
2023-05-26 02:03:52.591974: val Epoch: [73][63/72]	Time  0.274 ( 0.693)	Data  0.142 ( 0.558)	Loss 8.2808e-02 (1.2741e-01) 
2023-05-26 02:03:53.630496: val Epoch: [73][64/72]	Time  1.039 ( 0.698)	Data  0.911 ( 0.563)	Loss 5.1545e-02 (1.2624e-01) 
2023-05-26 02:03:53.921963: val Epoch: [73][65/72]	Time  0.291 ( 0.692)	Data  0.164 ( 0.557)	Loss 5.2620e-02 (1.2513e-01) 
2023-05-26 02:03:54.979644: val Epoch: [73][66/72]	Time  1.058 ( 0.697)	Data  0.928 ( 0.562)	Loss 9.0009e-02 (1.2460e-01) 
2023-05-26 02:03:55.338589: val Epoch: [73][67/72]	Time  0.359 ( 0.692)	Data  0.227 ( 0.558)	Loss 1.6392e-01 (1.2518e-01) 
2023-05-26 02:03:56.397372: val Epoch: [73][68/72]	Time  1.059 ( 0.698)	Data  0.927 ( 0.563)	Loss 1.0367e-01 (1.2487e-01) 
2023-05-26 02:03:56.753502: val Epoch: [73][69/72]	Time  0.356 ( 0.693)	Data  0.216 ( 0.558)	Loss 1.2787e-01 (1.2491e-01) 
2023-05-26 02:03:57.724643: val Epoch: [73][70/72]	Time  0.971 ( 0.697)	Data  0.841 ( 0.562)	Loss 5.6995e-02 (1.2396e-01) 
2023-05-26 02:03:58.068557: val Epoch: [73][71/72]	Time  0.344 ( 0.692)	Data  0.212 ( 0.557)	Loss 9.6649e-02 (1.2358e-01) 
2023-05-26 02:03:58.282742: Epoch 73 :Val : ['ET : 0.7375628352165222', 'TC : 0.7934972047805786', 'WT : 0.8751307725906372'] 
2023-05-26 02:03:58.285783: Epoch 73 :Val : ['ET : 0.7375628352165222', 'TC : 0.7934972047805786', 'WT : 0.8751307725906372'] 
2023-05-26 02:03:58.288359: Val epoch done in 50.93590959199719 s 
2023-05-26 02:03:58.294369: Batches per epoch:  129 
2023-05-26 02:04:04.010008: train Epoch: [74][  0/129]	Time  5.715 ( 5.715)	Data  4.636 ( 4.636)	Loss 6.3365e-02 (6.3365e-02) 
2023-05-26 02:04:04.995237: train Epoch: [74][  1/129]	Time  0.985 ( 3.350)	Data  0.001 ( 2.319)	Loss 1.0001e-01 (8.1685e-02) 
2023-05-26 02:04:07.969057: train Epoch: [74][  2/129]	Time  2.974 ( 3.225)	Data  2.005 ( 2.214)	Loss 9.3177e-02 (8.5516e-02) 
2023-05-26 02:04:08.948696: train Epoch: [74][  3/129]	Time  0.980 ( 2.663)	Data  0.001 ( 1.661)	Loss 5.8463e-02 (7.8753e-02) 
2023-05-26 02:04:12.174215: train Epoch: [74][  4/129]	Time  3.226 ( 2.776)	Data  2.225 ( 1.774)	Loss 6.0495e-02 (7.5101e-02) 
2023-05-26 02:04:13.180342: train Epoch: [74][  5/129]	Time  1.006 ( 2.481)	Data  0.001 ( 1.478)	Loss 4.6929e-02 (7.0406e-02) 
2023-05-26 02:04:16.212337: train Epoch: [74][  6/129]	Time  3.032 ( 2.560)	Data  2.055 ( 1.561)	Loss 5.2726e-02 (6.7880e-02) 
2023-05-26 02:04:17.193955: train Epoch: [74][  7/129]	Time  0.982 ( 2.362)	Data  0.002 ( 1.366)	Loss 5.7659e-02 (6.6602e-02) 
2023-05-26 02:04:20.386763: train Epoch: [74][  8/129]	Time  3.193 ( 2.455)	Data  2.216 ( 1.460)	Loss 5.6295e-02 (6.5457e-02) 
2023-05-26 02:04:21.369921: train Epoch: [74][  9/129]	Time  0.983 ( 2.308)	Data  0.001 ( 1.314)	Loss 6.8259e-02 (6.5737e-02) 
2023-05-26 02:04:24.630377: train Epoch: [74][ 10/129]	Time  3.260 ( 2.394)	Data  2.288 ( 1.403)	Loss 5.9300e-02 (6.5152e-02) 
2023-05-26 02:04:25.602478: train Epoch: [74][ 11/129]	Time  0.972 ( 2.276)	Data  0.001 ( 1.286)	Loss 5.8028e-02 (6.4559e-02) 
2023-05-26 02:04:28.659590: train Epoch: [74][ 12/129]	Time  3.057 ( 2.336)	Data  2.081 ( 1.347)	Loss 1.2537e-01 (6.9236e-02) 
2023-05-26 02:04:29.642057: train Epoch: [74][ 13/129]	Time  0.982 ( 2.239)	Data  0.001 ( 1.251)	Loss 6.9664e-02 (6.9267e-02) 
2023-05-26 02:04:32.699192: train Epoch: [74][ 14/129]	Time  3.057 ( 2.294)	Data  2.092 ( 1.307)	Loss 7.9750e-02 (6.9965e-02) 
2023-05-26 02:04:33.666701: train Epoch: [74][ 15/129]	Time  0.968 ( 2.211)	Data  0.001 ( 1.225)	Loss 6.8646e-02 (6.9883e-02) 
2023-05-26 02:04:36.783697: train Epoch: [74][ 16/129]	Time  3.117 ( 2.264)	Data  2.150 ( 1.280)	Loss 7.7511e-02 (7.0332e-02) 
2023-05-26 02:04:37.759168: train Epoch: [74][ 17/129]	Time  0.975 ( 2.192)	Data  0.001 ( 1.209)	Loss 5.2841e-02 (6.9360e-02) 
2023-05-26 02:04:40.860291: train Epoch: [74][ 18/129]	Time  3.101 ( 2.240)	Data  2.124 ( 1.257)	Loss 3.1088e-02 (6.7346e-02) 
2023-05-26 02:04:41.853783: train Epoch: [74][ 19/129]	Time  0.994 ( 2.178)	Data  0.002 ( 1.194)	Loss 6.9554e-02 (6.7456e-02) 
2023-05-26 02:04:44.874077: train Epoch: [74][ 20/129]	Time  3.020 ( 2.218)	Data  2.041 ( 1.235)	Loss 3.5566e-02 (6.5938e-02) 
2023-05-26 02:04:45.853139: train Epoch: [74][ 21/129]	Time  0.979 ( 2.162)	Data  0.001 ( 1.179)	Loss 8.2276e-02 (6.6680e-02) 
2023-05-26 02:04:49.011546: train Epoch: [74][ 22/129]	Time  3.158 ( 2.205)	Data  2.195 ( 1.223)	Loss 9.6242e-02 (6.7966e-02) 
2023-05-26 02:04:49.998329: train Epoch: [74][ 23/129]	Time  0.987 ( 2.154)	Data  0.001 ( 1.172)	Loss 6.7415e-02 (6.7943e-02) 
2023-05-26 02:04:53.179440: train Epoch: [74][ 24/129]	Time  3.181 ( 2.195)	Data  2.202 ( 1.213)	Loss 5.9949e-02 (6.7623e-02) 
2023-05-26 02:04:54.151217: train Epoch: [74][ 25/129]	Time  0.972 ( 2.148)	Data  0.001 ( 1.166)	Loss 8.3907e-02 (6.8249e-02) 
2023-05-26 02:04:57.156259: train Epoch: [74][ 26/129]	Time  3.005 ( 2.180)	Data  2.024 ( 1.198)	Loss 9.5864e-02 (6.9272e-02) 
2023-05-26 02:04:58.130489: train Epoch: [74][ 27/129]	Time  0.974 ( 2.137)	Data  0.001 ( 1.155)	Loss 1.5621e-01 (7.2377e-02) 
2023-05-26 02:05:01.210887: train Epoch: [74][ 28/129]	Time  3.080 ( 2.170)	Data  2.111 ( 1.188)	Loss 8.3426e-02 (7.2758e-02) 
2023-05-26 02:05:02.197544: train Epoch: [74][ 29/129]	Time  0.987 ( 2.130)	Data  0.002 ( 1.149)	Loss 1.0029e-01 (7.3676e-02) 
2023-05-26 02:05:05.401291: train Epoch: [74][ 30/129]	Time  3.204 ( 2.165)	Data  2.230 ( 1.184)	Loss 5.7633e-02 (7.3158e-02) 
2023-05-26 02:05:06.384251: train Epoch: [74][ 31/129]	Time  0.983 ( 2.128)	Data  0.002 ( 1.147)	Loss 8.7197e-02 (7.3597e-02) 
2023-05-26 02:05:09.479022: train Epoch: [74][ 32/129]	Time  3.095 ( 2.157)	Data  2.101 ( 1.176)	Loss 7.5417e-02 (7.3652e-02) 
2023-05-26 02:05:10.473814: train Epoch: [74][ 33/129]	Time  0.995 ( 2.123)	Data  0.001 ( 1.141)	Loss 1.1797e-01 (7.4956e-02) 
2023-05-26 02:05:13.666314: train Epoch: [74][ 34/129]	Time  3.192 ( 2.153)	Data  2.194 ( 1.171)	Loss 9.8971e-02 (7.5642e-02) 
2023-05-26 02:05:14.654908: train Epoch: [74][ 35/129]	Time  0.989 ( 2.121)	Data  0.001 ( 1.139)	Loss 6.2330e-02 (7.5272e-02) 
2023-05-26 02:05:17.809730: train Epoch: [74][ 36/129]	Time  3.155 ( 2.149)	Data  2.171 ( 1.167)	Loss 9.8240e-02 (7.5893e-02) 
2023-05-26 02:05:18.810090: train Epoch: [74][ 37/129]	Time  1.000 ( 2.119)	Data  0.001 ( 1.136)	Loss 1.1535e-01 (7.6931e-02) 
2023-05-26 02:05:22.188327: train Epoch: [74][ 38/129]	Time  3.378 ( 2.151)	Data  2.327 ( 1.166)	Loss 2.0216e-01 (8.0142e-02) 
2023-05-26 02:05:23.193816: train Epoch: [74][ 39/129]	Time  1.005 ( 2.122)	Data  0.001 ( 1.137)	Loss 6.6557e-02 (7.9803e-02) 
2023-05-26 02:05:26.137086: train Epoch: [74][ 40/129]	Time  2.943 ( 2.142)	Data  1.966 ( 1.158)	Loss 7.5739e-02 (7.9703e-02) 
2023-05-26 02:05:27.110792: train Epoch: [74][ 41/129]	Time  0.974 ( 2.115)	Data  0.001 ( 1.130)	Loss 8.1010e-02 (7.9735e-02) 
2023-05-26 02:05:30.131941: train Epoch: [74][ 42/129]	Time  3.021 ( 2.136)	Data  2.050 ( 1.151)	Loss 7.3457e-02 (7.9589e-02) 
2023-05-26 02:05:31.113922: train Epoch: [74][ 43/129]	Time  0.982 ( 2.110)	Data  0.001 ( 1.125)	Loss 1.0850e-01 (8.0246e-02) 
2023-05-26 02:05:34.382555: train Epoch: [74][ 44/129]	Time  3.269 ( 2.135)	Data  2.268 ( 1.151)	Loss 8.5883e-02 (8.0371e-02) 
2023-05-26 02:05:35.375891: train Epoch: [74][ 45/129]	Time  0.993 ( 2.110)	Data  0.002 ( 1.126)	Loss 1.1857e-01 (8.1201e-02) 
2023-05-26 02:05:38.407448: train Epoch: [74][ 46/129]	Time  3.032 ( 2.130)	Data  2.059 ( 1.146)	Loss 5.6432e-02 (8.0674e-02) 
2023-05-26 02:05:39.385781: train Epoch: [74][ 47/129]	Time  0.978 ( 2.106)	Data  0.001 ( 1.122)	Loss 6.3101e-02 (8.0308e-02) 
2023-05-26 02:05:42.465858: train Epoch: [74][ 48/129]	Time  3.080 ( 2.126)	Data  2.114 ( 1.142)	Loss 8.6511e-02 (8.0435e-02) 
2023-05-26 02:05:43.444878: train Epoch: [74][ 49/129]	Time  0.979 ( 2.103)	Data  0.001 ( 1.119)	Loss 6.4033e-02 (8.0107e-02) 
2023-05-26 02:05:46.409501: train Epoch: [74][ 50/129]	Time  2.965 ( 2.120)	Data  1.993 ( 1.136)	Loss 6.9292e-02 (7.9895e-02) 
2023-05-26 02:05:47.380892: train Epoch: [74][ 51/129]	Time  0.971 ( 2.098)	Data  0.001 ( 1.114)	Loss 8.4418e-02 (7.9982e-02) 
2023-05-26 02:05:50.558451: train Epoch: [74][ 52/129]	Time  3.178 ( 2.118)	Data  2.190 ( 1.135)	Loss 8.6326e-02 (8.0101e-02) 
2023-05-26 02:05:51.532259: train Epoch: [74][ 53/129]	Time  0.974 ( 2.097)	Data  0.002 ( 1.114)	Loss 9.3183e-02 (8.0344e-02) 
2023-05-26 02:05:54.698613: train Epoch: [74][ 54/129]	Time  3.166 ( 2.116)	Data  2.114 ( 1.132)	Loss 7.3166e-02 (8.0213e-02) 
2023-05-26 02:05:55.682709: train Epoch: [74][ 55/129]	Time  0.984 ( 2.096)	Data  0.002 ( 1.112)	Loss 7.0468e-02 (8.0039e-02) 
2023-05-26 02:05:58.701079: train Epoch: [74][ 56/129]	Time  3.018 ( 2.112)	Data  2.051 ( 1.128)	Loss 4.1638e-02 (7.9365e-02) 
2023-05-26 02:05:59.689485: train Epoch: [74][ 57/129]	Time  0.988 ( 2.093)	Data  0.001 ( 1.109)	Loss 4.7544e-02 (7.8817e-02) 
2023-05-26 02:06:02.852676: train Epoch: [74][ 58/129]	Time  3.163 ( 2.111)	Data  2.192 ( 1.127)	Loss 9.7246e-02 (7.9129e-02) 
2023-05-26 02:06:03.815521: train Epoch: [74][ 59/129]	Time  0.963 ( 2.092)	Data  0.001 ( 1.108)	Loss 8.6557e-02 (7.9253e-02) 
2023-05-26 02:06:07.006724: train Epoch: [74][ 60/129]	Time  3.191 ( 2.110)	Data  2.220 ( 1.127)	Loss 6.6419e-02 (7.9043e-02) 
2023-05-26 02:06:07.980498: train Epoch: [74][ 61/129]	Time  0.974 ( 2.092)	Data  0.001 ( 1.108)	Loss 8.0619e-02 (7.9068e-02) 
2023-05-26 02:06:11.042891: train Epoch: [74][ 62/129]	Time  3.062 ( 2.107)	Data  2.094 ( 1.124)	Loss 6.7349e-02 (7.8882e-02) 
2023-05-26 02:06:12.017082: train Epoch: [74][ 63/129]	Time  0.974 ( 2.089)	Data  0.001 ( 1.107)	Loss 6.5863e-02 (7.8679e-02) 
2023-05-26 02:06:15.183163: train Epoch: [74][ 64/129]	Time  3.166 ( 2.106)	Data  2.166 ( 1.123)	Loss 1.3520e-01 (7.9548e-02) 
2023-05-26 02:06:16.169553: train Epoch: [74][ 65/129]	Time  0.986 ( 2.089)	Data  0.001 ( 1.106)	Loss 6.2886e-02 (7.9296e-02) 
2023-05-26 02:06:19.302790: train Epoch: [74][ 66/129]	Time  3.133 ( 2.105)	Data  2.146 ( 1.121)	Loss 6.5380e-02 (7.9088e-02) 
2023-05-26 02:06:20.277663: train Epoch: [74][ 67/129]	Time  0.975 ( 2.088)	Data  0.001 ( 1.105)	Loss 6.7247e-02 (7.8914e-02) 
2023-05-26 02:06:23.467633: train Epoch: [74][ 68/129]	Time  3.190 ( 2.104)	Data  2.219 ( 1.121)	Loss 7.6632e-02 (7.8881e-02) 
2023-05-26 02:06:24.453006: train Epoch: [74][ 69/129]	Time  0.985 ( 2.088)	Data  0.001 ( 1.105)	Loss 4.7699e-02 (7.8435e-02) 
2023-05-26 02:06:27.481340: train Epoch: [74][ 70/129]	Time  3.028 ( 2.101)	Data  2.064 ( 1.119)	Loss 5.3179e-02 (7.8080e-02) 
2023-05-26 02:06:28.459831: train Epoch: [74][ 71/129]	Time  0.978 ( 2.086)	Data  0.001 ( 1.103)	Loss 8.8834e-02 (7.8229e-02) 
2023-05-26 02:06:31.741899: train Epoch: [74][ 72/129]	Time  3.282 ( 2.102)	Data  2.298 ( 1.119)	Loss 1.0371e-01 (7.8578e-02) 
2023-05-26 02:06:32.711367: train Epoch: [74][ 73/129]	Time  0.969 ( 2.087)	Data  0.001 ( 1.104)	Loss 8.0294e-02 (7.8601e-02) 
2023-05-26 02:06:35.914724: train Epoch: [74][ 74/129]	Time  3.203 ( 2.102)	Data  2.216 ( 1.119)	Loss 7.6882e-02 (7.8578e-02) 
2023-05-26 02:06:36.883288: train Epoch: [74][ 75/129]	Time  0.969 ( 2.087)	Data  0.001 ( 1.104)	Loss 9.4534e-02 (7.8788e-02) 
2023-05-26 02:06:40.109004: train Epoch: [74][ 76/129]	Time  3.226 ( 2.101)	Data  2.248 ( 1.119)	Loss 5.7723e-02 (7.8515e-02) 
2023-05-26 02:06:41.081308: train Epoch: [74][ 77/129]	Time  0.972 ( 2.087)	Data  0.001 ( 1.105)	Loss 9.3513e-02 (7.8707e-02) 
2023-05-26 02:06:44.227724: train Epoch: [74][ 78/129]	Time  3.146 ( 2.100)	Data  2.161 ( 1.118)	Loss 4.3898e-02 (7.8266e-02) 
2023-05-26 02:06:45.211867: train Epoch: [74][ 79/129]	Time  0.984 ( 2.086)	Data  0.001 ( 1.104)	Loss 5.2883e-02 (7.7949e-02) 
2023-05-26 02:06:48.317739: train Epoch: [74][ 80/129]	Time  3.106 ( 2.099)	Data  2.139 ( 1.117)	Loss 4.6625e-02 (7.7562e-02) 
2023-05-26 02:06:49.296987: train Epoch: [74][ 81/129]	Time  0.979 ( 2.085)	Data  0.002 ( 1.103)	Loss 5.2894e-02 (7.7261e-02) 
2023-05-26 02:06:52.402565: train Epoch: [74][ 82/129]	Time  3.106 ( 2.098)	Data  2.116 ( 1.116)	Loss 7.4924e-02 (7.7233e-02) 
2023-05-26 02:06:53.378364: train Epoch: [74][ 83/129]	Time  0.976 ( 2.084)	Data  0.002 ( 1.102)	Loss 6.6486e-02 (7.7105e-02) 
2023-05-26 02:06:56.454030: train Epoch: [74][ 84/129]	Time  3.076 ( 2.096)	Data  2.083 ( 1.114)	Loss 6.7338e-02 (7.6990e-02) 
2023-05-26 02:06:57.437625: train Epoch: [74][ 85/129]	Time  0.984 ( 2.083)	Data  0.001 ( 1.101)	Loss 5.2566e-02 (7.6706e-02) 
2023-05-26 02:07:00.405638: train Epoch: [74][ 86/129]	Time  2.968 ( 2.093)	Data  1.985 ( 1.111)	Loss 7.1357e-02 (7.6645e-02) 
2023-05-26 02:07:01.403978: train Epoch: [74][ 87/129]	Time  0.998 ( 2.081)	Data  0.001 ( 1.099)	Loss 6.4027e-02 (7.6502e-02) 
2023-05-26 02:07:04.584964: train Epoch: [74][ 88/129]	Time  3.181 ( 2.093)	Data  2.206 ( 1.111)	Loss 9.6911e-02 (7.6731e-02) 
2023-05-26 02:07:05.557149: train Epoch: [74][ 89/129]	Time  0.972 ( 2.081)	Data  0.001 ( 1.099)	Loss 6.5426e-02 (7.6605e-02) 
2023-05-26 02:07:08.739061: train Epoch: [74][ 90/129]	Time  3.182 ( 2.093)	Data  2.207 ( 1.111)	Loss 1.1344e-01 (7.7010e-02) 
2023-05-26 02:07:09.716248: train Epoch: [74][ 91/129]	Time  0.977 ( 2.081)	Data  0.001 ( 1.099)	Loss 6.8993e-02 (7.6923e-02) 
2023-05-26 02:07:12.873438: train Epoch: [74][ 92/129]	Time  3.157 ( 2.092)	Data  2.177 ( 1.110)	Loss 5.9730e-02 (7.6738e-02) 
2023-05-26 02:07:13.862358: train Epoch: [74][ 93/129]	Time  0.989 ( 2.080)	Data  0.001 ( 1.099)	Loss 1.1093e-01 (7.7102e-02) 
2023-05-26 02:07:16.988565: train Epoch: [74][ 94/129]	Time  3.126 ( 2.092)	Data  2.157 ( 1.110)	Loss 7.4224e-02 (7.7071e-02) 
2023-05-26 02:07:17.966368: train Epoch: [74][ 95/129]	Time  0.978 ( 2.080)	Data  0.001 ( 1.098)	Loss 6.3992e-02 (7.6935e-02) 
2023-05-26 02:07:21.011046: train Epoch: [74][ 96/129]	Time  3.045 ( 2.090)	Data  2.070 ( 1.108)	Loss 5.9602e-02 (7.6757e-02) 
2023-05-26 02:07:21.986128: train Epoch: [74][ 97/129]	Time  0.975 ( 2.078)	Data  0.001 ( 1.097)	Loss 7.6717e-02 (7.6756e-02) 
2023-05-26 02:07:25.021315: train Epoch: [74][ 98/129]	Time  3.035 ( 2.088)	Data  2.057 ( 1.107)	Loss 6.4295e-02 (7.6630e-02) 
2023-05-26 02:07:25.993962: train Epoch: [74][ 99/129]	Time  0.973 ( 2.077)	Data  0.001 ( 1.096)	Loss 8.0695e-02 (7.6671e-02) 
2023-05-26 02:07:29.076038: train Epoch: [74][100/129]	Time  3.082 ( 2.087)	Data  2.109 ( 1.106)	Loss 6.4982e-02 (7.6555e-02) 
2023-05-26 02:07:30.053027: train Epoch: [74][101/129]	Time  0.977 ( 2.076)	Data  0.001 ( 1.095)	Loss 6.5973e-02 (7.6451e-02) 
2023-05-26 02:07:33.084146: train Epoch: [74][102/129]	Time  3.031 ( 2.085)	Data  2.047 ( 1.104)	Loss 5.2660e-02 (7.6220e-02) 
2023-05-26 02:07:34.061619: train Epoch: [74][103/129]	Time  0.977 ( 2.075)	Data  0.001 ( 1.093)	Loss 1.1602e-01 (7.6603e-02) 
2023-05-26 02:07:37.201078: train Epoch: [74][104/129]	Time  3.139 ( 2.085)	Data  2.157 ( 1.104)	Loss 5.5647e-02 (7.6403e-02) 
2023-05-26 02:07:38.190371: train Epoch: [74][105/129]	Time  0.989 ( 2.074)	Data  0.001 ( 1.093)	Loss 4.7556e-02 (7.6131e-02) 
2023-05-26 02:07:41.317322: train Epoch: [74][106/129]	Time  3.127 ( 2.084)	Data  2.152 ( 1.103)	Loss 8.4181e-02 (7.6207e-02) 
2023-05-26 02:07:42.292876: train Epoch: [74][107/129]	Time  0.976 ( 2.074)	Data  0.001 ( 1.093)	Loss 7.4401e-02 (7.6190e-02) 
2023-05-26 02:07:45.590926: train Epoch: [74][108/129]	Time  3.298 ( 2.085)	Data  2.309 ( 1.104)	Loss 1.3157e-01 (7.6698e-02) 
2023-05-26 02:07:46.564810: train Epoch: [74][109/129]	Time  0.974 ( 2.075)	Data  0.001 ( 1.094)	Loss 7.8672e-02 (7.6716e-02) 
2023-05-26 02:07:49.649131: train Epoch: [74][110/129]	Time  3.084 ( 2.084)	Data  2.107 ( 1.103)	Loss 5.0331e-02 (7.6478e-02) 
2023-05-26 02:07:50.634327: train Epoch: [74][111/129]	Time  0.985 ( 2.074)	Data  0.001 ( 1.093)	Loss 4.7612e-02 (7.6220e-02) 
2023-05-26 02:07:53.868979: train Epoch: [74][112/129]	Time  3.235 ( 2.085)	Data  2.246 ( 1.103)	Loss 5.9781e-02 (7.6075e-02) 
2023-05-26 02:07:54.842663: train Epoch: [74][113/129]	Time  0.974 ( 2.075)	Data  0.001 ( 1.094)	Loss 4.6300e-02 (7.5814e-02) 
2023-05-26 02:07:57.972338: train Epoch: [74][114/129]	Time  3.130 ( 2.084)	Data  2.131 ( 1.103)	Loss 6.4463e-02 (7.5715e-02) 
2023-05-26 02:07:58.957519: train Epoch: [74][115/129]	Time  0.985 ( 2.075)	Data  0.001 ( 1.093)	Loss 5.8881e-02 (7.5570e-02) 
2023-05-26 02:08:01.960206: train Epoch: [74][116/129]	Time  3.003 ( 2.083)	Data  2.013 ( 1.101)	Loss 4.9928e-02 (7.5351e-02) 
2023-05-26 02:08:02.932672: train Epoch: [74][117/129]	Time  0.972 ( 2.073)	Data  0.001 ( 1.092)	Loss 6.8757e-02 (7.5295e-02) 
2023-05-26 02:08:05.925878: train Epoch: [74][118/129]	Time  2.993 ( 2.081)	Data  2.004 ( 1.099)	Loss 1.0056e-01 (7.5507e-02) 
2023-05-26 02:08:06.900428: train Epoch: [74][119/129]	Time  0.975 ( 2.072)	Data  0.001 ( 1.090)	Loss 8.0122e-02 (7.5546e-02) 
2023-05-26 02:08:09.981751: train Epoch: [74][120/129]	Time  3.081 ( 2.080)	Data  2.108 ( 1.099)	Loss 6.9303e-02 (7.5494e-02) 
2023-05-26 02:08:10.955909: train Epoch: [74][121/129]	Time  0.974 ( 2.071)	Data  0.001 ( 1.090)	Loss 8.2438e-02 (7.5551e-02) 
2023-05-26 02:08:14.080279: train Epoch: [74][122/129]	Time  3.124 ( 2.080)	Data  2.140 ( 1.098)	Loss 5.8893e-02 (7.5416e-02) 
2023-05-26 02:08:15.054515: train Epoch: [74][123/129]	Time  0.974 ( 2.071)	Data  0.001 ( 1.089)	Loss 5.6756e-02 (7.5265e-02) 
2023-05-26 02:08:18.126395: train Epoch: [74][124/129]	Time  3.072 ( 2.079)	Data  2.103 ( 1.098)	Loss 6.6470e-02 (7.5195e-02) 
2023-05-26 02:08:19.101117: train Epoch: [74][125/129]	Time  0.975 ( 2.070)	Data  0.001 ( 1.089)	Loss 5.5392e-02 (7.5038e-02) 
2023-05-26 02:08:22.286687: train Epoch: [74][126/129]	Time  3.186 ( 2.079)	Data  2.204 ( 1.098)	Loss 7.7218e-02 (7.5055e-02) 
2023-05-26 02:08:23.275069: train Epoch: [74][127/129]	Time  0.988 ( 2.070)	Data  0.001 ( 1.089)	Loss 7.3695e-02 (7.5044e-02) 
2023-05-26 02:08:25.239818: train Epoch: [74][128/129]	Time  1.965 ( 2.069)	Data  0.994 ( 1.088)	Loss 8.5163e-02 (7.5123e-02) 
2023-05-26 02:08:25.298827: Train Epoch done in 267.0045108430022 s 
2023-05-26 02:08:28.122307: val Epoch: [74][ 0/72]	Time  1.879 ( 1.879)	Data  1.638 ( 1.638)	Loss 5.4025e-02 (5.4025e-02) 
2023-05-26 02:08:28.261891: val Epoch: [74][ 1/72]	Time  0.140 ( 1.009)	Data  0.002 ( 0.820)	Loss 1.3477e-01 (9.4396e-02) 
2023-05-26 02:08:29.453416: val Epoch: [74][ 2/72]	Time  1.192 ( 1.070)	Data  1.060 ( 0.900)	Loss 9.7325e-02 (9.5372e-02) 
2023-05-26 02:08:29.583092: val Epoch: [74][ 3/72]	Time  0.130 ( 0.835)	Data  0.001 ( 0.675)	Loss 3.7813e-02 (8.0982e-02) 
2023-05-26 02:08:30.879282: val Epoch: [74][ 4/72]	Time  1.296 ( 0.927)	Data  1.157 ( 0.772)	Loss 1.2723e-01 (9.0232e-02) 
2023-05-26 02:08:31.011137: val Epoch: [74][ 5/72]	Time  0.132 ( 0.795)	Data  0.001 ( 0.643)	Loss 1.4165e-01 (9.8802e-02) 
2023-05-26 02:08:32.296789: val Epoch: [74][ 6/72]	Time  1.286 ( 0.865)	Data  1.151 ( 0.716)	Loss 9.8338e-02 (9.8736e-02) 
2023-05-26 02:08:32.440672: val Epoch: [74][ 7/72]	Time  0.144 ( 0.775)	Data  0.001 ( 0.626)	Loss 9.6999e-02 (9.8519e-02) 
2023-05-26 02:08:33.706374: val Epoch: [74][ 8/72]	Time  1.266 ( 0.829)	Data  1.136 ( 0.683)	Loss 3.7607e-02 (9.1751e-02) 
2023-05-26 02:08:33.841373: val Epoch: [74][ 9/72]	Time  0.135 ( 0.760)	Data  0.001 ( 0.615)	Loss 3.4585e-02 (8.6034e-02) 
2023-05-26 02:08:35.211730: val Epoch: [74][10/72]	Time  1.370 ( 0.815)	Data  1.238 ( 0.672)	Loss 2.8797e-01 (1.0439e-01) 
2023-05-26 02:08:35.341089: val Epoch: [74][11/72]	Time  0.129 ( 0.758)	Data  0.001 ( 0.616)	Loss 3.5269e-02 (9.8632e-02) 
2023-05-26 02:08:36.577165: val Epoch: [74][12/72]	Time  1.236 ( 0.795)	Data  1.100 ( 0.653)	Loss 4.3199e-02 (9.4368e-02) 
2023-05-26 02:08:36.719117: val Epoch: [74][13/72]	Time  0.142 ( 0.748)	Data  0.001 ( 0.606)	Loss 3.4307e-01 (1.1213e-01) 
2023-05-26 02:08:38.024599: val Epoch: [74][14/72]	Time  1.305 ( 0.785)	Data  1.169 ( 0.644)	Loss 1.5574e-01 (1.1504e-01) 
2023-05-26 02:08:38.154175: val Epoch: [74][15/72]	Time  0.130 ( 0.744)	Data  0.002 ( 0.604)	Loss 7.8230e-02 (1.1274e-01) 
2023-05-26 02:08:39.386699: val Epoch: [74][16/72]	Time  1.233 ( 0.773)	Data  1.102 ( 0.633)	Loss 5.5185e-02 (1.0935e-01) 
2023-05-26 02:08:39.533966: val Epoch: [74][17/72]	Time  0.147 ( 0.738)	Data  0.015 ( 0.599)	Loss 6.1345e-02 (1.0669e-01) 
2023-05-26 02:08:40.694356: val Epoch: [74][18/72]	Time  1.160 ( 0.761)	Data  1.033 ( 0.622)	Loss 5.8504e-02 (1.0415e-01) 
2023-05-26 02:08:40.854209: val Epoch: [74][19/72]	Time  0.160 ( 0.731)	Data  0.029 ( 0.592)	Loss 3.6337e-02 (1.0076e-01) 
2023-05-26 02:08:42.038898: val Epoch: [74][20/72]	Time  1.185 ( 0.752)	Data  1.057 ( 0.614)	Loss 4.8907e-01 (1.1925e-01) 
2023-05-26 02:08:42.196675: val Epoch: [74][21/72]	Time  0.158 ( 0.725)	Data  0.030 ( 0.587)	Loss 4.3293e-01 (1.3351e-01) 
2023-05-26 02:08:43.402501: val Epoch: [74][22/72]	Time  1.206 ( 0.746)	Data  1.073 ( 0.609)	Loss 7.9436e-02 (1.3116e-01) 
2023-05-26 02:08:43.545131: val Epoch: [74][23/72]	Time  0.143 ( 0.721)	Data  0.014 ( 0.584)	Loss 1.4356e-01 (1.3167e-01) 
2023-05-26 02:08:44.716527: val Epoch: [74][24/72]	Time  1.171 ( 0.739)	Data  1.044 ( 0.602)	Loss 6.9389e-02 (1.2918e-01) 
2023-05-26 02:08:44.868420: val Epoch: [74][25/72]	Time  0.152 ( 0.716)	Data  0.020 ( 0.580)	Loss 6.2464e-02 (1.2662e-01) 
2023-05-26 02:08:46.076916: val Epoch: [74][26/72]	Time  1.208 ( 0.735)	Data  1.083 ( 0.598)	Loss 3.6143e-01 (1.3531e-01) 
2023-05-26 02:08:46.261266: val Epoch: [74][27/72]	Time  0.184 ( 0.715)	Data  0.062 ( 0.579)	Loss 5.0866e-02 (1.3230e-01) 
2023-05-26 02:08:47.436107: val Epoch: [74][28/72]	Time  1.175 ( 0.731)	Data  1.050 ( 0.596)	Loss 1.9401e-01 (1.3443e-01) 
2023-05-26 02:08:47.605095: val Epoch: [74][29/72]	Time  0.169 ( 0.712)	Data  0.040 ( 0.577)	Loss 1.7384e-01 (1.3574e-01) 
2023-05-26 02:08:48.751143: val Epoch: [74][30/72]	Time  1.146 ( 0.726)	Data  1.017 ( 0.591)	Loss 4.4356e-02 (1.3279e-01) 
2023-05-26 02:08:49.017455: val Epoch: [74][31/72]	Time  0.266 ( 0.712)	Data  0.137 ( 0.577)	Loss 9.0124e-02 (1.3146e-01) 
2023-05-26 02:08:50.100249: val Epoch: [74][32/72]	Time  1.083 ( 0.723)	Data  0.946 ( 0.588)	Loss 1.1692e-01 (1.3102e-01) 
2023-05-26 02:08:50.363515: val Epoch: [74][33/72]	Time  0.263 ( 0.709)	Data  0.134 ( 0.575)	Loss 6.9266e-02 (1.2920e-01) 
2023-05-26 02:08:51.485296: val Epoch: [74][34/72]	Time  1.122 ( 0.721)	Data  0.992 ( 0.587)	Loss 8.2312e-02 (1.2786e-01) 
2023-05-26 02:08:51.747611: val Epoch: [74][35/72]	Time  0.262 ( 0.708)	Data  0.127 ( 0.574)	Loss 1.2673e-01 (1.2783e-01) 
2023-05-26 02:08:52.841500: val Epoch: [74][36/72]	Time  1.094 ( 0.719)	Data  0.961 ( 0.584)	Loss 6.0919e-02 (1.2602e-01) 
2023-05-26 02:08:53.117620: val Epoch: [74][37/72]	Time  0.276 ( 0.707)	Data  0.139 ( 0.573)	Loss 2.7281e-01 (1.2989e-01) 
2023-05-26 02:08:54.208157: val Epoch: [74][38/72]	Time  1.090 ( 0.717)	Data  0.965 ( 0.583)	Loss 1.0065e-01 (1.2914e-01) 
2023-05-26 02:08:54.440231: val Epoch: [74][39/72]	Time  0.232 ( 0.705)	Data  0.101 ( 0.571)	Loss 4.8593e-02 (1.2712e-01) 
2023-05-26 02:08:55.517741: val Epoch: [74][40/72]	Time  1.077 ( 0.714)	Data  0.948 ( 0.580)	Loss 7.3900e-02 (1.2582e-01) 
2023-05-26 02:08:55.792245: val Epoch: [74][41/72]	Time  0.275 ( 0.704)	Data  0.145 ( 0.570)	Loss 4.4713e-02 (1.2389e-01) 
2023-05-26 02:08:56.838297: val Epoch: [74][42/72]	Time  1.046 ( 0.712)	Data  0.916 ( 0.578)	Loss 3.7964e-02 (1.2189e-01) 
2023-05-26 02:08:57.144883: val Epoch: [74][43/72]	Time  0.307 ( 0.702)	Data  0.175 ( 0.569)	Loss 1.7653e-01 (1.2314e-01) 
2023-05-26 02:08:58.229506: val Epoch: [74][44/72]	Time  1.085 ( 0.711)	Data  0.957 ( 0.577)	Loss 6.4421e-02 (1.2183e-01) 
2023-05-26 02:08:58.501273: val Epoch: [74][45/72]	Time  0.272 ( 0.701)	Data  0.144 ( 0.568)	Loss 5.1450e-02 (1.2030e-01) 
2023-05-26 02:08:59.566671: val Epoch: [74][46/72]	Time  1.065 ( 0.709)	Data  0.936 ( 0.576)	Loss 9.3377e-02 (1.1973e-01) 
2023-05-26 02:08:59.829543: val Epoch: [74][47/72]	Time  0.263 ( 0.700)	Data  0.134 ( 0.566)	Loss 6.0973e-02 (1.1850e-01) 
2023-05-26 02:09:00.990961: val Epoch: [74][48/72]	Time  1.161 ( 0.709)	Data  1.033 ( 0.576)	Loss 3.3026e-01 (1.2283e-01) 
2023-05-26 02:09:01.231943: val Epoch: [74][49/72]	Time  0.241 ( 0.700)	Data  0.101 ( 0.566)	Loss 6.0942e-02 (1.2159e-01) 
2023-05-26 02:09:02.353249: val Epoch: [74][50/72]	Time  1.121 ( 0.708)	Data  0.993 ( 0.575)	Loss 9.3861e-02 (1.2104e-01) 
2023-05-26 02:09:02.547132: val Epoch: [74][51/72]	Time  0.194 ( 0.698)	Data  0.060 ( 0.565)	Loss 2.1849e-01 (1.2292e-01) 
2023-05-26 02:09:03.690825: val Epoch: [74][52/72]	Time  1.144 ( 0.707)	Data  1.010 ( 0.573)	Loss 1.2073e-01 (1.2288e-01) 
2023-05-26 02:09:03.916243: val Epoch: [74][53/72]	Time  0.225 ( 0.698)	Data  0.098 ( 0.564)	Loss 3.3709e-01 (1.2684e-01) 
2023-05-26 02:09:04.990225: val Epoch: [74][54/72]	Time  1.074 ( 0.704)	Data  0.946 ( 0.571)	Loss 6.7022e-02 (1.2576e-01) 
2023-05-26 02:09:05.284210: val Epoch: [74][55/72]	Time  0.294 ( 0.697)	Data  0.166 ( 0.564)	Loss 4.5302e-02 (1.2432e-01) 
2023-05-26 02:09:06.349382: val Epoch: [74][56/72]	Time  1.065 ( 0.704)	Data  0.935 ( 0.571)	Loss 5.9404e-02 (1.2318e-01) 
2023-05-26 02:09:06.673349: val Epoch: [74][57/72]	Time  0.324 ( 0.697)	Data  0.193 ( 0.564)	Loss 4.5300e-02 (1.2184e-01) 
2023-05-26 02:09:07.704500: val Epoch: [74][58/72]	Time  1.031 ( 0.703)	Data  0.904 ( 0.570)	Loss 3.7532e-02 (1.2041e-01) 
2023-05-26 02:09:08.011103: val Epoch: [74][59/72]	Time  0.307 ( 0.696)	Data  0.180 ( 0.563)	Loss 5.1667e-02 (1.1926e-01) 
2023-05-26 02:09:09.080678: val Epoch: [74][60/72]	Time  1.070 ( 0.702)	Data  0.942 ( 0.570)	Loss 2.9800e-01 (1.2219e-01) 
2023-05-26 02:09:09.398834: val Epoch: [74][61/72]	Time  0.318 ( 0.696)	Data  0.191 ( 0.563)	Loss 9.2119e-02 (1.2171e-01) 
2023-05-26 02:09:10.406130: val Epoch: [74][62/72]	Time  1.007 ( 0.701)	Data  0.877 ( 0.568)	Loss 6.2327e-02 (1.2077e-01) 
2023-05-26 02:09:10.739281: val Epoch: [74][63/72]	Time  0.333 ( 0.695)	Data  0.203 ( 0.563)	Loss 4.8773e-02 (1.1964e-01) 
2023-05-26 02:09:11.809810: val Epoch: [74][64/72]	Time  1.071 ( 0.701)	Data  0.942 ( 0.569)	Loss 7.3673e-02 (1.1893e-01) 
2023-05-26 02:09:12.070548: val Epoch: [74][65/72]	Time  0.261 ( 0.694)	Data  0.131 ( 0.562)	Loss 5.2053e-02 (1.1792e-01) 
2023-05-26 02:09:13.164536: val Epoch: [74][66/72]	Time  1.094 ( 0.700)	Data  0.967 ( 0.568)	Loss 1.8798e-01 (1.1897e-01) 
2023-05-26 02:09:13.479800: val Epoch: [74][67/72]	Time  0.315 ( 0.695)	Data  0.187 ( 0.562)	Loss 6.3903e-02 (1.1816e-01) 
2023-05-26 02:09:14.531457: val Epoch: [74][68/72]	Time  1.052 ( 0.700)	Data  0.924 ( 0.568)	Loss 2.8646e-01 (1.2060e-01) 
2023-05-26 02:09:14.838821: val Epoch: [74][69/72]	Time  0.307 ( 0.694)	Data  0.181 ( 0.562)	Loss 3.4439e-01 (1.2379e-01) 
2023-05-26 02:09:15.911086: val Epoch: [74][70/72]	Time  1.072 ( 0.700)	Data  0.944 ( 0.567)	Loss 8.2228e-02 (1.2321e-01) 
2023-05-26 02:09:16.135535: val Epoch: [74][71/72]	Time  0.224 ( 0.693)	Data  0.092 ( 0.561)	Loss 5.6732e-02 (1.2228e-01) 
2023-05-26 02:09:16.368885: Epoch 74 :Val : ['ET : 0.7594959735870361', 'TC : 0.7946091890335083', 'WT : 0.8737925291061401'] 
2023-05-26 02:09:16.374876: Epoch 74 :Val : ['ET : 0.7594959735870361', 'TC : 0.7946091890335083', 'WT : 0.8737925291061401'] 
2023-05-26 02:09:16.378983: Val epoch done in 51.080157734999375 s 
2023-05-26 02:09:16.387253: Batches per epoch:  129 
2023-05-26 02:09:21.844901: train Epoch: [75][  0/129]	Time  5.457 ( 5.457)	Data  4.413 ( 4.413)	Loss 5.2482e-02 (5.2482e-02) 
2023-05-26 02:09:22.819271: train Epoch: [75][  1/129]	Time  0.974 ( 3.216)	Data  0.002 ( 2.207)	Loss 4.8146e-02 (5.0314e-02) 
2023-05-26 02:09:25.878259: train Epoch: [75][  2/129]	Time  3.059 ( 3.163)	Data  2.082 ( 2.166)	Loss 1.1533e-01 (7.1985e-02) 
2023-05-26 02:09:26.852779: train Epoch: [75][  3/129]	Time  0.975 ( 2.616)	Data  0.001 ( 1.624)	Loss 1.1848e-01 (8.3609e-02) 
2023-05-26 02:09:30.225034: train Epoch: [75][  4/129]	Time  3.372 ( 2.767)	Data  2.387 ( 1.777)	Loss 1.0074e-01 (8.7034e-02) 
2023-05-26 02:09:31.206418: train Epoch: [75][  5/129]	Time  0.981 ( 2.470)	Data  0.001 ( 1.481)	Loss 6.9203e-02 (8.4062e-02) 
2023-05-26 02:09:34.336450: train Epoch: [75][  6/129]	Time  3.130 ( 2.564)	Data  2.155 ( 1.577)	Loss 7.8192e-02 (8.3224e-02) 
2023-05-26 02:09:35.326351: train Epoch: [75][  7/129]	Time  0.990 ( 2.367)	Data  0.001 ( 1.380)	Loss 5.6321e-02 (7.9861e-02) 
2023-05-26 02:09:38.509509: train Epoch: [75][  8/129]	Time  3.183 ( 2.458)	Data  2.204 ( 1.472)	Loss 6.4200e-02 (7.8121e-02) 
2023-05-26 02:09:39.482235: train Epoch: [75][  9/129]	Time  0.973 ( 2.309)	Data  0.001 ( 1.325)	Loss 7.5605e-02 (7.7869e-02) 
2023-05-26 02:09:42.615380: train Epoch: [75][ 10/129]	Time  3.133 ( 2.384)	Data  2.167 ( 1.401)	Loss 4.5369e-02 (7.4915e-02) 
2023-05-26 02:09:43.594851: train Epoch: [75][ 11/129]	Time  0.979 ( 2.267)	Data  0.001 ( 1.285)	Loss 7.2606e-02 (7.4722e-02) 
2023-05-26 02:09:46.750336: train Epoch: [75][ 12/129]	Time  3.155 ( 2.336)	Data  2.185 ( 1.354)	Loss 6.0337e-02 (7.3616e-02) 
2023-05-26 02:09:47.722129: train Epoch: [75][ 13/129]	Time  0.972 ( 2.238)	Data  0.001 ( 1.257)	Loss 6.9625e-02 (7.3331e-02) 
2023-05-26 02:09:50.979329: train Epoch: [75][ 14/129]	Time  3.257 ( 2.306)	Data  2.277 ( 1.325)	Loss 1.1344e-01 (7.6005e-02) 
2023-05-26 02:09:51.959628: train Epoch: [75][ 15/129]	Time  0.980 ( 2.223)	Data  0.002 ( 1.242)	Loss 1.1632e-01 (7.8524e-02) 
2023-05-26 02:09:55.163562: train Epoch: [75][ 16/129]	Time  3.204 ( 2.281)	Data  2.221 ( 1.300)	Loss 1.0549e-01 (8.0111e-02) 
2023-05-26 02:09:56.140774: train Epoch: [75][ 17/129]	Time  0.977 ( 2.208)	Data  0.001 ( 1.228)	Loss 4.9415e-02 (7.8405e-02) 
2023-05-26 02:09:59.250401: train Epoch: [75][ 18/129]	Time  3.110 ( 2.256)	Data  2.127 ( 1.275)	Loss 6.4063e-02 (7.7651e-02) 
2023-05-26 02:10:00.224938: train Epoch: [75][ 19/129]	Time  0.975 ( 2.192)	Data  0.001 ( 1.211)	Loss 1.1210e-01 (7.9373e-02) 
2023-05-26 02:10:03.310178: train Epoch: [75][ 20/129]	Time  3.085 ( 2.234)	Data  2.113 ( 1.254)	Loss 8.0100e-02 (7.9408e-02) 
2023-05-26 02:10:04.280699: train Epoch: [75][ 21/129]	Time  0.971 ( 2.177)	Data  0.001 ( 1.197)	Loss 6.2029e-02 (7.8618e-02) 
2023-05-26 02:10:07.382209: train Epoch: [75][ 22/129]	Time  3.102 ( 2.217)	Data  2.130 ( 1.238)	Loss 4.5287e-02 (7.7169e-02) 
2023-05-26 02:10:08.360102: train Epoch: [75][ 23/129]	Time  0.978 ( 2.166)	Data  0.001 ( 1.186)	Loss 1.1407e-01 (7.8706e-02) 
2023-05-26 02:10:11.548012: train Epoch: [75][ 24/129]	Time  3.188 ( 2.206)	Data  2.214 ( 1.228)	Loss 5.8857e-02 (7.7912e-02) 
2023-05-26 02:10:12.535540: train Epoch: [75][ 25/129]	Time  0.987 ( 2.160)	Data  0.002 ( 1.180)	Loss 7.7421e-02 (7.7893e-02) 
2023-05-26 02:10:15.721965: train Epoch: [75][ 26/129]	Time  3.187 ( 2.198)	Data  2.222 ( 1.219)	Loss 4.7302e-02 (7.6760e-02) 
2023-05-26 02:10:16.690728: train Epoch: [75][ 27/129]	Time  0.969 ( 2.154)	Data  0.001 ( 1.175)	Loss 7.3852e-02 (7.6656e-02) 
2023-05-26 02:10:19.700711: train Epoch: [75][ 28/129]	Time  3.010 ( 2.183)	Data  2.044 ( 1.205)	Loss 7.5849e-02 (7.6628e-02) 
2023-05-26 02:10:20.670281: train Epoch: [75][ 29/129]	Time  0.970 ( 2.143)	Data  0.001 ( 1.165)	Loss 6.5657e-02 (7.6263e-02) 
2023-05-26 02:10:23.906457: train Epoch: [75][ 30/129]	Time  3.236 ( 2.178)	Data  2.271 ( 1.201)	Loss 8.3955e-02 (7.6511e-02) 
2023-05-26 02:10:24.883843: train Epoch: [75][ 31/129]	Time  0.977 ( 2.140)	Data  0.001 ( 1.163)	Loss 7.0520e-02 (7.6324e-02) 
2023-05-26 02:10:27.918923: train Epoch: [75][ 32/129]	Time  3.035 ( 2.168)	Data  2.070 ( 1.191)	Loss 7.7524e-02 (7.6360e-02) 
2023-05-26 02:10:28.891389: train Epoch: [75][ 33/129]	Time  0.972 ( 2.132)	Data  0.001 ( 1.156)	Loss 4.0125e-02 (7.5294e-02) 
2023-05-26 02:10:31.965442: train Epoch: [75][ 34/129]	Time  3.074 ( 2.159)	Data  2.092 ( 1.183)	Loss 9.0950e-02 (7.5742e-02) 
2023-05-26 02:10:32.942986: train Epoch: [75][ 35/129]	Time  0.978 ( 2.127)	Data  0.002 ( 1.150)	Loss 1.0582e-01 (7.6577e-02) 
2023-05-26 02:10:35.906368: train Epoch: [75][ 36/129]	Time  2.963 ( 2.149)	Data  1.998 ( 1.173)	Loss 1.5354e-01 (7.8657e-02) 
2023-05-26 02:10:36.884693: train Epoch: [75][ 37/129]	Time  0.978 ( 2.118)	Data  0.001 ( 1.142)	Loss 7.6189e-02 (7.8592e-02) 
2023-05-26 02:10:39.997443: train Epoch: [75][ 38/129]	Time  3.113 ( 2.144)	Data  2.152 ( 1.168)	Loss 5.7005e-02 (7.8039e-02) 
2023-05-26 02:10:40.985291: train Epoch: [75][ 39/129]	Time  0.988 ( 2.115)	Data  0.001 ( 1.139)	Loss 1.0471e-01 (7.8706e-02) 
2023-05-26 02:10:43.988260: train Epoch: [75][ 40/129]	Time  3.003 ( 2.137)	Data  2.046 ( 1.161)	Loss 1.4442e-01 (8.0308e-02) 
2023-05-26 02:10:44.957733: train Epoch: [75][ 41/129]	Time  0.969 ( 2.109)	Data  0.001 ( 1.133)	Loss 5.9165e-02 (7.9805e-02) 
2023-05-26 02:10:48.119746: train Epoch: [75][ 42/129]	Time  3.162 ( 2.133)	Data  2.190 ( 1.158)	Loss 5.6664e-02 (7.9267e-02) 
2023-05-26 02:10:49.104064: train Epoch: [75][ 43/129]	Time  0.984 ( 2.107)	Data  0.002 ( 1.132)	Loss 6.9996e-02 (7.9056e-02) 
2023-05-26 02:10:52.220210: train Epoch: [75][ 44/129]	Time  3.116 ( 2.130)	Data  2.135 ( 1.154)	Loss 3.6022e-02 (7.8100e-02) 
2023-05-26 02:10:53.210365: train Epoch: [75][ 45/129]	Time  0.990 ( 2.105)	Data  0.001 ( 1.129)	Loss 7.4903e-02 (7.8030e-02) 
2023-05-26 02:10:56.233333: train Epoch: [75][ 46/129]	Time  3.023 ( 2.124)	Data  2.050 ( 1.148)	Loss 7.1227e-02 (7.7886e-02) 
2023-05-26 02:10:57.232670: train Epoch: [75][ 47/129]	Time  0.999 ( 2.101)	Data  0.001 ( 1.124)	Loss 4.8728e-02 (7.7278e-02) 
2023-05-26 02:11:00.279184: train Epoch: [75][ 48/129]	Time  3.047 ( 2.120)	Data  2.075 ( 1.144)	Loss 8.6420e-02 (7.7465e-02) 
2023-05-26 02:11:01.264377: train Epoch: [75][ 49/129]	Time  0.985 ( 2.098)	Data  0.001 ( 1.121)	Loss 6.8999e-02 (7.7295e-02) 
2023-05-26 02:11:04.306078: train Epoch: [75][ 50/129]	Time  3.042 ( 2.116)	Data  2.061 ( 1.139)	Loss 6.7108e-02 (7.7096e-02) 
2023-05-26 02:11:05.288159: train Epoch: [75][ 51/129]	Time  0.982 ( 2.094)	Data  0.001 ( 1.118)	Loss 7.9807e-02 (7.7148e-02) 
2023-05-26 02:11:08.470991: train Epoch: [75][ 52/129]	Time  3.183 ( 2.115)	Data  2.216 ( 1.138)	Loss 5.5919e-02 (7.6747e-02) 
2023-05-26 02:11:09.450784: train Epoch: [75][ 53/129]	Time  0.980 ( 2.094)	Data  0.001 ( 1.117)	Loss 7.7117e-02 (7.6754e-02) 
2023-05-26 02:11:12.641350: train Epoch: [75][ 54/129]	Time  3.191 ( 2.114)	Data  2.231 ( 1.137)	Loss 8.3129e-02 (7.6870e-02) 
2023-05-26 02:11:13.618029: train Epoch: [75][ 55/129]	Time  0.977 ( 2.093)	Data  0.001 ( 1.117)	Loss 6.0630e-02 (7.6580e-02) 
2023-05-26 02:11:16.630114: train Epoch: [75][ 56/129]	Time  3.012 ( 2.110)	Data  2.044 ( 1.133)	Loss 4.9661e-02 (7.6108e-02) 
2023-05-26 02:11:17.603440: train Epoch: [75][ 57/129]	Time  0.973 ( 2.090)	Data  0.001 ( 1.114)	Loss 7.7914e-02 (7.6139e-02) 
2023-05-26 02:11:20.746363: train Epoch: [75][ 58/129]	Time  3.143 ( 2.108)	Data  2.178 ( 1.132)	Loss 1.2471e-01 (7.6962e-02) 
2023-05-26 02:11:21.718080: train Epoch: [75][ 59/129]	Time  0.972 ( 2.089)	Data  0.001 ( 1.113)	Loss 7.8280e-02 (7.6984e-02) 
2023-05-26 02:11:24.906185: train Epoch: [75][ 60/129]	Time  3.188 ( 2.107)	Data  2.208 ( 1.131)	Loss 4.3088e-02 (7.6428e-02) 
2023-05-26 02:11:25.885598: train Epoch: [75][ 61/129]	Time  0.979 ( 2.089)	Data  0.001 ( 1.113)	Loss 8.6047e-02 (7.6584e-02) 
2023-05-26 02:11:28.908579: train Epoch: [75][ 62/129]	Time  3.023 ( 2.103)	Data  2.059 ( 1.128)	Loss 6.6867e-02 (7.6429e-02) 
2023-05-26 02:11:29.888851: train Epoch: [75][ 63/129]	Time  0.980 ( 2.086)	Data  0.001 ( 1.110)	Loss 4.6646e-02 (7.5964e-02) 
2023-05-26 02:11:33.073435: train Epoch: [75][ 64/129]	Time  3.185 ( 2.103)	Data  2.219 ( 1.127)	Loss 9.6832e-02 (7.6285e-02) 
2023-05-26 02:11:34.043367: train Epoch: [75][ 65/129]	Time  0.970 ( 2.086)	Data  0.001 ( 1.110)	Loss 6.0397e-02 (7.6044e-02) 
2023-05-26 02:11:37.247110: train Epoch: [75][ 66/129]	Time  3.204 ( 2.102)	Data  2.234 ( 1.127)	Loss 6.4527e-02 (7.5872e-02) 
2023-05-26 02:11:38.225206: train Epoch: [75][ 67/129]	Time  0.978 ( 2.086)	Data  0.001 ( 1.110)	Loss 8.4968e-02 (7.6006e-02) 
2023-05-26 02:11:41.356540: train Epoch: [75][ 68/129]	Time  3.131 ( 2.101)	Data  2.152 ( 1.126)	Loss 4.5710e-02 (7.5567e-02) 
2023-05-26 02:11:42.331485: train Epoch: [75][ 69/129]	Time  0.975 ( 2.085)	Data  0.001 ( 1.109)	Loss 9.7680e-02 (7.5883e-02) 
2023-05-26 02:11:45.372636: train Epoch: [75][ 70/129]	Time  3.041 ( 2.098)	Data  2.074 ( 1.123)	Loss 7.1632e-02 (7.5823e-02) 
2023-05-26 02:11:46.350229: train Epoch: [75][ 71/129]	Time  0.978 ( 2.083)	Data  0.001 ( 1.107)	Loss 7.1662e-02 (7.5765e-02) 
2023-05-26 02:11:49.496300: train Epoch: [75][ 72/129]	Time  3.146 ( 2.097)	Data  2.176 ( 1.122)	Loss 3.0392e-02 (7.5144e-02) 
2023-05-26 02:11:50.491561: train Epoch: [75][ 73/129]	Time  0.995 ( 2.082)	Data  0.001 ( 1.107)	Loss 4.9530e-02 (7.4798e-02) 
2023-05-26 02:11:53.607772: train Epoch: [75][ 74/129]	Time  3.116 ( 2.096)	Data  2.140 ( 1.121)	Loss 9.0167e-02 (7.5003e-02) 
2023-05-26 02:11:54.577920: train Epoch: [75][ 75/129]	Time  0.970 ( 2.081)	Data  0.001 ( 1.106)	Loss 5.3953e-02 (7.4726e-02) 
2023-05-26 02:11:57.633959: train Epoch: [75][ 76/129]	Time  3.056 ( 2.094)	Data  2.082 ( 1.119)	Loss 5.8598e-02 (7.4516e-02) 
2023-05-26 02:11:58.630657: train Epoch: [75][ 77/129]	Time  0.997 ( 2.080)	Data  0.001 ( 1.104)	Loss 1.0577e-01 (7.4917e-02) 
2023-05-26 02:12:01.772870: train Epoch: [75][ 78/129]	Time  3.142 ( 2.093)	Data  2.172 ( 1.118)	Loss 7.9911e-02 (7.4980e-02) 
2023-05-26 02:12:02.747843: train Epoch: [75][ 79/129]	Time  0.975 ( 2.079)	Data  0.001 ( 1.104)	Loss 6.7684e-02 (7.4889e-02) 
2023-05-26 02:12:05.951831: train Epoch: [75][ 80/129]	Time  3.204 ( 2.093)	Data  2.236 ( 1.118)	Loss 7.8901e-02 (7.4938e-02) 
2023-05-26 02:12:06.926879: train Epoch: [75][ 81/129]	Time  0.975 ( 2.080)	Data  0.002 ( 1.104)	Loss 7.2326e-02 (7.4907e-02) 
2023-05-26 02:12:10.120932: train Epoch: [75][ 82/129]	Time  3.194 ( 2.093)	Data  2.225 ( 1.118)	Loss 5.0197e-02 (7.4609e-02) 
2023-05-26 02:12:11.102386: train Epoch: [75][ 83/129]	Time  0.981 ( 2.080)	Data  0.001 ( 1.104)	Loss 1.2811e-01 (7.5246e-02) 
2023-05-26 02:12:14.170491: train Epoch: [75][ 84/129]	Time  3.068 ( 2.092)	Data  2.102 ( 1.116)	Loss 5.1814e-02 (7.4970e-02) 
2023-05-26 02:12:15.152466: train Epoch: [75][ 85/129]	Time  0.982 ( 2.079)	Data  0.001 ( 1.103)	Loss 6.7630e-02 (7.4885e-02) 
2023-05-26 02:12:18.302876: train Epoch: [75][ 86/129]	Time  3.150 ( 2.091)	Data  2.191 ( 1.116)	Loss 8.4591e-02 (7.4996e-02) 
2023-05-26 02:12:19.279602: train Epoch: [75][ 87/129]	Time  0.977 ( 2.078)	Data  0.001 ( 1.103)	Loss 8.2928e-02 (7.5086e-02) 
2023-05-26 02:12:22.328135: train Epoch: [75][ 88/129]	Time  3.048 ( 2.089)	Data  2.064 ( 1.114)	Loss 6.7631e-02 (7.5003e-02) 
2023-05-26 02:12:23.310760: train Epoch: [75][ 89/129]	Time  0.983 ( 2.077)	Data  0.001 ( 1.101)	Loss 5.9723e-02 (7.4833e-02) 
2023-05-26 02:12:26.389915: train Epoch: [75][ 90/129]	Time  3.079 ( 2.088)	Data  2.093 ( 1.112)	Loss 2.8721e-01 (7.7167e-02) 
2023-05-26 02:12:27.384039: train Epoch: [75][ 91/129]	Time  0.994 ( 2.076)	Data  0.001 ( 1.100)	Loss 5.4036e-02 (7.6915e-02) 
2023-05-26 02:12:30.383563: train Epoch: [75][ 92/129]	Time  3.000 ( 2.086)	Data  2.035 ( 1.110)	Loss 1.0934e-01 (7.7264e-02) 
2023-05-26 02:12:31.366672: train Epoch: [75][ 93/129]	Time  0.983 ( 2.074)	Data  0.001 ( 1.099)	Loss 5.6674e-02 (7.7045e-02) 
2023-05-26 02:12:34.554813: train Epoch: [75][ 94/129]	Time  3.188 ( 2.086)	Data  2.209 ( 1.110)	Loss 7.3122e-02 (7.7004e-02) 
2023-05-26 02:12:35.530422: train Epoch: [75][ 95/129]	Time  0.976 ( 2.074)	Data  0.001 ( 1.099)	Loss 7.1582e-02 (7.6947e-02) 
2023-05-26 02:12:38.707469: train Epoch: [75][ 96/129]	Time  3.177 ( 2.086)	Data  2.206 ( 1.110)	Loss 6.4977e-02 (7.6824e-02) 
2023-05-26 02:12:39.698591: train Epoch: [75][ 97/129]	Time  0.991 ( 2.075)	Data  0.002 ( 1.099)	Loss 4.6705e-02 (7.6516e-02) 
2023-05-26 02:12:42.828632: train Epoch: [75][ 98/129]	Time  3.130 ( 2.085)	Data  2.139 ( 1.109)	Loss 4.9771e-02 (7.6246e-02) 
2023-05-26 02:12:43.808115: train Epoch: [75][ 99/129]	Time  0.979 ( 2.074)	Data  0.001 ( 1.098)	Loss 4.7199e-02 (7.5956e-02) 
2023-05-26 02:12:46.784545: train Epoch: [75][100/129]	Time  2.976 ( 2.083)	Data  2.006 ( 1.107)	Loss 8.5050e-02 (7.6046e-02) 
2023-05-26 02:12:47.769027: train Epoch: [75][101/129]	Time  0.984 ( 2.072)	Data  0.001 ( 1.096)	Loss 3.9348e-02 (7.5686e-02) 
2023-05-26 02:12:50.975336: train Epoch: [75][102/129]	Time  3.206 ( 2.083)	Data  2.238 ( 1.107)	Loss 6.8720e-02 (7.5618e-02) 
2023-05-26 02:12:51.950603: train Epoch: [75][103/129]	Time  0.975 ( 2.073)	Data  0.001 ( 1.097)	Loss 5.9911e-02 (7.5467e-02) 
2023-05-26 02:12:55.026768: train Epoch: [75][104/129]	Time  3.076 ( 2.082)	Data  2.109 ( 1.106)	Loss 2.6977e-02 (7.5005e-02) 
2023-05-26 02:12:56.000940: train Epoch: [75][105/129]	Time  0.974 ( 2.072)	Data  0.001 ( 1.096)	Loss 1.2539e-01 (7.5481e-02) 
2023-05-26 02:12:59.130649: train Epoch: [75][106/129]	Time  3.130 ( 2.082)	Data  2.168 ( 1.106)	Loss 6.4917e-02 (7.5382e-02) 
2023-05-26 02:13:00.114312: train Epoch: [75][107/129]	Time  0.984 ( 2.072)	Data  0.001 ( 1.096)	Loss 9.2165e-02 (7.5537e-02) 
2023-05-26 02:13:03.222454: train Epoch: [75][108/129]	Time  3.108 ( 2.081)	Data  2.139 ( 1.105)	Loss 1.1023e-01 (7.5856e-02) 
2023-05-26 02:13:04.215452: train Epoch: [75][109/129]	Time  0.993 ( 2.071)	Data  0.001 ( 1.095)	Loss 5.8528e-02 (7.5698e-02) 
2023-05-26 02:13:07.492321: train Epoch: [75][110/129]	Time  3.277 ( 2.082)	Data  2.298 ( 1.106)	Loss 9.3605e-02 (7.5860e-02) 
2023-05-26 02:13:08.462869: train Epoch: [75][111/129]	Time  0.971 ( 2.072)	Data  0.001 ( 1.096)	Loss 5.7377e-02 (7.5695e-02) 
2023-05-26 02:13:11.516931: train Epoch: [75][112/129]	Time  3.054 ( 2.081)	Data  2.082 ( 1.105)	Loss 5.2076e-02 (7.5486e-02) 
2023-05-26 02:13:12.492152: train Epoch: [75][113/129]	Time  0.975 ( 2.071)	Data  0.001 ( 1.095)	Loss 6.2893e-02 (7.5375e-02) 
2023-05-26 02:13:15.487399: train Epoch: [75][114/129]	Time  2.995 ( 2.079)	Data  2.026 ( 1.103)	Loss 6.4920e-02 (7.5284e-02) 
2023-05-26 02:13:16.469671: train Epoch: [75][115/129]	Time  0.982 ( 2.070)	Data  0.002 ( 1.094)	Loss 5.9001e-02 (7.5144e-02) 
2023-05-26 02:13:19.635142: train Epoch: [75][116/129]	Time  3.165 ( 2.079)	Data  2.192 ( 1.103)	Loss 5.2596e-02 (7.4951e-02) 
2023-05-26 02:13:20.617980: train Epoch: [75][117/129]	Time  0.983 ( 2.070)	Data  0.001 ( 1.094)	Loss 7.3036e-02 (7.4935e-02) 
2023-05-26 02:13:23.762469: train Epoch: [75][118/129]	Time  3.145 ( 2.079)	Data  2.178 ( 1.103)	Loss 6.1641e-02 (7.4823e-02) 
2023-05-26 02:13:24.743667: train Epoch: [75][119/129]	Time  0.981 ( 2.070)	Data  0.001 ( 1.094)	Loss 8.1104e-02 (7.4875e-02) 
2023-05-26 02:13:27.814821: train Epoch: [75][120/129]	Time  3.071 ( 2.078)	Data  2.102 ( 1.102)	Loss 7.7390e-02 (7.4896e-02) 
2023-05-26 02:13:28.782728: train Epoch: [75][121/129]	Time  0.968 ( 2.069)	Data  0.001 ( 1.093)	Loss 7.8878e-02 (7.4929e-02) 
2023-05-26 02:13:31.817841: train Epoch: [75][122/129]	Time  3.035 ( 2.077)	Data  2.067 ( 1.101)	Loss 4.9892e-02 (7.4725e-02) 
2023-05-26 02:13:32.798125: train Epoch: [75][123/129]	Time  0.980 ( 2.068)	Data  0.001 ( 1.092)	Loss 9.9556e-02 (7.4926e-02) 
2023-05-26 02:13:35.884836: train Epoch: [75][124/129]	Time  3.087 ( 2.076)	Data  2.115 ( 1.100)	Loss 2.8351e-02 (7.4553e-02) 
2023-05-26 02:13:36.872652: train Epoch: [75][125/129]	Time  0.988 ( 2.067)	Data  0.001 ( 1.092)	Loss 6.3626e-02 (7.4466e-02) 
2023-05-26 02:13:39.873520: train Epoch: [75][126/129]	Time  3.001 ( 2.075)	Data  2.019 ( 1.099)	Loss 1.0405e-01 (7.4699e-02) 
2023-05-26 02:13:40.841285: train Epoch: [75][127/129]	Time  0.968 ( 2.066)	Data  0.001 ( 1.090)	Loss 8.3645e-02 (7.4769e-02) 
2023-05-26 02:13:43.050396: train Epoch: [75][128/129]	Time  2.209 ( 2.067)	Data  1.240 ( 1.092)	Loss 8.5014e-02 (7.4849e-02) 
2023-05-26 02:13:43.150784: Train Epoch done in 266.7636046359985 s 
2023-05-26 02:13:46.061034: val Epoch: [75][ 0/72]	Time  1.916 ( 1.916)	Data  1.698 ( 1.698)	Loss 2.8103e-01 (2.8103e-01) 
2023-05-26 02:13:46.191902: val Epoch: [75][ 1/72]	Time  0.131 ( 1.023)	Data  0.002 ( 0.850)	Loss 4.5814e-02 (1.6342e-01) 
2023-05-26 02:13:47.368578: val Epoch: [75][ 2/72]	Time  1.177 ( 1.074)	Data  1.047 ( 0.916)	Loss 2.2197e-01 (1.8294e-01) 
2023-05-26 02:13:47.497989: val Epoch: [75][ 3/72]	Time  0.129 ( 0.838)	Data  0.001 ( 0.687)	Loss 1.0688e-01 (1.6392e-01) 
2023-05-26 02:13:48.832845: val Epoch: [75][ 4/72]	Time  1.335 ( 0.938)	Data  1.206 ( 0.791)	Loss 3.2806e-01 (1.9675e-01) 
2023-05-26 02:13:48.963315: val Epoch: [75][ 5/72]	Time  0.130 ( 0.803)	Data  0.001 ( 0.659)	Loss 5.1469e-02 (1.7254e-01) 
2023-05-26 02:13:50.249734: val Epoch: [75][ 6/72]	Time  1.286 ( 0.872)	Data  1.160 ( 0.731)	Loss 3.0560e-01 (1.9155e-01) 
2023-05-26 02:13:50.383278: val Epoch: [75][ 7/72]	Time  0.134 ( 0.780)	Data  0.001 ( 0.639)	Loss 8.0144e-02 (1.7762e-01) 
2023-05-26 02:13:51.679886: val Epoch: [75][ 8/72]	Time  1.297 ( 0.837)	Data  1.165 ( 0.698)	Loss 7.2185e-02 (1.6591e-01) 
2023-05-26 02:13:51.814872: val Epoch: [75][ 9/72]	Time  0.135 ( 0.767)	Data  0.001 ( 0.628)	Loss 6.2371e-02 (1.5555e-01) 
2023-05-26 02:13:53.039799: val Epoch: [75][10/72]	Time  1.225 ( 0.809)	Data  1.094 ( 0.670)	Loss 6.8976e-02 (1.4768e-01) 
2023-05-26 02:13:53.157313: val Epoch: [75][11/72]	Time  0.118 ( 0.751)	Data  0.001 ( 0.615)	Loss 3.9496e-02 (1.3867e-01) 
2023-05-26 02:13:54.299754: val Epoch: [75][12/72]	Time  1.142 ( 0.781)	Data  1.025 ( 0.646)	Loss 5.0621e-02 (1.3189e-01) 
2023-05-26 02:13:54.417145: val Epoch: [75][13/72]	Time  0.117 ( 0.734)	Data  0.000 ( 0.600)	Loss 4.5370e-02 (1.2571e-01) 
2023-05-26 02:13:55.532620: val Epoch: [75][14/72]	Time  1.115 ( 0.759)	Data  0.991 ( 0.626)	Loss 6.1553e-02 (1.2144e-01) 
2023-05-26 02:13:55.656971: val Epoch: [75][15/72]	Time  0.124 ( 0.719)	Data  0.001 ( 0.587)	Loss 7.2500e-02 (1.1838e-01) 
2023-05-26 02:13:56.803628: val Epoch: [75][16/72]	Time  1.147 ( 0.745)	Data  1.028 ( 0.613)	Loss 4.3093e-02 (1.1395e-01) 
2023-05-26 02:13:56.923452: val Epoch: [75][17/72]	Time  0.120 ( 0.710)	Data  0.001 ( 0.579)	Loss 8.6696e-02 (1.1243e-01) 
2023-05-26 02:13:58.095586: val Epoch: [75][18/72]	Time  1.172 ( 0.734)	Data  1.053 ( 0.604)	Loss 8.3854e-02 (1.1093e-01) 
2023-05-26 02:13:58.218802: val Epoch: [75][19/72]	Time  0.123 ( 0.704)	Data  0.000 ( 0.574)	Loss 4.1446e-01 (1.2611e-01) 
2023-05-26 02:13:59.350520: val Epoch: [75][20/72]	Time  1.132 ( 0.724)	Data  1.013 ( 0.595)	Loss 5.5670e-02 (1.2275e-01) 
2023-05-26 02:13:59.471992: val Epoch: [75][21/72]	Time  0.121 ( 0.697)	Data  0.001 ( 0.568)	Loss 1.2845e-01 (1.2301e-01) 
2023-05-26 02:14:00.621606: val Epoch: [75][22/72]	Time  1.150 ( 0.716)	Data  1.029 ( 0.588)	Loss 2.9659e-02 (1.1895e-01) 
2023-05-26 02:14:00.740884: val Epoch: [75][23/72]	Time  0.119 ( 0.691)	Data  0.001 ( 0.563)	Loss 6.7155e-02 (1.1680e-01) 
2023-05-26 02:14:01.861368: val Epoch: [75][24/72]	Time  1.120 ( 0.709)	Data  0.998 ( 0.581)	Loss 3.4078e-02 (1.1349e-01) 
2023-05-26 02:14:01.984747: val Epoch: [75][25/72]	Time  0.123 ( 0.686)	Data  0.001 ( 0.558)	Loss 3.4018e-02 (1.1043e-01) 
2023-05-26 02:14:03.100840: val Epoch: [75][26/72]	Time  1.116 ( 0.702)	Data  0.993 ( 0.574)	Loss 4.4020e-02 (1.0797e-01) 
2023-05-26 02:14:03.224227: val Epoch: [75][27/72]	Time  0.123 ( 0.681)	Data  0.001 ( 0.554)	Loss 1.2215e-01 (1.0848e-01) 
2023-05-26 02:14:04.308573: val Epoch: [75][28/72]	Time  1.084 ( 0.695)	Data  0.963 ( 0.568)	Loss 1.0288e-01 (1.0828e-01) 
2023-05-26 02:14:04.429388: val Epoch: [75][29/72]	Time  0.121 ( 0.676)	Data  0.001 ( 0.549)	Loss 7.8992e-02 (1.0731e-01) 
2023-05-26 02:14:05.558842: val Epoch: [75][30/72]	Time  1.129 ( 0.691)	Data  1.012 ( 0.564)	Loss 1.3080e-01 (1.0807e-01) 
2023-05-26 02:14:05.676140: val Epoch: [75][31/72]	Time  0.117 ( 0.673)	Data  0.000 ( 0.546)	Loss 4.9105e-02 (1.0622e-01) 
2023-05-26 02:14:06.773282: val Epoch: [75][32/72]	Time  1.097 ( 0.686)	Data  0.979 ( 0.560)	Loss 5.1246e-02 (1.0456e-01) 
2023-05-26 02:14:06.890661: val Epoch: [75][33/72]	Time  0.117 ( 0.669)	Data  0.000 ( 0.543)	Loss 2.6797e-01 (1.0936e-01) 
2023-05-26 02:14:08.008127: val Epoch: [75][34/72]	Time  1.117 ( 0.682)	Data  1.000 ( 0.556)	Loss 3.7565e-01 (1.1697e-01) 
2023-05-26 02:14:08.125712: val Epoch: [75][35/72]	Time  0.118 ( 0.666)	Data  0.001 ( 0.541)	Loss 9.4058e-02 (1.1633e-01) 
2023-05-26 02:14:09.268311: val Epoch: [75][36/72]	Time  1.143 ( 0.679)	Data  1.025 ( 0.554)	Loss 9.1770e-02 (1.1567e-01) 
2023-05-26 02:14:09.385582: val Epoch: [75][37/72]	Time  0.117 ( 0.664)	Data  0.000 ( 0.539)	Loss 1.2255e-01 (1.1585e-01) 
2023-05-26 02:14:10.505023: val Epoch: [75][38/72]	Time  1.119 ( 0.676)	Data  1.002 ( 0.551)	Loss 9.4240e-02 (1.1530e-01) 
2023-05-26 02:14:10.621175: val Epoch: [75][39/72]	Time  0.116 ( 0.662)	Data  0.000 ( 0.537)	Loss 1.2938e-01 (1.1565e-01) 
2023-05-26 02:14:11.696408: val Epoch: [75][40/72]	Time  1.075 ( 0.672)	Data  0.959 ( 0.548)	Loss 3.7791e-02 (1.1375e-01) 
2023-05-26 02:14:11.812696: val Epoch: [75][41/72]	Time  0.116 ( 0.659)	Data  0.000 ( 0.535)	Loss 9.1048e-02 (1.1321e-01) 
2023-05-26 02:14:12.945325: val Epoch: [75][42/72]	Time  1.133 ( 0.670)	Data  1.015 ( 0.546)	Loss 3.1659e-01 (1.1794e-01) 
2023-05-26 02:14:13.062199: val Epoch: [75][43/72]	Time  0.117 ( 0.657)	Data  0.000 ( 0.533)	Loss 5.5561e-02 (1.1652e-01) 
2023-05-26 02:14:14.145721: val Epoch: [75][44/72]	Time  1.084 ( 0.667)	Data  0.966 ( 0.543)	Loss 5.5647e-02 (1.1517e-01) 
2023-05-26 02:14:14.262594: val Epoch: [75][45/72]	Time  0.117 ( 0.655)	Data  0.000 ( 0.531)	Loss 3.7615e-01 (1.2084e-01) 
2023-05-26 02:14:15.399306: val Epoch: [75][46/72]	Time  1.137 ( 0.665)	Data  1.019 ( 0.542)	Loss 3.6869e-01 (1.2612e-01) 
2023-05-26 02:14:15.515481: val Epoch: [75][47/72]	Time  0.116 ( 0.654)	Data  0.000 ( 0.530)	Loss 7.6398e-02 (1.2508e-01) 
2023-05-26 02:14:16.596600: val Epoch: [75][48/72]	Time  1.081 ( 0.662)	Data  0.964 ( 0.539)	Loss 3.4011e-02 (1.2322e-01) 
2023-05-26 02:14:16.712914: val Epoch: [75][49/72]	Time  0.116 ( 0.651)	Data  0.000 ( 0.528)	Loss 7.3333e-02 (1.2222e-01) 
2023-05-26 02:14:17.878024: val Epoch: [75][50/72]	Time  1.165 ( 0.661)	Data  1.048 ( 0.539)	Loss 1.6572e-01 (1.2308e-01) 
2023-05-26 02:14:17.995584: val Epoch: [75][51/72]	Time  0.118 ( 0.651)	Data  0.000 ( 0.528)	Loss 2.0890e-01 (1.2473e-01) 
2023-05-26 02:14:19.112101: val Epoch: [75][52/72]	Time  1.116 ( 0.660)	Data  1.000 ( 0.537)	Loss 5.8108e-02 (1.2347e-01) 
2023-05-26 02:14:19.229117: val Epoch: [75][53/72]	Time  0.117 ( 0.650)	Data  0.000 ( 0.527)	Loss 3.7375e-02 (1.2188e-01) 
2023-05-26 02:14:20.350757: val Epoch: [75][54/72]	Time  1.122 ( 0.658)	Data  1.004 ( 0.536)	Loss 8.9169e-02 (1.2128e-01) 
2023-05-26 02:14:20.468305: val Epoch: [75][55/72]	Time  0.118 ( 0.649)	Data  0.001 ( 0.526)	Loss 4.2174e-02 (1.1987e-01) 
2023-05-26 02:14:21.572710: val Epoch: [75][56/72]	Time  1.104 ( 0.657)	Data  0.987 ( 0.534)	Loss 1.8552e-01 (1.2102e-01) 
2023-05-26 02:14:21.690557: val Epoch: [75][57/72]	Time  0.118 ( 0.647)	Data  0.000 ( 0.525)	Loss 5.5596e-02 (1.1989e-01) 
2023-05-26 02:14:22.783430: val Epoch: [75][58/72]	Time  1.093 ( 0.655)	Data  0.975 ( 0.533)	Loss 5.9873e-02 (1.1888e-01) 
2023-05-26 02:14:22.900512: val Epoch: [75][59/72]	Time  0.117 ( 0.646)	Data  0.000 ( 0.524)	Loss 5.7403e-02 (1.1785e-01) 
2023-05-26 02:14:24.027884: val Epoch: [75][60/72]	Time  1.127 ( 0.654)	Data  1.010 ( 0.532)	Loss 4.5923e-02 (1.1667e-01) 
2023-05-26 02:14:24.144986: val Epoch: [75][61/72]	Time  0.117 ( 0.645)	Data  0.000 ( 0.523)	Loss 6.9619e-02 (1.1591e-01) 
2023-05-26 02:14:25.267445: val Epoch: [75][62/72]	Time  1.122 ( 0.653)	Data  1.004 ( 0.531)	Loss 9.7583e-02 (1.1562e-01) 
2023-05-26 02:14:25.384334: val Epoch: [75][63/72]	Time  0.117 ( 0.644)	Data  0.000 ( 0.523)	Loss 1.4057e-01 (1.1601e-01) 
2023-05-26 02:14:26.512731: val Epoch: [75][64/72]	Time  1.128 ( 0.652)	Data  1.011 ( 0.530)	Loss 6.4950e-02 (1.1523e-01) 
2023-05-26 02:14:26.629868: val Epoch: [75][65/72]	Time  0.117 ( 0.644)	Data  0.000 ( 0.522)	Loss 2.2264e-01 (1.1685e-01) 
2023-05-26 02:14:27.766180: val Epoch: [75][66/72]	Time  1.136 ( 0.651)	Data  1.018 ( 0.530)	Loss 2.1698e-01 (1.1835e-01) 
2023-05-26 02:14:27.884672: val Epoch: [75][67/72]	Time  0.118 ( 0.643)	Data  0.001 ( 0.522)	Loss 5.8560e-02 (1.1747e-01) 
2023-05-26 02:14:28.979726: val Epoch: [75][68/72]	Time  1.095 ( 0.650)	Data  0.977 ( 0.528)	Loss 4.8691e-02 (1.1647e-01) 
2023-05-26 02:14:29.097446: val Epoch: [75][69/72]	Time  0.118 ( 0.642)	Data  0.000 ( 0.521)	Loss 3.8173e-02 (1.1535e-01) 
2023-05-26 02:14:30.098172: val Epoch: [75][70/72]	Time  1.001 ( 0.647)	Data  0.883 ( 0.526)	Loss 4.8379e-02 (1.1441e-01) 
2023-05-26 02:14:30.215768: val Epoch: [75][71/72]	Time  0.118 ( 0.640)	Data  0.000 ( 0.519)	Loss 1.1069e-01 (1.1436e-01) 
2023-05-26 02:14:30.379286: Epoch 75 :Val : ['ET : 0.7520933151245117', 'TC : 0.8106882572174072', 'WT : 0.8865664601325989'] 
2023-05-26 02:14:30.383759: Epoch 75 :Val : ['ET : 0.7520933151245117', 'TC : 0.8106882572174072', 'WT : 0.8865664601325989'] 
2023-05-26 02:14:30.386813: Saving the model with DSC 0.8235912919044495 
2023-05-26 02:14:31.121643: Val epoch done in 47.97085134400186 s 
2023-05-26 02:14:31.127334: Batches per epoch:  129 
2023-05-26 02:14:36.650731: train Epoch: [76][  0/129]	Time  5.523 ( 5.523)	Data  4.474 ( 4.474)	Loss 5.1896e-02 (5.1896e-02) 
2023-05-26 02:14:37.625447: train Epoch: [76][  1/129]	Time  0.975 ( 3.249)	Data  0.001 ( 2.238)	Loss 5.0012e-02 (5.0954e-02) 
2023-05-26 02:14:40.759178: train Epoch: [76][  2/129]	Time  3.134 ( 3.211)	Data  2.150 ( 2.208)	Loss 5.9938e-02 (5.3949e-02) 
2023-05-26 02:14:41.732588: train Epoch: [76][  3/129]	Time  0.973 ( 2.651)	Data  0.001 ( 1.657)	Loss 4.7511e-02 (5.2339e-02) 
2023-05-26 02:14:44.659971: train Epoch: [76][  4/129]	Time  2.927 ( 2.706)	Data  1.940 ( 1.713)	Loss 6.7985e-02 (5.5468e-02) 
2023-05-26 02:14:45.634021: train Epoch: [76][  5/129]	Time  0.974 ( 2.418)	Data  0.001 ( 1.428)	Loss 4.1724e-02 (5.3178e-02) 
2023-05-26 02:14:48.601787: train Epoch: [76][  6/129]	Time  2.968 ( 2.496)	Data  1.981 ( 1.507)	Loss 7.4062e-02 (5.6161e-02) 
2023-05-26 02:14:49.589098: train Epoch: [76][  7/129]	Time  0.987 ( 2.308)	Data  0.003 ( 1.319)	Loss 7.7725e-02 (5.8857e-02) 
2023-05-26 02:14:52.653920: train Epoch: [76][  8/129]	Time  3.065 ( 2.392)	Data  2.086 ( 1.404)	Loss 7.9094e-02 (6.1105e-02) 
2023-05-26 02:14:53.629457: train Epoch: [76][  9/129]	Time  0.976 ( 2.250)	Data  0.002 ( 1.264)	Loss 6.1499e-02 (6.1145e-02) 
2023-05-26 02:14:56.578970: train Epoch: [76][ 10/129]	Time  2.949 ( 2.314)	Data  1.967 ( 1.328)	Loss 4.6734e-02 (5.9835e-02) 
2023-05-26 02:14:57.554883: train Epoch: [76][ 11/129]	Time  0.976 ( 2.202)	Data  0.001 ( 1.217)	Loss 7.3860e-02 (6.1003e-02) 
2023-05-26 02:15:00.757854: train Epoch: [76][ 12/129]	Time  3.203 ( 2.279)	Data  2.219 ( 1.294)	Loss 8.9367e-02 (6.3185e-02) 
2023-05-26 02:15:01.738068: train Epoch: [76][ 13/129]	Time  0.980 ( 2.186)	Data  0.001 ( 1.202)	Loss 5.7683e-02 (6.2792e-02) 
2023-05-26 02:15:04.831094: train Epoch: [76][ 14/129]	Time  3.093 ( 2.247)	Data  2.119 ( 1.263)	Loss 6.6604e-02 (6.3046e-02) 
2023-05-26 02:15:05.794940: train Epoch: [76][ 15/129]	Time  0.964 ( 2.167)	Data  0.001 ( 1.184)	Loss 7.8481e-02 (6.4011e-02) 
2023-05-26 02:15:09.003490: train Epoch: [76][ 16/129]	Time  3.209 ( 2.228)	Data  2.238 ( 1.246)	Loss 1.0474e-01 (6.6407e-02) 
2023-05-26 02:15:09.977772: train Epoch: [76][ 17/129]	Time  0.974 ( 2.158)	Data  0.002 ( 1.177)	Loss 5.6436e-02 (6.5853e-02) 
2023-05-26 02:15:13.015195: train Epoch: [76][ 18/129]	Time  3.037 ( 2.205)	Data  2.052 ( 1.223)	Loss 4.1696e-02 (6.4581e-02) 
2023-05-26 02:15:14.003931: train Epoch: [76][ 19/129]	Time  0.989 ( 2.144)	Data  0.001 ( 1.162)	Loss 4.7906e-02 (6.3748e-02) 
2023-05-26 02:15:17.232846: train Epoch: [76][ 20/129]	Time  3.229 ( 2.195)	Data  2.254 ( 1.214)	Loss 5.4534e-02 (6.3309e-02) 
2023-05-26 02:15:18.208568: train Epoch: [76][ 21/129]	Time  0.976 ( 2.140)	Data  0.001 ( 1.159)	Loss 6.0558e-02 (6.3184e-02) 
2023-05-26 02:15:21.218463: train Epoch: [76][ 22/129]	Time  3.010 ( 2.178)	Data  2.027 ( 1.197)	Loss 4.2301e-02 (6.2276e-02) 
2023-05-26 02:15:22.198142: train Epoch: [76][ 23/129]	Time  0.980 ( 2.128)	Data  0.001 ( 1.147)	Loss 3.3630e-02 (6.1082e-02) 
2023-05-26 02:15:25.263217: train Epoch: [76][ 24/129]	Time  3.065 ( 2.165)	Data  2.091 ( 1.185)	Loss 6.0661e-02 (6.1065e-02) 
2023-05-26 02:15:26.241691: train Epoch: [76][ 25/129]	Time  0.978 ( 2.120)	Data  0.001 ( 1.139)	Loss 5.8955e-02 (6.0984e-02) 
2023-05-26 02:15:29.320529: train Epoch: [76][ 26/129]	Time  3.079 ( 2.155)	Data  2.092 ( 1.174)	Loss 8.1830e-02 (6.1756e-02) 
2023-05-26 02:15:30.315678: train Epoch: [76][ 27/129]	Time  0.995 ( 2.114)	Data  0.002 ( 1.133)	Loss 5.6504e-02 (6.1569e-02) 
2023-05-26 02:15:33.515211: train Epoch: [76][ 28/129]	Time  3.200 ( 2.151)	Data  2.203 ( 1.169)	Loss 5.5232e-02 (6.1350e-02) 
2023-05-26 02:15:34.496218: train Epoch: [76][ 29/129]	Time  0.981 ( 2.112)	Data  0.001 ( 1.131)	Loss 1.1933e-01 (6.3283e-02) 
2023-05-26 02:15:37.555552: train Epoch: [76][ 30/129]	Time  3.059 ( 2.143)	Data  2.076 ( 1.161)	Loss 7.4631e-02 (6.3649e-02) 
2023-05-26 02:15:38.541103: train Epoch: [76][ 31/129]	Time  0.986 ( 2.107)	Data  0.001 ( 1.125)	Loss 6.0939e-02 (6.3564e-02) 
2023-05-26 02:15:41.596380: train Epoch: [76][ 32/129]	Time  3.055 ( 2.135)	Data  2.081 ( 1.154)	Loss 7.0112e-02 (6.3763e-02) 
2023-05-26 02:15:42.582145: train Epoch: [76][ 33/129]	Time  0.986 ( 2.102)	Data  0.001 ( 1.120)	Loss 6.5036e-02 (6.3800e-02) 
2023-05-26 02:15:45.621722: train Epoch: [76][ 34/129]	Time  3.040 ( 2.128)	Data  2.049 ( 1.146)	Loss 1.1664e-01 (6.5310e-02) 
2023-05-26 02:15:46.597178: train Epoch: [76][ 35/129]	Time  0.975 ( 2.096)	Data  0.001 ( 1.115)	Loss 1.2259e-01 (6.6901e-02) 
2023-05-26 02:15:49.649068: train Epoch: [76][ 36/129]	Time  3.052 ( 2.122)	Data  2.069 ( 1.140)	Loss 4.6899e-02 (6.6360e-02) 
2023-05-26 02:15:50.638209: train Epoch: [76][ 37/129]	Time  0.989 ( 2.092)	Data  0.001 ( 1.110)	Loss 7.2636e-02 (6.6525e-02) 
2023-05-26 02:15:53.778325: train Epoch: [76][ 38/129]	Time  3.140 ( 2.119)	Data  2.168 ( 1.138)	Loss 5.5151e-02 (6.6234e-02) 
2023-05-26 02:15:54.747876: train Epoch: [76][ 39/129]	Time  0.970 ( 2.091)	Data  0.001 ( 1.109)	Loss 5.6838e-02 (6.5999e-02) 
2023-05-26 02:15:57.958833: train Epoch: [76][ 40/129]	Time  3.211 ( 2.118)	Data  2.239 ( 1.137)	Loss 1.2070e-01 (6.7333e-02) 
2023-05-26 02:15:58.932382: train Epoch: [76][ 41/129]	Time  0.974 ( 2.091)	Data  0.001 ( 1.110)	Loss 1.0788e-01 (6.8298e-02) 
2023-05-26 02:16:02.217455: train Epoch: [76][ 42/129]	Time  3.285 ( 2.118)	Data  2.307 ( 1.137)	Loss 5.7633e-02 (6.8050e-02) 
2023-05-26 02:16:03.206949: train Epoch: [76][ 43/129]	Time  0.990 ( 2.093)	Data  0.002 ( 1.112)	Loss 1.0040e-01 (6.8786e-02) 
2023-05-26 02:16:06.403643: train Epoch: [76][ 44/129]	Time  3.197 ( 2.117)	Data  2.223 ( 1.136)	Loss 5.7944e-02 (6.8545e-02) 
2023-05-26 02:16:07.377881: train Epoch: [76][ 45/129]	Time  0.974 ( 2.092)	Data  0.001 ( 1.112)	Loss 8.5616e-02 (6.8916e-02) 
2023-05-26 02:16:10.593615: train Epoch: [76][ 46/129]	Time  3.216 ( 2.116)	Data  2.220 ( 1.135)	Loss 4.4484e-02 (6.8396e-02) 
2023-05-26 02:16:11.577066: train Epoch: [76][ 47/129]	Time  0.983 ( 2.093)	Data  0.001 ( 1.112)	Loss 6.2360e-02 (6.8270e-02) 
2023-05-26 02:16:14.705470: train Epoch: [76][ 48/129]	Time  3.128 ( 2.114)	Data  2.148 ( 1.133)	Loss 6.0450e-02 (6.8111e-02) 
2023-05-26 02:16:15.679700: train Epoch: [76][ 49/129]	Time  0.974 ( 2.091)	Data  0.001 ( 1.110)	Loss 7.6998e-02 (6.8288e-02) 
2023-05-26 02:16:19.000749: train Epoch: [76][ 50/129]	Time  3.321 ( 2.115)	Data  2.344 ( 1.134)	Loss 9.1477e-02 (6.8743e-02) 
2023-05-26 02:16:19.967350: train Epoch: [76][ 51/129]	Time  0.967 ( 2.093)	Data  0.002 ( 1.113)	Loss 5.7351e-02 (6.8524e-02) 
2023-05-26 02:16:23.217760: train Epoch: [76][ 52/129]	Time  3.250 ( 2.115)	Data  2.263 ( 1.134)	Loss 7.0343e-02 (6.8558e-02) 
2023-05-26 02:16:24.192000: train Epoch: [76][ 53/129]	Time  0.974 ( 2.094)	Data  0.001 ( 1.113)	Loss 1.0913e-01 (6.9310e-02) 
2023-05-26 02:16:27.363189: train Epoch: [76][ 54/129]	Time  3.171 ( 2.113)	Data  2.182 ( 1.133)	Loss 5.8534e-02 (6.9114e-02) 
2023-05-26 02:16:28.344837: train Epoch: [76][ 55/129]	Time  0.982 ( 2.093)	Data  0.001 ( 1.113)	Loss 8.4321e-02 (6.9385e-02) 
2023-05-26 02:16:31.509001: train Epoch: [76][ 56/129]	Time  3.164 ( 2.112)	Data  2.192 ( 1.131)	Loss 5.6379e-02 (6.9157e-02) 
2023-05-26 02:16:32.483086: train Epoch: [76][ 57/129]	Time  0.974 ( 2.092)	Data  0.001 ( 1.112)	Loss 8.7300e-02 (6.9470e-02) 
2023-05-26 02:16:35.643495: train Epoch: [76][ 58/129]	Time  3.160 ( 2.110)	Data  2.189 ( 1.130)	Loss 1.0137e-01 (7.0011e-02) 
2023-05-26 02:16:36.617647: train Epoch: [76][ 59/129]	Time  0.974 ( 2.091)	Data  0.001 ( 1.111)	Loss 5.5715e-02 (6.9772e-02) 
2023-05-26 02:16:39.825938: train Epoch: [76][ 60/129]	Time  3.208 ( 2.110)	Data  2.240 ( 1.130)	Loss 1.0887e-01 (7.0413e-02) 
2023-05-26 02:16:40.802099: train Epoch: [76][ 61/129]	Time  0.976 ( 2.092)	Data  0.001 ( 1.112)	Loss 4.9508e-02 (7.0076e-02) 
2023-05-26 02:16:44.016460: train Epoch: [76][ 62/129]	Time  3.214 ( 2.109)	Data  2.232 ( 1.129)	Loss 6.7199e-02 (7.0030e-02) 
2023-05-26 02:16:44.989391: train Epoch: [76][ 63/129]	Time  0.973 ( 2.092)	Data  0.001 ( 1.112)	Loss 1.0299e-01 (7.0545e-02) 
2023-05-26 02:16:48.120790: train Epoch: [76][ 64/129]	Time  3.131 ( 2.108)	Data  2.138 ( 1.128)	Loss 5.5824e-02 (7.0319e-02) 
2023-05-26 02:16:49.103806: train Epoch: [76][ 65/129]	Time  0.983 ( 2.091)	Data  0.001 ( 1.111)	Loss 7.8825e-02 (7.0448e-02) 
2023-05-26 02:16:52.198664: train Epoch: [76][ 66/129]	Time  3.095 ( 2.106)	Data  2.113 ( 1.126)	Loss 4.7109e-02 (7.0099e-02) 
2023-05-26 02:16:53.187605: train Epoch: [76][ 67/129]	Time  0.989 ( 2.089)	Data  0.002 ( 1.109)	Loss 4.6683e-02 (6.9755e-02) 
2023-05-26 02:16:56.251885: train Epoch: [76][ 68/129]	Time  3.064 ( 2.103)	Data  2.101 ( 1.123)	Loss 7.2591e-02 (6.9796e-02) 
2023-05-26 02:16:57.237173: train Epoch: [76][ 69/129]	Time  0.985 ( 2.087)	Data  0.001 ( 1.107)	Loss 6.0155e-02 (6.9658e-02) 
2023-05-26 02:17:00.294380: train Epoch: [76][ 70/129]	Time  3.057 ( 2.101)	Data  2.082 ( 1.121)	Loss 5.7186e-02 (6.9483e-02) 
2023-05-26 02:17:01.269115: train Epoch: [76][ 71/129]	Time  0.975 ( 2.085)	Data  0.001 ( 1.106)	Loss 6.5773e-02 (6.9431e-02) 
2023-05-26 02:17:04.263463: train Epoch: [76][ 72/129]	Time  2.994 ( 2.098)	Data  2.020 ( 1.118)	Loss 6.3515e-02 (6.9350e-02) 
2023-05-26 02:17:05.229161: train Epoch: [76][ 73/129]	Time  0.966 ( 2.082)	Data  0.002 ( 1.103)	Loss 6.7666e-02 (6.9327e-02) 
2023-05-26 02:17:08.404645: train Epoch: [76][ 74/129]	Time  3.175 ( 2.097)	Data  2.204 ( 1.118)	Loss 9.3177e-02 (6.9645e-02) 
2023-05-26 02:17:09.379835: train Epoch: [76][ 75/129]	Time  0.975 ( 2.082)	Data  0.001 ( 1.103)	Loss 5.4642e-02 (6.9448e-02) 
2023-05-26 02:17:12.493578: train Epoch: [76][ 76/129]	Time  3.114 ( 2.096)	Data  2.143 ( 1.116)	Loss 8.8670e-02 (6.9698e-02) 
2023-05-26 02:17:13.467208: train Epoch: [76][ 77/129]	Time  0.974 ( 2.081)	Data  0.001 ( 1.102)	Loss 8.7889e-02 (6.9931e-02) 
2023-05-26 02:17:16.504154: train Epoch: [76][ 78/129]	Time  3.037 ( 2.093)	Data  2.058 ( 1.114)	Loss 5.4378e-02 (6.9734e-02) 
2023-05-26 02:17:17.475684: train Epoch: [76][ 79/129]	Time  0.972 ( 2.079)	Data  0.001 ( 1.100)	Loss 6.1893e-02 (6.9636e-02) 
2023-05-26 02:17:20.616734: train Epoch: [76][ 80/129]	Time  3.141 ( 2.092)	Data  2.170 ( 1.114)	Loss 6.6064e-02 (6.9592e-02) 
2023-05-26 02:17:21.584530: train Epoch: [76][ 81/129]	Time  0.968 ( 2.079)	Data  0.001 ( 1.100)	Loss 7.9806e-02 (6.9716e-02) 
2023-05-26 02:17:24.702060: train Epoch: [76][ 82/129]	Time  3.118 ( 2.091)	Data  2.151 ( 1.113)	Loss 6.0905e-02 (6.9610e-02) 
2023-05-26 02:17:25.669434: train Epoch: [76][ 83/129]	Time  0.967 ( 2.078)	Data  0.001 ( 1.099)	Loss 3.3602e-02 (6.9182e-02) 
2023-05-26 02:17:28.770378: train Epoch: [76][ 84/129]	Time  3.101 ( 2.090)	Data  2.127 ( 1.112)	Loss 1.0220e-01 (6.9570e-02) 
2023-05-26 02:17:29.742659: train Epoch: [76][ 85/129]	Time  0.972 ( 2.077)	Data  0.001 ( 1.099)	Loss 9.2545e-02 (6.9837e-02) 
2023-05-26 02:17:32.969887: train Epoch: [76][ 86/129]	Time  3.227 ( 2.090)	Data  2.244 ( 1.112)	Loss 6.0887e-02 (6.9734e-02) 
2023-05-26 02:17:33.959794: train Epoch: [76][ 87/129]	Time  0.990 ( 2.078)	Data  0.001 ( 1.099)	Loss 7.0842e-02 (6.9747e-02) 
2023-05-26 02:17:37.007067: train Epoch: [76][ 88/129]	Time  3.047 ( 2.089)	Data  2.080 ( 1.110)	Loss 7.8561e-02 (6.9846e-02) 
2023-05-26 02:17:37.988482: train Epoch: [76][ 89/129]	Time  0.981 ( 2.076)	Data  0.001 ( 1.098)	Loss 4.1955e-02 (6.9536e-02) 
2023-05-26 02:17:41.334556: train Epoch: [76][ 90/129]	Time  3.346 ( 2.090)	Data  2.365 ( 1.112)	Loss 7.4008e-02 (6.9585e-02) 
2023-05-26 02:17:42.296048: train Epoch: [76][ 91/129]	Time  0.961 ( 2.078)	Data  0.001 ( 1.100)	Loss 9.6939e-02 (6.9883e-02) 
2023-05-26 02:17:45.570436: train Epoch: [76][ 92/129]	Time  3.274 ( 2.091)	Data  2.298 ( 1.113)	Loss 9.9890e-02 (7.0205e-02) 
2023-05-26 02:17:46.537876: train Epoch: [76][ 93/129]	Time  0.967 ( 2.079)	Data  0.001 ( 1.101)	Loss 6.0615e-02 (7.0103e-02) 
2023-05-26 02:17:49.863339: train Epoch: [76][ 94/129]	Time  3.325 ( 2.092)	Data  2.361 ( 1.114)	Loss 5.7552e-02 (6.9971e-02) 
2023-05-26 02:17:50.835726: train Epoch: [76][ 95/129]	Time  0.972 ( 2.080)	Data  0.001 ( 1.102)	Loss 4.4528e-02 (6.9706e-02) 
2023-05-26 02:17:54.031235: train Epoch: [76][ 96/129]	Time  3.196 ( 2.092)	Data  2.231 ( 1.114)	Loss 6.9972e-02 (6.9709e-02) 
2023-05-26 02:17:55.000143: train Epoch: [76][ 97/129]	Time  0.969 ( 2.080)	Data  0.001 ( 1.103)	Loss 3.9072e-02 (6.9396e-02) 
2023-05-26 02:17:57.951383: train Epoch: [76][ 98/129]	Time  2.951 ( 2.089)	Data  1.983 ( 1.112)	Loss 3.9476e-02 (6.9094e-02) 
2023-05-26 02:17:58.932528: train Epoch: [76][ 99/129]	Time  0.981 ( 2.078)	Data  0.001 ( 1.101)	Loss 7.0390e-02 (6.9107e-02) 
2023-05-26 02:18:02.130267: train Epoch: [76][100/129]	Time  3.198 ( 2.089)	Data  2.228 ( 1.112)	Loss 4.5334e-02 (6.8871e-02) 
2023-05-26 02:18:03.104650: train Epoch: [76][101/129]	Time  0.974 ( 2.078)	Data  0.001 ( 1.101)	Loss 6.3219e-02 (6.8816e-02) 
2023-05-26 02:18:06.204561: train Epoch: [76][102/129]	Time  3.100 ( 2.088)	Data  2.130 ( 1.111)	Loss 1.3018e-01 (6.9412e-02) 
2023-05-26 02:18:07.176754: train Epoch: [76][103/129]	Time  0.972 ( 2.077)	Data  0.001 ( 1.100)	Loss 8.9503e-02 (6.9605e-02) 
2023-05-26 02:18:10.391945: train Epoch: [76][104/129]	Time  3.215 ( 2.088)	Data  2.248 ( 1.111)	Loss 6.0655e-02 (6.9520e-02) 
2023-05-26 02:18:11.361756: train Epoch: [76][105/129]	Time  0.970 ( 2.078)	Data  0.001 ( 1.101)	Loss 6.8297e-02 (6.9508e-02) 
2023-05-26 02:18:14.491376: train Epoch: [76][106/129]	Time  3.130 ( 2.088)	Data  2.167 ( 1.111)	Loss 7.7255e-02 (6.9581e-02) 
2023-05-26 02:18:15.478470: train Epoch: [76][107/129]	Time  0.987 ( 2.077)	Data  0.001 ( 1.100)	Loss 6.7180e-02 (6.9558e-02) 
2023-05-26 02:18:18.754702: train Epoch: [76][108/129]	Time  3.276 ( 2.088)	Data  2.303 ( 1.111)	Loss 8.4388e-02 (6.9694e-02) 
2023-05-26 02:18:19.725875: train Epoch: [76][109/129]	Time  0.971 ( 2.078)	Data  0.001 ( 1.101)	Loss 4.6075e-02 (6.9480e-02) 
2023-05-26 02:18:22.839959: train Epoch: [76][110/129]	Time  3.114 ( 2.087)	Data  2.123 ( 1.110)	Loss 8.2368e-02 (6.9596e-02) 
2023-05-26 02:18:23.821527: train Epoch: [76][111/129]	Time  0.982 ( 2.078)	Data  0.002 ( 1.101)	Loss 4.1720e-02 (6.9347e-02) 
2023-05-26 02:18:26.953686: train Epoch: [76][112/129]	Time  3.132 ( 2.087)	Data  2.157 ( 1.110)	Loss 5.9047e-02 (6.9256e-02) 
2023-05-26 02:18:27.952129: train Epoch: [76][113/129]	Time  0.998 ( 2.077)	Data  0.001 ( 1.100)	Loss 6.9935e-02 (6.9262e-02) 
2023-05-26 02:18:31.073327: train Epoch: [76][114/129]	Time  3.121 ( 2.086)	Data  2.144 ( 1.109)	Loss 8.5164e-02 (6.9400e-02) 
2023-05-26 02:18:32.036678: train Epoch: [76][115/129]	Time  0.963 ( 2.077)	Data  0.001 ( 1.100)	Loss 6.7887e-02 (6.9387e-02) 
2023-05-26 02:18:35.087896: train Epoch: [76][116/129]	Time  3.051 ( 2.085)	Data  2.077 ( 1.108)	Loss 5.5385e-02 (6.9267e-02) 
2023-05-26 02:18:36.062210: train Epoch: [76][117/129]	Time  0.974 ( 2.076)	Data  0.001 ( 1.099)	Loss 7.2434e-02 (6.9294e-02) 
2023-05-26 02:18:39.083873: train Epoch: [76][118/129]	Time  3.022 ( 2.084)	Data  2.035 ( 1.107)	Loss 5.9677e-02 (6.9213e-02) 
2023-05-26 02:18:40.063712: train Epoch: [76][119/129]	Time  0.980 ( 2.074)	Data  0.001 ( 1.097)	Loss 5.9479e-02 (6.9132e-02) 
2023-05-26 02:18:43.066290: train Epoch: [76][120/129]	Time  3.003 ( 2.082)	Data  2.032 ( 1.105)	Loss 4.5680e-02 (6.8938e-02) 
2023-05-26 02:18:44.035184: train Epoch: [76][121/129]	Time  0.969 ( 2.073)	Data  0.001 ( 1.096)	Loss 1.0228e-01 (6.9212e-02) 
2023-05-26 02:18:47.164303: train Epoch: [76][122/129]	Time  3.129 ( 2.082)	Data  2.156 ( 1.105)	Loss 5.3972e-02 (6.9088e-02) 
2023-05-26 02:18:48.136891: train Epoch: [76][123/129]	Time  0.973 ( 2.073)	Data  0.001 ( 1.096)	Loss 7.1489e-02 (6.9107e-02) 
2023-05-26 02:18:51.288160: train Epoch: [76][124/129]	Time  3.151 ( 2.081)	Data  2.171 ( 1.104)	Loss 9.1164e-02 (6.9284e-02) 
2023-05-26 02:18:52.257843: train Epoch: [76][125/129]	Time  0.970 ( 2.072)	Data  0.001 ( 1.096)	Loss 7.2698e-02 (6.9311e-02) 
2023-05-26 02:18:55.233143: train Epoch: [76][126/129]	Time  2.975 ( 2.080)	Data  2.001 ( 1.103)	Loss 6.6360e-02 (6.9287e-02) 
2023-05-26 02:18:56.211685: train Epoch: [76][127/129]	Time  0.979 ( 2.071)	Data  0.001 ( 1.094)	Loss 1.4774e-01 (6.9900e-02) 
2023-05-26 02:18:58.233426: train Epoch: [76][128/129]	Time  2.022 ( 2.071)	Data  1.041 ( 1.094)	Loss 9.9126e-02 (7.0127e-02) 
2023-05-26 02:18:58.275113: Train Epoch done in 267.1478085509989 s 
2023-05-26 02:19:01.108683: val Epoch: [76][ 0/72]	Time  1.914 ( 1.914)	Data  1.671 ( 1.671)	Loss 1.2157e-01 (1.2157e-01) 
2023-05-26 02:19:01.244974: val Epoch: [76][ 1/72]	Time  0.137 ( 1.025)	Data  0.002 ( 0.837)	Loss 2.3065e-01 (1.7611e-01) 
2023-05-26 02:19:02.413999: val Epoch: [76][ 2/72]	Time  1.169 ( 1.073)	Data  1.026 ( 0.900)	Loss 5.4181e-02 (1.3547e-01) 
2023-05-26 02:19:02.561303: val Epoch: [76][ 3/72]	Time  0.147 ( 0.842)	Data  0.001 ( 0.675)	Loss 3.6182e-02 (1.1064e-01) 
2023-05-26 02:19:03.819926: val Epoch: [76][ 4/72]	Time  1.259 ( 0.925)	Data  1.110 ( 0.762)	Loss 7.2904e-02 (1.0310e-01) 
2023-05-26 02:19:03.963835: val Epoch: [76][ 5/72]	Time  0.144 ( 0.795)	Data  0.001 ( 0.635)	Loss 5.7645e-02 (9.5521e-02) 
2023-05-26 02:19:05.171889: val Epoch: [76][ 6/72]	Time  1.208 ( 0.854)	Data  1.078 ( 0.698)	Loss 5.0814e-02 (8.9135e-02) 
2023-05-26 02:19:05.308736: val Epoch: [76][ 7/72]	Time  0.137 ( 0.764)	Data  0.001 ( 0.611)	Loss 1.2629e-01 (9.3779e-02) 
2023-05-26 02:19:06.554579: val Epoch: [76][ 8/72]	Time  1.246 ( 0.818)	Data  1.119 ( 0.668)	Loss 8.7867e-02 (9.3122e-02) 
2023-05-26 02:19:06.683574: val Epoch: [76][ 9/72]	Time  0.129 ( 0.749)	Data  0.001 ( 0.601)	Loss 5.4601e-02 (8.9270e-02) 
2023-05-26 02:19:07.937688: val Epoch: [76][10/72]	Time  1.254 ( 0.795)	Data  1.129 ( 0.649)	Loss 1.6260e-01 (9.5936e-02) 
2023-05-26 02:19:08.064981: val Epoch: [76][11/72]	Time  0.127 ( 0.739)	Data  0.001 ( 0.595)	Loss 4.8327e-02 (9.1969e-02) 
2023-05-26 02:19:09.268157: val Epoch: [76][12/72]	Time  1.203 ( 0.775)	Data  1.077 ( 0.632)	Loss 3.1650e-02 (8.7329e-02) 
2023-05-26 02:19:09.397159: val Epoch: [76][13/72]	Time  0.129 ( 0.729)	Data  0.001 ( 0.587)	Loss 7.3097e-02 (8.6312e-02) 
2023-05-26 02:19:10.620432: val Epoch: [76][14/72]	Time  1.223 ( 0.762)	Data  1.095 ( 0.621)	Loss 1.0037e-01 (8.7250e-02) 
2023-05-26 02:19:10.749048: val Epoch: [76][15/72]	Time  0.129 ( 0.722)	Data  0.001 ( 0.582)	Loss 5.8473e-02 (8.5451e-02) 
2023-05-26 02:19:12.005222: val Epoch: [76][16/72]	Time  1.256 ( 0.754)	Data  1.128 ( 0.614)	Loss 4.2454e-01 (1.0540e-01) 
2023-05-26 02:19:12.133770: val Epoch: [76][17/72]	Time  0.129 ( 0.719)	Data  0.001 ( 0.580)	Loss 7.2348e-02 (1.0356e-01) 
2023-05-26 02:19:13.365487: val Epoch: [76][18/72]	Time  1.232 ( 0.746)	Data  1.094 ( 0.607)	Loss 4.2973e-02 (1.0037e-01) 
2023-05-26 02:19:13.502737: val Epoch: [76][19/72]	Time  0.137 ( 0.715)	Data  0.001 ( 0.577)	Loss 3.9857e-02 (9.7347e-02) 
2023-05-26 02:19:14.758209: val Epoch: [76][20/72]	Time  1.255 ( 0.741)	Data  1.118 ( 0.603)	Loss 5.9758e-02 (9.5557e-02) 
2023-05-26 02:19:14.898647: val Epoch: [76][21/72]	Time  0.140 ( 0.714)	Data  0.001 ( 0.575)	Loss 3.4773e-01 (1.0702e-01) 
2023-05-26 02:19:16.137516: val Epoch: [76][22/72]	Time  1.239 ( 0.737)	Data  1.107 ( 0.598)	Loss 5.2582e-02 (1.0465e-01) 
2023-05-26 02:19:16.271021: val Epoch: [76][23/72]	Time  0.134 ( 0.712)	Data  0.001 ( 0.573)	Loss 5.2670e-02 (1.0249e-01) 
2023-05-26 02:19:17.541401: val Epoch: [76][24/72]	Time  1.270 ( 0.734)	Data  1.147 ( 0.596)	Loss 1.6338e-01 (1.0492e-01) 
2023-05-26 02:19:17.669292: val Epoch: [76][25/72]	Time  0.128 ( 0.711)	Data  0.001 ( 0.573)	Loss 3.6056e-01 (1.1476e-01) 
2023-05-26 02:19:18.964369: val Epoch: [76][26/72]	Time  1.295 ( 0.732)	Data  1.167 ( 0.595)	Loss 6.6034e-02 (1.1295e-01) 
2023-05-26 02:19:19.103602: val Epoch: [76][27/72]	Time  0.139 ( 0.711)	Data  0.001 ( 0.574)	Loss 8.8318e-02 (1.1207e-01) 
2023-05-26 02:19:20.264590: val Epoch: [76][28/72]	Time  1.161 ( 0.727)	Data  1.034 ( 0.590)	Loss 4.3460e-02 (1.0970e-01) 
2023-05-26 02:19:20.390824: val Epoch: [76][29/72]	Time  0.126 ( 0.707)	Data  0.001 ( 0.570)	Loss 4.3906e-01 (1.2068e-01) 
2023-05-26 02:19:21.584713: val Epoch: [76][30/72]	Time  1.194 ( 0.722)	Data  1.066 ( 0.586)	Loss 4.7442e-02 (1.1832e-01) 
2023-05-26 02:19:21.713917: val Epoch: [76][31/72]	Time  0.129 ( 0.704)	Data  0.001 ( 0.568)	Loss 9.0546e-02 (1.1745e-01) 
2023-05-26 02:19:22.986863: val Epoch: [76][32/72]	Time  1.273 ( 0.721)	Data  1.137 ( 0.585)	Loss 3.7064e-01 (1.2513e-01) 
2023-05-26 02:19:23.124422: val Epoch: [76][33/72]	Time  0.138 ( 0.704)	Data  0.001 ( 0.568)	Loss 1.2900e-01 (1.2524e-01) 
2023-05-26 02:19:24.358671: val Epoch: [76][34/72]	Time  1.234 ( 0.719)	Data  1.108 ( 0.584)	Loss 8.9825e-02 (1.2423e-01) 
2023-05-26 02:19:24.487807: val Epoch: [76][35/72]	Time  0.129 ( 0.703)	Data  0.001 ( 0.567)	Loss 1.2280e-01 (1.2419e-01) 
2023-05-26 02:19:25.732101: val Epoch: [76][36/72]	Time  1.244 ( 0.717)	Data  1.105 ( 0.582)	Loss 3.3912e-02 (1.2175e-01) 
2023-05-26 02:19:25.872687: val Epoch: [76][37/72]	Time  0.141 ( 0.702)	Data  0.001 ( 0.567)	Loss 7.0226e-02 (1.2039e-01) 
2023-05-26 02:19:27.175899: val Epoch: [76][38/72]	Time  1.303 ( 0.717)	Data  1.174 ( 0.582)	Loss 6.4937e-02 (1.1897e-01) 
2023-05-26 02:19:27.305411: val Epoch: [76][39/72]	Time  0.130 ( 0.703)	Data  0.001 ( 0.568)	Loss 1.1402e-01 (1.1885e-01) 
2023-05-26 02:19:28.589758: val Epoch: [76][40/72]	Time  1.284 ( 0.717)	Data  1.155 ( 0.582)	Loss 8.4450e-02 (1.1801e-01) 
2023-05-26 02:19:28.719772: val Epoch: [76][41/72]	Time  0.130 ( 0.703)	Data  0.001 ( 0.568)	Loss 4.0436e-02 (1.1616e-01) 
2023-05-26 02:19:29.991058: val Epoch: [76][42/72]	Time  1.271 ( 0.716)	Data  1.144 ( 0.582)	Loss 5.6227e-02 (1.1477e-01) 
2023-05-26 02:19:30.120057: val Epoch: [76][43/72]	Time  0.129 ( 0.703)	Data  0.001 ( 0.568)	Loss 7.1340e-02 (1.1378e-01) 
2023-05-26 02:19:31.375738: val Epoch: [76][44/72]	Time  1.256 ( 0.715)	Data  1.127 ( 0.581)	Loss 8.4117e-02 (1.1312e-01) 
2023-05-26 02:19:31.508754: val Epoch: [76][45/72]	Time  0.133 ( 0.702)	Data  0.001 ( 0.568)	Loss 7.9520e-02 (1.1239e-01) 
2023-05-26 02:19:32.800196: val Epoch: [76][46/72]	Time  1.291 ( 0.715)	Data  1.150 ( 0.581)	Loss 9.3543e-02 (1.1199e-01) 
2023-05-26 02:19:32.932407: val Epoch: [76][47/72]	Time  0.132 ( 0.703)	Data  0.001 ( 0.568)	Loss 5.0260e-02 (1.1070e-01) 
2023-05-26 02:19:34.130295: val Epoch: [76][48/72]	Time  1.198 ( 0.713)	Data  1.070 ( 0.579)	Loss 6.6584e-02 (1.0980e-01) 
2023-05-26 02:19:34.257967: val Epoch: [76][49/72]	Time  0.128 ( 0.701)	Data  0.001 ( 0.567)	Loss 5.8547e-02 (1.0878e-01) 
2023-05-26 02:19:35.480633: val Epoch: [76][50/72]	Time  1.223 ( 0.711)	Data  1.095 ( 0.578)	Loss 9.6772e-02 (1.0854e-01) 
2023-05-26 02:19:35.607369: val Epoch: [76][51/72]	Time  0.127 ( 0.700)	Data  0.001 ( 0.566)	Loss 1.7317e-01 (1.0978e-01) 
2023-05-26 02:19:36.868915: val Epoch: [76][52/72]	Time  1.262 ( 0.711)	Data  1.134 ( 0.577)	Loss 3.2258e-01 (1.1380e-01) 
2023-05-26 02:19:36.996814: val Epoch: [76][53/72]	Time  0.128 ( 0.700)	Data  0.001 ( 0.566)	Loss 3.9655e-02 (1.1243e-01) 
2023-05-26 02:19:38.204410: val Epoch: [76][54/72]	Time  1.208 ( 0.709)	Data  1.077 ( 0.576)	Loss 1.5132e-01 (1.1313e-01) 
2023-05-26 02:19:38.333080: val Epoch: [76][55/72]	Time  0.129 ( 0.699)	Data  0.001 ( 0.565)	Loss 3.6847e-02 (1.1177e-01) 
2023-05-26 02:19:39.598659: val Epoch: [76][56/72]	Time  1.266 ( 0.709)	Data  1.124 ( 0.575)	Loss 2.1991e-01 (1.1367e-01) 
2023-05-26 02:19:39.730485: val Epoch: [76][57/72]	Time  0.132 ( 0.699)	Data  0.001 ( 0.565)	Loss 4.9106e-02 (1.1256e-01) 
2023-05-26 02:19:40.950923: val Epoch: [76][58/72]	Time  1.220 ( 0.708)	Data  1.080 ( 0.574)	Loss 9.6273e-02 (1.1228e-01) 
2023-05-26 02:19:41.088472: val Epoch: [76][59/72]	Time  0.138 ( 0.698)	Data  0.001 ( 0.565)	Loss 2.7755e-01 (1.1503e-01) 
2023-05-26 02:19:42.350363: val Epoch: [76][60/72]	Time  1.262 ( 0.707)	Data  1.125 ( 0.574)	Loss 9.3560e-02 (1.1468e-01) 
2023-05-26 02:19:42.487403: val Epoch: [76][61/72]	Time  0.137 ( 0.698)	Data  0.001 ( 0.564)	Loss 3.9534e-02 (1.1347e-01) 
2023-05-26 02:19:43.773777: val Epoch: [76][62/72]	Time  1.286 ( 0.708)	Data  1.146 ( 0.574)	Loss 4.5392e-02 (1.1239e-01) 
2023-05-26 02:19:43.909054: val Epoch: [76][63/72]	Time  0.135 ( 0.699)	Data  0.001 ( 0.565)	Loss 5.7260e-02 (1.1153e-01) 
2023-05-26 02:19:45.132965: val Epoch: [76][64/72]	Time  1.224 ( 0.707)	Data  1.082 ( 0.573)	Loss 2.2163e-01 (1.1322e-01) 
2023-05-26 02:19:45.270543: val Epoch: [76][65/72]	Time  0.138 ( 0.698)	Data  0.001 ( 0.564)	Loss 2.7008e-01 (1.1560e-01) 
2023-05-26 02:19:46.512932: val Epoch: [76][66/72]	Time  1.242 ( 0.706)	Data  1.099 ( 0.572)	Loss 3.4952e-02 (1.1439e-01) 
2023-05-26 02:19:46.652651: val Epoch: [76][67/72]	Time  0.140 ( 0.698)	Data  0.001 ( 0.564)	Loss 6.1905e-02 (1.1362e-01) 
2023-05-26 02:19:47.844421: val Epoch: [76][68/72]	Time  1.192 ( 0.705)	Data  1.066 ( 0.571)	Loss 1.6974e-01 (1.1444e-01) 
2023-05-26 02:19:47.973366: val Epoch: [76][69/72]	Time  0.129 ( 0.697)	Data  0.001 ( 0.563)	Loss 2.5636e-01 (1.1646e-01) 
2023-05-26 02:19:49.179518: val Epoch: [76][70/72]	Time  1.206 ( 0.704)	Data  1.078 ( 0.570)	Loss 4.4709e-02 (1.1545e-01) 
2023-05-26 02:19:49.308544: val Epoch: [76][71/72]	Time  0.129 ( 0.696)	Data  0.001 ( 0.562)	Loss 3.4596e-02 (1.1433e-01) 
2023-05-26 02:19:49.517107: Epoch 76 :Val : ['ET : 0.7477895021438599', 'TC : 0.811474084854126', 'WT : 0.8878566026687622'] 
2023-05-26 02:19:49.522138: Epoch 76 :Val : ['ET : 0.7477895021438599', 'TC : 0.811474084854126', 'WT : 0.8878566026687622'] 
2023-05-26 02:19:49.525065: Val epoch done in 51.24995355899955 s 
2023-05-26 02:19:49.531198: Batches per epoch:  129 
2023-05-26 02:19:55.040943: train Epoch: [77][  0/129]	Time  5.509 ( 5.509)	Data  4.415 ( 4.415)	Loss 5.8587e-02 (5.8587e-02) 
2023-05-26 02:19:56.047314: train Epoch: [77][  1/129]	Time  1.006 ( 3.258)	Data  0.002 ( 2.208)	Loss 3.3913e-02 (4.6250e-02) 
2023-05-26 02:19:59.242094: train Epoch: [77][  2/129]	Time  3.195 ( 3.237)	Data  2.205 ( 2.207)	Loss 6.5884e-02 (5.2795e-02) 
2023-05-26 02:20:00.206277: train Epoch: [77][  3/129]	Time  0.964 ( 2.669)	Data  0.001 ( 1.656)	Loss 5.8119e-02 (5.4126e-02) 
2023-05-26 02:20:03.169770: train Epoch: [77][  4/129]	Time  2.964 ( 2.728)	Data  1.984 ( 1.721)	Loss 1.2390e-01 (6.8081e-02) 
2023-05-26 02:20:04.154199: train Epoch: [77][  5/129]	Time  0.984 ( 2.437)	Data  0.001 ( 1.435)	Loss 7.2357e-02 (6.8794e-02) 
2023-05-26 02:20:07.228971: train Epoch: [77][  6/129]	Time  3.075 ( 2.528)	Data  2.091 ( 1.528)	Loss 7.2315e-02 (6.9297e-02) 
2023-05-26 02:20:08.213088: train Epoch: [77][  7/129]	Time  0.984 ( 2.335)	Data  0.001 ( 1.338)	Loss 3.8630e-02 (6.5464e-02) 
2023-05-26 02:20:11.143942: train Epoch: [77][  8/129]	Time  2.931 ( 2.401)	Data  1.961 ( 1.407)	Loss 1.0821e-01 (7.0213e-02) 
2023-05-26 02:20:12.118953: train Epoch: [77][  9/129]	Time  0.975 ( 2.259)	Data  0.001 ( 1.266)	Loss 6.6238e-02 (6.9815e-02) 
2023-05-26 02:20:15.292753: train Epoch: [77][ 10/129]	Time  3.174 ( 2.342)	Data  2.189 ( 1.350)	Loss 8.7961e-02 (7.1465e-02) 
2023-05-26 02:20:16.281514: train Epoch: [77][ 11/129]	Time  0.989 ( 2.229)	Data  0.002 ( 1.238)	Loss 7.4547e-02 (7.1722e-02) 
2023-05-26 02:20:19.366173: train Epoch: [77][ 12/129]	Time  3.085 ( 2.295)	Data  2.105 ( 1.304)	Loss 7.1932e-02 (7.1738e-02) 
2023-05-26 02:20:20.357782: train Epoch: [77][ 13/129]	Time  0.992 ( 2.202)	Data  0.001 ( 1.211)	Loss 4.4212e-02 (6.9772e-02) 
2023-05-26 02:20:23.489128: train Epoch: [77][ 14/129]	Time  3.131 ( 2.264)	Data  2.150 ( 1.274)	Loss 5.3227e-02 (6.8669e-02) 
2023-05-26 02:20:24.456551: train Epoch: [77][ 15/129]	Time  0.967 ( 2.183)	Data  0.001 ( 1.194)	Loss 6.3073e-02 (6.8319e-02) 
2023-05-26 02:20:27.558939: train Epoch: [77][ 16/129]	Time  3.102 ( 2.237)	Data  2.122 ( 1.249)	Loss 4.7166e-02 (6.7075e-02) 
2023-05-26 02:20:28.554579: train Epoch: [77][ 17/129]	Time  0.996 ( 2.168)	Data  0.002 ( 1.180)	Loss 9.5244e-02 (6.8640e-02) 
2023-05-26 02:20:31.568305: train Epoch: [77][ 18/129]	Time  3.014 ( 2.212)	Data  2.037 ( 1.225)	Loss 6.7073e-02 (6.8557e-02) 
2023-05-26 02:20:32.546235: train Epoch: [77][ 19/129]	Time  0.978 ( 2.151)	Data  0.001 ( 1.164)	Loss 5.8862e-02 (6.8072e-02) 
2023-05-26 02:20:35.609427: train Epoch: [77][ 20/129]	Time  3.063 ( 2.194)	Data  2.091 ( 1.208)	Loss 8.2821e-02 (6.8775e-02) 
2023-05-26 02:20:36.582698: train Epoch: [77][ 21/129]	Time  0.973 ( 2.139)	Data  0.001 ( 1.153)	Loss 6.7702e-02 (6.8726e-02) 
2023-05-26 02:20:39.781525: train Epoch: [77][ 22/129]	Time  3.199 ( 2.185)	Data  2.229 ( 1.200)	Loss 4.9164e-02 (6.7875e-02) 
2023-05-26 02:20:40.757592: train Epoch: [77][ 23/129]	Time  0.976 ( 2.134)	Data  0.002 ( 1.150)	Loss 5.9579e-02 (6.7530e-02) 
2023-05-26 02:20:43.929057: train Epoch: [77][ 24/129]	Time  3.171 ( 2.176)	Data  2.193 ( 1.192)	Loss 6.1518e-02 (6.7289e-02) 
2023-05-26 02:20:44.917343: train Epoch: [77][ 25/129]	Time  0.988 ( 2.130)	Data  0.002 ( 1.146)	Loss 5.8600e-02 (6.6955e-02) 
2023-05-26 02:20:48.050820: train Epoch: [77][ 26/129]	Time  3.133 ( 2.167)	Data  2.152 ( 1.183)	Loss 8.0030e-02 (6.7439e-02) 
2023-05-26 02:20:49.022887: train Epoch: [77][ 27/129]	Time  0.972 ( 2.125)	Data  0.001 ( 1.141)	Loss 5.4867e-02 (6.6990e-02) 
2023-05-26 02:20:52.212218: train Epoch: [77][ 28/129]	Time  3.189 ( 2.161)	Data  2.174 ( 1.176)	Loss 6.4063e-02 (6.6889e-02) 
2023-05-26 02:20:53.205844: train Epoch: [77][ 29/129]	Time  0.994 ( 2.122)	Data  0.002 ( 1.137)	Loss 8.4864e-02 (6.7488e-02) 
2023-05-26 02:20:56.296512: train Epoch: [77][ 30/129]	Time  3.091 ( 2.154)	Data  2.090 ( 1.168)	Loss 4.8636e-02 (6.6880e-02) 
2023-05-26 02:20:57.282801: train Epoch: [77][ 31/129]	Time  0.986 ( 2.117)	Data  0.002 ( 1.132)	Loss 5.8693e-02 (6.6624e-02) 
2023-05-26 02:21:00.446924: train Epoch: [77][ 32/129]	Time  3.164 ( 2.149)	Data  2.202 ( 1.164)	Loss 8.7987e-02 (6.7272e-02) 
2023-05-26 02:21:01.414969: train Epoch: [77][ 33/129]	Time  0.968 ( 2.114)	Data  0.002 ( 1.130)	Loss 5.9244e-02 (6.7036e-02) 
2023-05-26 02:21:07.677521: train Epoch: [77][ 34/129]	Time  6.263 ( 2.233)	Data  5.285 ( 1.249)	Loss 8.6555e-02 (6.7593e-02) 
2023-05-26 02:21:08.653136: train Epoch: [77][ 35/129]	Time  0.976 ( 2.198)	Data  0.001 ( 1.214)	Loss 7.7998e-02 (6.7882e-02) 
2023-05-26 02:21:16.097069: train Epoch: [77][ 36/129]	Time  7.444 ( 2.340)	Data  6.460 ( 1.356)	Loss 5.3549e-02 (6.7495e-02) 
2023-05-26 02:21:17.062735: train Epoch: [77][ 37/129]	Time  0.966 ( 2.303)	Data  0.001 ( 1.320)	Loss 1.3535e-01 (6.9281e-02) 
2023-05-26 02:21:21.676447: train Epoch: [77][ 38/129]	Time  4.614 ( 2.363)	Data  3.630 ( 1.379)	Loss 4.6092e-02 (6.8686e-02) 
2023-05-26 02:21:22.655704: train Epoch: [77][ 39/129]	Time  0.979 ( 2.328)	Data  0.001 ( 1.345)	Loss 4.9243e-02 (6.8200e-02) 
2023-05-26 02:21:25.675365: train Epoch: [77][ 40/129]	Time  3.020 ( 2.345)	Data  2.051 ( 1.362)	Loss 1.0003e-01 (6.8977e-02) 
2023-05-26 02:21:26.647341: train Epoch: [77][ 41/129]	Time  0.972 ( 2.312)	Data  0.001 ( 1.330)	Loss 5.5672e-02 (6.8660e-02) 
2023-05-26 02:21:29.712784: train Epoch: [77][ 42/129]	Time  3.065 ( 2.330)	Data  2.078 ( 1.347)	Loss 4.1880e-02 (6.8037e-02) 
2023-05-26 02:21:30.685207: train Epoch: [77][ 43/129]	Time  0.972 ( 2.299)	Data  0.001 ( 1.316)	Loss 1.0365e-01 (6.8846e-02) 
2023-05-26 02:21:33.911104: train Epoch: [77][ 44/129]	Time  3.226 ( 2.320)	Data  2.240 ( 1.337)	Loss 8.8084e-02 (6.9274e-02) 
2023-05-26 02:21:34.896441: train Epoch: [77][ 45/129]	Time  0.985 ( 2.291)	Data  0.002 ( 1.308)	Loss 4.6720e-02 (6.8784e-02) 
2023-05-26 02:21:37.978144: train Epoch: [77][ 46/129]	Time  3.082 ( 2.307)	Data  2.095 ( 1.325)	Loss 5.4090e-02 (6.8471e-02) 
2023-05-26 02:21:38.949319: train Epoch: [77][ 47/129]	Time  0.971 ( 2.280)	Data  0.001 ( 1.297)	Loss 6.6011e-02 (6.8420e-02) 
2023-05-26 02:21:41.948150: train Epoch: [77][ 48/129]	Time  2.999 ( 2.294)	Data  2.032 ( 1.312)	Loss 9.7689e-02 (6.9017e-02) 
2023-05-26 02:21:42.929283: train Epoch: [77][ 49/129]	Time  0.981 ( 2.268)	Data  0.001 ( 1.286)	Loss 6.6510e-02 (6.8967e-02) 
2023-05-26 02:21:46.019191: train Epoch: [77][ 50/129]	Time  3.090 ( 2.284)	Data  2.115 ( 1.302)	Loss 8.8381e-02 (6.9348e-02) 
2023-05-26 02:21:46.989891: train Epoch: [77][ 51/129]	Time  0.971 ( 2.259)	Data  0.001 ( 1.277)	Loss 9.6312e-02 (6.9866e-02) 
2023-05-26 02:21:50.142923: train Epoch: [77][ 52/129]	Time  3.153 ( 2.276)	Data  2.167 ( 1.294)	Loss 5.8135e-02 (6.9645e-02) 
2023-05-26 02:21:51.127522: train Epoch: [77][ 53/129]	Time  0.985 ( 2.252)	Data  0.001 ( 1.270)	Loss 4.3786e-02 (6.9166e-02) 
2023-05-26 02:21:54.345169: train Epoch: [77][ 54/129]	Time  3.218 ( 2.269)	Data  2.242 ( 1.288)	Loss 3.8054e-02 (6.8600e-02) 
2023-05-26 02:21:55.333065: train Epoch: [77][ 55/129]	Time  0.988 ( 2.246)	Data  0.001 ( 1.265)	Loss 5.8841e-02 (6.8426e-02) 
2023-05-26 02:21:58.631205: train Epoch: [77][ 56/129]	Time  3.298 ( 2.265)	Data  2.318 ( 1.283)	Loss 1.0167e-01 (6.9009e-02) 
2023-05-26 02:21:59.609577: train Epoch: [77][ 57/129]	Time  0.978 ( 2.243)	Data  0.001 ( 1.261)	Loss 6.5318e-02 (6.8945e-02) 
2023-05-26 02:22:02.702445: train Epoch: [77][ 58/129]	Time  3.093 ( 2.257)	Data  2.095 ( 1.275)	Loss 4.6717e-02 (6.8569e-02) 
2023-05-26 02:22:03.675083: train Epoch: [77][ 59/129]	Time  0.973 ( 2.236)	Data  0.001 ( 1.254)	Loss 6.1700e-02 (6.8454e-02) 
2023-05-26 02:22:06.795629: train Epoch: [77][ 60/129]	Time  3.121 ( 2.250)	Data  2.138 ( 1.268)	Loss 4.9849e-02 (6.8149e-02) 
2023-05-26 02:22:07.827269: train Epoch: [77][ 61/129]	Time  1.032 ( 2.231)	Data  0.002 ( 1.248)	Loss 5.8836e-02 (6.7999e-02) 
2023-05-26 02:22:10.898611: train Epoch: [77][ 62/129]	Time  3.071 ( 2.244)	Data  2.103 ( 1.262)	Loss 8.2323e-02 (6.8226e-02) 
2023-05-26 02:22:11.882549: train Epoch: [77][ 63/129]	Time  0.984 ( 2.224)	Data  0.001 ( 1.242)	Loss 1.1272e-01 (6.8922e-02) 
2023-05-26 02:22:16.558615: train Epoch: [77][ 64/129]	Time  4.676 ( 2.262)	Data  3.678 ( 1.279)	Loss 7.5089e-02 (6.9016e-02) 
2023-05-26 02:22:17.536257: train Epoch: [77][ 65/129]	Time  0.978 ( 2.242)	Data  0.002 ( 1.260)	Loss 3.2901e-02 (6.8469e-02) 
2023-05-26 02:22:24.983513: train Epoch: [77][ 66/129]	Time  7.447 ( 2.320)	Data  6.472 ( 1.338)	Loss 8.6772e-02 (6.8742e-02) 
2023-05-26 02:22:25.952991: train Epoch: [77][ 67/129]	Time  0.969 ( 2.300)	Data  0.001 ( 1.318)	Loss 7.6126e-02 (6.8851e-02) 
2023-05-26 02:22:29.366452: train Epoch: [77][ 68/129]	Time  3.413 ( 2.316)	Data  2.427 ( 1.334)	Loss 7.5270e-02 (6.8944e-02) 
2023-05-26 02:22:30.362120: train Epoch: [77][ 69/129]	Time  0.996 ( 2.298)	Data  0.001 ( 1.315)	Loss 5.5649e-02 (6.8754e-02) 
2023-05-26 02:22:33.475209: train Epoch: [77][ 70/129]	Time  3.113 ( 2.309)	Data  2.128 ( 1.327)	Loss 6.0120e-02 (6.8633e-02) 
2023-05-26 02:22:34.451195: train Epoch: [77][ 71/129]	Time  0.976 ( 2.291)	Data  0.001 ( 1.308)	Loss 7.2382e-02 (6.8685e-02) 
2023-05-26 02:22:37.707567: train Epoch: [77][ 72/129]	Time  3.256 ( 2.304)	Data  2.259 ( 1.321)	Loss 7.8675e-02 (6.8821e-02) 
2023-05-26 02:22:38.682527: train Epoch: [77][ 73/129]	Time  0.975 ( 2.286)	Data  0.001 ( 1.303)	Loss 6.3418e-02 (6.8748e-02) 
2023-05-26 02:22:41.817597: train Epoch: [77][ 74/129]	Time  3.135 ( 2.297)	Data  2.178 ( 1.315)	Loss 7.9006e-02 (6.8885e-02) 
2023-05-26 02:22:42.801171: train Epoch: [77][ 75/129]	Time  0.984 ( 2.280)	Data  0.001 ( 1.298)	Loss 6.1238e-02 (6.8785e-02) 
2023-05-26 02:22:46.054935: train Epoch: [77][ 76/129]	Time  3.254 ( 2.293)	Data  2.256 ( 1.310)	Loss 6.5219e-02 (6.8738e-02) 
2023-05-26 02:22:47.031531: train Epoch: [77][ 77/129]	Time  0.977 ( 2.276)	Data  0.001 ( 1.293)	Loss 4.9351e-02 (6.8490e-02) 
2023-05-26 02:22:50.120516: train Epoch: [77][ 78/129]	Time  3.089 ( 2.286)	Data  2.103 ( 1.304)	Loss 5.5642e-02 (6.8327e-02) 
2023-05-26 02:22:51.102313: train Epoch: [77][ 79/129]	Time  0.982 ( 2.270)	Data  0.001 ( 1.287)	Loss 9.5954e-02 (6.8672e-02) 
2023-05-26 02:22:54.293017: train Epoch: [77][ 80/129]	Time  3.191 ( 2.281)	Data  2.207 ( 1.299)	Loss 6.4102e-02 (6.8616e-02) 
2023-05-26 02:22:55.270382: train Epoch: [77][ 81/129]	Time  0.977 ( 2.265)	Data  0.001 ( 1.283)	Loss 7.4558e-02 (6.8688e-02) 
2023-05-26 02:22:58.393741: train Epoch: [77][ 82/129]	Time  3.123 ( 2.275)	Data  2.155 ( 1.293)	Loss 7.9561e-02 (6.8819e-02) 
2023-05-26 02:22:59.366347: train Epoch: [77][ 83/129]	Time  0.973 ( 2.260)	Data  0.001 ( 1.278)	Loss 4.7944e-02 (6.8571e-02) 
2023-05-26 02:23:02.590897: train Epoch: [77][ 84/129]	Time  3.225 ( 2.271)	Data  2.240 ( 1.289)	Loss 5.3772e-02 (6.8397e-02) 
2023-05-26 02:23:03.576593: train Epoch: [77][ 85/129]	Time  0.986 ( 2.256)	Data  0.002 ( 1.274)	Loss 9.1138e-02 (6.8661e-02) 
2023-05-26 02:23:06.653617: train Epoch: [77][ 86/129]	Time  3.077 ( 2.266)	Data  2.090 ( 1.284)	Loss 5.4313e-02 (6.8496e-02) 
2023-05-26 02:23:07.627118: train Epoch: [77][ 87/129]	Time  0.973 ( 2.251)	Data  0.001 ( 1.269)	Loss 6.7076e-02 (6.8480e-02) 
2023-05-26 02:23:10.810202: train Epoch: [77][ 88/129]	Time  3.183 ( 2.262)	Data  2.204 ( 1.280)	Loss 1.0571e-01 (6.8898e-02) 
2023-05-26 02:23:11.780497: train Epoch: [77][ 89/129]	Time  0.970 ( 2.247)	Data  0.001 ( 1.265)	Loss 8.3203e-02 (6.9057e-02) 
2023-05-26 02:23:14.879596: train Epoch: [77][ 90/129]	Time  3.099 ( 2.257)	Data  2.114 ( 1.275)	Loss 5.5664e-02 (6.8910e-02) 
2023-05-26 02:23:15.859780: train Epoch: [77][ 91/129]	Time  0.980 ( 2.243)	Data  0.001 ( 1.261)	Loss 5.3922e-02 (6.8747e-02) 
2023-05-26 02:23:18.968586: train Epoch: [77][ 92/129]	Time  3.109 ( 2.252)	Data  2.131 ( 1.270)	Loss 7.1962e-02 (6.8782e-02) 
2023-05-26 02:23:19.936401: train Epoch: [77][ 93/129]	Time  0.968 ( 2.238)	Data  0.001 ( 1.257)	Loss 3.4940e-02 (6.8422e-02) 
2023-05-26 02:23:23.037297: train Epoch: [77][ 94/129]	Time  3.101 ( 2.247)	Data  2.103 ( 1.266)	Loss 6.5401e-02 (6.8390e-02) 
2023-05-26 02:23:24.023187: train Epoch: [77][ 95/129]	Time  0.986 ( 2.234)	Data  0.002 ( 1.253)	Loss 5.8232e-02 (6.8284e-02) 
2023-05-26 02:23:27.197378: train Epoch: [77][ 96/129]	Time  3.174 ( 2.244)	Data  2.198 ( 1.262)	Loss 9.5923e-02 (6.8569e-02) 
2023-05-26 02:23:28.171827: train Epoch: [77][ 97/129]	Time  0.974 ( 2.231)	Data  0.001 ( 1.249)	Loss 7.6824e-02 (6.8653e-02) 
2023-05-26 02:23:31.454291: train Epoch: [77][ 98/129]	Time  3.282 ( 2.242)	Data  2.306 ( 1.260)	Loss 7.5456e-02 (6.8722e-02) 
2023-05-26 02:23:32.433089: train Epoch: [77][ 99/129]	Time  0.979 ( 2.229)	Data  0.001 ( 1.248)	Loss 5.4144e-02 (6.8576e-02) 
2023-05-26 02:23:35.435175: train Epoch: [77][100/129]	Time  3.002 ( 2.237)	Data  2.028 ( 1.255)	Loss 8.6328e-02 (6.8752e-02) 
2023-05-26 02:23:36.423985: train Epoch: [77][101/129]	Time  0.989 ( 2.224)	Data  0.002 ( 1.243)	Loss 9.0942e-02 (6.8970e-02) 
2023-05-26 02:23:39.624223: train Epoch: [77][102/129]	Time  3.200 ( 2.234)	Data  2.211 ( 1.252)	Loss 6.9514e-02 (6.8975e-02) 
2023-05-26 02:23:40.605832: train Epoch: [77][103/129]	Time  0.982 ( 2.222)	Data  0.002 ( 1.240)	Loss 8.7306e-02 (6.9151e-02) 
2023-05-26 02:23:43.793877: train Epoch: [77][104/129]	Time  3.188 ( 2.231)	Data  2.204 ( 1.249)	Loss 7.3248e-02 (6.9190e-02) 
2023-05-26 02:23:44.767906: train Epoch: [77][105/129]	Time  0.974 ( 2.219)	Data  0.001 ( 1.238)	Loss 4.8274e-02 (6.8993e-02) 
2023-05-26 02:23:47.848217: train Epoch: [77][106/129]	Time  3.080 ( 2.227)	Data  2.095 ( 1.246)	Loss 7.2585e-02 (6.9026e-02) 
2023-05-26 02:23:48.838002: train Epoch: [77][107/129]	Time  0.990 ( 2.216)	Data  0.002 ( 1.234)	Loss 4.1460e-02 (6.8771e-02) 
2023-05-26 02:23:52.031161: train Epoch: [77][108/129]	Time  3.193 ( 2.225)	Data  2.216 ( 1.243)	Loss 7.6045e-02 (6.8838e-02) 
2023-05-26 02:23:53.010768: train Epoch: [77][109/129]	Time  0.980 ( 2.213)	Data  0.001 ( 1.232)	Loss 1.8461e-01 (6.9890e-02) 
2023-05-26 02:23:56.206402: train Epoch: [77][110/129]	Time  3.196 ( 2.222)	Data  2.220 ( 1.241)	Loss 5.7062e-02 (6.9775e-02) 
2023-05-26 02:23:57.177110: train Epoch: [77][111/129]	Time  0.971 ( 2.211)	Data  0.001 ( 1.230)	Loss 1.1159e-01 (7.0148e-02) 
2023-05-26 02:24:00.321773: train Epoch: [77][112/129]	Time  3.145 ( 2.219)	Data  2.170 ( 1.238)	Loss 1.1348e-01 (7.0532e-02) 
2023-05-26 02:24:01.298882: train Epoch: [77][113/129]	Time  0.977 ( 2.208)	Data  0.001 ( 1.227)	Loss 6.4201e-02 (7.0476e-02) 
2023-05-26 02:24:04.363037: train Epoch: [77][114/129]	Time  3.064 ( 2.216)	Data  2.098 ( 1.235)	Loss 5.8308e-02 (7.0370e-02) 
2023-05-26 02:24:05.350666: train Epoch: [77][115/129]	Time  0.988 ( 2.205)	Data  0.002 ( 1.224)	Loss 6.3265e-02 (7.0309e-02) 
2023-05-26 02:24:08.578514: train Epoch: [77][116/129]	Time  3.228 ( 2.214)	Data  2.230 ( 1.233)	Loss 1.2465e-01 (7.0774e-02) 
2023-05-26 02:24:09.565735: train Epoch: [77][117/129]	Time  0.987 ( 2.204)	Data  0.002 ( 1.222)	Loss 8.3969e-02 (7.0885e-02) 
2023-05-26 02:24:12.695640: train Epoch: [77][118/129]	Time  3.130 ( 2.211)	Data  2.150 ( 1.230)	Loss 4.8407e-02 (7.0696e-02) 
2023-05-26 02:24:13.670022: train Epoch: [77][119/129]	Time  0.974 ( 2.201)	Data  0.002 ( 1.220)	Loss 6.4027e-02 (7.0641e-02) 
2023-05-26 02:24:16.979064: train Epoch: [77][120/129]	Time  3.309 ( 2.210)	Data  2.312 ( 1.229)	Loss 7.7342e-02 (7.0696e-02) 
2023-05-26 02:24:17.964996: train Epoch: [77][121/129]	Time  0.986 ( 2.200)	Data  0.001 ( 1.219)	Loss 9.0764e-02 (7.0861e-02) 
2023-05-26 02:24:20.877589: train Epoch: [77][122/129]	Time  2.913 ( 2.206)	Data  1.949 ( 1.225)	Loss 5.0728e-02 (7.0697e-02) 
2023-05-26 02:24:21.850730: train Epoch: [77][123/129]	Time  0.973 ( 2.196)	Data  0.001 ( 1.215)	Loss 8.3387e-02 (7.0799e-02) 
2023-05-26 02:24:25.054085: train Epoch: [77][124/129]	Time  3.203 ( 2.204)	Data  2.219 ( 1.223)	Loss 9.7178e-02 (7.1010e-02) 
2023-05-26 02:24:26.031919: train Epoch: [77][125/129]	Time  0.978 ( 2.194)	Data  0.001 ( 1.213)	Loss 9.6050e-02 (7.1209e-02) 
2023-05-26 02:24:29.150974: train Epoch: [77][126/129]	Time  3.119 ( 2.202)	Data  2.147 ( 1.221)	Loss 9.4026e-02 (7.1389e-02) 
2023-05-26 02:24:30.124183: train Epoch: [77][127/129]	Time  0.973 ( 2.192)	Data  0.001 ( 1.211)	Loss 8.1453e-02 (7.1467e-02) 
2023-05-26 02:24:32.316179: train Epoch: [77][128/129]	Time  2.192 ( 2.192)	Data  1.217 ( 1.211)	Loss 6.9256e-02 (7.1450e-02) 
2023-05-26 02:24:32.365483: Train Epoch done in 282.8343472689994 s 
2023-05-26 02:24:35.216615: val Epoch: [77][ 0/72]	Time  1.861 ( 1.861)	Data  1.646 ( 1.646)	Loss 6.9933e-02 (6.9933e-02) 
2023-05-26 02:24:35.353909: val Epoch: [77][ 1/72]	Time  0.138 ( 0.999)	Data  0.002 ( 0.824)	Loss 2.9813e-01 (1.8403e-01) 
2023-05-26 02:24:36.572584: val Epoch: [77][ 2/72]	Time  1.219 ( 1.072)	Data  1.086 ( 0.911)	Loss 1.7623e-01 (1.8143e-01) 
2023-05-26 02:24:36.701901: val Epoch: [77][ 3/72]	Time  0.129 ( 0.837)	Data  0.001 ( 0.684)	Loss 3.4152e-01 (2.2145e-01) 
2023-05-26 02:24:37.909592: val Epoch: [77][ 4/72]	Time  1.208 ( 0.911)	Data  1.072 ( 0.761)	Loss 2.1561e-01 (2.2028e-01) 
2023-05-26 02:24:38.042008: val Epoch: [77][ 5/72]	Time  0.132 ( 0.781)	Data  0.001 ( 0.635)	Loss 5.0088e-02 (1.9192e-01) 
2023-05-26 02:24:39.334096: val Epoch: [77][ 6/72]	Time  1.292 ( 0.854)	Data  1.147 ( 0.708)	Loss 5.3502e-02 (1.7214e-01) 
2023-05-26 02:24:39.471915: val Epoch: [77][ 7/72]	Time  0.138 ( 0.765)	Data  0.001 ( 0.619)	Loss 2.8004e-01 (1.8563e-01) 
2023-05-26 02:24:40.596183: val Epoch: [77][ 8/72]	Time  1.124 ( 0.805)	Data  0.998 ( 0.661)	Loss 5.0806e-02 (1.7065e-01) 
2023-05-26 02:24:40.756536: val Epoch: [77][ 9/72]	Time  0.160 ( 0.740)	Data  0.034 ( 0.599)	Loss 3.0829e-01 (1.8441e-01) 
2023-05-26 02:24:41.894505: val Epoch: [77][10/72]	Time  1.138 ( 0.776)	Data  1.011 ( 0.636)	Loss 6.3520e-02 (1.7342e-01) 
2023-05-26 02:24:42.153014: val Epoch: [77][11/72]	Time  0.259 ( 0.733)	Data  0.129 ( 0.594)	Loss 7.6569e-02 (1.6535e-01) 
2023-05-26 02:24:43.315577: val Epoch: [77][12/72]	Time  1.163 ( 0.766)	Data  1.030 ( 0.627)	Loss 4.8171e-02 (1.5634e-01) 
2023-05-26 02:24:43.518137: val Epoch: [77][13/72]	Time  0.203 ( 0.726)	Data  0.075 ( 0.588)	Loss 5.9677e-02 (1.4943e-01) 
2023-05-26 02:24:44.661462: val Epoch: [77][14/72]	Time  1.143 ( 0.754)	Data  1.016 ( 0.616)	Loss 3.9166e-01 (1.6558e-01) 
2023-05-26 02:24:44.844665: val Epoch: [77][15/72]	Time  0.183 ( 0.718)	Data  0.055 ( 0.581)	Loss 3.4769e-02 (1.5741e-01) 
2023-05-26 02:24:45.978837: val Epoch: [77][16/72]	Time  1.134 ( 0.743)	Data  1.010 ( 0.607)	Loss 9.5233e-02 (1.5375e-01) 
2023-05-26 02:24:46.252742: val Epoch: [77][17/72]	Time  0.274 ( 0.717)	Data  0.142 ( 0.581)	Loss 1.4700e-01 (1.5337e-01) 
2023-05-26 02:24:47.320512: val Epoch: [77][18/72]	Time  1.068 ( 0.735)	Data  0.929 ( 0.599)	Loss 6.0485e-02 (1.4849e-01) 
2023-05-26 02:24:47.611490: val Epoch: [77][19/72]	Time  0.291 ( 0.713)	Data  0.155 ( 0.577)	Loss 5.9280e-02 (1.4402e-01) 
2023-05-26 02:24:48.625924: val Epoch: [77][20/72]	Time  1.014 ( 0.727)	Data  0.880 ( 0.591)	Loss 5.6316e-02 (1.3985e-01) 
2023-05-26 02:24:49.012827: val Epoch: [77][21/72]	Time  0.387 ( 0.712)	Data  0.256 ( 0.576)	Loss 4.5719e-02 (1.3557e-01) 
2023-05-26 02:24:50.030694: val Epoch: [77][22/72]	Time  1.018 ( 0.725)	Data  0.890 ( 0.590)	Loss 3.6066e-02 (1.3124e-01) 
2023-05-26 02:24:50.378696: val Epoch: [77][23/72]	Time  0.348 ( 0.709)	Data  0.221 ( 0.574)	Loss 3.8208e-01 (1.4169e-01) 
2023-05-26 02:24:51.471342: val Epoch: [77][24/72]	Time  1.093 ( 0.725)	Data  0.963 ( 0.590)	Loss 5.2244e-02 (1.3812e-01) 
2023-05-26 02:24:51.769640: val Epoch: [77][25/72]	Time  0.298 ( 0.708)	Data  0.165 ( 0.574)	Loss 1.8790e-01 (1.4003e-01) 
2023-05-26 02:24:52.879599: val Epoch: [77][26/72]	Time  1.110 ( 0.723)	Data  0.973 ( 0.588)	Loss 1.3492e-01 (1.3984e-01) 
2023-05-26 02:24:53.202859: val Epoch: [77][27/72]	Time  0.323 ( 0.709)	Data  0.182 ( 0.574)	Loss 4.8099e-01 (1.5203e-01) 
2023-05-26 02:24:54.279261: val Epoch: [77][28/72]	Time  1.076 ( 0.722)	Data  0.945 ( 0.587)	Loss 8.6541e-02 (1.4977e-01) 
2023-05-26 02:24:54.509661: val Epoch: [77][29/72]	Time  0.230 ( 0.705)	Data  0.093 ( 0.570)	Loss 4.0511e-02 (1.4613e-01) 
2023-05-26 02:24:55.665162: val Epoch: [77][30/72]	Time  1.155 ( 0.720)	Data  1.014 ( 0.584)	Loss 4.6169e-02 (1.4290e-01) 
2023-05-26 02:24:55.897940: val Epoch: [77][31/72]	Time  0.233 ( 0.704)	Data  0.105 ( 0.569)	Loss 7.7126e-02 (1.4085e-01) 
2023-05-26 02:24:57.020277: val Epoch: [77][32/72]	Time  1.122 ( 0.717)	Data  0.986 ( 0.582)	Loss 1.5796e-01 (1.4137e-01) 
2023-05-26 02:24:57.263179: val Epoch: [77][33/72]	Time  0.243 ( 0.703)	Data  0.109 ( 0.568)	Loss 4.9605e-02 (1.3867e-01) 
2023-05-26 02:24:58.418300: val Epoch: [77][34/72]	Time  1.155 ( 0.716)	Data  1.026 ( 0.581)	Loss 5.3663e-02 (1.3624e-01) 
2023-05-26 02:24:58.692580: val Epoch: [77][35/72]	Time  0.274 ( 0.704)	Data  0.142 ( 0.569)	Loss 7.5246e-02 (1.3454e-01) 
2023-05-26 02:24:59.785426: val Epoch: [77][36/72]	Time  1.093 ( 0.714)	Data  0.959 ( 0.580)	Loss 5.6165e-02 (1.3243e-01) 
2023-05-26 02:25:00.079503: val Epoch: [77][37/72]	Time  0.294 ( 0.703)	Data  0.164 ( 0.569)	Loss 9.4548e-02 (1.3143e-01) 
2023-05-26 02:25:01.158493: val Epoch: [77][38/72]	Time  1.079 ( 0.713)	Data  0.949 ( 0.578)	Loss 3.0023e-02 (1.2883e-01) 
2023-05-26 02:25:01.500660: val Epoch: [77][39/72]	Time  0.342 ( 0.704)	Data  0.212 ( 0.569)	Loss 7.9473e-02 (1.2759e-01) 
2023-05-26 02:25:02.549795: val Epoch: [77][40/72]	Time  1.049 ( 0.712)	Data  0.921 ( 0.578)	Loss 1.3088e-01 (1.2767e-01) 
2023-05-26 02:25:02.853951: val Epoch: [77][41/72]	Time  0.304 ( 0.702)	Data  0.176 ( 0.568)	Loss 9.4463e-02 (1.2688e-01) 
2023-05-26 02:25:03.943240: val Epoch: [77][42/72]	Time  1.089 ( 0.711)	Data  0.957 ( 0.577)	Loss 3.6455e-01 (1.3241e-01) 
2023-05-26 02:25:04.231976: val Epoch: [77][43/72]	Time  0.289 ( 0.702)	Data  0.160 ( 0.568)	Loss 9.4785e-02 (1.3156e-01) 
2023-05-26 02:25:05.345713: val Epoch: [77][44/72]	Time  1.114 ( 0.711)	Data  0.983 ( 0.577)	Loss 4.5941e-01 (1.3884e-01) 
2023-05-26 02:25:05.650517: val Epoch: [77][45/72]	Time  0.305 ( 0.702)	Data  0.175 ( 0.568)	Loss 3.2666e-01 (1.4292e-01) 
2023-05-26 02:25:06.703683: val Epoch: [77][46/72]	Time  1.053 ( 0.710)	Data  0.919 ( 0.576)	Loss 4.6410e-02 (1.4087e-01) 
2023-05-26 02:25:07.087779: val Epoch: [77][47/72]	Time  0.384 ( 0.703)	Data  0.248 ( 0.569)	Loss 9.3050e-02 (1.3987e-01) 
2023-05-26 02:25:08.147552: val Epoch: [77][48/72]	Time  1.060 ( 0.710)	Data  0.912 ( 0.576)	Loss 6.0975e-02 (1.3826e-01) 
2023-05-26 02:25:08.529074: val Epoch: [77][49/72]	Time  0.381 ( 0.703)	Data  0.223 ( 0.569)	Loss 8.7289e-02 (1.3724e-01) 
2023-05-26 02:25:09.615499: val Epoch: [77][50/72]	Time  1.086 ( 0.711)	Data  0.951 ( 0.576)	Loss 1.5409e-01 (1.3758e-01) 
2023-05-26 02:25:09.910944: val Epoch: [77][51/72]	Time  0.295 ( 0.703)	Data  0.159 ( 0.568)	Loss 9.8381e-02 (1.3682e-01) 
2023-05-26 02:25:10.953001: val Epoch: [77][52/72]	Time  1.042 ( 0.709)	Data  0.914 ( 0.575)	Loss 4.3260e-02 (1.3506e-01) 
2023-05-26 02:25:11.217786: val Epoch: [77][53/72]	Time  0.265 ( 0.701)	Data  0.137 ( 0.567)	Loss 6.9990e-02 (1.3385e-01) 
2023-05-26 02:25:12.327676: val Epoch: [77][54/72]	Time  1.110 ( 0.709)	Data  0.966 ( 0.574)	Loss 1.2237e-01 (1.3364e-01) 
2023-05-26 02:25:12.533400: val Epoch: [77][55/72]	Time  0.206 ( 0.700)	Data  0.074 ( 0.565)	Loss 1.2675e-01 (1.3352e-01) 
2023-05-26 02:25:13.813653: val Epoch: [77][56/72]	Time  1.280 ( 0.710)	Data  1.011 ( 0.573)	Loss 8.6414e-02 (1.3269e-01) 
2023-05-26 02:25:13.942942: val Epoch: [77][57/72]	Time  0.129 ( 0.700)	Data  0.001 ( 0.563)	Loss 5.0136e-02 (1.3127e-01) 
2023-05-26 02:25:14.985821: val Epoch: [77][58/72]	Time  1.043 ( 0.706)	Data  0.910 ( 0.569)	Loss 9.8170e-02 (1.3071e-01) 
2023-05-26 02:25:15.257862: val Epoch: [77][59/72]	Time  0.272 ( 0.698)	Data  0.142 ( 0.562)	Loss 4.6197e-02 (1.2930e-01) 
2023-05-26 02:25:16.418046: val Epoch: [77][60/72]	Time  1.160 ( 0.706)	Data  1.031 ( 0.570)	Loss 9.8484e-02 (1.2880e-01) 
2023-05-26 02:25:16.628697: val Epoch: [77][61/72]	Time  0.211 ( 0.698)	Data  0.083 ( 0.562)	Loss 6.1174e-02 (1.2770e-01) 
2023-05-26 02:25:17.781343: val Epoch: [77][62/72]	Time  1.153 ( 0.705)	Data  1.024 ( 0.569)	Loss 6.4374e-02 (1.2670e-01) 
2023-05-26 02:25:17.959720: val Epoch: [77][63/72]	Time  0.178 ( 0.697)	Data  0.050 ( 0.561)	Loss 3.4765e-02 (1.2526e-01) 
2023-05-26 02:25:19.092793: val Epoch: [77][64/72]	Time  1.133 ( 0.704)	Data  1.007 ( 0.568)	Loss 4.5758e-02 (1.2404e-01) 
2023-05-26 02:25:19.291769: val Epoch: [77][65/72]	Time  0.199 ( 0.696)	Data  0.069 ( 0.560)	Loss 1.1335e-01 (1.2388e-01) 
2023-05-26 02:25:21.113605: val Epoch: [77][66/72]	Time  1.822 ( 0.713)	Data  1.694 ( 0.577)	Loss 1.2277e-01 (1.2386e-01) 
2023-05-26 02:25:21.570352: val Epoch: [77][67/72]	Time  0.457 ( 0.709)	Data  0.329 ( 0.573)	Loss 5.1526e-02 (1.2280e-01) 
2023-05-26 02:25:23.951856: val Epoch: [77][68/72]	Time  2.381 ( 0.733)	Data  2.058 ( 0.595)	Loss 2.2879e-01 (1.2433e-01) 
2023-05-26 02:25:24.186574: val Epoch: [77][69/72]	Time  0.235 ( 0.726)	Data  0.107 ( 0.588)	Loss 7.5382e-02 (1.2363e-01) 
2023-05-26 02:25:26.467644: val Epoch: [77][70/72]	Time  2.281 ( 0.748)	Data  1.943 ( 0.607)	Loss 4.5209e-02 (1.2253e-01) 
2023-05-26 02:25:26.597554: val Epoch: [77][71/72]	Time  0.130 ( 0.739)	Data  0.001 ( 0.599)	Loss 7.8610e-02 (1.2192e-01) 
2023-05-26 02:25:26.847620: Epoch 77 :Val : ['ET : 0.7564103007316589', 'TC : 0.7914636135101318', 'WT : 0.860956609249115'] 
2023-05-26 02:25:26.850747: Epoch 77 :Val : ['ET : 0.7564103007316589', 'TC : 0.7914636135101318', 'WT : 0.860956609249115'] 
2023-05-26 02:25:26.853565: Val epoch done in 54.488098212001205 s 
2023-05-26 02:25:26.859807: Batches per epoch:  129 
2023-05-26 02:25:36.589939: train Epoch: [78][  0/129]	Time  9.729 ( 9.729)	Data  8.675 ( 8.675)	Loss 1.1700e-01 (1.1700e-01) 
2023-05-26 02:25:37.868369: train Epoch: [78][  1/129]	Time  1.279 ( 5.504)	Data  0.002 ( 4.339)	Loss 6.1190e-02 (8.9093e-02) 
2023-05-26 02:25:44.759140: train Epoch: [78][  2/129]	Time  6.891 ( 5.966)	Data  5.491 ( 4.723)	Loss 4.6330e-02 (7.4839e-02) 
2023-05-26 02:25:45.870355: train Epoch: [78][  3/129]	Time  1.111 ( 4.752)	Data  0.002 ( 3.542)	Loss 5.7674e-02 (7.0548e-02) 
2023-05-26 02:25:52.982288: train Epoch: [78][  4/129]	Time  7.112 ( 5.224)	Data  6.047 ( 4.043)	Loss 8.2023e-02 (7.2843e-02) 
2023-05-26 02:25:53.960198: train Epoch: [78][  5/129]	Time  0.978 ( 4.517)	Data  0.001 ( 3.370)	Loss 8.7941e-02 (7.5359e-02) 
2023-05-26 02:25:58.666664: train Epoch: [78][  6/129]	Time  4.706 ( 4.544)	Data  3.745 ( 3.423)	Loss 6.5441e-02 (7.3942e-02) 
2023-05-26 02:25:59.629765: train Epoch: [78][  7/129]	Time  0.963 ( 4.096)	Data  0.001 ( 2.995)	Loss 5.6412e-02 (7.1751e-02) 
2023-05-26 02:26:02.803835: train Epoch: [78][  8/129]	Time  3.174 ( 3.994)	Data  2.189 ( 2.906)	Loss 1.8943e-01 (8.4826e-02) 
2023-05-26 02:26:03.780107: train Epoch: [78][  9/129]	Time  0.976 ( 3.692)	Data  0.001 ( 2.615)	Loss 6.8980e-02 (8.3241e-02) 
2023-05-26 02:26:06.853027: train Epoch: [78][ 10/129]	Time  3.073 ( 3.636)	Data  2.108 ( 2.569)	Loss 7.4854e-02 (8.2479e-02) 
2023-05-26 02:26:07.823870: train Epoch: [78][ 11/129]	Time  0.971 ( 3.414)	Data  0.002 ( 2.355)	Loss 4.5430e-02 (7.9391e-02) 
2023-05-26 02:26:11.321565: train Epoch: [78][ 12/129]	Time  3.498 ( 3.420)	Data  2.503 ( 2.367)	Loss 1.1444e-01 (8.2088e-02) 
2023-05-26 02:26:12.297904: train Epoch: [78][ 13/129]	Time  0.976 ( 3.246)	Data  0.001 ( 2.198)	Loss 5.5585e-02 (8.0195e-02) 
2023-05-26 02:26:15.494252: train Epoch: [78][ 14/129]	Time  3.196 ( 3.242)	Data  2.235 ( 2.200)	Loss 5.5554e-02 (7.8552e-02) 
2023-05-26 02:26:16.493436: train Epoch: [78][ 15/129]	Time  0.999 ( 3.102)	Data  0.001 ( 2.063)	Loss 7.0179e-02 (7.8029e-02) 
2023-05-26 02:26:19.554255: train Epoch: [78][ 16/129]	Time  3.061 ( 3.100)	Data  2.104 ( 2.065)	Loss 5.5679e-02 (7.6714e-02) 
2023-05-26 02:26:20.529286: train Epoch: [78][ 17/129]	Time  0.975 ( 2.982)	Data  0.001 ( 1.950)	Loss 6.2909e-02 (7.5947e-02) 
2023-05-26 02:26:23.625874: train Epoch: [78][ 18/129]	Time  3.097 ( 2.988)	Data  2.116 ( 1.959)	Loss 7.7969e-02 (7.6053e-02) 
2023-05-26 02:26:24.611588: train Epoch: [78][ 19/129]	Time  0.986 ( 2.888)	Data  0.002 ( 1.861)	Loss 5.4341e-02 (7.4968e-02) 
2023-05-26 02:26:27.737830: train Epoch: [78][ 20/129]	Time  3.126 ( 2.899)	Data  2.157 ( 1.875)	Loss 8.3294e-02 (7.5364e-02) 
2023-05-26 02:26:28.711949: train Epoch: [78][ 21/129]	Time  0.974 ( 2.811)	Data  0.001 ( 1.790)	Loss 6.8834e-02 (7.5067e-02) 
2023-05-26 02:26:31.911734: train Epoch: [78][ 22/129]	Time  3.200 ( 2.828)	Data  2.224 ( 1.809)	Loss 6.6924e-02 (7.4713e-02) 
2023-05-26 02:26:32.884503: train Epoch: [78][ 23/129]	Time  0.973 ( 2.751)	Data  0.001 ( 1.734)	Loss 5.3212e-02 (7.3818e-02) 
2023-05-26 02:26:36.020305: train Epoch: [78][ 24/129]	Time  3.136 ( 2.766)	Data  2.160 ( 1.751)	Loss 4.7131e-02 (7.2750e-02) 
2023-05-26 02:26:37.002591: train Epoch: [78][ 25/129]	Time  0.982 ( 2.698)	Data  0.002 ( 1.683)	Loss 5.6332e-02 (7.2119e-02) 
2023-05-26 02:26:40.126768: train Epoch: [78][ 26/129]	Time  3.124 ( 2.714)	Data  2.151 ( 1.701)	Loss 5.5037e-02 (7.1486e-02) 
2023-05-26 02:26:41.106126: train Epoch: [78][ 27/129]	Time  0.979 ( 2.652)	Data  0.001 ( 1.640)	Loss 8.9530e-02 (7.2130e-02) 
2023-05-26 02:26:44.266153: train Epoch: [78][ 28/129]	Time  3.160 ( 2.669)	Data  2.192 ( 1.659)	Loss 8.6876e-02 (7.2639e-02) 
2023-05-26 02:26:45.239700: train Epoch: [78][ 29/129]	Time  0.974 ( 2.613)	Data  0.001 ( 1.604)	Loss 7.6009e-02 (7.2751e-02) 
2023-05-26 02:26:48.209245: train Epoch: [78][ 30/129]	Time  2.970 ( 2.624)	Data  1.997 ( 1.617)	Loss 8.4394e-02 (7.3127e-02) 
2023-05-26 02:26:49.173960: train Epoch: [78][ 31/129]	Time  0.965 ( 2.572)	Data  0.001 ( 1.566)	Loss 5.4815e-02 (7.2555e-02) 
2023-05-26 02:26:52.302667: train Epoch: [78][ 32/129]	Time  3.129 ( 2.589)	Data  2.140 ( 1.583)	Loss 1.0113e-01 (7.3420e-02) 
2023-05-26 02:26:53.295134: train Epoch: [78][ 33/129]	Time  0.992 ( 2.542)	Data  0.001 ( 1.537)	Loss 8.3556e-02 (7.3719e-02) 
2023-05-26 02:26:56.418206: train Epoch: [78][ 34/129]	Time  3.123 ( 2.559)	Data  2.144 ( 1.554)	Loss 9.6384e-02 (7.4366e-02) 
2023-05-26 02:26:57.389077: train Epoch: [78][ 35/129]	Time  0.971 ( 2.515)	Data  0.001 ( 1.511)	Loss 1.0838e-01 (7.5311e-02) 
2023-05-26 02:27:00.530116: train Epoch: [78][ 36/129]	Time  3.141 ( 2.532)	Data  2.161 ( 1.529)	Loss 5.8674e-02 (7.4861e-02) 
2023-05-26 02:27:01.508459: train Epoch: [78][ 37/129]	Time  0.978 ( 2.491)	Data  0.001 ( 1.488)	Loss 8.1109e-02 (7.5026e-02) 
2023-05-26 02:27:04.635530: train Epoch: [78][ 38/129]	Time  3.127 ( 2.507)	Data  2.157 ( 1.506)	Loss 6.7125e-02 (7.4823e-02) 
2023-05-26 02:27:05.632886: train Epoch: [78][ 39/129]	Time  0.997 ( 2.469)	Data  0.001 ( 1.468)	Loss 1.3813e-01 (7.6406e-02) 
2023-05-26 02:27:08.853153: train Epoch: [78][ 40/129]	Time  3.220 ( 2.488)	Data  2.245 ( 1.487)	Loss 6.9591e-02 (7.6240e-02) 
2023-05-26 02:27:09.828197: train Epoch: [78][ 41/129]	Time  0.975 ( 2.452)	Data  0.001 ( 1.452)	Loss 4.6705e-02 (7.5536e-02) 
2023-05-26 02:27:12.994907: train Epoch: [78][ 42/129]	Time  3.167 ( 2.468)	Data  2.196 ( 1.469)	Loss 8.5988e-02 (7.5779e-02) 
2023-05-26 02:27:13.981015: train Epoch: [78][ 43/129]	Time  0.986 ( 2.435)	Data  0.001 ( 1.435)	Loss 6.0652e-02 (7.5436e-02) 
2023-05-26 02:27:17.191929: train Epoch: [78][ 44/129]	Time  3.211 ( 2.452)	Data  2.226 ( 1.453)	Loss 6.3020e-02 (7.5160e-02) 
2023-05-26 02:27:18.387247: train Epoch: [78][ 45/129]	Time  1.195 ( 2.424)	Data  0.001 ( 1.421)	Loss 3.9521e-02 (7.4385e-02) 
2023-05-26 02:27:21.209990: train Epoch: [78][ 46/129]	Time  2.823 ( 2.433)	Data  1.845 ( 1.431)	Loss 1.0523e-01 (7.5041e-02) 
2023-05-26 02:27:22.177606: train Epoch: [78][ 47/129]	Time  0.968 ( 2.402)	Data  0.001 ( 1.401)	Loss 5.3201e-02 (7.4586e-02) 
2023-05-26 02:27:26.310069: train Epoch: [78][ 48/129]	Time  4.132 ( 2.438)	Data  3.153 ( 1.436)	Loss 7.2423e-02 (7.4542e-02) 
2023-05-26 02:27:27.407325: train Epoch: [78][ 49/129]	Time  1.097 ( 2.411)	Data  0.002 ( 1.408)	Loss 7.9577e-02 (7.4643e-02) 
2023-05-26 02:27:34.681035: train Epoch: [78][ 50/129]	Time  7.274 ( 2.506)	Data  6.307 ( 1.504)	Loss 4.7836e-02 (7.4117e-02) 
2023-05-26 02:27:35.958111: train Epoch: [78][ 51/129]	Time  1.277 ( 2.483)	Data  0.001 ( 1.475)	Loss 6.0615e-02 (7.3857e-02) 
2023-05-26 02:27:42.844215: train Epoch: [78][ 52/129]	Time  6.886 ( 2.566)	Data  5.913 ( 1.559)	Loss 6.6403e-02 (7.3717e-02) 
2023-05-26 02:27:44.059870: train Epoch: [78][ 53/129]	Time  1.216 ( 2.541)	Data  0.001 ( 1.530)	Loss 8.3586e-02 (7.3900e-02) 
2023-05-26 02:27:51.023103: train Epoch: [78][ 54/129]	Time  6.963 ( 2.621)	Data  5.964 ( 1.610)	Loss 9.8619e-02 (7.4349e-02) 
2023-05-26 02:27:52.481390: train Epoch: [78][ 55/129]	Time  1.458 ( 2.600)	Data  0.001 ( 1.582)	Loss 4.0236e-02 (7.3740e-02) 
2023-05-26 02:27:59.150084: train Epoch: [78][ 56/129]	Time  6.669 ( 2.672)	Data  5.703 ( 1.654)	Loss 6.2885e-02 (7.3549e-02) 
2023-05-26 02:28:00.236286: train Epoch: [78][ 57/129]	Time  1.086 ( 2.644)	Data  0.001 ( 1.626)	Loss 9.6872e-02 (7.3952e-02) 
2023-05-26 02:28:07.180330: train Epoch: [78][ 58/129]	Time  6.944 ( 2.717)	Data  5.918 ( 1.698)	Loss 9.4554e-02 (7.4301e-02) 
2023-05-26 02:28:08.180835: train Epoch: [78][ 59/129]	Time  1.000 ( 2.689)	Data  0.001 ( 1.670)	Loss 5.8433e-02 (7.4036e-02) 
2023-05-26 02:28:15.455694: train Epoch: [78][ 60/129]	Time  7.275 ( 2.764)	Data  6.185 ( 1.744)	Loss 7.0162e-02 (7.3973e-02) 
2023-05-26 02:28:16.430438: train Epoch: [78][ 61/129]	Time  0.975 ( 2.735)	Data  0.001 ( 1.716)	Loss 6.5083e-02 (7.3829e-02) 
2023-05-26 02:28:23.484746: train Epoch: [78][ 62/129]	Time  7.054 ( 2.804)	Data  5.949 ( 1.783)	Loss 4.1154e-02 (7.3311e-02) 
2023-05-26 02:28:24.455268: train Epoch: [78][ 63/129]	Time  0.971 ( 2.775)	Data  0.001 ( 1.755)	Loss 8.4635e-02 (7.3488e-02) 
2023-05-26 02:28:31.583848: train Epoch: [78][ 64/129]	Time  7.129 ( 2.842)	Data  6.153 ( 1.823)	Loss 7.8042e-02 (7.3558e-02) 
2023-05-26 02:28:32.554045: train Epoch: [78][ 65/129]	Time  0.970 ( 2.814)	Data  0.001 ( 1.795)	Loss 5.1004e-02 (7.3216e-02) 
2023-05-26 02:28:39.733382: train Epoch: [78][ 66/129]	Time  7.179 ( 2.879)	Data  6.136 ( 1.860)	Loss 9.4001e-02 (7.3526e-02) 
2023-05-26 02:28:40.726995: train Epoch: [78][ 67/129]	Time  0.994 ( 2.851)	Data  0.001 ( 1.833)	Loss 9.2962e-02 (7.3812e-02) 
2023-05-26 02:28:47.800141: train Epoch: [78][ 68/129]	Time  7.073 ( 2.912)	Data  6.006 ( 1.893)	Loss 1.0002e-01 (7.4192e-02) 
2023-05-26 02:28:48.827327: train Epoch: [78][ 69/129]	Time  1.027 ( 2.885)	Data  0.002 ( 1.866)	Loss 4.9654e-02 (7.3841e-02) 
2023-05-26 02:28:56.136322: train Epoch: [78][ 70/129]	Time  7.309 ( 2.948)	Data  6.259 ( 1.928)	Loss 7.2866e-02 (7.3828e-02) 
2023-05-26 02:28:57.176620: train Epoch: [78][ 71/129]	Time  1.040 ( 2.921)	Data  0.002 ( 1.901)	Loss 5.3128e-02 (7.3540e-02) 
2023-05-26 02:29:04.396663: train Epoch: [78][ 72/129]	Time  7.220 ( 2.980)	Data  6.052 ( 1.958)	Loss 7.6194e-02 (7.3576e-02) 
2023-05-26 02:29:05.429183: train Epoch: [78][ 73/129]	Time  1.033 ( 2.954)	Data  0.002 ( 1.932)	Loss 6.6619e-02 (7.3482e-02) 
2023-05-26 02:29:12.305796: train Epoch: [78][ 74/129]	Time  6.877 ( 3.006)	Data  5.751 ( 1.983)	Loss 4.5274e-02 (7.3106e-02) 
2023-05-26 02:29:13.315298: train Epoch: [78][ 75/129]	Time  1.010 ( 2.980)	Data  0.002 ( 1.957)	Loss 7.2285e-02 (7.3096e-02) 
2023-05-26 02:29:20.378246: train Epoch: [78][ 76/129]	Time  7.063 ( 3.033)	Data  6.055 ( 2.010)	Loss 5.9835e-02 (7.2923e-02) 
2023-05-26 02:29:21.607385: train Epoch: [78][ 77/129]	Time  1.229 ( 3.010)	Data  0.001 ( 1.984)	Loss 5.2181e-02 (7.2657e-02) 
2023-05-26 02:29:28.337868: train Epoch: [78][ 78/129]	Time  6.730 ( 3.057)	Data  5.752 ( 2.032)	Loss 1.1454e-01 (7.3188e-02) 
2023-05-26 02:29:29.512134: train Epoch: [78][ 79/129]	Time  1.174 ( 3.033)	Data  0.002 ( 2.006)	Loss 8.2670e-02 (7.3306e-02) 
2023-05-26 02:29:36.433254: train Epoch: [78][ 80/129]	Time  6.921 ( 3.081)	Data  5.942 ( 2.055)	Loss 5.9433e-02 (7.3135e-02) 
2023-05-26 02:29:37.672127: train Epoch: [78][ 81/129]	Time  1.239 ( 3.059)	Data  0.001 ( 2.030)	Loss 1.4174e-01 (7.3971e-02) 
2023-05-26 02:29:44.548115: train Epoch: [78][ 82/129]	Time  6.876 ( 3.105)	Data  5.906 ( 2.077)	Loss 8.8681e-02 (7.4149e-02) 
2023-05-26 02:29:45.605119: train Epoch: [78][ 83/129]	Time  1.057 ( 3.080)	Data  0.001 ( 2.052)	Loss 5.4850e-02 (7.3919e-02) 
2023-05-26 02:29:53.269841: train Epoch: [78][ 84/129]	Time  7.665 ( 3.134)	Data  6.551 ( 2.105)	Loss 8.0297e-02 (7.3994e-02) 
2023-05-26 02:29:54.280106: train Epoch: [78][ 85/129]	Time  1.010 ( 3.110)	Data  0.001 ( 2.080)	Loss 7.0883e-02 (7.3958e-02) 
2023-05-26 02:30:01.446889: train Epoch: [78][ 86/129]	Time  7.167 ( 3.156)	Data  6.182 ( 2.128)	Loss 8.3212e-02 (7.4064e-02) 
2023-05-26 02:30:02.470161: train Epoch: [78][ 87/129]	Time  1.023 ( 3.132)	Data  0.001 ( 2.103)	Loss 1.0608e-01 (7.4428e-02) 
2023-05-26 02:30:10.061862: train Epoch: [78][ 88/129]	Time  7.592 ( 3.182)	Data  6.300 ( 2.151)	Loss 8.3890e-02 (7.4534e-02) 
2023-05-26 02:30:11.249444: train Epoch: [78][ 89/129]	Time  1.188 ( 3.160)	Data  0.001 ( 2.127)	Loss 8.9984e-02 (7.4706e-02) 
2023-05-26 02:30:17.799652: train Epoch: [78][ 90/129]	Time  6.550 ( 3.197)	Data  5.535 ( 2.164)	Loss 1.0401e-01 (7.5028e-02) 
2023-05-26 02:30:18.806378: train Epoch: [78][ 91/129]	Time  1.007 ( 3.173)	Data  0.001 ( 2.141)	Loss 5.3691e-02 (7.4796e-02) 
2023-05-26 02:30:25.719069: train Epoch: [78][ 92/129]	Time  6.913 ( 3.214)	Data  5.622 ( 2.178)	Loss 9.2896e-02 (7.4991e-02) 
2023-05-26 02:30:26.707259: train Epoch: [78][ 93/129]	Time  0.988 ( 3.190)	Data  0.001 ( 2.155)	Loss 8.2421e-02 (7.5070e-02) 
2023-05-26 02:30:33.248752: train Epoch: [78][ 94/129]	Time  6.541 ( 3.225)	Data  5.542 ( 2.191)	Loss 4.9146e-02 (7.4797e-02) 
2023-05-26 02:30:34.237324: train Epoch: [78][ 95/129]	Time  0.989 ( 3.202)	Data  0.001 ( 2.168)	Loss 9.8654e-02 (7.5045e-02) 
2023-05-26 02:30:40.934410: train Epoch: [78][ 96/129]	Time  6.697 ( 3.238)	Data  5.697 ( 2.204)	Loss 8.5793e-02 (7.5156e-02) 
2023-05-26 02:30:41.888705: train Epoch: [78][ 97/129]	Time  0.954 ( 3.215)	Data  0.001 ( 2.182)	Loss 6.5136e-02 (7.5054e-02) 
2023-05-26 02:30:48.621671: train Epoch: [78][ 98/129]	Time  6.733 ( 3.250)	Data  5.775 ( 2.218)	Loss 9.6505e-02 (7.5271e-02) 
2023-05-26 02:30:49.580302: train Epoch: [78][ 99/129]	Time  0.959 ( 3.227)	Data  0.001 ( 2.196)	Loss 4.0817e-02 (7.4926e-02) 
2023-05-26 02:30:56.784454: train Epoch: [78][100/129]	Time  7.204 ( 3.267)	Data  5.890 ( 2.232)	Loss 5.6554e-02 (7.4744e-02) 
2023-05-26 02:30:57.765984: train Epoch: [78][101/129]	Time  0.982 ( 3.244)	Data  0.001 ( 2.210)	Loss 6.8084e-02 (7.4679e-02) 
2023-05-26 02:31:04.525378: train Epoch: [78][102/129]	Time  6.759 ( 3.278)	Data  5.718 ( 2.245)	Loss 7.2153e-02 (7.4654e-02) 
2023-05-26 02:31:05.638820: train Epoch: [78][103/129]	Time  1.113 ( 3.257)	Data  0.001 ( 2.223)	Loss 4.8444e-02 (7.4402e-02) 
2023-05-26 02:31:12.911535: train Epoch: [78][104/129]	Time  7.273 ( 3.296)	Data  6.039 ( 2.259)	Loss 6.7885e-02 (7.4340e-02) 
2023-05-26 02:31:13.962373: train Epoch: [78][105/129]	Time  1.051 ( 3.275)	Data  0.001 ( 2.238)	Loss 5.9398e-02 (7.4199e-02) 
2023-05-26 02:31:21.145812: train Epoch: [78][106/129]	Time  7.183 ( 3.311)	Data  6.059 ( 2.274)	Loss 5.7405e-02 (7.4042e-02) 
2023-05-26 02:31:22.151632: train Epoch: [78][107/129]	Time  1.006 ( 3.290)	Data  0.001 ( 2.253)	Loss 8.4775e-02 (7.4142e-02) 
2023-05-26 02:31:29.480226: train Epoch: [78][108/129]	Time  7.329 ( 3.327)	Data  6.324 ( 2.290)	Loss 9.2743e-02 (7.4312e-02) 
2023-05-26 02:31:30.490548: train Epoch: [78][109/129]	Time  1.010 ( 3.306)	Data  0.002 ( 2.269)	Loss 7.4735e-02 (7.4316e-02) 
2023-05-26 02:31:37.803523: train Epoch: [78][110/129]	Time  7.313 ( 3.342)	Data  6.299 ( 2.306)	Loss 6.6989e-02 (7.4250e-02) 
2023-05-26 02:31:38.853422: train Epoch: [78][111/129]	Time  1.050 ( 3.321)	Data  0.001 ( 2.285)	Loss 6.7990e-02 (7.4194e-02) 
2023-05-26 02:31:45.941010: train Epoch: [78][112/129]	Time  7.088 ( 3.355)	Data  6.082 ( 2.319)	Loss 6.5047e-02 (7.4113e-02) 
2023-05-26 02:31:46.958005: train Epoch: [78][113/129]	Time  1.017 ( 3.334)	Data  0.002 ( 2.298)	Loss 6.9689e-02 (7.4075e-02) 
2023-05-26 02:31:54.176971: train Epoch: [78][114/129]	Time  7.219 ( 3.368)	Data  6.244 ( 2.333)	Loss 9.5483e-02 (7.4261e-02) 
2023-05-26 02:31:55.150852: train Epoch: [78][115/129]	Time  0.974 ( 3.347)	Data  0.002 ( 2.312)	Loss 8.8155e-02 (7.4380e-02) 
2023-05-26 02:32:02.425213: train Epoch: [78][116/129]	Time  7.274 ( 3.381)	Data  6.306 ( 2.347)	Loss 7.0267e-02 (7.4345e-02) 
2023-05-26 02:32:03.420332: train Epoch: [78][117/129]	Time  0.995 ( 3.361)	Data  0.001 ( 2.327)	Loss 4.5920e-02 (7.4104e-02) 
2023-05-26 02:32:10.947511: train Epoch: [78][118/129]	Time  7.527 ( 3.396)	Data  6.383 ( 2.361)	Loss 7.2973e-02 (7.4095e-02) 
2023-05-26 02:32:12.020949: train Epoch: [78][119/129]	Time  1.073 ( 3.376)	Data  0.001 ( 2.341)	Loss 9.2848e-02 (7.4251e-02) 
2023-05-26 02:32:18.766087: train Epoch: [78][120/129]	Time  6.745 ( 3.404)	Data  5.749 ( 2.369)	Loss 5.3102e-02 (7.4076e-02) 
2023-05-26 02:32:19.758837: train Epoch: [78][121/129]	Time  0.993 ( 3.384)	Data  0.001 ( 2.350)	Loss 5.2745e-02 (7.3902e-02) 
2023-05-26 02:32:26.885340: train Epoch: [78][122/129]	Time  7.126 ( 3.415)	Data  6.137 ( 2.381)	Loss 6.6404e-02 (7.3841e-02) 
2023-05-26 02:32:27.856278: train Epoch: [78][123/129]	Time  0.971 ( 3.395)	Data  0.001 ( 2.361)	Loss 7.6547e-02 (7.3862e-02) 
2023-05-26 02:32:34.736219: train Epoch: [78][124/129]	Time  6.880 ( 3.423)	Data  5.909 ( 2.390)	Loss 6.4057e-02 (7.3784e-02) 
2023-05-26 02:32:36.104551: train Epoch: [78][125/129]	Time  1.368 ( 3.407)	Data  0.001 ( 2.371)	Loss 5.6461e-02 (7.3647e-02) 
2023-05-26 02:32:42.631794: train Epoch: [78][126/129]	Time  6.527 ( 3.431)	Data  5.554 ( 2.396)	Loss 4.4169e-02 (7.3414e-02) 
2023-05-26 02:32:43.784204: train Epoch: [78][127/129]	Time  1.152 ( 3.413)	Data  0.001 ( 2.377)	Loss 7.2252e-02 (7.3405e-02) 
2023-05-26 02:32:48.921240: train Epoch: [78][128/129]	Time  5.137 ( 3.427)	Data  3.861 ( 2.389)	Loss 5.2221e-02 (7.3241e-02) 
2023-05-26 02:32:48.994313: Train Epoch done in 442.13456995199886 s 
2023-05-26 02:32:53.580565: val Epoch: [78][ 0/72]	Time  3.499 ( 3.499)	Data  3.114 ( 3.114)	Loss 7.1672e-02 (7.1672e-02) 
2023-05-26 02:32:53.961643: val Epoch: [78][ 1/72]	Time  0.381 ( 1.940)	Data  0.002 ( 1.558)	Loss 4.0245e-02 (5.5958e-02) 
2023-05-26 02:32:56.098444: val Epoch: [78][ 2/72]	Time  2.137 ( 2.006)	Data  1.933 ( 1.683)	Loss 5.0787e-02 (5.4235e-02) 
2023-05-26 02:32:56.237090: val Epoch: [78][ 3/72]	Time  0.139 ( 1.539)	Data  0.001 ( 1.262)	Loss 3.4394e-02 (4.9275e-02) 
2023-05-26 02:32:58.678860: val Epoch: [78][ 4/72]	Time  2.442 ( 1.719)	Data  2.317 ( 1.473)	Loss 8.2882e-02 (5.5996e-02) 
2023-05-26 02:32:58.867253: val Epoch: [78][ 5/72]	Time  0.188 ( 1.464)	Data  0.055 ( 1.237)	Loss 5.3925e-02 (5.5651e-02) 
2023-05-26 02:33:01.476321: val Epoch: [78][ 6/72]	Time  2.609 ( 1.628)	Data  2.463 ( 1.412)	Loss 4.0716e-02 (5.3517e-02) 
2023-05-26 02:33:01.776086: val Epoch: [78][ 7/72]	Time  0.300 ( 1.462)	Data  0.160 ( 1.256)	Loss 7.6510e-02 (5.6391e-02) 
2023-05-26 02:33:04.203346: val Epoch: [78][ 8/72]	Time  2.427 ( 1.569)	Data  2.287 ( 1.370)	Loss 3.5755e-01 (8.9854e-02) 
2023-05-26 02:33:04.350685: val Epoch: [78][ 9/72]	Time  0.147 ( 1.427)	Data  0.007 ( 1.234)	Loss 5.0245e-02 (8.5893e-02) 
2023-05-26 02:33:06.779568: val Epoch: [78][10/72]	Time  2.429 ( 1.518)	Data  2.300 ( 1.331)	Loss 1.6377e-01 (9.2972e-02) 
2023-05-26 02:33:07.114615: val Epoch: [78][11/72]	Time  0.335 ( 1.419)	Data  0.207 ( 1.237)	Loss 5.7013e-02 (8.9976e-02) 
2023-05-26 02:33:09.566637: val Epoch: [78][12/72]	Time  2.452 ( 1.499)	Data  2.323 ( 1.321)	Loss 8.9205e-02 (8.9917e-02) 
2023-05-26 02:33:09.792494: val Epoch: [78][13/72]	Time  0.226 ( 1.408)	Data  0.093 ( 1.233)	Loss 1.5146e-01 (9.4313e-02) 
2023-05-26 02:33:12.288656: val Epoch: [78][14/72]	Time  2.496 ( 1.480)	Data  2.367 ( 1.309)	Loss 3.3592e-02 (9.0265e-02) 
2023-05-26 02:33:12.491416: val Epoch: [78][15/72]	Time  0.203 ( 1.401)	Data  0.066 ( 1.231)	Loss 8.4337e-02 (8.9894e-02) 
2023-05-26 02:33:15.189787: val Epoch: [78][16/72]	Time  2.698 ( 1.477)	Data  2.556 ( 1.309)	Loss 1.8848e-01 (9.5693e-02) 
2023-05-26 02:33:15.327290: val Epoch: [78][17/72]	Time  0.137 ( 1.403)	Data  0.001 ( 1.236)	Loss 5.9588e-02 (9.3688e-02) 
2023-05-26 02:33:17.858486: val Epoch: [78][18/72]	Time  2.531 ( 1.462)	Data  2.286 ( 1.291)	Loss 4.8841e-02 (9.1327e-02) 
2023-05-26 02:33:17.991242: val Epoch: [78][19/72]	Time  0.133 ( 1.395)	Data  0.001 ( 1.227)	Loss 8.7964e-02 (9.1159e-02) 
2023-05-26 02:33:20.680951: val Epoch: [78][20/72]	Time  2.690 ( 1.457)	Data  2.120 ( 1.269)	Loss 5.4599e-02 (8.9418e-02) 
2023-05-26 02:33:20.812955: val Epoch: [78][21/72]	Time  0.132 ( 1.397)	Data  0.001 ( 1.212)	Loss 6.2159e-02 (8.8179e-02) 
2023-05-26 02:33:23.329662: val Epoch: [78][22/72]	Time  2.517 ( 1.446)	Data  1.982 ( 1.245)	Loss 6.6065e-02 (8.7218e-02) 
2023-05-26 02:33:23.516376: val Epoch: [78][23/72]	Time  0.187 ( 1.393)	Data  0.001 ( 1.193)	Loss 3.8255e-01 (9.9523e-02) 
2023-05-26 02:33:26.096017: val Epoch: [78][24/72]	Time  2.580 ( 1.441)	Data  2.022 ( 1.227)	Loss 1.0404e-01 (9.9704e-02) 
2023-05-26 02:33:26.237125: val Epoch: [78][25/72]	Time  0.141 ( 1.391)	Data  0.001 ( 1.179)	Loss 4.2426e-02 (9.7501e-02) 
2023-05-26 02:33:28.604931: val Epoch: [78][26/72]	Time  2.368 ( 1.427)	Data  1.962 ( 1.208)	Loss 7.8974e-02 (9.6815e-02) 
2023-05-26 02:33:28.743156: val Epoch: [78][27/72]	Time  0.138 ( 1.381)	Data  0.001 ( 1.165)	Loss 5.5384e-02 (9.5335e-02) 
2023-05-26 02:33:31.384858: val Epoch: [78][28/72]	Time  2.642 ( 1.424)	Data  2.003 ( 1.194)	Loss 8.5645e-02 (9.5001e-02) 
2023-05-26 02:33:31.521805: val Epoch: [78][29/72]	Time  0.137 ( 1.381)	Data  0.001 ( 1.154)	Loss 3.1187e-01 (1.0223e-01) 
2023-05-26 02:33:33.741280: val Epoch: [78][30/72]	Time  2.219 ( 1.408)	Data  1.893 ( 1.178)	Loss 5.0476e-02 (1.0056e-01) 
2023-05-26 02:33:34.075735: val Epoch: [78][31/72]	Time  0.334 ( 1.375)	Data  0.062 ( 1.143)	Loss 2.7725e-01 (1.0608e-01) 
2023-05-26 02:33:36.403585: val Epoch: [78][32/72]	Time  2.328 ( 1.404)	Data  2.070 ( 1.171)	Loss 1.8071e-01 (1.0834e-01) 
2023-05-26 02:33:36.983386: val Epoch: [78][33/72]	Time  0.580 ( 1.379)	Data  0.107 ( 1.140)	Loss 3.3093e-01 (1.1489e-01) 
2023-05-26 02:33:39.293167: val Epoch: [78][34/72]	Time  2.310 ( 1.406)	Data  1.940 ( 1.163)	Loss 1.5213e-01 (1.1595e-01) 
2023-05-26 02:33:39.642420: val Epoch: [78][35/72]	Time  0.349 ( 1.377)	Data  0.061 ( 1.132)	Loss 3.4742e-01 (1.2238e-01) 
2023-05-26 02:33:42.265633: val Epoch: [78][36/72]	Time  2.623 ( 1.410)	Data  2.139 ( 1.160)	Loss 7.3213e-02 (1.2105e-01) 
2023-05-26 02:33:42.408115: val Epoch: [78][37/72]	Time  0.142 ( 1.377)	Data  0.001 ( 1.129)	Loss 4.3643e-02 (1.1902e-01) 
2023-05-26 02:33:45.033142: val Epoch: [78][38/72]	Time  2.625 ( 1.409)	Data  2.083 ( 1.154)	Loss 8.2097e-02 (1.1807e-01) 
2023-05-26 02:33:45.184283: val Epoch: [78][39/72]	Time  0.151 ( 1.378)	Data  0.001 ( 1.125)	Loss 5.8633e-02 (1.1658e-01) 
2023-05-26 02:33:47.749827: val Epoch: [78][40/72]	Time  2.566 ( 1.407)	Data  1.974 ( 1.145)	Loss 1.2122e-01 (1.1670e-01) 
2023-05-26 02:33:47.897339: val Epoch: [78][41/72]	Time  0.148 ( 1.377)	Data  0.003 ( 1.118)	Loss 4.3693e-01 (1.2432e-01) 
2023-05-26 02:33:49.876721: val Epoch: [78][42/72]	Time  1.979 ( 1.391)	Data  1.854 ( 1.135)	Loss 1.3116e-01 (1.2448e-01) 
2023-05-26 02:33:50.663597: val Epoch: [78][43/72]	Time  0.787 ( 1.377)	Data  0.359 ( 1.118)	Loss 4.2803e-02 (1.2262e-01) 
2023-05-26 02:33:52.515491: val Epoch: [78][44/72]	Time  1.852 ( 1.387)	Data  1.723 ( 1.131)	Loss 8.2619e-02 (1.2174e-01) 
2023-05-26 02:33:53.301987: val Epoch: [78][45/72]	Time  0.786 ( 1.374)	Data  0.283 ( 1.113)	Loss 3.5458e-02 (1.1986e-01) 
2023-05-26 02:33:55.219216: val Epoch: [78][46/72]	Time  1.917 ( 1.386)	Data  1.777 ( 1.127)	Loss 1.0446e-01 (1.1953e-01) 
2023-05-26 02:33:55.645394: val Epoch: [78][47/72]	Time  0.426 ( 1.366)	Data  0.227 ( 1.108)	Loss 5.1207e-02 (1.1811e-01) 
2023-05-26 02:33:57.929202: val Epoch: [78][48/72]	Time  2.284 ( 1.385)	Data  2.139 ( 1.129)	Loss 3.1777e-01 (1.2218e-01) 
2023-05-26 02:33:58.274507: val Epoch: [78][49/72]	Time  0.345 ( 1.364)	Data  0.201 ( 1.111)	Loss 1.1225e-01 (1.2199e-01) 
2023-05-26 02:34:00.692574: val Epoch: [78][50/72]	Time  2.418 ( 1.385)	Data  2.249 ( 1.133)	Loss 8.0331e-02 (1.2117e-01) 
2023-05-26 02:34:00.872105: val Epoch: [78][51/72]	Time  0.179 ( 1.361)	Data  0.041 ( 1.112)	Loss 6.1700e-02 (1.2002e-01) 
2023-05-26 02:34:03.596628: val Epoch: [78][52/72]	Time  2.725 ( 1.387)	Data  2.377 ( 1.136)	Loss 3.8814e-01 (1.2508e-01) 
2023-05-26 02:34:03.737255: val Epoch: [78][53/72]	Time  0.141 ( 1.364)	Data  0.001 ( 1.115)	Loss 5.9343e-02 (1.2387e-01) 
2023-05-26 02:34:06.416021: val Epoch: [78][54/72]	Time  2.679 ( 1.388)	Data  2.295 ( 1.136)	Loss 2.8845e-01 (1.2686e-01) 
2023-05-26 02:34:06.545089: val Epoch: [78][55/72]	Time  0.129 ( 1.365)	Data  0.001 ( 1.116)	Loss 1.0728e-01 (1.2651e-01) 
2023-05-26 02:34:09.149078: val Epoch: [78][56/72]	Time  2.604 ( 1.387)	Data  2.155 ( 1.134)	Loss 2.7883e-01 (1.2918e-01) 
2023-05-26 02:34:09.271693: val Epoch: [78][57/72]	Time  0.123 ( 1.365)	Data  0.001 ( 1.115)	Loss 9.3107e-02 (1.2856e-01) 
2023-05-26 02:34:11.831935: val Epoch: [78][58/72]	Time  2.560 ( 1.386)	Data  1.987 ( 1.129)	Loss 5.7956e-02 (1.2736e-01) 
2023-05-26 02:34:11.972556: val Epoch: [78][59/72]	Time  0.141 ( 1.365)	Data  0.001 ( 1.111)	Loss 2.7200e-01 (1.2977e-01) 
2023-05-26 02:34:14.164979: val Epoch: [78][60/72]	Time  2.192 ( 1.378)	Data  2.016 ( 1.125)	Loss 2.6978e-01 (1.3207e-01) 
2023-05-26 02:34:14.701901: val Epoch: [78][61/72]	Time  0.537 ( 1.365)	Data  0.362 ( 1.113)	Loss 1.3222e-01 (1.3207e-01) 
2023-05-26 02:34:16.735977: val Epoch: [78][62/72]	Time  2.034 ( 1.375)	Data  1.854 ( 1.125)	Loss 5.2259e-02 (1.3080e-01) 
2023-05-26 02:34:17.482020: val Epoch: [78][63/72]	Time  0.746 ( 1.366)	Data  0.616 ( 1.117)	Loss 1.5607e-01 (1.3120e-01) 
2023-05-26 02:34:19.673341: val Epoch: [78][64/72]	Time  2.191 ( 1.378)	Data  1.887 ( 1.129)	Loss 4.8927e-02 (1.2993e-01) 
2023-05-26 02:34:20.166986: val Epoch: [78][65/72]	Time  0.494 ( 1.365)	Data  0.338 ( 1.117)	Loss 7.2279e-02 (1.2906e-01) 
2023-05-26 02:34:22.135210: val Epoch: [78][66/72]	Time  1.968 ( 1.374)	Data  1.840 ( 1.128)	Loss 3.8116e-02 (1.2770e-01) 
2023-05-26 02:34:23.005868: val Epoch: [78][67/72]	Time  0.871 ( 1.367)	Data  0.739 ( 1.122)	Loss 1.8693e-01 (1.2857e-01) 
2023-05-26 02:34:25.143283: val Epoch: [78][68/72]	Time  2.137 ( 1.378)	Data  2.006 ( 1.135)	Loss 6.7141e-02 (1.2768e-01) 
2023-05-26 02:34:25.919845: val Epoch: [78][69/72]	Time  0.777 ( 1.369)	Data  0.285 ( 1.123)	Loss 1.1491e-01 (1.2750e-01) 
2023-05-26 02:34:27.968658: val Epoch: [78][70/72]	Time  2.049 ( 1.379)	Data  1.918 ( 1.134)	Loss 5.4781e-02 (1.2648e-01) 
2023-05-26 02:34:28.701790: val Epoch: [78][71/72]	Time  0.733 ( 1.370)	Data  0.220 ( 1.121)	Loss 2.2973e-01 (1.2791e-01) 
2023-05-26 02:34:28.952522: Epoch 78 :Val : ['ET : 0.7512955069541931', 'TC : 0.7774083018302917', 'WT : 0.8687863945960999'] 
2023-05-26 02:34:28.953928: Epoch 78 :Val : ['ET : 0.7512955069541931', 'TC : 0.7774083018302917', 'WT : 0.8687863945960999'] 
2023-05-26 02:34:28.960901: Val epoch done in 99.96658785199907 s 
2023-05-26 02:34:28.970607: Batches per epoch:  129 
2023-05-26 02:34:38.878995: train Epoch: [79][  0/129]	Time  9.908 ( 9.908)	Data  8.782 ( 8.782)	Loss 6.8485e-02 (6.8485e-02) 
2023-05-26 02:34:39.854891: train Epoch: [79][  1/129]	Time  0.976 ( 5.442)	Data  0.001 ( 4.392)	Loss 7.4827e-02 (7.1656e-02) 
2023-05-26 02:34:46.947438: train Epoch: [79][  2/129]	Time  7.093 ( 5.992)	Data  6.118 ( 4.967)	Loss 8.6819e-02 (7.6710e-02) 
2023-05-26 02:34:47.919502: train Epoch: [79][  3/129]	Time  0.972 ( 4.737)	Data  0.001 ( 3.726)	Loss 4.9817e-02 (6.9987e-02) 
2023-05-26 02:34:55.167273: train Epoch: [79][  4/129]	Time  7.248 ( 5.239)	Data  6.277 ( 4.236)	Loss 1.2572e-01 (8.1134e-02) 
2023-05-26 02:34:56.183914: train Epoch: [79][  5/129]	Time  1.017 ( 4.535)	Data  0.001 ( 3.530)	Loss 6.0652e-02 (7.7720e-02) 
2023-05-26 02:35:03.492420: train Epoch: [79][  6/129]	Time  7.309 ( 4.932)	Data  6.329 ( 3.930)	Loss 1.2813e-01 (8.4922e-02) 
2023-05-26 02:35:04.531439: train Epoch: [79][  7/129]	Time  1.039 ( 4.445)	Data  0.001 ( 3.439)	Loss 7.6406e-02 (8.3858e-02) 
2023-05-26 02:35:11.607810: train Epoch: [79][  8/129]	Time  7.076 ( 4.737)	Data  6.101 ( 3.735)	Loss 8.6737e-02 (8.4177e-02) 
2023-05-26 02:35:12.765357: train Epoch: [79][  9/129]	Time  1.158 ( 4.379)	Data  0.001 ( 3.361)	Loss 6.3010e-02 (8.2061e-02) 
2023-05-26 02:35:20.134057: train Epoch: [79][ 10/129]	Time  7.369 ( 4.651)	Data  6.395 ( 3.637)	Loss 5.2786e-02 (7.9399e-02) 
2023-05-26 02:35:21.116293: train Epoch: [79][ 11/129]	Time  0.982 ( 4.345)	Data  0.001 ( 3.334)	Loss 4.8064e-02 (7.6788e-02) 
2023-05-26 02:35:28.214221: train Epoch: [79][ 12/129]	Time  7.098 ( 4.557)	Data  6.117 ( 3.548)	Loss 6.6313e-02 (7.5982e-02) 
2023-05-26 02:35:29.322842: train Epoch: [79][ 13/129]	Time  1.109 ( 4.311)	Data  0.002 ( 3.295)	Loss 6.3717e-02 (7.5106e-02) 
2023-05-26 02:35:36.721910: train Epoch: [79][ 14/129]	Time  7.399 ( 4.517)	Data  6.425 ( 3.504)	Loss 7.5475e-02 (7.5131e-02) 
2023-05-26 02:35:37.757343: train Epoch: [79][ 15/129]	Time  1.035 ( 4.299)	Data  0.002 ( 3.285)	Loss 1.3787e-01 (7.9052e-02) 
2023-05-26 02:35:45.086584: train Epoch: [79][ 16/129]	Time  7.329 ( 4.477)	Data  6.346 ( 3.465)	Loss 8.0587e-02 (7.9142e-02) 
2023-05-26 02:35:46.318054: train Epoch: [79][ 17/129]	Time  1.231 ( 4.297)	Data  0.002 ( 3.272)	Loss 6.7744e-02 (7.8509e-02) 
2023-05-26 02:35:53.116318: train Epoch: [79][ 18/129]	Time  6.798 ( 4.429)	Data  5.816 ( 3.406)	Loss 5.7301e-02 (7.7393e-02) 
2023-05-26 02:35:54.234407: train Epoch: [79][ 19/129]	Time  1.118 ( 4.263)	Data  0.001 ( 3.236)	Loss 5.8444e-02 (7.6445e-02) 
2023-05-26 02:36:01.102391: train Epoch: [79][ 20/129]	Time  6.868 ( 4.387)	Data  5.890 ( 3.362)	Loss 6.2369e-02 (7.5775e-02) 
2023-05-26 02:36:02.076606: train Epoch: [79][ 21/129]	Time  0.974 ( 4.232)	Data  0.001 ( 3.210)	Loss 7.6407e-02 (7.5804e-02) 
2023-05-26 02:36:08.920166: train Epoch: [79][ 22/129]	Time  6.844 ( 4.346)	Data  5.615 ( 3.314)	Loss 1.0644e-01 (7.7136e-02) 
2023-05-26 02:36:10.273847: train Epoch: [79][ 23/129]	Time  1.354 ( 4.221)	Data  0.001 ( 3.176)	Loss 7.1546e-02 (7.6903e-02) 
2023-05-26 02:36:13.942417: train Epoch: [79][ 24/129]	Time  3.669 ( 4.199)	Data  2.694 ( 3.157)	Loss 8.8914e-02 (7.7384e-02) 
2023-05-26 02:36:14.912284: train Epoch: [79][ 25/129]	Time  0.970 ( 4.075)	Data  0.001 ( 3.036)	Loss 1.2757e-01 (7.9314e-02) 
2023-05-26 02:36:21.805982: train Epoch: [79][ 26/129]	Time  6.894 ( 4.179)	Data  5.918 ( 3.142)	Loss 9.3983e-02 (7.9857e-02) 
2023-05-26 02:36:22.777779: train Epoch: [79][ 27/129]	Time  0.972 ( 4.065)	Data  0.001 ( 3.030)	Loss 8.5345e-02 (8.0053e-02) 
2023-05-26 02:36:29.947795: train Epoch: [79][ 28/129]	Time  7.170 ( 4.172)	Data  6.193 ( 3.139)	Loss 5.7421e-02 (7.9273e-02) 
2023-05-26 02:36:30.929878: train Epoch: [79][ 29/129]	Time  0.982 ( 4.065)	Data  0.002 ( 3.035)	Loss 6.4536e-02 (7.8781e-02) 
2023-05-26 02:36:38.428009: train Epoch: [79][ 30/129]	Time  7.498 ( 4.176)	Data  6.517 ( 3.147)	Loss 1.2433e-01 (8.0251e-02) 
2023-05-26 02:36:39.400286: train Epoch: [79][ 31/129]	Time  0.972 ( 4.076)	Data  0.001 ( 3.049)	Loss 9.8874e-02 (8.0833e-02) 
2023-05-26 02:36:46.653971: train Epoch: [79][ 32/129]	Time  7.254 ( 4.172)	Data  6.283 ( 3.147)	Loss 4.8791e-02 (7.9862e-02) 
2023-05-26 02:36:47.618391: train Epoch: [79][ 33/129]	Time  0.964 ( 4.078)	Data  0.001 ( 3.054)	Loss 5.0747e-02 (7.9005e-02) 
2023-05-26 02:36:55.222039: train Epoch: [79][ 34/129]	Time  7.604 ( 4.179)	Data  6.610 ( 3.156)	Loss 6.2957e-02 (7.8547e-02) 
2023-05-26 02:36:56.216910: train Epoch: [79][ 35/129]	Time  0.995 ( 4.090)	Data  0.001 ( 3.068)	Loss 7.0067e-02 (7.8311e-02) 
2023-05-26 02:37:03.318591: train Epoch: [79][ 36/129]	Time  7.102 ( 4.172)	Data  6.132 ( 3.151)	Loss 1.2760e-01 (7.9644e-02) 
2023-05-26 02:37:04.292240: train Epoch: [